# Comparing `tmp/torchrl-0.1.0-cp39-cp39-win_amd64.whl.zip` & `tmp/torchrl-0.1.1-cp39-cp39-win_amd64.whl.zip`

## zipinfo {}

```diff
@@ -1,124 +1,129 @@
-Zip file size: 482176 bytes, number of entries: 122
--rw-rw-rw-  2.0 fat      183 b- defN 23-Mar-16 20:30 build_tools/__init__.py
--rw-rw-rw-  2.0 fat      245 b- defN 23-Mar-16 20:30 build_tools/setup_helpers/__init__.py
--rw-rw-rw-  2.0 fat     6085 b- defN 23-Mar-16 20:30 build_tools/setup_helpers/extension.py
--rw-rw-rw-  2.0 fat      957 b- defN 23-Mar-16 20:30 torchrl/__init__.py
--rw-rw-rw-  2.0 fat      868 b- defN 23-Mar-16 20:30 torchrl/_extension.py
--rw-rw-rw-  2.0 fat   330240 b- defN 23-Mar-16 20:33 torchrl/_torchrl.pyd
--rw-rw-rw-  2.0 fat     9652 b- defN 23-Mar-16 20:30 torchrl/_utils.py
--rw-rw-rw-  2.0 fat      323 b- defN 23-Mar-16 20:30 torchrl/collectors/__init__.py
--rw-rw-rw-  2.0 fat    87773 b- defN 23-Mar-16 20:30 torchrl/collectors/collectors.py
--rw-rw-rw-  2.0 fat     3847 b- defN 23-Mar-16 20:30 torchrl/collectors/utils.py
--rw-rw-rw-  2.0 fat      381 b- defN 23-Mar-16 20:30 torchrl/collectors/distributed/__init__.py
--rw-rw-rw-  2.0 fat      674 b- defN 23-Mar-16 20:30 torchrl/collectors/distributed/default_configs.py
--rw-rw-rw-  2.0 fat    33562 b- defN 23-Mar-16 20:30 torchrl/collectors/distributed/generic.py
--rw-rw-rw-  2.0 fat    27373 b- defN 23-Mar-16 20:30 torchrl/collectors/distributed/rpc.py
--rw-rw-rw-  2.0 fat    19805 b- defN 23-Mar-16 20:30 torchrl/collectors/distributed/sync.py
--rw-rw-rw-  2.0 fat     6005 b- defN 23-Mar-16 20:30 torchrl/collectors/distributed/utils.py
--rw-rw-rw-  2.0 fat      822 b- defN 23-Mar-16 20:30 torchrl/data/__init__.py
--rw-rw-rw-  2.0 fat    79465 b- defN 23-Mar-16 20:30 torchrl/data/tensor_specs.py
--rw-rw-rw-  2.0 fat     2061 b- defN 23-Mar-16 20:30 torchrl/data/utils.py
--rw-rw-rw-  2.0 fat       40 b- defN 23-Mar-16 20:30 torchrl/data/datasets/__init__.py
--rw-rw-rw-  2.0 fat    11118 b- defN 23-Mar-16 20:30 torchrl/data/datasets/d4rl.py
--rw-rw-rw-  2.0 fat      219 b- defN 23-Mar-16 20:30 torchrl/data/postprocs/__init__.py
--rw-rw-rw-  2.0 fat     9361 b- defN 23-Mar-16 20:30 torchrl/data/postprocs/postprocs.py
--rw-rw-rw-  2.0 fat      620 b- defN 23-Mar-16 20:30 torchrl/data/replay_buffers/__init__.py
--rw-rw-rw-  2.0 fat    25854 b- defN 23-Mar-16 20:30 torchrl/data/replay_buffers/replay_buffers.py
--rw-rw-rw-  2.0 fat    11363 b- defN 23-Mar-16 20:30 torchrl/data/replay_buffers/samplers.py
--rw-rw-rw-  2.0 fat    16631 b- defN 23-Mar-16 20:30 torchrl/data/replay_buffers/storages.py
--rw-rw-rw-  2.0 fat     1079 b- defN 23-Mar-16 20:30 torchrl/data/replay_buffers/utils.py
--rw-rw-rw-  2.0 fat     2486 b- defN 23-Mar-16 20:30 torchrl/data/replay_buffers/writers.py
--rw-rw-rw-  2.0 fat     1258 b- defN 23-Mar-16 20:30 torchrl/envs/__init__.py
--rw-rw-rw-  2.0 fat    37573 b- defN 23-Mar-16 20:30 torchrl/envs/common.py
--rw-rw-rw-  2.0 fat     7603 b- defN 23-Mar-16 20:30 torchrl/envs/env_creator.py
--rw-rw-rw-  2.0 fat    12623 b- defN 23-Mar-16 20:30 torchrl/envs/gym_like.py
--rw-rw-rw-  2.0 fat    15289 b- defN 23-Mar-16 20:30 torchrl/envs/utils.py
--rw-rw-rw-  2.0 fat    51335 b- defN 23-Mar-16 20:30 torchrl/envs/vec_env.py
--rw-rw-rw-  2.0 fat      183 b- defN 23-Mar-16 20:30 torchrl/envs/libs/__init__.py
--rw-rw-rw-  2.0 fat    14334 b- defN 23-Mar-16 20:30 torchrl/envs/libs/brax.py
--rw-rw-rw-  2.0 fat    12161 b- defN 23-Mar-16 20:30 torchrl/envs/libs/dm_control.py
--rw-rw-rw-  2.0 fat    18339 b- defN 23-Mar-16 20:30 torchrl/envs/libs/gym.py
--rw-rw-rw-  2.0 fat     2902 b- defN 23-Mar-16 20:30 torchrl/envs/libs/habitat.py
--rw-rw-rw-  2.0 fat     4305 b- defN 23-Mar-16 20:30 torchrl/envs/libs/jax_utils.py
--rw-rw-rw-  2.0 fat    12761 b- defN 23-Mar-16 20:30 torchrl/envs/libs/jumanji.py
--rw-rw-rw-  2.0 fat     5265 b- defN 23-Mar-16 20:30 torchrl/envs/libs/utils.py
--rw-rw-rw-  2.0 fat    16414 b- defN 23-Mar-16 20:30 torchrl/envs/libs/vmas.py
--rw-rw-rw-  2.0 fat      224 b- defN 23-Mar-16 20:30 torchrl/envs/model_based/__init__.py
--rw-rw-rw-  2.0 fat     8025 b- defN 23-Mar-16 20:30 torchrl/envs/model_based/common.py
--rw-rw-rw-  2.0 fat     2792 b- defN 23-Mar-16 20:30 torchrl/envs/model_based/dreamer.py
--rw-rw-rw-  2.0 fat      996 b- defN 23-Mar-16 20:30 torchrl/envs/transforms/__init__.py
--rw-rw-rw-  2.0 fat     1485 b- defN 23-Mar-16 20:30 torchrl/envs/transforms/functional.py
--rw-rw-rw-  2.0 fat    13722 b- defN 23-Mar-16 20:30 torchrl/envs/transforms/r3m.py
--rw-rw-rw-  2.0 fat   141937 b- defN 23-Mar-16 20:30 torchrl/envs/transforms/transforms.py
--rw-rw-rw-  2.0 fat      408 b- defN 23-Mar-16 20:30 torchrl/envs/transforms/utils.py
--rw-rw-rw-  2.0 fat    14083 b- defN 23-Mar-16 20:30 torchrl/envs/transforms/vip.py
--rw-rw-rw-  2.0 fat     1269 b- defN 23-Mar-16 20:30 torchrl/modules/__init__.py
--rw-rw-rw-  2.0 fat      581 b- defN 23-Mar-16 20:30 torchrl/modules/distributions/__init__.py
--rw-rw-rw-  2.0 fat    21186 b- defN 23-Mar-16 20:30 torchrl/modules/distributions/continuous.py
--rw-rw-rw-  2.0 fat     2619 b- defN 23-Mar-16 20:30 torchrl/modules/distributions/discrete.py
--rw-rw-rw-  2.0 fat     5988 b- defN 23-Mar-16 20:30 torchrl/modules/distributions/truncated_normal.py
--rw-rw-rw-  2.0 fat     1133 b- defN 23-Mar-16 20:30 torchrl/modules/distributions/utils.py
--rw-rw-rw-  2.0 fat      580 b- defN 23-Mar-16 20:30 torchrl/modules/models/__init__.py
--rw-rw-rw-  2.0 fat    20146 b- defN 23-Mar-16 20:30 torchrl/modules/models/exploration.py
--rw-rw-rw-  2.0 fat    11860 b- defN 23-Mar-16 20:30 torchrl/modules/models/model_based.py
--rw-rw-rw-  2.0 fat    43772 b- defN 23-Mar-16 20:30 torchrl/modules/models/models.py
--rw-rw-rw-  2.0 fat     4023 b- defN 23-Mar-16 20:30 torchrl/modules/models/utils.py
--rw-rw-rw-  2.0 fat      281 b- defN 23-Mar-16 20:30 torchrl/modules/planners/__init__.py
--rw-rw-rw-  2.0 fat     9147 b- defN 23-Mar-16 20:30 torchrl/modules/planners/cem.py
--rw-rw-rw-  2.0 fat     2455 b- defN 23-Mar-16 20:30 torchrl/modules/planners/common.py
--rw-rw-rw-  2.0 fat    10333 b- defN 23-Mar-16 20:30 torchrl/modules/planners/mppi.py
--rw-rw-rw-  2.0 fat      710 b- defN 23-Mar-16 20:30 torchrl/modules/tensordict_module/__init__.py
--rw-rw-rw-  2.0 fat    37611 b- defN 23-Mar-16 20:30 torchrl/modules/tensordict_module/actors.py
--rw-rw-rw-  2.0 fat    16488 b- defN 23-Mar-16 20:30 torchrl/modules/tensordict_module/common.py
--rw-rw-rw-  2.0 fat    18755 b- defN 23-Mar-16 20:30 torchrl/modules/tensordict_module/exploration.py
--rw-rw-rw-  2.0 fat    11277 b- defN 23-Mar-16 20:30 torchrl/modules/tensordict_module/probabilistic.py
--rw-rw-rw-  2.0 fat     5828 b- defN 23-Mar-16 20:30 torchrl/modules/tensordict_module/sequence.py
--rw-rw-rw-  2.0 fat     1318 b- defN 23-Mar-16 20:30 torchrl/modules/tensordict_module/world_models.py
--rw-rw-rw-  2.0 fat     3982 b- defN 23-Mar-16 20:30 torchrl/modules/utils/__init__.py
--rw-rw-rw-  2.0 fat     2435 b- defN 23-Mar-16 20:30 torchrl/modules/utils/mappings.py
--rw-rw-rw-  2.0 fat      829 b- defN 23-Mar-16 20:30 torchrl/objectives/__init__.py
--rw-rw-rw-  2.0 fat     5863 b- defN 23-Mar-16 20:30 torchrl/objectives/a2c.py
--rw-rw-rw-  2.0 fat    14310 b- defN 23-Mar-16 20:30 torchrl/objectives/common.py
--rw-rw-rw-  2.0 fat     6564 b- defN 23-Mar-16 20:30 torchrl/objectives/ddpg.py
--rw-rw-rw-  2.0 fat    10691 b- defN 23-Mar-16 20:30 torchrl/objectives/deprecated.py
--rw-rw-rw-  2.0 fat    12339 b- defN 23-Mar-16 20:30 torchrl/objectives/dqn.py
--rw-rw-rw-  2.0 fat    10819 b- defN 23-Mar-16 20:30 torchrl/objectives/dreamer.py
--rw-rw-rw-  2.0 fat     2119 b- defN 23-Mar-16 20:30 torchrl/objectives/functional.py
--rw-rw-rw-  2.0 fat     9414 b- defN 23-Mar-16 20:30 torchrl/objectives/iql.py
--rw-rw-rw-  2.0 fat    17489 b- defN 23-Mar-16 20:30 torchrl/objectives/ppo.py
--rw-rw-rw-  2.0 fat    12398 b- defN 23-Mar-16 20:30 torchrl/objectives/redq.py
--rw-rw-rw-  2.0 fat     3474 b- defN 23-Mar-16 20:30 torchrl/objectives/reinforce.py
--rw-rw-rw-  2.0 fat    16418 b- defN 23-Mar-16 20:30 torchrl/objectives/sac.py
--rw-rw-rw-  2.0 fat     8291 b- defN 23-Mar-16 20:30 torchrl/objectives/td3.py
--rw-rw-rw-  2.0 fat    12368 b- defN 23-Mar-16 20:30 torchrl/objectives/utils.py
--rw-rw-rw-  2.0 fat      244 b- defN 23-Mar-16 20:30 torchrl/objectives/value/__init__.py
--rw-rw-rw-  2.0 fat    24520 b- defN 23-Mar-16 20:30 torchrl/objectives/value/advantages.py
--rw-rw-rw-  2.0 fat    20126 b- defN 23-Mar-16 20:30 torchrl/objectives/value/functional.py
--rw-rw-rw-  2.0 fat      317 b- defN 23-Mar-16 20:30 torchrl/objectives/value/pg.py
--rw-rw-rw-  2.0 fat     7629 b- defN 23-Mar-16 20:30 torchrl/objectives/value/utils.py
--rw-rw-rw-  2.0 fat     1724 b- defN 23-Mar-16 20:30 torchrl/objectives/value/vtrace.py
--rw-rw-rw-  2.0 fat      242 b- defN 23-Mar-16 20:30 torchrl/record/__init__.py
--rw-rw-rw-  2.0 fat     6831 b- defN 23-Mar-16 20:30 torchrl/record/recorder.py
--rw-rw-rw-  2.0 fat      413 b- defN 23-Mar-16 20:30 torchrl/record/loggers/__init__.py
--rw-rw-rw-  2.0 fat     1130 b- defN 23-Mar-16 20:30 torchrl/record/loggers/common.py
--rw-rw-rw-  2.0 fat     4650 b- defN 23-Mar-16 20:30 torchrl/record/loggers/csv.py
--rw-rw-rw-  2.0 fat     4344 b- defN 23-Mar-16 20:30 torchrl/record/loggers/mlflow.py
--rw-rw-rw-  2.0 fat     3412 b- defN 23-Mar-16 20:30 torchrl/record/loggers/tensorboard.py
--rw-rw-rw-  2.0 fat     2248 b- defN 23-Mar-16 20:30 torchrl/record/loggers/utils.py
--rw-rw-rw-  2.0 fat     6025 b- defN 23-Mar-16 20:30 torchrl/record/loggers/wandb.py
--rw-rw-rw-  2.0 fat      467 b- defN 23-Mar-16 20:30 torchrl/trainers/__init__.py
--rw-rw-rw-  2.0 fat    49723 b- defN 23-Mar-16 20:30 torchrl/trainers/trainers.py
--rw-rw-rw-  2.0 fat      942 b- defN 23-Mar-16 20:30 torchrl/trainers/helpers/__init__.py
--rw-rw-rw-  2.0 fat    19204 b- defN 23-Mar-16 20:30 torchrl/trainers/helpers/collectors.py
--rw-rw-rw-  2.0 fat    22562 b- defN 23-Mar-16 20:30 torchrl/trainers/helpers/envs.py
--rw-rw-rw-  2.0 fat     1206 b- defN 23-Mar-16 20:30 torchrl/trainers/helpers/logger.py
--rw-rw-rw-  2.0 fat    10928 b- defN 23-Mar-16 20:30 torchrl/trainers/helpers/losses.py
--rw-rw-rw-  2.0 fat    76993 b- defN 23-Mar-16 20:30 torchrl/trainers/helpers/models.py
--rw-rw-rw-  2.0 fat     1903 b- defN 23-Mar-16 20:30 torchrl/trainers/helpers/replay_buffer.py
--rw-rw-rw-  2.0 fat    11891 b- defN 23-Mar-16 20:30 torchrl/trainers/helpers/trainers.py
--rw-rw-rw-  2.0 fat     1119 b- defN 23-Mar-16 20:33 torchrl-0.1.0.dist-info/LICENSE
--rw-rw-rw-  2.0 fat    28394 b- defN 23-Mar-16 20:33 torchrl-0.1.0.dist-info/METADATA
--rw-rw-rw-  2.0 fat      100 b- defN 23-Mar-16 20:33 torchrl-0.1.0.dist-info/WHEEL
--rw-rw-rw-  2.0 fat       20 b- defN 23-Mar-16 20:33 torchrl-0.1.0.dist-info/top_level.txt
--rw-rw-r--  2.0 fat    10893 b- defN 23-Mar-16 20:33 torchrl-0.1.0.dist-info/RECORD
-122 files, 1782472 bytes uncompressed, 464936 bytes compressed:  73.9%
+Zip file size: 549428 bytes, number of entries: 127
+-rw-rw-rw-  2.0 fat      183 b- defN 23-May-06 21:17 build_tools/__init__.py
+-rw-rw-rw-  2.0 fat      245 b- defN 23-May-06 21:17 build_tools/setup_helpers/__init__.py
+-rw-rw-rw-  2.0 fat     6085 b- defN 23-May-06 21:17 build_tools/setup_helpers/extension.py
+-rw-rw-rw-  2.0 fat      957 b- defN 23-May-06 21:17 torchrl/__init__.py
+-rw-rw-rw-  2.0 fat      868 b- defN 23-May-06 21:17 torchrl/_extension.py
+-rw-rw-rw-  2.0 fat   330240 b- defN 23-May-06 21:20 torchrl/_torchrl.pyd
+-rw-rw-rw-  2.0 fat    17746 b- defN 23-May-06 21:17 torchrl/_utils.py
+-rw-rw-rw-  2.0 fat      366 b- defN 23-May-06 21:17 torchrl/collectors/__init__.py
+-rw-rw-rw-  2.0 fat    97240 b- defN 23-May-06 21:17 torchrl/collectors/collectors.py
+-rw-rw-rw-  2.0 fat     3847 b- defN 23-May-06 21:17 torchrl/collectors/utils.py
+-rw-rw-rw-  2.0 fat      412 b- defN 23-May-06 21:17 torchrl/collectors/distributed/__init__.py
+-rw-rw-rw-  2.0 fat      674 b- defN 23-May-06 21:17 torchrl/collectors/distributed/default_configs.py
+-rw-rw-rw-  2.0 fat    34086 b- defN 23-May-06 21:17 torchrl/collectors/distributed/generic.py
+-rw-rw-rw-  2.0 fat    27837 b- defN 23-May-06 21:17 torchrl/collectors/distributed/ray.py
+-rw-rw-rw-  2.0 fat    27697 b- defN 23-May-06 21:17 torchrl/collectors/distributed/rpc.py
+-rw-rw-rw-  2.0 fat    20055 b- defN 23-May-06 21:17 torchrl/collectors/distributed/sync.py
+-rw-rw-rw-  2.0 fat     6244 b- defN 23-May-06 21:17 torchrl/collectors/distributed/utils.py
+-rw-rw-rw-  2.0 fat      905 b- defN 23-May-06 21:17 torchrl/data/__init__.py
+-rw-rw-rw-  2.0 fat   118083 b- defN 23-May-06 21:17 torchrl/data/tensor_specs.py
+-rw-rw-rw-  2.0 fat     2061 b- defN 23-May-06 21:17 torchrl/data/utils.py
+-rw-rw-rw-  2.0 fat       84 b- defN 23-May-06 21:17 torchrl/data/datasets/__init__.py
+-rw-rw-rw-  2.0 fat    12501 b- defN 23-May-06 21:17 torchrl/data/datasets/d4rl.py
+-rw-rw-rw-  2.0 fat     6333 b- defN 23-May-06 21:17 torchrl/data/datasets/openml.py
+-rw-rw-rw-  2.0 fat      219 b- defN 23-May-06 21:17 torchrl/data/postprocs/__init__.py
+-rw-rw-rw-  2.0 fat     9361 b- defN 23-May-06 21:17 torchrl/data/postprocs/postprocs.py
+-rw-rw-rw-  2.0 fat      620 b- defN 23-May-06 21:17 torchrl/data/replay_buffers/__init__.py
+-rw-rw-rw-  2.0 fat    42723 b- defN 23-May-06 21:17 torchrl/data/replay_buffers/replay_buffers.py
+-rw-rw-rw-  2.0 fat    11538 b- defN 23-May-06 21:17 torchrl/data/replay_buffers/samplers.py
+-rw-rw-rw-  2.0 fat    17810 b- defN 23-May-06 21:17 torchrl/data/replay_buffers/storages.py
+-rw-rw-rw-  2.0 fat     1079 b- defN 23-May-06 21:17 torchrl/data/replay_buffers/utils.py
+-rw-rw-rw-  2.0 fat     2486 b- defN 23-May-06 21:17 torchrl/data/replay_buffers/writers.py
+-rw-rw-rw-  2.0 fat     1515 b- defN 23-May-06 21:17 torchrl/envs/__init__.py
+-rw-rw-rw-  2.0 fat    43940 b- defN 23-May-06 21:17 torchrl/envs/common.py
+-rw-rw-rw-  2.0 fat     7603 b- defN 23-May-06 21:17 torchrl/envs/env_creator.py
+-rw-rw-rw-  2.0 fat    12626 b- defN 23-May-06 21:17 torchrl/envs/gym_like.py
+-rw-rw-rw-  2.0 fat    18346 b- defN 23-May-06 21:17 torchrl/envs/utils.py
+-rw-rw-rw-  2.0 fat    52854 b- defN 23-May-06 21:17 torchrl/envs/vec_env.py
+-rw-rw-rw-  2.0 fat      183 b- defN 23-May-06 21:17 torchrl/envs/libs/__init__.py
+-rw-rw-rw-  2.0 fat    15512 b- defN 23-May-06 21:17 torchrl/envs/libs/brax.py
+-rw-rw-rw-  2.0 fat    12169 b- defN 23-May-06 21:17 torchrl/envs/libs/dm_control.py
+-rw-rw-rw-  2.0 fat    25967 b- defN 23-May-06 21:17 torchrl/envs/libs/gym.py
+-rw-rw-rw-  2.0 fat     2857 b- defN 23-May-06 21:17 torchrl/envs/libs/habitat.py
+-rw-rw-rw-  2.0 fat     4699 b- defN 23-May-06 21:17 torchrl/envs/libs/jax_utils.py
+-rw-rw-rw-  2.0 fat    12836 b- defN 23-May-06 21:17 torchrl/envs/libs/jumanji.py
+-rw-rw-rw-  2.0 fat     5260 b- defN 23-May-06 21:17 torchrl/envs/libs/openml.py
+-rw-rw-rw-  2.0 fat     5319 b- defN 23-May-06 21:17 torchrl/envs/libs/utils.py
+-rw-rw-rw-  2.0 fat    18211 b- defN 23-May-06 21:17 torchrl/envs/libs/vmas.py
+-rw-rw-rw-  2.0 fat      224 b- defN 23-May-06 21:17 torchrl/envs/model_based/__init__.py
+-rw-rw-rw-  2.0 fat     8029 b- defN 23-May-06 21:17 torchrl/envs/model_based/common.py
+-rw-rw-rw-  2.0 fat     2790 b- defN 23-May-06 21:17 torchrl/envs/model_based/dreamer.py
+-rw-rw-rw-  2.0 fat     1040 b- defN 23-May-06 21:17 torchrl/envs/transforms/__init__.py
+-rw-rw-rw-  2.0 fat     1485 b- defN 23-May-06 21:17 torchrl/envs/transforms/functional.py
+-rw-rw-rw-  2.0 fat    13726 b- defN 23-May-06 21:17 torchrl/envs/transforms/r3m.py
+-rw-rw-rw-  2.0 fat   166778 b- defN 23-May-06 21:17 torchrl/envs/transforms/transforms.py
+-rw-rw-rw-  2.0 fat      408 b- defN 23-May-06 21:17 torchrl/envs/transforms/utils.py
+-rw-rw-rw-  2.0 fat    14087 b- defN 23-May-06 21:17 torchrl/envs/transforms/vip.py
+-rw-rw-rw-  2.0 fat     1420 b- defN 23-May-06 21:17 torchrl/modules/__init__.py
+-rw-rw-rw-  2.0 fat      600 b- defN 23-May-06 21:17 torchrl/modules/distributions/__init__.py
+-rw-rw-rw-  2.0 fat    21253 b- defN 23-May-06 21:17 torchrl/modules/distributions/continuous.py
+-rw-rw-rw-  2.0 fat     9293 b- defN 23-May-06 21:17 torchrl/modules/distributions/discrete.py
+-rw-rw-rw-  2.0 fat     5988 b- defN 23-May-06 21:17 torchrl/modules/distributions/truncated_normal.py
+-rw-rw-rw-  2.0 fat     3841 b- defN 23-May-06 21:17 torchrl/modules/distributions/utils.py
+-rw-rw-rw-  2.0 fat      580 b- defN 23-May-06 21:17 torchrl/modules/models/__init__.py
+-rw-rw-rw-  2.0 fat    20516 b- defN 23-May-06 21:17 torchrl/modules/models/exploration.py
+-rw-rw-rw-  2.0 fat    11863 b- defN 23-May-06 21:17 torchrl/modules/models/model_based.py
+-rw-rw-rw-  2.0 fat    45667 b- defN 23-May-06 21:17 torchrl/modules/models/models.py
+-rw-rw-rw-  2.0 fat     4023 b- defN 23-May-06 21:17 torchrl/modules/models/utils.py
+-rw-rw-rw-  2.0 fat      281 b- defN 23-May-06 21:17 torchrl/modules/planners/__init__.py
+-rw-rw-rw-  2.0 fat     9572 b- defN 23-May-06 21:17 torchrl/modules/planners/cem.py
+-rw-rw-rw-  2.0 fat     2455 b- defN 23-May-06 21:17 torchrl/modules/planners/common.py
+-rw-rw-rw-  2.0 fat    10683 b- defN 23-May-06 21:17 torchrl/modules/planners/mppi.py
+-rw-rw-rw-  2.0 fat      865 b- defN 23-May-06 21:17 torchrl/modules/tensordict_module/__init__.py
+-rw-rw-rw-  2.0 fat    71610 b- defN 23-May-06 21:17 torchrl/modules/tensordict_module/actors.py
+-rw-rw-rw-  2.0 fat    17209 b- defN 23-May-06 21:17 torchrl/modules/tensordict_module/common.py
+-rw-rw-rw-  2.0 fat    24439 b- defN 23-May-06 21:17 torchrl/modules/tensordict_module/exploration.py
+-rw-rw-rw-  2.0 fat    11471 b- defN 23-May-06 21:17 torchrl/modules/tensordict_module/probabilistic.py
+-rw-rw-rw-  2.0 fat    18148 b- defN 23-May-06 21:17 torchrl/modules/tensordict_module/rnn.py
+-rw-rw-rw-  2.0 fat     5838 b- defN 23-May-06 21:17 torchrl/modules/tensordict_module/sequence.py
+-rw-rw-rw-  2.0 fat     1360 b- defN 23-May-06 21:17 torchrl/modules/tensordict_module/world_models.py
+-rw-rw-rw-  2.0 fat     3984 b- defN 23-May-06 21:17 torchrl/modules/utils/__init__.py
+-rw-rw-rw-  2.0 fat     2435 b- defN 23-May-06 21:17 torchrl/modules/utils/mappings.py
+-rw-rw-rw-  2.0 fat     1368 b- defN 23-May-06 21:17 torchrl/modules/utils/utils.py
+-rw-rw-rw-  2.0 fat      895 b- defN 23-May-06 21:17 torchrl/objectives/__init__.py
+-rw-rw-rw-  2.0 fat     9506 b- defN 23-May-06 21:17 torchrl/objectives/a2c.py
+-rw-rw-rw-  2.0 fat    23370 b- defN 23-May-06 21:17 torchrl/objectives/common.py
+-rw-rw-rw-  2.0 fat     7549 b- defN 23-May-06 21:17 torchrl/objectives/ddpg.py
+-rw-rw-rw-  2.0 fat    12829 b- defN 23-May-06 21:17 torchrl/objectives/deprecated.py
+-rw-rw-rw-  2.0 fat    17568 b- defN 23-May-06 21:17 torchrl/objectives/dqn.py
+-rw-rw-rw-  2.0 fat    13161 b- defN 23-May-06 21:17 torchrl/objectives/dreamer.py
+-rw-rw-rw-  2.0 fat     2119 b- defN 23-May-06 21:17 torchrl/objectives/functional.py
+-rw-rw-rw-  2.0 fat    10465 b- defN 23-May-06 21:17 torchrl/objectives/iql.py
+-rw-rw-rw-  2.0 fat    29370 b- defN 23-May-06 21:17 torchrl/objectives/ppo.py
+-rw-rw-rw-  2.0 fat    14194 b- defN 23-May-06 21:17 torchrl/objectives/redq.py
+-rw-rw-rw-  2.0 fat     7221 b- defN 23-May-06 21:17 torchrl/objectives/reinforce.py
+-rw-rw-rw-  2.0 fat    30845 b- defN 23-May-06 21:17 torchrl/objectives/sac.py
+-rw-rw-rw-  2.0 fat     9845 b- defN 23-May-06 21:17 torchrl/objectives/td3.py
+-rw-rw-rw-  2.0 fat    14764 b- defN 23-May-06 21:17 torchrl/objectives/utils.py
+-rw-rw-rw-  2.0 fat      371 b- defN 23-May-06 21:17 torchrl/objectives/value/__init__.py
+-rw-rw-rw-  2.0 fat    42893 b- defN 23-May-06 21:17 torchrl/objectives/value/advantages.py
+-rw-rw-rw-  2.0 fat    41525 b- defN 23-May-06 21:17 torchrl/objectives/value/functional.py
+-rw-rw-rw-  2.0 fat      317 b- defN 23-May-06 21:17 torchrl/objectives/value/pg.py
+-rw-rw-rw-  2.0 fat     7683 b- defN 23-May-06 21:17 torchrl/objectives/value/utils.py
+-rw-rw-rw-  2.0 fat     1724 b- defN 23-May-06 21:17 torchrl/objectives/value/vtrace.py
+-rw-rw-rw-  2.0 fat      242 b- defN 23-May-06 21:17 torchrl/record/__init__.py
+-rw-rw-rw-  2.0 fat     6839 b- defN 23-May-06 21:17 torchrl/record/recorder.py
+-rw-rw-rw-  2.0 fat      413 b- defN 23-May-06 21:17 torchrl/record/loggers/__init__.py
+-rw-rw-rw-  2.0 fat     1130 b- defN 23-May-06 21:17 torchrl/record/loggers/common.py
+-rw-rw-rw-  2.0 fat     4709 b- defN 23-May-06 21:17 torchrl/record/loggers/csv.py
+-rw-rw-rw-  2.0 fat     4344 b- defN 23-May-06 21:17 torchrl/record/loggers/mlflow.py
+-rw-rw-rw-  2.0 fat     3412 b- defN 23-May-06 21:17 torchrl/record/loggers/tensorboard.py
+-rw-rw-rw-  2.0 fat     2248 b- defN 23-May-06 21:17 torchrl/record/loggers/utils.py
+-rw-rw-rw-  2.0 fat     6025 b- defN 23-May-06 21:17 torchrl/record/loggers/wandb.py
+-rw-rw-rw-  2.0 fat      467 b- defN 23-May-06 21:17 torchrl/trainers/__init__.py
+-rw-rw-rw-  2.0 fat    52048 b- defN 23-May-06 21:17 torchrl/trainers/trainers.py
+-rw-rw-rw-  2.0 fat      942 b- defN 23-May-06 21:17 torchrl/trainers/helpers/__init__.py
+-rw-rw-rw-  2.0 fat    19309 b- defN 23-May-06 21:17 torchrl/trainers/helpers/collectors.py
+-rw-rw-rw-  2.0 fat    22620 b- defN 23-May-06 21:17 torchrl/trainers/helpers/envs.py
+-rw-rw-rw-  2.0 fat     1206 b- defN 23-May-06 21:17 torchrl/trainers/helpers/logger.py
+-rw-rw-rw-  2.0 fat    10920 b- defN 23-May-06 21:17 torchrl/trainers/helpers/losses.py
+-rw-rw-rw-  2.0 fat    77293 b- defN 23-May-06 21:17 torchrl/trainers/helpers/models.py
+-rw-rw-rw-  2.0 fat     1939 b- defN 23-May-06 21:17 torchrl/trainers/helpers/replay_buffer.py
+-rw-rw-rw-  2.0 fat    12076 b- defN 23-May-06 21:17 torchrl/trainers/helpers/trainers.py
+-rw-rw-rw-  2.0 fat     1119 b- defN 23-May-06 21:20 torchrl-0.1.1.dist-info/LICENSE
+-rw-rw-rw-  2.0 fat    28554 b- defN 23-May-06 21:20 torchrl-0.1.1.dist-info/METADATA
+-rw-rw-rw-  2.0 fat      100 b- defN 23-May-06 21:20 torchrl-0.1.1.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat       20 b- defN 23-May-06 21:20 torchrl-0.1.1.dist-info/top_level.txt
+-rw-rw-r--  2.0 fat    11349 b- defN 23-May-06 21:20 torchrl-0.1.1.dist-info/RECORD
+127 files, 2123349 bytes uncompressed, 531478 bytes compressed:  75.0%
```

## zipnote {}

```diff
@@ -33,14 +33,17 @@
 
 Filename: torchrl/collectors/distributed/default_configs.py
 Comment: 
 
 Filename: torchrl/collectors/distributed/generic.py
 Comment: 
 
+Filename: torchrl/collectors/distributed/ray.py
+Comment: 
+
 Filename: torchrl/collectors/distributed/rpc.py
 Comment: 
 
 Filename: torchrl/collectors/distributed/sync.py
 Comment: 
 
 Filename: torchrl/collectors/distributed/utils.py
@@ -57,14 +60,17 @@
 
 Filename: torchrl/data/datasets/__init__.py
 Comment: 
 
 Filename: torchrl/data/datasets/d4rl.py
 Comment: 
 
+Filename: torchrl/data/datasets/openml.py
+Comment: 
+
 Filename: torchrl/data/postprocs/__init__.py
 Comment: 
 
 Filename: torchrl/data/postprocs/postprocs.py
 Comment: 
 
 Filename: torchrl/data/replay_buffers/__init__.py
@@ -120,14 +126,17 @@
 
 Filename: torchrl/envs/libs/jax_utils.py
 Comment: 
 
 Filename: torchrl/envs/libs/jumanji.py
 Comment: 
 
+Filename: torchrl/envs/libs/openml.py
+Comment: 
+
 Filename: torchrl/envs/libs/utils.py
 Comment: 
 
 Filename: torchrl/envs/libs/vmas.py
 Comment: 
 
 Filename: torchrl/envs/model_based/__init__.py
@@ -213,26 +222,32 @@
 
 Filename: torchrl/modules/tensordict_module/exploration.py
 Comment: 
 
 Filename: torchrl/modules/tensordict_module/probabilistic.py
 Comment: 
 
+Filename: torchrl/modules/tensordict_module/rnn.py
+Comment: 
+
 Filename: torchrl/modules/tensordict_module/sequence.py
 Comment: 
 
 Filename: torchrl/modules/tensordict_module/world_models.py
 Comment: 
 
 Filename: torchrl/modules/utils/__init__.py
 Comment: 
 
 Filename: torchrl/modules/utils/mappings.py
 Comment: 
 
+Filename: torchrl/modules/utils/utils.py
+Comment: 
+
 Filename: torchrl/objectives/__init__.py
 Comment: 
 
 Filename: torchrl/objectives/a2c.py
 Comment: 
 
 Filename: torchrl/objectives/common.py
@@ -345,23 +360,23 @@
 
 Filename: torchrl/trainers/helpers/replay_buffer.py
 Comment: 
 
 Filename: torchrl/trainers/helpers/trainers.py
 Comment: 
 
-Filename: torchrl-0.1.0.dist-info/LICENSE
+Filename: torchrl-0.1.1.dist-info/LICENSE
 Comment: 
 
-Filename: torchrl-0.1.0.dist-info/METADATA
+Filename: torchrl-0.1.1.dist-info/METADATA
 Comment: 
 
-Filename: torchrl-0.1.0.dist-info/WHEEL
+Filename: torchrl-0.1.1.dist-info/WHEEL
 Comment: 
 
-Filename: torchrl-0.1.0.dist-info/top_level.txt
+Filename: torchrl-0.1.1.dist-info/top_level.txt
 Comment: 
 
-Filename: torchrl-0.1.0.dist-info/RECORD
+Filename: torchrl-0.1.1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## torchrl/_utils.py

```diff
@@ -1,23 +1,30 @@
 import collections
 
+import functools
+import inspect
+
 import math
 import os
 import sys
 import time
 import warnings
+from copy import copy
 from distutils.util import strtobool
 from functools import wraps
 from importlib import import_module
+from typing import Any, Callable, cast, TypeVar, Union
 
 import numpy as np
 import torch
+from packaging.version import parse
 
 VERBOSE = strtobool(os.environ.get("VERBOSE", "0"))
 _os_is_windows = sys.platform == "win32"
+RL_WARNINGS = strtobool(os.environ.get("RL_WARNINGS", "1"))
 
 
 class timeit:
     """A dirty but easy to use decorator for profiling code."""
 
     _REG = {}
 
@@ -165,15 +172,16 @@
                 import torchsnapshot  # noqa: F401
 
                 _has_ts = True
             except ImportError:
                 _has_ts = False
             if not _has_ts:
                 raise ImportError(
-                    f"torchsnapshot not found, but the backend points to this library. Consider installing torchsnapshot or choose another backend (available backends: {self.backends})"
+                    f"torchsnapshot not found, but the backend points to this library. "
+                    f"Consider installing torchsnapshot or choose another backend (available backends: {self.backends})"
                 )
         return backend
 
     def __getattr__(self, item):
         return getattr(self._get_backend(), item)
 
     def __eq__(self, other):
@@ -190,31 +198,38 @@
 
 
 class implement_for:
     """A version decorator that checks the version in the environment and implements a function with the fitting one.
 
     If specified module is missing or there is no fitting implementation, call of the decorated function
     will lead to the explicit error.
-    In case of intersected ranges, first fitting implementation is used.
+    In case of intersected ranges, last fitting implementation is used.
 
     This wrapper also works to implement different backends for a same function (eg. gym vs gymnasium,
     numpy vs jax-numpy etc).
 
     Args:
-        module_name: version is checked for the module with this name (e.g. "gym").
+        module_name (str or callable): version is checked for the module with this
+            name (e.g. "gym"). If a callable is provided, it should return the
+            module.
         from_version: version from which implementation is compatible. Can be open (None).
         to_version: version from which implementation is no longer compatible. Can be open (None).
 
     Examples:
         >>> @implement_for(“gym”, “0.13”, “0.14”)
         >>> def fun(self, x):
         ...     # Older gym versions will return x + 1
         ...     return x + 1
         ...
-        >>> @implement_for(“gym”, “0.14”, None)
+        >>> @implement_for(“gym”, “0.14”, "0.23")
+        >>> def fun(self, x):
+        ...     # More recent gym versions will return x + 2
+        ...     return x + 2
+        ...
+        >>> @implement_for(lambda: import_module(“gym”), “0.23", None)
         >>> def fun(self, x):
         ...     # More recent gym versions will return x + 2
         ...     return x + 2
         ...
         >>> @implement_for(“gymnasium”, “0.27”, None)
         >>> def fun(self, x):
         ...     # If gymnasium is to be used instead of gym, x+3 will be returned
@@ -222,68 +237,118 @@
         ...
 
         This indicates that the function is compatible with gym 0.13+, but doesn't with gym 0.14+.
     """
 
     # Stores pointers to fitting implementations: dict[func_name] = func_pointer
     _implementations = {}
+    _setters = []
 
     def __init__(
-        self, module_name: str, from_version: str = None, to_version: str = None
+        self,
+        module_name: Union[str, Callable],
+        from_version: str = None,
+        to_version: str = None,
     ):
         self.module_name = module_name
         self.from_version = from_version
         self.to_version = to_version
+        implement_for._setters.append(self)
+
+    @staticmethod
+    def check_version(version, from_version, to_version):
+        return (from_version is None or parse(version) >= parse(from_version)) and (
+            to_version is None or parse(version) < parse(to_version)
+        )
+
+    @staticmethod
+    def get_class_that_defined_method(f):
+        """Returns the class of a method, if it is defined, and None otherwise."""
+        return f.__globals__.get(f.__qualname__.split(".")[0], None)
+
+    @property
+    def func_name(self):
+        return self.fn.__name__
+
+    def module_set(self):
+        """Sets the function in its module, if it exists already."""
+        cls = self.get_class_that_defined_method(self.fn)
+        if cls is None:
+            # class not yet defined
+            return
+        if cls.__class__.__name__ == "function":
+            cls = inspect.getmodule(self.fn)
+        setattr(cls, self.fn.__name__, self.fn)
+
+    @staticmethod
+    def import_module(module_name: Union[Callable, str]) -> str:
+        """Imports module and returns its version."""
+        if not callable(module_name):
+            module = import_module(module_name)
+        else:
+            module = module_name()
+        return module.__version__
 
     def __call__(self, fn):
+        self.fn = fn
 
         # If the module is missing replace the function with the mock.
-        func_name = f"{fn.__module__}.{fn.__name__}"
+        func_name = self.func_name
         implementations = implement_for._implementations
 
         @wraps(fn)
         def unsupported(*args, **kwargs):
             raise ModuleNotFoundError(
                 f"Supported version of '{func_name}' has not been found."
             )
 
+        do_set = False
         # Return fitting implementation if it was encountered before.
         if func_name in implementations:
             try:
                 # check that backends don't conflict
-                module = import_module(self.module_name)
-                version = module.__version__
-
-                if (self.from_version is None or version >= self.from_version) and (
-                    self.to_version is None or version < self.to_version
-                ):
-                    warnings.warn(
-                        f"Got multiple backends for {func_name}. "
-                        f"Using the last queried ({module} with version {version})."
-                    )
-                else:
+                version = self.import_module(self.module_name)
+                if self.check_version(version, self.from_version, self.to_version):
+                    if VERBOSE:
+                        module = import_module(self.module_name)
+                        warnings.warn(
+                            f"Got multiple backends for {func_name}. "
+                            f"Using the last queried ({module} with version {version})."
+                        )
+                    do_set = True
+                if not do_set:
                     return implementations[func_name]
             except ModuleNotFoundError:
                 # then it's ok, there is no conflict
                 return implementations[func_name]
-        try:
-            module = import_module(self.module_name)
-            version = module.__version__
-
-            if (self.from_version is None or version >= self.from_version) and (
-                self.to_version is None or version < self.to_version
-            ):
-                implementations[func_name] = fn
-                return fn
-
-        except ModuleNotFoundError:
-            return unsupported
-
+        else:
+            try:
+                version = self.import_module(self.module_name)
+                if self.check_version(version, self.from_version, self.to_version):
+                    do_set = True
+            except ModuleNotFoundError:
+                return unsupported
+        if do_set:
+            implementations[func_name] = fn
+            self.module_set()
+            return fn
         return unsupported
 
+    @classmethod
+    def reset(cls, setters=None):
+        if VERBOSE:
+            print("resetting implement_for")
+        if setters is None:
+            setters = copy(cls._setters)
+        cls._setters = []
+        cls._implementations = {}
+        for setter in setters:
+            setter(setter.fn)
+            cls._setters.append(setter)
+
 
 def accept_remote_rref_invocation(func):
     """Decorator that allows a method to be invoked remotely.
 
     Passes the `rpc.RRef` associated with the remote object construction as first argument in place of the object reference.
 
     """
@@ -302,7 +367,154 @@
     """Class decorator that applies `accept_remote_rref_invocation` to all public methods."""
     # ignores private methods
     for name in dir(decorated_class):
         method = getattr(decorated_class, name)
         if callable(method) and not name.startswith("_"):
             setattr(decorated_class, name, accept_remote_rref_invocation(method))
     return decorated_class
+
+
+# We copy this from torch as older versions do not have it
+# see torch.utils._contextlib
+
+# Extra utilities for working with context managers that should have been
+# in the standard library but are not
+
+# Used for annotating the decorator usage of _DecoratorContextManager (e.g.,
+# 'no_grad' and 'enable_grad').
+# See https://mypy.readthedocs.io/en/latest/generics.html#declaring-decorators
+FuncType = Callable[..., Any]
+F = TypeVar("F", bound=FuncType)
+
+
+def _wrap_generator(ctx_factory, func):
+    """Wrap each generator invocation with the context manager factory.
+
+    The input should be a function that returns a context manager,
+    not a context manager itself, to handle one-shot context managers.
+    """
+
+    @functools.wraps(func)
+    def generator_context(*args, **kwargs):
+        gen = func(*args, **kwargs)
+
+        # Generators are suspended and unsuspended at `yield`, hence we
+        # make sure the grad mode is properly set every time the execution
+        # flow returns into the wrapped generator and restored when it
+        # returns through our `yield` to our caller (see PR #49017).
+        try:
+            # Issuing `None` to a generator fires it up
+            with ctx_factory():
+                response = gen.send(None)
+
+            while True:
+                try:
+                    # Forward the response to our caller and get its next request
+                    request = yield response
+
+                except GeneratorExit:
+                    # Inform the still active generator about its imminent closure
+                    with ctx_factory():
+                        gen.close()
+                    raise
+
+                except BaseException:
+                    # Propagate the exception thrown at us by the caller
+                    with ctx_factory():
+                        response = gen.throw(*sys.exc_info())
+
+                else:
+                    # Pass the last request to the generator and get its response
+                    with ctx_factory():
+                        response = gen.send(request)
+
+        # We let the exceptions raised above by the generator's `.throw` or
+        # `.send` methods bubble up to our caller, except for StopIteration
+        except StopIteration as e:
+            # The generator informed us that it is done: take whatever its
+            # returned value (if any) was and indicate that we're done too
+            # by returning it (see docs for python's return-statement).
+            return e.value
+
+    return generator_context
+
+
+def context_decorator(ctx, func):
+    """Context decorator.
+
+    Like contextlib.ContextDecorator, but:
+
+    1. Is done by wrapping, rather than inheritance, so it works with context
+       managers that are implemented from C and thus cannot easily inherit from
+       Python classes
+    2. Wraps generators in the intuitive way (c.f. https://bugs.python.org/issue37743)
+    3. Errors out if you try to wrap a class, because it is ambiguous whether
+       or not you intended to wrap only the constructor
+
+    The input argument can either be a context manager (in which case it must
+    be a multi-shot context manager that can be directly invoked multiple times)
+    or a callable that produces a context manager.
+    """
+    if callable(ctx) and hasattr(ctx, "__enter__"):
+        raise RuntimeError(
+            f"Passed in {ctx} is both callable and also a valid context manager "
+            "(has __enter__), making it ambiguous which interface to use.  If you "
+            "intended to pass a context manager factory, rewrite your call as "
+            "context_decorator(lambda: ctx()); if you intended to pass a context "
+            "manager directly, rewrite your call as context_decorator(lambda: ctx)"
+        )
+
+    if not callable(ctx):
+
+        def ctx_factory():
+            return ctx
+
+    else:
+        ctx_factory = ctx
+
+    if inspect.isclass(func):
+        raise RuntimeError(
+            "Cannot decorate classes; it is ambiguous whether or not only the "
+            "constructor or all methods should have the context manager applied; "
+            "additionally, decorating a class at definition-site will prevent "
+            "use of the identifier as a conventional type.  "
+            "To specify which methods to decorate, decorate each of them "
+            "individually."
+        )
+
+    if inspect.isgeneratorfunction(func):
+        return _wrap_generator(ctx_factory, func)
+
+    @functools.wraps(func)
+    def decorate_context(*args, **kwargs):
+        with ctx_factory():
+            return func(*args, **kwargs)
+
+    return decorate_context
+
+
+class _DecoratorContextManager:
+    """Allow a context manager to be used as a decorator."""
+
+    def __call__(self, orig_func: F) -> F:
+        if inspect.isclass(orig_func):
+            warnings.warn(
+                "Decorating classes is deprecated and will be disabled in "
+                "future versions. You should only decorate functions or methods. "
+                "To preserve the current behavior of class decoration, you can "
+                "directly decorate the `__init__` method and nothing else."
+            )
+            func = cast(F, lambda *args, **kwargs: orig_func(*args, **kwargs))
+        else:
+            func = orig_func
+
+        return cast(F, context_decorator(self.clone, func))
+
+    def __enter__(self) -> None:
+        raise NotImplementedError
+
+    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None:
+        raise NotImplementedError
+
+    def clone(self):
+        # override this method if your children class takes __init__ parameters
+        return self.__class__()
```

## torchrl/collectors/__init__.py

```diff
@@ -1,11 +1,13 @@
 # Copyright (c) Meta Platforms, Inc. and affiliates.
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
 
 from .collectors import (
     aSyncDataCollector,
+    DataCollectorBase,
     MultiaSyncDataCollector,
     MultiSyncDataCollector,
+    RandomPolicy,
     SyncDataCollector,
 )
```

## torchrl/collectors/collectors.py

```diff
@@ -10,5477 +10,6069 @@
 00000090: 6520 726f 6f74 2064 6972 6563 746f 7279  e root directory
 000000a0: 206f 6620 7468 6973 2073 6f75 7263 6520   of this source 
 000000b0: 7472 6565 2e0d 0a69 6d70 6f72 7420 5f70  tree...import _p
 000000c0: 6963 6b6c 650d 0a69 6d70 6f72 7420 6162  ickle..import ab
 000000d0: 630d 0a69 6d70 6f72 7420 696e 7370 6563  c..import inspec
 000000e0: 740d 0a69 6d70 6f72 7420 6f73 0d0a 696d  t..import os..im
 000000f0: 706f 7274 2071 7565 7565 0d0a 696d 706f  port queue..impo
-00000100: 7274 2074 696d 650d 0a69 6d70 6f72 7420  rt time..import 
-00000110: 7761 726e 696e 6773 0d0a 6672 6f6d 2063  warnings..from c
-00000120: 6f6c 6c65 6374 696f 6e73 2069 6d70 6f72  ollections impor
-00000130: 7420 4f72 6465 7265 6444 6963 740d 0a66  t OrderedDict..f
-00000140: 726f 6d20 636f 7079 2069 6d70 6f72 7420  rom copy import 
-00000150: 6465 6570 636f 7079 0d0a 6672 6f6d 206d  deepcopy..from m
-00000160: 756c 7469 7072 6f63 6573 7369 6e67 2069  ultiprocessing i
-00000170: 6d70 6f72 7420 636f 6e6e 6563 7469 6f6e  mport connection
-00000180: 2c20 7175 6575 6573 0d0a 6672 6f6d 2074  , queues..from t
-00000190: 6578 7477 7261 7020 696d 706f 7274 2069  extwrap import i
-000001a0: 6e64 656e 740d 0a66 726f 6d20 7479 7069  ndent..from typi
-000001b0: 6e67 2069 6d70 6f72 7420 416e 792c 2043  ng import Any, C
-000001c0: 616c 6c61 626c 652c 2044 6963 742c 2049  allable, Dict, I
-000001d0: 7465 7261 746f 722c 204f 7074 696f 6e61  terator, Optiona
-000001e0: 6c2c 2053 6571 7565 6e63 652c 2054 7570  l, Sequence, Tup
-000001f0: 6c65 2c20 556e 696f 6e0d 0a0d 0a69 6d70  le, Union....imp
-00000200: 6f72 7420 6e75 6d70 7920 6173 206e 700d  ort numpy as np.
-00000210: 0a69 6d70 6f72 7420 746f 7263 680d 0a69  .import torch..i
-00000220: 6d70 6f72 7420 746f 7263 682e 6e6e 2061  mport torch.nn a
-00000230: 7320 6e6e 0d0a 6672 6f6d 2074 656e 736f  s nn..from tenso
-00000240: 7264 6963 742e 6e6e 2069 6d70 6f72 7420  rdict.nn import 
-00000250: 5465 6e73 6f72 4469 6374 4d6f 6475 6c65  TensorDictModule
-00000260: 0d0a 6672 6f6d 2074 656e 736f 7264 6963  ..from tensordic
-00000270: 742e 7465 6e73 6f72 6469 6374 2069 6d70  t.tensordict imp
-00000280: 6f72 7420 5465 6e73 6f72 4469 6374 2c20  ort TensorDict, 
-00000290: 5465 6e73 6f72 4469 6374 4261 7365 0d0a  TensorDictBase..
-000002a0: 6672 6f6d 2074 6f72 6368 2069 6d70 6f72  from torch impor
-000002b0: 7420 6d75 6c74 6970 726f 6365 7373 696e  t multiprocessin
-000002c0: 6720 6173 206d 700d 0a66 726f 6d20 746f  g as mp..from to
-000002d0: 7263 682e 7574 696c 732e 6461 7461 2069  rch.utils.data i
-000002e0: 6d70 6f72 7420 4974 6572 6162 6c65 4461  mport IterableDa
-000002f0: 7461 7365 740d 0a0d 0a66 726f 6d20 746f  taset....from to
-00000300: 7263 6872 6c2e 5f75 7469 6c73 2069 6d70  rchrl._utils imp
-00000310: 6f72 7420 280d 0a20 2020 205f 6368 6563  ort (..    _chec
-00000320: 6b5f 666f 725f 6661 756c 7479 5f70 726f  k_for_faulty_pro
-00000330: 6365 7373 2c0d 0a20 2020 2061 6363 6570  cess,..    accep
-00000340: 745f 7265 6d6f 7465 5f72 7265 665f 7564  t_remote_rref_ud
-00000350: 665f 696e 766f 6361 7469 6f6e 2c0d 0a20  f_invocation,.. 
-00000360: 2020 2070 726f 642c 0d0a 2020 2020 5645     prod,..    VE
-00000370: 5242 4f53 452c 0d0a 290d 0a66 726f 6d20  RBOSE,..)..from 
-00000380: 746f 7263 6872 6c2e 636f 6c6c 6563 746f  torchrl.collecto
-00000390: 7273 2e75 7469 6c73 2069 6d70 6f72 7420  rs.utils import 
-000003a0: 7370 6c69 745f 7472 616a 6563 746f 7269  split_trajectori
-000003b0: 6573 0d0a 6672 6f6d 2074 6f72 6368 726c  es..from torchrl
-000003c0: 2e64 6174 612e 7465 6e73 6f72 5f73 7065  .data.tensor_spe
-000003d0: 6373 2069 6d70 6f72 7420 5465 6e73 6f72  cs import Tensor
-000003e0: 5370 6563 0d0a 6672 6f6d 2074 6f72 6368  Spec..from torch
-000003f0: 726c 2e64 6174 612e 7574 696c 7320 696d  rl.data.utils im
-00000400: 706f 7274 2043 6c6f 7564 7069 636b 6c65  port Cloudpickle
-00000410: 5772 6170 7065 722c 2044 4556 4943 455f  Wrapper, DEVICE_
-00000420: 5459 5049 4e47 0d0a 6672 6f6d 2074 6f72  TYPING..from tor
-00000430: 6368 726c 2e65 6e76 732e 636f 6d6d 6f6e  chrl.envs.common
-00000440: 2069 6d70 6f72 7420 456e 7642 6173 650d   import EnvBase.
-00000450: 0a66 726f 6d20 746f 7263 6872 6c2e 656e  .from torchrl.en
-00000460: 7673 2e74 7261 6e73 666f 726d 7320 696d  vs.transforms im
-00000470: 706f 7274 2053 7465 7043 6f75 6e74 6572  port StepCounter
-00000480: 2c20 5472 616e 7366 6f72 6d65 6445 6e76  , TransformedEnv
+00000100: 7274 2073 7973 0d0a 696d 706f 7274 2074  rt sys..import t
+00000110: 696d 650d 0a69 6d70 6f72 7420 7761 726e  ime..import warn
+00000120: 696e 6773 0d0a 6672 6f6d 2063 6f6c 6c65  ings..from colle
+00000130: 6374 696f 6e73 2069 6d70 6f72 7420 4f72  ctions import Or
+00000140: 6465 7265 6444 6963 740d 0a66 726f 6d20  deredDict..from 
+00000150: 636f 7079 2069 6d70 6f72 7420 6465 6570  copy import deep
+00000160: 636f 7079 0d0a 0d0a 6672 6f6d 206d 756c  copy....from mul
+00000170: 7469 7072 6f63 6573 7369 6e67 2069 6d70  tiprocessing imp
+00000180: 6f72 7420 636f 6e6e 6563 7469 6f6e 2c20  ort connection, 
+00000190: 7175 6575 6573 0d0a 6672 6f6d 206d 756c  queues..from mul
+000001a0: 7469 7072 6f63 6573 7369 6e67 2e6d 616e  tiprocessing.man
+000001b0: 6167 6572 7320 696d 706f 7274 2053 796e  agers import Syn
+000001c0: 634d 616e 6167 6572 0d0a 0d0a 6672 6f6d  cManager....from
+000001d0: 2074 6578 7477 7261 7020 696d 706f 7274   textwrap import
+000001e0: 2069 6e64 656e 740d 0a66 726f 6d20 7479   indent..from ty
+000001f0: 7069 6e67 2069 6d70 6f72 7420 416e 792c  ping import Any,
+00000200: 2043 616c 6c61 626c 652c 2044 6963 742c   Callable, Dict,
+00000210: 2049 7465 7261 746f 722c 204f 7074 696f   Iterator, Optio
+00000220: 6e61 6c2c 2053 6571 7565 6e63 652c 2054  nal, Sequence, T
+00000230: 7570 6c65 2c20 556e 696f 6e0d 0a0d 0a69  uple, Union....i
+00000240: 6d70 6f72 7420 6e75 6d70 7920 6173 206e  mport numpy as n
+00000250: 700d 0a69 6d70 6f72 7420 746f 7263 680d  p..import torch.
+00000260: 0a69 6d70 6f72 7420 746f 7263 682e 6e6e  .import torch.nn
+00000270: 2061 7320 6e6e 0d0a 6672 6f6d 2074 656e   as nn..from ten
+00000280: 736f 7264 6963 742e 6e6e 2069 6d70 6f72  sordict.nn impor
+00000290: 7420 5465 6e73 6f72 4469 6374 4d6f 6475  t TensorDictModu
+000002a0: 6c65 2c20 5465 6e73 6f72 4469 6374 4d6f  le, TensorDictMo
+000002b0: 6475 6c65 4261 7365 0d0a 6672 6f6d 2074  duleBase..from t
+000002c0: 656e 736f 7264 6963 742e 7465 6e73 6f72  ensordict.tensor
+000002d0: 6469 6374 2069 6d70 6f72 7420 5465 6e73  dict import Tens
+000002e0: 6f72 4469 6374 2c20 5465 6e73 6f72 4469  orDict, TensorDi
+000002f0: 6374 4261 7365 0d0a 6672 6f6d 2074 6f72  ctBase..from tor
+00000300: 6368 2069 6d70 6f72 7420 6d75 6c74 6970  ch import multip
+00000310: 726f 6365 7373 696e 6720 6173 206d 700d  rocessing as mp.
+00000320: 0a66 726f 6d20 746f 7263 682e 7574 696c  .from torch.util
+00000330: 732e 6461 7461 2069 6d70 6f72 7420 4974  s.data import It
+00000340: 6572 6162 6c65 4461 7461 7365 740d 0a0d  erableDataset...
+00000350: 0a66 726f 6d20 746f 7263 6872 6c2e 5f75  .from torchrl._u
+00000360: 7469 6c73 2069 6d70 6f72 7420 280d 0a20  tils import (.. 
+00000370: 2020 205f 6368 6563 6b5f 666f 725f 6661     _check_for_fa
+00000380: 756c 7479 5f70 726f 6365 7373 2c0d 0a20  ulty_process,.. 
+00000390: 2020 2061 6363 6570 745f 7265 6d6f 7465     accept_remote
+000003a0: 5f72 7265 665f 7564 665f 696e 766f 6361  _rref_udf_invoca
+000003b0: 7469 6f6e 2c0d 0a20 2020 2070 726f 642c  tion,..    prod,
+000003c0: 0d0a 2020 2020 524c 5f57 4152 4e49 4e47  ..    RL_WARNING
+000003d0: 532c 0d0a 2020 2020 5645 5242 4f53 452c  S,..    VERBOSE,
+000003e0: 0d0a 290d 0a66 726f 6d20 746f 7263 6872  ..)..from torchr
+000003f0: 6c2e 636f 6c6c 6563 746f 7273 2e75 7469  l.collectors.uti
+00000400: 6c73 2069 6d70 6f72 7420 7370 6c69 745f  ls import split_
+00000410: 7472 616a 6563 746f 7269 6573 0d0a 6672  trajectories..fr
+00000420: 6f6d 2074 6f72 6368 726c 2e64 6174 612e  om torchrl.data.
+00000430: 7465 6e73 6f72 5f73 7065 6373 2069 6d70  tensor_specs imp
+00000440: 6f72 7420 5465 6e73 6f72 5370 6563 0d0a  ort TensorSpec..
+00000450: 6672 6f6d 2074 6f72 6368 726c 2e64 6174  from torchrl.dat
+00000460: 612e 7574 696c 7320 696d 706f 7274 2043  a.utils import C
+00000470: 6c6f 7564 7069 636b 6c65 5772 6170 7065  loudpickleWrappe
+00000480: 722c 2044 4556 4943 455f 5459 5049 4e47  r, DEVICE_TYPING
 00000490: 0d0a 6672 6f6d 2074 6f72 6368 726c 2e65  ..from torchrl.e
-000004a0: 6e76 732e 7574 696c 7320 696d 706f 7274  nvs.utils import
-000004b0: 2073 6574 5f65 7870 6c6f 7261 7469 6f6e   set_exploration
-000004c0: 5f6d 6f64 652c 2073 7465 705f 6d64 700d  _mode, step_mdp.
-000004d0: 0a66 726f 6d20 746f 7263 6872 6c2e 656e  .from torchrl.en
-000004e0: 7673 2e76 6563 5f65 6e76 2069 6d70 6f72  vs.vec_env impor
-000004f0: 7420 5f42 6174 6368 6564 456e 760d 0a0d  t _BatchedEnv...
-00000500: 0a5f 5449 4d45 4f55 5420 3d20 312e 300d  ._TIMEOUT = 1.0.
-00000510: 0a5f 4d49 4e5f 5449 4d45 4f55 5420 3d20  ._MIN_TIMEOUT = 
-00000520: 3165 2d33 2020 2320 7368 6f75 6c64 2062  1e-3  # should b
-00000530: 6520 7365 7665 7261 6c20 6f72 6465 7273  e several orders
-00000540: 206f 6620 6d61 676e 6974 7564 6520 696e   of magnitude in
-00000550: 6665 7269 6f72 2077 7274 2074 696d 6520  ferior wrt time 
-00000560: 7370 656e 7420 636f 6c6c 6563 7469 6e67  spent collecting
-00000570: 2061 2074 7261 6a65 6374 6f72 790d 0a5f   a trajectory.._
-00000580: 4d41 585f 4944 4c45 5f43 4f55 4e54 203d  MAX_IDLE_COUNT =
-00000590: 2069 6e74 286f 732e 656e 7669 726f 6e2e   int(os.environ.
-000005a0: 6765 7428 224d 4158 5f49 444c 455f 434f  get("MAX_IDLE_CO
-000005b0: 554e 5422 2c20 3130 3030 2929 0d0a 0d0a  UNT", 1000))....
-000005c0: 4445 4641 554c 545f 4558 504c 4f52 4154  DEFAULT_EXPLORAT
-000005d0: 494f 4e5f 4d4f 4445 3a20 7374 7220 3d20  ION_MODE: str = 
-000005e0: 2272 616e 646f 6d22 0d0a 0d0a 0d0a 636c  "random"......cl
-000005f0: 6173 7320 5261 6e64 6f6d 506f 6c69 6379  ass RandomPolicy
-00000600: 3a0d 0a20 2020 2022 2222 4120 7261 6e64  :..    """A rand
-00000610: 6f6d 2070 6f6c 6963 7920 666f 7220 6461  om policy for da
-00000620: 7461 2063 6f6c 6c65 6374 6f72 732e 2222  ta collectors.""
-00000630: 220d 0a0d 0a20 2020 2064 6566 205f 5f69  "....    def __i
-00000640: 6e69 745f 5f28 7365 6c66 2c20 6163 7469  nit__(self, acti
-00000650: 6f6e 5f73 7065 633a 2054 656e 736f 7253  on_spec: TensorS
-00000660: 7065 6329 3a0d 0a20 2020 2020 2020 2022  pec):..        "
-00000670: 2222 5261 6e64 6f6d 2070 6f6c 6963 7920  ""Random policy 
-00000680: 666f 7220 6120 6769 7665 6e20 6163 7469  for a given acti
-00000690: 6f6e 5f73 7065 632e 0d0a 0d0a 2020 2020  on_spec.....    
-000006a0: 2020 2020 5468 6973 2069 7320 6120 7772      This is a wr
-000006b0: 6170 7065 7220 6172 6f75 6e64 2074 6865  apper around the
-000006c0: 2061 6374 696f 6e5f 7370 6563 2e72 616e   action_spec.ran
-000006d0: 6420 6d65 7468 6f64 2e0d 0a0d 0a0d 0a20  d method....... 
-000006e0: 2020 2020 2020 2024 2070 7974 686f 6e20         $ python 
-000006f0: 6578 616d 706c 655f 676f 6f67 6c65 2e70  example_google.p
-00000700: 790d 0a0d 0a20 2020 2020 2020 2041 7267  y....        Arg
-00000710: 733a 0d0a 2020 2020 2020 2020 2020 2020  s:..            
-00000720: 6163 7469 6f6e 5f73 7065 633a 2054 656e  action_spec: Ten
-00000730: 736f 7253 7065 6320 6f62 6a65 6374 2064  sorSpec object d
-00000740: 6573 6372 6962 696e 6720 7468 6520 6163  escribing the ac
-00000750: 7469 6f6e 2073 7065 6373 0d0a 0d0a 2020  tion specs....  
-00000760: 2020 2020 2020 4578 616d 706c 6573 3a0d        Examples:.
-00000770: 0a20 2020 2020 2020 2020 2020 203e 3e3e  .            >>>
-00000780: 2066 726f 6d20 7465 6e73 6f72 6469 6374   from tensordict
-00000790: 2069 6d70 6f72 7420 5465 6e73 6f72 4469   import TensorDi
-000007a0: 6374 0d0a 2020 2020 2020 2020 2020 2020  ct..            
-000007b0: 3e3e 3e20 6672 6f6d 2074 6f72 6368 726c  >>> from torchrl
-000007c0: 2e64 6174 612e 7465 6e73 6f72 5f73 7065  .data.tensor_spe
-000007d0: 6373 2069 6d70 6f72 7420 426f 756e 6465  cs import Bounde
-000007e0: 6454 656e 736f 7253 7065 630d 0a20 2020  dTensorSpec..   
-000007f0: 2020 2020 2020 2020 203e 3e3e 2061 6374           >>> act
-00000800: 696f 6e5f 7370 6563 203d 2042 6f75 6e64  ion_spec = Bound
-00000810: 6564 5465 6e73 6f72 5370 6563 282d 746f  edTensorSpec(-to
-00000820: 7263 682e 6f6e 6573 2833 292c 2074 6f72  rch.ones(3), tor
-00000830: 6368 2e6f 6e65 7328 3329 290d 0a20 2020  ch.ones(3))..   
-00000840: 2020 2020 2020 2020 203e 3e3e 2061 6374           >>> act
-00000850: 6f72 203d 2052 616e 646f 6d50 6f6c 6963  or = RandomPolic
-00000860: 7928 7370 6563 3d61 6374 696f 6e5f 7370  y(spec=action_sp
-00000870: 6563 290d 0a20 2020 2020 2020 2020 2020  ec)..           
-00000880: 203e 3e3e 2074 6420 3d20 6163 746f 7228   >>> td = actor(
-00000890: 5465 6e73 6f72 4469 6374 2862 6174 6368  TensorDict(batch
-000008a0: 5f73 697a 653d 5b5d 2929 2023 2073 656c  _size=[])) # sel
-000008b0: 6563 7473 2061 2072 616e 646f 6d20 6163  ects a random ac
-000008c0: 7469 6f6e 2069 6e20 7468 6520 6375 6265  tion in the cube
-000008d0: 205b 2d31 3b20 315d 0d0a 0d0a 2020 2020   [-1; 1]....    
-000008e0: 2020 2020 2222 220d 0a20 2020 2020 2020      """..       
-000008f0: 2073 656c 662e 6163 7469 6f6e 5f73 7065   self.action_spe
-00000900: 6320 3d20 6163 7469 6f6e 5f73 7065 630d  c = action_spec.
-00000910: 0a0d 0a20 2020 2064 6566 205f 5f63 616c  ...    def __cal
-00000920: 6c5f 5f28 7365 6c66 2c20 7464 3a20 5465  l__(self, td: Te
-00000930: 6e73 6f72 4469 6374 4261 7365 2920 2d3e  nsorDictBase) ->
-00000940: 2054 656e 736f 7244 6963 7442 6173 653a   TensorDictBase:
-00000950: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
-00000960: 2074 642e 7365 7428 2261 6374 696f 6e22   td.set("action"
-00000970: 2c20 7365 6c66 2e61 6374 696f 6e5f 7370  , self.action_sp
-00000980: 6563 2e72 616e 6428 2929 0d0a 0d0a 0d0a  ec.rand())......
-00000990: 6465 6620 7265 6375 7273 6976 655f 6d61  def recursive_ma
-000009a0: 705f 746f 5f63 7075 2864 6963 7469 6f6e  p_to_cpu(diction
-000009b0: 6172 793a 204f 7264 6572 6564 4469 6374  ary: OrderedDict
-000009c0: 2920 2d3e 204f 7264 6572 6564 4469 6374  ) -> OrderedDict
-000009d0: 3a0d 0a20 2020 2022 2222 4d61 7073 2074  :..    """Maps t
-000009e0: 6865 2074 656e 736f 7273 2074 6f20 4350  he tensors to CP
-000009f0: 5520 7468 726f 7567 6820 6120 6e65 7374  U through a nest
-00000a00: 6564 2064 6963 7469 6f6e 6172 792e 2222  ed dictionary.""
-00000a10: 220d 0a20 2020 2072 6574 7572 6e20 4f72  "..    return Or
-00000a20: 6465 7265 6444 6963 7428 0d0a 2020 2020  deredDict(..    
-00000a30: 2020 2020 2a2a 7b0d 0a20 2020 2020 2020      **{..       
-00000a40: 2020 2020 206b 3a20 7265 6375 7273 6976       k: recursiv
-00000a50: 655f 6d61 705f 746f 5f63 7075 2869 7465  e_map_to_cpu(ite
-00000a60: 6d29 0d0a 2020 2020 2020 2020 2020 2020  m)..            
-00000a70: 6966 2069 7369 6e73 7461 6e63 6528 6974  if isinstance(it
-00000a80: 656d 2c20 4f72 6465 7265 6444 6963 7429  em, OrderedDict)
-00000a90: 0d0a 2020 2020 2020 2020 2020 2020 656c  ..            el
-00000aa0: 7365 2069 7465 6d2e 6370 7528 290d 0a20  se item.cpu().. 
-00000ab0: 2020 2020 2020 2020 2020 2069 6620 6973             if is
-00000ac0: 696e 7374 616e 6365 2869 7465 6d2c 2074  instance(item, t
-00000ad0: 6f72 6368 2e54 656e 736f 7229 0d0a 2020  orch.Tensor)..  
-00000ae0: 2020 2020 2020 2020 2020 656c 7365 2069            else i
-00000af0: 7465 6d0d 0a20 2020 2020 2020 2020 2020  tem..           
-00000b00: 2066 6f72 206b 2c20 6974 656d 2069 6e20   for k, item in 
-00000b10: 6469 6374 696f 6e61 7279 2e69 7465 6d73  dictionary.items
-00000b20: 2829 0d0a 2020 2020 2020 2020 7d0d 0a20  ()..        }.. 
-00000b30: 2020 2029 0d0a 0d0a 0d0a 6465 6620 5f70     )......def _p
-00000b40: 6f6c 6963 795f 6973 5f74 656e 736f 7264  olicy_is_tensord
-00000b50: 6963 745f 636f 6d70 6174 6962 6c65 2870  ict_compatible(p
-00000b60: 6f6c 6963 793a 206e 6e2e 4d6f 6475 6c65  olicy: nn.Module
-00000b70: 293a 0d0a 2020 2020 7369 6720 3d20 696e  ):..    sig = in
-00000b80: 7370 6563 742e 7369 676e 6174 7572 6528  spect.signature(
-00000b90: 706f 6c69 6379 2e66 6f72 7761 7264 290d  policy.forward).
-00000ba0: 0a0d 0a20 2020 2069 6620 6973 696e 7374  ...    if isinst
-00000bb0: 616e 6365 2870 6f6c 6963 792c 2054 656e  ance(policy, Ten
-00000bc0: 736f 7244 6963 744d 6f64 756c 6529 206f  sorDictModule) o
-00000bd0: 7220 280d 0a20 2020 2020 2020 206c 656e  r (..        len
-00000be0: 2873 6967 2e70 6172 616d 6574 6572 7329  (sig.parameters)
-00000bf0: 203d 3d20 310d 0a20 2020 2020 2020 2061   == 1..        a
-00000c00: 6e64 2068 6173 6174 7472 2870 6f6c 6963  nd hasattr(polic
-00000c10: 792c 2022 696e 5f6b 6579 7322 290d 0a20  y, "in_keys").. 
-00000c20: 2020 2020 2020 2061 6e64 2068 6173 6174         and hasat
-00000c30: 7472 2870 6f6c 6963 792c 2022 6f75 745f  tr(policy, "out_
-00000c40: 6b65 7973 2229 0d0a 2020 2020 293a 0d0a  keys")..    ):..
-00000c50: 2020 2020 2020 2020 2320 6966 2074 6865          # if the
-00000c60: 2070 6f6c 6963 7920 6973 2061 2054 656e   policy is a Ten
-00000c70: 736f 7244 6963 744d 6f64 756c 6520 6f72  sorDictModule or
-00000c80: 2074 616b 6573 2061 2073 696e 676c 6520   takes a single 
-00000c90: 6172 6775 6d65 6e74 2061 6e64 2064 6566  argument and def
-00000ca0: 696e 6573 0d0a 2020 2020 2020 2020 2320  ines..        # 
-00000cb0: 696e 5f6b 6579 7320 616e 6420 6f75 745f  in_keys and out_
-00000cc0: 6b65 7973 2074 6865 6e20 7765 2061 7373  keys then we ass
-00000cd0: 756d 6520 6974 2063 616e 2061 6c72 6561  ume it can alrea
-00000ce0: 6479 2064 6561 6c20 7769 7468 2054 656e  dy deal with Ten
-00000cf0: 736f 7244 6963 7420 696e 7075 740d 0a20  sorDict input.. 
-00000d00: 2020 2020 2020 2023 2074 6f20 666f 7277         # to forw
-00000d10: 6172 6420 616e 6420 7765 2072 6574 7572  ard and we retur
-00000d20: 6e20 5472 7565 0d0a 2020 2020 2020 2020  n True..        
-00000d30: 7265 7475 726e 2054 7275 650d 0a20 2020  return True..   
-00000d40: 2065 6c69 6620 6e6f 7420 6861 7361 7474   elif not hasatt
-00000d50: 7228 706f 6c69 6379 2c20 2269 6e5f 6b65  r(policy, "in_ke
-00000d60: 7973 2229 2061 6e64 206e 6f74 2068 6173  ys") and not has
-00000d70: 6174 7472 2870 6f6c 6963 792c 2022 6f75  attr(policy, "ou
-00000d80: 745f 6b65 7973 2229 3a0d 0a20 2020 2020  t_keys"):..     
-00000d90: 2020 2023 2069 6620 6974 2773 206e 6f74     # if it's not
-00000da0: 2061 2054 656e 736f 7244 6963 744d 6f64   a TensorDictMod
-00000db0: 756c 652c 2061 6e64 2069 6e5f 6b65 7973  ule, and in_keys
-00000dc0: 2061 6e64 206f 7574 5f6b 6579 7320 6172   and out_keys ar
-00000dd0: 6520 6e6f 7420 6465 6669 6e65 6420 7468  e not defined th
-00000de0: 656e 0d0a 2020 2020 2020 2020 2320 7765  en..        # we
-00000df0: 2061 7373 756d 6520 6e6f 2054 656e 736f   assume no Tenso
-00000e00: 7244 6963 7420 636f 6d70 6174 6962 696c  rDict compatibil
-00000e10: 6974 7920 616e 6420 7769 6c6c 2074 7279  ity and will try
-00000e20: 2074 6f20 7772 6170 2069 742e 0d0a 2020   to wrap it...  
-00000e30: 2020 2020 2020 7265 7475 726e 2046 616c        return Fal
-00000e40: 7365 0d0a 0d0a 2020 2020 2320 6966 2069  se....    # if i
-00000e50: 6e5f 6b65 7973 206f 7220 6f75 745f 6b65  n_keys or out_ke
-00000e60: 7973 2077 6572 6520 6465 6669 6e65 6420  ys were defined 
-00000e70: 6275 7420 706f 6c69 6379 2069 7320 6e6f  but policy is no
-00000e80: 7420 6120 5465 6e73 6f72 4469 6374 4d6f  t a TensorDictMo
-00000e90: 6475 6c65 206f 720d 0a20 2020 2023 2061  dule or..    # a
-00000ea0: 6363 6570 7473 206d 756c 7469 706c 6520  ccepts multiple 
-00000eb0: 6172 6775 6d65 6e74 7320 7468 656e 2069  arguments then i
-00000ec0: 7427 7320 6c69 6b65 6c79 2074 6865 2075  t's likely the u
-00000ed0: 7365 7220 6973 2074 7279 696e 6720 746f  ser is trying to
-00000ee0: 2064 6f20 736f 6d65 7468 696e 670d 0a20   do something.. 
-00000ef0: 2020 2023 2074 6861 7420 7769 6c6c 2068     # that will h
-00000f00: 6176 6520 756e 6465 7465 726d 696e 6564  ave undetermined
-00000f10: 2062 6568 6176 696f 7572 2c20 7765 2072   behaviour, we r
-00000f20: 6169 7365 2061 6e20 6572 726f 720d 0a20  aise an error.. 
-00000f30: 2020 2072 6169 7365 2054 7970 6545 7272     raise TypeErr
-00000f40: 6f72 280d 0a20 2020 2020 2020 2022 5265  or(..        "Re
-00000f50: 6365 6976 6564 2061 2070 6f6c 6963 7920  ceived a policy 
-00000f60: 7468 6174 2064 6566 696e 6573 2069 6e5f  that defines in_
-00000f70: 6b65 7973 206f 7220 6f75 745f 6b65 7973  keys or out_keys
-00000f80: 2061 6e64 2061 6c73 6f20 6578 7065 6374   and also expect
-00000f90: 7320 6d75 6c74 6970 6c65 2022 0d0a 2020  s multiple "..  
-00000fa0: 2020 2020 2020 2261 7267 756d 656e 7473        "arguments
-00000fb0: 2074 6f20 706f 6c69 6379 2e66 6f72 7761   to policy.forwa
-00000fc0: 7264 2e20 4966 2074 6865 2070 6f6c 6963  rd. If the polic
-00000fd0: 7920 6973 2063 6f6d 7061 7469 626c 6520  y is compatible 
-00000fe0: 7769 7468 2054 656e 736f 7244 6963 742c  with TensorDict,
-00000ff0: 2069 7420 220d 0a20 2020 2020 2020 2022   it "..        "
-00001000: 7368 6f75 6c64 2074 616b 6520 6120 7369  should take a si
-00001010: 6e67 6c65 2061 7267 756d 656e 7420 6f66  ngle argument of
-00001020: 2074 7970 6520 5465 6e73 6f72 4469 6374   type TensorDict
-00001030: 2074 6f20 706f 6c69 6379 2e66 6f72 7761   to policy.forwa
-00001040: 7264 2061 6e64 2064 6566 696e 6520 220d  rd and define ".
-00001050: 0a20 2020 2020 2020 2022 626f 7468 2069  .        "both i
-00001060: 6e5f 6b65 7973 2061 6e64 206f 7574 5f6b  n_keys and out_k
-00001070: 6579 732e 2041 6c74 6572 6e61 7469 7665  eys. Alternative
-00001080: 6c79 2c20 706f 6c69 6379 2e66 6f72 7761  ly, policy.forwa
-00001090: 7264 2063 616e 2061 6363 6570 7420 220d  rd can accept ".
-000010a0: 0a20 2020 2020 2020 2022 6172 6269 7472  .        "arbitr
-000010b0: 6172 696c 7920 6d61 6e79 2074 656e 736f  arily many tenso
-000010c0: 7220 696e 7075 7473 2061 6e64 206c 6561  r inputs and lea
-000010d0: 7665 2069 6e5f 6b65 7973 2061 6e64 206f  ve in_keys and o
-000010e0: 7574 5f6b 6579 7320 756e 6465 6669 6e65  ut_keys undefine
-000010f0: 6420 616e 6420 220d 0a20 2020 2020 2020  d and "..       
-00001100: 2022 546f 7263 6852 4c20 7769 6c6c 2061   "TorchRL will a
-00001110: 7474 656d 7074 2074 6f20 6175 746f 6d61  ttempt to automa
-00001120: 7469 6361 6c6c 7920 7772 6170 2074 6865  tically wrap the
-00001130: 2070 6f6c 6963 7920 7769 7468 2061 2054   policy with a T
-00001140: 656e 736f 7244 6963 744d 6f64 756c 652e  ensorDictModule.
-00001150: 220d 0a20 2020 2029 0d0a 0d0a 0d0a 636c  "..    )......cl
-00001160: 6173 7320 5f44 6174 6143 6f6c 6c65 6374  ass _DataCollect
-00001170: 6f72 2849 7465 7261 626c 6544 6174 6173  or(IterableDatas
-00001180: 6574 2c20 6d65 7461 636c 6173 733d 6162  et, metaclass=ab
-00001190: 632e 4142 434d 6574 6129 3a0d 0a20 2020  c.ABCMeta):..   
-000011a0: 205f 6974 6572 6174 6f72 203d 204e 6f6e   _iterator = Non
-000011b0: 650d 0a0d 0a20 2020 2064 6566 205f 6765  e....    def _ge
-000011c0: 745f 706f 6c69 6379 5f61 6e64 5f64 6576  t_policy_and_dev
-000011d0: 6963 6528 0d0a 2020 2020 2020 2020 7365  ice(..        se
-000011e0: 6c66 2c0d 0a20 2020 2020 2020 2070 6f6c  lf,..        pol
-000011f0: 6963 793a 204f 7074 696f 6e61 6c5b 0d0a  icy: Optional[..
-00001200: 2020 2020 2020 2020 2020 2020 556e 696f              Unio
-00001210: 6e5b 0d0a 2020 2020 2020 2020 2020 2020  n[..            
-00001220: 2020 2020 5465 6e73 6f72 4469 6374 4d6f      TensorDictMo
-00001230: 6475 6c65 2c0d 0a20 2020 2020 2020 2020  dule,..         
-00001240: 2020 2020 2020 2043 616c 6c61 626c 655b         Callable[
-00001250: 5b54 656e 736f 7244 6963 7442 6173 655d  [TensorDictBase]
-00001260: 2c20 5465 6e73 6f72 4469 6374 4261 7365  , TensorDictBase
-00001270: 5d2c 0d0a 2020 2020 2020 2020 2020 2020  ],..            
-00001280: 5d0d 0a20 2020 2020 2020 205d 203d 204e  ]..        ] = N
-00001290: 6f6e 652c 0d0a 2020 2020 2020 2020 6465  one,..        de
-000012a0: 7669 6365 3a20 4f70 7469 6f6e 616c 5b44  vice: Optional[D
-000012b0: 4556 4943 455f 5459 5049 4e47 5d20 3d20  EVICE_TYPING] = 
-000012c0: 4e6f 6e65 2c0d 0a20 2020 2020 2020 206f  None,..        o
-000012d0: 6273 6572 7661 7469 6f6e 5f73 7065 633a  bservation_spec:
-000012e0: 2054 656e 736f 7253 7065 6320 3d20 4e6f   TensorSpec = No
-000012f0: 6e65 2c0d 0a20 2020 2029 202d 3e20 5475  ne,..    ) -> Tu
-00001300: 706c 655b 5465 6e73 6f72 4469 6374 4d6f  ple[TensorDictMo
-00001310: 6475 6c65 2c20 746f 7263 682e 6465 7669  dule, torch.devi
-00001320: 6365 2c20 556e 696f 6e5b 4e6f 6e65 2c20  ce, Union[None, 
-00001330: 4361 6c6c 6162 6c65 5b5b 5d2c 2064 6963  Callable[[], dic
-00001340: 745d 5d5d 3a0d 0a20 2020 2020 2020 2022  t]]]:..        "
-00001350: 2222 5574 696c 206d 6574 686f 6420 746f  ""Util method to
-00001360: 2067 6574 2061 2070 6f6c 6963 7920 616e   get a policy an
-00001370: 6420 6974 7320 6465 7669 6365 2067 6976  d its device giv
-00001380: 656e 2074 6865 2063 6f6c 6c65 6374 6f72  en the collector
-00001390: 205f 5f69 6e69 745f 5f20 696e 7075 7473   __init__ inputs
-000013a0: 2e0d 0a0d 0a20 2020 2020 2020 2046 726f  .....        Fro
-000013b0: 6d20 6120 706f 6c69 6379 2061 6e64 2061  m a policy and a
-000013c0: 2064 6576 6963 652c 2061 7373 6967 6e73   device, assigns
-000013d0: 2074 6865 2073 656c 662e 6465 7669 6365   the self.device
-000013e0: 2061 7474 7269 6275 7465 2074 6f0d 0a20   attribute to.. 
-000013f0: 2020 2020 2020 2074 6865 2064 6573 6972         the desir
-00001400: 6564 2064 6576 6963 6520 616e 6420 6d61  ed device and ma
-00001410: 7073 2074 6865 2070 6f6c 6963 7920 6f6e  ps the policy on
-00001420: 746f 2069 7420 6f72 2028 6966 2074 6865  to it or (if the
-00001430: 2064 6576 6963 6520 6973 0d0a 2020 2020   device is..    
-00001440: 2020 2020 6f6d 6d69 7474 6564 2920 6173      ommitted) as
-00001450: 7369 676e 7320 7468 6520 7365 6c66 2e64  signs the self.d
-00001460: 6576 6963 6520 6174 7472 6962 7574 6520  evice attribute 
-00001470: 746f 2074 6865 2070 6f6c 6963 7920 6465  to the policy de
-00001480: 7669 6365 2e0d 0a0d 0a20 2020 2020 2020  vice.....       
-00001490: 2041 7267 733a 0d0a 2020 2020 2020 2020   Args:..        
-000014a0: 2020 2020 6372 6561 7465 5f65 6e76 5f66      create_env_f
-000014b0: 6e20 2843 616c 6c61 626c 6520 6f72 206c  n (Callable or l
-000014c0: 6973 7420 6f66 2063 616c 6c61 626c 6573  ist of callables
-000014d0: 293a 2061 6e20 656e 7620 6372 6561 746f  ): an env creato
-000014e0: 720d 0a20 2020 2020 2020 2020 2020 2020  r..             
-000014f0: 2020 2066 756e 6374 696f 6e20 286f 7220     function (or 
-00001500: 6120 6c69 7374 206f 6620 6372 6561 746f  a list of creato
-00001510: 7273 290d 0a20 2020 2020 2020 2020 2020  rs)..           
-00001520: 2063 7265 6174 655f 656e 765f 6b77 6172   create_env_kwar
-00001530: 6773 2028 6469 6374 696f 6e61 7279 293a  gs (dictionary):
-00001540: 206b 7761 7267 7320 666f 7220 7468 6520   kwargs for the 
-00001550: 656e 7620 6372 6561 746f 720d 0a20 2020  env creator..   
-00001560: 2020 2020 2020 2020 2070 6f6c 6963 7920           policy 
-00001570: 2854 656e 736f 7244 6963 744d 6f64 756c  (TensorDictModul
-00001580: 652c 206f 7074 696f 6e61 6c29 3a20 6120  e, optional): a 
-00001590: 706f 6c69 6379 2074 6f20 6265 2075 7365  policy to be use
-000015a0: 640d 0a20 2020 2020 2020 2020 2020 2064  d..            d
-000015b0: 6576 6963 6520 2869 6e74 2c20 7374 7220  evice (int, str 
-000015c0: 6f72 2074 6f72 6368 2e64 6576 6963 652c  or torch.device,
-000015d0: 206f 7074 696f 6e61 6c29 3a20 6465 7669   optional): devi
-000015e0: 6365 2077 6865 7265 2074 6f20 706c 6163  ce where to plac
-000015f0: 650d 0a20 2020 2020 2020 2020 2020 2020  e..             
-00001600: 2020 2074 6865 2070 6f6c 6963 790d 0a20     the policy.. 
-00001610: 2020 2020 2020 2020 2020 206f 6273 6572             obser
-00001620: 7661 7469 6f6e 5f73 7065 6320 2854 656e  vation_spec (Ten
-00001630: 736f 7253 7065 632c 206f 7074 696f 6e61  sorSpec, optiona
-00001640: 6c29 3a20 7370 6563 206f 6620 7468 6520  l): spec of the 
-00001650: 6f62 7365 7276 6174 696f 6e73 0d0a 0d0a  observations....
-00001660: 2020 2020 2020 2020 2222 220d 0a20 2020          """..   
-00001670: 2020 2020 2023 2069 6620 6372 6561 7465       # if create
-00001680: 5f65 6e76 5f66 6e20 6973 206e 6f74 204e  _env_fn is not N
-00001690: 6f6e 653a 0d0a 2020 2020 2020 2020 2320  one:..        # 
-000016a0: 2020 2020 6966 2063 7265 6174 655f 656e      if create_en
-000016b0: 765f 6b77 6172 6773 2069 7320 4e6f 6e65  v_kwargs is None
-000016c0: 3a0d 0a20 2020 2020 2020 2023 2020 2020  :..        #    
-000016d0: 2020 2020 2063 7265 6174 655f 656e 765f       create_env_
-000016e0: 6b77 6172 6773 203d 207b 7d0d 0a20 2020  kwargs = {}..   
-000016f0: 2020 2020 2023 2020 2020 2073 656c 662e       #     self.
-00001700: 6372 6561 7465 5f65 6e76 5f66 6e20 3d20  create_env_fn = 
-00001710: 6372 6561 7465 5f65 6e76 5f66 6e0d 0a20  create_env_fn.. 
-00001720: 2020 2020 2020 2023 2020 2020 2069 6620         #     if 
-00001730: 6973 696e 7374 616e 6365 2863 7265 6174  isinstance(creat
-00001740: 655f 656e 765f 666e 2c20 456e 7642 6173  e_env_fn, EnvBas
-00001750: 6529 3a0d 0a20 2020 2020 2020 2023 2020  e):..        #  
-00001760: 2020 2020 2020 2065 6e76 203d 2063 7265         env = cre
-00001770: 6174 655f 656e 765f 666e 0d0a 2020 2020  ate_env_fn..    
-00001780: 2020 2020 2320 2020 2020 656c 7365 3a0d      #     else:.
-00001790: 0a20 2020 2020 2020 2023 2020 2020 2020  .        #      
-000017a0: 2020 2065 6e76 203d 2073 656c 662e 6372     env = self.cr
-000017b0: 6561 7465 5f65 6e76 5f66 6e28 2a2a 6372  eate_env_fn(**cr
-000017c0: 6561 7465 5f65 6e76 5f6b 7761 7267 7329  eate_env_kwargs)
-000017d0: 0d0a 2020 2020 2020 2020 2320 656c 7365  ..        # else
-000017e0: 3a0d 0a20 2020 2020 2020 2023 2020 2020  :..        #    
-000017f0: 2065 6e76 203d 204e 6f6e 650d 0a0d 0a20   env = None.... 
-00001800: 2020 2020 2020 2069 6620 706f 6c69 6379         if policy
-00001810: 2069 7320 4e6f 6e65 3a0d 0a20 2020 2020   is None:..     
-00001820: 2020 2020 2020 2069 6620 6e6f 7420 6861         if not ha
-00001830: 7361 7474 7228 7365 6c66 2c20 2265 6e76  sattr(self, "env
-00001840: 2229 206f 7220 7365 6c66 2e65 6e76 2069  ") or self.env i
-00001850: 7320 4e6f 6e65 3a0d 0a20 2020 2020 2020  s None:..       
-00001860: 2020 2020 2020 2020 2072 6169 7365 2056           raise V
-00001870: 616c 7565 4572 726f 7228 0d0a 2020 2020  alueError(..    
-00001880: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001890: 2265 6e76 206d 7573 7420 6265 2070 726f  "env must be pro
-000018a0: 7669 6465 6420 746f 205f 6765 745f 706f  vided to _get_po
-000018b0: 6c69 6379 5f61 6e64 5f64 6576 6963 6520  licy_and_device 
-000018c0: 6966 2070 6f6c 6963 7920 6973 204e 6f6e  if policy is Non
-000018d0: 6522 0d0a 2020 2020 2020 2020 2020 2020  e"..            
-000018e0: 2020 2020 290d 0a20 2020 2020 2020 2020      )..         
-000018f0: 2020 2070 6f6c 6963 7920 3d20 5261 6e64     policy = Rand
-00001900: 6f6d 506f 6c69 6379 2873 656c 662e 656e  omPolicy(self.en
-00001910: 762e 6163 7469 6f6e 5f73 7065 6329 0d0a  v.action_spec)..
-00001920: 2020 2020 2020 2020 656c 6966 2069 7369          elif isi
-00001930: 6e73 7461 6e63 6528 706f 6c69 6379 2c20  nstance(policy, 
-00001940: 6e6e 2e4d 6f64 756c 6529 3a0d 0a20 2020  nn.Module):..   
-00001950: 2020 2020 2020 2020 2023 2054 4f44 4f3a           # TODO:
-00001960: 2072 6576 6973 6974 2074 6865 7365 2063   revisit these c
-00001970: 6865 636b 7320 7768 656e 2077 6520 6861  hecks when we ha
-00001980: 7665 2064 6574 6572 6d69 6e65 6420 7768  ve determined wh
-00001990: 6574 6865 7220 6172 6269 7472 6172 790d  ether arbitrary.
-000019a0: 0a20 2020 2020 2020 2020 2020 2023 2063  .            # c
-000019b0: 616c 6c61 626c 6573 2073 686f 756c 6420  allables should 
-000019c0: 6265 2073 7570 706f 7274 6564 2061 7320  be supported as 
-000019d0: 706f 6c69 6369 6573 2e0d 0a20 2020 2020  policies...     
-000019e0: 2020 2020 2020 2069 6620 6e6f 7420 5f70         if not _p
-000019f0: 6f6c 6963 795f 6973 5f74 656e 736f 7264  olicy_is_tensord
-00001a00: 6963 745f 636f 6d70 6174 6962 6c65 2870  ict_compatible(p
-00001a10: 6f6c 6963 7929 3a0d 0a20 2020 2020 2020  olicy):..       
-00001a20: 2020 2020 2020 2020 2023 2070 6f6c 6963           # polic
-00001a30: 7920 6973 2061 206e 6e2e 4d6f 6475 6c65  y is a nn.Module
-00001a40: 2074 6861 7420 646f 6573 6e27 7420 6f70   that doesn't op
-00001a50: 6572 6174 6520 6f6e 2074 656e 736f 7264  erate on tensord
-00001a60: 6963 7473 2064 6972 6563 746c 790d 0a20  icts directly.. 
-00001a70: 2020 2020 2020 2020 2020 2020 2020 2023                 #
-00001a80: 2073 6f20 7765 2061 7474 656d 7074 2074   so we attempt t
-00001a90: 6f20 6175 746f 2d77 7261 7020 706f 6c69  o auto-wrap poli
-00001aa0: 6379 2077 6974 6820 5465 6e73 6f72 4469  cy with TensorDi
-00001ab0: 6374 4d6f 6475 6c65 0d0a 2020 2020 2020  ctModule..      
-00001ac0: 2020 2020 2020 2020 2020 6966 206f 6273            if obs
-00001ad0: 6572 7661 7469 6f6e 5f73 7065 6320 6973  ervation_spec is
-00001ae0: 204e 6f6e 653a 0d0a 2020 2020 2020 2020   None:..        
-00001af0: 2020 2020 2020 2020 2020 2020 7261 6973              rais
-00001b00: 6520 5661 6c75 6545 7272 6f72 280d 0a20  e ValueError(.. 
-00001b10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001b20: 2020 2020 2020 2022 556e 6162 6c65 2074         "Unable t
-00001b30: 6f20 7265 6164 206f 6273 6572 7661 7469  o read observati
-00001b40: 6f6e 5f73 7065 6320 6672 6f6d 2074 6865  on_spec from the
-00001b50: 2065 6e76 6972 6f6e 6d65 6e74 2e20 5468   environment. Th
-00001b60: 6973 2069 7320 220d 0a20 2020 2020 2020  is is "..       
-00001b70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001b80: 2022 7265 7175 6972 6564 2074 6f20 6368   "required to ch
-00001b90: 6563 6b20 636f 6d70 6174 6962 696c 6974  eck compatibilit
-00001ba0: 7920 6f66 2074 6865 2065 6e76 6972 6f6e  y of the environ
-00001bb0: 6d65 6e74 2061 6e64 2070 6f6c 6963 7920  ment and policy 
-00001bc0: 220d 0a20 2020 2020 2020 2020 2020 2020  "..             
-00001bd0: 2020 2020 2020 2020 2020 2022 7369 6e63             "sinc
-00001be0: 6520 7468 6520 706f 6c69 6379 2069 7320  e the policy is 
-00001bf0: 6120 6e6e 2e4d 6f64 756c 6520 7468 6174  a nn.Module that
-00001c00: 206f 7065 7261 7465 7320 6f6e 2074 656e   operates on ten
-00001c10: 736f 7273 2022 0d0a 2020 2020 2020 2020  sors "..        
-00001c20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001c30: 2272 6174 6865 7220 7468 616e 2061 2054  "rather than a T
-00001c40: 656e 736f 7244 6963 744d 6f64 756c 6520  ensorDictModule 
-00001c50: 6f72 2061 206e 6e2e 4d6f 6475 6c65 2074  or a nn.Module t
-00001c60: 6861 7420 6163 6365 7074 7320 6120 220d  hat accepts a ".
-00001c70: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00001c80: 2020 2020 2020 2020 2022 5465 6e73 6f72           "Tensor
-00001c90: 4469 6374 2061 7320 696e 7075 7420 616e  Dict as input an
-00001ca0: 6420 6465 6669 6e65 7320 696e 5f6b 6579  d defines in_key
-00001cb0: 7320 616e 6420 6f75 745f 6b65 7973 2e22  s and out_keys."
-00001cc0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00001cd0: 2020 2020 2020 290d 0a20 2020 2020 2020        )..       
-00001ce0: 2020 2020 2020 2020 2073 6967 203d 2069           sig = i
-00001cf0: 6e73 7065 6374 2e73 6967 6e61 7475 7265  nspect.signature
-00001d00: 2870 6f6c 6963 792e 666f 7277 6172 6429  (policy.forward)
-00001d10: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00001d20: 2020 6e65 7874 5f6f 6273 6572 7661 7469    next_observati
-00001d30: 6f6e 203d 207b 0d0a 2020 2020 2020 2020  on = {..        
-00001d40: 2020 2020 2020 2020 2020 2020 6b65 793a              key:
-00001d50: 2076 616c 7565 2066 6f72 206b 6579 2c20   value for key, 
-00001d60: 7661 6c75 6520 696e 206f 6273 6572 7661  value in observa
-00001d70: 7469 6f6e 5f73 7065 632e 7261 6e64 2829  tion_spec.rand()
-00001d80: 2e69 7465 6d73 2829 0d0a 2020 2020 2020  .items()..      
-00001d90: 2020 2020 2020 2020 2020 7d0d 0a20 2020            }..   
-00001da0: 2020 2020 2020 2020 2020 2020 2069 6620               if 
-00001db0: 7365 7428 7369 672e 7061 7261 6d65 7465  set(sig.paramete
-00001dc0: 7273 2920 3d3d 2073 6574 286e 6578 745f  rs) == set(next_
-00001dd0: 6f62 7365 7276 6174 696f 6e29 3a0d 0a20  observation):.. 
-00001de0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001df0: 2020 206f 7574 5f6b 6579 7320 3d20 5b22     out_keys = ["
-00001e00: 6163 7469 6f6e 225d 0d0a 2020 2020 2020  action"]..      
-00001e10: 2020 2020 2020 2020 2020 2020 2020 6f75                ou
-00001e20: 7470 7574 203d 2070 6f6c 6963 7928 2a2a  tput = policy(**
-00001e30: 6e65 7874 5f6f 6273 6572 7661 7469 6f6e  next_observation
-00001e40: 290d 0a0d 0a20 2020 2020 2020 2020 2020  )....           
-00001e50: 2020 2020 2020 2020 2069 6620 6973 696e           if isin
-00001e60: 7374 616e 6365 286f 7574 7075 742c 2074  stance(output, t
-00001e70: 7570 6c65 293a 0d0a 2020 2020 2020 2020  uple):..        
-00001e80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001e90: 6f75 745f 6b65 7973 2e65 7874 656e 6428  out_keys.extend(
-00001ea0: 6622 6f75 7470 7574 7b69 2b31 7d22 2066  f"output{i+1}" f
-00001eb0: 6f72 2069 2069 6e20 7261 6e67 6528 6c65  or i in range(le
-00001ec0: 6e28 6f75 7470 7574 2920 2d20 3129 290d  n(output) - 1)).
-00001ed0: 0a0d 0a20 2020 2020 2020 2020 2020 2020  ...             
-00001ee0: 2020 2020 2020 2070 6f6c 6963 7920 3d20         policy = 
-00001ef0: 5465 6e73 6f72 4469 6374 4d6f 6475 6c65  TensorDictModule
-00001f00: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
-00001f10: 2020 2020 2020 2020 2020 2070 6f6c 6963             polic
-00001f20: 792c 2069 6e5f 6b65 7973 3d6c 6973 7428  y, in_keys=list(
-00001f30: 7369 672e 7061 7261 6d65 7465 7273 292c  sig.parameters),
-00001f40: 206f 7574 5f6b 6579 733d 6f75 745f 6b65   out_keys=out_ke
-00001f50: 7973 0d0a 2020 2020 2020 2020 2020 2020  ys..            
-00001f60: 2020 2020 2020 2020 290d 0a20 2020 2020          )..     
-00001f70: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
-00001f80: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00001f90: 2020 2020 2020 7261 6973 6520 5479 7065        raise Type
-00001fa0: 4572 726f 7228 0d0a 2020 2020 2020 2020  Error(..        
-00001fb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001fc0: 2241 7267 756d 656e 7473 2074 6f20 706f  "Arguments to po
-00001fd0: 6c69 6379 2e66 6f72 7761 7264 2061 7265  licy.forward are
-00001fe0: 2069 6e63 6f6d 7061 7469 626c 6520 7769   incompatible wi
-00001ff0: 7468 2065 6e74 7269 6573 2069 6e20 220d  th entries in ".
-00002000: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00002010: 2020 2020 2020 2020 2022 656e 762e 6f62           "env.ob
-00002020: 7365 7276 6174 696f 6e5f 7370 6563 2e20  servation_spec. 
-00002030: 4966 2079 6f75 2077 616e 7420 546f 7263  If you want Torc
-00002040: 6852 4c20 746f 2061 7574 6f6d 6174 6963  hRL to automatic
-00002050: 616c 6c79 2022 0d0a 2020 2020 2020 2020  ally "..        
-00002060: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002070: 2277 7261 7020 796f 7572 2070 6f6c 6963  "wrap your polic
-00002080: 7920 7769 7468 2061 2054 656e 736f 7244  y with a TensorD
-00002090: 6963 744d 6f64 756c 6520 7468 656e 2074  ictModule then t
-000020a0: 6865 2061 7267 756d 656e 7473 2022 0d0a  he arguments "..
-000020b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000020c0: 2020 2020 2020 2020 2274 6f20 706f 6c69          "to poli
-000020d0: 6379 2e66 6f72 7761 7264 206d 7573 7420  cy.forward must 
-000020e0: 636f 7272 6573 706f 6e64 206f 6e65 2d74  correspond one-t
-000020f0: 6f2d 6f6e 6520 7769 7468 2065 6e74 7269  o-one with entri
-00002100: 6573 2069 6e20 220d 0a20 2020 2020 2020  es in "..       
-00002110: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002120: 2022 656e 762e 6f62 7365 7276 6174 696f   "env.observatio
-00002130: 6e5f 7370 6563 2074 6861 7420 6172 6520  n_spec that are 
-00002140: 7072 6566 6978 6564 2077 6974 6820 276e  prefixed with 'n
-00002150: 6578 745f 272e 2046 6f72 206d 6f72 6520  ext_'. For more 
-00002160: 220d 0a20 2020 2020 2020 2020 2020 2020  "..             
-00002170: 2020 2020 2020 2020 2020 2022 636f 6d70             "comp
-00002180: 6c65 7820 6265 6861 7669 6f75 7220 616e  lex behaviour an
-00002190: 6420 6d6f 7265 2063 6f6e 7472 6f6c 2079  d more control y
-000021a0: 6f75 2063 616e 2063 6f6e 7369 6465 7220  ou can consider 
-000021b0: 7772 6974 696e 6720 220d 0a20 2020 2020  writing "..     
-000021c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000021d0: 2020 2022 796f 7572 206f 776e 2054 656e     "your own Ten
-000021e0: 736f 7244 6963 744d 6f64 756c 652e 220d  sorDictModule.".
-000021f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00002200: 2020 2020 2029 0d0a 0d0a 2020 2020 2020       )....      
-00002210: 2020 7472 793a 0d0a 2020 2020 2020 2020    try:..        
-00002220: 2020 2020 706f 6c69 6379 5f64 6576 6963      policy_devic
-00002230: 6520 3d20 6e65 7874 2870 6f6c 6963 792e  e = next(policy.
-00002240: 7061 7261 6d65 7465 7273 2829 292e 6465  parameters()).de
-00002250: 7669 6365 0d0a 2020 2020 2020 2020 6578  vice..        ex
-00002260: 6365 7074 3a20 2023 206e 6f71 610d 0a20  cept:  # noqa.. 
-00002270: 2020 2020 2020 2020 2020 2070 6f6c 6963             polic
-00002280: 795f 6465 7669 6365 203d 2028 0d0a 2020  y_device = (..  
-00002290: 2020 2020 2020 2020 2020 2020 2020 746f                to
-000022a0: 7263 682e 6465 7669 6365 2864 6576 6963  rch.device(devic
-000022b0: 6529 2069 6620 6465 7669 6365 2069 7320  e) if device is 
-000022c0: 6e6f 7420 4e6f 6e65 2065 6c73 6520 746f  not None else to
-000022d0: 7263 682e 6465 7669 6365 2822 6370 7522  rch.device("cpu"
-000022e0: 290d 0a20 2020 2020 2020 2020 2020 2029  )..            )
-000022f0: 0d0a 0d0a 2020 2020 2020 2020 6465 7669  ....        devi
-00002300: 6365 203d 2074 6f72 6368 2e64 6576 6963  ce = torch.devic
-00002310: 6528 6465 7669 6365 2920 6966 2064 6576  e(device) if dev
-00002320: 6963 6520 6973 206e 6f74 204e 6f6e 6520  ice is not None 
-00002330: 656c 7365 2070 6f6c 6963 795f 6465 7669  else policy_devi
-00002340: 6365 0d0a 2020 2020 2020 2020 6966 2064  ce..        if d
-00002350: 6576 6963 6520 6973 204e 6f6e 653a 0d0a  evice is None:..
-00002360: 2020 2020 2020 2020 2020 2020 6465 7669              devi
-00002370: 6365 203d 2074 6f72 6368 2e64 6576 6963  ce = torch.devic
-00002380: 6528 2263 7075 2229 0d0a 2020 2020 2020  e("cpu")..      
-00002390: 2020 6765 745f 7765 6967 6874 735f 666e    get_weights_fn
-000023a0: 203d 204e 6f6e 650d 0a20 2020 2020 2020   = None..       
-000023b0: 2069 6620 706f 6c69 6379 5f64 6576 6963   if policy_devic
-000023c0: 6520 213d 2064 6576 6963 653a 0d0a 2020  e != device:..  
-000023d0: 2020 2020 2020 2020 2020 6765 745f 7765            get_we
-000023e0: 6967 6874 735f 666e 203d 2070 6f6c 6963  ights_fn = polic
-000023f0: 792e 7374 6174 655f 6469 6374 0d0a 2020  y.state_dict..  
-00002400: 2020 2020 2020 2020 2020 706f 6c69 6379            policy
-00002410: 203d 2064 6565 7063 6f70 7928 706f 6c69   = deepcopy(poli
-00002420: 6379 292e 7265 7175 6972 6573 5f67 7261  cy).requires_gra
-00002430: 645f 2846 616c 7365 292e 746f 2864 6576  d_(False).to(dev
-00002440: 6963 6529 0d0a 2020 2020 2020 2020 2020  ice)..          
-00002450: 2020 6966 2064 6576 6963 6520 3d3d 2074    if device == t
-00002460: 6f72 6368 2e64 6576 6963 6528 2263 7075  orch.device("cpu
-00002470: 2229 3a0d 0a20 2020 2020 2020 2020 2020  "):..           
-00002480: 2020 2020 2070 6f6c 6963 792e 7368 6172       policy.shar
-00002490: 655f 6d65 6d6f 7279 2829 0d0a 2020 2020  e_memory()..    
-000024a0: 2020 2020 7265 7475 726e 2070 6f6c 6963      return polic
-000024b0: 792c 2064 6576 6963 652c 2067 6574 5f77  y, device, get_w
-000024c0: 6569 6768 7473 5f66 6e0d 0a0d 0a20 2020  eights_fn....   
-000024d0: 2064 6566 2075 7064 6174 655f 706f 6c69   def update_poli
-000024e0: 6379 5f77 6569 6768 7473 5f28 0d0a 2020  cy_weights_(..  
-000024f0: 2020 2020 2020 7365 6c66 2c20 706f 6c69        self, poli
-00002500: 6379 5f77 6569 6768 7473 3a20 4f70 7469  cy_weights: Opti
-00002510: 6f6e 616c 5b54 656e 736f 7244 6963 7442  onal[TensorDictB
-00002520: 6173 655d 203d 204e 6f6e 650d 0a20 2020  ase] = None..   
-00002530: 2029 202d 3e20 4e6f 6e65 3a0d 0a20 2020   ) -> None:..   
-00002540: 2020 2020 2022 2222 5570 6461 7465 7320       """Updates 
-00002550: 7468 6520 706f 6c69 6379 2077 6569 6768  the policy weigh
-00002560: 7473 2069 6620 7468 6520 706f 6c69 6379  ts if the policy
-00002570: 206f 6620 7468 6520 6461 7461 2063 6f6c   of the data col
-00002580: 6c65 6374 6f72 2061 6e64 2074 6865 2074  lector and the t
-00002590: 7261 696e 6564 2070 6f6c 6963 7920 6c69  rained policy li
-000025a0: 7665 206f 6e20 6469 6666 6572 656e 7420  ve on different 
-000025b0: 6465 7669 6365 732e 0d0a 0d0a 2020 2020  devices.....    
-000025c0: 2020 2020 4172 6773 3a0d 0a20 2020 2020      Args:..     
-000025d0: 2020 2020 2020 2070 6f6c 6963 795f 7765         policy_we
-000025e0: 6967 6874 7320 2854 656e 736f 7244 6963  ights (TensorDic
-000025f0: 7442 6173 652c 206f 7074 696f 6e61 6c29  tBase, optional)
-00002600: 3a20 6966 2070 726f 7669 6465 642c 2061  : if provided, a
-00002610: 2054 656e 736f 7244 6963 7420 636f 6e74   TensorDict cont
-00002620: 6169 6e69 6e67 0d0a 2020 2020 2020 2020  aining..        
-00002630: 2020 2020 2020 2020 7468 6520 7765 6967          the weig
-00002640: 6874 7320 6f66 2074 6865 2070 6f6c 6963  hts of the polic
-00002650: 7920 746f 2062 6520 7573 6564 2066 6f72  y to be used for
-00002660: 2074 6865 2075 6470 6461 7465 2e0d 0a0d   the udpdate....
-00002670: 0a20 2020 2020 2020 2022 2222 0d0a 2020  .        """..  
-00002680: 2020 2020 2020 6966 2070 6f6c 6963 795f        if policy_
-00002690: 7765 6967 6874 7320 6973 206e 6f74 204e  weights is not N
-000026a0: 6f6e 653a 0d0a 2020 2020 2020 2020 2020  one:..          
-000026b0: 2020 7365 6c66 2e70 6f6c 6963 795f 7765    self.policy_we
-000026c0: 6967 6874 732e 6170 706c 7928 6c61 6d62  ights.apply(lamb
-000026d0: 6461 2078 3a20 782e 6461 7461 292e 7570  da x: x.data).up
-000026e0: 6461 7465 5f28 706f 6c69 6379 5f77 6569  date_(policy_wei
-000026f0: 6768 7473 290d 0a20 2020 2020 2020 2065  ghts)..        e
-00002700: 6c69 6620 7365 6c66 2e67 6574 5f77 6569  lif self.get_wei
-00002710: 6768 7473 5f66 6e20 6973 206e 6f74 204e  ghts_fn is not N
-00002720: 6f6e 653a 0d0a 2020 2020 2020 2020 2020  one:..          
-00002730: 2020 7365 6c66 2e70 6f6c 6963 792e 6c6f    self.policy.lo
-00002740: 6164 5f73 7461 7465 5f64 6963 7428 7365  ad_state_dict(se
-00002750: 6c66 2e67 6574 5f77 6569 6768 7473 5f66  lf.get_weights_f
-00002760: 6e28 2929 0d0a 0d0a 2020 2020 6465 6620  n())....    def 
-00002770: 5f5f 6974 6572 5f5f 2873 656c 6629 202d  __iter__(self) -
-00002780: 3e20 4974 6572 6174 6f72 5b54 656e 736f  > Iterator[Tenso
-00002790: 7244 6963 7442 6173 655d 3a0d 0a20 2020  rDictBase]:..   
-000027a0: 2020 2020 2072 6574 7572 6e20 7365 6c66       return self
-000027b0: 2e69 7465 7261 746f 7228 290d 0a0d 0a20  .iterator().... 
-000027c0: 2020 2064 6566 206e 6578 7428 7365 6c66     def next(self
-000027d0: 293a 0d0a 2020 2020 2020 2020 7472 793a  ):..        try:
-000027e0: 0d0a 2020 2020 2020 2020 2020 2020 6966  ..            if
-000027f0: 2073 656c 662e 5f69 7465 7261 746f 7220   self._iterator 
-00002800: 6973 204e 6f6e 653a 0d0a 2020 2020 2020  is None:..      
-00002810: 2020 2020 2020 2020 2020 7365 6c66 2e5f            self._
-00002820: 6974 6572 6174 6f72 203d 2069 7465 7228  iterator = iter(
-00002830: 7365 6c66 290d 0a20 2020 2020 2020 2020  self)..         
-00002840: 2020 206f 7574 203d 206e 6578 7428 7365     out = next(se
-00002850: 6c66 2e5f 6974 6572 6174 6f72 290d 0a20  lf._iterator).. 
-00002860: 2020 2020 2020 2020 2020 2023 2069 6620             # if 
-00002870: 616e 792c 2077 6520 646f 6e27 7420 7761  any, we don't wa
-00002880: 6e74 2074 6865 2064 6576 6963 6520 7265  nt the device re
-00002890: 6620 746f 2062 6520 7061 7373 6564 2069  f to be passed i
-000028a0: 6e20 6469 7374 7269 6275 7465 6420 7365  n distributed se
-000028b0: 7474 696e 6773 0d0a 2020 2020 2020 2020  ttings..        
-000028c0: 2020 2020 6f75 742e 636c 6561 725f 6465      out.clear_de
-000028d0: 7669 6365 5f28 290d 0a20 2020 2020 2020  vice_()..       
-000028e0: 2020 2020 2072 6574 7572 6e20 6f75 740d       return out.
-000028f0: 0a20 2020 2020 2020 2065 7863 6570 7420  .        except 
-00002900: 5374 6f70 4974 6572 6174 696f 6e3a 0d0a  StopIteration:..
-00002910: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-00002920: 726e 204e 6f6e 650d 0a0d 0a20 2020 2040  rn None....    @
-00002930: 6162 632e 6162 7374 7261 6374 6d65 7468  abc.abstractmeth
-00002940: 6f64 0d0a 2020 2020 6465 6620 7368 7574  od..    def shut
-00002950: 646f 776e 2873 656c 6629 3a0d 0a20 2020  down(self):..   
-00002960: 2020 2020 2072 6169 7365 204e 6f74 496d       raise NotIm
-00002970: 706c 656d 656e 7465 6445 7272 6f72 0d0a  plementedError..
-00002980: 0d0a 2020 2020 4061 6263 2e61 6273 7472  ..    @abc.abstr
-00002990: 6163 746d 6574 686f 640d 0a20 2020 2064  actmethod..    d
-000029a0: 6566 2069 7465 7261 746f 7228 7365 6c66  ef iterator(self
-000029b0: 2920 2d3e 2049 7465 7261 746f 725b 5465  ) -> Iterator[Te
-000029c0: 6e73 6f72 4469 6374 4261 7365 5d3a 0d0a  nsorDictBase]:..
-000029d0: 2020 2020 2020 2020 7261 6973 6520 4e6f          raise No
-000029e0: 7449 6d70 6c65 6d65 6e74 6564 4572 726f  tImplementedErro
-000029f0: 720d 0a0d 0a20 2020 2040 6162 632e 6162  r....    @abc.ab
-00002a00: 7374 7261 6374 6d65 7468 6f64 0d0a 2020  stractmethod..  
-00002a10: 2020 6465 6620 7365 745f 7365 6564 2873    def set_seed(s
-00002a20: 656c 662c 2073 6565 643a 2069 6e74 2c20  elf, seed: int, 
-00002a30: 7374 6174 6963 5f73 6565 643a 2062 6f6f  static_seed: boo
-00002a40: 6c20 3d20 4661 6c73 6529 202d 3e20 696e  l = False) -> in
-00002a50: 743a 0d0a 2020 2020 2020 2020 7261 6973  t:..        rais
-00002a60: 6520 4e6f 7449 6d70 6c65 6d65 6e74 6564  e NotImplemented
-00002a70: 4572 726f 720d 0a0d 0a20 2020 2040 6162  Error....    @ab
-00002a80: 632e 6162 7374 7261 6374 6d65 7468 6f64  c.abstractmethod
-00002a90: 0d0a 2020 2020 6465 6620 7374 6174 655f  ..    def state_
-00002aa0: 6469 6374 2873 656c 6629 202d 3e20 4f72  dict(self) -> Or
-00002ab0: 6465 7265 6444 6963 743a 0d0a 2020 2020  deredDict:..    
-00002ac0: 2020 2020 7261 6973 6520 4e6f 7449 6d70      raise NotImp
-00002ad0: 6c65 6d65 6e74 6564 4572 726f 720d 0a0d  lementedError...
-00002ae0: 0a20 2020 2040 6162 632e 6162 7374 7261  .    @abc.abstra
-00002af0: 6374 6d65 7468 6f64 0d0a 2020 2020 6465  ctmethod..    de
-00002b00: 6620 6c6f 6164 5f73 7461 7465 5f64 6963  f load_state_dic
-00002b10: 7428 7365 6c66 2c20 7374 6174 655f 6469  t(self, state_di
-00002b20: 6374 3a20 4f72 6465 7265 6444 6963 7429  ct: OrderedDict)
-00002b30: 202d 3e20 4e6f 6e65 3a0d 0a20 2020 2020   -> None:..     
-00002b40: 2020 2072 6169 7365 204e 6f74 496d 706c     raise NotImpl
-00002b50: 656d 656e 7465 6445 7272 6f72 0d0a 0d0a  ementedError....
-00002b60: 2020 2020 6465 6620 5f5f 7265 7072 5f5f      def __repr__
-00002b70: 2873 656c 6629 202d 3e20 7374 723a 0d0a  (self) -> str:..
-00002b80: 2020 2020 2020 2020 7374 7269 6e67 203d          string =
-00002b90: 2066 227b 7365 6c66 2e5f 5f63 6c61 7373   f"{self.__class
-00002ba0: 5f5f 2e5f 5f6e 616d 655f 5f7d 2829 220d  __.__name__}()".
-00002bb0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00002bc0: 7374 7269 6e67 0d0a 0d0a 0d0a 4061 6363  string......@acc
-00002bd0: 6570 745f 7265 6d6f 7465 5f72 7265 665f  ept_remote_rref_
-00002be0: 7564 665f 696e 766f 6361 7469 6f6e 0d0a  udf_invocation..
-00002bf0: 636c 6173 7320 5379 6e63 4461 7461 436f  class SyncDataCo
-00002c00: 6c6c 6563 746f 7228 5f44 6174 6143 6f6c  llector(_DataCol
-00002c10: 6c65 6374 6f72 293a 0d0a 2020 2020 2222  lector):..    ""
-00002c20: 2247 656e 6572 6963 2064 6174 6120 636f  "Generic data co
-00002c30: 6c6c 6563 746f 7220 666f 7220 524c 2070  llector for RL p
-00002c40: 726f 626c 656d 732e 2052 6571 7569 7265  roblems. Require
-00002c50: 7320 616e 6420 656e 7669 726f 6e6d 656e  s and environmen
-00002c60: 7420 636f 6e73 7472 7563 746f 7220 616e  t constructor an
-00002c70: 6420 6120 706f 6c69 6379 2e0d 0a0d 0a20  d a policy..... 
-00002c80: 2020 2041 7267 733a 0d0a 2020 2020 2020     Args:..      
-00002c90: 2020 6372 6561 7465 5f65 6e76 5f66 6e20    create_env_fn 
-00002ca0: 2843 616c 6c61 626c 6529 3a20 6120 6361  (Callable): a ca
-00002cb0: 6c6c 6162 6c65 2074 6861 7420 7265 7475  llable that retu
-00002cc0: 726e 7320 616e 2069 6e73 7461 6e63 6520  rns an instance 
-00002cd0: 6f66 0d0a 2020 2020 2020 2020 2020 2020  of..            
-00002ce0: 3a63 6c61 7373 3a60 746f 7263 6872 6c2e  :class:`torchrl.
-00002cf0: 656e 7673 2e45 6e76 4261 7365 6020 636c  envs.EnvBase` cl
-00002d00: 6173 732e 0d0a 2020 2020 2020 2020 706f  ass...        po
-00002d10: 6c69 6379 2028 4361 6c6c 6162 6c65 293a  licy (Callable):
-00002d20: 2050 6f6c 6963 7920 746f 2062 6520 6578   Policy to be ex
-00002d30: 6563 7574 6564 2069 6e20 7468 6520 656e  ecuted in the en
-00002d40: 7669 726f 6e6d 656e 742e 0d0a 2020 2020  vironment...    
-00002d50: 2020 2020 2020 2020 4d75 7374 2061 6363          Must acc
-00002d60: 6570 7420 3a63 6c61 7373 3a60 7465 6e73  ept :class:`tens
-00002d70: 6f72 6469 6374 2e74 656e 736f 7264 6963  ordict.tensordic
-00002d80: 742e 5465 6e73 6f72 4469 6374 4261 7365  t.TensorDictBase
-00002d90: 6020 6f62 6a65 6374 2061 7320 696e 7075  ` object as inpu
-00002da0: 742e 0d0a 2020 2020 2020 2020 2020 2020  t...            
-00002db0: 4966 2060 604e 6f6e 6560 6020 6973 2070  If ``None`` is p
-00002dc0: 726f 7669 6465 642c 2074 6865 2070 6f6c  rovided, the pol
-00002dd0: 6963 7920 7573 6564 2077 696c 6c20 6265  icy used will be
-00002de0: 2061 0d0a 2020 2020 2020 2020 2020 2020   a..            
-00002df0: 3a63 6c61 7373 3a60 5261 6e64 6f6d 506f  :class:`RandomPo
-00002e00: 6c69 6379 6020 696e 7374 616e 6365 2077  licy` instance w
-00002e10: 6974 6820 7468 6520 656e 7669 726f 6e6d  ith the environm
-00002e20: 656e 740d 0a20 2020 2020 2020 2020 2020  ent..           
-00002e30: 2060 6061 6374 696f 6e5f 7370 6563 6060   ``action_spec``
-00002e40: 2e0d 0a20 2020 2020 2020 2066 7261 6d65  ...        frame
-00002e50: 735f 7065 725f 6261 7463 6820 2869 6e74  s_per_batch (int
-00002e60: 293a 2041 206b 6579 776f 7264 2d6f 6e6c  ): A keyword-onl
-00002e70: 7920 6172 6775 6d65 6e74 2072 6570 7265  y argument repre
-00002e80: 7365 6e74 696e 6720 7468 6520 746f 7461  senting the tota
-00002e90: 6c0d 0a20 2020 2020 2020 2020 2020 206e  l..            n
-00002ea0: 756d 6265 7220 6f66 2065 6c65 6d65 6e74  umber of element
-00002eb0: 7320 696e 2061 2062 6174 6368 2e0d 0a20  s in a batch... 
-00002ec0: 2020 2020 2020 2074 6f74 616c 5f66 7261         total_fra
-00002ed0: 6d65 7320 2869 6e74 293a 2041 206b 6579  mes (int): A key
-00002ee0: 776f 7264 2d6f 6e6c 7920 6172 6775 6d65  word-only argume
-00002ef0: 6e74 2072 6570 7265 7365 6e74 696e 6720  nt representing 
-00002f00: 7468 6520 746f 7461 6c0d 0a20 2020 2020  the total..     
-00002f10: 2020 2020 2020 206e 756d 6265 7220 6f66         number of
-00002f20: 2066 7261 6d65 7320 7265 7475 726e 6564   frames returned
-00002f30: 2062 7920 7468 6520 636f 6c6c 6563 746f   by the collecto
-00002f40: 720d 0a20 2020 2020 2020 2020 2020 2064  r..            d
-00002f50: 7572 696e 6720 6974 7320 6c69 6665 7370  uring its lifesp
-00002f60: 616e 2e20 4966 2074 6865 2060 6074 6f74  an. If the ``tot
-00002f70: 616c 5f66 7261 6d65 7360 6020 6973 206e  al_frames`` is n
-00002f80: 6f74 2064 6976 6973 6962 6c65 2062 790d  ot divisible by.
-00002f90: 0a20 2020 2020 2020 2020 2020 2060 6066  .            ``f
-00002fa0: 7261 6d65 735f 7065 725f 6261 7463 6860  rames_per_batch`
-00002fb0: 602c 2061 6e20 6578 6365 7074 696f 6e20  `, an exception 
-00002fc0: 6973 2072 6169 7365 642e 0d0a 2020 2020  is raised...    
-00002fd0: 2020 2020 2020 2020 2045 6e64 6c65 7373           Endless
-00002fe0: 2063 6f6c 6c65 6374 6f72 7320 6361 6e20   collectors can 
-00002ff0: 6265 2063 7265 6174 6564 2062 7920 7061  be created by pa
-00003000: 7373 696e 6720 6060 746f 7461 6c5f 6672  ssing ``total_fr
-00003010: 616d 6573 3d2d 3160 602e 0d0a 2020 2020  ames=-1``...    
-00003020: 2020 2020 6465 7669 6365 2028 696e 742c      device (int,
-00003030: 2073 7472 206f 7220 746f 7263 682e 6465   str or torch.de
-00003040: 7669 6365 2c20 6f70 7469 6f6e 616c 293a  vice, optional):
-00003050: 2054 6865 2064 6576 6963 6520 6f6e 2077   The device on w
-00003060: 6869 6368 2074 6865 0d0a 2020 2020 2020  hich the..      
-00003070: 2020 2020 2020 706f 6c69 6379 2077 696c        policy wil
-00003080: 6c20 6265 2070 6c61 6365 642e 0d0a 2020  l be placed...  
-00003090: 2020 2020 2020 2020 2020 4966 2069 7420            If it 
-000030a0: 6469 6666 6572 7320 6672 6f6d 2074 6865  differs from the
-000030b0: 2069 6e70 7574 2070 6f6c 6963 7920 6465   input policy de
-000030c0: 7669 6365 2c20 7468 650d 0a20 2020 2020  vice, the..     
-000030d0: 2020 2020 2020 203a 6d65 7468 3a60 7e2e         :meth:`~.
-000030e0: 7570 6461 7465 5f70 6f6c 6963 795f 7765  update_policy_we
-000030f0: 6967 6874 735f 6020 6d65 7468 6f64 2073  ights_` method s
-00003100: 686f 756c 6420 6265 2071 7565 7269 6564  hould be queried
-00003110: 0d0a 2020 2020 2020 2020 2020 2020 6174  ..            at
-00003120: 2061 7070 726f 7072 6961 7465 2074 696d   appropriate tim
-00003130: 6573 2064 7572 696e 6720 7468 6520 7472  es during the tr
-00003140: 6169 6e69 6e67 206c 6f6f 7020 746f 2061  aining loop to a
-00003150: 6363 6f6d 6d6f 6461 7465 2066 6f72 0d0a  ccommodate for..
-00003160: 2020 2020 2020 2020 2020 2020 7468 6520              the 
-00003170: 6c61 6720 6265 7477 6565 6e20 7061 7261  lag between para
-00003180: 6d65 7465 7220 636f 6e66 6967 7572 6174  meter configurat
-00003190: 696f 6e20 6174 2076 6172 696f 7573 2074  ion at various t
-000031a0: 696d 6573 2e0d 0a20 2020 2020 2020 2020  imes...         
-000031b0: 2020 2044 6566 6175 6c74 7320 746f 2060     Defaults to `
-000031c0: 604e 6f6e 6560 6020 2869 2e65 2e20 706f  `None`` (i.e. po
-000031d0: 6c69 6379 2069 7320 6b65 7074 206f 6e20  licy is kept on 
-000031e0: 6974 7320 6f72 6967 696e 616c 2064 6576  its original dev
-000031f0: 6963 6529 2e0d 0a20 2020 2020 2020 2073  ice)...        s
-00003200: 746f 7269 6e67 5f64 6576 6963 6520 2869  toring_device (i
-00003210: 6e74 2c20 7374 7220 6f72 2074 6f72 6368  nt, str or torch
-00003220: 2e64 6576 6963 652c 206f 7074 696f 6e61  .device, optiona
-00003230: 6c29 3a20 5468 6520 6465 7669 6365 206f  l): The device o
-00003240: 6e20 7768 6963 680d 0a20 2020 2020 2020  n which..       
-00003250: 2020 2020 2074 6865 206f 7574 7075 7420       the output 
-00003260: 3a63 6c61 7373 3a60 7465 6e73 6f72 6469  :class:`tensordi
-00003270: 6374 2e54 656e 736f 7244 6963 7460 2077  ct.TensorDict` w
-00003280: 696c 6c20 6265 2073 746f 7265 642e 2046  ill be stored. F
-00003290: 6f72 206c 6f6e 670d 0a20 2020 2020 2020  or long..       
-000032a0: 2020 2020 2074 7261 6a65 6374 6f72 6965       trajectorie
-000032b0: 732c 2069 7420 6d61 7920 6265 206e 6563  s, it may be nec
-000032c0: 6573 7361 7279 2074 6f20 7374 6f72 6520  essary to store 
-000032d0: 7468 6520 6461 7461 206f 6e20 6120 6469  the data on a di
-000032e0: 6666 6572 656e 740d 0a20 2020 2020 2020  fferent..       
-000032f0: 2020 2020 2064 6576 6963 6520 7468 616e       device than
-00003300: 2074 6865 206f 6e65 2077 6865 7265 2074   the one where t
-00003310: 6865 2070 6f6c 6963 7920 616e 6420 656e  he policy and en
-00003320: 7620 6172 6520 6578 6563 7574 6564 2e0d  v are executed..
-00003330: 0a20 2020 2020 2020 2020 2020 2044 6566  .            Def
-00003340: 6175 6c74 7320 746f 2060 6022 6370 7522  aults to ``"cpu"
-00003350: 6060 2e0d 0a20 2020 2020 2020 2063 7265  ``...        cre
-00003360: 6174 655f 656e 765f 6b77 6172 6773 2028  ate_env_kwargs (
-00003370: 6469 6374 2c20 6f70 7469 6f6e 616c 293a  dict, optional):
-00003380: 2044 6963 7469 6f6e 6172 7920 6f66 206b   Dictionary of k
-00003390: 7761 7267 7320 666f 720d 0a20 2020 2020  wargs for..     
-000033a0: 2020 2020 2020 2060 6063 7265 6174 655f         ``create_
-000033b0: 656e 765f 666e 6060 2e0d 0a20 2020 2020  env_fn``...     
-000033c0: 2020 206d 6178 5f66 7261 6d65 735f 7065     max_frames_pe
-000033d0: 725f 7472 616a 2028 696e 742c 206f 7074  r_traj (int, opt
-000033e0: 696f 6e61 6c29 3a20 4d61 7869 6d75 6d20  ional): Maximum 
-000033f0: 7374 6570 7320 7065 7220 7472 616a 6563  steps per trajec
-00003400: 746f 7279 2e0d 0a20 2020 2020 2020 2020  tory...         
-00003410: 2020 204e 6f74 6520 7468 6174 2061 2074     Note that a t
-00003420: 7261 6a65 6374 6f72 7920 6361 6e20 7370  rajectory can sp
-00003430: 616e 206f 7665 7220 6d75 6c74 6970 6c65  an over multiple
-00003440: 2062 6174 6368 6573 2028 756e 6c65 7373   batches (unless
-00003450: 0d0a 2020 2020 2020 2020 2020 2020 6060  ..            ``
-00003460: 7265 7365 745f 6174 5f65 6163 685f 6974  reset_at_each_it
-00003470: 6572 6060 2069 7320 7365 7420 746f 2060  er`` is set to `
-00003480: 6054 7275 6560 602c 2073 6565 2062 656c  `True``, see bel
-00003490: 6f77 292e 0d0a 2020 2020 2020 2020 2020  ow)...          
-000034a0: 2020 4f6e 6365 2061 2074 7261 6a65 6374    Once a traject
-000034b0: 6f72 7920 7265 6163 6865 7320 6060 6e5f  ory reaches ``n_
-000034c0: 7374 6570 7360 602c 2074 6865 2065 6e76  steps``, the env
-000034d0: 6972 6f6e 6d65 6e74 2069 7320 7265 7365  ironment is rese
-000034e0: 742e 0d0a 2020 2020 2020 2020 2020 2020  t...            
-000034f0: 4966 2074 6865 2065 6e76 6972 6f6e 6d65  If the environme
-00003500: 6e74 2077 7261 7073 206d 756c 7469 706c  nt wraps multipl
-00003510: 6520 656e 7669 726f 6e6d 656e 7473 2074  e environments t
-00003520: 6f67 6574 6865 722c 2074 6865 206e 756d  ogether, the num
-00003530: 6265 720d 0a20 2020 2020 2020 2020 2020  ber..           
-00003540: 206f 6620 7374 6570 7320 6973 2074 7261   of steps is tra
-00003550: 636b 6564 2066 6f72 2065 6163 6820 656e  cked for each en
-00003560: 7669 726f 6e6d 656e 7420 696e 6465 7065  vironment indepe
-00003570: 6e64 656e 746c 792e 204e 6567 6174 6976  ndently. Negativ
-00003580: 650d 0a20 2020 2020 2020 2020 2020 2076  e..            v
-00003590: 616c 7565 7320 6172 6520 616c 6c6f 7765  alues are allowe
-000035a0: 642c 2069 6e20 7768 6963 6820 6361 7365  d, in which case
-000035b0: 2074 6869 7320 6172 6775 6d65 6e74 2069   this argument i
-000035c0: 7320 6967 6e6f 7265 642e 0d0a 2020 2020  s ignored...    
-000035d0: 2020 2020 2020 2020 4465 6661 756c 7473          Defaults
-000035e0: 2074 6f20 6060 2d31 6060 2028 692e 652e   to ``-1`` (i.e.
-000035f0: 206e 6f20 6d61 7869 6d75 6d20 6e75 6d62   no maximum numb
-00003600: 6572 206f 6620 7374 6570 7329 2e0d 0a20  er of steps)... 
-00003610: 2020 2020 2020 2069 6e69 745f 7261 6e64         init_rand
-00003620: 6f6d 5f66 7261 6d65 7320 2869 6e74 2c20  om_frames (int, 
-00003630: 6f70 7469 6f6e 616c 293a 204e 756d 6265  optional): Numbe
-00003640: 7220 6f66 2066 7261 6d65 7320 666f 7220  r of frames for 
-00003650: 7768 6963 6820 7468 650d 0a20 2020 2020  which the..     
-00003660: 2020 2020 2020 2070 6f6c 6963 7920 6973         policy is
-00003670: 2069 676e 6f72 6564 2062 6566 6f72 6520   ignored before 
-00003680: 6974 2069 7320 6361 6c6c 6564 2e20 5468  it is called. Th
-00003690: 6973 2066 6561 7475 7265 2069 7320 6d61  is feature is ma
-000036a0: 696e 6c79 0d0a 2020 2020 2020 2020 2020  inly..          
-000036b0: 2020 696e 7465 6e64 6564 2074 6f20 6265    intended to be
-000036c0: 2075 7365 6420 696e 206f 6666 6c69 6e65   used in offline
-000036d0: 2f6d 6f64 656c 2d62 6173 6564 2073 6574  /model-based set
-000036e0: 7469 6e67 732c 2077 6865 7265 2061 0d0a  tings, where a..
-000036f0: 2020 2020 2020 2020 2020 2020 6261 7463              batc
-00003700: 6820 6f66 2072 616e 646f 6d20 7472 616a  h of random traj
-00003710: 6563 746f 7269 6573 2063 616e 2062 6520  ectories can be 
-00003720: 7573 6564 2074 6f20 696e 6974 6961 6c69  used to initiali
-00003730: 7a65 2074 7261 696e 696e 672e 0d0a 2020  ze training...  
-00003740: 2020 2020 2020 2020 2020 4465 6661 756c            Defaul
-00003750: 7473 2074 6f20 6060 2d31 6060 2028 692e  ts to ``-1`` (i.
-00003760: 652e 206e 6f20 7261 6e64 6f6d 2066 7261  e. no random fra
-00003770: 6d65 7329 2e0d 0a20 2020 2020 2020 2072  mes)...        r
-00003780: 6573 6574 5f61 745f 6561 6368 5f69 7465  eset_at_each_ite
-00003790: 7220 2862 6f6f 6c2c 206f 7074 696f 6e61  r (bool, optiona
-000037a0: 6c29 3a20 5768 6574 6865 7220 656e 7669  l): Whether envi
-000037b0: 726f 6e6d 656e 7473 2073 686f 756c 6420  ronments should 
-000037c0: 6265 2072 6573 6574 0d0a 2020 2020 2020  be reset..      
-000037d0: 2020 2020 2020 6174 2074 6865 2062 6567        at the beg
-000037e0: 696e 6e69 6e67 206f 6620 6120 6261 7463  inning of a batc
-000037f0: 6820 636f 6c6c 6563 7469 6f6e 2e0d 0a20  h collection... 
-00003800: 2020 2020 2020 2020 2020 2044 6566 6175             Defau
-00003810: 6c74 7320 746f 2060 6046 616c 7365 6060  lts to ``False``
-00003820: 2e0d 0a20 2020 2020 2020 2070 6f73 7470  ...        postp
-00003830: 726f 6320 2843 616c 6c61 626c 652c 206f  roc (Callable, o
-00003840: 7074 696f 6e61 6c29 3a20 4120 706f 7374  ptional): A post
-00003850: 2d70 726f 6365 7373 696e 6720 7472 616e  -processing tran
-00003860: 7366 6f72 6d2c 2073 7563 6820 6173 0d0a  sform, such as..
-00003870: 2020 2020 2020 2020 2020 2020 6120 3a63              a :c
-00003880: 6c61 7373 3a60 746f 7263 6872 6c2e 656e  lass:`torchrl.en
-00003890: 7673 2e54 7261 6e73 666f 726d 6020 6f72  vs.Transform` or
-000038a0: 2061 203a 636c 6173 733a 6074 6f72 6368   a :class:`torch
-000038b0: 726c 2e64 6174 612e 706f 7374 7072 6f63  rl.data.postproc
-000038c0: 732e 4d75 6c74 6953 7465 7060 0d0a 2020  s.MultiStep`..  
-000038d0: 2020 2020 2020 2020 2020 696e 7374 616e            instan
-000038e0: 6365 2e0d 0a20 2020 2020 2020 2020 2020  ce...           
-000038f0: 2044 6566 6175 6c74 7320 746f 2060 604e   Defaults to ``N
-00003900: 6f6e 6560 602e 0d0a 2020 2020 2020 2020  one``...        
-00003910: 7370 6c69 745f 7472 616a 7320 2862 6f6f  split_trajs (boo
-00003920: 6c2c 206f 7074 696f 6e61 6c29 3a20 426f  l, optional): Bo
-00003930: 6f6c 6561 6e20 696e 6469 6361 7469 6e67  olean indicating
-00003940: 2077 6865 7468 6572 2074 6865 2072 6573   whether the res
-00003950: 756c 7469 6e67 0d0a 2020 2020 2020 2020  ulting..        
-00003960: 2020 2020 5465 6e73 6f72 4469 6374 2073      TensorDict s
-00003970: 686f 756c 6420 6265 2073 706c 6974 2061  hould be split a
-00003980: 6363 6f72 6469 6e67 2074 6f20 7468 6520  ccording to the 
-00003990: 7472 616a 6563 746f 7269 6573 2e0d 0a20  trajectories... 
-000039a0: 2020 2020 2020 2020 2020 2053 6565 203a             See :
-000039b0: 6675 6e63 3a60 746f 7263 6872 6c2e 636f  func:`torchrl.co
-000039c0: 6c6c 6563 746f 7273 2e75 7469 6c73 2e73  llectors.utils.s
-000039d0: 706c 6974 5f74 7261 6a65 6374 6f72 6965  plit_trajectorie
-000039e0: 7360 2066 6f72 206d 6f72 650d 0a20 2020  s` for more..   
-000039f0: 2020 2020 2020 2020 2069 6e66 6f72 6d61           informa
-00003a00: 7469 6f6e 2e0d 0a20 2020 2020 2020 2020  tion...         
-00003a10: 2020 2044 6566 6175 6c74 7320 746f 2060     Defaults to `
-00003a20: 6046 616c 7365 6060 2e0d 0a20 2020 2020  `False``...     
-00003a30: 2020 2065 7870 6c6f 7261 7469 6f6e 5f6d     exploration_m
-00003a40: 6f64 6520 2873 7472 2c20 6f70 7469 6f6e  ode (str, option
-00003a50: 616c 293a 2069 6e74 6572 6163 7469 6f6e  al): interaction
-00003a60: 206d 6f64 6520 746f 2062 6520 7573 6564   mode to be used
-00003a70: 2077 6865 6e0d 0a20 2020 2020 2020 2020   when..         
-00003a80: 2020 2063 6f6c 6c65 6374 696e 6720 6461     collecting da
-00003a90: 7461 2e20 4d75 7374 2062 6520 6f6e 6520  ta. Must be one 
-00003aa0: 6f66 2060 6022 7261 6e64 6f6d 2260 602c  of ``"random"``,
-00003ab0: 2060 6022 6d6f 6465 2260 6020 6f72 0d0a   ``"mode"`` or..
-00003ac0: 2020 2020 2020 2020 2020 2020 6060 226d              ``"m
-00003ad0: 6561 6e22 6060 2e0d 0a20 2020 2020 2020  ean"``...       
-00003ae0: 2020 2020 2044 6566 6175 6c74 7320 746f       Defaults to
-00003af0: 2060 6022 7261 6e64 6f6d 2260 600d 0a20   ``"random"``.. 
-00003b00: 2020 2020 2020 2072 6574 7572 6e5f 7361         return_sa
-00003b10: 6d65 5f74 6420 2862 6f6f 6c2c 206f 7074  me_td (bool, opt
-00003b20: 696f 6e61 6c29 3a20 6966 2060 6054 7275  ional): if ``Tru
-00003b30: 6560 602c 2074 6865 2073 616d 6520 5465  e``, the same Te
-00003b40: 6e73 6f72 4469 6374 0d0a 2020 2020 2020  nsorDict..      
-00003b50: 2020 2020 2020 7769 6c6c 2062 6520 7265        will be re
-00003b60: 7475 726e 6564 2061 7420 6561 6368 2069  turned at each i
-00003b70: 7465 7261 7469 6f6e 2c20 7769 7468 2069  teration, with i
-00003b80: 7473 2076 616c 7565 730d 0a20 2020 2020  ts values..     
-00003b90: 2020 2020 2020 2075 7064 6174 6564 2e20         updated. 
-00003ba0: 5468 6973 2066 6561 7475 7265 2073 686f  This feature sho
-00003bb0: 756c 6420 6265 2075 7365 6420 6361 7574  uld be used caut
-00003bc0: 696f 7573 6c79 3a20 6966 2074 6865 2073  iously: if the s
-00003bd0: 616d 650d 0a20 2020 2020 2020 2020 2020  ame..           
-00003be0: 2074 656e 736f 7264 6963 7420 6973 2061   tensordict is a
-00003bf0: 6464 6564 2074 6f20 6120 7265 706c 6179  dded to a replay
-00003c00: 2062 7566 6665 7220 666f 7220 696e 7374   buffer for inst
-00003c10: 616e 6365 2c0d 0a20 2020 2020 2020 2020  ance,..         
-00003c20: 2020 2074 6865 2077 686f 6c65 2063 6f6e     the whole con
-00003c30: 7465 6e74 206f 6620 7468 6520 6275 6666  tent of the buff
-00003c40: 6572 2077 696c 6c20 6265 2069 6465 6e74  er will be ident
-00003c50: 6963 616c 2e0d 0a20 2020 2020 2020 2020  ical...         
-00003c60: 2020 2044 6566 6175 6c74 2069 7320 6060     Default is ``
-00003c70: 4661 6c73 6560 602e 0d0a 2020 2020 2020  False``...      
-00003c80: 2020 7265 7365 745f 7768 656e 5f64 6f6e    reset_when_don
-00003c90: 6520 2862 6f6f 6c2c 206f 7074 696f 6e61  e (bool, optiona
-00003ca0: 6c29 3a20 6966 2060 6054 7275 6560 6020  l): if ``True`` 
-00003cb0: 2864 6566 6175 6c74 292c 2061 6e20 656e  (default), an en
-00003cc0: 7669 726f 6e6d 656e 740d 0a20 2020 2020  vironment..     
-00003cd0: 2020 2020 2020 2074 6861 7420 7265 7475         that retu
-00003ce0: 726e 2061 2060 6054 7275 6560 6020 7661  rn a ``True`` va
-00003cf0: 6c75 6520 696e 2069 7473 2060 6022 646f  lue in its ``"do
-00003d00: 6e65 2260 6020 6f72 2060 6022 7472 756e  ne"`` or ``"trun
-00003d10: 6361 7465 6422 6060 0d0a 2020 2020 2020  cated"``..      
-00003d20: 2020 2020 2020 656e 7472 7920 7769 6c6c        entry will
-00003d30: 2062 6520 7265 7365 7420 6174 2074 6865   be reset at the
-00003d40: 2063 6f72 7265 7370 6f6e 6469 6e67 2069   corresponding i
-00003d50: 6e64 6963 6573 2e0d 0a0d 0a20 2020 2045  ndices.....    E
-00003d60: 7861 6d70 6c65 733a 0d0a 2020 2020 2020  xamples:..      
-00003d70: 2020 3e3e 3e20 6672 6f6d 2074 6f72 6368    >>> from torch
-00003d80: 726c 2e65 6e76 732e 6c69 6273 2e67 796d  rl.envs.libs.gym
-00003d90: 2069 6d70 6f72 7420 4779 6d45 6e76 0d0a   import GymEnv..
-00003da0: 2020 2020 2020 2020 3e3e 3e20 6672 6f6d          >>> from
-00003db0: 2074 656e 736f 7264 6963 742e 6e6e 2069   tensordict.nn i
-00003dc0: 6d70 6f72 7420 5465 6e73 6f72 4469 6374  mport TensorDict
-00003dd0: 4d6f 6475 6c65 0d0a 2020 2020 2020 2020  Module..        
-00003de0: 3e3e 3e20 6672 6f6d 2074 6f72 6368 2069  >>> from torch i
-00003df0: 6d70 6f72 7420 6e6e 0d0a 2020 2020 2020  mport nn..      
-00003e00: 2020 3e3e 3e20 656e 765f 6d61 6b65 7220    >>> env_maker 
-00003e10: 3d20 6c61 6d62 6461 3a20 4779 6d45 6e76  = lambda: GymEnv
-00003e20: 2822 5065 6e64 756c 756d 2d76 3122 2c20  ("Pendulum-v1", 
-00003e30: 6465 7669 6365 3d22 6370 7522 290d 0a20  device="cpu").. 
-00003e40: 2020 2020 2020 203e 3e3e 2070 6f6c 6963         >>> polic
-00003e50: 7920 3d20 5465 6e73 6f72 4469 6374 4d6f  y = TensorDictMo
-00003e60: 6475 6c65 286e 6e2e 4c69 6e65 6172 2833  dule(nn.Linear(3
-00003e70: 2c20 3129 2c20 696e 5f6b 6579 733d 5b22  , 1), in_keys=["
-00003e80: 6f62 7365 7276 6174 696f 6e22 5d2c 206f  observation"], o
-00003e90: 7574 5f6b 6579 733d 5b22 6163 7469 6f6e  ut_keys=["action
-00003ea0: 225d 290d 0a20 2020 2020 2020 203e 3e3e  "])..        >>>
-00003eb0: 2063 6f6c 6c65 6374 6f72 203d 2053 796e   collector = Syn
-00003ec0: 6344 6174 6143 6f6c 6c65 6374 6f72 280d  cDataCollector(.
-00003ed0: 0a20 2020 2020 2020 202e 2e2e 2020 2020  .        ...    
-00003ee0: 2063 7265 6174 655f 656e 765f 666e 3d65   create_env_fn=e
-00003ef0: 6e76 5f6d 616b 6572 2c0d 0a20 2020 2020  nv_maker,..     
-00003f00: 2020 202e 2e2e 2020 2020 2070 6f6c 6963     ...     polic
-00003f10: 793d 706f 6c69 6379 2c0d 0a20 2020 2020  y=policy,..     
-00003f20: 2020 202e 2e2e 2020 2020 2074 6f74 616c     ...     total
-00003f30: 5f66 7261 6d65 733d 3230 3030 2c0d 0a20  _frames=2000,.. 
-00003f40: 2020 2020 2020 202e 2e2e 2020 2020 206d         ...     m
-00003f50: 6178 5f66 7261 6d65 735f 7065 725f 7472  ax_frames_per_tr
-00003f60: 616a 3d35 302c 0d0a 2020 2020 2020 2020  aj=50,..        
-00003f70: 2e2e 2e20 2020 2020 6672 616d 6573 5f70  ...     frames_p
-00003f80: 6572 5f62 6174 6368 3d32 3030 2c0d 0a20  er_batch=200,.. 
-00003f90: 2020 2020 2020 202e 2e2e 2020 2020 2069         ...     i
-00003fa0: 6e69 745f 7261 6e64 6f6d 5f66 7261 6d65  nit_random_frame
-00003fb0: 733d 2d31 2c0d 0a20 2020 2020 2020 202e  s=-1,..        .
-00003fc0: 2e2e 2020 2020 2072 6573 6574 5f61 745f  ..     reset_at_
-00003fd0: 6561 6368 5f69 7465 723d 4661 6c73 652c  each_iter=False,
-00003fe0: 0d0a 2020 2020 2020 2020 2e2e 2e20 2020  ..        ...   
-00003ff0: 2020 6465 7669 6365 3d22 6370 7522 2c0d    device="cpu",.
-00004000: 0a20 2020 2020 2020 202e 2e2e 2020 2020  .        ...    
-00004010: 2073 746f 7269 6e67 5f64 6576 6963 653d   storing_device=
-00004020: 2263 7075 222c 0d0a 2020 2020 2020 2020  "cpu",..        
-00004030: 2e2e 2e20 290d 0a20 2020 2020 2020 203e  ... )..        >
-00004040: 3e3e 2066 6f72 2069 2c20 6461 7461 2069  >> for i, data i
-00004050: 6e20 656e 756d 6572 6174 6528 636f 6c6c  n enumerate(coll
-00004060: 6563 746f 7229 3a0d 0a20 2020 2020 2020  ector):..       
-00004070: 202e 2e2e 2020 2020 2069 6620 6920 3d3d   ...     if i ==
-00004080: 2032 3a0d 0a20 2020 2020 2020 202e 2e2e   2:..        ...
-00004090: 2020 2020 2020 2020 2070 7269 6e74 2864           print(d
-000040a0: 6174 6129 0d0a 2020 2020 2020 2020 2e2e  ata)..        ..
-000040b0: 2e20 2020 2020 2020 2020 6272 6561 6b0d  .         break.
-000040c0: 0a20 2020 2020 2020 2054 656e 736f 7244  .        TensorD
-000040d0: 6963 7428 0d0a 2020 2020 2020 2020 2020  ict(..          
-000040e0: 2020 6669 656c 6473 3d7b 0d0a 2020 2020    fields={..    
-000040f0: 2020 2020 2020 2020 2020 2020 6163 7469              acti
-00004100: 6f6e 3a20 5465 6e73 6f72 2873 6861 7065  on: Tensor(shape
-00004110: 3d74 6f72 6368 2e53 697a 6528 5b34 2c20  =torch.Size([4, 
-00004120: 3530 2c20 315d 292c 2064 6576 6963 653d  50, 1]), device=
-00004130: 6370 752c 2064 7479 7065 3d74 6f72 6368  cpu, dtype=torch
-00004140: 2e66 6c6f 6174 3332 2c20 6973 5f73 6861  .float32, is_sha
-00004150: 7265 643d 4661 6c73 6529 2c0d 0a20 2020  red=False),..   
-00004160: 2020 2020 2020 2020 2020 2020 2063 6f6c               col
-00004170: 6c65 6374 6f72 3a20 5465 6e73 6f72 4469  lector: TensorDi
-00004180: 6374 280d 0a20 2020 2020 2020 2020 2020  ct(..           
-00004190: 2020 2020 2020 2020 2066 6965 6c64 733d           fields=
-000041a0: 7b0d 0a20 2020 2020 2020 2020 2020 2020  {..             
-000041b0: 2020 2020 2020 2020 2020 2073 7465 705f             step_
-000041c0: 636f 756e 743a 2054 656e 736f 7228 7368  count: Tensor(sh
-000041d0: 6170 653d 746f 7263 682e 5369 7a65 285b  ape=torch.Size([
-000041e0: 342c 2035 305d 292c 2064 6576 6963 653d  4, 50]), device=
-000041f0: 6370 752c 2064 7479 7065 3d74 6f72 6368  cpu, dtype=torch
-00004200: 2e69 6e74 3634 2c20 6973 5f73 6861 7265  .int64, is_share
-00004210: 643d 4661 6c73 6529 2c0d 0a20 2020 2020  d=False),..     
-00004220: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004230: 2020 2022 7472 616a 5f69 6473 3a20 5465     "traj_ids: Te
-00004240: 6e73 6f72 2873 6861 7065 3d74 6f72 6368  nsor(shape=torch
-00004250: 2e53 697a 6528 5b34 2c20 3530 5d29 2c20  .Size([4, 50]), 
-00004260: 6465 7669 6365 3d63 7075 2c20 6474 7970  device=cpu, dtyp
-00004270: 653d 746f 7263 682e 696e 7436 342c 2069  e=torch.int64, i
-00004280: 735f 7368 6172 6564 3d46 616c 7365 297d  s_shared=False)}
-00004290: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
-000042a0: 2020 2020 2020 2062 6174 6368 5f73 697a         batch_siz
-000042b0: 653d 746f 7263 682e 5369 7a65 285b 342c  e=torch.Size([4,
-000042c0: 2035 305d 292c 0d0a 2020 2020 2020 2020   50]),..        
-000042d0: 2020 2020 2020 2020 2020 2020 6465 7669              devi
-000042e0: 6365 3d63 7075 2c0d 0a20 2020 2020 2020  ce=cpu,..       
-000042f0: 2020 2020 2020 2020 2020 2020 2069 735f               is_
-00004300: 7368 6172 6564 3d46 616c 7365 292c 0d0a  shared=False),..
-00004310: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004320: 646f 6e65 3a20 5465 6e73 6f72 2873 6861  done: Tensor(sha
-00004330: 7065 3d74 6f72 6368 2e53 697a 6528 5b34  pe=torch.Size([4
-00004340: 2c20 3530 2c20 315d 292c 2064 6576 6963  , 50, 1]), devic
-00004350: 653d 6370 752c 2064 7479 7065 3d74 6f72  e=cpu, dtype=tor
-00004360: 6368 2e62 6f6f 6c2c 2069 735f 7368 6172  ch.bool, is_shar
-00004370: 6564 3d46 616c 7365 292c 0d0a 2020 2020  ed=False),..    
-00004380: 2020 2020 2020 2020 2020 2020 6d61 736b              mask
-00004390: 3a20 5465 6e73 6f72 2873 6861 7065 3d74  : Tensor(shape=t
-000043a0: 6f72 6368 2e53 697a 6528 5b34 2c20 3530  orch.Size([4, 50
-000043b0: 5d29 2c20 6465 7669 6365 3d63 7075 2c20  ]), device=cpu, 
-000043c0: 6474 7970 653d 746f 7263 682e 626f 6f6c  dtype=torch.bool
-000043d0: 2c20 6973 5f73 6861 7265 643d 4661 6c73  , is_shared=Fals
-000043e0: 6529 2c0d 0a20 2020 2020 2020 2020 2020  e),..           
-000043f0: 2020 2020 206e 6578 743a 2054 656e 736f       next: Tenso
-00004400: 7244 6963 7428 0d0a 2020 2020 2020 2020  rDict(..        
-00004410: 2020 2020 2020 2020 2020 2020 6669 656c              fiel
-00004420: 6473 3d7b 0d0a 2020 2020 2020 2020 2020  ds={..          
-00004430: 2020 2020 2020 2020 2020 2020 2020 6f62                ob
-00004440: 7365 7276 6174 696f 6e3a 2054 656e 736f  servation: Tenso
-00004450: 7228 7368 6170 653d 746f 7263 682e 5369  r(shape=torch.Si
-00004460: 7a65 285b 342c 2035 302c 2033 5d29 2c20  ze([4, 50, 3]), 
-00004470: 6465 7669 6365 3d63 7075 2c20 6474 7970  device=cpu, dtyp
-00004480: 653d 746f 7263 682e 666c 6f61 7433 322c  e=torch.float32,
-00004490: 2069 735f 7368 6172 6564 3d46 616c 7365   is_shared=False
-000044a0: 297d 2c0d 0a20 2020 2020 2020 2020 2020  )},..           
-000044b0: 2020 2020 2020 2020 2062 6174 6368 5f73           batch_s
-000044c0: 697a 653d 746f 7263 682e 5369 7a65 285b  ize=torch.Size([
-000044d0: 342c 2035 305d 292c 0d0a 2020 2020 2020  4, 50]),..      
-000044e0: 2020 2020 2020 2020 2020 2020 2020 6465                de
-000044f0: 7669 6365 3d63 7075 2c0d 0a20 2020 2020  vice=cpu,..     
-00004500: 2020 2020 2020 2020 2020 2020 2020 2069                 i
-00004510: 735f 7368 6172 6564 3d46 616c 7365 292c  s_shared=False),
-00004520: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00004530: 2020 6f62 7365 7276 6174 696f 6e3a 2054    observation: T
-00004540: 656e 736f 7228 7368 6170 653d 746f 7263  ensor(shape=torc
-00004550: 682e 5369 7a65 285b 342c 2035 302c 2033  h.Size([4, 50, 3
-00004560: 5d29 2c20 6465 7669 6365 3d63 7075 2c20  ]), device=cpu, 
-00004570: 6474 7970 653d 746f 7263 682e 666c 6f61  dtype=torch.floa
-00004580: 7433 322c 2069 735f 7368 6172 6564 3d46  t32, is_shared=F
-00004590: 616c 7365 292c 0d0a 2020 2020 2020 2020  alse),..        
-000045a0: 2020 2020 2020 2020 7265 7761 7264 3a20          reward: 
-000045b0: 5465 6e73 6f72 2873 6861 7065 3d74 6f72  Tensor(shape=tor
-000045c0: 6368 2e53 697a 6528 5b34 2c20 3530 2c20  ch.Size([4, 50, 
-000045d0: 315d 292c 2064 6576 6963 653d 6370 752c  1]), device=cpu,
-000045e0: 2064 7479 7065 3d74 6f72 6368 2e66 6c6f   dtype=torch.flo
-000045f0: 6174 3332 2c20 6973 5f73 6861 7265 643d  at32, is_shared=
-00004600: 4661 6c73 6529 7d2c 0d0a 2020 2020 2020  False)},..      
-00004610: 2020 2020 2020 6261 7463 685f 7369 7a65        batch_size
-00004620: 3d74 6f72 6368 2e53 697a 6528 5b34 2c20  =torch.Size([4, 
-00004630: 3530 5d29 2c0d 0a20 2020 2020 2020 2020  50]),..         
-00004640: 2020 2064 6576 6963 653d 6370 752c 0d0a     device=cpu,..
-00004650: 2020 2020 2020 2020 2020 2020 6973 5f73              is_s
-00004660: 6861 7265 643d 4661 6c73 6529 0d0a 2020  hared=False)..  
-00004670: 2020 2020 2020 3e3e 3e20 6465 6c20 636f        >>> del co
-00004680: 6c6c 6563 746f 720d 0a0d 0a20 2020 2022  llector....    "
-00004690: 2222 0d0a 0d0a 2020 2020 6465 6620 5f5f  ""....    def __
-000046a0: 696e 6974 5f5f 280d 0a20 2020 2020 2020  init__(..       
-000046b0: 2073 656c 662c 0d0a 2020 2020 2020 2020   self,..        
-000046c0: 6372 6561 7465 5f65 6e76 5f66 6e3a 2055  create_env_fn: U
-000046d0: 6e69 6f6e 5b0d 0a20 2020 2020 2020 2020  nion[..         
-000046e0: 2020 2045 6e76 4261 7365 2c20 2245 6e76     EnvBase, "Env
-000046f0: 4372 6561 746f 7222 2c20 5365 7175 656e  Creator", Sequen
-00004700: 6365 5b43 616c 6c61 626c 655b 5b5d 2c20  ce[Callable[[], 
-00004710: 456e 7642 6173 655d 5d20 2023 206e 6f71  EnvBase]]  # noq
-00004720: 613a 2046 3832 310d 0a20 2020 2020 2020  a: F821..       
-00004730: 205d 2c20 2023 206e 6f71 613a 2046 3832   ],  # noqa: F82
-00004740: 310d 0a20 2020 2020 2020 2070 6f6c 6963  1..        polic
-00004750: 793a 204f 7074 696f 6e61 6c5b 0d0a 2020  y: Optional[..  
-00004760: 2020 2020 2020 2020 2020 556e 696f 6e5b            Union[
-00004770: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00004780: 2020 5465 6e73 6f72 4469 6374 4d6f 6475    TensorDictModu
-00004790: 6c65 2c0d 0a20 2020 2020 2020 2020 2020  le,..           
-000047a0: 2020 2020 2043 616c 6c61 626c 655b 5b54       Callable[[T
-000047b0: 656e 736f 7244 6963 7442 6173 655d 2c20  ensorDictBase], 
-000047c0: 5465 6e73 6f72 4469 6374 4261 7365 5d2c  TensorDictBase],
-000047d0: 0d0a 2020 2020 2020 2020 2020 2020 5d0d  ..            ].
-000047e0: 0a20 2020 2020 2020 205d 2c0d 0a20 2020  .        ],..   
-000047f0: 2020 2020 202a 2c0d 0a20 2020 2020 2020       *,..       
-00004800: 2066 7261 6d65 735f 7065 725f 6261 7463   frames_per_batc
-00004810: 683a 2069 6e74 2c0d 0a20 2020 2020 2020  h: int,..       
-00004820: 2074 6f74 616c 5f66 7261 6d65 733a 2069   total_frames: i
-00004830: 6e74 2c0d 0a20 2020 2020 2020 2064 6576  nt,..        dev
-00004840: 6963 653a 2044 4556 4943 455f 5459 5049  ice: DEVICE_TYPI
-00004850: 4e47 203d 204e 6f6e 652c 0d0a 2020 2020  NG = None,..    
-00004860: 2020 2020 7374 6f72 696e 675f 6465 7669      storing_devi
-00004870: 6365 3a20 4445 5649 4345 5f54 5950 494e  ce: DEVICE_TYPIN
-00004880: 4720 3d20 4e6f 6e65 2c0d 0a20 2020 2020  G = None,..     
-00004890: 2020 2063 7265 6174 655f 656e 765f 6b77     create_env_kw
-000048a0: 6172 6773 3a20 4f70 7469 6f6e 616c 5b64  args: Optional[d
-000048b0: 6963 745d 203d 204e 6f6e 652c 0d0a 2020  ict] = None,..  
-000048c0: 2020 2020 2020 6d61 785f 6672 616d 6573        max_frames
-000048d0: 5f70 6572 5f74 7261 6a3a 2069 6e74 203d  _per_traj: int =
-000048e0: 202d 312c 0d0a 2020 2020 2020 2020 696e   -1,..        in
-000048f0: 6974 5f72 616e 646f 6d5f 6672 616d 6573  it_random_frames
-00004900: 3a20 696e 7420 3d20 2d31 2c0d 0a20 2020  : int = -1,..   
-00004910: 2020 2020 2072 6573 6574 5f61 745f 6561       reset_at_ea
-00004920: 6368 5f69 7465 723a 2062 6f6f 6c20 3d20  ch_iter: bool = 
-00004930: 4661 6c73 652c 0d0a 2020 2020 2020 2020  False,..        
-00004940: 706f 7374 7072 6f63 3a20 4f70 7469 6f6e  postproc: Option
-00004950: 616c 5b43 616c 6c61 626c 655b 5b54 656e  al[Callable[[Ten
-00004960: 736f 7244 6963 7442 6173 655d 2c20 5465  sorDictBase], Te
-00004970: 6e73 6f72 4469 6374 4261 7365 5d5d 203d  nsorDictBase]] =
-00004980: 204e 6f6e 652c 0d0a 2020 2020 2020 2020   None,..        
-00004990: 7370 6c69 745f 7472 616a 733a 204f 7074  split_trajs: Opt
-000049a0: 696f 6e61 6c5b 626f 6f6c 5d20 3d20 4e6f  ional[bool] = No
-000049b0: 6e65 2c0d 0a20 2020 2020 2020 2065 7870  ne,..        exp
-000049c0: 6c6f 7261 7469 6f6e 5f6d 6f64 653a 2073  loration_mode: s
-000049d0: 7472 203d 2044 4546 4155 4c54 5f45 5850  tr = DEFAULT_EXP
-000049e0: 4c4f 5241 5449 4f4e 5f4d 4f44 452c 0d0a  LORATION_MODE,..
-000049f0: 2020 2020 2020 2020 7265 7475 726e 5f73          return_s
-00004a00: 616d 655f 7464 3a20 626f 6f6c 203d 2046  ame_td: bool = F
-00004a10: 616c 7365 2c0d 0a20 2020 2020 2020 2072  alse,..        r
-00004a20: 6573 6574 5f77 6865 6e5f 646f 6e65 3a20  eset_when_done: 
-00004a30: 626f 6f6c 203d 2054 7275 652c 0d0a 2020  bool = True,..  
-00004a40: 2020 293a 0d0a 2020 2020 2020 2020 7365    ):..        se
-00004a50: 6c66 2e63 6c6f 7365 6420 3d20 5472 7565  lf.closed = True
-00004a60: 0d0a 0d0a 2020 2020 2020 2020 6966 2063  ....        if c
-00004a70: 7265 6174 655f 656e 765f 6b77 6172 6773  reate_env_kwargs
-00004a80: 2069 7320 4e6f 6e65 3a0d 0a20 2020 2020   is None:..     
-00004a90: 2020 2020 2020 2063 7265 6174 655f 656e         create_en
-00004aa0: 765f 6b77 6172 6773 203d 207b 7d0d 0a20  v_kwargs = {}.. 
-00004ab0: 2020 2020 2020 2069 6620 6e6f 7420 6973         if not is
-00004ac0: 696e 7374 616e 6365 2863 7265 6174 655f  instance(create_
-00004ad0: 656e 765f 666e 2c20 456e 7642 6173 6529  env_fn, EnvBase)
-00004ae0: 3a0d 0a20 2020 2020 2020 2020 2020 2065  :..            e
-00004af0: 6e76 203d 2063 7265 6174 655f 656e 765f  nv = create_env_
-00004b00: 666e 282a 2a63 7265 6174 655f 656e 765f  fn(**create_env_
-00004b10: 6b77 6172 6773 290d 0a20 2020 2020 2020  kwargs)..       
-00004b20: 2065 6c73 653a 0d0a 2020 2020 2020 2020   else:..        
-00004b30: 2020 2020 656e 7620 3d20 6372 6561 7465      env = create
-00004b40: 5f65 6e76 5f66 6e0d 0a20 2020 2020 2020  _env_fn..       
-00004b50: 2020 2020 2069 6620 6372 6561 7465 5f65       if create_e
-00004b60: 6e76 5f6b 7761 7267 733a 0d0a 2020 2020  nv_kwargs:..    
-00004b70: 2020 2020 2020 2020 2020 2020 6966 206e              if n
-00004b80: 6f74 2069 7369 6e73 7461 6e63 6528 656e  ot isinstance(en
-00004b90: 762c 205f 4261 7463 6865 6445 6e76 293a  v, _BatchedEnv):
-00004ba0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00004bb0: 2020 2020 2020 7261 6973 6520 5275 6e74        raise Runt
-00004bc0: 696d 6545 7272 6f72 280d 0a20 2020 2020  imeError(..     
-00004bd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004be0: 2020 2022 6b77 6172 6773 2077 6572 6520     "kwargs were 
-00004bf0: 7061 7373 6564 2074 6f20 5379 6e63 4461  passed to SyncDa
-00004c00: 7461 436f 6c6c 6563 746f 7220 6275 7420  taCollector but 
-00004c10: 7468 6579 2063 616e 2774 2062 6520 7365  they can't be se
-00004c20: 7420 220d 0a20 2020 2020 2020 2020 2020  t "..           
-00004c30: 2020 2020 2020 2020 2020 2020 2066 226f               f"o
-00004c40: 6e20 656e 7669 726f 6e6d 656e 7420 6f66  n environment of
-00004c50: 2074 7970 6520 7b74 7970 6528 6372 6561   type {type(crea
-00004c60: 7465 5f65 6e76 5f66 6e29 7d2e 220d 0a20  te_env_fn)}.".. 
+000004a0: 6e76 732e 636f 6d6d 6f6e 2069 6d70 6f72  nvs.common impor
+000004b0: 7420 456e 7642 6173 650d 0a66 726f 6d20  t EnvBase..from 
+000004c0: 746f 7263 6872 6c2e 656e 7673 2e74 7261  torchrl.envs.tra
+000004d0: 6e73 666f 726d 7320 696d 706f 7274 2053  nsforms import S
+000004e0: 7465 7043 6f75 6e74 6572 2c20 5472 616e  tepCounter, Tran
+000004f0: 7366 6f72 6d65 6445 6e76 0d0a 6672 6f6d  sformedEnv..from
+00000500: 2074 6f72 6368 726c 2e65 6e76 732e 7574   torchrl.envs.ut
+00000510: 696c 7320 696d 706f 7274 2028 0d0a 2020  ils import (..  
+00000520: 2020 5f63 6f6e 7665 7274 5f65 7870 6c6f    _convert_explo
+00000530: 7261 7469 6f6e 5f74 7970 652c 0d0a 2020  ration_type,..  
+00000540: 2020 4578 706c 6f72 6174 696f 6e54 7970    ExplorationTyp
+00000550: 652c 0d0a 2020 2020 7365 745f 6578 706c  e,..    set_expl
+00000560: 6f72 6174 696f 6e5f 7479 7065 2c0d 0a20  oration_type,.. 
+00000570: 2020 2073 7465 705f 6d64 702c 0d0a 290d     step_mdp,..).
+00000580: 0a66 726f 6d20 746f 7263 6872 6c2e 656e  .from torchrl.en
+00000590: 7673 2e76 6563 5f65 6e76 2069 6d70 6f72  vs.vec_env impor
+000005a0: 7420 5f42 6174 6368 6564 456e 760d 0a0d  t _BatchedEnv...
+000005b0: 0a5f 5449 4d45 4f55 5420 3d20 312e 300d  ._TIMEOUT = 1.0.
+000005c0: 0a5f 4d49 4e5f 5449 4d45 4f55 5420 3d20  ._MIN_TIMEOUT = 
+000005d0: 3165 2d33 2020 2320 7368 6f75 6c64 2062  1e-3  # should b
+000005e0: 6520 7365 7665 7261 6c20 6f72 6465 7273  e several orders
+000005f0: 206f 6620 6d61 676e 6974 7564 6520 696e   of magnitude in
+00000600: 6665 7269 6f72 2077 7274 2074 696d 6520  ferior wrt time 
+00000610: 7370 656e 7420 636f 6c6c 6563 7469 6e67  spent collecting
+00000620: 2061 2074 7261 6a65 6374 6f72 790d 0a5f   a trajectory.._
+00000630: 4d41 585f 4944 4c45 5f43 4f55 4e54 203d  MAX_IDLE_COUNT =
+00000640: 2069 6e74 286f 732e 656e 7669 726f 6e2e   int(os.environ.
+00000650: 6765 7428 224d 4158 5f49 444c 455f 434f  get("MAX_IDLE_CO
+00000660: 554e 5422 2c20 3130 3030 2929 0d0a 0d0a  UNT", 1000))....
+00000670: 4445 4641 554c 545f 4558 504c 4f52 4154  DEFAULT_EXPLORAT
+00000680: 494f 4e5f 5459 5045 3a20 4578 706c 6f72  ION_TYPE: Explor
+00000690: 6174 696f 6e54 7970 6520 3d20 4578 706c  ationType = Expl
+000006a0: 6f72 6174 696f 6e54 7970 652e 5241 4e44  orationType.RAND
+000006b0: 4f4d 0d0a 0d0a 5f69 735f 6f73 7820 3d20  OM...._is_osx = 
+000006c0: 7379 732e 706c 6174 666f 726d 2e73 7461  sys.platform.sta
+000006d0: 7274 7377 6974 6828 2264 6172 7769 6e22  rtswith("darwin"
+000006e0: 290d 0a0d 0a0d 0a63 6c61 7373 2052 616e  )......class Ran
+000006f0: 646f 6d50 6f6c 6963 793a 0d0a 2020 2020  domPolicy:..    
+00000700: 2222 2241 2072 616e 646f 6d20 706f 6c69  """A random poli
+00000710: 6379 2066 6f72 2064 6174 6120 636f 6c6c  cy for data coll
+00000720: 6563 746f 7273 2e0d 0a0d 0a20 2020 2054  ectors.....    T
+00000730: 6869 7320 6973 2061 2077 7261 7070 6572  his is a wrapper
+00000740: 2061 726f 756e 6420 7468 6520 6163 7469   around the acti
+00000750: 6f6e 5f73 7065 632e 7261 6e64 206d 6574  on_spec.rand met
+00000760: 686f 642e 0d0a 0d0a 2020 2020 4172 6773  hod.....    Args
+00000770: 3a0d 0a20 2020 2020 2020 2061 6374 696f  :..        actio
+00000780: 6e5f 7370 6563 3a20 5465 6e73 6f72 5370  n_spec: TensorSp
+00000790: 6563 206f 626a 6563 7420 6465 7363 7269  ec object descri
+000007a0: 6269 6e67 2074 6865 2061 6374 696f 6e20  bing the action 
+000007b0: 7370 6563 730d 0a0d 0a20 2020 2045 7861  specs....    Exa
+000007c0: 6d70 6c65 733a 0d0a 2020 2020 2020 2020  mples:..        
+000007d0: 3e3e 3e20 6672 6f6d 2074 656e 736f 7264  >>> from tensord
+000007e0: 6963 7420 696d 706f 7274 2054 656e 736f  ict import Tenso
+000007f0: 7244 6963 740d 0a20 2020 2020 2020 203e  rDict..        >
+00000800: 3e3e 2066 726f 6d20 746f 7263 6872 6c2e  >> from torchrl.
+00000810: 6461 7461 2e74 656e 736f 725f 7370 6563  data.tensor_spec
+00000820: 7320 696d 706f 7274 2042 6f75 6e64 6564  s import Bounded
+00000830: 5465 6e73 6f72 5370 6563 0d0a 2020 2020  TensorSpec..    
+00000840: 2020 2020 3e3e 3e20 6163 7469 6f6e 5f73      >>> action_s
+00000850: 7065 6320 3d20 426f 756e 6465 6454 656e  pec = BoundedTen
+00000860: 736f 7253 7065 6328 2d74 6f72 6368 2e6f  sorSpec(-torch.o
+00000870: 6e65 7328 3329 2c20 746f 7263 682e 6f6e  nes(3), torch.on
+00000880: 6573 2833 2929 0d0a 2020 2020 2020 2020  es(3))..        
+00000890: 3e3e 3e20 6163 746f 7220 3d20 5261 6e64  >>> actor = Rand
+000008a0: 6f6d 506f 6c69 6379 2873 7065 633d 6163  omPolicy(spec=ac
+000008b0: 7469 6f6e 5f73 7065 6329 0d0a 2020 2020  tion_spec)..    
+000008c0: 2020 2020 3e3e 3e20 7464 203d 2061 6374      >>> td = act
+000008d0: 6f72 2854 656e 736f 7244 6963 7428 6261  or(TensorDict(ba
+000008e0: 7463 685f 7369 7a65 3d5b 5d29 2920 2320  tch_size=[])) # 
+000008f0: 7365 6c65 6374 7320 6120 7261 6e64 6f6d  selects a random
+00000900: 2061 6374 696f 6e20 696e 2074 6865 2063   action in the c
+00000910: 7562 6520 5b2d 313b 2031 5d0d 0a20 2020  ube [-1; 1]..   
+00000920: 2022 2222 0d0a 0d0a 2020 2020 6465 6620   """....    def 
+00000930: 5f5f 696e 6974 5f5f 2873 656c 662c 2061  __init__(self, a
+00000940: 6374 696f 6e5f 7370 6563 3a20 5465 6e73  ction_spec: Tens
+00000950: 6f72 5370 6563 293a 0d0a 2020 2020 2020  orSpec):..      
+00000960: 2020 7365 6c66 2e61 6374 696f 6e5f 7370    self.action_sp
+00000970: 6563 203d 2061 6374 696f 6e5f 7370 6563  ec = action_spec
+00000980: 0d0a 0d0a 2020 2020 6465 6620 5f5f 6361  ....    def __ca
+00000990: 6c6c 5f5f 2873 656c 662c 2074 643a 2054  ll__(self, td: T
+000009a0: 656e 736f 7244 6963 7442 6173 6529 202d  ensorDictBase) -
+000009b0: 3e20 5465 6e73 6f72 4469 6374 4261 7365  > TensorDictBase
+000009c0: 3a0d 0a20 2020 2020 2020 2072 6574 7572  :..        retur
+000009d0: 6e20 7464 2e73 6574 2822 6163 7469 6f6e  n td.set("action
+000009e0: 222c 2073 656c 662e 6163 7469 6f6e 5f73  ", self.action_s
+000009f0: 7065 632e 7261 6e64 2829 290d 0a0d 0a0d  pec.rand()).....
+00000a00: 0a63 6c61 7373 205f 496e 7465 7272 7570  .class _Interrup
+00000a10: 746f 723a 0d0a 2020 2020 2222 2241 2063  tor:..    """A c
+00000a20: 6c61 7373 2066 6f72 206d 616e 6167 696e  lass for managin
+00000a30: 6720 7468 6520 636f 6c6c 6563 7469 6f6e  g the collection
+00000a40: 2073 7461 7465 206f 6620 6120 7072 6f63   state of a proc
+00000a50: 6573 732e 0d0a 0d0a 2020 2020 5468 6973  ess.....    This
+00000a60: 2063 6c61 7373 2070 726f 7669 6465 7320   class provides 
+00000a70: 6d65 7468 6f64 7320 746f 2073 7461 7274  methods to start
+00000a80: 2061 6e64 2073 746f 7020 636f 6c6c 6563   and stop collec
+00000a90: 7469 6f6e 2c20 616e 6420 746f 2063 6865  tion, and to che
+00000aa0: 636b 0d0a 2020 2020 7768 6574 6865 7220  ck..    whether 
+00000ab0: 636f 6c6c 6563 7469 6f6e 2068 6173 2062  collection has b
+00000ac0: 6565 6e20 7374 6f70 7065 642e 2054 6865  een stopped. The
+00000ad0: 2063 6f6c 6c65 6374 696f 6e20 7374 6174   collection stat
+00000ae0: 6520 6973 2070 726f 7465 6374 6564 0d0a  e is protected..
+00000af0: 2020 2020 6279 2061 206c 6f63 6b20 746f      by a lock to
+00000b00: 2065 6e73 7572 6520 7468 7265 6164 2d73   ensure thread-s
+00000b10: 6166 6574 792e 0d0a 2020 2020 2222 220d  afety...    """.
+00000b20: 0a0d 0a20 2020 2023 2069 6e74 6572 7275  ...    # interru
+00000b30: 7074 6572 2076 7320 696e 7465 7272 7570  pter vs interrup
+00000b40: 746f 723a 2067 6f6f 676c 6520 7472 656e  tor: google tren
+00000b50: 6473 2073 6565 6d73 2074 6f20 696e 6469  ds seems to indi
+00000b60: 6361 7465 2074 6861 7420 226f 7222 2069  cate that "or" i
+00000b70: 7320 6d6f 7265 0d0a 2020 2020 2320 7769  s more..    # wi
+00000b80: 6465 6c79 2075 7365 6420 7468 616e 2022  dely used than "
+00000b90: 6572 2220 6576 656e 2069 6620 6d79 2049  er" even if my I
+00000ba0: 4445 2063 6f6d 706c 6169 6e73 2061 626f  DE complains abo
+00000bb0: 7574 2074 6861 742e 2e2e 0d0a 2020 2020  ut that.....    
+00000bc0: 6465 6620 5f5f 696e 6974 5f5f 2873 656c  def __init__(sel
+00000bd0: 6629 3a0d 0a20 2020 2020 2020 2073 656c  f):..        sel
+00000be0: 662e 5f63 6f6c 6c65 6374 203d 2054 7275  f._collect = Tru
+00000bf0: 650d 0a20 2020 2020 2020 2073 656c 662e  e..        self.
+00000c00: 5f6c 6f63 6b20 3d20 6d70 2e4c 6f63 6b28  _lock = mp.Lock(
+00000c10: 290d 0a0d 0a20 2020 2064 6566 2073 7461  )....    def sta
+00000c20: 7274 5f63 6f6c 6c65 6374 696f 6e28 7365  rt_collection(se
+00000c30: 6c66 293a 0d0a 2020 2020 2020 2020 7769  lf):..        wi
+00000c40: 7468 2073 656c 662e 5f6c 6f63 6b3a 0d0a  th self._lock:..
+00000c50: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+00000c60: 2e5f 636f 6c6c 6563 7420 3d20 5472 7565  ._collect = True
+00000c70: 0d0a 0d0a 2020 2020 6465 6620 7374 6f70  ....    def stop
+00000c80: 5f63 6f6c 6c65 6374 696f 6e28 7365 6c66  _collection(self
+00000c90: 293a 0d0a 2020 2020 2020 2020 7769 7468  ):..        with
+00000ca0: 2073 656c 662e 5f6c 6f63 6b3a 0d0a 2020   self._lock:..  
+00000cb0: 2020 2020 2020 2020 2020 7365 6c66 2e5f            self._
+00000cc0: 636f 6c6c 6563 7420 3d20 4661 6c73 650d  collect = False.
+00000cd0: 0a0d 0a20 2020 2064 6566 2063 6f6c 6c65  ...    def colle
+00000ce0: 6374 696f 6e5f 7374 6f70 7065 6428 7365  ction_stopped(se
+00000cf0: 6c66 293a 0d0a 2020 2020 2020 2020 7769  lf):..        wi
+00000d00: 7468 2073 656c 662e 5f6c 6f63 6b3a 0d0a  th self._lock:..
+00000d10: 2020 2020 2020 2020 2020 2020 7265 7475              retu
+00000d20: 726e 2073 656c 662e 5f63 6f6c 6c65 6374  rn self._collect
+00000d30: 2069 7320 4661 6c73 650d 0a0d 0a0d 0a63   is False......c
+00000d40: 6c61 7373 205f 496e 7465 7272 7570 746f  lass _Interrupto
+00000d50: 724d 616e 6167 6572 2853 796e 634d 616e  rManager(SyncMan
+00000d60: 6167 6572 293a 0d0a 2020 2020 2222 2241  ager):..    """A
+00000d70: 2063 7573 746f 6d20 5379 6e63 4d61 6e61   custom SyncMana
+00000d80: 6765 7220 666f 7220 6d61 6e61 6769 6e67  ger for managing
+00000d90: 2074 6865 2063 6f6c 6c65 6374 696f 6e20   the collection 
+00000da0: 7374 6174 6520 6f66 2061 2070 726f 6365  state of a proce
+00000db0: 7373 2e0d 0a0d 0a20 2020 2054 6869 7320  ss.....    This 
+00000dc0: 636c 6173 7320 6578 7465 6e64 7320 7468  class extends th
+00000dd0: 6520 5379 6e63 4d61 6e61 6765 7220 636c  e SyncManager cl
+00000de0: 6173 7320 616e 6420 616c 6c6f 7773 2074  ass and allows t
+00000df0: 6f20 7368 6172 6520 616e 2049 6e74 6572  o share an Inter
+00000e00: 7275 7074 6f72 206f 626a 6563 740d 0a20  ruptor object.. 
+00000e10: 2020 2062 6574 7765 656e 2070 726f 6365     between proce
+00000e20: 7373 6573 2e0d 0a20 2020 2022 2222 0d0a  sses...    """..
+00000e30: 0d0a 2020 2020 7061 7373 0d0a 0d0a 0d0a  ..    pass......
+00000e40: 5f49 6e74 6572 7275 7074 6f72 4d61 6e61  _InterruptorMana
+00000e50: 6765 722e 7265 6769 7374 6572 2822 5f49  ger.register("_I
+00000e60: 6e74 6572 7275 7074 6f72 222c 205f 496e  nterruptor", _In
+00000e70: 7465 7272 7570 746f 7229 0d0a 0d0a 0d0a  terruptor)......
+00000e80: 6465 6620 7265 6375 7273 6976 655f 6d61  def recursive_ma
+00000e90: 705f 746f 5f63 7075 2864 6963 7469 6f6e  p_to_cpu(diction
+00000ea0: 6172 793a 204f 7264 6572 6564 4469 6374  ary: OrderedDict
+00000eb0: 2920 2d3e 204f 7264 6572 6564 4469 6374  ) -> OrderedDict
+00000ec0: 3a0d 0a20 2020 2022 2222 4d61 7073 2074  :..    """Maps t
+00000ed0: 6865 2074 656e 736f 7273 2074 6f20 4350  he tensors to CP
+00000ee0: 5520 7468 726f 7567 6820 6120 6e65 7374  U through a nest
+00000ef0: 6564 2064 6963 7469 6f6e 6172 792e 2222  ed dictionary.""
+00000f00: 220d 0a20 2020 2072 6574 7572 6e20 4f72  "..    return Or
+00000f10: 6465 7265 6444 6963 7428 0d0a 2020 2020  deredDict(..    
+00000f20: 2020 2020 2a2a 7b0d 0a20 2020 2020 2020      **{..       
+00000f30: 2020 2020 206b 3a20 7265 6375 7273 6976       k: recursiv
+00000f40: 655f 6d61 705f 746f 5f63 7075 2869 7465  e_map_to_cpu(ite
+00000f50: 6d29 0d0a 2020 2020 2020 2020 2020 2020  m)..            
+00000f60: 6966 2069 7369 6e73 7461 6e63 6528 6974  if isinstance(it
+00000f70: 656d 2c20 4f72 6465 7265 6444 6963 7429  em, OrderedDict)
+00000f80: 0d0a 2020 2020 2020 2020 2020 2020 656c  ..            el
+00000f90: 7365 2069 7465 6d2e 6370 7528 290d 0a20  se item.cpu().. 
+00000fa0: 2020 2020 2020 2020 2020 2069 6620 6973             if is
+00000fb0: 696e 7374 616e 6365 2869 7465 6d2c 2074  instance(item, t
+00000fc0: 6f72 6368 2e54 656e 736f 7229 0d0a 2020  orch.Tensor)..  
+00000fd0: 2020 2020 2020 2020 2020 656c 7365 2069            else i
+00000fe0: 7465 6d0d 0a20 2020 2020 2020 2020 2020  tem..           
+00000ff0: 2066 6f72 206b 2c20 6974 656d 2069 6e20   for k, item in 
+00001000: 6469 6374 696f 6e61 7279 2e69 7465 6d73  dictionary.items
+00001010: 2829 0d0a 2020 2020 2020 2020 7d0d 0a20  ()..        }.. 
+00001020: 2020 2029 0d0a 0d0a 0d0a 6465 6620 5f70     )......def _p
+00001030: 6f6c 6963 795f 6973 5f74 656e 736f 7264  olicy_is_tensord
+00001040: 6963 745f 636f 6d70 6174 6962 6c65 2870  ict_compatible(p
+00001050: 6f6c 6963 793a 206e 6e2e 4d6f 6475 6c65  olicy: nn.Module
+00001060: 293a 0d0a 2020 2020 7369 6720 3d20 696e  ):..    sig = in
+00001070: 7370 6563 742e 7369 676e 6174 7572 6528  spect.signature(
+00001080: 706f 6c69 6379 2e66 6f72 7761 7264 290d  policy.forward).
+00001090: 0a0d 0a20 2020 2069 6620 6973 696e 7374  ...    if isinst
+000010a0: 616e 6365 2870 6f6c 6963 792c 2054 656e  ance(policy, Ten
+000010b0: 736f 7244 6963 744d 6f64 756c 6542 6173  sorDictModuleBas
+000010c0: 6529 3a0d 0a20 2020 2020 2020 2072 6574  e):..        ret
+000010d0: 7572 6e20 5472 7565 0d0a 2020 2020 6966  urn True..    if
+000010e0: 2028 0d0a 2020 2020 2020 2020 6c65 6e28   (..        len(
+000010f0: 7369 672e 7061 7261 6d65 7465 7273 2920  sig.parameters) 
+00001100: 3d3d 2031 0d0a 2020 2020 2020 2020 616e  == 1..        an
+00001110: 6420 6861 7361 7474 7228 706f 6c69 6379  d hasattr(policy
+00001120: 2c20 2269 6e5f 6b65 7973 2229 0d0a 2020  , "in_keys")..  
+00001130: 2020 2020 2020 616e 6420 6861 7361 7474        and hasatt
+00001140: 7228 706f 6c69 6379 2c20 226f 7574 5f6b  r(policy, "out_k
+00001150: 6579 7322 290d 0a20 2020 2029 3a0d 0a20  eys")..    ):.. 
+00001160: 2020 2020 2020 2077 6172 6e69 6e67 732e         warnings.
+00001170: 7761 726e 280d 0a20 2020 2020 2020 2020  warn(..         
+00001180: 2020 2022 5061 7373 696e 6720 6120 706f     "Passing a po
+00001190: 6c69 6379 2074 6861 7420 6973 206e 6f74  licy that is not
+000011a0: 2061 2054 656e 736f 7244 6963 744d 6f64   a TensorDictMod
+000011b0: 756c 6542 6173 6520 7375 6263 6c61 7373  uleBase subclass
+000011c0: 2062 7574 2068 6173 2069 6e5f 6b65 7973   but has in_keys
+000011d0: 2061 6e64 206f 7574 5f6b 6579 7320 220d   and out_keys ".
+000011e0: 0a20 2020 2020 2020 2020 2020 2022 7769  .            "wi
+000011f0: 6c6c 2073 6f6f 6e20 6265 2064 6570 7265  ll soon be depre
+00001200: 6361 7465 642e 2057 6527 6420 6c69 6b65  cated. We'd like
+00001210: 2074 6f20 6d6f 7469 7661 7465 206f 7572   to motivate our
+00001220: 2075 7365 7273 2074 6f20 696e 6865 7269   users to inheri
+00001230: 7420 6672 6f6d 2074 6869 7320 636c 6173  t from this clas
+00001240: 7320 2877 6869 6368 2022 0d0a 2020 2020  s (which "..    
+00001250: 2020 2020 2020 2020 2268 6173 2076 6572          "has ver
+00001260: 7920 6665 7720 7265 7374 7269 6374 696f  y few restrictio
+00001270: 6e73 2920 746f 206d 616b 6520 7468 6520  ns) to make the 
+00001280: 6578 7065 7269 656e 6365 2073 6d6f 6f74  experience smoot
+00001290: 6865 722e 222c 0d0a 2020 2020 2020 2020  her.",..        
+000012a0: 2020 2020 6361 7465 676f 7279 3d44 6570      category=Dep
+000012b0: 7265 6361 7469 6f6e 5761 726e 696e 672c  recationWarning,
+000012c0: 0d0a 2020 2020 2020 2020 290d 0a20 2020  ..        )..   
+000012d0: 2020 2020 2023 2069 6620 7468 6520 706f       # if the po
+000012e0: 6c69 6379 2069 7320 6120 5465 6e73 6f72  licy is a Tensor
+000012f0: 4469 6374 4d6f 6475 6c65 206f 7220 7461  DictModule or ta
+00001300: 6b65 7320 6120 7369 6e67 6c65 2061 7267  kes a single arg
+00001310: 756d 656e 7420 616e 6420 6465 6669 6e65  ument and define
+00001320: 730d 0a20 2020 2020 2020 2023 2069 6e5f  s..        # in_
+00001330: 6b65 7973 2061 6e64 206f 7574 5f6b 6579  keys and out_key
+00001340: 7320 7468 656e 2077 6520 6173 7375 6d65  s then we assume
+00001350: 2069 7420 6361 6e20 616c 7265 6164 7920   it can already 
+00001360: 6465 616c 2077 6974 6820 5465 6e73 6f72  deal with Tensor
+00001370: 4469 6374 2069 6e70 7574 0d0a 2020 2020  Dict input..    
+00001380: 2020 2020 2320 746f 2066 6f72 7761 7264      # to forward
+00001390: 2061 6e64 2077 6520 7265 7475 726e 2054   and we return T
+000013a0: 7275 650d 0a20 2020 2020 2020 2072 6574  rue..        ret
+000013b0: 7572 6e20 5472 7565 0d0a 2020 2020 656c  urn True..    el
+000013c0: 6966 206e 6f74 2068 6173 6174 7472 2870  if not hasattr(p
+000013d0: 6f6c 6963 792c 2022 696e 5f6b 6579 7322  olicy, "in_keys"
+000013e0: 2920 616e 6420 6e6f 7420 6861 7361 7474  ) and not hasatt
+000013f0: 7228 706f 6c69 6379 2c20 226f 7574 5f6b  r(policy, "out_k
+00001400: 6579 7322 293a 0d0a 2020 2020 2020 2020  eys"):..        
+00001410: 2320 6966 2069 7427 7320 6e6f 7420 6120  # if it's not a 
+00001420: 5465 6e73 6f72 4469 6374 4d6f 6475 6c65  TensorDictModule
+00001430: 2c20 616e 6420 696e 5f6b 6579 7320 616e  , and in_keys an
+00001440: 6420 6f75 745f 6b65 7973 2061 7265 206e  d out_keys are n
+00001450: 6f74 2064 6566 696e 6564 2074 6865 6e0d  ot defined then.
+00001460: 0a20 2020 2020 2020 2023 2077 6520 6173  .        # we as
+00001470: 7375 6d65 206e 6f20 5465 6e73 6f72 4469  sume no TensorDi
+00001480: 6374 2063 6f6d 7061 7469 6269 6c69 7479  ct compatibility
+00001490: 2061 6e64 2077 696c 6c20 7472 7920 746f   and will try to
+000014a0: 2077 7261 7020 6974 2e0d 0a20 2020 2020   wrap it...     
+000014b0: 2020 2072 6574 7572 6e20 4661 6c73 650d     return False.
+000014c0: 0a0d 0a20 2020 2023 2069 6620 696e 5f6b  ...    # if in_k
+000014d0: 6579 7320 6f72 206f 7574 5f6b 6579 7320  eys or out_keys 
+000014e0: 7765 7265 2064 6566 696e 6564 2062 7574  were defined but
+000014f0: 2070 6f6c 6963 7920 6973 206e 6f74 2061   policy is not a
+00001500: 2054 656e 736f 7244 6963 744d 6f64 756c   TensorDictModul
+00001510: 6520 6f72 0d0a 2020 2020 2320 6163 6365  e or..    # acce
+00001520: 7074 7320 6d75 6c74 6970 6c65 2061 7267  pts multiple arg
+00001530: 756d 656e 7473 2074 6865 6e20 6974 2773  uments then it's
+00001540: 206c 696b 656c 7920 7468 6520 7573 6572   likely the user
+00001550: 2069 7320 7472 7969 6e67 2074 6f20 646f   is trying to do
+00001560: 2073 6f6d 6574 6869 6e67 0d0a 2020 2020   something..    
+00001570: 2320 7468 6174 2077 696c 6c20 6861 7665  # that will have
+00001580: 2075 6e64 6574 6572 6d69 6e65 6420 6265   undetermined be
+00001590: 6861 7669 6f75 722c 2077 6520 7261 6973  haviour, we rais
+000015a0: 6520 616e 2065 7272 6f72 0d0a 2020 2020  e an error..    
+000015b0: 7261 6973 6520 5479 7065 4572 726f 7228  raise TypeError(
+000015c0: 0d0a 2020 2020 2020 2020 2252 6563 6569  ..        "Recei
+000015d0: 7665 6420 6120 706f 6c69 6379 2074 6861  ved a policy tha
+000015e0: 7420 6465 6669 6e65 7320 696e 5f6b 6579  t defines in_key
+000015f0: 7320 6f72 206f 7574 5f6b 6579 7320 616e  s or out_keys an
+00001600: 6420 616c 736f 2065 7870 6563 7473 206d  d also expects m
+00001610: 756c 7469 706c 6520 220d 0a20 2020 2020  ultiple "..     
+00001620: 2020 2022 6172 6775 6d65 6e74 7320 746f     "arguments to
+00001630: 2070 6f6c 6963 792e 666f 7277 6172 642e   policy.forward.
+00001640: 2049 6620 7468 6520 706f 6c69 6379 2069   If the policy i
+00001650: 7320 636f 6d70 6174 6962 6c65 2077 6974  s compatible wit
+00001660: 6820 5465 6e73 6f72 4469 6374 2c20 6974  h TensorDict, it
+00001670: 2022 0d0a 2020 2020 2020 2020 2273 686f   "..        "sho
+00001680: 756c 6420 7461 6b65 2061 2073 696e 676c  uld take a singl
+00001690: 6520 6172 6775 6d65 6e74 206f 6620 7479  e argument of ty
+000016a0: 7065 2054 656e 736f 7244 6963 7420 746f  pe TensorDict to
+000016b0: 2070 6f6c 6963 792e 666f 7277 6172 6420   policy.forward 
+000016c0: 616e 6420 6465 6669 6e65 2022 0d0a 2020  and define "..  
+000016d0: 2020 2020 2020 2262 6f74 6820 696e 5f6b        "both in_k
+000016e0: 6579 7320 616e 6420 6f75 745f 6b65 7973  eys and out_keys
+000016f0: 2e20 416c 7465 726e 6174 6976 656c 792c  . Alternatively,
+00001700: 2070 6f6c 6963 792e 666f 7277 6172 6420   policy.forward 
+00001710: 6361 6e20 6163 6365 7074 2022 0d0a 2020  can accept "..  
+00001720: 2020 2020 2020 2261 7262 6974 7261 7269        "arbitrari
+00001730: 6c79 206d 616e 7920 7465 6e73 6f72 2069  ly many tensor i
+00001740: 6e70 7574 7320 616e 6420 6c65 6176 6520  nputs and leave 
+00001750: 696e 5f6b 6579 7320 616e 6420 6f75 745f  in_keys and out_
+00001760: 6b65 7973 2075 6e64 6566 696e 6564 2061  keys undefined a
+00001770: 6e64 2022 0d0a 2020 2020 2020 2020 2254  nd "..        "T
+00001780: 6f72 6368 524c 2077 696c 6c20 6174 7465  orchRL will atte
+00001790: 6d70 7420 746f 2061 7574 6f6d 6174 6963  mpt to automatic
+000017a0: 616c 6c79 2077 7261 7020 7468 6520 706f  ally wrap the po
+000017b0: 6c69 6379 2077 6974 6820 6120 5465 6e73  licy with a Tens
+000017c0: 6f72 4469 6374 4d6f 6475 6c65 2e22 0d0a  orDictModule."..
+000017d0: 2020 2020 290d 0a0d 0a0d 0a63 6c61 7373      )......class
+000017e0: 2044 6174 6143 6f6c 6c65 6374 6f72 4261   DataCollectorBa
+000017f0: 7365 2849 7465 7261 626c 6544 6174 6173  se(IterableDatas
+00001800: 6574 2c20 6d65 7461 636c 6173 733d 6162  et, metaclass=ab
+00001810: 632e 4142 434d 6574 6129 3a0d 0a20 2020  c.ABCMeta):..   
+00001820: 2022 2222 4261 7365 2063 6c61 7373 2066   """Base class f
+00001830: 6f72 2064 6174 6120 636f 6c6c 6563 746f  or data collecto
+00001840: 7273 2e22 2222 0d0a 0d0a 2020 2020 5f69  rs."""....    _i
+00001850: 7465 7261 746f 7220 3d20 4e6f 6e65 0d0a  terator = None..
+00001860: 0d0a 2020 2020 6465 6620 5f67 6574 5f70  ..    def _get_p
+00001870: 6f6c 6963 795f 616e 645f 6465 7669 6365  olicy_and_device
+00001880: 280d 0a20 2020 2020 2020 2073 656c 662c  (..        self,
+00001890: 0d0a 2020 2020 2020 2020 706f 6c69 6379  ..        policy
+000018a0: 3a20 4f70 7469 6f6e 616c 5b0d 0a20 2020  : Optional[..   
+000018b0: 2020 2020 2020 2020 2055 6e69 6f6e 5b0d           Union[.
+000018c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000018d0: 2054 656e 736f 7244 6963 744d 6f64 756c   TensorDictModul
+000018e0: 652c 0d0a 2020 2020 2020 2020 2020 2020  e,..            
+000018f0: 2020 2020 4361 6c6c 6162 6c65 5b5b 5465      Callable[[Te
+00001900: 6e73 6f72 4469 6374 4261 7365 5d2c 2054  nsorDictBase], T
+00001910: 656e 736f 7244 6963 7442 6173 655d 2c0d  ensorDictBase],.
+00001920: 0a20 2020 2020 2020 2020 2020 205d 0d0a  .            ]..
+00001930: 2020 2020 2020 2020 5d20 3d20 4e6f 6e65          ] = None
+00001940: 2c0d 0a20 2020 2020 2020 2064 6576 6963  ,..        devic
+00001950: 653a 204f 7074 696f 6e61 6c5b 4445 5649  e: Optional[DEVI
+00001960: 4345 5f54 5950 494e 475d 203d 204e 6f6e  CE_TYPING] = Non
+00001970: 652c 0d0a 2020 2020 2020 2020 6f62 7365  e,..        obse
+00001980: 7276 6174 696f 6e5f 7370 6563 3a20 5465  rvation_spec: Te
+00001990: 6e73 6f72 5370 6563 203d 204e 6f6e 652c  nsorSpec = None,
+000019a0: 0d0a 2020 2020 2920 2d3e 2054 7570 6c65  ..    ) -> Tuple
+000019b0: 5b54 656e 736f 7244 6963 744d 6f64 756c  [TensorDictModul
+000019c0: 652c 2074 6f72 6368 2e64 6576 6963 652c  e, torch.device,
+000019d0: 2055 6e69 6f6e 5b4e 6f6e 652c 2043 616c   Union[None, Cal
+000019e0: 6c61 626c 655b 5b5d 2c20 6469 6374 5d5d  lable[[], dict]]
+000019f0: 5d3a 0d0a 2020 2020 2020 2020 2222 2255  ]:..        """U
+00001a00: 7469 6c20 6d65 7468 6f64 2074 6f20 6765  til method to ge
+00001a10: 7420 6120 706f 6c69 6379 2061 6e64 2069  t a policy and i
+00001a20: 7473 2064 6576 6963 6520 6769 7665 6e20  ts device given 
+00001a30: 7468 6520 636f 6c6c 6563 746f 7220 5f5f  the collector __
+00001a40: 696e 6974 5f5f 2069 6e70 7574 732e 0d0a  init__ inputs...
+00001a50: 0d0a 2020 2020 2020 2020 4672 6f6d 2061  ..        From a
+00001a60: 2070 6f6c 6963 7920 616e 6420 6120 6465   policy and a de
+00001a70: 7669 6365 2c20 6173 7369 676e 7320 7468  vice, assigns th
+00001a80: 6520 7365 6c66 2e64 6576 6963 6520 6174  e self.device at
+00001a90: 7472 6962 7574 6520 746f 0d0a 2020 2020  tribute to..    
+00001aa0: 2020 2020 7468 6520 6465 7369 7265 6420      the desired 
+00001ab0: 6465 7669 6365 2061 6e64 206d 6170 7320  device and maps 
+00001ac0: 7468 6520 706f 6c69 6379 206f 6e74 6f20  the policy onto 
+00001ad0: 6974 206f 7220 2869 6620 7468 6520 6465  it or (if the de
+00001ae0: 7669 6365 2069 730d 0a20 2020 2020 2020  vice is..       
+00001af0: 206f 6d6d 6974 7465 6429 2061 7373 6967   ommitted) assig
+00001b00: 6e73 2074 6865 2073 656c 662e 6465 7669  ns the self.devi
+00001b10: 6365 2061 7474 7269 6275 7465 2074 6f20  ce attribute to 
+00001b20: 7468 6520 706f 6c69 6379 2064 6576 6963  the policy devic
+00001b30: 652e 0d0a 0d0a 2020 2020 2020 2020 4172  e.....        Ar
+00001b40: 6773 3a0d 0a20 2020 2020 2020 2020 2020  gs:..           
+00001b50: 2063 7265 6174 655f 656e 765f 666e 2028   create_env_fn (
+00001b60: 4361 6c6c 6162 6c65 206f 7220 6c69 7374  Callable or list
+00001b70: 206f 6620 6361 6c6c 6162 6c65 7329 3a20   of callables): 
+00001b80: 616e 2065 6e76 2063 7265 6174 6f72 0d0a  an env creator..
+00001b90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001ba0: 6675 6e63 7469 6f6e 2028 6f72 2061 206c  function (or a l
+00001bb0: 6973 7420 6f66 2063 7265 6174 6f72 7329  ist of creators)
+00001bc0: 0d0a 2020 2020 2020 2020 2020 2020 6372  ..            cr
+00001bd0: 6561 7465 5f65 6e76 5f6b 7761 7267 7320  eate_env_kwargs 
+00001be0: 2864 6963 7469 6f6e 6172 7929 3a20 6b77  (dictionary): kw
+00001bf0: 6172 6773 2066 6f72 2074 6865 2065 6e76  args for the env
+00001c00: 2063 7265 6174 6f72 0d0a 2020 2020 2020   creator..      
+00001c10: 2020 2020 2020 706f 6c69 6379 2028 5465        policy (Te
+00001c20: 6e73 6f72 4469 6374 4d6f 6475 6c65 2c20  nsorDictModule, 
+00001c30: 6f70 7469 6f6e 616c 293a 2061 2070 6f6c  optional): a pol
+00001c40: 6963 7920 746f 2062 6520 7573 6564 0d0a  icy to be used..
+00001c50: 2020 2020 2020 2020 2020 2020 6465 7669              devi
+00001c60: 6365 2028 696e 742c 2073 7472 206f 7220  ce (int, str or 
+00001c70: 746f 7263 682e 6465 7669 6365 2c20 6f70  torch.device, op
+00001c80: 7469 6f6e 616c 293a 2064 6576 6963 6520  tional): device 
+00001c90: 7768 6572 6520 746f 2070 6c61 6365 0d0a  where to place..
+00001ca0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001cb0: 7468 6520 706f 6c69 6379 0d0a 2020 2020  the policy..    
+00001cc0: 2020 2020 2020 2020 6f62 7365 7276 6174          observat
+00001cd0: 696f 6e5f 7370 6563 2028 5465 6e73 6f72  ion_spec (Tensor
+00001ce0: 5370 6563 2c20 6f70 7469 6f6e 616c 293a  Spec, optional):
+00001cf0: 2073 7065 6320 6f66 2074 6865 206f 6273   spec of the obs
+00001d00: 6572 7661 7469 6f6e 730d 0a0d 0a20 2020  ervations....   
+00001d10: 2020 2020 2022 2222 0d0a 2020 2020 2020       """..      
+00001d20: 2020 6966 2070 6f6c 6963 7920 6973 204e    if policy is N
+00001d30: 6f6e 653a 0d0a 2020 2020 2020 2020 2020  one:..          
+00001d40: 2020 6966 206e 6f74 2068 6173 6174 7472    if not hasattr
+00001d50: 2873 656c 662c 2022 656e 7622 2920 6f72  (self, "env") or
+00001d60: 2073 656c 662e 656e 7620 6973 204e 6f6e   self.env is Non
+00001d70: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
+00001d80: 2020 2020 7261 6973 6520 5661 6c75 6545      raise ValueE
+00001d90: 7272 6f72 280d 0a20 2020 2020 2020 2020  rror(..         
+00001da0: 2020 2020 2020 2020 2020 2022 656e 7620             "env 
+00001db0: 6d75 7374 2062 6520 7072 6f76 6964 6564  must be provided
+00001dc0: 2074 6f20 5f67 6574 5f70 6f6c 6963 795f   to _get_policy_
+00001dd0: 616e 645f 6465 7669 6365 2069 6620 706f  and_device if po
+00001de0: 6c69 6379 2069 7320 4e6f 6e65 220d 0a20  licy is None".. 
+00001df0: 2020 2020 2020 2020 2020 2020 2020 2029                 )
+00001e00: 0d0a 2020 2020 2020 2020 2020 2020 706f  ..            po
+00001e10: 6c69 6379 203d 2052 616e 646f 6d50 6f6c  licy = RandomPol
+00001e20: 6963 7928 7365 6c66 2e65 6e76 2e61 6374  icy(self.env.act
+00001e30: 696f 6e5f 7370 6563 290d 0a20 2020 2020  ion_spec)..     
+00001e40: 2020 2065 6c69 6620 6973 696e 7374 616e     elif isinstan
+00001e50: 6365 2870 6f6c 6963 792c 206e 6e2e 4d6f  ce(policy, nn.Mo
+00001e60: 6475 6c65 293a 0d0a 2020 2020 2020 2020  dule):..        
+00001e70: 2020 2020 2320 544f 444f 3a20 7265 7669      # TODO: revi
+00001e80: 7369 7420 7468 6573 6520 6368 6563 6b73  sit these checks
+00001e90: 2077 6865 6e20 7765 2068 6176 6520 6465   when we have de
+00001ea0: 7465 726d 696e 6564 2077 6865 7468 6572  termined whether
+00001eb0: 2061 7262 6974 7261 7279 0d0a 2020 2020   arbitrary..    
+00001ec0: 2020 2020 2020 2020 2320 6361 6c6c 6162          # callab
+00001ed0: 6c65 7320 7368 6f75 6c64 2062 6520 7375  les should be su
+00001ee0: 7070 6f72 7465 6420 6173 2070 6f6c 6963  pported as polic
+00001ef0: 6965 732e 0d0a 2020 2020 2020 2020 2020  ies...          
+00001f00: 2020 6966 206e 6f74 205f 706f 6c69 6379    if not _policy
+00001f10: 5f69 735f 7465 6e73 6f72 6469 6374 5f63  _is_tensordict_c
+00001f20: 6f6d 7061 7469 626c 6528 706f 6c69 6379  ompatible(policy
+00001f30: 293a 0d0a 2020 2020 2020 2020 2020 2020  ):..            
+00001f40: 2020 2020 2320 706f 6c69 6379 2069 7320      # policy is 
+00001f50: 6120 6e6e 2e4d 6f64 756c 6520 7468 6174  a nn.Module that
+00001f60: 2064 6f65 736e 2774 206f 7065 7261 7465   doesn't operate
+00001f70: 206f 6e20 7465 6e73 6f72 6469 6374 7320   on tensordicts 
+00001f80: 6469 7265 6374 6c79 0d0a 2020 2020 2020  directly..      
+00001f90: 2020 2020 2020 2020 2020 2320 736f 2077            # so w
+00001fa0: 6520 6174 7465 6d70 7420 746f 2061 7574  e attempt to aut
+00001fb0: 6f2d 7772 6170 2070 6f6c 6963 7920 7769  o-wrap policy wi
+00001fc0: 7468 2054 656e 736f 7244 6963 744d 6f64  th TensorDictMod
+00001fd0: 756c 650d 0a20 2020 2020 2020 2020 2020  ule..           
+00001fe0: 2020 2020 2069 6620 6f62 7365 7276 6174       if observat
+00001ff0: 696f 6e5f 7370 6563 2069 7320 4e6f 6e65  ion_spec is None
+00002000: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
+00002010: 2020 2020 2020 2072 6169 7365 2056 616c         raise Val
+00002020: 7565 4572 726f 7228 0d0a 2020 2020 2020  ueError(..      
+00002030: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002040: 2020 2255 6e61 626c 6520 746f 2072 6561    "Unable to rea
+00002050: 6420 6f62 7365 7276 6174 696f 6e5f 7370  d observation_sp
+00002060: 6563 2066 726f 6d20 7468 6520 656e 7669  ec from the envi
+00002070: 726f 6e6d 656e 742e 2054 6869 7320 6973  ronment. This is
+00002080: 2022 0d0a 2020 2020 2020 2020 2020 2020   "..            
+00002090: 2020 2020 2020 2020 2020 2020 2272 6571              "req
+000020a0: 7569 7265 6420 746f 2063 6865 636b 2063  uired to check c
+000020b0: 6f6d 7061 7469 6269 6c69 7479 206f 6620  ompatibility of 
+000020c0: 7468 6520 656e 7669 726f 6e6d 656e 7420  the environment 
+000020d0: 616e 6420 706f 6c69 6379 2022 0d0a 2020  and policy "..  
+000020e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000020f0: 2020 2020 2020 2273 696e 6365 2074 6865        "since the
+00002100: 2070 6f6c 6963 7920 6973 2061 206e 6e2e   policy is a nn.
+00002110: 4d6f 6475 6c65 2074 6861 7420 6f70 6572  Module that oper
+00002120: 6174 6573 206f 6e20 7465 6e73 6f72 7320  ates on tensors 
+00002130: 220d 0a20 2020 2020 2020 2020 2020 2020  "..             
+00002140: 2020 2020 2020 2020 2020 2022 7261 7468             "rath
+00002150: 6572 2074 6861 6e20 6120 5465 6e73 6f72  er than a Tensor
+00002160: 4469 6374 4d6f 6475 6c65 206f 7220 6120  DictModule or a 
+00002170: 6e6e 2e4d 6f64 756c 6520 7468 6174 2061  nn.Module that a
+00002180: 6363 6570 7473 2061 2022 0d0a 2020 2020  ccepts a "..    
+00002190: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000021a0: 2020 2020 2254 656e 736f 7244 6963 7420      "TensorDict 
+000021b0: 6173 2069 6e70 7574 2061 6e64 2064 6566  as input and def
+000021c0: 696e 6573 2069 6e5f 6b65 7973 2061 6e64  ines in_keys and
+000021d0: 206f 7574 5f6b 6579 732e 220d 0a20 2020   out_keys."..   
+000021e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000021f0: 2029 0d0a 0d0a 2020 2020 2020 2020 2020   )....          
+00002200: 2020 2020 2020 7472 793a 0d0a 2020 2020        try:..    
+00002210: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002220: 2320 7369 676e 6174 7572 6520 6d6f 6469  # signature modi
+00002230: 6669 6564 2062 7920 6d61 6b65 5f66 756e  fied by make_fun
+00002240: 6374 696f 6e61 6c0d 0a20 2020 2020 2020  ctional..       
+00002250: 2020 2020 2020 2020 2020 2020 2073 6967               sig
+00002260: 203d 2070 6f6c 6963 792e 666f 7277 6172   = policy.forwar
+00002270: 642e 5f5f 7369 676e 6174 7572 655f 5f0d  d.__signature__.
+00002280: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00002290: 2065 7863 6570 7420 4174 7472 6962 7574   except Attribut
+000022a0: 6545 7272 6f72 3a0d 0a20 2020 2020 2020  eError:..       
+000022b0: 2020 2020 2020 2020 2020 2020 2073 6967               sig
+000022c0: 203d 2069 6e73 7065 6374 2e73 6967 6e61   = inspect.signa
+000022d0: 7475 7265 2870 6f6c 6963 792e 666f 7277  ture(policy.forw
+000022e0: 6172 6429 0d0a 2020 2020 2020 2020 2020  ard)..          
+000022f0: 2020 2020 2020 7265 7175 6972 6564 5f70        required_p
+00002300: 6172 616d 7320 3d20 7b0d 0a20 2020 2020  arams = {..     
+00002310: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+00002320: 7472 286b 290d 0a20 2020 2020 2020 2020  tr(k)..         
+00002330: 2020 2020 2020 2020 2020 2066 6f72 206b             for k
+00002340: 2c20 7020 696e 2073 6967 2e70 6172 616d  , p in sig.param
+00002350: 6574 6572 732e 6974 656d 7328 290d 0a20  eters.items().. 
+00002360: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002370: 2020 2069 6620 702e 6465 6661 756c 7420     if p.default 
+00002380: 6973 2069 6e73 7065 6374 2e5f 656d 7074  is inspect._empt
+00002390: 790d 0a20 2020 2020 2020 2020 2020 2020  y..             
+000023a0: 2020 207d 0d0a 2020 2020 2020 2020 2020     }..          
+000023b0: 2020 2020 2020 6e65 7874 5f6f 6273 6572        next_obser
+000023c0: 7661 7469 6f6e 203d 207b 0d0a 2020 2020  vation = {..    
+000023d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000023e0: 6b65 793a 2076 616c 7565 2066 6f72 206b  key: value for k
+000023f0: 6579 2c20 7661 6c75 6520 696e 206f 6273  ey, value in obs
+00002400: 6572 7661 7469 6f6e 5f73 7065 632e 7261  ervation_spec.ra
+00002410: 6e64 2829 2e69 7465 6d73 2829 0d0a 2020  nd().items()..  
+00002420: 2020 2020 2020 2020 2020 2020 2020 7d0d                }.
+00002430: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00002440: 2023 2077 6520 6368 6563 6b20 6966 2061   # we check if a
+00002450: 6c6c 2074 6865 206d 616e 6461 746f 7279  ll the mandatory
+00002460: 2070 6172 616d 7320 6172 6520 7468 6572   params are ther
+00002470: 650d 0a20 2020 2020 2020 2020 2020 2020  e..             
+00002480: 2020 2069 6620 6e6f 7420 7265 7175 6972     if not requir
+00002490: 6564 5f70 6172 616d 732e 6469 6666 6572  ed_params.differ
+000024a0: 656e 6365 2873 6574 286e 6578 745f 6f62  ence(set(next_ob
+000024b0: 7365 7276 6174 696f 6e29 293a 0d0a 2020  servation)):..  
+000024c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000024d0: 2020 696e 5f6b 6579 7320 3d20 5b73 7472    in_keys = [str
+000024e0: 286b 2920 666f 7220 6b20 696e 2073 6967  (k) for k in sig
+000024f0: 2e70 6172 616d 6574 6572 7320 6966 206b  .parameters if k
+00002500: 2069 6e20 6e65 7874 5f6f 6273 6572 7661   in next_observa
+00002510: 7469 6f6e 5d0d 0a20 2020 2020 2020 2020  tion]..         
+00002520: 2020 2020 2020 2020 2020 206f 7574 5f6b             out_k
+00002530: 6579 7320 3d20 5b22 6163 7469 6f6e 225d  eys = ["action"]
+00002540: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00002550: 2020 2020 2020 6f75 7470 7574 203d 2070        output = p
+00002560: 6f6c 6963 7928 2a2a 6e65 7874 5f6f 6273  olicy(**next_obs
+00002570: 6572 7661 7469 6f6e 290d 0a0d 0a20 2020  ervation)....   
+00002580: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002590: 2069 6620 6973 696e 7374 616e 6365 286f   if isinstance(o
+000025a0: 7574 7075 742c 2074 7570 6c65 293a 0d0a  utput, tuple):..
+000025b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000025c0: 2020 2020 2020 2020 6f75 745f 6b65 7973          out_keys
+000025d0: 2e65 7874 656e 6428 6622 6f75 7470 7574  .extend(f"output
+000025e0: 7b69 2b31 7d22 2066 6f72 2069 2069 6e20  {i+1}" for i in 
+000025f0: 7261 6e67 6528 6c65 6e28 6f75 7470 7574  range(len(output
+00002600: 2920 2d20 3129 290d 0a0d 0a20 2020 2020  ) - 1))....     
+00002610: 2020 2020 2020 2020 2020 2020 2020 2070                 p
+00002620: 6f6c 6963 7920 3d20 5465 6e73 6f72 4469  olicy = TensorDi
+00002630: 6374 4d6f 6475 6c65 280d 0a20 2020 2020  ctModule(..     
+00002640: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002650: 2020 2070 6f6c 6963 792c 2069 6e5f 6b65     policy, in_ke
+00002660: 7973 3d69 6e5f 6b65 7973 2c20 6f75 745f  ys=in_keys, out_
+00002670: 6b65 7973 3d6f 7574 5f6b 6579 730d 0a20  keys=out_keys.. 
+00002680: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002690: 2020 2029 0d0a 2020 2020 2020 2020 2020     )..          
+000026a0: 2020 2020 2020 656c 7365 3a0d 0a20 2020        else:..   
+000026b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000026c0: 2072 6169 7365 2054 7970 6545 7272 6f72   raise TypeError
+000026d0: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
+000026e0: 2020 2020 2020 2020 2020 2066 2222 2241             f"""A
+000026f0: 7267 756d 656e 7473 2074 6f20 706f 6c69  rguments to poli
+00002700: 6379 2e66 6f72 7761 7264 2061 7265 2069  cy.forward are i
+00002710: 6e63 6f6d 7061 7469 626c 6520 7769 7468  ncompatible with
+00002720: 2065 6e74 7269 6573 2069 6e0d 0a65 6e76   entries in..env
+00002730: 2e6f 6273 6572 7661 7469 6f6e 5f73 7065  .observation_spe
+00002740: 6320 2867 6f74 2069 6e63 6f6e 6772 7565  c (got incongrue
+00002750: 6e74 2073 6967 6e61 7475 7265 733a 2066  nt signatures: f
+00002760: 756e 2073 6967 6e61 7475 7265 2069 7320  un signature is 
+00002770: 7b73 6574 2873 6967 2e70 6172 616d 6574  {set(sig.paramet
+00002780: 6572 7329 7d20 7673 2073 7065 6373 207b  ers)} vs specs {
+00002790: 7365 7428 6e65 7874 5f6f 6273 6572 7661  set(next_observa
+000027a0: 7469 6f6e 297d 292e 0d0a 4966 2079 6f75  tion)})...If you
+000027b0: 2077 616e 7420 546f 7263 6852 4c20 746f   want TorchRL to
+000027c0: 2061 7574 6f6d 6174 6963 616c 6c79 2077   automatically w
+000027d0: 7261 7020 796f 7572 2070 6f6c 6963 7920  rap your policy 
+000027e0: 7769 7468 2061 2054 656e 736f 7244 6963  with a TensorDic
+000027f0: 744d 6f64 756c 650d 0a74 6865 6e20 7468  tModule..then th
+00002800: 6520 6172 6775 6d65 6e74 7320 746f 2070  e arguments to p
+00002810: 6f6c 6963 792e 666f 7277 6172 6420 6d75  olicy.forward mu
+00002820: 7374 2063 6f72 7265 7370 6f6e 6420 6f6e  st correspond on
+00002830: 652d 746f 2d6f 6e65 2077 6974 6820 656e  e-to-one with en
+00002840: 7472 6965 730d 0a69 6e20 656e 762e 6f62  tries..in env.ob
+00002850: 7365 7276 6174 696f 6e5f 7370 6563 2074  servation_spec t
+00002860: 6861 7420 6172 6520 7072 6566 6978 6564  hat are prefixed
+00002870: 2077 6974 6820 276e 6578 745f 272e 2046   with 'next_'. F
+00002880: 6f72 206d 6f72 6520 636f 6d70 6c65 780d  or more complex.
+00002890: 0a62 6568 6176 696f 7572 2061 6e64 206d  .behaviour and m
+000028a0: 6f72 6520 636f 6e74 726f 6c20 796f 7520  ore control you 
+000028b0: 6361 6e20 636f 6e73 6964 6572 2077 7269  can consider wri
+000028c0: 7469 6e67 2079 6f75 7220 6f77 6e20 5465  ting your own Te
+000028d0: 6e73 6f72 4469 6374 4d6f 6475 6c65 2e0d  nsorDictModule..
+000028e0: 0a22 2222 0d0a 2020 2020 2020 2020 2020  ."""..          
+000028f0: 2020 2020 2020 2020 2020 290d 0a0d 0a20            ).... 
+00002900: 2020 2020 2020 2074 7279 3a0d 0a20 2020         try:..   
+00002910: 2020 2020 2020 2020 2070 6f6c 6963 795f           policy_
+00002920: 6465 7669 6365 203d 206e 6578 7428 706f  device = next(po
+00002930: 6c69 6379 2e70 6172 616d 6574 6572 7328  licy.parameters(
+00002940: 2929 2e64 6576 6963 650d 0a20 2020 2020  )).device..     
+00002950: 2020 2065 7863 6570 743a 2020 2320 6e6f     except:  # no
+00002960: 7161 0d0a 2020 2020 2020 2020 2020 2020  qa..            
+00002970: 706f 6c69 6379 5f64 6576 6963 6520 3d20  policy_device = 
+00002980: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
+00002990: 2020 2074 6f72 6368 2e64 6576 6963 6528     torch.device(
+000029a0: 6465 7669 6365 2920 6966 2064 6576 6963  device) if devic
+000029b0: 6520 6973 206e 6f74 204e 6f6e 6520 656c  e is not None el
+000029c0: 7365 2074 6f72 6368 2e64 6576 6963 6528  se torch.device(
+000029d0: 2263 7075 2229 0d0a 2020 2020 2020 2020  "cpu")..        
+000029e0: 2020 2020 290d 0a0d 0a20 2020 2020 2020      )....       
+000029f0: 2064 6576 6963 6520 3d20 746f 7263 682e   device = torch.
+00002a00: 6465 7669 6365 2864 6576 6963 6529 2069  device(device) i
+00002a10: 6620 6465 7669 6365 2069 7320 6e6f 7420  f device is not 
+00002a20: 4e6f 6e65 2065 6c73 6520 706f 6c69 6379  None else policy
+00002a30: 5f64 6576 6963 650d 0a20 2020 2020 2020  _device..       
+00002a40: 2067 6574 5f77 6569 6768 7473 5f66 6e20   get_weights_fn 
+00002a50: 3d20 4e6f 6e65 0d0a 2020 2020 2020 2020  = None..        
+00002a60: 6966 2070 6f6c 6963 795f 6465 7669 6365  if policy_device
+00002a70: 2021 3d20 6465 7669 6365 3a0d 0a20 2020   != device:..   
+00002a80: 2020 2020 2020 2020 2070 6172 616d 5f61           param_a
+00002a90: 6e64 5f62 7566 203d 2064 6963 7428 706f  nd_buf = dict(po
+00002aa0: 6c69 6379 2e6e 616d 6564 5f70 6172 616d  licy.named_param
+00002ab0: 6574 6572 7328 2929 0d0a 2020 2020 2020  eters())..      
+00002ac0: 2020 2020 2020 7061 7261 6d5f 616e 645f        param_and_
+00002ad0: 6275 662e 7570 6461 7465 2864 6963 7428  buf.update(dict(
+00002ae0: 706f 6c69 6379 2e6e 616d 6564 5f62 7566  policy.named_buf
+00002af0: 6665 7273 2829 2929 0d0a 0d0a 2020 2020  fers()))....    
+00002b00: 2020 2020 2020 2020 6465 6620 6765 745f          def get_
+00002b10: 7765 6967 6874 735f 666e 2870 6172 616d  weights_fn(param
+00002b20: 5f61 6e64 5f62 7566 3d70 6172 616d 5f61  _and_buf=param_a
+00002b30: 6e64 5f62 7566 293a 0d0a 2020 2020 2020  nd_buf):..      
+00002b40: 2020 2020 2020 2020 2020 7265 7475 726e            return
+00002b50: 2054 656e 736f 7244 6963 7428 7061 7261   TensorDict(para
+00002b60: 6d5f 616e 645f 6275 662c 205b 5d29 2e61  m_and_buf, []).a
+00002b70: 7070 6c79 286c 616d 6264 6120 783a 2078  pply(lambda x: x
+00002b80: 2e64 6174 6129 0d0a 0d0a 2020 2020 2020  .data)....      
+00002b90: 2020 2020 2020 706f 6c69 6379 5f63 6173        policy_cas
+00002ba0: 7420 3d20 6465 6570 636f 7079 2870 6f6c  t = deepcopy(pol
+00002bb0: 6963 7929 2e72 6571 7569 7265 735f 6772  icy).requires_gr
+00002bc0: 6164 5f28 4661 6c73 6529 2e74 6f28 6465  ad_(False).to(de
+00002bd0: 7669 6365 290d 0a20 2020 2020 2020 2020  vice)..         
+00002be0: 2020 2023 2068 6572 6520 7468 696e 6773     # here things
+00002bf0: 206d 6179 2062 7265 616b 2062 6320 706f   may break bc po
+00002c00: 6c69 6379 2e74 6f28 2263 7564 6122 2920  licy.to("cuda") 
+00002c10: 6769 7665 7320 7573 2077 6569 6768 7473  gives us weights
+00002c20: 206f 6e20 6375 6461 3a30 2028 7361 6d65   on cuda:0 (same
+00002c30: 0d0a 2020 2020 2020 2020 2020 2020 2320  ..            # 
+00002c40: 6275 7420 6469 6666 6572 656e 7429 0d0a  but different)..
+00002c50: 2020 2020 2020 2020 2020 2020 7472 793a              try:
+00002c60: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00002c70: 2020 6465 7669 6365 203d 206e 6578 7428    device = next(
+00002c80: 706f 6c69 6379 5f63 6173 742e 7061 7261  policy_cast.para
+00002c90: 6d65 7465 7273 2829 292e 6465 7669 6365  meters()).device
+00002ca0: 0d0a 2020 2020 2020 2020 2020 2020 6578  ..            ex
+00002cb0: 6365 7074 2053 746f 7049 7465 7261 7469  cept StopIterati
+00002cc0: 6f6e 3a20 2023 206e 6f71 610d 0a20 2020  on:  # noqa..   
+00002cd0: 2020 2020 2020 2020 2020 2020 2070 6173               pas
+00002ce0: 730d 0a20 2020 2020 2020 2065 6c73 653a  s..        else:
+00002cf0: 0d0a 2020 2020 2020 2020 2020 2020 706f  ..            po
+00002d00: 6c69 6379 5f63 6173 7420 3d20 706f 6c69  licy_cast = poli
+00002d10: 6379 0d0a 2020 2020 2020 2020 7265 7475  cy..        retu
+00002d20: 726e 2070 6f6c 6963 795f 6361 7374 2c20  rn policy_cast, 
+00002d30: 6465 7669 6365 2c20 6765 745f 7765 6967  device, get_weig
+00002d40: 6874 735f 666e 0d0a 0d0a 2020 2020 6465  hts_fn....    de
+00002d50: 6620 7570 6461 7465 5f70 6f6c 6963 795f  f update_policy_
+00002d60: 7765 6967 6874 735f 280d 0a20 2020 2020  weights_(..     
+00002d70: 2020 2073 656c 662c 2070 6f6c 6963 795f     self, policy_
+00002d80: 7765 6967 6874 733a 204f 7074 696f 6e61  weights: Optiona
+00002d90: 6c5b 5465 6e73 6f72 4469 6374 4261 7365  l[TensorDictBase
+00002da0: 5d20 3d20 4e6f 6e65 0d0a 2020 2020 2920  ] = None..    ) 
+00002db0: 2d3e 204e 6f6e 653a 0d0a 2020 2020 2020  -> None:..      
+00002dc0: 2020 2222 2255 7064 6174 6573 2074 6865    """Updates the
+00002dd0: 2070 6f6c 6963 7920 7765 6967 6874 7320   policy weights 
+00002de0: 6966 2074 6865 2070 6f6c 6963 7920 6f66  if the policy of
+00002df0: 2074 6865 2064 6174 6120 636f 6c6c 6563   the data collec
+00002e00: 746f 7220 616e 6420 7468 6520 7472 6169  tor and the trai
+00002e10: 6e65 6420 706f 6c69 6379 206c 6976 6520  ned policy live 
+00002e20: 6f6e 2064 6966 6665 7265 6e74 2064 6576  on different dev
+00002e30: 6963 6573 2e0d 0a0d 0a20 2020 2020 2020  ices.....       
+00002e40: 2041 7267 733a 0d0a 2020 2020 2020 2020   Args:..        
+00002e50: 2020 2020 706f 6c69 6379 5f77 6569 6768      policy_weigh
+00002e60: 7473 2028 5465 6e73 6f72 4469 6374 4261  ts (TensorDictBa
+00002e70: 7365 2c20 6f70 7469 6f6e 616c 293a 2069  se, optional): i
+00002e80: 6620 7072 6f76 6964 6564 2c20 6120 5465  f provided, a Te
+00002e90: 6e73 6f72 4469 6374 2063 6f6e 7461 696e  nsorDict contain
+00002ea0: 696e 670d 0a20 2020 2020 2020 2020 2020  ing..           
+00002eb0: 2020 2020 2074 6865 2077 6569 6768 7473       the weights
+00002ec0: 206f 6620 7468 6520 706f 6c69 6379 2074   of the policy t
+00002ed0: 6f20 6265 2075 7365 6420 666f 7220 7468  o be used for th
+00002ee0: 6520 7564 7064 6174 652e 0d0a 0d0a 2020  e udpdate.....  
+00002ef0: 2020 2020 2020 2222 220d 0a20 2020 2020        """..     
+00002f00: 2020 2069 6620 706f 6c69 6379 5f77 6569     if policy_wei
+00002f10: 6768 7473 2069 7320 6e6f 7420 4e6f 6e65  ghts is not None
+00002f20: 3a0d 0a20 2020 2020 2020 2020 2020 2073  :..            s
+00002f30: 656c 662e 706f 6c69 6379 5f77 6569 6768  elf.policy_weigh
+00002f40: 7473 2e61 7070 6c79 286c 616d 6264 6120  ts.apply(lambda 
+00002f50: 783a 2078 2e64 6174 6129 2e75 7064 6174  x: x.data).updat
+00002f60: 655f 2870 6f6c 6963 795f 7765 6967 6874  e_(policy_weight
+00002f70: 7329 0d0a 2020 2020 2020 2020 656c 6966  s)..        elif
+00002f80: 2073 656c 662e 6765 745f 7765 6967 6874   self.get_weight
+00002f90: 735f 666e 2069 7320 6e6f 7420 4e6f 6e65  s_fn is not None
+00002fa0: 3a0d 0a20 2020 2020 2020 2020 2020 2073  :..            s
+00002fb0: 656c 662e 706f 6c69 6379 2e6c 6f61 645f  elf.policy.load_
+00002fc0: 7374 6174 655f 6469 6374 2873 656c 662e  state_dict(self.
+00002fd0: 6765 745f 7765 6967 6874 735f 666e 2829  get_weights_fn()
+00002fe0: 290d 0a0d 0a20 2020 2064 6566 205f 5f69  )....    def __i
+00002ff0: 7465 725f 5f28 7365 6c66 2920 2d3e 2049  ter__(self) -> I
+00003000: 7465 7261 746f 725b 5465 6e73 6f72 4469  terator[TensorDi
+00003010: 6374 4261 7365 5d3a 0d0a 2020 2020 2020  ctBase]:..      
+00003020: 2020 7265 7475 726e 2073 656c 662e 6974    return self.it
+00003030: 6572 6174 6f72 2829 0d0a 0d0a 2020 2020  erator()....    
+00003040: 6465 6620 6e65 7874 2873 656c 6629 3a0d  def next(self):.
+00003050: 0a20 2020 2020 2020 2074 7279 3a0d 0a20  .        try:.. 
+00003060: 2020 2020 2020 2020 2020 2069 6620 7365             if se
+00003070: 6c66 2e5f 6974 6572 6174 6f72 2069 7320  lf._iterator is 
+00003080: 4e6f 6e65 3a0d 0a20 2020 2020 2020 2020  None:..         
+00003090: 2020 2020 2020 2073 656c 662e 5f69 7465         self._ite
+000030a0: 7261 746f 7220 3d20 6974 6572 2873 656c  rator = iter(sel
+000030b0: 6629 0d0a 2020 2020 2020 2020 2020 2020  f)..            
+000030c0: 6f75 7420 3d20 6e65 7874 2873 656c 662e  out = next(self.
+000030d0: 5f69 7465 7261 746f 7229 0d0a 2020 2020  _iterator)..    
+000030e0: 2020 2020 2020 2020 2320 6966 2061 6e79          # if any
+000030f0: 2c20 7765 2064 6f6e 2774 2077 616e 7420  , we don't want 
+00003100: 7468 6520 6465 7669 6365 2072 6566 2074  the device ref t
+00003110: 6f20 6265 2070 6173 7365 6420 696e 2064  o be passed in d
+00003120: 6973 7472 6962 7574 6564 2073 6574 7469  istributed setti
+00003130: 6e67 730d 0a20 2020 2020 2020 2020 2020  ngs..           
+00003140: 206f 7574 2e63 6c65 6172 5f64 6576 6963   out.clear_devic
+00003150: 655f 2829 0d0a 2020 2020 2020 2020 2020  e_()..          
+00003160: 2020 7265 7475 726e 206f 7574 0d0a 2020    return out..  
+00003170: 2020 2020 2020 6578 6365 7074 2053 746f        except Sto
+00003180: 7049 7465 7261 7469 6f6e 3a0d 0a20 2020  pIteration:..   
+00003190: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+000031a0: 4e6f 6e65 0d0a 0d0a 2020 2020 4061 6263  None....    @abc
+000031b0: 2e61 6273 7472 6163 746d 6574 686f 640d  .abstractmethod.
+000031c0: 0a20 2020 2064 6566 2073 6875 7464 6f77  .    def shutdow
+000031d0: 6e28 7365 6c66 293a 0d0a 2020 2020 2020  n(self):..      
+000031e0: 2020 7261 6973 6520 4e6f 7449 6d70 6c65    raise NotImple
+000031f0: 6d65 6e74 6564 4572 726f 720d 0a0d 0a20  mentedError.... 
+00003200: 2020 2040 6162 632e 6162 7374 7261 6374     @abc.abstract
+00003210: 6d65 7468 6f64 0d0a 2020 2020 6465 6620  method..    def 
+00003220: 6974 6572 6174 6f72 2873 656c 6629 202d  iterator(self) -
+00003230: 3e20 4974 6572 6174 6f72 5b54 656e 736f  > Iterator[Tenso
+00003240: 7244 6963 7442 6173 655d 3a0d 0a20 2020  rDictBase]:..   
+00003250: 2020 2020 2072 6169 7365 204e 6f74 496d       raise NotIm
+00003260: 706c 656d 656e 7465 6445 7272 6f72 0d0a  plementedError..
+00003270: 0d0a 2020 2020 4061 6263 2e61 6273 7472  ..    @abc.abstr
+00003280: 6163 746d 6574 686f 640d 0a20 2020 2064  actmethod..    d
+00003290: 6566 2073 6574 5f73 6565 6428 7365 6c66  ef set_seed(self
+000032a0: 2c20 7365 6564 3a20 696e 742c 2073 7461  , seed: int, sta
+000032b0: 7469 635f 7365 6564 3a20 626f 6f6c 203d  tic_seed: bool =
+000032c0: 2046 616c 7365 2920 2d3e 2069 6e74 3a0d   False) -> int:.
+000032d0: 0a20 2020 2020 2020 2072 6169 7365 204e  .        raise N
+000032e0: 6f74 496d 706c 656d 656e 7465 6445 7272  otImplementedErr
+000032f0: 6f72 0d0a 0d0a 2020 2020 4061 6263 2e61  or....    @abc.a
+00003300: 6273 7472 6163 746d 6574 686f 640d 0a20  bstractmethod.. 
+00003310: 2020 2064 6566 2073 7461 7465 5f64 6963     def state_dic
+00003320: 7428 7365 6c66 2920 2d3e 204f 7264 6572  t(self) -> Order
+00003330: 6564 4469 6374 3a0d 0a20 2020 2020 2020  edDict:..       
+00003340: 2072 6169 7365 204e 6f74 496d 706c 656d   raise NotImplem
+00003350: 656e 7465 6445 7272 6f72 0d0a 0d0a 2020  entedError....  
+00003360: 2020 4061 6263 2e61 6273 7472 6163 746d    @abc.abstractm
+00003370: 6574 686f 640d 0a20 2020 2064 6566 206c  ethod..    def l
+00003380: 6f61 645f 7374 6174 655f 6469 6374 2873  oad_state_dict(s
+00003390: 656c 662c 2073 7461 7465 5f64 6963 743a  elf, state_dict:
+000033a0: 204f 7264 6572 6564 4469 6374 2920 2d3e   OrderedDict) ->
+000033b0: 204e 6f6e 653a 0d0a 2020 2020 2020 2020   None:..        
+000033c0: 7261 6973 6520 4e6f 7449 6d70 6c65 6d65  raise NotImpleme
+000033d0: 6e74 6564 4572 726f 720d 0a0d 0a20 2020  ntedError....   
+000033e0: 2064 6566 205f 5f72 6570 725f 5f28 7365   def __repr__(se
+000033f0: 6c66 2920 2d3e 2073 7472 3a0d 0a20 2020  lf) -> str:..   
+00003400: 2020 2020 2073 7472 696e 6720 3d20 6622       string = f"
+00003410: 7b73 656c 662e 5f5f 636c 6173 735f 5f2e  {self.__class__.
+00003420: 5f5f 6e61 6d65 5f5f 7d28 2922 0d0a 2020  __name__}()"..  
+00003430: 2020 2020 2020 7265 7475 726e 2073 7472        return str
+00003440: 696e 670d 0a0d 0a0d 0a40 6163 6365 7074  ing......@accept
+00003450: 5f72 656d 6f74 655f 7272 6566 5f75 6466  _remote_rref_udf
+00003460: 5f69 6e76 6f63 6174 696f 6e0d 0a63 6c61  _invocation..cla
+00003470: 7373 2053 796e 6344 6174 6143 6f6c 6c65  ss SyncDataColle
+00003480: 6374 6f72 2844 6174 6143 6f6c 6c65 6374  ctor(DataCollect
+00003490: 6f72 4261 7365 293a 0d0a 2020 2020 2222  orBase):..    ""
+000034a0: 2247 656e 6572 6963 2064 6174 6120 636f  "Generic data co
+000034b0: 6c6c 6563 746f 7220 666f 7220 524c 2070  llector for RL p
+000034c0: 726f 626c 656d 732e 2052 6571 7569 7265  roblems. Require
+000034d0: 7320 616e 2065 6e76 6972 6f6e 6d65 6e74  s an environment
+000034e0: 2063 6f6e 7374 7275 6374 6f72 2061 6e64   constructor and
+000034f0: 2061 2070 6f6c 6963 792e 0d0a 0d0a 2020   a policy.....  
+00003500: 2020 4172 6773 3a0d 0a20 2020 2020 2020    Args:..       
+00003510: 2063 7265 6174 655f 656e 765f 666e 2028   create_env_fn (
+00003520: 4361 6c6c 6162 6c65 293a 2061 2063 616c  Callable): a cal
+00003530: 6c61 626c 6520 7468 6174 2072 6574 7572  lable that retur
+00003540: 6e73 2061 6e20 696e 7374 616e 6365 206f  ns an instance o
+00003550: 660d 0a20 2020 2020 2020 2020 2020 203a  f..            :
+00003560: 636c 6173 733a 607e 746f 7263 6872 6c2e  class:`~torchrl.
+00003570: 656e 7673 2e45 6e76 4261 7365 6020 636c  envs.EnvBase` cl
+00003580: 6173 732e 0d0a 2020 2020 2020 2020 706f  ass...        po
+00003590: 6c69 6379 2028 4361 6c6c 6162 6c65 293a  licy (Callable):
+000035a0: 2050 6f6c 6963 7920 746f 2062 6520 6578   Policy to be ex
+000035b0: 6563 7574 6564 2069 6e20 7468 6520 656e  ecuted in the en
+000035c0: 7669 726f 6e6d 656e 742e 0d0a 2020 2020  vironment...    
+000035d0: 2020 2020 2020 2020 4d75 7374 2061 6363          Must acc
+000035e0: 6570 7420 3a63 6c61 7373 3a60 7465 6e73  ept :class:`tens
+000035f0: 6f72 6469 6374 2e74 656e 736f 7264 6963  ordict.tensordic
+00003600: 742e 5465 6e73 6f72 4469 6374 4261 7365  t.TensorDictBase
+00003610: 6020 6f62 6a65 6374 2061 7320 696e 7075  ` object as inpu
+00003620: 742e 0d0a 2020 2020 2020 2020 2020 2020  t...            
+00003630: 4966 2060 604e 6f6e 6560 6020 6973 2070  If ``None`` is p
+00003640: 726f 7669 6465 642c 2074 6865 2070 6f6c  rovided, the pol
+00003650: 6963 7920 7573 6564 2077 696c 6c20 6265  icy used will be
+00003660: 2061 0d0a 2020 2020 2020 2020 2020 2020   a..            
+00003670: 3a63 6c61 7373 3a60 7e74 6f72 6368 726c  :class:`~torchrl
+00003680: 2e63 6f6c 6c65 6374 6f72 732e 5261 6e64  .collectors.Rand
+00003690: 6f6d 506f 6c69 6379 6020 696e 7374 616e  omPolicy` instan
+000036a0: 6365 2077 6974 6820 7468 6520 656e 7669  ce with the envi
+000036b0: 726f 6e6d 656e 740d 0a20 2020 2020 2020  ronment..       
+000036c0: 2020 2020 2060 6061 6374 696f 6e5f 7370       ``action_sp
+000036d0: 6563 6060 2e0d 0a20 2020 2020 2020 2066  ec``...        f
+000036e0: 7261 6d65 735f 7065 725f 6261 7463 6820  rames_per_batch 
+000036f0: 2869 6e74 293a 2041 206b 6579 776f 7264  (int): A keyword
+00003700: 2d6f 6e6c 7920 6172 6775 6d65 6e74 2072  -only argument r
+00003710: 6570 7265 7365 6e74 696e 6720 7468 6520  epresenting the 
+00003720: 746f 7461 6c0d 0a20 2020 2020 2020 2020  total..         
+00003730: 2020 206e 756d 6265 7220 6f66 2065 6c65     number of ele
+00003740: 6d65 6e74 7320 696e 2061 2062 6174 6368  ments in a batch
+00003750: 2e0d 0a20 2020 2020 2020 2074 6f74 616c  ...        total
+00003760: 5f66 7261 6d65 7320 2869 6e74 293a 2041  _frames (int): A
+00003770: 206b 6579 776f 7264 2d6f 6e6c 7920 6172   keyword-only ar
+00003780: 6775 6d65 6e74 2072 6570 7265 7365 6e74  gument represent
+00003790: 696e 6720 7468 6520 746f 7461 6c0d 0a20  ing the total.. 
+000037a0: 2020 2020 2020 2020 2020 206e 756d 6265             numbe
+000037b0: 7220 6f66 2066 7261 6d65 7320 7265 7475  r of frames retu
+000037c0: 726e 6564 2062 7920 7468 6520 636f 6c6c  rned by the coll
+000037d0: 6563 746f 720d 0a20 2020 2020 2020 2020  ector..         
+000037e0: 2020 2064 7572 696e 6720 6974 7320 6c69     during its li
+000037f0: 6665 7370 616e 2e20 4966 2074 6865 2060  fespan. If the `
+00003800: 6074 6f74 616c 5f66 7261 6d65 7360 6020  `total_frames`` 
+00003810: 6973 206e 6f74 2064 6976 6973 6962 6c65  is not divisible
+00003820: 2062 790d 0a20 2020 2020 2020 2020 2020   by..           
+00003830: 2060 6066 7261 6d65 735f 7065 725f 6261   ``frames_per_ba
+00003840: 7463 6860 602c 2061 6e20 6578 6365 7074  tch``, an except
+00003850: 696f 6e20 6973 2072 6169 7365 642e 0d0a  ion is raised...
+00003860: 2020 2020 2020 2020 2020 2020 2045 6e64               End
+00003870: 6c65 7373 2063 6f6c 6c65 6374 6f72 7320  less collectors 
+00003880: 6361 6e20 6265 2063 7265 6174 6564 2062  can be created b
+00003890: 7920 7061 7373 696e 6720 6060 746f 7461  y passing ``tota
+000038a0: 6c5f 6672 616d 6573 3d2d 3160 602e 0d0a  l_frames=-1``...
+000038b0: 2020 2020 2020 2020 6465 7669 6365 2028          device (
+000038c0: 696e 742c 2073 7472 206f 7220 746f 7263  int, str or torc
+000038d0: 682e 6465 7669 6365 2c20 6f70 7469 6f6e  h.device, option
+000038e0: 616c 293a 2054 6865 2064 6576 6963 6520  al): The device 
+000038f0: 6f6e 2077 6869 6368 2074 6865 0d0a 2020  on which the..  
+00003900: 2020 2020 2020 2020 2020 706f 6c69 6379            policy
+00003910: 2077 696c 6c20 6265 2070 6c61 6365 642e   will be placed.
+00003920: 0d0a 2020 2020 2020 2020 2020 2020 4966  ..            If
+00003930: 2069 7420 6469 6666 6572 7320 6672 6f6d   it differs from
+00003940: 2074 6865 2069 6e70 7574 2070 6f6c 6963   the input polic
+00003950: 7920 6465 7669 6365 2c20 7468 650d 0a20  y device, the.. 
+00003960: 2020 2020 2020 2020 2020 203a 6d65 7468             :meth
+00003970: 3a60 7e2e 7570 6461 7465 5f70 6f6c 6963  :`~.update_polic
+00003980: 795f 7765 6967 6874 735f 6020 6d65 7468  y_weights_` meth
+00003990: 6f64 2073 686f 756c 6420 6265 2071 7565  od should be que
+000039a0: 7269 6564 0d0a 2020 2020 2020 2020 2020  ried..          
+000039b0: 2020 6174 2061 7070 726f 7072 6961 7465    at appropriate
+000039c0: 2074 696d 6573 2064 7572 696e 6720 7468   times during th
+000039d0: 6520 7472 6169 6e69 6e67 206c 6f6f 7020  e training loop 
+000039e0: 746f 2061 6363 6f6d 6d6f 6461 7465 2066  to accommodate f
+000039f0: 6f72 0d0a 2020 2020 2020 2020 2020 2020  or..            
+00003a00: 7468 6520 6c61 6720 6265 7477 6565 6e20  the lag between 
+00003a10: 7061 7261 6d65 7465 7220 636f 6e66 6967  parameter config
+00003a20: 7572 6174 696f 6e20 6174 2076 6172 696f  uration at vario
+00003a30: 7573 2074 696d 6573 2e0d 0a20 2020 2020  us times...     
+00003a40: 2020 2020 2020 2044 6566 6175 6c74 7320         Defaults 
+00003a50: 746f 2060 604e 6f6e 6560 6020 2869 2e65  to ``None`` (i.e
+00003a60: 2e20 706f 6c69 6379 2069 7320 6b65 7074  . policy is kept
+00003a70: 206f 6e20 6974 7320 6f72 6967 696e 616c   on its original
+00003a80: 2064 6576 6963 6529 2e0d 0a20 2020 2020   device)...     
+00003a90: 2020 2073 746f 7269 6e67 5f64 6576 6963     storing_devic
+00003aa0: 6520 2869 6e74 2c20 7374 7220 6f72 2074  e (int, str or t
+00003ab0: 6f72 6368 2e64 6576 6963 652c 206f 7074  orch.device, opt
+00003ac0: 696f 6e61 6c29 3a20 5468 6520 6465 7669  ional): The devi
+00003ad0: 6365 206f 6e20 7768 6963 680d 0a20 2020  ce on which..   
+00003ae0: 2020 2020 2020 2020 2074 6865 206f 7574           the out
+00003af0: 7075 7420 3a63 6c61 7373 3a60 7465 6e73  put :class:`tens
+00003b00: 6f72 6469 6374 2e54 656e 736f 7244 6963  ordict.TensorDic
+00003b10: 7460 2077 696c 6c20 6265 2073 746f 7265  t` will be store
+00003b20: 642e 2046 6f72 206c 6f6e 670d 0a20 2020  d. For long..   
+00003b30: 2020 2020 2020 2020 2074 7261 6a65 6374           traject
+00003b40: 6f72 6965 732c 2069 7420 6d61 7920 6265  ories, it may be
+00003b50: 206e 6563 6573 7361 7279 2074 6f20 7374   necessary to st
+00003b60: 6f72 6520 7468 6520 6461 7461 206f 6e20  ore the data on 
+00003b70: 6120 6469 6666 6572 656e 740d 0a20 2020  a different..   
+00003b80: 2020 2020 2020 2020 2064 6576 6963 6520           device 
+00003b90: 7468 616e 2074 6865 206f 6e65 2077 6865  than the one whe
+00003ba0: 7265 2074 6865 2070 6f6c 6963 7920 616e  re the policy an
+00003bb0: 6420 656e 7620 6172 6520 6578 6563 7574  d env are execut
+00003bc0: 6564 2e0d 0a20 2020 2020 2020 2020 2020  ed...           
+00003bd0: 2044 6566 6175 6c74 7320 746f 2060 6022   Defaults to ``"
+00003be0: 6370 7522 6060 2e0d 0a20 2020 2020 2020  cpu"``...       
+00003bf0: 2063 7265 6174 655f 656e 765f 6b77 6172   create_env_kwar
+00003c00: 6773 2028 6469 6374 2c20 6f70 7469 6f6e  gs (dict, option
+00003c10: 616c 293a 2044 6963 7469 6f6e 6172 7920  al): Dictionary 
+00003c20: 6f66 206b 7761 7267 7320 666f 720d 0a20  of kwargs for.. 
+00003c30: 2020 2020 2020 2020 2020 2060 6063 7265             ``cre
+00003c40: 6174 655f 656e 765f 666e 6060 2e0d 0a20  ate_env_fn``... 
+00003c50: 2020 2020 2020 206d 6178 5f66 7261 6d65         max_frame
+00003c60: 735f 7065 725f 7472 616a 2028 696e 742c  s_per_traj (int,
+00003c70: 206f 7074 696f 6e61 6c29 3a20 4d61 7869   optional): Maxi
+00003c80: 6d75 6d20 7374 6570 7320 7065 7220 7472  mum steps per tr
+00003c90: 616a 6563 746f 7279 2e0d 0a20 2020 2020  ajectory...     
+00003ca0: 2020 2020 2020 204e 6f74 6520 7468 6174         Note that
+00003cb0: 2061 2074 7261 6a65 6374 6f72 7920 6361   a trajectory ca
+00003cc0: 6e20 7370 616e 206f 7665 7220 6d75 6c74  n span over mult
+00003cd0: 6970 6c65 2062 6174 6368 6573 2028 756e  iple batches (un
+00003ce0: 6c65 7373 0d0a 2020 2020 2020 2020 2020  less..          
+00003cf0: 2020 6060 7265 7365 745f 6174 5f65 6163    ``reset_at_eac
+00003d00: 685f 6974 6572 6060 2069 7320 7365 7420  h_iter`` is set 
+00003d10: 746f 2060 6054 7275 6560 602c 2073 6565  to ``True``, see
+00003d20: 2062 656c 6f77 292e 0d0a 2020 2020 2020   below)...      
+00003d30: 2020 2020 2020 4f6e 6365 2061 2074 7261        Once a tra
+00003d40: 6a65 6374 6f72 7920 7265 6163 6865 7320  jectory reaches 
+00003d50: 6060 6e5f 7374 6570 7360 602c 2074 6865  ``n_steps``, the
+00003d60: 2065 6e76 6972 6f6e 6d65 6e74 2069 7320   environment is 
+00003d70: 7265 7365 742e 0d0a 2020 2020 2020 2020  reset...        
+00003d80: 2020 2020 4966 2074 6865 2065 6e76 6972      If the envir
+00003d90: 6f6e 6d65 6e74 2077 7261 7073 206d 756c  onment wraps mul
+00003da0: 7469 706c 6520 656e 7669 726f 6e6d 656e  tiple environmen
+00003db0: 7473 2074 6f67 6574 6865 722c 2074 6865  ts together, the
+00003dc0: 206e 756d 6265 720d 0a20 2020 2020 2020   number..       
+00003dd0: 2020 2020 206f 6620 7374 6570 7320 6973       of steps is
+00003de0: 2074 7261 636b 6564 2066 6f72 2065 6163   tracked for eac
+00003df0: 6820 656e 7669 726f 6e6d 656e 7420 696e  h environment in
+00003e00: 6465 7065 6e64 656e 746c 792e 204e 6567  dependently. Neg
+00003e10: 6174 6976 650d 0a20 2020 2020 2020 2020  ative..         
+00003e20: 2020 2076 616c 7565 7320 6172 6520 616c     values are al
+00003e30: 6c6f 7765 642c 2069 6e20 7768 6963 6820  lowed, in which 
+00003e40: 6361 7365 2074 6869 7320 6172 6775 6d65  case this argume
+00003e50: 6e74 2069 7320 6967 6e6f 7265 642e 0d0a  nt is ignored...
+00003e60: 2020 2020 2020 2020 2020 2020 4465 6661              Defa
+00003e70: 756c 7473 2074 6f20 6060 2d31 6060 2028  ults to ``-1`` (
+00003e80: 692e 652e 206e 6f20 6d61 7869 6d75 6d20  i.e. no maximum 
+00003e90: 6e75 6d62 6572 206f 6620 7374 6570 7329  number of steps)
+00003ea0: 2e0d 0a20 2020 2020 2020 2069 6e69 745f  ...        init_
+00003eb0: 7261 6e64 6f6d 5f66 7261 6d65 7320 2869  random_frames (i
+00003ec0: 6e74 2c20 6f70 7469 6f6e 616c 293a 204e  nt, optional): N
+00003ed0: 756d 6265 7220 6f66 2066 7261 6d65 7320  umber of frames 
+00003ee0: 666f 7220 7768 6963 6820 7468 650d 0a20  for which the.. 
+00003ef0: 2020 2020 2020 2020 2020 2070 6f6c 6963             polic
+00003f00: 7920 6973 2069 676e 6f72 6564 2062 6566  y is ignored bef
+00003f10: 6f72 6520 6974 2069 7320 6361 6c6c 6564  ore it is called
+00003f20: 2e20 5468 6973 2066 6561 7475 7265 2069  . This feature i
+00003f30: 7320 6d61 696e 6c79 0d0a 2020 2020 2020  s mainly..      
+00003f40: 2020 2020 2020 696e 7465 6e64 6564 2074        intended t
+00003f50: 6f20 6265 2075 7365 6420 696e 206f 6666  o be used in off
+00003f60: 6c69 6e65 2f6d 6f64 656c 2d62 6173 6564  line/model-based
+00003f70: 2073 6574 7469 6e67 732c 2077 6865 7265   settings, where
+00003f80: 2061 0d0a 2020 2020 2020 2020 2020 2020   a..            
+00003f90: 6261 7463 6820 6f66 2072 616e 646f 6d20  batch of random 
+00003fa0: 7472 616a 6563 746f 7269 6573 2063 616e  trajectories can
+00003fb0: 2062 6520 7573 6564 2074 6f20 696e 6974   be used to init
+00003fc0: 6961 6c69 7a65 2074 7261 696e 696e 672e  ialize training.
+00003fd0: 0d0a 2020 2020 2020 2020 2020 2020 4465  ..            De
+00003fe0: 6661 756c 7473 2074 6f20 6060 2d31 6060  faults to ``-1``
+00003ff0: 2028 692e 652e 206e 6f20 7261 6e64 6f6d   (i.e. no random
+00004000: 2066 7261 6d65 7329 2e0d 0a20 2020 2020   frames)...     
+00004010: 2020 2072 6573 6574 5f61 745f 6561 6368     reset_at_each
+00004020: 5f69 7465 7220 2862 6f6f 6c2c 206f 7074  _iter (bool, opt
+00004030: 696f 6e61 6c29 3a20 5768 6574 6865 7220  ional): Whether 
+00004040: 656e 7669 726f 6e6d 656e 7473 2073 686f  environments sho
+00004050: 756c 6420 6265 2072 6573 6574 0d0a 2020  uld be reset..  
+00004060: 2020 2020 2020 2020 2020 6174 2074 6865            at the
+00004070: 2062 6567 696e 6e69 6e67 206f 6620 6120   beginning of a 
+00004080: 6261 7463 6820 636f 6c6c 6563 7469 6f6e  batch collection
+00004090: 2e0d 0a20 2020 2020 2020 2020 2020 2044  ...            D
+000040a0: 6566 6175 6c74 7320 746f 2060 6046 616c  efaults to ``Fal
+000040b0: 7365 6060 2e0d 0a20 2020 2020 2020 2070  se``...        p
+000040c0: 6f73 7470 726f 6320 2843 616c 6c61 626c  ostproc (Callabl
+000040d0: 652c 206f 7074 696f 6e61 6c29 3a20 4120  e, optional): A 
+000040e0: 706f 7374 2d70 726f 6365 7373 696e 6720  post-processing 
+000040f0: 7472 616e 7366 6f72 6d2c 2073 7563 6820  transform, such 
+00004100: 6173 0d0a 2020 2020 2020 2020 2020 2020  as..            
+00004110: 6120 3a63 6c61 7373 3a60 7e74 6f72 6368  a :class:`~torch
+00004120: 726c 2e65 6e76 732e 5472 616e 7366 6f72  rl.envs.Transfor
+00004130: 6d60 206f 7220 6120 3a63 6c61 7373 3a60  m` or a :class:`
+00004140: 7e74 6f72 6368 726c 2e64 6174 612e 706f  ~torchrl.data.po
+00004150: 7374 7072 6f63 732e 4d75 6c74 6953 7465  stprocs.MultiSte
+00004160: 7060 0d0a 2020 2020 2020 2020 2020 2020  p`..            
+00004170: 696e 7374 616e 6365 2e0d 0a20 2020 2020  instance...     
+00004180: 2020 2020 2020 2044 6566 6175 6c74 7320         Defaults 
+00004190: 746f 2060 604e 6f6e 6560 602e 0d0a 2020  to ``None``...  
+000041a0: 2020 2020 2020 7370 6c69 745f 7472 616a        split_traj
+000041b0: 7320 2862 6f6f 6c2c 206f 7074 696f 6e61  s (bool, optiona
+000041c0: 6c29 3a20 426f 6f6c 6561 6e20 696e 6469  l): Boolean indi
+000041d0: 6361 7469 6e67 2077 6865 7468 6572 2074  cating whether t
+000041e0: 6865 2072 6573 756c 7469 6e67 0d0a 2020  he resulting..  
+000041f0: 2020 2020 2020 2020 2020 5465 6e73 6f72            Tensor
+00004200: 4469 6374 2073 686f 756c 6420 6265 2073  Dict should be s
+00004210: 706c 6974 2061 6363 6f72 6469 6e67 2074  plit according t
+00004220: 6f20 7468 6520 7472 616a 6563 746f 7269  o the trajectori
+00004230: 6573 2e0d 0a20 2020 2020 2020 2020 2020  es...           
+00004240: 2053 6565 203a 6675 6e63 3a60 7e74 6f72   See :func:`~tor
+00004250: 6368 726c 2e63 6f6c 6c65 6374 6f72 732e  chrl.collectors.
+00004260: 7574 696c 732e 7370 6c69 745f 7472 616a  utils.split_traj
+00004270: 6563 746f 7269 6573 6020 666f 7220 6d6f  ectories` for mo
+00004280: 7265 0d0a 2020 2020 2020 2020 2020 2020  re..            
+00004290: 696e 666f 726d 6174 696f 6e2e 0d0a 2020  information...  
+000042a0: 2020 2020 2020 2020 2020 4465 6661 756c            Defaul
+000042b0: 7473 2074 6f20 6060 4661 6c73 6560 602e  ts to ``False``.
+000042c0: 0d0a 2020 2020 2020 2020 6578 706c 6f72  ..        explor
+000042d0: 6174 696f 6e5f 7479 7065 2028 4578 706c  ation_type (Expl
+000042e0: 6f72 6174 696f 6e54 7970 652c 206f 7074  orationType, opt
+000042f0: 696f 6e61 6c29 3a20 696e 7465 7261 6374  ional): interact
+00004300: 696f 6e20 6d6f 6465 2074 6f20 6265 2075  ion mode to be u
+00004310: 7365 6420 7768 656e 0d0a 2020 2020 2020  sed when..      
+00004320: 2020 2020 2020 636f 6c6c 6563 7469 6e67        collecting
+00004330: 2064 6174 612e 204d 7573 7420 6265 206f   data. Must be o
+00004340: 6e65 206f 6620 6060 4578 706c 6f72 6174  ne of ``Explorat
+00004350: 696f 6e54 7970 652e 5241 4e44 4f4d 6060  ionType.RANDOM``
+00004360: 2c20 6060 4578 706c 6f72 6174 696f 6e54  , ``ExplorationT
+00004370: 7970 652e 4d4f 4445 6060 206f 720d 0a20  ype.MODE`` or.. 
+00004380: 2020 2020 2020 2020 2020 2060 6045 7870             ``Exp
+00004390: 6c6f 7261 7469 6f6e 5479 7065 2e4d 4541  lorationType.MEA
+000043a0: 4e60 602e 0d0a 2020 2020 2020 2020 2020  N``...          
+000043b0: 2020 4465 6661 756c 7473 2074 6f20 6060    Defaults to ``
+000043c0: 4578 706c 6f72 6174 696f 6e54 7970 652e  ExplorationType.
+000043d0: 5241 4e44 4f4d 6060 0d0a 2020 2020 2020  RANDOM``..      
+000043e0: 2020 7265 7475 726e 5f73 616d 655f 7464    return_same_td
+000043f0: 2028 626f 6f6c 2c20 6f70 7469 6f6e 616c   (bool, optional
+00004400: 293a 2069 6620 6060 5472 7565 6060 2c20  ): if ``True``, 
+00004410: 7468 6520 7361 6d65 2054 656e 736f 7244  the same TensorD
+00004420: 6963 740d 0a20 2020 2020 2020 2020 2020  ict..           
+00004430: 2077 696c 6c20 6265 2072 6574 7572 6e65   will be returne
+00004440: 6420 6174 2065 6163 6820 6974 6572 6174  d at each iterat
+00004450: 696f 6e2c 2077 6974 6820 6974 7320 7661  ion, with its va
+00004460: 6c75 6573 0d0a 2020 2020 2020 2020 2020  lues..          
+00004470: 2020 7570 6461 7465 642e 2054 6869 7320    updated. This 
+00004480: 6665 6174 7572 6520 7368 6f75 6c64 2062  feature should b
+00004490: 6520 7573 6564 2063 6175 7469 6f75 736c  e used cautiousl
+000044a0: 793a 2069 6620 7468 6520 7361 6d65 0d0a  y: if the same..
+000044b0: 2020 2020 2020 2020 2020 2020 7465 6e73              tens
+000044c0: 6f72 6469 6374 2069 7320 6164 6465 6420  ordict is added 
+000044d0: 746f 2061 2072 6570 6c61 7920 6275 6666  to a replay buff
+000044e0: 6572 2066 6f72 2069 6e73 7461 6e63 652c  er for instance,
+000044f0: 0d0a 2020 2020 2020 2020 2020 2020 7468  ..            th
+00004500: 6520 7768 6f6c 6520 636f 6e74 656e 7420  e whole content 
+00004510: 6f66 2074 6865 2062 7566 6665 7220 7769  of the buffer wi
+00004520: 6c6c 2062 6520 6964 656e 7469 6361 6c2e  ll be identical.
+00004530: 0d0a 2020 2020 2020 2020 2020 2020 4465  ..            De
+00004540: 6661 756c 7420 6973 2046 616c 7365 2e0d  fault is False..
+00004550: 0a20 2020 2020 2020 2069 6e74 6572 7275  .        interru
+00004560: 7074 6f72 2028 5f49 6e74 6572 7275 7074  ptor (_Interrupt
+00004570: 6f72 2c20 6f70 7469 6f6e 616c 293a 0d0a  or, optional):..
+00004580: 2020 2020 2020 2020 2020 2020 416e 205f              An _
+00004590: 496e 7465 7272 7570 746f 7220 6f62 6a65  Interruptor obje
+000045a0: 6374 2074 6861 7420 6361 6e20 6265 2075  ct that can be u
+000045b0: 7365 6420 6672 6f6d 206f 7574 7369 6465  sed from outside
+000045c0: 2074 6865 2063 6c61 7373 2074 6f20 636f   the class to co
+000045d0: 6e74 726f 6c20 726f 6c6c 6f75 7420 636f  ntrol rollout co
+000045e0: 6c6c 6563 7469 6f6e 2e0d 0a20 2020 2020  llection...     
+000045f0: 2020 2020 2020 2054 6865 205f 496e 7465         The _Inte
+00004600: 7272 7570 746f 7220 636c 6173 7320 6861  rruptor class ha
+00004610: 7320 6d65 7468 6f64 7320 c2b4 7374 6172  s methods ..star
+00004620: 745f 636f 6c6c 6563 7469 6f6e c2b4 2061  t_collection.. a
+00004630: 6e64 20c2 b473 746f 705f 636f 6c6c 6563  nd ..stop_collec
+00004640: 7469 6f6e c2b4 2c20 7768 6963 6820 616c  tion.., which al
+00004650: 6c6f 7720 746f 2069 6d70 6c65 6d65 6e74  low to implement
+00004660: 0d0a 2020 2020 2020 2020 2020 2020 7374  ..            st
+00004670: 7261 7465 6769 6573 2073 7563 6820 6173  rategies such as
+00004680: 2070 7265 6570 7469 7665 6c79 2073 746f   preeptively sto
+00004690: 7070 696e 6720 726f 6c6c 6f75 7420 636f  pping rollout co
+000046a0: 6c6c 6563 7469 6f6e 2e0d 0a20 2020 2020  llection...     
+000046b0: 2020 2020 2020 2044 6566 6175 6c74 2069         Default i
+000046c0: 7320 6060 4661 6c73 6560 602e 0d0a 2020  s ``False``...  
+000046d0: 2020 2020 2020 7265 7365 745f 7768 656e        reset_when
+000046e0: 5f64 6f6e 6520 2862 6f6f 6c2c 206f 7074  _done (bool, opt
+000046f0: 696f 6e61 6c29 3a20 6966 2060 6054 7275  ional): if ``Tru
+00004700: 6560 6020 2864 6566 6175 6c74 292c 2061  e`` (default), a
+00004710: 6e20 656e 7669 726f 6e6d 656e 740d 0a20  n environment.. 
+00004720: 2020 2020 2020 2020 2020 2074 6861 7420             that 
+00004730: 7265 7475 726e 2061 2060 6054 7275 6560  return a ``True`
+00004740: 6020 7661 6c75 6520 696e 2069 7473 2060  ` value in its `
+00004750: 6022 646f 6e65 2260 6020 6f72 2060 6022  `"done"`` or ``"
+00004760: 7472 756e 6361 7465 6422 6060 0d0a 2020  truncated"``..  
+00004770: 2020 2020 2020 2020 2020 656e 7472 7920            entry 
+00004780: 7769 6c6c 2062 6520 7265 7365 7420 6174  will be reset at
+00004790: 2074 6865 2063 6f72 7265 7370 6f6e 6469   the correspondi
+000047a0: 6e67 2069 6e64 6963 6573 2e0d 0a0d 0a20  ng indices..... 
+000047b0: 2020 2045 7861 6d70 6c65 733a 0d0a 2020     Examples:..  
+000047c0: 2020 2020 2020 3e3e 3e20 6672 6f6d 2074        >>> from t
+000047d0: 6f72 6368 726c 2e65 6e76 732e 6c69 6273  orchrl.envs.libs
+000047e0: 2e67 796d 2069 6d70 6f72 7420 4779 6d45  .gym import GymE
+000047f0: 6e76 0d0a 2020 2020 2020 2020 3e3e 3e20  nv..        >>> 
+00004800: 6672 6f6d 2074 656e 736f 7264 6963 742e  from tensordict.
+00004810: 6e6e 2069 6d70 6f72 7420 5465 6e73 6f72  nn import Tensor
+00004820: 4469 6374 4d6f 6475 6c65 0d0a 2020 2020  DictModule..    
+00004830: 2020 2020 3e3e 3e20 6672 6f6d 2074 6f72      >>> from tor
+00004840: 6368 2069 6d70 6f72 7420 6e6e 0d0a 2020  ch import nn..  
+00004850: 2020 2020 2020 3e3e 3e20 656e 765f 6d61        >>> env_ma
+00004860: 6b65 7220 3d20 6c61 6d62 6461 3a20 4779  ker = lambda: Gy
+00004870: 6d45 6e76 2822 5065 6e64 756c 756d 2d76  mEnv("Pendulum-v
+00004880: 3122 2c20 6465 7669 6365 3d22 6370 7522  1", device="cpu"
+00004890: 290d 0a20 2020 2020 2020 203e 3e3e 2070  )..        >>> p
+000048a0: 6f6c 6963 7920 3d20 5465 6e73 6f72 4469  olicy = TensorDi
+000048b0: 6374 4d6f 6475 6c65 286e 6e2e 4c69 6e65  ctModule(nn.Line
+000048c0: 6172 2833 2c20 3129 2c20 696e 5f6b 6579  ar(3, 1), in_key
+000048d0: 733d 5b22 6f62 7365 7276 6174 696f 6e22  s=["observation"
+000048e0: 5d2c 206f 7574 5f6b 6579 733d 5b22 6163  ], out_keys=["ac
+000048f0: 7469 6f6e 225d 290d 0a20 2020 2020 2020  tion"])..       
+00004900: 203e 3e3e 2063 6f6c 6c65 6374 6f72 203d   >>> collector =
+00004910: 2053 796e 6344 6174 6143 6f6c 6c65 6374   SyncDataCollect
+00004920: 6f72 280d 0a20 2020 2020 2020 202e 2e2e  or(..        ...
+00004930: 2020 2020 2063 7265 6174 655f 656e 765f       create_env_
+00004940: 666e 3d65 6e76 5f6d 616b 6572 2c0d 0a20  fn=env_maker,.. 
+00004950: 2020 2020 2020 202e 2e2e 2020 2020 2070         ...     p
+00004960: 6f6c 6963 793d 706f 6c69 6379 2c0d 0a20  olicy=policy,.. 
+00004970: 2020 2020 2020 202e 2e2e 2020 2020 2074         ...     t
+00004980: 6f74 616c 5f66 7261 6d65 733d 3230 3030  otal_frames=2000
+00004990: 2c0d 0a20 2020 2020 2020 202e 2e2e 2020  ,..        ...  
+000049a0: 2020 206d 6178 5f66 7261 6d65 735f 7065     max_frames_pe
+000049b0: 725f 7472 616a 3d35 302c 0d0a 2020 2020  r_traj=50,..    
+000049c0: 2020 2020 2e2e 2e20 2020 2020 6672 616d      ...     fram
+000049d0: 6573 5f70 6572 5f62 6174 6368 3d32 3030  es_per_batch=200
+000049e0: 2c0d 0a20 2020 2020 2020 202e 2e2e 2020  ,..        ...  
+000049f0: 2020 2069 6e69 745f 7261 6e64 6f6d 5f66     init_random_f
+00004a00: 7261 6d65 733d 2d31 2c0d 0a20 2020 2020  rames=-1,..     
+00004a10: 2020 202e 2e2e 2020 2020 2072 6573 6574     ...     reset
+00004a20: 5f61 745f 6561 6368 5f69 7465 723d 4661  _at_each_iter=Fa
+00004a30: 6c73 652c 0d0a 2020 2020 2020 2020 2e2e  lse,..        ..
+00004a40: 2e20 2020 2020 6465 7669 6365 3d22 6370  .     device="cp
+00004a50: 7522 2c0d 0a20 2020 2020 2020 202e 2e2e  u",..        ...
+00004a60: 2020 2020 2073 746f 7269 6e67 5f64 6576       storing_dev
+00004a70: 6963 653d 2263 7075 222c 0d0a 2020 2020  ice="cpu",..    
+00004a80: 2020 2020 2e2e 2e20 290d 0a20 2020 2020      ... )..     
+00004a90: 2020 203e 3e3e 2066 6f72 2069 2c20 6461     >>> for i, da
+00004aa0: 7461 2069 6e20 656e 756d 6572 6174 6528  ta in enumerate(
+00004ab0: 636f 6c6c 6563 746f 7229 3a0d 0a20 2020  collector):..   
+00004ac0: 2020 2020 202e 2e2e 2020 2020 2069 6620       ...     if 
+00004ad0: 6920 3d3d 2032 3a0d 0a20 2020 2020 2020  i == 2:..       
+00004ae0: 202e 2e2e 2020 2020 2020 2020 2070 7269   ...         pri
+00004af0: 6e74 2864 6174 6129 0d0a 2020 2020 2020  nt(data)..      
+00004b00: 2020 2e2e 2e20 2020 2020 2020 2020 6272    ...         br
+00004b10: 6561 6b0d 0a20 2020 2020 2020 2054 656e  eak..        Ten
+00004b20: 736f 7244 6963 7428 0d0a 2020 2020 2020  sorDict(..      
+00004b30: 2020 2020 2020 6669 656c 6473 3d7b 0d0a        fields={..
+00004b40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004b50: 6163 7469 6f6e 3a20 5465 6e73 6f72 2873  action: Tensor(s
+00004b60: 6861 7065 3d74 6f72 6368 2e53 697a 6528  hape=torch.Size(
+00004b70: 5b34 2c20 3530 2c20 315d 292c 2064 6576  [4, 50, 1]), dev
+00004b80: 6963 653d 6370 752c 2064 7479 7065 3d74  ice=cpu, dtype=t
+00004b90: 6f72 6368 2e66 6c6f 6174 3332 2c20 6973  orch.float32, is
+00004ba0: 5f73 6861 7265 643d 4661 6c73 6529 2c0d  _shared=False),.
+00004bb0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00004bc0: 2063 6f6c 6c65 6374 6f72 3a20 5465 6e73   collector: Tens
+00004bd0: 6f72 4469 6374 280d 0a20 2020 2020 2020  orDict(..       
+00004be0: 2020 2020 2020 2020 2020 2020 2066 6965               fie
+00004bf0: 6c64 733d 7b0d 0a20 2020 2020 2020 2020  lds={..         
+00004c00: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+00004c10: 7465 705f 636f 756e 743a 2054 656e 736f  tep_count: Tenso
+00004c20: 7228 7368 6170 653d 746f 7263 682e 5369  r(shape=torch.Si
+00004c30: 7a65 285b 342c 2035 305d 292c 2064 6576  ze([4, 50]), dev
+00004c40: 6963 653d 6370 752c 2064 7479 7065 3d74  ice=cpu, dtype=t
+00004c50: 6f72 6368 2e69 6e74 3634 2c20 6973 5f73  orch.int64, is_s
+00004c60: 6861 7265 643d 4661 6c73 6529 2c0d 0a20  hared=False),.. 
 00004c70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004c80: 2020 2029 0d0a 2020 2020 2020 2020 2020     )..          
-00004c90: 2020 2020 2020 656e 762e 7570 6461 7465        env.update
-00004ca0: 5f6b 7761 7267 7328 6372 6561 7465 5f65  _kwargs(create_e
-00004cb0: 6e76 5f6b 7761 7267 7329 0d0a 0d0a 2020  nv_kwargs)....  
-00004cc0: 2020 2020 2020 6966 2073 746f 7269 6e67        if storing
-00004cd0: 5f64 6576 6963 6520 6973 204e 6f6e 653a  _device is None:
-00004ce0: 0d0a 2020 2020 2020 2020 2020 2020 6966  ..            if
-00004cf0: 2064 6576 6963 6520 6973 206e 6f74 204e   device is not N
-00004d00: 6f6e 653a 0d0a 2020 2020 2020 2020 2020  one:..          
-00004d10: 2020 2020 2020 7374 6f72 696e 675f 6465        storing_de
-00004d20: 7669 6365 203d 2064 6576 6963 650d 0a20  vice = device.. 
-00004d30: 2020 2020 2020 2020 2020 2065 6c69 6620             elif 
-00004d40: 706f 6c69 6379 2069 7320 6e6f 7420 4e6f  policy is not No
-00004d50: 6e65 3a0d 0a20 2020 2020 2020 2020 2020  ne:..           
-00004d60: 2020 2020 2074 7279 3a0d 0a20 2020 2020       try:..     
-00004d70: 2020 2020 2020 2020 2020 2020 2020 2070                 p
-00004d80: 6f6c 6963 795f 6465 7669 6365 203d 206e  olicy_device = n
-00004d90: 6578 7428 706f 6c69 6379 2e70 6172 616d  ext(policy.param
-00004da0: 6574 6572 7328 2929 2e64 6576 6963 650d  eters()).device.
-00004db0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00004dc0: 2065 7863 6570 7420 2841 7474 7269 6275   except (Attribu
-00004dd0: 7465 4572 726f 722c 2053 746f 7049 7465  teError, StopIte
-00004de0: 7261 7469 6f6e 293a 0d0a 2020 2020 2020  ration):..      
-00004df0: 2020 2020 2020 2020 2020 2020 2020 706f                po
-00004e00: 6c69 6379 5f64 6576 6963 6520 3d20 746f  licy_device = to
-00004e10: 7263 682e 6465 7669 6365 2822 6370 7522  rch.device("cpu"
-00004e20: 290d 0a20 2020 2020 2020 2020 2020 2020  )..             
-00004e30: 2020 2073 746f 7269 6e67 5f64 6576 6963     storing_devic
-00004e40: 6520 3d20 706f 6c69 6379 5f64 6576 6963  e = policy_devic
-00004e50: 650d 0a20 2020 2020 2020 2020 2020 2065  e..            e
-00004e60: 6c73 653a 0d0a 2020 2020 2020 2020 2020  lse:..          
-00004e70: 2020 2020 2020 7374 6f72 696e 675f 6465        storing_de
-00004e80: 7669 6365 203d 2074 6f72 6368 2e64 6576  vice = torch.dev
-00004e90: 6963 6528 2263 7075 2229 0d0a 0d0a 2020  ice("cpu")....  
-00004ea0: 2020 2020 2020 7365 6c66 2e73 746f 7269        self.stori
-00004eb0: 6e67 5f64 6576 6963 6520 3d20 746f 7263  ng_device = torc
-00004ec0: 682e 6465 7669 6365 2873 746f 7269 6e67  h.device(storing
-00004ed0: 5f64 6576 6963 6529 0d0a 2020 2020 2020  _device)..      
-00004ee0: 2020 7365 6c66 2e65 6e76 3a20 456e 7642    self.env: EnvB
-00004ef0: 6173 6520 3d20 656e 760d 0a20 2020 2020  ase = env..     
-00004f00: 2020 2073 656c 662e 636c 6f73 6564 203d     self.closed =
-00004f10: 2046 616c 7365 0d0a 2020 2020 2020 2020   False..        
-00004f20: 7365 6c66 2e72 6573 6574 5f77 6865 6e5f  self.reset_when_
-00004f30: 646f 6e65 203d 2072 6573 6574 5f77 6865  done = reset_whe
-00004f40: 6e5f 646f 6e65 0d0a 2020 2020 2020 2020  n_done..        
-00004f50: 7365 6c66 2e6e 5f65 6e76 203d 2073 656c  self.n_env = sel
-00004f60: 662e 656e 762e 6261 7463 685f 7369 7a65  f.env.batch_size
-00004f70: 2e6e 756d 656c 2829 0d0a 0d0a 2020 2020  .numel()....    
-00004f80: 2020 2020 2873 656c 662e 706f 6c69 6379      (self.policy
-00004f90: 2c20 7365 6c66 2e64 6576 6963 652c 2073  , self.device, s
-00004fa0: 656c 662e 6765 745f 7765 6967 6874 735f  elf.get_weights_
-00004fb0: 666e 2c29 203d 2073 656c 662e 5f67 6574  fn,) = self._get
-00004fc0: 5f70 6f6c 6963 795f 616e 645f 6465 7669  _policy_and_devi
-00004fd0: 6365 280d 0a20 2020 2020 2020 2020 2020  ce(..           
-00004fe0: 2070 6f6c 6963 793d 706f 6c69 6379 2c0d   policy=policy,.
-00004ff0: 0a20 2020 2020 2020 2020 2020 2064 6576  .            dev
-00005000: 6963 653d 6465 7669 6365 2c0d 0a20 2020  ice=device,..   
-00005010: 2020 2020 2020 2020 206f 6273 6572 7661           observa
-00005020: 7469 6f6e 5f73 7065 633d 7365 6c66 2e65  tion_spec=self.e
-00005030: 6e76 2e6f 6273 6572 7661 7469 6f6e 5f73  nv.observation_s
-00005040: 7065 632c 0d0a 2020 2020 2020 2020 290d  pec,..        ).
-00005050: 0a20 2020 2020 2020 2069 6620 6973 696e  .        if isin
-00005060: 7374 616e 6365 2873 656c 662e 706f 6c69  stance(self.poli
-00005070: 6379 2c20 6e6e 2e4d 6f64 756c 6529 3a0d  cy, nn.Module):.
-00005080: 0a20 2020 2020 2020 2020 2020 2073 656c  .            sel
-00005090: 662e 706f 6c69 6379 5f77 6569 6768 7473  f.policy_weights
-000050a0: 203d 2054 656e 736f 7244 6963 7428 6469   = TensorDict(di
-000050b0: 6374 2873 656c 662e 706f 6c69 6379 2e6e  ct(self.policy.n
-000050c0: 616d 6564 5f70 6172 616d 6574 6572 7328  amed_parameters(
-000050d0: 2929 2c20 5b5d 290d 0a20 2020 2020 2020  )), [])..       
-000050e0: 2065 6c73 653a 0d0a 2020 2020 2020 2020   else:..        
-000050f0: 2020 2020 7365 6c66 2e70 6f6c 6963 795f      self.policy_
-00005100: 7765 6967 6874 7320 3d20 5465 6e73 6f72  weights = Tensor
-00005110: 4469 6374 287b 7d2c 205b 5d29 0d0a 0d0a  Dict({}, [])....
-00005120: 2020 2020 2020 2020 7365 6c66 2e65 6e76          self.env
-00005130: 3a20 456e 7642 6173 6520 3d20 7365 6c66  : EnvBase = self
-00005140: 2e65 6e76 2e74 6f28 7365 6c66 2e64 6576  .env.to(self.dev
-00005150: 6963 6529 0d0a 2020 2020 2020 2020 7365  ice)..        se
-00005160: 6c66 2e6d 6178 5f66 7261 6d65 735f 7065  lf.max_frames_pe
-00005170: 725f 7472 616a 203d 206d 6178 5f66 7261  r_traj = max_fra
-00005180: 6d65 735f 7065 725f 7472 616a 0d0a 2020  mes_per_traj..  
-00005190: 2020 2020 2020 6966 2073 656c 662e 6d61        if self.ma
-000051a0: 785f 6672 616d 6573 5f70 6572 5f74 7261  x_frames_per_tra
-000051b0: 6a20 3e20 303a 0d0a 2020 2020 2020 2020  j > 0:..        
-000051c0: 2020 2020 656e 7620 3d20 7365 6c66 2e65      env = self.e
-000051d0: 6e76 203d 2054 7261 6e73 666f 726d 6564  nv = Transformed
-000051e0: 456e 7628 0d0a 2020 2020 2020 2020 2020  Env(..          
-000051f0: 2020 2020 2020 7365 6c66 2e65 6e76 2c20        self.env, 
-00005200: 5374 6570 436f 756e 7465 7228 6d61 785f  StepCounter(max_
-00005210: 7374 6570 733d 7365 6c66 2e6d 6178 5f66  steps=self.max_f
-00005220: 7261 6d65 735f 7065 725f 7472 616a 290d  rames_per_traj).
-00005230: 0a20 2020 2020 2020 2020 2020 2029 0d0a  .            )..
-00005240: 0d0a 2020 2020 2020 2020 6966 2074 6f74  ..        if tot
-00005250: 616c 5f66 7261 6d65 7320 6973 204e 6f6e  al_frames is Non
-00005260: 6520 6f72 2074 6f74 616c 5f66 7261 6d65  e or total_frame
-00005270: 7320 3c20 303a 0d0a 2020 2020 2020 2020  s < 0:..        
-00005280: 2020 2020 746f 7461 6c5f 6672 616d 6573      total_frames
-00005290: 203d 2066 6c6f 6174 2822 696e 6622 290d   = float("inf").
-000052a0: 0a20 2020 2020 2020 2065 6c73 653a 0d0a  .        else:..
-000052b0: 2020 2020 2020 2020 2020 2020 6966 2074              if t
-000052c0: 6f74 616c 5f66 7261 6d65 7320 2520 6672  otal_frames % fr
-000052d0: 616d 6573 5f70 6572 5f62 6174 6368 2021  ames_per_batch !
-000052e0: 3d20 303a 0d0a 2020 2020 2020 2020 2020  = 0:..          
-000052f0: 2020 2020 2020 7261 6973 6520 5661 6c75        raise Valu
-00005300: 6545 7272 6f72 280d 0a20 2020 2020 2020  eError(..       
-00005310: 2020 2020 2020 2020 2020 2020 2066 2274               f"t
-00005320: 6f74 616c 5f66 7261 6d65 7320 287b 746f  otal_frames ({to
-00005330: 7461 6c5f 6672 616d 6573 7d29 206d 7573  tal_frames}) mus
-00005340: 7420 6265 2064 6976 6973 6962 6c65 2062  t be divisible b
-00005350: 7920 6672 616d 6573 5f70 6572 5f62 6174  y frames_per_bat
-00005360: 6368 2028 7b66 7261 6d65 735f 7065 725f  ch ({frames_per_
-00005370: 6261 7463 687d 292e 220d 0a20 2020 2020  batch})."..     
-00005380: 2020 2020 2020 2020 2020 2029 0d0a 2020             )..  
-00005390: 2020 2020 2020 7365 6c66 2e74 6f74 616c        self.total
-000053a0: 5f66 7261 6d65 7320 3d20 746f 7461 6c5f  _frames = total_
-000053b0: 6672 616d 6573 0d0a 2020 2020 2020 2020  frames..        
-000053c0: 7365 6c66 2e72 6573 6574 5f61 745f 6561  self.reset_at_ea
-000053d0: 6368 5f69 7465 7220 3d20 7265 7365 745f  ch_iter = reset_
-000053e0: 6174 5f65 6163 685f 6974 6572 0d0a 2020  at_each_iter..  
-000053f0: 2020 2020 2020 7365 6c66 2e69 6e69 745f        self.init_
-00005400: 7261 6e64 6f6d 5f66 7261 6d65 7320 3d20  random_frames = 
-00005410: 696e 6974 5f72 616e 646f 6d5f 6672 616d  init_random_fram
-00005420: 6573 0d0a 2020 2020 2020 2020 7365 6c66  es..        self
-00005430: 2e70 6f73 7470 726f 6320 3d20 706f 7374  .postproc = post
-00005440: 7072 6f63 0d0a 2020 2020 2020 2020 6966  proc..        if
-00005450: 2073 656c 662e 706f 7374 7072 6f63 2069   self.postproc i
-00005460: 7320 6e6f 7420 4e6f 6e65 3a0d 0a20 2020  s not None:..   
-00005470: 2020 2020 2020 2020 2073 656c 662e 706f           self.po
-00005480: 7374 7072 6f63 2e74 6f28 7365 6c66 2e73  stproc.to(self.s
-00005490: 746f 7269 6e67 5f64 6576 6963 6529 0d0a  toring_device)..
-000054a0: 2020 2020 2020 2020 7365 6c66 2e66 7261          self.fra
-000054b0: 6d65 735f 7065 725f 6261 7463 6820 3d20  mes_per_batch = 
-000054c0: 2d28 2d66 7261 6d65 735f 7065 725f 6261  -(-frames_per_ba
-000054d0: 7463 6820 2f2f 2073 656c 662e 6e5f 656e  tch // self.n_en
-000054e0: 7629 0d0a 2020 2020 2020 2020 7365 6c66  v)..        self
-000054f0: 2e65 7870 6c6f 7261 7469 6f6e 5f6d 6f64  .exploration_mod
-00005500: 6520 3d20 280d 0a20 2020 2020 2020 2020  e = (..         
-00005510: 2020 2065 7870 6c6f 7261 7469 6f6e 5f6d     exploration_m
-00005520: 6f64 6520 6966 2065 7870 6c6f 7261 7469  ode if explorati
-00005530: 6f6e 5f6d 6f64 6520 656c 7365 2044 4546  on_mode else DEF
-00005540: 4155 4c54 5f45 5850 4c4f 5241 5449 4f4e  AULT_EXPLORATION
-00005550: 5f4d 4f44 450d 0a20 2020 2020 2020 2029  _MODE..        )
-00005560: 0d0a 2020 2020 2020 2020 7365 6c66 2e72  ..        self.r
-00005570: 6574 7572 6e5f 7361 6d65 5f74 6420 3d20  eturn_same_td = 
-00005580: 7265 7475 726e 5f73 616d 655f 7464 0d0a  return_same_td..
-00005590: 0d0a 2020 2020 2020 2020 7365 6c66 2e5f  ..        self._
-000055a0: 7465 6e73 6f72 6469 6374 203d 2065 6e76  tensordict = env
-000055b0: 2e72 6573 6574 2829 0d0a 2020 2020 2020  .reset()..      
-000055c0: 2020 6e20 3d20 7365 6c66 2e65 6e76 2e62    n = self.env.b
-000055d0: 6174 6368 5f73 697a 652e 6e75 6d65 6c28  atch_size.numel(
-000055e0: 2920 6966 206c 656e 2873 656c 662e 656e  ) if len(self.en
-000055f0: 762e 6261 7463 685f 7369 7a65 2920 656c  v.batch_size) el
-00005600: 7365 2031 0d0a 2020 2020 2020 2020 7472  se 1..        tr
-00005610: 616a 5f69 6473 203d 2074 6f72 6368 2e61  aj_ids = torch.a
-00005620: 7261 6e67 6528 6e2c 2064 6576 6963 653d  range(n, device=
-00005630: 656e 762e 6465 7669 6365 292e 7669 6577  env.device).view
-00005640: 2873 656c 662e 656e 762e 6261 7463 685f  (self.env.batch_
-00005650: 7369 7a65 290d 0a20 2020 2020 2020 2073  size)..        s
-00005660: 656c 662e 5f74 656e 736f 7264 6963 742e  elf._tensordict.
-00005670: 7365 7428 0d0a 2020 2020 2020 2020 2020  set(..          
-00005680: 2020 2822 636f 6c6c 6563 746f 7222 2c20    ("collector", 
-00005690: 2274 7261 6a5f 6964 7322 292c 0d0a 2020  "traj_ids"),..  
-000056a0: 2020 2020 2020 2020 2020 7472 616a 5f69            traj_i
-000056b0: 6473 2c0d 0a20 2020 2020 2020 2029 0d0a  ds,..        )..
-000056c0: 0d0a 2020 2020 2020 2020 6966 2028 0d0a  ..        if (..
-000056d0: 2020 2020 2020 2020 2020 2020 6861 7361              hasa
-000056e0: 7474 7228 7365 6c66 2e70 6f6c 6963 792c  ttr(self.policy,
-000056f0: 2022 7370 6563 2229 0d0a 2020 2020 2020   "spec")..      
-00005700: 2020 2020 2020 616e 6420 7365 6c66 2e70        and self.p
-00005710: 6f6c 6963 792e 7370 6563 2069 7320 6e6f  olicy.spec is no
-00005720: 7420 4e6f 6e65 0d0a 2020 2020 2020 2020  t None..        
-00005730: 2020 2020 616e 6420 616c 6c28 7620 6973      and all(v is
-00005740: 206e 6f74 204e 6f6e 6520 666f 7220 7620   not None for v 
-00005750: 696e 2073 656c 662e 706f 6c69 6379 2e73  in self.policy.s
-00005760: 7065 632e 7661 6c75 6573 2829 290d 0a20  pec.values()).. 
-00005770: 2020 2020 2020 2020 2020 2061 6e64 2073             and s
-00005780: 6574 2873 656c 662e 706f 6c69 6379 2e73  et(self.policy.s
-00005790: 7065 632e 6b65 7973 2854 7275 652c 2054  pec.keys(True, T
-000057a0: 7275 6529 2920 3d3d 2073 6574 2873 656c  rue)) == set(sel
-000057b0: 662e 706f 6c69 6379 2e6f 7574 5f6b 6579  f.policy.out_key
-000057c0: 7329 0d0a 2020 2020 2020 2020 293a 0d0a  s)..        ):..
-000057d0: 2020 2020 2020 2020 2020 2020 2320 6966              # if
-000057e0: 2070 6f6c 6963 7920 7370 6563 2069 7320   policy spec is 
-000057f0: 6e6f 6e2d 656d 7074 792c 2061 6c6c 2074  non-empty, all t
-00005800: 6865 2076 616c 7565 7320 6172 6520 6e6f  he values are no
-00005810: 7420 4e6f 6e65 2061 6e64 2074 6865 206b  t None and the k
-00005820: 6579 730d 0a20 2020 2020 2020 2020 2020  eys..           
-00005830: 2023 206d 6174 6368 2074 6865 206f 7574   # match the out
-00005840: 5f6b 6579 7320 7765 2061 7373 756d 6520  _keys we assume 
-00005850: 7468 6520 7573 6572 2068 6173 2067 6976  the user has giv
-00005860: 656e 2061 6c6c 2072 656c 6576 616e 7420  en all relevant 
-00005870: 696e 666f 726d 6174 696f 6e0d 0a20 2020  information..   
-00005880: 2020 2020 2020 2020 2073 656c 662e 5f74           self._t
-00005890: 656e 736f 7264 6963 745f 6f75 7420 3d20  ensordict_out = 
-000058a0: 656e 762e 6661 6b65 5f74 656e 736f 7264  env.fake_tensord
-000058b0: 6963 7428 292e 746f 5f74 656e 736f 7264  ict().to_tensord
-000058c0: 6963 7428 290d 0a20 2020 2020 2020 2020  ict()..         
-000058d0: 2020 2073 656c 662e 5f74 656e 736f 7264     self._tensord
-000058e0: 6963 745f 6f75 742e 7570 6461 7465 2873  ict_out.update(s
-000058f0: 656c 662e 706f 6c69 6379 2e73 7065 632e  elf.policy.spec.
-00005900: 7a65 726f 2829 290d 0a20 2020 2020 2020  zero())..       
-00005910: 2020 2020 2073 656c 662e 5f74 656e 736f       self._tenso
-00005920: 7264 6963 745f 6f75 7420 3d20 280d 0a20  rdict_out = (.. 
-00005930: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-00005940: 656c 662e 5f74 656e 736f 7264 6963 745f  elf._tensordict_
-00005950: 6f75 742e 756e 7371 7565 657a 6528 2d31  out.unsqueeze(-1
-00005960: 290d 0a20 2020 2020 2020 2020 2020 2020  )..             
-00005970: 2020 202e 6578 7061 6e64 282a 656e 762e     .expand(*env.
-00005980: 6261 7463 685f 7369 7a65 2c20 7365 6c66  batch_size, self
-00005990: 2e66 7261 6d65 735f 7065 725f 6261 7463  .frames_per_batc
-000059a0: 6829 0d0a 2020 2020 2020 2020 2020 2020  h)..            
-000059b0: 2020 2020 2e74 6f5f 7465 6e73 6f72 6469      .to_tensordi
-000059c0: 6374 2829 0d0a 2020 2020 2020 2020 2020  ct()..          
-000059d0: 2020 290d 0a20 2020 2020 2020 2065 6c73    )..        els
-000059e0: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
-000059f0: 2320 6f74 6865 7277 6973 652c 2077 6520  # otherwise, we 
-00005a00: 7065 7266 6f72 6d20 6120 736d 616c 6c20  perform a small 
-00005a10: 6e75 6d62 6572 206f 6620 7374 6570 7320  number of steps 
-00005a20: 7769 7468 2074 6865 2070 6f6c 6963 7920  with the policy 
-00005a30: 746f 0d0a 2020 2020 2020 2020 2020 2020  to..            
-00005a40: 2320 6465 7465 726d 696e 6520 7468 6520  # determine the 
-00005a50: 7265 6c65 7661 6e74 206b 6579 7320 7769  relevant keys wi
-00005a60: 7468 2077 6869 6368 2074 6f20 7072 652d  th which to pre-
-00005a70: 706f 7075 6c61 7465 205f 7465 6e73 6f72  populate _tensor
-00005a80: 6469 6374 5f6f 7574 2e0d 0a20 2020 2020  dict_out...     
-00005a90: 2020 2020 2020 2023 2053 6565 2023 3530         # See #50
-00005aa0: 3520 666f 7220 6164 6469 7469 6f6e 616c  5 for additional
-00005ab0: 2063 6f6e 7465 7874 2e0d 0a20 2020 2020   context...     
-00005ac0: 2020 2020 2020 2077 6974 6820 746f 7263         with torc
-00005ad0: 682e 6e6f 5f67 7261 6428 293a 0d0a 2020  h.no_grad():..  
-00005ae0: 2020 2020 2020 2020 2020 2020 2020 7365                se
-00005af0: 6c66 2e5f 7465 6e73 6f72 6469 6374 5f6f  lf._tensordict_o
-00005b00: 7574 203d 2065 6e76 2e66 616b 655f 7465  ut = env.fake_te
-00005b10: 6e73 6f72 6469 6374 2829 0d0a 2020 2020  nsordict()..    
-00005b20: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-00005b30: 2e5f 7465 6e73 6f72 6469 6374 5f6f 7574  ._tensordict_out
-00005b40: 203d 2073 656c 662e 5f74 656e 736f 7264   = self._tensord
-00005b50: 6963 745f 6f75 742e 746f 2873 656c 662e  ict_out.to(self.
-00005b60: 6465 7669 6365 290d 0a20 2020 2020 2020  device)..       
-00005b70: 2020 2020 2020 2020 2073 656c 662e 5f74           self._t
-00005b80: 656e 736f 7264 6963 745f 6f75 7420 3d20  ensordict_out = 
-00005b90: 7365 6c66 2e70 6f6c 6963 7928 7365 6c66  self.policy(self
-00005ba0: 2e5f 7465 6e73 6f72 6469 6374 5f6f 7574  ._tensordict_out
-00005bb0: 292e 756e 7371 7565 657a 6528 2d31 290d  ).unsqueeze(-1).
-00005bc0: 0a20 2020 2020 2020 2020 2020 2073 656c  .            sel
-00005bd0: 662e 5f74 656e 736f 7264 6963 745f 6f75  f._tensordict_ou
-00005be0: 7420 3d20 280d 0a20 2020 2020 2020 2020  t = (..         
-00005bf0: 2020 2020 2020 2073 656c 662e 5f74 656e         self._ten
-00005c00: 736f 7264 6963 745f 6f75 742e 6578 7061  sordict_out.expa
-00005c10: 6e64 282a 656e 762e 6261 7463 685f 7369  nd(*env.batch_si
-00005c20: 7a65 2c20 7365 6c66 2e66 7261 6d65 735f  ze, self.frames_
-00005c30: 7065 725f 6261 7463 6829 0d0a 2020 2020  per_batch)..    
-00005c40: 2020 2020 2020 2020 2020 2020 2e74 6f5f              .to_
-00005c50: 7465 6e73 6f72 6469 6374 2829 0d0a 2020  tensordict()..  
-00005c60: 2020 2020 2020 2020 2020 2020 2020 2e7a                .z
-00005c70: 6572 6f5f 2829 0d0a 2020 2020 2020 2020  ero_()..        
-00005c80: 2020 2020 290d 0a20 2020 2020 2020 2023      )..        #
-00005c90: 2069 6e20 6164 6469 7469 6f6e 2074 6f20   in addition to 
-00005ca0: 6f75 7470 7574 7320 6f66 2074 6865 2070  outputs of the p
-00005cb0: 6f6c 6963 792c 2077 6520 6164 6420 7472  olicy, we add tr
-00005cc0: 616a 5f69 6473 2061 6e64 2073 7465 705f  aj_ids and step_
-00005cd0: 636f 756e 7420 746f 0d0a 2020 2020 2020  count to..      
-00005ce0: 2020 2320 5f74 656e 736f 7264 6963 745f    # _tensordict_
-00005cf0: 6f75 7420 7768 6963 6820 7769 6c6c 2062  out which will b
-00005d00: 6520 636f 6c6c 6563 7465 6420 6475 7269  e collected duri
-00005d10: 6e67 2072 6f6c 6c6f 7574 0d0a 2020 2020  ng rollout..    
-00005d20: 2020 2020 7365 6c66 2e5f 7465 6e73 6f72      self._tensor
-00005d30: 6469 6374 5f6f 7574 203d 2073 656c 662e  dict_out = self.
-00005d40: 5f74 656e 736f 7264 6963 745f 6f75 742e  _tensordict_out.
-00005d50: 746f 2873 656c 662e 7374 6f72 696e 675f  to(self.storing_
-00005d60: 6465 7669 6365 290d 0a20 2020 2020 2020  device)..       
-00005d70: 2073 656c 662e 5f74 656e 736f 7264 6963   self._tensordic
-00005d80: 745f 6f75 742e 7365 7428 0d0a 2020 2020  t_out.set(..    
-00005d90: 2020 2020 2020 2020 2822 636f 6c6c 6563          ("collec
-00005da0: 746f 7222 2c20 2274 7261 6a5f 6964 7322  tor", "traj_ids"
-00005db0: 292c 0d0a 2020 2020 2020 2020 2020 2020  ),..            
-00005dc0: 746f 7263 682e 7a65 726f 7328 0d0a 2020  torch.zeros(..  
-00005dd0: 2020 2020 2020 2020 2020 2020 2020 2a73                *s
-00005de0: 656c 662e 5f74 656e 736f 7264 6963 745f  elf._tensordict_
-00005df0: 6f75 742e 6261 7463 685f 7369 7a65 2c0d  out.batch_size,.
-00005e00: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00005e10: 2064 7479 7065 3d74 6f72 6368 2e69 6e74   dtype=torch.int
-00005e20: 3634 2c0d 0a20 2020 2020 2020 2020 2020  64,..           
-00005e30: 2020 2020 2064 6576 6963 653d 7365 6c66       device=self
-00005e40: 2e73 746f 7269 6e67 5f64 6576 6963 652c  .storing_device,
-00005e50: 0d0a 2020 2020 2020 2020 2020 2020 292c  ..            ),
-00005e60: 0d0a 2020 2020 2020 2020 290d 0a0d 0a20  ..        ).... 
-00005e70: 2020 2020 2020 2069 6620 7370 6c69 745f         if split_
-00005e80: 7472 616a 7320 6973 204e 6f6e 653a 0d0a  trajs is None:..
-00005e90: 2020 2020 2020 2020 2020 2020 7370 6c69              spli
-00005ea0: 745f 7472 616a 7320 3d20 4661 6c73 650d  t_trajs = False.
-00005eb0: 0a20 2020 2020 2020 2065 6c69 6620 6e6f  .        elif no
-00005ec0: 7420 7365 6c66 2e72 6573 6574 5f77 6865  t self.reset_whe
-00005ed0: 6e5f 646f 6e65 2061 6e64 2073 706c 6974  n_done and split
-00005ee0: 5f74 7261 6a73 3a0d 0a20 2020 2020 2020  _trajs:..       
-00005ef0: 2020 2020 2072 6169 7365 2052 756e 7469       raise Runti
-00005f00: 6d65 4572 726f 7228 0d0a 2020 2020 2020  meError(..      
-00005f10: 2020 2020 2020 2020 2020 2243 616e 6e6f            "Canno
-00005f20: 7420 7370 6c69 7420 7472 616a 6563 746f  t split trajecto
-00005f30: 7269 6573 2077 6865 6e20 7265 7365 745f  ries when reset_
-00005f40: 7768 656e 5f64 6f6e 6520 6973 2046 616c  when_done is Fal
-00005f50: 7365 2e22 0d0a 2020 2020 2020 2020 2020  se."..          
-00005f60: 2020 290d 0a20 2020 2020 2020 2073 656c    )..        sel
-00005f70: 662e 7370 6c69 745f 7472 616a 7320 3d20  f.split_trajs = 
-00005f80: 7370 6c69 745f 7472 616a 730d 0a20 2020  split_trajs..   
-00005f90: 2020 2020 2073 656c 662e 5f68 6173 5f62       self._has_b
-00005fa0: 6565 6e5f 646f 6e65 203d 204e 6f6e 650d  een_done = None.
-00005fb0: 0a20 2020 2020 2020 2073 656c 662e 5f65  .        self._e
-00005fc0: 7863 6c75 6465 5f70 7269 7661 7465 5f6b  xclude_private_k
-00005fd0: 6579 7320 3d20 5472 7565 0d0a 0d0a 2020  eys = True....  
-00005fe0: 2020 2320 666f 7220 5250 430d 0a20 2020    # for RPC..   
-00005ff0: 2064 6566 206e 6578 7428 7365 6c66 293a   def next(self):
-00006000: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
-00006010: 2073 7570 6572 2829 2e6e 6578 7428 290d   super().next().
-00006020: 0a0d 0a20 2020 2023 2066 6f72 2052 5043  ...    # for RPC
-00006030: 0d0a 2020 2020 6465 6620 7570 6461 7465  ..    def update
-00006040: 5f70 6f6c 6963 795f 7765 6967 6874 735f  _policy_weights_
-00006050: 280d 0a20 2020 2020 2020 2073 656c 662c  (..        self,
-00006060: 2070 6f6c 6963 795f 7765 6967 6874 733a   policy_weights:
-00006070: 204f 7074 696f 6e61 6c5b 5465 6e73 6f72   Optional[Tensor
-00006080: 4469 6374 4261 7365 5d20 3d20 4e6f 6e65  DictBase] = None
-00006090: 0d0a 2020 2020 2920 2d3e 204e 6f6e 653a  ..    ) -> None:
-000060a0: 0d0a 2020 2020 2020 2020 7375 7065 7228  ..        super(
-000060b0: 292e 7570 6461 7465 5f70 6f6c 6963 795f  ).update_policy_
-000060c0: 7765 6967 6874 735f 2870 6f6c 6963 795f  weights_(policy_
-000060d0: 7765 6967 6874 7329 0d0a 0d0a 2020 2020  weights)....    
-000060e0: 6465 6620 7365 745f 7365 6564 2873 656c  def set_seed(sel
-000060f0: 662c 2073 6565 643a 2069 6e74 2c20 7374  f, seed: int, st
-00006100: 6174 6963 5f73 6565 643a 2062 6f6f 6c20  atic_seed: bool 
-00006110: 3d20 4661 6c73 6529 202d 3e20 696e 743a  = False) -> int:
-00006120: 0d0a 2020 2020 2020 2020 2222 2253 6574  ..        """Set
-00006130: 7320 7468 6520 7365 6564 7320 6f66 2074  s the seeds of t
-00006140: 6865 2065 6e76 6972 6f6e 6d65 6e74 7320  he environments 
-00006150: 7374 6f72 6564 2069 6e20 7468 6520 4461  stored in the Da
-00006160: 7461 436f 6c6c 6563 746f 722e 0d0a 0d0a  taCollector.....
-00006170: 2020 2020 2020 2020 4172 6773 3a0d 0a20          Args:.. 
-00006180: 2020 2020 2020 2020 2020 2073 6565 6420             seed 
-00006190: 2869 6e74 293a 2069 6e74 6567 6572 2072  (int): integer r
-000061a0: 6570 7265 7365 6e74 696e 6720 7468 6520  epresenting the 
-000061b0: 7365 6564 2074 6f20 6265 2075 7365 6420  seed to be used 
-000061c0: 666f 7220 7468 6520 656e 7669 726f 6e6d  for the environm
-000061d0: 656e 742e 0d0a 2020 2020 2020 2020 2020  ent...          
-000061e0: 2020 7374 6174 6963 5f73 6565 6428 626f    static_seed(bo
-000061f0: 6f6c 2c20 6f70 7469 6f6e 616c 293a 2069  ol, optional): i
-00006200: 6620 5472 7565 2c20 7468 6520 7365 6564  f True, the seed
-00006210: 2069 7320 6e6f 7420 696e 6372 656d 656e   is not incremen
-00006220: 7465 642e 0d0a 2020 2020 2020 2020 2020  ted...          
-00006230: 2020 2020 2020 4465 6661 756c 7473 2074        Defaults t
-00006240: 6f20 4661 6c73 650d 0a0d 0a20 2020 2020  o False....     
-00006250: 2020 2052 6574 7572 6e73 3a0d 0a20 2020     Returns:..   
-00006260: 2020 2020 2020 2020 204f 7574 7075 7420           Output 
-00006270: 7365 6564 2e20 5468 6973 2069 7320 7573  seed. This is us
-00006280: 6566 756c 2077 6865 6e20 6d6f 7265 2074  eful when more t
-00006290: 6861 6e20 6f6e 6520 656e 7669 726f 6e6d  han one environm
-000062a0: 656e 7420 6973 2063 6f6e 7461 696e 6564  ent is contained
-000062b0: 2069 6e20 7468 6520 4461 7461 436f 6c6c   in the DataColl
-000062c0: 6563 746f 722c 2061 7320 7468 650d 0a20  ector, as the.. 
-000062d0: 2020 2020 2020 2020 2020 2073 6565 6420             seed 
-000062e0: 7769 6c6c 2062 6520 696e 6372 656d 656e  will be incremen
-000062f0: 7465 6420 666f 7220 6561 6368 206f 6620  ted for each of 
-00006300: 7468 6573 652e 2054 6865 2072 6573 756c  these. The resul
-00006310: 7469 6e67 2073 6565 6420 6973 2074 6865  ting seed is the
-00006320: 2073 6565 6420 6f66 2074 6865 206c 6173   seed of the las
-00006330: 7420 656e 7669 726f 6e6d 656e 742e 0d0a  t environment...
-00006340: 0d0a 2020 2020 2020 2020 4578 616d 706c  ..        Exampl
-00006350: 6573 3a0d 0a20 2020 2020 2020 2020 2020  es:..           
-00006360: 203e 3e3e 2066 726f 6d20 746f 7263 6872   >>> from torchr
-00006370: 6c2e 656e 7673 2069 6d70 6f72 7420 5061  l.envs import Pa
-00006380: 7261 6c6c 656c 456e 760d 0a20 2020 2020  rallelEnv..     
-00006390: 2020 2020 2020 203e 3e3e 2066 726f 6d20         >>> from 
-000063a0: 746f 7263 6872 6c2e 656e 7673 2e6c 6962  torchrl.envs.lib
-000063b0: 732e 6779 6d20 696d 706f 7274 2047 796d  s.gym import Gym
-000063c0: 456e 760d 0a20 2020 2020 2020 2020 2020  Env..           
-000063d0: 203e 3e3e 2065 6e76 5f66 6e20 3d20 6c61   >>> env_fn = la
-000063e0: 6d62 6461 3a20 4779 6d45 6e76 2822 5065  mbda: GymEnv("Pe
-000063f0: 6e64 756c 756d 2d76 3122 290d 0a20 2020  ndulum-v1")..   
-00006400: 2020 2020 2020 2020 203e 3e3e 2065 6e76           >>> env
-00006410: 5f66 6e5f 7061 7261 6c6c 656c 203d 2050  _fn_parallel = P
-00006420: 6172 616c 6c65 6c45 6e76 2836 2c20 656e  arallelEnv(6, en
-00006430: 765f 666e 290d 0a20 2020 2020 2020 2020  v_fn)..         
-00006440: 2020 203e 3e3e 2063 6f6c 6c65 6374 6f72     >>> collector
-00006450: 203d 2053 796e 6344 6174 6143 6f6c 6c65   = SyncDataColle
-00006460: 6374 6f72 2865 6e76 5f66 6e5f 7061 7261  ctor(env_fn_para
-00006470: 6c6c 656c 290d 0a20 2020 2020 2020 2020  llel)..         
-00006480: 2020 203e 3e3e 206f 7574 5f73 6565 6420     >>> out_seed 
-00006490: 3d20 636f 6c6c 6563 746f 722e 7365 745f  = collector.set_
-000064a0: 7365 6564 2831 2920 2023 206f 7574 5f73  seed(1)  # out_s
-000064b0: 6565 6420 3d20 360d 0a0d 0a20 2020 2020  eed = 6....     
-000064c0: 2020 2022 2222 0d0a 2020 2020 2020 2020     """..        
-000064d0: 7265 7475 726e 2073 656c 662e 656e 762e  return self.env.
-000064e0: 7365 745f 7365 6564 2873 6565 642c 2073  set_seed(seed, s
-000064f0: 7461 7469 635f 7365 6564 3d73 7461 7469  tatic_seed=stati
-00006500: 635f 7365 6564 290d 0a0d 0a20 2020 2064  c_seed)....    d
-00006510: 6566 2069 7465 7261 746f 7228 7365 6c66  ef iterator(self
-00006520: 2920 2d3e 2049 7465 7261 746f 725b 5465  ) -> Iterator[Te
-00006530: 6e73 6f72 4469 6374 4261 7365 5d3a 0d0a  nsorDictBase]:..
-00006540: 2020 2020 2020 2020 2222 2249 7465 7261          """Itera
-00006550: 7465 7320 7468 726f 7567 6820 7468 6520  tes through the 
-00006560: 4461 7461 436f 6c6c 6563 746f 722e 0d0a  DataCollector...
-00006570: 0d0a 2020 2020 2020 2020 5969 656c 6473  ..        Yields
-00006580: 3a20 5465 6e73 6f72 4469 6374 4261 7365  : TensorDictBase
-00006590: 206f 626a 6563 7473 2063 6f6e 7461 696e   objects contain
-000065a0: 696e 6720 2863 6875 6e6b 7320 6f66 2920  ing (chunks of) 
-000065b0: 7472 616a 6563 746f 7269 6573 0d0a 0d0a  trajectories....
-000065c0: 2020 2020 2020 2020 2222 220d 0a20 2020          """..   
-000065d0: 2020 2020 2074 6f74 616c 5f66 7261 6d65       total_frame
-000065e0: 7320 3d20 7365 6c66 2e74 6f74 616c 5f66  s = self.total_f
-000065f0: 7261 6d65 730d 0a20 2020 2020 2020 2069  rames..        i
-00006600: 203d 202d 310d 0a20 2020 2020 2020 2073   = -1..        s
-00006610: 656c 662e 5f66 7261 6d65 7320 3d20 300d  elf._frames = 0.
-00006620: 0a20 2020 2020 2020 2077 6869 6c65 2054  .        while T
-00006630: 7275 653a 0d0a 2020 2020 2020 2020 2020  rue:..          
-00006640: 2020 6920 2b3d 2031 0d0a 2020 2020 2020    i += 1..      
-00006650: 2020 2020 2020 7365 6c66 2e5f 6974 6572        self._iter
-00006660: 203d 2069 0d0a 2020 2020 2020 2020 2020   = i..          
-00006670: 2020 7465 6e73 6f72 6469 6374 5f6f 7574    tensordict_out
-00006680: 203d 2073 656c 662e 726f 6c6c 6f75 7428   = self.rollout(
-00006690: 290d 0a20 2020 2020 2020 2020 2020 2073  )..            s
-000066a0: 656c 662e 5f66 7261 6d65 7320 2b3d 2074  elf._frames += t
-000066b0: 656e 736f 7264 6963 745f 6f75 742e 6e75  ensordict_out.nu
-000066c0: 6d65 6c28 290d 0a20 2020 2020 2020 2020  mel()..         
-000066d0: 2020 2069 6620 7365 6c66 2e5f 6672 616d     if self._fram
-000066e0: 6573 203e 3d20 746f 7461 6c5f 6672 616d  es >= total_fram
-000066f0: 6573 3a0d 0a20 2020 2020 2020 2020 2020  es:..           
-00006700: 2020 2020 2073 656c 662e 656e 762e 636c       self.env.cl
-00006710: 6f73 6528 290d 0a0d 0a20 2020 2020 2020  ose()....       
-00006720: 2020 2020 2069 6620 7365 6c66 2e73 706c       if self.spl
-00006730: 6974 5f74 7261 6a73 3a0d 0a20 2020 2020  it_trajs:..     
-00006740: 2020 2020 2020 2020 2020 2074 656e 736f             tenso
-00006750: 7264 6963 745f 6f75 7420 3d20 7370 6c69  rdict_out = spli
-00006760: 745f 7472 616a 6563 746f 7269 6573 2874  t_trajectories(t
-00006770: 656e 736f 7264 6963 745f 6f75 742c 2070  ensordict_out, p
-00006780: 7265 6669 783d 2263 6f6c 6c65 6374 6f72  refix="collector
-00006790: 2229 0d0a 2020 2020 2020 2020 2020 2020  ")..            
-000067a0: 6966 2073 656c 662e 706f 7374 7072 6f63  if self.postproc
-000067b0: 2069 7320 6e6f 7420 4e6f 6e65 3a0d 0a20   is not None:.. 
-000067c0: 2020 2020 2020 2020 2020 2020 2020 2074                 t
-000067d0: 656e 736f 7264 6963 745f 6f75 7420 3d20  ensordict_out = 
-000067e0: 7365 6c66 2e70 6f73 7470 726f 6328 7465  self.postproc(te
-000067f0: 6e73 6f72 6469 6374 5f6f 7574 290d 0a20  nsordict_out).. 
-00006800: 2020 2020 2020 2020 2020 2069 6620 7365             if se
-00006810: 6c66 2e5f 6578 636c 7564 655f 7072 6976  lf._exclude_priv
-00006820: 6174 655f 6b65 7973 3a0d 0a20 2020 2020  ate_keys:..     
-00006830: 2020 2020 2020 2020 2020 2065 7863 6c75             exclu
-00006840: 6465 645f 6b65 7973 203d 205b 0d0a 2020  ded_keys = [..  
-00006850: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006860: 2020 6b65 7920 666f 7220 6b65 7920 696e    key for key in
-00006870: 2074 656e 736f 7264 6963 745f 6f75 742e   tensordict_out.
-00006880: 6b65 7973 2829 2069 6620 6b65 792e 7374  keys() if key.st
-00006890: 6172 7473 7769 7468 2822 5f22 290d 0a20  artswith("_").. 
-000068a0: 2020 2020 2020 2020 2020 2020 2020 205d                 ]
-000068b0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-000068c0: 2020 7465 6e73 6f72 6469 6374 5f6f 7574    tensordict_out
-000068d0: 203d 2074 656e 736f 7264 6963 745f 6f75   = tensordict_ou
-000068e0: 742e 6578 636c 7564 6528 2a65 7863 6c75  t.exclude(*exclu
-000068f0: 6465 645f 6b65 7973 2c20 696e 706c 6163  ded_keys, inplac
-00006900: 653d 5472 7565 290d 0a20 2020 2020 2020  e=True)..       
-00006910: 2020 2020 2069 6620 7365 6c66 2e72 6574       if self.ret
-00006920: 7572 6e5f 7361 6d65 5f74 643a 0d0a 2020  urn_same_td:..  
-00006930: 2020 2020 2020 2020 2020 2020 2020 7969                yi
-00006940: 656c 6420 7465 6e73 6f72 6469 6374 5f6f  eld tensordict_o
-00006950: 7574 0d0a 2020 2020 2020 2020 2020 2020  ut..            
-00006960: 656c 7365 3a0d 0a20 2020 2020 2020 2020  else:..         
-00006970: 2020 2020 2020 2023 2077 6520 6d75 7374         # we must
-00006980: 2063 6c6f 6e65 2074 6865 2076 616c 7565   clone the value
-00006990: 732c 2061 7320 7468 6520 7465 6e73 6f72  s, as the tensor
-000069a0: 6469 6374 2069 7320 7570 6461 7465 6420  dict is updated 
-000069b0: 696e 2d70 6c61 6365 2e0d 0a20 2020 2020  in-place...     
-000069c0: 2020 2020 2020 2020 2020 2023 206f 7468             # oth
-000069d0: 6572 7769 7365 2074 6865 2066 6f6c 6c6f  erwise the follo
-000069e0: 7769 6e67 2063 6f64 6520 6d61 7920 6272  wing code may br
-000069f0: 6561 6b3a 0d0a 2020 2020 2020 2020 2020  eak:..          
-00006a00: 2020 2020 2020 2320 3e3e 3e20 666f 7220        # >>> for 
-00006a10: 692c 2064 6174 6120 696e 2065 6e75 6d65  i, data in enume
-00006a20: 7261 7465 2863 6f6c 6c65 6374 6f72 293a  rate(collector):
-00006a30: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00006a40: 2020 2320 3e3e 3e20 2020 2020 2069 6620    # >>>      if 
-00006a50: 6920 3d3d 2030 3a0d 0a20 2020 2020 2020  i == 0:..       
-00006a60: 2020 2020 2020 2020 2023 203e 3e3e 2020           # >>>  
-00006a70: 2020 2020 2020 2020 6461 7461 3020 3d20          data0 = 
-00006a80: 6461 7461 0d0a 2020 2020 2020 2020 2020  data..          
-00006a90: 2020 2020 2020 2320 3e3e 3e20 2020 2020        # >>>     
-00006aa0: 2065 6c69 6620 6920 3d3d 2031 3a0d 0a20   elif i == 1:.. 
-00006ab0: 2020 2020 2020 2020 2020 2020 2020 2023                 #
-00006ac0: 203e 3e3e 2020 2020 2020 2020 2020 6461   >>>          da
-00006ad0: 7461 3120 3d20 6461 7461 0d0a 2020 2020  ta1 = data..    
-00006ae0: 2020 2020 2020 2020 2020 2020 2320 3e3e              # >>
-00006af0: 3e20 2020 2020 2065 6c73 653a 0d0a 2020  >      else:..  
-00006b00: 2020 2020 2020 2020 2020 2020 2020 2320                # 
-00006b10: 3e3e 3e20 2020 2020 2020 2020 2062 7265  >>>          bre
-00006b20: 616b 0d0a 2020 2020 2020 2020 2020 2020  ak..            
-00006b30: 2020 2020 2320 3e3e 3e20 6173 7365 7274      # >>> assert
-00006b40: 2064 6174 6130 5b22 646f 6e65 225d 2069   data0["done"] i
-00006b50: 7320 6e6f 7420 6461 7461 315b 2264 6f6e  s not data1["don
-00006b60: 6522 5d0d 0a20 2020 2020 2020 2020 2020  e"]..           
-00006b70: 2020 2020 2079 6965 6c64 2074 656e 736f       yield tenso
-00006b80: 7264 6963 745f 6f75 742e 636c 6f6e 6528  rdict_out.clone(
-00006b90: 290d 0a0d 0a20 2020 2020 2020 2020 2020  )....           
-00006ba0: 2069 6620 7365 6c66 2e5f 6672 616d 6573   if self._frames
-00006bb0: 203e 3d20 7365 6c66 2e74 6f74 616c 5f66   >= self.total_f
-00006bc0: 7261 6d65 733a 0d0a 2020 2020 2020 2020  rames:..        
-00006bd0: 2020 2020 2020 2020 6272 6561 6b0d 0a0d          break...
-00006be0: 0a20 2020 2064 6566 205f 7374 6570 5f61  .    def _step_a
-00006bf0: 6e64 5f6d 6179 6265 5f72 6573 6574 2873  nd_maybe_reset(s
-00006c00: 656c 6629 202d 3e20 4e6f 6e65 3a0d 0a20  elf) -> None:.. 
-00006c10: 2020 2020 2020 2064 6f6e 6520 3d20 7365         done = se
-00006c20: 6c66 2e5f 7465 6e73 6f72 6469 6374 2e67  lf._tensordict.g
-00006c30: 6574 2828 226e 6578 7422 2c20 2264 6f6e  et(("next", "don
-00006c40: 6522 2929 0d0a 2020 2020 2020 2020 7472  e"))..        tr
-00006c50: 756e 6361 7465 6420 3d20 7365 6c66 2e5f  uncated = self._
-00006c60: 7465 6e73 6f72 6469 6374 2e67 6574 2828  tensordict.get((
-00006c70: 226e 6578 7422 2c20 2274 7275 6e63 6174  "next", "truncat
-00006c80: 6564 2229 2c20 4e6f 6e65 290d 0a20 2020  ed"), None)..   
-00006c90: 2020 2020 2069 6620 7472 756e 6361 7465       if truncate
-00006ca0: 6420 6973 204e 6f6e 653a 0d0a 2020 2020  d is None:..    
-00006cb0: 2020 2020 2020 2020 7472 756e 6361 7465          truncate
-00006cc0: 6420 3d20 746f 7263 682e 7a65 726f 735f  d = torch.zeros_
-00006cd0: 6c69 6b65 2864 6f6e 6529 0d0a 2020 2020  like(done)..    
-00006ce0: 2020 2020 7472 616a 5f69 6473 203d 2073      traj_ids = s
-00006cf0: 656c 662e 5f74 656e 736f 7264 6963 742e  elf._tensordict.
-00006d00: 6765 7428 2822 636f 6c6c 6563 746f 7222  get(("collector"
-00006d10: 2c20 2274 7261 6a5f 6964 7322 2929 2e63  , "traj_ids")).c
-00006d20: 6c6f 6e65 2829 0d0a 0d0a 2020 2020 2020  lone()....      
-00006d30: 2020 7365 6c66 2e5f 7465 6e73 6f72 6469    self._tensordi
-00006d40: 6374 203d 2073 7465 705f 6d64 7028 7365  ct = step_mdp(se
-00006d50: 6c66 2e5f 7465 6e73 6f72 6469 6374 290d  lf._tensordict).
-00006d60: 0a0d 0a20 2020 2020 2020 2069 6620 6e6f  ...        if no
-00006d70: 7420 7365 6c66 2e72 6573 6574 5f77 6865  t self.reset_whe
-00006d80: 6e5f 646f 6e65 3a0d 0a20 2020 2020 2020  n_done:..       
-00006d90: 2020 2020 2064 6f6e 6520 3d20 746f 7263       done = torc
-00006da0: 682e 7a65 726f 735f 6c69 6b65 2864 6f6e  h.zeros_like(don
-00006db0: 6529 0d0a 2020 2020 2020 2020 646f 6e65  e)..        done
-00006dc0: 5f6f 725f 7465 726d 696e 6174 6564 203d  _or_terminated =
-00006dd0: 2064 6f6e 652e 7371 7565 657a 6528 2d31   done.squeeze(-1
-00006de0: 2920 7c20 7472 756e 6361 7465 642e 7371  ) | truncated.sq
-00006df0: 7565 657a 6528 2d31 290d 0a20 2020 2020  ueeze(-1)..     
-00006e00: 2020 2023 206b 6565 7020 7472 6163 6b20     # keep track 
-00006e10: 6f66 2065 6e76 7320 7468 6174 2068 6176  of envs that hav
-00006e20: 6520 6265 656e 2064 6f6e 6520 6174 206c  e been done at l
-00006e30: 6561 7374 206f 6e63 650d 0a20 2020 2020  east once..     
-00006e40: 2020 2069 6620 7365 6c66 2e5f 6861 735f     if self._has_
-00006e50: 6265 656e 5f64 6f6e 6520 6973 204e 6f6e  been_done is Non
-00006e60: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
-00006e70: 7365 6c66 2e5f 6861 735f 6265 656e 5f64  self._has_been_d
-00006e80: 6f6e 6520 3d20 646f 6e65 5f6f 725f 7465  one = done_or_te
-00006e90: 726d 696e 6174 6564 0d0a 2020 2020 2020  rminated..      
-00006ea0: 2020 656c 7365 3a0d 0a20 2020 2020 2020    else:..       
-00006eb0: 2020 2020 2073 656c 662e 5f68 6173 5f62       self._has_b
-00006ec0: 6565 6e5f 646f 6e65 203d 2073 656c 662e  een_done = self.
-00006ed0: 5f68 6173 5f62 6565 6e5f 646f 6e65 207c  _has_been_done |
-00006ee0: 2064 6f6e 655f 6f72 5f74 6572 6d69 6e61   done_or_termina
-00006ef0: 7465 640d 0a20 2020 2020 2020 2069 6620  ted..        if 
-00006f00: 646f 6e65 5f6f 725f 7465 726d 696e 6174  done_or_terminat
-00006f10: 6564 2e61 6e79 2829 3a0d 0a20 2020 2020  ed.any():..     
-00006f20: 2020 2020 2020 2023 2063 6f6c 6c65 6374         # collect
-00006f30: 6f72 7320 646f 206e 6f74 2073 7570 706f  ors do not suppo
-00006f40: 7274 2070 6173 7369 6e67 206f 7468 6572  rt passing other
-00006f50: 2074 656e 736f 7273 2074 6861 6e20 6022   tensors than `"
-00006f60: 5f72 6573 6574 2260 0d0a 2020 2020 2020  _reset"`..      
-00006f70: 2020 2020 2020 2320 746f 2060 7265 7365        # to `rese
-00006f80: 7428 2960 2e0d 0a20 2020 2020 2020 2020  t()`...         
-00006f90: 2020 2069 6620 6c65 6e28 7365 6c66 2e65     if len(self.e
-00006fa0: 6e76 2e62 6174 6368 5f73 697a 6529 3a0d  nv.batch_size):.
-00006fb0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00006fc0: 2073 656c 662e 5f74 656e 736f 7264 6963   self._tensordic
-00006fd0: 742e 6d61 736b 6564 5f66 696c 6c5f 2864  t.masked_fill_(d
-00006fe0: 6f6e 655f 6f72 5f74 6572 6d69 6e61 7465  one_or_terminate
-00006ff0: 642c 2030 290d 0a20 2020 2020 2020 2020  d, 0)..         
-00007000: 2020 2020 2020 205f 7265 7365 7420 3d20         _reset = 
-00007010: 646f 6e65 5f6f 725f 7465 726d 696e 6174  done_or_terminat
-00007020: 6564 0d0a 2020 2020 2020 2020 2020 2020  ed..            
-00007030: 2020 2020 7464 5f72 6573 6574 203d 2073      td_reset = s
-00007040: 656c 662e 5f74 656e 736f 7264 6963 742e  elf._tensordict.
-00007050: 7365 6c65 6374 2829 2e73 6574 2822 5f72  select().set("_r
-00007060: 6573 6574 222c 205f 7265 7365 7429 0d0a  eset", _reset)..
-00007070: 2020 2020 2020 2020 2020 2020 656c 7365              else
-00007080: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
-00007090: 2020 205f 7265 7365 7420 3d20 4e6f 6e65     _reset = None
-000070a0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-000070b0: 2020 7464 5f72 6573 6574 203d 204e 6f6e    td_reset = Non
-000070c0: 650d 0a20 2020 2020 2020 2020 2020 2074  e..            t
-000070d0: 645f 7265 7365 7420 3d20 7365 6c66 2e65  d_reset = self.e
-000070e0: 6e76 2e72 6573 6574 2874 645f 7265 7365  nv.reset(td_rese
-000070f0: 7429 0d0a 2020 2020 2020 2020 2020 2020  t)..            
-00007100: 7365 6c66 2e5f 7465 6e73 6f72 6469 6374  self._tensordict
-00007110: 2e75 7064 6174 6528 7464 5f72 6573 6574  .update(td_reset
-00007120: 2c20 696e 706c 6163 653d 5472 7565 290d  , inplace=True).
-00007130: 0a20 2020 2020 2020 2020 2020 2064 6f6e  .            don
-00007140: 6520 3d20 7365 6c66 2e5f 7465 6e73 6f72  e = self._tensor
-00007150: 6469 6374 2e67 6574 2822 646f 6e65 2229  dict.get("done")
-00007160: 0d0a 2020 2020 2020 2020 2020 2020 6966  ..            if
-00007170: 2028 5f72 6573 6574 2069 7320 4e6f 6e65   (_reset is None
-00007180: 2061 6e64 2064 6f6e 652e 616e 7928 2929   and done.any())
-00007190: 206f 7220 280d 0a20 2020 2020 2020 2020   or (..         
-000071a0: 2020 2020 2020 205f 7265 7365 7420 6973         _reset is
-000071b0: 206e 6f74 204e 6f6e 6520 616e 6420 646f   not None and do
-000071c0: 6e65 5b5f 7265 7365 745d 2e61 6e79 2829  ne[_reset].any()
-000071d0: 0d0a 2020 2020 2020 2020 2020 2020 293a  ..            ):
-000071e0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-000071f0: 2020 7261 6973 6520 5275 6e74 696d 6545    raise RuntimeE
-00007200: 7272 6f72 280d 0a20 2020 2020 2020 2020  rror(..         
-00007210: 2020 2020 2020 2020 2020 2066 2245 6e76             f"Env
-00007220: 207b 7365 6c66 2e65 6e76 7d20 7761 7320   {self.env} was 
-00007230: 646f 6e65 2061 6674 6572 2072 6573 6574  done after reset
-00007240: 206f 6e20 7370 6563 6966 6965 6420 275f   on specified '_
-00007250: 7265 7365 7427 2064 696d 656e 7369 6f6e  reset' dimension
-00007260: 732e 2054 6869 7320 6973 2028 6375 7272  s. This is (curr
-00007270: 656e 746c 7929 206e 6f74 2061 6c6c 6f77  ently) not allow
-00007280: 6564 2e22 0d0a 2020 2020 2020 2020 2020  ed."..          
-00007290: 2020 2020 2020 290d 0a20 2020 2020 2020        )..       
-000072a0: 2020 2020 2074 7261 6a5f 6964 735b 646f       traj_ids[do
-000072b0: 6e65 5f6f 725f 7465 726d 696e 6174 6564  ne_or_terminated
-000072c0: 5d20 3d20 7472 616a 5f69 6473 2e6d 6178  ] = traj_ids.max
-000072d0: 2829 202b 2074 6f72 6368 2e61 7261 6e67  () + torch.arang
-000072e0: 6528 0d0a 2020 2020 2020 2020 2020 2020  e(..            
-000072f0: 2020 2020 312c 2064 6f6e 655f 6f72 5f74      1, done_or_t
-00007300: 6572 6d69 6e61 7465 642e 7375 6d28 2920  erminated.sum() 
-00007310: 2b20 312c 2064 6576 6963 653d 7472 616a  + 1, device=traj
-00007320: 5f69 6473 2e64 6576 6963 650d 0a20 2020  _ids.device..   
-00007330: 2020 2020 2020 2020 2029 0d0a 2020 2020           )..    
-00007340: 2020 2020 2020 2020 7365 6c66 2e5f 7465          self._te
-00007350: 6e73 6f72 6469 6374 2e73 6574 5f28 0d0a  nsordict.set_(..
-00007360: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007370: 2822 636f 6c6c 6563 746f 7222 2c20 2274  ("collector", "t
-00007380: 7261 6a5f 6964 7322 292c 2074 7261 6a5f  raj_ids"), traj_
-00007390: 6964 730d 0a20 2020 2020 2020 2020 2020  ids..           
-000073a0: 2029 2020 2320 6e6f 206f 7073 2069 6620   )  # no ops if 
-000073b0: 7468 6579 2061 6c72 6561 6479 206d 6174  they already mat
-000073c0: 6368 0d0a 0d0a 2020 2020 4074 6f72 6368  ch....    @torch
-000073d0: 2e6e 6f5f 6772 6164 2829 0d0a 2020 2020  .no_grad()..    
-000073e0: 6465 6620 726f 6c6c 6f75 7428 7365 6c66  def rollout(self
-000073f0: 2920 2d3e 2054 656e 736f 7244 6963 7442  ) -> TensorDictB
-00007400: 6173 653a 0d0a 2020 2020 2020 2020 2222  ase:..        ""
-00007410: 2243 6f6d 7075 7465 7320 6120 726f 6c6c  "Computes a roll
-00007420: 6f75 7420 696e 2074 6865 2065 6e76 6972  out in the envir
-00007430: 6f6e 6d65 6e74 2075 7369 6e67 2074 6865  onment using the
-00007440: 2070 726f 7669 6465 6420 706f 6c69 6379   provided policy
-00007450: 2e0d 0a0d 0a20 2020 2020 2020 2052 6574  .....        Ret
-00007460: 7572 6e73 3a0d 0a20 2020 2020 2020 2020  urns:..         
-00007470: 2020 2054 656e 736f 7244 6963 7442 6173     TensorDictBas
-00007480: 6520 636f 6e74 6169 6e69 6e67 2074 6865  e containing the
-00007490: 2063 6f6d 7075 7465 6420 726f 6c6c 6f75   computed rollou
-000074a0: 742e 0d0a 0d0a 2020 2020 2020 2020 2222  t.....        ""
-000074b0: 220d 0a20 2020 2020 2020 2069 6620 7365  "..        if se
-000074c0: 6c66 2e72 6573 6574 5f61 745f 6561 6368  lf.reset_at_each
-000074d0: 5f69 7465 723a 0d0a 2020 2020 2020 2020  _iter:..        
-000074e0: 2020 2020 7365 6c66 2e5f 7465 6e73 6f72      self._tensor
-000074f0: 6469 6374 2e75 7064 6174 6528 7365 6c66  dict.update(self
-00007500: 2e65 6e76 2e72 6573 6574 2829 2c20 696e  .env.reset(), in
-00007510: 706c 6163 653d 5472 7565 290d 0a0d 0a20  place=True).... 
-00007520: 2020 2020 2020 2077 6974 6820 7365 745f         with set_
-00007530: 6578 706c 6f72 6174 696f 6e5f 6d6f 6465  exploration_mode
-00007540: 2873 656c 662e 6578 706c 6f72 6174 696f  (self.exploratio
-00007550: 6e5f 6d6f 6465 293a 0d0a 2020 2020 2020  n_mode):..      
-00007560: 2020 2020 2020 666f 7220 6a20 696e 2072        for j in r
-00007570: 616e 6765 2873 656c 662e 6672 616d 6573  ange(self.frames
-00007580: 5f70 6572 5f62 6174 6368 293a 0d0a 2020  _per_batch):..  
-00007590: 2020 2020 2020 2020 2020 2020 2020 6966                if
-000075a0: 2073 656c 662e 5f66 7261 6d65 7320 3c20   self._frames < 
-000075b0: 7365 6c66 2e69 6e69 745f 7261 6e64 6f6d  self.init_random
-000075c0: 5f66 7261 6d65 733a 0d0a 2020 2020 2020  _frames:..      
-000075d0: 2020 2020 2020 2020 2020 2020 2020 7365                se
-000075e0: 6c66 2e65 6e76 2e72 616e 645f 7374 6570  lf.env.rand_step
-000075f0: 2873 656c 662e 5f74 656e 736f 7264 6963  (self._tensordic
-00007600: 7429 0d0a 2020 2020 2020 2020 2020 2020  t)..            
-00007610: 2020 2020 656c 7365 3a0d 0a20 2020 2020      else:..     
-00007620: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-00007630: 656c 662e 656e 762e 7374 6570 2873 656c  elf.env.step(sel
-00007640: 662e 706f 6c69 6379 2873 656c 662e 5f74  f.policy(self._t
-00007650: 656e 736f 7264 6963 7429 290d 0a0d 0a20  ensordict)).... 
-00007660: 2020 2020 2020 2020 2020 2020 2020 2023                 #
-00007670: 2077 6520 6d75 7374 2063 6c6f 6e65 2061   we must clone a
-00007680: 6c6c 2074 6865 2076 616c 7565 732c 2073  ll the values, s
-00007690: 696e 6365 2074 6865 2073 7465 7020 2f20  ince the step / 
-000076a0: 7472 616a 5f69 6420 7570 6461 7465 7320  traj_id updates 
-000076b0: 6172 6520 646f 6e65 2069 6e2d 706c 6163  are done in-plac
-000076c0: 650d 0a20 2020 2020 2020 2020 2020 2020  e..             
-000076d0: 2020 2074 7279 3a0d 0a20 2020 2020 2020     try:..       
-000076e0: 2020 2020 2020 2020 2020 2020 2073 656c               sel
-000076f0: 662e 5f74 656e 736f 7264 6963 745f 6f75  f._tensordict_ou
-00007700: 745b 2e2e 2e2c 206a 5d20 3d20 7365 6c66  t[..., j] = self
-00007710: 2e5f 7465 6e73 6f72 6469 6374 0d0a 2020  ._tensordict..  
-00007720: 2020 2020 2020 2020 2020 2020 2020 6578                ex
-00007730: 6365 7074 2052 756e 7469 6d65 4572 726f  cept RuntimeErro
-00007740: 723a 0d0a 2020 2020 2020 2020 2020 2020  r:..            
-00007750: 2020 2020 2020 2020 2320 756e 6c6f 636b          # unlock
-00007760: 2074 6865 206f 7574 7075 7420 7465 6e73   the output tens
-00007770: 6f72 6469 6374 2074 6f20 616c 6c6f 7720  ordict to allow 
-00007780: 666f 7220 6e65 7720 6b65 7973 2074 6f20  for new keys to 
-00007790: 6265 2077 7269 7474 656e 0d0a 2020 2020  be written..    
-000077a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000077b0: 2320 7468 6573 6520 7769 6c6c 2062 6520  # these will be 
-000077c0: 6d69 7373 6564 2064 7572 696e 6720 7468  missed during th
-000077d0: 6520 7379 6e63 2062 7574 2061 7420 6c65  e sync but at le
-000077e0: 6173 7420 7765 2077 6f6e 2774 2067 6574  ast we won't get
-000077f0: 2061 6e20 6572 726f 7220 6475 7269 6e67   an error during
-00007800: 2074 6865 2075 7064 6174 650d 0a20 2020   the update..   
-00007810: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007820: 2069 735f 7368 6172 6564 203d 2073 656c   is_shared = sel
-00007830: 662e 5f74 656e 736f 7264 6963 745f 6f75  f._tensordict_ou
-00007840: 742e 6973 5f73 6861 7265 6428 290d 0a20  t.is_shared().. 
-00007850: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007860: 2020 2073 656c 662e 5f74 656e 736f 7264     self._tensord
-00007870: 6963 745f 6f75 742e 756e 6c6f 636b 5f28  ict_out.unlock_(
-00007880: 290d 0a20 2020 2020 2020 2020 2020 2020  )..             
-00007890: 2020 2020 2020 2073 656c 662e 5f74 656e         self._ten
-000078a0: 736f 7264 6963 745f 6f75 745b 2e2e 2e2c  sordict_out[...,
-000078b0: 206a 5d20 3d20 7365 6c66 2e5f 7465 6e73   j] = self._tens
-000078c0: 6f72 6469 6374 0d0a 2020 2020 2020 2020  ordict..        
-000078d0: 2020 2020 2020 2020 2020 2020 6966 2069              if i
-000078e0: 735f 7368 6172 6564 3a0d 0a20 2020 2020  s_shared:..     
-000078f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007900: 2020 2073 656c 662e 5f74 656e 736f 7264     self._tensord
-00007910: 6963 745f 6f75 742e 7368 6172 655f 6d65  ict_out.share_me
-00007920: 6d6f 7279 5f28 290d 0a20 2020 2020 2020  mory_()..       
-00007930: 2020 2020 2020 2020 2020 2020 2065 6c73               els
-00007940: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
-00007950: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-00007960: 2e5f 7465 6e73 6f72 6469 6374 5f6f 7574  ._tensordict_out
-00007970: 2e6c 6f63 6b28 290d 0a0d 0a20 2020 2020  .lock()....     
-00007980: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-00007990: 5f73 7465 705f 616e 645f 6d61 7962 655f  _step_and_maybe_
-000079a0: 7265 7365 7428 290d 0a0d 0a20 2020 2020  reset()....     
-000079b0: 2020 2072 6574 7572 6e20 7365 6c66 2e5f     return self._
-000079c0: 7465 6e73 6f72 6469 6374 5f6f 7574 0d0a  tensordict_out..
-000079d0: 0d0a 2020 2020 6465 6620 7265 7365 7428  ..    def reset(
-000079e0: 7365 6c66 2c20 696e 6465 783d 4e6f 6e65  self, index=None
-000079f0: 2c20 2a2a 6b77 6172 6773 2920 2d3e 204e  , **kwargs) -> N
-00007a00: 6f6e 653a 0d0a 2020 2020 2020 2020 2222  one:..        ""
-00007a10: 2252 6573 6574 7320 7468 6520 656e 7669  "Resets the envi
-00007a20: 726f 6e6d 656e 7473 2074 6f20 6120 6e65  ronments to a ne
-00007a30: 7720 696e 6974 6961 6c20 7374 6174 652e  w initial state.
-00007a40: 2222 220d 0a20 2020 2020 2020 2023 206d  """..        # m
-00007a50: 6574 6164 6174 610d 0a20 2020 2020 2020  etadata..       
-00007a60: 206d 6420 3d20 7365 6c66 2e5f 7465 6e73   md = self._tens
-00007a70: 6f72 6469 6374 5b22 636f 6c6c 6563 746f  ordict["collecto
-00007a80: 7222 5d2e 636c 6f6e 6528 290d 0a20 2020  r"].clone()..   
-00007a90: 2020 2020 2069 6620 696e 6465 7820 6973       if index is
-00007aa0: 206e 6f74 204e 6f6e 653a 0d0a 2020 2020   not None:..    
-00007ab0: 2020 2020 2020 2020 2320 6368 6563 6b20          # check 
-00007ac0: 7468 6174 2074 6865 2065 6e76 2073 7570  that the env sup
-00007ad0: 706f 7274 7320 7061 7274 6961 6c20 7265  ports partial re
-00007ae0: 7365 740d 0a20 2020 2020 2020 2020 2020  set..           
-00007af0: 2069 6620 7072 6f64 2873 656c 662e 656e   if prod(self.en
-00007b00: 762e 6261 7463 685f 7369 7a65 2920 3d3d  v.batch_size) ==
-00007b10: 2030 3a0d 0a20 2020 2020 2020 2020 2020   0:..           
-00007b20: 2020 2020 2072 6169 7365 2052 756e 7469       raise Runti
-00007b30: 6d65 4572 726f 7228 2272 6573 6574 7469  meError("resetti
-00007b40: 6e67 2075 6e69 7175 6520 656e 7620 7769  ng unique env wi
-00007b50: 7468 2069 6e64 6578 2069 7320 6e6f 7420  th index is not 
-00007b60: 7065 726d 6974 7465 642e 2229 0d0a 2020  permitted.")..  
-00007b70: 2020 2020 2020 2020 2020 5f72 6573 6574            _reset
-00007b80: 203d 2074 6f72 6368 2e7a 6572 6f73 280d   = torch.zeros(.
-00007b90: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00007ba0: 2073 656c 662e 656e 762e 6261 7463 685f   self.env.batch_
-00007bb0: 7369 7a65 2c0d 0a20 2020 2020 2020 2020  size,..         
-00007bc0: 2020 2020 2020 2064 7479 7065 3d74 6f72         dtype=tor
-00007bd0: 6368 2e62 6f6f 6c2c 0d0a 2020 2020 2020  ch.bool,..      
-00007be0: 2020 2020 2020 2020 2020 6465 7669 6365            device
-00007bf0: 3d73 656c 662e 656e 762e 6465 7669 6365  =self.env.device
-00007c00: 2c0d 0a20 2020 2020 2020 2020 2020 2029  ,..            )
-00007c10: 0d0a 2020 2020 2020 2020 2020 2020 5f72  ..            _r
-00007c20: 6573 6574 5b69 6e64 6578 5d20 3d20 310d  eset[index] = 1.
-00007c30: 0a20 2020 2020 2020 2020 2020 2073 656c  .            sel
-00007c40: 662e 5f74 656e 736f 7264 6963 745b 696e  f._tensordict[in
-00007c50: 6465 785d 2e7a 6572 6f5f 2829 0d0a 2020  dex].zero_()..  
-00007c60: 2020 2020 2020 2020 2020 7365 6c66 2e5f            self._
-00007c70: 7465 6e73 6f72 6469 6374 5b22 5f72 6573  tensordict["_res
-00007c80: 6574 225d 203d 205f 7265 7365 740d 0a20  et"] = _reset.. 
-00007c90: 2020 2020 2020 2065 6c73 653a 0d0a 2020         else:..  
-00007ca0: 2020 2020 2020 2020 2020 5f72 6573 6574            _reset
-00007cb0: 203d 204e 6f6e 650d 0a20 2020 2020 2020   = None..       
-00007cc0: 2020 2020 2073 656c 662e 5f74 656e 736f       self._tenso
-00007cd0: 7264 6963 742e 7a65 726f 5f28 290d 0a0d  rdict.zero_()...
-00007ce0: 0a20 2020 2020 2020 2073 656c 662e 5f74  .        self._t
-00007cf0: 656e 736f 7264 6963 742e 7570 6461 7465  ensordict.update
-00007d00: 2873 656c 662e 656e 762e 7265 7365 7428  (self.env.reset(
-00007d10: 2a2a 6b77 6172 6773 2929 0d0a 2020 2020  **kwargs))..    
-00007d20: 2020 2020 6d64 5b22 7472 616a 5f69 6473      md["traj_ids
-00007d30: 225d 203d 206d 645b 2274 7261 6a5f 6964  "] = md["traj_id
-00007d40: 7322 5d20 2d20 6d64 5b22 7472 616a 5f69  s"] - md["traj_i
-00007d50: 6473 225d 2e6d 696e 2829 0d0a 2020 2020  ds"].min()..    
-00007d60: 2020 2020 7365 6c66 2e5f 7465 6e73 6f72      self._tensor
-00007d70: 6469 6374 5b22 636f 6c6c 6563 746f 7222  dict["collector"
-00007d80: 5d20 3d20 6d64 0d0a 0d0a 2020 2020 6465  ] = md....    de
-00007d90: 6620 7368 7574 646f 776e 2873 656c 6629  f shutdown(self)
-00007da0: 202d 3e20 4e6f 6e65 3a0d 0a20 2020 2020   -> None:..     
-00007db0: 2020 2022 2222 5368 7574 7320 646f 776e     """Shuts down
-00007dc0: 2061 6c6c 2077 6f72 6b65 7273 2061 6e64   all workers and
-00007dd0: 2f6f 7220 636c 6f73 6573 2074 6865 206c  /or closes the l
-00007de0: 6f63 616c 2065 6e76 6972 6f6e 6d65 6e74  ocal environment
-00007df0: 2e22 2222 0d0a 2020 2020 2020 2020 6966  ."""..        if
-00007e00: 206e 6f74 2073 656c 662e 636c 6f73 6564   not self.closed
-00007e10: 3a0d 0a20 2020 2020 2020 2020 2020 2073  :..            s
-00007e20: 656c 662e 636c 6f73 6564 203d 2054 7275  elf.closed = Tru
-00007e30: 650d 0a20 2020 2020 2020 2020 2020 2064  e..            d
-00007e40: 656c 2073 656c 662e 5f74 656e 736f 7264  el self._tensord
-00007e50: 6963 742c 2073 656c 662e 5f74 656e 736f  ict, self._tenso
-00007e60: 7264 6963 745f 6f75 740d 0a20 2020 2020  rdict_out..     
-00007e70: 2020 2020 2020 2069 6620 6e6f 7420 7365         if not se
-00007e80: 6c66 2e65 6e76 2e69 735f 636c 6f73 6564  lf.env.is_closed
-00007e90: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
-00007ea0: 2020 2073 656c 662e 656e 762e 636c 6f73     self.env.clos
-00007eb0: 6528 290d 0a20 2020 2020 2020 2020 2020  e()..           
-00007ec0: 2064 656c 2073 656c 662e 656e 760d 0a20   del self.env.. 
-00007ed0: 2020 2020 2020 2072 6574 7572 6e0d 0a0d         return...
-00007ee0: 0a20 2020 2064 6566 205f 5f64 656c 5f5f  .    def __del__
-00007ef0: 2873 656c 6629 3a0d 0a20 2020 2020 2020  (self):..       
-00007f00: 2074 7279 3a0d 0a20 2020 2020 2020 2020   try:..         
-00007f10: 2020 2073 656c 662e 7368 7574 646f 776e     self.shutdown
-00007f20: 2829 0d0a 2020 2020 2020 2020 6578 6365  ()..        exce
-00007f30: 7074 2045 7863 6570 7469 6f6e 3a0d 0a20  pt Exception:.. 
-00007f40: 2020 2020 2020 2020 2020 2023 2061 6e20             # an 
-00007f50: 4174 7472 6962 7574 6545 7272 6f72 2077  AttributeError w
-00007f60: 696c 6c20 7479 7069 6361 6c6c 7920 6265  ill typically be
-00007f70: 2072 6169 7365 6420 6966 2074 6865 2063   raised if the c
-00007f80: 6f6c 6c65 6374 6f72 2069 7320 6465 6c65  ollector is dele
-00007f90: 7465 6420 7768 656e 2074 6865 2070 726f  ted when the pro
-00007fa0: 6772 616d 2065 6e64 732e 0d0a 2020 2020  gram ends...    
-00007fb0: 2020 2020 2020 2020 2320 496e 2074 6865          # In the
-00007fc0: 2066 7574 7572 652c 2069 6e73 6967 6e69   future, insigni
-00007fd0: 6669 6361 6e74 2063 6861 6e67 6573 2074  ficant changes t
-00007fe0: 6f20 7468 6520 636c 6f73 6520 6d65 7468  o the close meth
-00007ff0: 6f64 206d 6179 2063 6861 6e67 6520 7468  od may change th
-00008000: 6520 6572 726f 7220 7479 7065 2e0d 0a20  e error type... 
-00008010: 2020 2020 2020 2020 2020 2023 2057 6520             # We 
-00008020: 6578 6370 6c69 6369 7465 6c79 2061 7373  excplicitely ass
-00008030: 756d 6520 7468 6174 2061 6e79 2065 7272  ume that any err
-00008040: 6f72 2072 6169 7365 6420 6475 7269 6e67  or raised during
-00008050: 2063 6c6f 7375 7265 2069 6e0d 0a20 2020   closure in..   
-00008060: 2020 2020 2020 2020 2023 205f 5f64 656c           # __del
-00008070: 5f5f 2077 696c 6c20 6e6f 7420 6166 6665  __ will not affe
-00008080: 6374 2074 6865 2070 726f 6772 616d 2e0d  ct the program..
-00008090: 0a20 2020 2020 2020 2020 2020 2070 6173  .            pas
-000080a0: 730d 0a0d 0a20 2020 2064 6566 2073 7461  s....    def sta
-000080b0: 7465 5f64 6963 7428 7365 6c66 2920 2d3e  te_dict(self) ->
-000080c0: 204f 7264 6572 6564 4469 6374 3a0d 0a20   OrderedDict:.. 
-000080d0: 2020 2020 2020 2022 2222 5265 7475 726e         """Return
-000080e0: 7320 7468 6520 6c6f 6361 6c20 7374 6174  s the local stat
-000080f0: 655f 6469 6374 206f 6620 7468 6520 6461  e_dict of the da
-00008100: 7461 2063 6f6c 6c65 6374 6f72 2028 656e  ta collector (en
-00008110: 7669 726f 6e6d 656e 7420 616e 6420 706f  vironment and po
-00008120: 6c69 6379 292e 0d0a 0d0a 2020 2020 2020  licy).....      
-00008130: 2020 5265 7475 726e 733a 0d0a 2020 2020    Returns:..    
-00008140: 2020 2020 2020 2020 616e 206f 7264 6572          an order
-00008150: 6564 2064 6963 7469 6f6e 6172 7920 7769  ed dictionary wi
-00008160: 7468 2066 6965 6c64 7320 3a6f 626a 3a60  th fields :obj:`
-00008170: 2270 6f6c 6963 795f 7374 6174 655f 6469  "policy_state_di
-00008180: 6374 2260 2061 6e64 0d0a 2020 2020 2020  ct"` and..      
-00008190: 2020 2020 2020 6022 656e 765f 7374 6174        `"env_stat
-000081a0: 655f 6469 6374 2260 2e0d 0a0d 0a20 2020  e_dict"`.....   
-000081b0: 2020 2020 2022 2222 0d0a 2020 2020 2020       """..      
-000081c0: 2020 6966 2069 7369 6e73 7461 6e63 6528    if isinstance(
-000081d0: 7365 6c66 2e65 6e76 2c20 5472 616e 7366  self.env, Transf
-000081e0: 6f72 6d65 6445 6e76 293a 0d0a 2020 2020  ormedEnv):..    
-000081f0: 2020 2020 2020 2020 656e 765f 7374 6174          env_stat
-00008200: 655f 6469 6374 203d 2073 656c 662e 656e  e_dict = self.en
-00008210: 762e 7472 616e 7366 6f72 6d2e 7374 6174  v.transform.stat
-00008220: 655f 6469 6374 2829 0d0a 2020 2020 2020  e_dict()..      
-00008230: 2020 656c 6966 2069 7369 6e73 7461 6e63    elif isinstanc
-00008240: 6528 7365 6c66 2e65 6e76 2c20 5f42 6174  e(self.env, _Bat
-00008250: 6368 6564 456e 7629 3a0d 0a20 2020 2020  chedEnv):..     
-00008260: 2020 2020 2020 2065 6e76 5f73 7461 7465         env_state
-00008270: 5f64 6963 7420 3d20 7365 6c66 2e65 6e76  _dict = self.env
-00008280: 2e73 7461 7465 5f64 6963 7428 290d 0a20  .state_dict().. 
-00008290: 2020 2020 2020 2065 6c73 653a 0d0a 2020         else:..  
-000082a0: 2020 2020 2020 2020 2020 656e 765f 7374            env_st
-000082b0: 6174 655f 6469 6374 203d 204f 7264 6572  ate_dict = Order
-000082c0: 6564 4469 6374 2829 0d0a 0d0a 2020 2020  edDict()....    
-000082d0: 2020 2020 6966 2068 6173 6174 7472 2873      if hasattr(s
-000082e0: 656c 662e 706f 6c69 6379 2c20 2273 7461  elf.policy, "sta
-000082f0: 7465 5f64 6963 7422 293a 0d0a 2020 2020  te_dict"):..    
-00008300: 2020 2020 2020 2020 706f 6c69 6379 5f73          policy_s
-00008310: 7461 7465 5f64 6963 7420 3d20 7365 6c66  tate_dict = self
-00008320: 2e70 6f6c 6963 792e 7374 6174 655f 6469  .policy.state_di
-00008330: 6374 2829 0d0a 2020 2020 2020 2020 2020  ct()..          
-00008340: 2020 7374 6174 655f 6469 6374 203d 204f    state_dict = O
-00008350: 7264 6572 6564 4469 6374 280d 0a20 2020  rderedDict(..   
-00008360: 2020 2020 2020 2020 2020 2020 2070 6f6c               pol
-00008370: 6963 795f 7374 6174 655f 6469 6374 3d70  icy_state_dict=p
-00008380: 6f6c 6963 795f 7374 6174 655f 6469 6374  olicy_state_dict
-00008390: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
-000083a0: 2020 2065 6e76 5f73 7461 7465 5f64 6963     env_state_dic
-000083b0: 743d 656e 765f 7374 6174 655f 6469 6374  t=env_state_dict
-000083c0: 2c0d 0a20 2020 2020 2020 2020 2020 2029  ,..            )
-000083d0: 0d0a 2020 2020 2020 2020 656c 7365 3a0d  ..        else:.
-000083e0: 0a20 2020 2020 2020 2020 2020 2073 7461  .            sta
-000083f0: 7465 5f64 6963 7420 3d20 4f72 6465 7265  te_dict = Ordere
-00008400: 6444 6963 7428 656e 765f 7374 6174 655f  dDict(env_state_
-00008410: 6469 6374 3d65 6e76 5f73 7461 7465 5f64  dict=env_state_d
-00008420: 6963 7429 0d0a 0d0a 2020 2020 2020 2020  ict)....        
-00008430: 7265 7475 726e 2073 7461 7465 5f64 6963  return state_dic
-00008440: 740d 0a0d 0a20 2020 2064 6566 206c 6f61  t....    def loa
-00008450: 645f 7374 6174 655f 6469 6374 2873 656c  d_state_dict(sel
-00008460: 662c 2073 7461 7465 5f64 6963 743a 204f  f, state_dict: O
-00008470: 7264 6572 6564 4469 6374 2c20 2a2a 6b77  rderedDict, **kw
-00008480: 6172 6773 2920 2d3e 204e 6f6e 653a 0d0a  args) -> None:..
-00008490: 2020 2020 2020 2020 2222 224c 6f61 6473          """Loads
-000084a0: 2061 2073 7461 7465 5f64 6963 7420 6f6e   a state_dict on
-000084b0: 2074 6865 2065 6e76 6972 6f6e 6d65 6e74   the environment
-000084c0: 2061 6e64 2070 6f6c 6963 792e 0d0a 0d0a   and policy.....
-000084d0: 2020 2020 2020 2020 4172 6773 3a0d 0a20          Args:.. 
-000084e0: 2020 2020 2020 2020 2020 2073 7461 7465             state
-000084f0: 5f64 6963 7420 284f 7264 6572 6564 4469  _dict (OrderedDi
-00008500: 6374 293a 206f 7264 6572 6564 2064 6963  ct): ordered dic
-00008510: 7469 6f6e 6172 7920 636f 6e74 6169 6e69  tionary containi
-00008520: 6e67 2074 6865 2066 6965 6c64 730d 0a20  ng the fields.. 
-00008530: 2020 2020 2020 2020 2020 2020 2020 2060                 `
-00008540: 2270 6f6c 6963 795f 7374 6174 655f 6469  "policy_state_di
-00008550: 6374 2260 2061 6e64 203a 6f62 6a3a 6022  ct"` and :obj:`"
-00008560: 656e 765f 7374 6174 655f 6469 6374 2260  env_state_dict"`
-00008570: 2e0d 0a0d 0a20 2020 2020 2020 2022 2222  .....        """
-00008580: 0d0a 2020 2020 2020 2020 7374 7269 6374  ..        strict
-00008590: 203d 206b 7761 7267 732e 6765 7428 2273   = kwargs.get("s
-000085a0: 7472 6963 7422 2c20 5472 7565 290d 0a20  trict", True).. 
-000085b0: 2020 2020 2020 2069 6620 7374 7269 6374         if strict
-000085c0: 206f 7220 2265 6e76 5f73 7461 7465 5f64   or "env_state_d
-000085d0: 6963 7422 2069 6e20 7374 6174 655f 6469  ict" in state_di
-000085e0: 6374 3a0d 0a20 2020 2020 2020 2020 2020  ct:..           
-000085f0: 2073 656c 662e 656e 762e 6c6f 6164 5f73   self.env.load_s
-00008600: 7461 7465 5f64 6963 7428 7374 6174 655f  tate_dict(state_
-00008610: 6469 6374 5b22 656e 765f 7374 6174 655f  dict["env_state_
-00008620: 6469 6374 225d 2c20 2a2a 6b77 6172 6773  dict"], **kwargs
-00008630: 290d 0a20 2020 2020 2020 2069 6620 7374  )..        if st
-00008640: 7269 6374 206f 7220 2270 6f6c 6963 795f  rict or "policy_
-00008650: 7374 6174 655f 6469 6374 2220 696e 2073  state_dict" in s
-00008660: 7461 7465 5f64 6963 743a 0d0a 2020 2020  tate_dict:..    
-00008670: 2020 2020 2020 2020 7365 6c66 2e70 6f6c          self.pol
-00008680: 6963 792e 6c6f 6164 5f73 7461 7465 5f64  icy.load_state_d
-00008690: 6963 7428 7374 6174 655f 6469 6374 5b22  ict(state_dict["
-000086a0: 706f 6c69 6379 5f73 7461 7465 5f64 6963  policy_state_dic
-000086b0: 7422 5d2c 202a 2a6b 7761 7267 7329 0d0a  t"], **kwargs)..
-000086c0: 0d0a 2020 2020 6465 6620 5f5f 7265 7072  ..    def __repr
-000086d0: 5f5f 2873 656c 6629 202d 3e20 7374 723a  __(self) -> str:
-000086e0: 0d0a 2020 2020 2020 2020 656e 765f 7374  ..        env_st
-000086f0: 7220 3d20 696e 6465 6e74 2866 2265 6e76  r = indent(f"env
-00008700: 3d7b 7365 6c66 2e65 6e76 7d22 2c20 3420  ={self.env}", 4 
-00008710: 2a20 2220 2229 0d0a 2020 2020 2020 2020  * " ")..        
-00008720: 706f 6c69 6379 5f73 7472 203d 2069 6e64  policy_str = ind
-00008730: 656e 7428 6622 706f 6c69 6379 3d7b 7365  ent(f"policy={se
-00008740: 6c66 2e70 6f6c 6963 797d 222c 2034 202a  lf.policy}", 4 *
-00008750: 2022 2022 290d 0a20 2020 2020 2020 2074   " ")..        t
-00008760: 645f 6f75 745f 7374 7220 3d20 696e 6465  d_out_str = inde
-00008770: 6e74 2866 2274 645f 6f75 743d 7b73 656c  nt(f"td_out={sel
-00008780: 662e 5f74 656e 736f 7264 6963 745f 6f75  f._tensordict_ou
-00008790: 747d 222c 2034 202a 2022 2022 290d 0a20  t}", 4 * " ").. 
-000087a0: 2020 2020 2020 2073 7472 696e 6720 3d20         string = 
-000087b0: 280d 0a20 2020 2020 2020 2020 2020 2066  (..            f
-000087c0: 227b 7365 6c66 2e5f 5f63 6c61 7373 5f5f  "{self.__class__
-000087d0: 2e5f 5f6e 616d 655f 5f7d 2822 0d0a 2020  .__name__}("..  
-000087e0: 2020 2020 2020 2020 2020 6622 5c6e 7b65            f"\n{e
-000087f0: 6e76 5f73 7472 7d2c 220d 0a20 2020 2020  nv_str},"..     
-00008800: 2020 2020 2020 2066 225c 6e7b 706f 6c69         f"\n{poli
-00008810: 6379 5f73 7472 7d2c 220d 0a20 2020 2020  cy_str},"..     
-00008820: 2020 2020 2020 2066 225c 6e7b 7464 5f6f         f"\n{td_o
-00008830: 7574 5f73 7472 7d2c 220d 0a20 2020 2020  ut_str},"..     
-00008840: 2020 2020 2020 2066 225c 6e65 7870 6c6f         f"\nexplo
-00008850: 7261 7469 6f6e 3d7b 7365 6c66 2e65 7870  ration={self.exp
-00008860: 6c6f 7261 7469 6f6e 5f6d 6f64 657d 2922  loration_mode})"
-00008870: 0d0a 2020 2020 2020 2020 290d 0a20 2020  ..        )..   
-00008880: 2020 2020 2072 6574 7572 6e20 7374 7269       return stri
-00008890: 6e67 0d0a 0d0a 0d0a 636c 6173 7320 5f4d  ng......class _M
-000088a0: 756c 7469 4461 7461 436f 6c6c 6563 746f  ultiDataCollecto
-000088b0: 7228 5f44 6174 6143 6f6c 6c65 6374 6f72  r(_DataCollector
-000088c0: 293a 0d0a 2020 2020 2222 2252 756e 7320  ):..    """Runs 
-000088d0: 6120 6769 7665 6e20 6e75 6d62 6572 206f  a given number o
-000088e0: 6620 4461 7461 436f 6c6c 6563 746f 7273  f DataCollectors
-000088f0: 206f 6e20 7365 7061 7261 7465 2070 726f   on separate pro
-00008900: 6365 7373 6573 2e0d 0a0d 0a20 2020 2041  cesses.....    A
-00008910: 7267 733a 0d0a 2020 2020 2020 2020 6372  rgs:..        cr
-00008920: 6561 7465 5f65 6e76 5f66 6e20 284c 6973  eate_env_fn (Lis
-00008930: 745b 4361 6c6c 6162 6c65 645d 293a 206c  t[Callabled]): l
-00008940: 6973 7420 6f66 2043 616c 6c61 626c 6573  ist of Callables
-00008950: 2c20 6561 6368 2072 6574 7572 6e69 6e67  , each returning
-00008960: 2061 6e0d 0a20 2020 2020 2020 2020 2020   an..           
-00008970: 2069 6e73 7461 6e63 6520 6f66 203a 636c   instance of :cl
-00008980: 6173 733a 6074 6f72 6368 726c 2e65 6e76  ass:`torchrl.env
-00008990: 732e 456e 7642 6173 6560 2e0d 0a20 2020  s.EnvBase`...   
-000089a0: 2020 2020 2070 6f6c 6963 7920 2843 616c       policy (Cal
-000089b0: 6c61 626c 652c 206f 7074 696f 6e61 6c29  lable, optional)
-000089c0: 3a20 496e 7374 616e 6365 206f 6620 5465  : Instance of Te
-000089d0: 6e73 6f72 4469 6374 4d6f 6475 6c65 2063  nsorDictModule c
-000089e0: 6c61 7373 2e0d 0a20 2020 2020 2020 2020  lass...         
-000089f0: 2020 204d 7573 7420 6163 6365 7074 2054     Must accept T
-00008a00: 656e 736f 7244 6963 7442 6173 6520 6f62  ensorDictBase ob
-00008a10: 6a65 6374 2061 7320 696e 7075 742e 0d0a  ject as input...
-00008a20: 2020 2020 2020 2020 2020 2020 4966 2060              If `
-00008a30: 604e 6f6e 6560 6020 6973 2070 726f 7669  `None`` is provi
-00008a40: 6465 642c 2074 6865 2070 6f6c 6963 7920  ded, the policy 
-00008a50: 7573 6564 2077 696c 6c20 6265 2061 0d0a  used will be a..
-00008a60: 2020 2020 2020 2020 2020 2020 3a63 6c61              :cla
-00008a70: 7373 3a60 5261 6e64 6f6d 506f 6c69 6379  ss:`RandomPolicy
-00008a80: 6020 696e 7374 616e 6365 2077 6974 6820  ` instance with 
-00008a90: 7468 6520 656e 7669 726f 6e6d 656e 740d  the environment.
-00008aa0: 0a20 2020 2020 2020 2020 2020 2060 6061  .            ``a
-00008ab0: 6374 696f 6e5f 7370 6563 6060 2e0d 0a20  ction_spec``... 
-00008ac0: 2020 2020 2020 2066 7261 6d65 735f 7065         frames_pe
-00008ad0: 725f 6261 7463 6820 2869 6e74 293a 2041  r_batch (int): A
-00008ae0: 206b 6579 776f 7264 2d6f 6e6c 7920 6172   keyword-only ar
-00008af0: 6775 6d65 6e74 2072 6570 7265 7365 6e74  gument represent
-00008b00: 696e 6720 7468 650d 0a20 2020 2020 2020  ing the..       
-00008b10: 2020 2020 2074 6f74 616c 206e 756d 6265       total numbe
-00008b20: 7220 6f66 2065 6c65 6d65 6e74 7320 696e  r of elements in
-00008b30: 2061 2062 6174 6368 2e0d 0a20 2020 2020   a batch...     
-00008b40: 2020 2074 6f74 616c 5f66 7261 6d65 7320     total_frames 
-00008b50: 2869 6e74 293a 2041 206b 6579 776f 7264  (int): A keyword
-00008b60: 2d6f 6e6c 7920 6172 6775 6d65 6e74 2072  -only argument r
-00008b70: 6570 7265 7365 6e74 696e 6720 7468 650d  epresenting the.
-00008b80: 0a20 2020 2020 2020 2020 2020 2074 6f74  .            tot
-00008b90: 616c 206e 756d 6265 7220 6f66 2066 7261  al number of fra
-00008ba0: 6d65 7320 7265 7475 726e 6564 2062 7920  mes returned by 
-00008bb0: 7468 6520 636f 6c6c 6563 746f 720d 0a20  the collector.. 
-00008bc0: 2020 2020 2020 2020 2020 2064 7572 696e             durin
-00008bd0: 6720 6974 7320 6c69 6665 7370 616e 2e20  g its lifespan. 
-00008be0: 4966 2074 6865 2060 6074 6f74 616c 5f66  If the ``total_f
-00008bf0: 7261 6d65 7360 6020 6973 206e 6f74 2064  rames`` is not d
-00008c00: 6976 6973 6962 6c65 2062 790d 0a20 2020  ivisible by..   
-00008c10: 2020 2020 2020 2020 2060 6066 7261 6d65           ``frame
-00008c20: 735f 7065 725f 6261 7463 6860 602c 2061  s_per_batch``, a
-00008c30: 6e20 6578 6365 7074 696f 6e20 6973 2072  n exception is r
-00008c40: 6169 7365 642e 0d0a 2020 2020 2020 2020  aised...        
-00008c50: 2020 2020 2045 6e64 6c65 7373 2063 6f6c       Endless col
-00008c60: 6c65 6374 6f72 7320 6361 6e20 6265 2063  lectors can be c
-00008c70: 7265 6174 6564 2062 7920 7061 7373 696e  reated by passin
-00008c80: 6720 6060 746f 7461 6c5f 6672 616d 6573  g ``total_frames
-00008c90: 3d2d 3160 602e 0d0a 2020 2020 2020 2020  =-1``...        
-00008ca0: 6465 7669 6365 2028 696e 742c 2073 7472  device (int, str
-00008cb0: 2c20 746f 7263 682e 6465 7669 6365 206f  , torch.device o
-00008cc0: 7220 7365 7175 656e 6365 206f 6620 7375  r sequence of su
-00008cd0: 6368 2c20 6f70 7469 6f6e 616c 293a 0d0a  ch, optional):..
-00008ce0: 2020 2020 2020 2020 2020 2020 5468 6520              The 
-00008cf0: 6465 7669 6365 206f 6e20 7768 6963 6820  device on which 
-00008d00: 7468 6520 706f 6c69 6379 2077 696c 6c20  the policy will 
-00008d10: 6265 2070 6c61 6365 642e 0d0a 2020 2020  be placed...    
-00008d20: 2020 2020 2020 2020 4966 2069 7420 6469          If it di
-00008d30: 6666 6572 7320 6672 6f6d 2074 6865 2069  ffers from the i
-00008d40: 6e70 7574 2070 6f6c 6963 7920 6465 7669  nput policy devi
-00008d50: 6365 2c20 7468 650d 0a20 2020 2020 2020  ce, the..       
-00008d60: 2020 2020 203a 6d65 7468 3a60 7e2e 7570       :meth:`~.up
-00008d70: 6461 7465 5f70 6f6c 6963 795f 7765 6967  date_policy_weig
-00008d80: 6874 735f 6020 6d65 7468 6f64 2073 686f  hts_` method sho
-00008d90: 756c 6420 6265 2071 7565 7269 6564 0d0a  uld be queried..
-00008da0: 2020 2020 2020 2020 2020 2020 6174 2061              at a
-00008db0: 7070 726f 7072 6961 7465 2074 696d 6573  ppropriate times
-00008dc0: 2064 7572 696e 6720 7468 6520 7472 6169   during the trai
-00008dd0: 6e69 6e67 206c 6f6f 7020 746f 2061 6363  ning loop to acc
-00008de0: 6f6d 6d6f 6461 7465 2066 6f72 0d0a 2020  ommodate for..  
-00008df0: 2020 2020 2020 2020 2020 7468 6520 6c61            the la
-00008e00: 6720 6265 7477 6565 6e20 7061 7261 6d65  g between parame
-00008e10: 7465 7220 636f 6e66 6967 7572 6174 696f  ter configuratio
-00008e20: 6e20 6174 2076 6172 696f 7573 2074 696d  n at various tim
-00008e30: 6573 2e0d 0a20 2020 2020 2020 2020 2020  es...           
-00008e40: 2049 6620 6e65 6365 7373 6172 792c 2061   If necessary, a
-00008e50: 206c 6973 7420 6f66 2064 6576 6963 6573   list of devices
-00008e60: 2063 616e 2062 6520 7061 7373 6564 2069   can be passed i
-00008e70: 6e20 7768 6963 6820 6361 7365 2065 6163  n which case eac
-00008e80: 680d 0a20 2020 2020 2020 2020 2020 2065  h..            e
-00008e90: 6c65 6d65 6e74 2077 696c 6c20 636f 7272  lement will corr
-00008ea0: 6573 706f 6e64 2074 6f20 7468 6520 6465  espond to the de
-00008eb0: 7369 676e 6174 6564 2064 6576 6963 6520  signated device 
-00008ec0: 6f66 2061 2073 7562 2d63 6f6c 6c65 6374  of a sub-collect
-00008ed0: 6f72 2e0d 0a20 2020 2020 2020 2020 2020  or...           
-00008ee0: 2044 6566 6175 6c74 7320 746f 2060 604e   Defaults to ``N
-00008ef0: 6f6e 6560 6020 2869 2e65 2e20 706f 6c69  one`` (i.e. poli
-00008f00: 6379 2069 7320 6b65 7074 206f 6e20 6974  cy is kept on it
-00008f10: 7320 6f72 6967 696e 616c 2064 6576 6963  s original devic
-00008f20: 6529 2e0d 0a20 2020 2020 2020 2073 746f  e)...        sto
-00008f30: 7269 6e67 5f64 6576 6963 6520 2869 6e74  ring_device (int
-00008f40: 2c20 7374 722c 2074 6f72 6368 2e64 6576  , str, torch.dev
-00008f50: 6963 6520 6f72 2073 6571 7565 6e63 6520  ice or sequence 
-00008f60: 6f66 2073 7563 682c 206f 7074 696f 6e61  of such, optiona
-00008f70: 6c29 3a0d 0a20 2020 2020 2020 2020 2020  l):..           
-00008f80: 2054 6865 2064 6576 6963 6520 6f6e 2077   The device on w
-00008f90: 6869 6368 2074 6865 206f 7574 7075 7420  hich the output 
-00008fa0: 3a63 6c61 7373 3a60 7465 6e73 6f72 6469  :class:`tensordi
-00008fb0: 6374 2e54 656e 736f 7244 6963 7460 2077  ct.TensorDict` w
-00008fc0: 696c 6c0d 0a20 2020 2020 2020 2020 2020  ill..           
-00008fd0: 2062 6520 7374 6f72 6564 2e20 466f 7220   be stored. For 
-00008fe0: 6c6f 6e67 2074 7261 6a65 6374 6f72 6965  long trajectorie
-00008ff0: 732c 2069 7420 6d61 7920 6265 206e 6563  s, it may be nec
-00009000: 6573 7361 7279 2074 6f20 7374 6f72 6520  essary to store 
-00009010: 7468 650d 0a20 2020 2020 2020 2020 2020  the..           
-00009020: 2064 6174 6120 6f6e 2061 2064 6966 6665   data on a diffe
-00009030: 7265 6e74 2064 6576 6963 6520 7468 616e  rent device than
-00009040: 2074 6865 206f 6e65 2077 6865 7265 2074   the one where t
-00009050: 6865 2070 6f6c 6963 7920 616e 6420 656e  he policy and en
-00009060: 760d 0a20 2020 2020 2020 2020 2020 2061  v..            a
-00009070: 7265 2065 7865 6375 7465 642e 0d0a 2020  re executed...  
-00009080: 2020 2020 2020 2020 2020 4966 206e 6563            If nec
-00009090: 6573 7361 7279 2c20 6120 6c69 7374 206f  essary, a list o
-000090a0: 6620 6465 7669 6365 7320 6361 6e20 6265  f devices can be
-000090b0: 2070 6173 7365 6420 696e 2077 6869 6368   passed in which
-000090c0: 2063 6173 6520 6561 6368 0d0a 2020 2020   case each..    
-000090d0: 2020 2020 2020 2020 656c 656d 656e 7420          element 
-000090e0: 7769 6c6c 2063 6f72 7265 7370 6f6e 6420  will correspond 
-000090f0: 746f 2074 6865 2064 6573 6967 6e61 7465  to the designate
-00009100: 6420 7374 6f72 696e 6720 6465 7669 6365  d storing device
-00009110: 206f 6620 610d 0a20 2020 2020 2020 2020   of a..         
-00009120: 2020 2073 7562 2d63 6f6c 6c65 6374 6f72     sub-collector
-00009130: 2e0d 0a20 2020 2020 2020 2020 2020 2044  ...            D
-00009140: 6566 6175 6c74 7320 746f 2060 6022 6370  efaults to ``"cp
-00009150: 7522 6060 2e0d 0a20 2020 2020 2020 2063  u"``...        c
-00009160: 7265 6174 655f 656e 765f 6b77 6172 6773  reate_env_kwargs
-00009170: 2028 6469 6374 2c20 6f70 7469 6f6e 616c   (dict, optional
-00009180: 293a 2041 2064 6963 7469 6f6e 6172 7920  ): A dictionary 
-00009190: 7769 7468 2074 6865 0d0a 2020 2020 2020  with the..      
-000091a0: 2020 2020 2020 6b65 7977 6f72 6420 6172        keyword ar
-000091b0: 6775 6d65 6e74 7320 7573 6564 2074 6f20  guments used to 
-000091c0: 6372 6561 7465 2061 6e20 656e 7669 726f  create an enviro
-000091d0: 6e6d 656e 742e 2049 6620 6120 6c69 7374  nment. If a list
-000091e0: 2069 730d 0a20 2020 2020 2020 2020 2020   is..           
-000091f0: 2070 726f 7669 6465 642c 2065 6163 6820   provided, each 
-00009200: 6f66 2069 7473 2065 6c65 6d65 6e74 7320  of its elements 
-00009210: 7769 6c6c 2062 6520 6173 7369 676e 6564  will be assigned
-00009220: 2074 6f20 6120 7375 622d 636f 6c6c 6563   to a sub-collec
-00009230: 746f 722e 0d0a 2020 2020 2020 2020 6d61  tor...        ma
-00009240: 785f 6672 616d 6573 5f70 6572 5f74 7261  x_frames_per_tra
-00009250: 6a20 2869 6e74 2c20 6f70 7469 6f6e 616c  j (int, optional
-00009260: 293a 204d 6178 696d 756d 2073 7465 7073  ): Maximum steps
-00009270: 2070 6572 2074 7261 6a65 6374 6f72 792e   per trajectory.
-00009280: 0d0a 2020 2020 2020 2020 2020 2020 4e6f  ..            No
-00009290: 7465 2074 6861 7420 6120 7472 616a 6563  te that a trajec
-000092a0: 746f 7279 2063 616e 2073 7061 6e20 6f76  tory can span ov
-000092b0: 6572 206d 756c 7469 706c 6520 6261 7463  er multiple batc
-000092c0: 6865 7320 2875 6e6c 6573 730d 0a20 2020  hes (unless..   
-000092d0: 2020 2020 2020 2020 2060 6072 6573 6574           ``reset
-000092e0: 5f61 745f 6561 6368 5f69 7465 7260 6020  _at_each_iter`` 
-000092f0: 6973 2073 6574 2074 6f20 6060 5472 7565  is set to ``True
-00009300: 6060 2c20 7365 6520 6265 6c6f 7729 2e0d  ``, see below)..
-00009310: 0a20 2020 2020 2020 2020 2020 204f 6e63  .            Onc
-00009320: 6520 6120 7472 616a 6563 746f 7279 2072  e a trajectory r
-00009330: 6561 6368 6573 2060 606e 5f73 7465 7073  eaches ``n_steps
-00009340: 6060 2c20 7468 6520 656e 7669 726f 6e6d  ``, the environm
-00009350: 656e 7420 6973 2072 6573 6574 2e0d 0a20  ent is reset... 
-00009360: 2020 2020 2020 2020 2020 2049 6620 7468             If th
-00009370: 6520 656e 7669 726f 6e6d 656e 7420 7772  e environment wr
-00009380: 6170 7320 6d75 6c74 6970 6c65 2065 6e76  aps multiple env
-00009390: 6972 6f6e 6d65 6e74 7320 746f 6765 7468  ironments togeth
-000093a0: 6572 2c20 7468 6520 6e75 6d62 6572 0d0a  er, the number..
-000093b0: 2020 2020 2020 2020 2020 2020 6f66 2073              of s
-000093c0: 7465 7073 2069 7320 7472 6163 6b65 6420  teps is tracked 
-000093d0: 666f 7220 6561 6368 2065 6e76 6972 6f6e  for each environ
-000093e0: 6d65 6e74 2069 6e64 6570 656e 6465 6e74  ment independent
-000093f0: 6c79 2e20 4e65 6761 7469 7665 0d0a 2020  ly. Negative..  
-00009400: 2020 2020 2020 2020 2020 7661 6c75 6573            values
-00009410: 2061 7265 2061 6c6c 6f77 6564 2c20 696e   are allowed, in
-00009420: 2077 6869 6368 2063 6173 6520 7468 6973   which case this
-00009430: 2061 7267 756d 656e 7420 6973 2069 676e   argument is ign
-00009440: 6f72 6564 2e0d 0a20 2020 2020 2020 2020  ored...         
-00009450: 2020 2044 6566 6175 6c74 7320 746f 2060     Defaults to `
-00009460: 602d 3160 6020 2869 2e65 2e20 6e6f 206d  `-1`` (i.e. no m
-00009470: 6178 696d 756d 206e 756d 6265 7220 6f66  aximum number of
-00009480: 2073 7465 7073 292e 0d0a 2020 2020 2020   steps)...      
-00009490: 2020 696e 6974 5f72 616e 646f 6d5f 6672    init_random_fr
-000094a0: 616d 6573 2028 696e 742c 206f 7074 696f  ames (int, optio
-000094b0: 6e61 6c29 3a20 4e75 6d62 6572 206f 6620  nal): Number of 
-000094c0: 6672 616d 6573 2066 6f72 2077 6869 6368  frames for which
-000094d0: 2074 6865 0d0a 2020 2020 2020 2020 2020   the..          
-000094e0: 2020 706f 6c69 6379 2069 7320 6967 6e6f    policy is igno
-000094f0: 7265 6420 6265 666f 7265 2069 7420 6973  red before it is
-00009500: 2063 616c 6c65 642e 2054 6869 7320 6665   called. This fe
-00009510: 6174 7572 6520 6973 206d 6169 6e6c 790d  ature is mainly.
-00009520: 0a20 2020 2020 2020 2020 2020 2069 6e74  .            int
-00009530: 656e 6465 6420 746f 2062 6520 7573 6564  ended to be used
-00009540: 2069 6e20 6f66 666c 696e 652f 6d6f 6465   in offline/mode
-00009550: 6c2d 6261 7365 6420 7365 7474 696e 6773  l-based settings
-00009560: 2c20 7768 6572 6520 610d 0a20 2020 2020  , where a..     
-00009570: 2020 2020 2020 2062 6174 6368 206f 6620         batch of 
-00009580: 7261 6e64 6f6d 2074 7261 6a65 6374 6f72  random trajector
-00009590: 6965 7320 6361 6e20 6265 2075 7365 6420  ies can be used 
-000095a0: 746f 2069 6e69 7469 616c 697a 6520 7472  to initialize tr
-000095b0: 6169 6e69 6e67 2e0d 0a20 2020 2020 2020  aining...       
-000095c0: 2020 2020 2044 6566 6175 6c74 7320 746f       Defaults to
-000095d0: 2060 602d 3160 6020 2869 2e65 2e20 6e6f   ``-1`` (i.e. no
-000095e0: 2072 616e 646f 6d20 6672 616d 6573 292e   random frames).
-000095f0: 0d0a 2020 2020 2020 2020 7265 7365 745f  ..        reset_
-00009600: 6174 5f65 6163 685f 6974 6572 2028 626f  at_each_iter (bo
-00009610: 6f6c 2c20 6f70 7469 6f6e 616c 293a 2057  ol, optional): W
-00009620: 6865 7468 6572 2065 6e76 6972 6f6e 6d65  hether environme
-00009630: 6e74 7320 7368 6f75 6c64 2062 6520 7265  nts should be re
-00009640: 7365 740d 0a20 2020 2020 2020 2020 2020  set..           
-00009650: 2061 7420 7468 6520 6265 6769 6e6e 696e   at the beginnin
-00009660: 6720 6f66 2061 2062 6174 6368 2063 6f6c  g of a batch col
-00009670: 6c65 6374 696f 6e2e 0d0a 2020 2020 2020  lection...      
-00009680: 2020 2020 2020 4465 6661 756c 7473 2074        Defaults t
-00009690: 6f20 6060 4661 6c73 6560 602e 0d0a 2020  o ``False``...  
-000096a0: 2020 2020 2020 706f 7374 7072 6f63 2028        postproc (
-000096b0: 4361 6c6c 6162 6c65 2c20 6f70 7469 6f6e  Callable, option
-000096c0: 616c 293a 2041 2070 6f73 742d 7072 6f63  al): A post-proc
-000096d0: 6573 7369 6e67 2074 7261 6e73 666f 726d  essing transform
-000096e0: 2c20 7375 6368 2061 730d 0a20 2020 2020  , such as..     
-000096f0: 2020 2020 2020 2061 203a 636c 6173 733a         a :class:
-00009700: 6074 6f72 6368 726c 2e65 6e76 732e 5472  `torchrl.envs.Tr
-00009710: 616e 7366 6f72 6d60 206f 7220 6120 3a63  ansform` or a :c
-00009720: 6c61 7373 3a60 746f 7263 6872 6c2e 6461  lass:`torchrl.da
-00009730: 7461 2e70 6f73 7470 726f 6373 2e4d 756c  ta.postprocs.Mul
-00009740: 7469 5374 6570 600d 0a20 2020 2020 2020  tiStep`..       
-00009750: 2020 2020 2069 6e73 7461 6e63 652e 0d0a       instance...
-00009760: 2020 2020 2020 2020 2020 2020 4465 6661              Defa
-00009770: 756c 7473 2074 6f20 6060 4e6f 6e65 6060  ults to ``None``
-00009780: 2e0d 0a20 2020 2020 2020 2073 706c 6974  ...        split
-00009790: 5f74 7261 6a73 2028 626f 6f6c 2c20 6f70  _trajs (bool, op
-000097a0: 7469 6f6e 616c 293a 2042 6f6f 6c65 616e  tional): Boolean
-000097b0: 2069 6e64 6963 6174 696e 6720 7768 6574   indicating whet
-000097c0: 6865 7220 7468 6520 7265 7375 6c74 696e  her the resultin
-000097d0: 670d 0a20 2020 2020 2020 2020 2020 2054  g..            T
-000097e0: 656e 736f 7244 6963 7420 7368 6f75 6c64  ensorDict should
-000097f0: 2062 6520 7370 6c69 7420 6163 636f 7264   be split accord
-00009800: 696e 6720 746f 2074 6865 2074 7261 6a65  ing to the traje
-00009810: 6374 6f72 6965 732e 0d0a 2020 2020 2020  ctories...      
-00009820: 2020 2020 2020 5365 6520 3a66 756e 633a        See :func:
-00009830: 6074 6f72 6368 726c 2e63 6f6c 6c65 6374  `torchrl.collect
-00009840: 6f72 732e 7574 696c 732e 7370 6c69 745f  ors.utils.split_
-00009850: 7472 616a 6563 746f 7269 6573 6020 666f  trajectories` fo
-00009860: 7220 6d6f 7265 0d0a 2020 2020 2020 2020  r more..        
-00009870: 2020 2020 696e 666f 726d 6174 696f 6e2e      information.
-00009880: 0d0a 2020 2020 2020 2020 2020 2020 4465  ..            De
-00009890: 6661 756c 7473 2074 6f20 6060 4661 6c73  faults to ``Fals
-000098a0: 6560 602e 0d0a 2020 2020 2020 2020 6578  e``...        ex
-000098b0: 706c 6f72 6174 696f 6e5f 6d6f 6465 2028  ploration_mode (
-000098c0: 7374 722c 206f 7074 696f 6e61 6c29 3a20  str, optional): 
-000098d0: 696e 7465 7261 6374 696f 6e20 6d6f 6465  interaction mode
-000098e0: 2074 6f20 6265 2075 7365 6420 7768 656e   to be used when
-000098f0: 0d0a 2020 2020 2020 2020 2020 2020 636f  ..            co
-00009900: 6c6c 6563 7469 6e67 2064 6174 612e 204d  llecting data. M
-00009910: 7573 7420 6265 206f 6e65 206f 6620 6060  ust be one of ``
-00009920: 2272 616e 646f 6d22 6060 2c20 6060 226d  "random"``, ``"m
-00009930: 6f64 6522 6060 206f 720d 0a20 2020 2020  ode"`` or..     
-00009940: 2020 2020 2020 2060 6022 6d65 616e 2260         ``"mean"`
-00009950: 602e 0d0a 2020 2020 2020 2020 2020 2020  `...            
-00009960: 4465 6661 756c 7473 2074 6f20 6060 2272  Defaults to ``"r
-00009970: 616e 646f 6d22 6060 0d0a 2020 2020 2020  andom"``..      
-00009980: 2020 7265 7475 726e 5f73 616d 655f 7464    return_same_td
-00009990: 2028 626f 6f6c 2c20 6f70 7469 6f6e 616c   (bool, optional
-000099a0: 293a 2069 6620 6060 5472 7565 6060 2c20  ): if ``True``, 
-000099b0: 7468 6520 7361 6d65 2054 656e 736f 7244  the same TensorD
-000099c0: 6963 740d 0a20 2020 2020 2020 2020 2020  ict..           
-000099d0: 2077 696c 6c20 6265 2072 6574 7572 6e65   will be returne
-000099e0: 6420 6174 2065 6163 6820 6974 6572 6174  d at each iterat
-000099f0: 696f 6e2c 2077 6974 6820 6974 7320 7661  ion, with its va
-00009a00: 6c75 6573 0d0a 2020 2020 2020 2020 2020  lues..          
-00009a10: 2020 7570 6461 7465 642e 2054 6869 7320    updated. This 
-00009a20: 6665 6174 7572 6520 7368 6f75 6c64 2062  feature should b
-00009a30: 6520 7573 6564 2063 6175 7469 6f75 736c  e used cautiousl
-00009a40: 793a 2069 6620 7468 6520 7361 6d65 0d0a  y: if the same..
-00009a50: 2020 2020 2020 2020 2020 2020 7465 6e73              tens
-00009a60: 6f72 6469 6374 2069 7320 6164 6465 6420  ordict is added 
-00009a70: 746f 2061 2072 6570 6c61 7920 6275 6666  to a replay buff
-00009a80: 6572 2066 6f72 2069 6e73 7461 6e63 652c  er for instance,
-00009a90: 0d0a 2020 2020 2020 2020 2020 2020 7468  ..            th
-00009aa0: 6520 7768 6f6c 6520 636f 6e74 656e 7420  e whole content 
-00009ab0: 6f66 2074 6865 2062 7566 6665 7220 7769  of the buffer wi
-00009ac0: 6c6c 2062 6520 6964 656e 7469 6361 6c2e  ll be identical.
-00009ad0: 0d0a 2020 2020 2020 2020 2020 2020 4465  ..            De
-00009ae0: 6661 756c 7420 6973 2060 6046 616c 7365  fault is ``False
-00009af0: 6060 2e0d 0a20 2020 2020 2020 2072 6573  ``...        res
-00009b00: 6574 5f77 6865 6e5f 646f 6e65 2028 626f  et_when_done (bo
-00009b10: 6f6c 2c20 6f70 7469 6f6e 616c 293a 2069  ol, optional): i
-00009b20: 6620 6060 5472 7565 6060 2028 6465 6661  f ``True`` (defa
-00009b30: 756c 7429 2c20 616e 2065 6e76 6972 6f6e  ult), an environ
-00009b40: 6d65 6e74 0d0a 2020 2020 2020 2020 2020  ment..          
-00009b50: 2020 7468 6174 2072 6574 7572 6e20 6120    that return a 
-00009b60: 6060 5472 7565 6060 2076 616c 7565 2069  ``True`` value i
-00009b70: 6e20 6974 7320 6060 2264 6f6e 6522 6060  n its ``"done"``
-00009b80: 206f 7220 6060 2274 7275 6e63 6174 6564   or ``"truncated
-00009b90: 2260 600d 0a20 2020 2020 2020 2020 2020  "``..           
-00009ba0: 2065 6e74 7279 2077 696c 6c20 6265 2072   entry will be r
-00009bb0: 6573 6574 2061 7420 7468 6520 636f 7272  eset at the corr
-00009bc0: 6573 706f 6e64 696e 6720 696e 6469 6365  esponding indice
-00009bd0: 732e 0d0a 2020 2020 2020 2020 7570 6461  s...        upda
-00009be0: 7465 5f61 745f 6561 6368 5f62 6174 6368  te_at_each_batch
-00009bf0: 2028 626f 6f6c 6d20 6f70 7469 6f6e 616c   (boolm optional
-00009c00: 293a 2069 6620 6060 5472 7565 6060 2c20  ): if ``True``, 
-00009c10: 3a6d 6574 683a 607e 2e75 7064 6174 655f  :meth:`~.update_
-00009c20: 706f 6c69 6379 5f77 6569 6768 745f 2829  policy_weight_()
-00009c30: 600d 0a20 2020 2020 2020 2020 2020 2077  `..            w
-00009c40: 696c 6c20 6265 2063 616c 6c65 6420 6265  ill be called be
-00009c50: 666f 7265 2028 7379 6e63 2920 6f72 2061  fore (sync) or a
-00009c60: 6674 6572 2028 6173 796e 6329 2065 6163  fter (async) eac
-00009c70: 6820 6461 7461 2063 6f6c 6c65 6374 696f  h data collectio
-00009c80: 6e2e 0d0a 2020 2020 2020 2020 2020 2020  n...            
-00009c90: 4465 6661 756c 7473 2074 6f20 6060 4661  Defaults to ``Fa
-00009ca0: 6c73 6560 602e 0d0a 0d0a 2020 2020 2222  lse``.....    ""
-00009cb0: 220d 0a0d 0a20 2020 2064 6566 205f 5f69  "....    def __i
-00009cc0: 6e69 745f 5f28 0d0a 2020 2020 2020 2020  nit__(..        
-00009cd0: 7365 6c66 2c0d 0a20 2020 2020 2020 2063  self,..        c
-00009ce0: 7265 6174 655f 656e 765f 666e 3a20 5365  reate_env_fn: Se
-00009cf0: 7175 656e 6365 5b43 616c 6c61 626c 655b  quence[Callable[
-00009d00: 5b5d 2c20 456e 7642 6173 655d 5d2c 0d0a  [], EnvBase]],..
-00009d10: 2020 2020 2020 2020 706f 6c69 6379 3a20          policy: 
-00009d20: 4f70 7469 6f6e 616c 5b0d 0a20 2020 2020  Optional[..     
-00009d30: 2020 2020 2020 2055 6e69 6f6e 5b0d 0a20         Union[.. 
-00009d40: 2020 2020 2020 2020 2020 2020 2020 2054                 T
-00009d50: 656e 736f 7244 6963 744d 6f64 756c 652c  ensorDictModule,
-00009d60: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00009d70: 2020 4361 6c6c 6162 6c65 5b5b 5465 6e73    Callable[[Tens
-00009d80: 6f72 4469 6374 4261 7365 5d2c 2054 656e  orDictBase], Ten
-00009d90: 736f 7244 6963 7442 6173 655d 2c0d 0a20  sorDictBase],.. 
-00009da0: 2020 2020 2020 2020 2020 205d 0d0a 2020             ]..  
-00009db0: 2020 2020 2020 5d2c 0d0a 2020 2020 2020        ],..      
-00009dc0: 2020 2a2c 0d0a 2020 2020 2020 2020 6672    *,..        fr
-00009dd0: 616d 6573 5f70 6572 5f62 6174 6368 3a20  ames_per_batch: 
-00009de0: 696e 7420 3d20 3230 302c 0d0a 2020 2020  int = 200,..    
-00009df0: 2020 2020 746f 7461 6c5f 6672 616d 6573      total_frames
-00009e00: 3a20 4f70 7469 6f6e 616c 5b69 6e74 5d20  : Optional[int] 
-00009e10: 3d20 2d31 2c0d 0a20 2020 2020 2020 2064  = -1,..        d
-00009e20: 6576 6963 653a 2044 4556 4943 455f 5459  evice: DEVICE_TY
-00009e30: 5049 4e47 203d 204e 6f6e 652c 0d0a 2020  PING = None,..  
-00009e40: 2020 2020 2020 7374 6f72 696e 675f 6465        storing_de
-00009e50: 7669 6365 3a20 4f70 7469 6f6e 616c 5b55  vice: Optional[U
-00009e60: 6e69 6f6e 5b44 4556 4943 455f 5459 5049  nion[DEVICE_TYPI
-00009e70: 4e47 2c20 5365 7175 656e 6365 5b44 4556  NG, Sequence[DEV
-00009e80: 4943 455f 5459 5049 4e47 5d5d 5d20 3d20  ICE_TYPING]]] = 
-00009e90: 4e6f 6e65 2c0d 0a20 2020 2020 2020 2063  None,..        c
-00009ea0: 7265 6174 655f 656e 765f 6b77 6172 6773  reate_env_kwargs
-00009eb0: 3a20 4f70 7469 6f6e 616c 5b53 6571 7565  : Optional[Seque
-00009ec0: 6e63 655b 6469 6374 5d5d 203d 204e 6f6e  nce[dict]] = Non
-00009ed0: 652c 0d0a 2020 2020 2020 2020 6d61 785f  e,..        max_
-00009ee0: 6672 616d 6573 5f70 6572 5f74 7261 6a3a  frames_per_traj:
-00009ef0: 2069 6e74 203d 202d 312c 0d0a 2020 2020   int = -1,..    
-00009f00: 2020 2020 696e 6974 5f72 616e 646f 6d5f      init_random_
-00009f10: 6672 616d 6573 3a20 696e 7420 3d20 2d31  frames: int = -1
-00009f20: 2c0d 0a20 2020 2020 2020 2072 6573 6574  ,..        reset
-00009f30: 5f61 745f 6561 6368 5f69 7465 723a 2062  _at_each_iter: b
-00009f40: 6f6f 6c20 3d20 4661 6c73 652c 0d0a 2020  ool = False,..  
-00009f50: 2020 2020 2020 706f 7374 7072 6f63 3a20        postproc: 
-00009f60: 4f70 7469 6f6e 616c 5b43 616c 6c61 626c  Optional[Callabl
-00009f70: 655b 5b54 656e 736f 7244 6963 7442 6173  e[[TensorDictBas
-00009f80: 655d 2c20 5465 6e73 6f72 4469 6374 4261  e], TensorDictBa
-00009f90: 7365 5d5d 203d 204e 6f6e 652c 0d0a 2020  se]] = None,..  
-00009fa0: 2020 2020 2020 7370 6c69 745f 7472 616a        split_traj
-00009fb0: 733a 204f 7074 696f 6e61 6c5b 626f 6f6c  s: Optional[bool
-00009fc0: 5d20 3d20 4e6f 6e65 2c0d 0a20 2020 2020  ] = None,..     
-00009fd0: 2020 2065 7870 6c6f 7261 7469 6f6e 5f6d     exploration_m
-00009fe0: 6f64 653a 2073 7472 203d 2044 4546 4155  ode: str = DEFAU
-00009ff0: 4c54 5f45 5850 4c4f 5241 5449 4f4e 5f4d  LT_EXPLORATION_M
-0000a000: 4f44 452c 0d0a 2020 2020 2020 2020 7265  ODE,..        re
-0000a010: 7365 745f 7768 656e 5f64 6f6e 653a 2062  set_when_done: b
-0000a020: 6f6f 6c20 3d20 5472 7565 2c0d 0a20 2020  ool = True,..   
-0000a030: 2020 2020 2075 7064 6174 655f 6174 5f65       update_at_e
-0000a040: 6163 685f 6261 7463 683a 2062 6f6f 6c20  ach_batch: bool 
-0000a050: 3d20 4661 6c73 652c 0d0a 2020 2020 2020  = False,..      
-0000a060: 2020 6465 7669 6365 733d 4e6f 6e65 2c0d    devices=None,.
-0000a070: 0a20 2020 2020 2020 2073 746f 7269 6e67  .        storing
-0000a080: 5f64 6576 6963 6573 3d4e 6f6e 652c 0d0a  _devices=None,..
-0000a090: 2020 2020 293a 0d0a 2020 2020 2020 2020      ):..        
-0000a0a0: 7365 6c66 2e63 6c6f 7365 6420 3d20 5472  self.closed = Tr
-0000a0b0: 7565 0d0a 2020 2020 2020 2020 7365 6c66  ue..        self
-0000a0c0: 2e63 7265 6174 655f 656e 765f 666e 203d  .create_env_fn =
-0000a0d0: 2063 7265 6174 655f 656e 765f 666e 0d0a   create_env_fn..
-0000a0e0: 2020 2020 2020 2020 7365 6c66 2e6e 756d          self.num
-0000a0f0: 5f77 6f72 6b65 7273 203d 206c 656e 2863  _workers = len(c
-0000a100: 7265 6174 655f 656e 765f 666e 290d 0a20  reate_env_fn).. 
-0000a110: 2020 2020 2020 2073 656c 662e 6372 6561         self.crea
-0000a120: 7465 5f65 6e76 5f6b 7761 7267 7320 3d20  te_env_kwargs = 
-0000a130: 280d 0a20 2020 2020 2020 2020 2020 2063  (..            c
-0000a140: 7265 6174 655f 656e 765f 6b77 6172 6773  reate_env_kwargs
-0000a150: 0d0a 2020 2020 2020 2020 2020 2020 6966  ..            if
-0000a160: 2063 7265 6174 655f 656e 765f 6b77 6172   create_env_kwar
-0000a170: 6773 2069 7320 6e6f 7420 4e6f 6e65 0d0a  gs is not None..
-0000a180: 2020 2020 2020 2020 2020 2020 656c 7365              else
-0000a190: 205b 7b7d 2066 6f72 205f 2069 6e20 7261   [{} for _ in ra
-0000a1a0: 6e67 6528 7365 6c66 2e6e 756d 5f77 6f72  nge(self.num_wor
-0000a1b0: 6b65 7273 295d 0d0a 2020 2020 2020 2020  kers)]..        
-0000a1c0: 290d 0a20 2020 2020 2020 2023 2050 7265  )..        # Pre
-0000a1d0: 7061 7269 6e67 2064 6576 6963 6573 3a0d  paring devices:.
-0000a1e0: 0a20 2020 2020 2020 2023 2057 6520 7761  .        # We wa
-0000a1f0: 6e74 2074 6865 2075 7365 7220 746f 2062  nt the user to b
-0000a200: 6520 6162 6c65 2074 6f20 6368 6f6f 7365  e able to choose
-0000a210: 2c20 666f 7220 6561 6368 2077 6f72 6b65  , for each worke
-0000a220: 722c 206f 6e20 7768 6963 680d 0a20 2020  r, on which..   
-0000a230: 2020 2020 2023 2064 6576 6963 6520 7769       # device wi
-0000a240: 6c6c 2074 6865 2070 6f6c 6963 7920 6c69  ll the policy li
-0000a250: 7665 2061 6e64 2077 6869 6368 2064 6576  ve and which dev
-0000a260: 6963 6520 7769 6c6c 2062 6520 7573 6564  ice will be used
-0000a270: 2074 6f20 7374 6f72 650d 0a20 2020 2020   to store..     
-0000a280: 2020 2023 2064 6174 612e 2054 686f 7365     # data. Those
-0000a290: 2064 6576 6963 6573 206d 6179 206f 7220   devices may or 
-0000a2a0: 6d61 7920 6e6f 7420 6d61 7463 682e 0d0a  may not match...
-0000a2b0: 2020 2020 2020 2020 2320 4f6e 6520 6361          # One ca
-0000a2c0: 7665 6174 2069 7320 7468 6174 2c20 6966  veat is that, if
-0000a2d0: 2074 6865 7265 2069 7320 6f6e 6c79 206f   there is only o
-0000a2e0: 6e65 2064 6576 6963 6520 666f 7220 7468  ne device for th
-0000a2f0: 6520 706f 6c69 6379 2c20 616e 640d 0a20  e policy, and.. 
-0000a300: 2020 2020 2020 2023 2069 6620 7468 6572         # if ther
-0000a310: 6520 6172 6520 6d75 6c74 6970 6c65 2077  e are multiple w
-0000a320: 6f72 6b65 7273 2c20 7365 6e64 696e 6720  orkers, sending 
-0000a330: 7468 6520 7361 6d65 2064 6576 6963 6520  the same device 
-0000a340: 616e 6420 706f 6c69 6379 0d0a 2020 2020  and policy..    
-0000a350: 2020 2020 2320 746f 2062 6520 636f 7069      # to be copi
-0000a360: 6564 2074 6f20 6561 6368 2077 6f72 6b65  ed to each worke
-0000a370: 7220 7769 6c6c 2072 6573 756c 7420 696e  r will result in
-0000a380: 206d 756c 7469 706c 6520 636f 7069 6573   multiple copies
-0000a390: 206f 6620 7468 650d 0a20 2020 2020 2020   of the..       
-0000a3a0: 2023 2073 616d 6520 706f 6c69 6379 206f   # same policy o
-0000a3b0: 6e20 7468 6520 7361 6d65 2064 6576 6963  n the same devic
-0000a3c0: 652e 0d0a 2020 2020 2020 2020 2320 546f  e...        # To
-0000a3d0: 2067 6f20 6172 6f75 6e64 2074 6869 732c   go around this,
-0000a3e0: 2077 6520 646f 2074 6865 2063 6f70 6965   we do the copie
-0000a3f0: 7320 6f66 2074 6865 2070 6f6c 6963 7920  s of the policy 
-0000a400: 696e 2074 6865 2073 6572 7665 720d 0a20  in the server.. 
-0000a410: 2020 2020 2020 2023 2028 7468 6973 206f         # (this o
-0000a420: 626a 6563 7429 2074 6f20 6561 6368 2070  bject) to each p
-0000a430: 6f73 7369 626c 6520 6465 7669 6365 2c20  ossible device, 
-0000a440: 616e 6420 7365 6e64 2074 6f20 616c 6c20  and send to all 
-0000a450: 7468 650d 0a20 2020 2020 2020 2023 2070  the..        # p
-0000a460: 726f 6365 7373 6573 2074 6865 6972 2063  rocesses their c
-0000a470: 6f70 7920 6f66 2074 6865 2070 6f6c 6963  opy of the polic
-0000a480: 792e 0d0a 2020 2020 2020 2020 6966 2064  y...        if d
-0000a490: 6576 6963 6573 2069 7320 6e6f 7420 4e6f  evices is not No
-0000a4a0: 6e65 3a0d 0a20 2020 2020 2020 2020 2020  ne:..           
-0000a4b0: 2069 6620 6465 7669 6365 2069 7320 6e6f   if device is no
-0000a4c0: 7420 4e6f 6e65 3a0d 0a20 2020 2020 2020  t None:..       
-0000a4d0: 2020 2020 2020 2020 2072 6169 7365 2056           raise V
-0000a4e0: 616c 7565 4572 726f 7228 2243 616e 6e6f  alueError("Canno
-0000a4f0: 7420 7061 7373 2062 6f74 6820 6465 7669  t pass both devi
-0000a500: 6365 7320 616e 6420 6465 7669 6365 2229  ces and device")
-0000a510: 0d0a 2020 2020 2020 2020 2020 2020 7761  ..            wa
-0000a520: 726e 696e 6773 2e77 6172 6e28 0d0a 2020  rnings.warn(..  
-0000a530: 2020 2020 2020 2020 2020 2020 2020 2260                "`
-0000a540: 6465 7669 6365 7360 206b 6579 776f 7264  devices` keyword
-0000a550: 2061 7267 756d 656e 7420 7769 6c6c 2073   argument will s
-0000a560: 6f6f 6e20 6265 2064 6570 7265 6361 7465  oon be deprecate
-0000a570: 6420 6672 6f6d 206d 756c 7469 7072 6f63  d from multiproc
-0000a580: 6573 7365 6420 636f 6c6c 6563 746f 7273  essed collectors
-0000a590: 2e20 220d 0a20 2020 2020 2020 2020 2020  . "..           
-0000a5a0: 2020 2020 2022 506c 6561 7365 2075 7365       "Please use
-0000a5b0: 2060 6465 7669 6365 6020 696e 7374 6561   `device` instea
-0000a5c0: 642e 220d 0a20 2020 2020 2020 2020 2020  d."..           
-0000a5d0: 2029 0d0a 2020 2020 2020 2020 2020 2020   )..            
-0000a5e0: 6465 7669 6365 203d 2064 6576 6963 6573  device = devices
-0000a5f0: 0d0a 2020 2020 2020 2020 6966 2073 746f  ..        if sto
-0000a600: 7269 6e67 5f64 6576 6963 6573 2069 7320  ring_devices is 
-0000a610: 6e6f 7420 4e6f 6e65 3a0d 0a20 2020 2020  not None:..     
-0000a620: 2020 2020 2020 2069 6620 7374 6f72 696e         if storin
-0000a630: 675f 6465 7669 6365 2069 7320 6e6f 7420  g_device is not 
-0000a640: 4e6f 6e65 3a0d 0a20 2020 2020 2020 2020  None:..         
-0000a650: 2020 2020 2020 2072 6169 7365 2056 616c         raise Val
-0000a660: 7565 4572 726f 7228 2243 616e 6e6f 7420  ueError("Cannot 
-0000a670: 7061 7373 2062 6f74 6820 7374 6f72 696e  pass both storin
-0000a680: 675f 6465 7669 6365 7320 616e 6420 7374  g_devices and st
-0000a690: 6f72 696e 675f 6465 7669 6365 2229 0d0a  oring_device")..
-0000a6a0: 2020 2020 2020 2020 2020 2020 7761 726e              warn
-0000a6b0: 696e 6773 2e77 6172 6e28 0d0a 2020 2020  ings.warn(..    
-0000a6c0: 2020 2020 2020 2020 2020 2020 2260 7374              "`st
-0000a6d0: 6f72 696e 675f 6465 7669 6365 7360 206b  oring_devices` k
-0000a6e0: 6579 776f 7264 2061 7267 756d 656e 7420  eyword argument 
-0000a6f0: 7769 6c6c 2073 6f6f 6e20 6265 2064 6570  will soon be dep
-0000a700: 7265 6361 7465 6420 6672 6f6d 206d 756c  recated from mul
-0000a710: 7469 7072 6f63 6573 7365 6420 636f 6c6c  tiprocessed coll
-0000a720: 6563 746f 7273 2e20 220d 0a20 2020 2020  ectors. "..     
-0000a730: 2020 2020 2020 2020 2020 2022 506c 6561             "Plea
-0000a740: 7365 2075 7365 2060 7374 6f72 696e 675f  se use `storing_
-0000a750: 6465 7669 6365 6020 696e 7374 6561 642e  device` instead.
-0000a760: 220d 0a20 2020 2020 2020 2020 2020 2029  "..            )
-0000a770: 0d0a 2020 2020 2020 2020 2020 2020 7374  ..            st
-0000a780: 6f72 696e 675f 6465 7669 6365 203d 2073  oring_device = s
-0000a790: 746f 7269 6e67 5f64 6576 6963 6573 0d0a  toring_devices..
-0000a7a0: 0d0a 2020 2020 2020 2020 6465 6620 6465  ..        def de
-0000a7b0: 7669 6365 5f65 7272 5f6d 7367 2864 6576  vice_err_msg(dev
-0000a7c0: 6963 655f 6e61 6d65 2c20 6465 7669 6365  ice_name, device
-0000a7d0: 735f 6c69 7374 293a 0d0a 2020 2020 2020  s_list):..      
-0000a7e0: 2020 2020 2020 7265 7475 726e 2028 0d0a        return (..
-0000a7f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a800: 6622 5468 6520 6c65 6e67 7468 206f 6620  f"The length of 
-0000a810: 7468 6520 7b64 6576 6963 655f 6e61 6d65  the {device_name
-0000a820: 7d20 6172 6775 6d65 6e74 2073 686f 756c  } argument shoul
-0000a830: 6420 6d61 7463 6820 7468 6520 220d 0a20  d match the ".. 
-0000a840: 2020 2020 2020 2020 2020 2020 2020 2066                 f
-0000a850: 226e 756d 6265 7220 6f66 2077 6f72 6b65  "number of worke
-0000a860: 7273 206f 6620 7468 6520 636f 6c6c 6563  rs of the collec
-0000a870: 746f 722e 2047 6f74 206c 656e 2822 0d0a  tor. Got len("..
-0000a880: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000a890: 6622 6372 6561 7465 5f65 6e76 5f66 6e29  f"create_env_fn)
-0000a8a0: 3d7b 7365 6c66 2e6e 756d 5f77 6f72 6b65  ={self.num_worke
-0000a8b0: 7273 7d20 616e 6420 6c65 6e28 220d 0a20  rs} and len(".. 
-0000a8c0: 2020 2020 2020 2020 2020 2020 2020 2066                 f
-0000a8d0: 2273 746f 7269 6e67 5f64 6576 6963 6529  "storing_device)
-0000a8e0: 3d7b 6c65 6e28 6465 7669 6365 735f 6c69  ={len(devices_li
-0000a8f0: 7374 297d 220d 0a20 2020 2020 2020 2020  st)}"..         
-0000a900: 2020 2029 0d0a 0d0a 2020 2020 2020 2020     )....        
-0000a910: 6966 2069 7369 6e73 7461 6e63 6528 6465  if isinstance(de
-0000a920: 7669 6365 2c20 2873 7472 2c20 696e 742c  vice, (str, int,
-0000a930: 2074 6f72 6368 2e64 6576 6963 6529 293a   torch.device)):
-0000a940: 0d0a 2020 2020 2020 2020 2020 2020 6465  ..            de
-0000a950: 7669 6365 203d 205b 746f 7263 682e 6465  vice = [torch.de
-0000a960: 7669 6365 2864 6576 6963 6529 2066 6f72  vice(device) for
-0000a970: 205f 2069 6e20 7261 6e67 6528 7365 6c66   _ in range(self
-0000a980: 2e6e 756d 5f77 6f72 6b65 7273 295d 0d0a  .num_workers)]..
-0000a990: 2020 2020 2020 2020 656c 6966 2064 6576          elif dev
-0000a9a0: 6963 6520 6973 204e 6f6e 653a 0d0a 2020  ice is None:..  
-0000a9b0: 2020 2020 2020 2020 2020 6465 7669 6365            device
-0000a9c0: 203d 205b 4e6f 6e65 2066 6f72 205f 2069   = [None for _ i
-0000a9d0: 6e20 7261 6e67 6528 7365 6c66 2e6e 756d  n range(self.num
-0000a9e0: 5f77 6f72 6b65 7273 295d 0d0a 2020 2020  _workers)]..    
-0000a9f0: 2020 2020 656c 6966 2069 7369 6e73 7461      elif isinsta
-0000aa00: 6e63 6528 6465 7669 6365 2c20 5365 7175  nce(device, Sequ
-0000aa10: 656e 6365 293a 0d0a 2020 2020 2020 2020  ence):..        
-0000aa20: 2020 2020 6966 206c 656e 2864 6576 6963      if len(devic
-0000aa30: 6529 2021 3d20 7365 6c66 2e6e 756d 5f77  e) != self.num_w
-0000aa40: 6f72 6b65 7273 3a0d 0a20 2020 2020 2020  orkers:..       
-0000aa50: 2020 2020 2020 2020 2072 6169 7365 2052           raise R
-0000aa60: 756e 7469 6d65 4572 726f 7228 6465 7669  untimeError(devi
-0000aa70: 6365 5f65 7272 5f6d 7367 2822 6465 7669  ce_err_msg("devi
-0000aa80: 6365 7322 2c20 6465 7669 6365 2929 0d0a  ces", device))..
-0000aa90: 2020 2020 2020 2020 2020 2020 6465 7669              devi
-0000aaa0: 6365 203d 205b 746f 7263 682e 6465 7669  ce = [torch.devi
-0000aab0: 6365 285f 6465 7669 6365 2920 666f 7220  ce(_device) for 
-0000aac0: 5f64 6576 6963 6520 696e 2064 6576 6963  _device in devic
-0000aad0: 655d 0d0a 2020 2020 2020 2020 656c 7365  e]..        else
-0000aae0: 3a0d 0a20 2020 2020 2020 2020 2020 2072  :..            r
-0000aaf0: 6169 7365 2056 616c 7565 4572 726f 7228  aise ValueError(
-0000ab00: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-0000ab10: 2020 2264 6576 6963 6573 2073 686f 756c    "devices shoul
-0000ab20: 6420 6265 2065 6974 6865 7220 4e6f 6e65  d be either None
-0000ab30: 2c20 6120 746f 7263 682e 6465 7669 6365  , a torch.device
-0000ab40: 206f 7220 6571 7569 7661 6c65 6e74 2022   or equivalent "
-0000ab50: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-0000ab60: 2020 226f 7220 616e 2069 7465 7261 626c    "or an iterabl
-0000ab70: 6520 6f66 2064 6576 6963 6573 2e20 220d  e of devices. ".
-0000ab80: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000ab90: 2066 2246 6f75 6e64 207b 7479 7065 2864   f"Found {type(d
-0000aba0: 6576 6963 6529 7d20 696e 7374 6561 642e  evice)} instead.
-0000abb0: 220d 0a20 2020 2020 2020 2020 2020 2029  "..            )
-0000abc0: 0d0a 2020 2020 2020 2020 7365 6c66 2e5f  ..        self._
-0000abd0: 706f 6c69 6379 5f64 6963 7420 3d20 7b7d  policy_dict = {}
-0000abe0: 0d0a 2020 2020 2020 2020 7365 6c66 2e5f  ..        self._
-0000abf0: 706f 6c69 6379 5f77 6569 6768 7473 5f64  policy_weights_d
-0000ac00: 6963 7420 3d20 7b7d 0d0a 2020 2020 2020  ict = {}..      
-0000ac10: 2020 7365 6c66 2e5f 6765 745f 7765 6967    self._get_weig
-0000ac20: 6874 735f 666e 5f64 6963 7420 3d20 7b7d  hts_fn_dict = {}
-0000ac30: 0d0a 0d0a 2020 2020 2020 2020 666f 7220  ....        for 
-0000ac40: 692c 2028 5f64 6576 6963 652c 2063 7265  i, (_device, cre
-0000ac50: 6174 655f 656e 762c 206b 7761 7267 7329  ate_env, kwargs)
-0000ac60: 2069 6e20 656e 756d 6572 6174 6528 0d0a   in enumerate(..
-0000ac70: 2020 2020 2020 2020 2020 2020 7a69 7028              zip(
-0000ac80: 6465 7669 6365 2c20 7365 6c66 2e63 7265  device, self.cre
-0000ac90: 6174 655f 656e 765f 666e 2c20 7365 6c66  ate_env_fn, self
-0000aca0: 2e63 7265 6174 655f 656e 765f 6b77 6172  .create_env_kwar
-0000acb0: 6773 290d 0a20 2020 2020 2020 2029 3a0d  gs)..        ):.
-0000acc0: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
-0000acd0: 5f64 6576 6963 6520 696e 2073 656c 662e  _device in self.
-0000ace0: 5f70 6f6c 6963 795f 6469 6374 3a0d 0a20  _policy_dict:.. 
-0000acf0: 2020 2020 2020 2020 2020 2020 2020 2064                 d
-0000ad00: 6576 6963 655b 695d 203d 205f 6465 7669  evice[i] = _devi
-0000ad10: 6365 0d0a 2020 2020 2020 2020 2020 2020  ce..            
-0000ad20: 2020 2020 636f 6e74 696e 7565 0d0a 0d0a      continue....
-0000ad30: 2020 2020 2020 2020 2020 2020 6966 2068              if h
-0000ad40: 6173 6174 7472 2863 7265 6174 655f 656e  asattr(create_en
-0000ad50: 762c 2022 6f62 7365 7276 6174 696f 6e5f  v, "observation_
-0000ad60: 7370 6563 2229 3a0d 0a20 2020 2020 2020  spec"):..       
-0000ad70: 2020 2020 2020 2020 206f 6273 6572 7661           observa
-0000ad80: 7469 6f6e 5f73 7065 6320 3d20 6372 6561  tion_spec = crea
-0000ad90: 7465 5f65 6e76 2e6f 6273 6572 7661 7469  te_env.observati
-0000ada0: 6f6e 5f73 7065 630d 0a20 2020 2020 2020  on_spec..       
-0000adb0: 2020 2020 2065 6c73 653a 0d0a 2020 2020       else:..    
-0000adc0: 2020 2020 2020 2020 2020 2020 7472 793a              try:
-0000add0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-0000ade0: 2020 2020 2020 6f62 7365 7276 6174 696f        observatio
-0000adf0: 6e5f 7370 6563 203d 2063 7265 6174 655f  n_spec = create_
-0000ae00: 656e 7628 2a2a 6b77 6172 6773 292e 6f62  env(**kwargs).ob
-0000ae10: 7365 7276 6174 696f 6e5f 7370 6563 0d0a  servation_spec..
-0000ae20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ae30: 6578 6365 7074 3a20 2023 206e 6f71 610d  except:  # noqa.
-0000ae40: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000ae50: 2020 2020 206f 6273 6572 7661 7469 6f6e       observation
-0000ae60: 5f73 7065 6320 3d20 4e6f 6e65 0d0a 0d0a  _spec = None....
-0000ae70: 2020 2020 2020 2020 2020 2020 5f70 6f6c              _pol
-0000ae80: 6963 792c 205f 6465 7669 6365 2c20 5f67  icy, _device, _g
-0000ae90: 6574 5f77 6569 6768 745f 666e 203d 2073  et_weight_fn = s
-0000aea0: 656c 662e 5f67 6574 5f70 6f6c 6963 795f  elf._get_policy_
-0000aeb0: 616e 645f 6465 7669 6365 280d 0a20 2020  and_device(..   
-0000aec0: 2020 2020 2020 2020 2020 2020 2070 6f6c               pol
-0000aed0: 6963 793d 706f 6c69 6379 2c20 6465 7669  icy=policy, devi
-0000aee0: 6365 3d5f 6465 7669 6365 2c20 6f62 7365  ce=_device, obse
-0000aef0: 7276 6174 696f 6e5f 7370 6563 3d6f 6273  rvation_spec=obs
-0000af00: 6572 7661 7469 6f6e 5f73 7065 630d 0a20  ervation_spec.. 
-0000af10: 2020 2020 2020 2020 2020 2029 0d0a 2020             )..  
-0000af20: 2020 2020 2020 2020 2020 7365 6c66 2e5f            self._
-0000af30: 706f 6c69 6379 5f64 6963 745b 5f64 6576  policy_dict[_dev
-0000af40: 6963 655d 203d 205f 706f 6c69 6379 0d0a  ice] = _policy..
-0000af50: 2020 2020 2020 2020 2020 2020 6966 2069              if i
-0000af60: 7369 6e73 7461 6e63 6528 5f70 6f6c 6963  sinstance(_polic
-0000af70: 792c 206e 6e2e 4d6f 6475 6c65 293a 0d0a  y, nn.Module):..
-0000af80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000af90: 7365 6c66 2e5f 706f 6c69 6379 5f77 6569  self._policy_wei
-0000afa0: 6768 7473 5f64 6963 745b 5f64 6576 6963  ghts_dict[_devic
-0000afb0: 655d 203d 2054 656e 736f 7244 6963 7428  e] = TensorDict(
-0000afc0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-0000afd0: 2020 2020 2020 6469 6374 285f 706f 6c69        dict(_poli
-0000afe0: 6379 2e6e 616d 6564 5f70 6172 616d 6574  cy.named_paramet
-0000aff0: 6572 7328 2929 2c20 5b5d 0d0a 2020 2020  ers()), []..    
-0000b000: 2020 2020 2020 2020 2020 2020 290d 0a20              ).. 
-0000b010: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
-0000b020: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-0000b030: 2020 7365 6c66 2e5f 706f 6c69 6379 5f77    self._policy_w
-0000b040: 6569 6768 7473 5f64 6963 745b 5f64 6576  eights_dict[_dev
-0000b050: 6963 655d 203d 2054 656e 736f 7244 6963  ice] = TensorDic
-0000b060: 7428 7b7d 2c20 5b5d 290d 0a0d 0a20 2020  t({}, [])....   
-0000b070: 2020 2020 2020 2020 2073 656c 662e 5f67           self._g
-0000b080: 6574 5f77 6569 6768 7473 5f66 6e5f 6469  et_weights_fn_di
-0000b090: 6374 5b5f 6465 7669 6365 5d20 3d20 5f67  ct[_device] = _g
-0000b0a0: 6574 5f77 6569 6768 745f 666e 0d0a 2020  et_weight_fn..  
-0000b0b0: 2020 2020 2020 2020 2020 6465 7669 6365            device
-0000b0c0: 5b69 5d20 3d20 5f64 6576 6963 650d 0a20  [i] = _device.. 
-0000b0d0: 2020 2020 2020 2073 656c 662e 6465 7669         self.devi
-0000b0e0: 6365 203d 2064 6576 6963 650d 0a0d 0a20  ce = device.... 
-0000b0f0: 2020 2020 2020 2069 6620 7374 6f72 696e         if storin
-0000b100: 675f 6465 7669 6365 2069 7320 4e6f 6e65  g_device is None
-0000b110: 3a0d 0a20 2020 2020 2020 2020 2020 2073  :..            s
-0000b120: 656c 662e 7374 6f72 696e 675f 6465 7669  elf.storing_devi
-0000b130: 6365 203d 2073 656c 662e 6465 7669 6365  ce = self.device
-0000b140: 0d0a 2020 2020 2020 2020 656c 7365 3a0d  ..        else:.
-0000b150: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
-0000b160: 6973 696e 7374 616e 6365 2873 746f 7269  isinstance(stori
-0000b170: 6e67 5f64 6576 6963 652c 2028 7374 722c  ng_device, (str,
-0000b180: 2069 6e74 2c20 746f 7263 682e 6465 7669   int, torch.devi
-0000b190: 6365 2929 3a0d 0a20 2020 2020 2020 2020  ce)):..         
-0000b1a0: 2020 2020 2020 2073 656c 662e 7374 6f72         self.stor
-0000b1b0: 696e 675f 6465 7669 6365 203d 205b 0d0a  ing_device = [..
-0000b1c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b1d0: 2020 2020 746f 7263 682e 6465 7669 6365      torch.device
-0000b1e0: 2873 746f 7269 6e67 5f64 6576 6963 6529  (storing_device)
-0000b1f0: 2066 6f72 205f 2069 6e20 7261 6e67 6528   for _ in range(
-0000b200: 7365 6c66 2e6e 756d 5f77 6f72 6b65 7273  self.num_workers
-0000b210: 290d 0a20 2020 2020 2020 2020 2020 2020  )..             
-0000b220: 2020 205d 0d0a 2020 2020 2020 2020 2020     ]..          
-0000b230: 2020 656c 6966 2069 7369 6e73 7461 6e63    elif isinstanc
-0000b240: 6528 7374 6f72 696e 675f 6465 7669 6365  e(storing_device
-0000b250: 2c20 5365 7175 656e 6365 293a 0d0a 2020  , Sequence):..  
-0000b260: 2020 2020 2020 2020 2020 2020 2020 6966                if
-0000b270: 206c 656e 2873 746f 7269 6e67 5f64 6576   len(storing_dev
-0000b280: 6963 6529 2021 3d20 7365 6c66 2e6e 756d  ice) != self.num
-0000b290: 5f77 6f72 6b65 7273 3a0d 0a20 2020 2020  _workers:..     
-0000b2a0: 2020 2020 2020 2020 2020 2020 2020 2072                 r
-0000b2b0: 6169 7365 2052 756e 7469 6d65 4572 726f  aise RuntimeErro
-0000b2c0: 7228 0d0a 2020 2020 2020 2020 2020 2020  r(..            
-0000b2d0: 2020 2020 2020 2020 2020 2020 6465 7669              devi
-0000b2e0: 6365 5f65 7272 5f6d 7367 2822 7374 6f72  ce_err_msg("stor
-0000b2f0: 696e 675f 6465 7669 6365 7322 2c20 7374  ing_devices", st
-0000b300: 6f72 696e 675f 6465 7669 6365 290d 0a20  oring_device).. 
-0000b310: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b320: 2020 2029 0d0a 2020 2020 2020 2020 2020     )..          
-0000b330: 2020 2020 2020 7365 6c66 2e73 746f 7269        self.stori
-0000b340: 6e67 5f64 6576 6963 6520 3d20 5b0d 0a20  ng_device = [.. 
-0000b350: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b360: 2020 2074 6f72 6368 2e64 6576 6963 6528     torch.device(
-0000b370: 5f73 746f 7269 6e67 5f64 6576 6963 6529  _storing_device)
-0000b380: 2066 6f72 205f 7374 6f72 696e 675f 6465   for _storing_de
-0000b390: 7669 6365 2069 6e20 7374 6f72 696e 675f  vice in storing_
-0000b3a0: 6465 7669 6365 0d0a 2020 2020 2020 2020  device..        
-0000b3b0: 2020 2020 2020 2020 5d0d 0a20 2020 2020          ]..     
-0000b3c0: 2020 2020 2020 2065 6c73 653a 0d0a 2020         else:..  
-0000b3d0: 2020 2020 2020 2020 2020 2020 2020 7261                ra
-0000b3e0: 6973 6520 5661 6c75 6545 7272 6f72 280d  ise ValueError(.
-0000b3f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000b400: 2020 2020 2022 7374 6f72 696e 675f 6465       "storing_de
-0000b410: 7669 6365 7320 7368 6f75 6c64 2062 6520  vices should be 
-0000b420: 6569 7468 6572 2061 2074 6f72 6368 2e64  either a torch.d
-0000b430: 6576 6963 6520 6f72 2065 7175 6976 616c  evice or equival
-0000b440: 656e 7420 6f72 2061 6e20 6974 6572 6162  ent or an iterab
-0000b450: 6c65 206f 6620 6465 7669 6365 732e 2022  le of devices. "
-0000b460: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-0000b470: 2020 2020 2020 6622 466f 756e 6420 7b74        f"Found {t
-0000b480: 7970 6528 7374 6f72 696e 675f 6465 7669  ype(storing_devi
-0000b490: 6365 297d 2069 6e73 7465 6164 2e22 0d0a  ce)} instead."..
-0000b4a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b4b0: 290d 0a0d 0a20 2020 2020 2020 2069 6620  )....        if 
-0000b4c0: 746f 7461 6c5f 6672 616d 6573 2069 7320  total_frames is 
-0000b4d0: 4e6f 6e65 206f 7220 746f 7461 6c5f 6672  None or total_fr
-0000b4e0: 616d 6573 203c 2030 3a0d 0a20 2020 2020  ames < 0:..     
-0000b4f0: 2020 2020 2020 2074 6f74 616c 5f66 7261         total_fra
-0000b500: 6d65 7320 3d20 666c 6f61 7428 2269 6e66  mes = float("inf
-0000b510: 2229 0d0a 2020 2020 2020 2020 656c 7365  ")..        else
-0000b520: 3a0d 0a20 2020 2020 2020 2020 2020 2069  :..            i
-0000b530: 6620 746f 7461 6c5f 6672 616d 6573 2025  f total_frames %
-0000b540: 2066 7261 6d65 735f 7065 725f 6261 7463   frames_per_batc
-0000b550: 6820 213d 2030 3a0d 0a20 2020 2020 2020  h != 0:..       
-0000b560: 2020 2020 2020 2020 2072 6169 7365 2056           raise V
-0000b570: 616c 7565 4572 726f 7228 0d0a 2020 2020  alueError(..    
-0000b580: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b590: 6622 746f 7461 6c5f 6672 616d 6573 2028  f"total_frames (
-0000b5a0: 7b74 6f74 616c 5f66 7261 6d65 737d 2920  {total_frames}) 
-0000b5b0: 6d75 7374 2062 6520 6469 7669 7369 626c  must be divisibl
-0000b5c0: 6520 6279 2066 7261 6d65 735f 7065 725f  e by frames_per_
-0000b5d0: 6261 7463 6820 287b 6672 616d 6573 5f70  batch ({frames_p
-0000b5e0: 6572 5f62 6174 6368 7d29 2e22 0d0a 2020  er_batch})."..  
-0000b5f0: 2020 2020 2020 2020 2020 2020 2020 290d                ).
-0000b600: 0a20 2020 2020 2020 2073 656c 662e 746f  .        self.to
-0000b610: 7461 6c5f 6672 616d 6573 203d 2074 6f74  tal_frames = tot
-0000b620: 616c 5f66 7261 6d65 730d 0a20 2020 2020  al_frames..     
-0000b630: 2020 2073 656c 662e 7265 7365 745f 6174     self.reset_at
-0000b640: 5f65 6163 685f 6974 6572 203d 2072 6573  _each_iter = res
-0000b650: 6574 5f61 745f 6561 6368 5f69 7465 720d  et_at_each_iter.
-0000b660: 0a20 2020 2020 2020 2073 656c 662e 706f  .        self.po
-0000b670: 7374 7072 6f63 7320 3d20 706f 7374 7072  stprocs = postpr
-0000b680: 6f63 0d0a 2020 2020 2020 2020 7365 6c66  oc..        self
-0000b690: 2e6d 6178 5f66 7261 6d65 735f 7065 725f  .max_frames_per_
-0000b6a0: 7472 616a 203d 206d 6178 5f66 7261 6d65  traj = max_frame
-0000b6b0: 735f 7065 725f 7472 616a 0d0a 2020 2020  s_per_traj..    
-0000b6c0: 2020 2020 7365 6c66 2e66 7261 6d65 735f      self.frames_
-0000b6d0: 7065 725f 6261 7463 6820 3d20 6672 616d  per_batch = fram
-0000b6e0: 6573 5f70 6572 5f62 6174 6368 0d0a 2020  es_per_batch..  
-0000b6f0: 2020 2020 2020 7365 6c66 2e72 6573 6574        self.reset
-0000b700: 5f77 6865 6e5f 646f 6e65 203d 2072 6573  _when_done = res
-0000b710: 6574 5f77 6865 6e5f 646f 6e65 0d0a 2020  et_when_done..  
-0000b720: 2020 2020 2020 6966 2073 706c 6974 5f74        if split_t
-0000b730: 7261 6a73 2069 7320 4e6f 6e65 3a0d 0a20  rajs is None:.. 
-0000b740: 2020 2020 2020 2020 2020 2073 706c 6974             split
-0000b750: 5f74 7261 6a73 203d 2046 616c 7365 0d0a  _trajs = False..
-0000b760: 2020 2020 2020 2020 656c 6966 206e 6f74          elif not
-0000b770: 2073 656c 662e 7265 7365 745f 7768 656e   self.reset_when
-0000b780: 5f64 6f6e 6520 616e 6420 7370 6c69 745f  _done and split_
-0000b790: 7472 616a 733a 0d0a 2020 2020 2020 2020  trajs:..        
-0000b7a0: 2020 2020 7261 6973 6520 5275 6e74 696d      raise Runtim
-0000b7b0: 6545 7272 6f72 280d 0a20 2020 2020 2020  eError(..       
-0000b7c0: 2020 2020 2020 2020 2022 4361 6e6e 6f74           "Cannot
-0000b7d0: 2073 706c 6974 2074 7261 6a65 6374 6f72   split trajector
-0000b7e0: 6965 7320 7768 656e 2072 6573 6574 5f77  ies when reset_w
-0000b7f0: 6865 6e5f 646f 6e65 2069 7320 4661 6c73  hen_done is Fals
-0000b800: 652e 220d 0a20 2020 2020 2020 2020 2020  e."..           
-0000b810: 2029 0d0a 2020 2020 2020 2020 7365 6c66   )..        self
-0000b820: 2e73 706c 6974 5f74 7261 6a73 203d 2073  .split_trajs = s
-0000b830: 706c 6974 5f74 7261 6a73 0d0a 2020 2020  plit_trajs..    
-0000b840: 2020 2020 7365 6c66 2e69 6e69 745f 7261      self.init_ra
-0000b850: 6e64 6f6d 5f66 7261 6d65 7320 3d20 696e  ndom_frames = in
-0000b860: 6974 5f72 616e 646f 6d5f 6672 616d 6573  it_random_frames
-0000b870: 0d0a 2020 2020 2020 2020 7365 6c66 2e75  ..        self.u
-0000b880: 7064 6174 655f 6174 5f65 6163 685f 6261  pdate_at_each_ba
-0000b890: 7463 6820 3d20 7570 6461 7465 5f61 745f  tch = update_at_
-0000b8a0: 6561 6368 5f62 6174 6368 0d0a 2020 2020  each_batch..    
-0000b8b0: 2020 2020 7365 6c66 2e65 7870 6c6f 7261      self.explora
-0000b8c0: 7469 6f6e 5f6d 6f64 6520 3d20 6578 706c  tion_mode = expl
-0000b8d0: 6f72 6174 696f 6e5f 6d6f 6465 0d0a 2020  oration_mode..  
-0000b8e0: 2020 2020 2020 7365 6c66 2e5f 7275 6e5f        self._run_
-0000b8f0: 7072 6f63 6573 7365 7328 290d 0a20 2020  processes()..   
-0000b900: 2020 2020 2073 656c 662e 5f65 7863 6c75       self._exclu
-0000b910: 6465 5f70 7269 7661 7465 5f6b 6579 7320  de_private_keys 
-0000b920: 3d20 5472 7565 0d0a 0d0a 2020 2020 4070  = True....    @p
-0000b930: 726f 7065 7274 790d 0a20 2020 2064 6566  roperty..    def
-0000b940: 2066 7261 6d65 735f 7065 725f 6261 7463   frames_per_batc
-0000b950: 685f 776f 726b 6572 2873 656c 6629 3a0d  h_worker(self):.
-0000b960: 0a20 2020 2020 2020 2072 6169 7365 204e  .        raise N
-0000b970: 6f74 496d 706c 656d 656e 7465 6445 7272  otImplementedErr
-0000b980: 6f72 0d0a 0d0a 2020 2020 6465 6620 7570  or....    def up
-0000b990: 6461 7465 5f70 6f6c 6963 795f 7765 6967  date_policy_weig
-0000b9a0: 6874 735f 2873 656c 662c 2070 6f6c 6963  hts_(self, polic
-0000b9b0: 795f 7765 6967 6874 733d 4e6f 6e65 2920  y_weights=None) 
-0000b9c0: 2d3e 204e 6f6e 653a 0d0a 2020 2020 2020  -> None:..      
-0000b9d0: 2020 666f 7220 5f64 6576 6963 6520 696e    for _device in
-0000b9e0: 2073 656c 662e 5f70 6f6c 6963 795f 6469   self._policy_di
-0000b9f0: 6374 3a0d 0a20 2020 2020 2020 2020 2020  ct:..           
-0000ba00: 2069 6620 706f 6c69 6379 5f77 6569 6768   if policy_weigh
-0000ba10: 7473 2069 7320 6e6f 7420 4e6f 6e65 3a0d  ts is not None:.
-0000ba20: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000ba30: 2073 656c 662e 5f70 6f6c 6963 795f 7765   self._policy_we
-0000ba40: 6967 6874 735f 6469 6374 5b5f 6465 7669  ights_dict[_devi
-0000ba50: 6365 5d2e 6170 706c 7928 6c61 6d62 6461  ce].apply(lambda
-0000ba60: 2078 3a20 782e 6461 7461 292e 7570 6461   x: x.data).upda
-0000ba70: 7465 5f28 0d0a 2020 2020 2020 2020 2020  te_(..          
-0000ba80: 2020 2020 2020 2020 2020 706f 6c69 6379            policy
-0000ba90: 5f77 6569 6768 7473 0d0a 2020 2020 2020  _weights..      
-0000baa0: 2020 2020 2020 2020 2020 290d 0a20 2020            )..   
-0000bab0: 2020 2020 2020 2020 2065 6c69 6620 7365           elif se
-0000bac0: 6c66 2e5f 6765 745f 7765 6967 6874 735f  lf._get_weights_
-0000bad0: 666e 5f64 6963 745b 5f64 6576 6963 655d  fn_dict[_device]
-0000bae0: 2069 7320 6e6f 7420 4e6f 6e65 3a0d 0a20   is not None:.. 
-0000baf0: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-0000bb00: 656c 662e 5f70 6f6c 6963 795f 6469 6374  elf._policy_dict
-0000bb10: 5b5f 6465 7669 6365 5d2e 6c6f 6164 5f73  [_device].load_s
-0000bb20: 7461 7465 5f64 6963 7428 0d0a 2020 2020  tate_dict(..    
-0000bb30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000bb40: 7365 6c66 2e5f 6765 745f 7765 6967 6874  self._get_weight
-0000bb50: 735f 666e 5f64 6963 745b 5f64 6576 6963  s_fn_dict[_devic
-0000bb60: 655d 2829 0d0a 2020 2020 2020 2020 2020  e]()..          
-0000bb70: 2020 2020 2020 290d 0a0d 0a20 2020 2040        )....    @
-0000bb80: 7072 6f70 6572 7479 0d0a 2020 2020 6465  property..    de
-0000bb90: 6620 5f71 7565 7565 5f6c 656e 2873 656c  f _queue_len(sel
-0000bba0: 6629 202d 3e20 696e 743a 0d0a 2020 2020  f) -> int:..    
-0000bbb0: 2020 2020 7261 6973 6520 4e6f 7449 6d70      raise NotImp
-0000bbc0: 6c65 6d65 6e74 6564 4572 726f 720d 0a0d  lementedError...
-0000bbd0: 0a20 2020 2064 6566 205f 7275 6e5f 7072  .    def _run_pr
-0000bbe0: 6f63 6573 7365 7328 7365 6c66 2920 2d3e  ocesses(self) ->
-0000bbf0: 204e 6f6e 653a 0d0a 2020 2020 2020 2020   None:..        
-0000bc00: 7175 6575 655f 6f75 7420 3d20 6d70 2e51  queue_out = mp.Q
-0000bc10: 7565 7565 2873 656c 662e 5f71 7565 7565  ueue(self._queue
-0000bc20: 5f6c 656e 2920 2023 2073 656e 6473 2064  _len)  # sends d
-0000bc30: 6174 6120 6672 6f6d 2070 726f 6320 746f  ata from proc to
-0000bc40: 206d 6169 6e0d 0a20 2020 2020 2020 2073   main..        s
-0000bc50: 656c 662e 7072 6f63 7320 3d20 5b5d 0d0a  elf.procs = []..
-0000bc60: 2020 2020 2020 2020 7365 6c66 2e70 6970          self.pip
-0000bc70: 6573 203d 205b 5d0d 0a20 2020 2020 2020  es = []..       
-0000bc80: 2066 6f72 2069 2c20 2865 6e76 5f66 756e   for i, (env_fun
-0000bc90: 2c20 656e 765f 6675 6e5f 6b77 6172 6773  , env_fun_kwargs
-0000bca0: 2920 696e 2065 6e75 6d65 7261 7465 280d  ) in enumerate(.
-0000bcb0: 0a20 2020 2020 2020 2020 2020 207a 6970  .            zip
-0000bcc0: 2873 656c 662e 6372 6561 7465 5f65 6e76  (self.create_env
-0000bcd0: 5f66 6e2c 2073 656c 662e 6372 6561 7465  _fn, self.create
-0000bce0: 5f65 6e76 5f6b 7761 7267 7329 0d0a 2020  _env_kwargs)..  
-0000bcf0: 2020 2020 2020 293a 0d0a 2020 2020 2020        ):..      
-0000bd00: 2020 2020 2020 5f64 6576 6963 6520 3d20        _device = 
-0000bd10: 7365 6c66 2e64 6576 6963 655b 695d 0d0a  self.device[i]..
-0000bd20: 2020 2020 2020 2020 2020 2020 5f73 746f              _sto
-0000bd30: 7269 6e67 5f64 6576 6963 6520 3d20 7365  ring_device = se
-0000bd40: 6c66 2e73 746f 7269 6e67 5f64 6576 6963  lf.storing_devic
-0000bd50: 655b 695d 0d0a 2020 2020 2020 2020 2020  e[i]..          
-0000bd60: 2020 7069 7065 5f70 6172 656e 742c 2070    pipe_parent, p
-0000bd70: 6970 655f 6368 696c 6420 3d20 6d70 2e50  ipe_child = mp.P
-0000bd80: 6970 6528 2920 2023 2073 656e 6420 6d65  ipe()  # send me
-0000bd90: 7373 6167 6573 2074 6f20 7072 6f63 730d  ssages to procs.
-0000bda0: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
-0000bdb0: 656e 765f 6675 6e2e 5f5f 636c 6173 735f  env_fun.__class_
-0000bdc0: 5f2e 5f5f 6e61 6d65 5f5f 2021 3d20 2245  _.__name__ != "E
-0000bdd0: 6e76 4372 6561 746f 7222 2061 6e64 206e  nvCreator" and n
-0000bde0: 6f74 2069 7369 6e73 7461 6e63 6528 0d0a  ot isinstance(..
-0000bdf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000be00: 656e 765f 6675 6e2c 2045 6e76 4261 7365  env_fun, EnvBase
-0000be10: 0d0a 2020 2020 2020 2020 2020 2020 293a  ..            ):
-0000be20: 2020 2320 746f 2061 766f 6964 2063 6972    # to avoid cir
-0000be30: 6375 6c61 7220 696d 706f 7274 730d 0a20  cular imports.. 
-0000be40: 2020 2020 2020 2020 2020 2020 2020 2065                 e
-0000be50: 6e76 5f66 756e 203d 2043 6c6f 7564 7069  nv_fun = Cloudpi
-0000be60: 636b 6c65 5772 6170 7065 7228 656e 765f  ckleWrapper(env_
-0000be70: 6675 6e29 0d0a 0d0a 2020 2020 2020 2020  fun)....        
-0000be80: 2020 2020 6b77 6172 6773 203d 207b 0d0a      kwargs = {..
-0000be90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000bea0: 2270 6970 655f 7061 7265 6e74 223a 2070  "pipe_parent": p
-0000beb0: 6970 655f 7061 7265 6e74 2c0d 0a20 2020  ipe_parent,..   
-0000bec0: 2020 2020 2020 2020 2020 2020 2022 7069               "pi
-0000bed0: 7065 5f63 6869 6c64 223a 2070 6970 655f  pe_child": pipe_
-0000bee0: 6368 696c 642c 0d0a 2020 2020 2020 2020  child,..        
-0000bef0: 2020 2020 2020 2020 2271 7565 7565 5f6f          "queue_o
-0000bf00: 7574 223a 2071 7565 7565 5f6f 7574 2c0d  ut": queue_out,.
-0000bf10: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000bf20: 2022 6372 6561 7465 5f65 6e76 5f66 6e22   "create_env_fn"
-0000bf30: 3a20 656e 765f 6675 6e2c 0d0a 2020 2020  : env_fun,..    
-0000bf40: 2020 2020 2020 2020 2020 2020 2263 7265              "cre
-0000bf50: 6174 655f 656e 765f 6b77 6172 6773 223a  ate_env_kwargs":
-0000bf60: 2065 6e76 5f66 756e 5f6b 7761 7267 732c   env_fun_kwargs,
-0000bf70: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-0000bf80: 2020 2270 6f6c 6963 7922 3a20 7365 6c66    "policy": self
-0000bf90: 2e5f 706f 6c69 6379 5f64 6963 745b 5f64  ._policy_dict[_d
-0000bfa0: 6576 6963 655d 2c0d 0a20 2020 2020 2020  evice],..       
-0000bfb0: 2020 2020 2020 2020 2022 6d61 785f 6672           "max_fr
-0000bfc0: 616d 6573 5f70 6572 5f74 7261 6a22 3a20  ames_per_traj": 
-0000bfd0: 7365 6c66 2e6d 6178 5f66 7261 6d65 735f  self.max_frames_
-0000bfe0: 7065 725f 7472 616a 2c0d 0a20 2020 2020  per_traj,..     
-0000bff0: 2020 2020 2020 2020 2020 2022 6672 616d             "fram
-0000c000: 6573 5f70 6572 5f62 6174 6368 223a 2073  es_per_batch": s
-0000c010: 656c 662e 6672 616d 6573 5f70 6572 5f62  elf.frames_per_b
-0000c020: 6174 6368 5f77 6f72 6b65 722c 0d0a 2020  atch_worker,..  
-0000c030: 2020 2020 2020 2020 2020 2020 2020 2272                "r
-0000c040: 6573 6574 5f61 745f 6561 6368 5f69 7465  eset_at_each_ite
-0000c050: 7222 3a20 7365 6c66 2e72 6573 6574 5f61  r": self.reset_a
-0000c060: 745f 6561 6368 5f69 7465 722c 0d0a 2020  t_each_iter,..  
-0000c070: 2020 2020 2020 2020 2020 2020 2020 2264                "d
-0000c080: 6576 6963 6522 3a20 5f64 6576 6963 652c  evice": _device,
-0000c090: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-0000c0a0: 2020 2273 746f 7269 6e67 5f64 6576 6963    "storing_devic
-0000c0b0: 6522 3a20 5f73 746f 7269 6e67 5f64 6576  e": _storing_dev
-0000c0c0: 6963 652c 0d0a 2020 2020 2020 2020 2020  ice,..          
-0000c0d0: 2020 2020 2020 2265 7870 6c6f 7261 7469        "explorati
-0000c0e0: 6f6e 5f6d 6f64 6522 3a20 7365 6c66 2e65  on_mode": self.e
-0000c0f0: 7870 6c6f 7261 7469 6f6e 5f6d 6f64 652c  xploration_mode,
-0000c100: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-0000c110: 2020 2272 6573 6574 5f77 6865 6e5f 646f    "reset_when_do
-0000c120: 6e65 223a 2073 656c 662e 7265 7365 745f  ne": self.reset_
-0000c130: 7768 656e 5f64 6f6e 652c 0d0a 2020 2020  when_done,..    
-0000c140: 2020 2020 2020 2020 2020 2020 2269 6478              "idx
-0000c150: 223a 2069 2c0d 0a20 2020 2020 2020 2020  ": i,..         
-0000c160: 2020 207d 0d0a 2020 2020 2020 2020 2020     }..          
-0000c170: 2020 7072 6f63 203d 206d 702e 5072 6f63    proc = mp.Proc
-0000c180: 6573 7328 7461 7267 6574 3d5f 6d61 696e  ess(target=_main
-0000c190: 5f61 7379 6e63 5f63 6f6c 6c65 6374 6f72  _async_collector
-0000c1a0: 2c20 6b77 6172 6773 3d6b 7761 7267 7329  , kwargs=kwargs)
-0000c1b0: 0d0a 2020 2020 2020 2020 2020 2020 2320  ..            # 
-0000c1c0: 7072 6f63 2e64 6165 6d6f 6e20 6361 6e27  proc.daemon can'
-0000c1d0: 7420 6265 2073 6574 2061 7320 6461 656d  t be set as daem
-0000c1e0: 6f6e 6963 2070 726f 6365 7373 6573 206d  onic processes m
-0000c1f0: 6179 2062 6520 6c61 756e 6368 6564 2062  ay be launched b
-0000c200: 7920 7468 6520 7072 6f63 6573 7320 6974  y the process it
-0000c210: 7365 6c66 0d0a 2020 2020 2020 2020 2020  self..          
-0000c220: 2020 7472 793a 0d0a 2020 2020 2020 2020    try:..        
-0000c230: 2020 2020 2020 2020 7072 6f63 2e73 7461          proc.sta
-0000c240: 7274 2829 0d0a 2020 2020 2020 2020 2020  rt()..          
-0000c250: 2020 6578 6365 7074 205f 7069 636b 6c65    except _pickle
-0000c260: 2e50 6963 6b6c 696e 6745 7272 6f72 2061  .PicklingError a
-0000c270: 7320 6572 723a 0d0a 2020 2020 2020 2020  s err:..        
-0000c280: 2020 2020 2020 2020 6966 2022 3c6c 616d          if "<lam
-0000c290: 6264 613e 2220 696e 2073 7472 2865 7272  bda>" in str(err
-0000c2a0: 293a 0d0a 2020 2020 2020 2020 2020 2020  ):..            
-0000c2b0: 2020 2020 2020 2020 7261 6973 6520 5275          raise Ru
-0000c2c0: 6e74 696d 6545 7272 6f72 280d 0a20 2020  ntimeError(..   
-0000c2d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c2e0: 2020 2020 2022 2222 4361 6e27 7420 6f70       """Can't op
-0000c2f0: 656e 2061 2070 726f 6365 7373 2077 6974  en a process wit
-0000c300: 6820 646f 7562 6c79 2063 6c6f 7564 2d70  h doubly cloud-p
-0000c310: 6963 6b6c 6564 206c 616d 6264 6120 6675  ickled lambda fu
-0000c320: 6e63 7469 6f6e 2e0d 0a54 6869 7320 6572  nction...This er
-0000c330: 726f 7220 6973 206c 696b 656c 7920 6475  ror is likely du
-0000c340: 6520 746f 2061 6e20 6174 7465 6d70 7420  e to an attempt 
-0000c350: 746f 2075 7365 2061 2050 6172 616c 6c65  to use a Paralle
-0000c360: 6c45 6e76 2069 6e20 610d 0a6d 756c 7469  lEnv in a..multi
-0000c370: 7072 6f63 6573 7365 6420 6461 7461 2063  processed data c
-0000c380: 6f6c 6c65 6374 6f72 2e20 546f 2064 6f20  ollector. To do 
-0000c390: 7468 6973 2c20 636f 6e73 6964 6572 2077  this, consider w
-0000c3a0: 7261 7070 696e 6720 796f 7572 0d0a 6c61  rapping your..la
-0000c3b0: 6d62 6461 2066 756e 6374 696f 6e20 696e  mbda function in
-0000c3c0: 2061 6e20 6074 6f72 6368 726c 2e65 6e76   an `torchrl.env
-0000c3d0: 732e 456e 7643 7265 6174 6f72 6020 7772  s.EnvCreator` wr
-0000c3e0: 6170 7065 7220 6173 2066 6f6c 6c6f 7773  apper as follows
-0000c3f0: 3a0d 0a60 656e 7620 3d20 5061 7261 6c6c  :..`env = Parall
-0000c400: 656c 456e 7628 4e2c 2045 6e76 4372 6561  elEnv(N, EnvCrea
-0000c410: 746f 7228 6d79 5f6c 616d 6264 615f 6675  tor(my_lambda_fu
-0000c420: 6e63 7469 6f6e 2929 602e 0d0a 5468 6973  nction))`...This
-0000c430: 2077 696c 6c20 6e6f 7420 6f6e 6c79 2065   will not only e
-0000c440: 6e73 7572 6520 7468 6174 2079 6f75 7220  nsure that your 
-0000c450: 6c61 6d62 6461 2066 756e 6374 696f 6e20  lambda function 
-0000c460: 6973 2063 6c6f 7564 2d70 6963 6b6c 6564  is cloud-pickled
-0000c470: 206f 6e63 652c 2062 7574 0d0a 616c 736f   once, but..also
-0000c480: 2074 6861 7420 7468 6520 7374 6174 6520   that the state 
-0000c490: 6469 6374 2069 7320 7379 6e63 6872 6f6e  dict is synchron
-0000c4a0: 6973 6564 2061 6372 6f73 7320 7072 6f63  ised across proc
-0000c4b0: 6573 7365 7320 6966 206e 6565 6465 642e  esses if needed.
-0000c4c0: 2222 220d 0a20 2020 2020 2020 2020 2020  """..           
-0000c4d0: 2020 2020 2020 2020 2029 2066 726f 6d20           ) from 
-0000c4e0: 6572 720d 0a20 2020 2020 2020 2020 2020  err..           
-0000c4f0: 2070 6970 655f 6368 696c 642e 636c 6f73   pipe_child.clos
-0000c500: 6528 290d 0a20 2020 2020 2020 2020 2020  e()..           
-0000c510: 2073 656c 662e 7072 6f63 732e 6170 7065   self.procs.appe
-0000c520: 6e64 2870 726f 6329 0d0a 2020 2020 2020  nd(proc)..      
-0000c530: 2020 2020 2020 7365 6c66 2e70 6970 6573        self.pipes
-0000c540: 2e61 7070 656e 6428 7069 7065 5f70 6172  .append(pipe_par
-0000c550: 656e 7429 0d0a 2020 2020 2020 2020 2020  ent)..          
-0000c560: 2020 6d73 6720 3d20 7069 7065 5f70 6172    msg = pipe_par
-0000c570: 656e 742e 7265 6376 2829 0d0a 2020 2020  ent.recv()..    
-0000c580: 2020 2020 2020 2020 6966 206d 7367 2021          if msg !
-0000c590: 3d20 2269 6e73 7461 6e74 6961 7465 6422  = "instantiated"
-0000c5a0: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
-0000c5b0: 2020 2072 6169 7365 2052 756e 7469 6d65     raise Runtime
-0000c5c0: 4572 726f 7228 6d73 6729 0d0a 2020 2020  Error(msg)..    
-0000c5d0: 2020 2020 7365 6c66 2e71 7565 7565 5f6f      self.queue_o
-0000c5e0: 7574 203d 2071 7565 7565 5f6f 7574 0d0a  ut = queue_out..
-0000c5f0: 2020 2020 2020 2020 7365 6c66 2e63 6c6f          self.clo
-0000c600: 7365 6420 3d20 4661 6c73 650d 0a0d 0a20  sed = False.... 
-0000c610: 2020 2064 6566 205f 5f64 656c 5f5f 2873     def __del__(s
-0000c620: 656c 6629 3a0d 0a20 2020 2020 2020 2074  elf):..        t
-0000c630: 7279 3a0d 0a20 2020 2020 2020 2020 2020  ry:..           
-0000c640: 2073 656c 662e 7368 7574 646f 776e 2829   self.shutdown()
-0000c650: 0d0a 2020 2020 2020 2020 6578 6365 7074  ..        except
-0000c660: 2045 7863 6570 7469 6f6e 3a0d 0a20 2020   Exception:..   
-0000c670: 2020 2020 2020 2020 2023 2061 6e20 4174           # an At
-0000c680: 7472 6962 7574 6545 7272 6f72 2077 696c  tributeError wil
-0000c690: 6c20 7479 7069 6361 6c6c 7920 6265 2072  l typically be r
-0000c6a0: 6169 7365 6420 6966 2074 6865 2063 6f6c  aised if the col
-0000c6b0: 6c65 6374 6f72 2069 7320 6465 6c65 7465  lector is delete
-0000c6c0: 6420 7768 656e 2074 6865 2070 726f 6772  d when the progr
-0000c6d0: 616d 2065 6e64 732e 0d0a 2020 2020 2020  am ends...      
-0000c6e0: 2020 2020 2020 2320 496e 2074 6865 2066        # In the f
-0000c6f0: 7574 7572 652c 2069 6e73 6967 6e69 6669  uture, insignifi
-0000c700: 6361 6e74 2063 6861 6e67 6573 2074 6f20  cant changes to 
-0000c710: 7468 6520 636c 6f73 6520 6d65 7468 6f64  the close method
-0000c720: 206d 6179 2063 6861 6e67 6520 7468 6520   may change the 
-0000c730: 6572 726f 7220 7479 7065 2e0d 0a20 2020  error type...   
-0000c740: 2020 2020 2020 2020 2023 2057 6520 6578           # We ex
-0000c750: 6370 6c69 6369 7465 6c79 2061 7373 756d  cplicitely assum
-0000c760: 6520 7468 6174 2061 6e79 2065 7272 6f72  e that any error
-0000c770: 2072 6169 7365 6420 6475 7269 6e67 2063   raised during c
-0000c780: 6c6f 7375 7265 2069 6e0d 0a20 2020 2020  losure in..     
-0000c790: 2020 2020 2020 2023 205f 5f64 656c 5f5f         # __del__
-0000c7a0: 2077 696c 6c20 6e6f 7420 6166 6665 6374   will not affect
-0000c7b0: 2074 6865 2070 726f 6772 616d 2e0d 0a20   the program... 
-0000c7c0: 2020 2020 2020 2020 2020 2070 6173 730d             pass.
-0000c7d0: 0a0d 0a20 2020 2064 6566 2073 6875 7464  ...    def shutd
-0000c7e0: 6f77 6e28 7365 6c66 2920 2d3e 204e 6f6e  own(self) -> Non
-0000c7f0: 653a 0d0a 2020 2020 2020 2020 2222 2253  e:..        """S
-0000c800: 6875 7473 2064 6f77 6e20 616c 6c20 7072  huts down all pr
-0000c810: 6f63 6573 7365 732e 2054 6869 7320 6f70  ocesses. This op
-0000c820: 6572 6174 696f 6e20 6973 2069 7272 6576  eration is irrev
-0000c830: 6572 7369 626c 652e 2222 220d 0a20 2020  ersible."""..   
-0000c840: 2020 2020 2073 656c 662e 5f73 6875 7464       self._shutd
-0000c850: 6f77 6e5f 6d61 696e 2829 0d0a 0d0a 2020  own_main()....  
-0000c860: 2020 6465 6620 5f73 6875 7464 6f77 6e5f    def _shutdown_
-0000c870: 6d61 696e 2873 656c 6629 202d 3e20 4e6f  main(self) -> No
-0000c880: 6e65 3a0d 0a20 2020 2020 2020 2069 6620  ne:..        if 
-0000c890: 7365 6c66 2e63 6c6f 7365 643a 0d0a 2020  self.closed:..  
-0000c8a0: 2020 2020 2020 2020 2020 7265 7475 726e            return
-0000c8b0: 0d0a 2020 2020 2020 2020 5f63 6865 636b  ..        _check
-0000c8c0: 5f66 6f72 5f66 6175 6c74 795f 7072 6f63  _for_faulty_proc
-0000c8d0: 6573 7328 7365 6c66 2e70 726f 6373 290d  ess(self.procs).
-0000c8e0: 0a20 2020 2020 2020 2073 656c 662e 636c  .        self.cl
-0000c8f0: 6f73 6564 203d 2054 7275 650d 0a20 2020  osed = True..   
-0000c900: 2020 2020 2066 6f72 2069 6478 2069 6e20       for idx in 
-0000c910: 7261 6e67 6528 7365 6c66 2e6e 756d 5f77  range(self.num_w
-0000c920: 6f72 6b65 7273 293a 0d0a 2020 2020 2020  orkers):..      
-0000c930: 2020 2020 2020 7365 6c66 2e70 6970 6573        self.pipes
-0000c940: 5b69 6478 5d2e 7365 6e64 2828 4e6f 6e65  [idx].send((None
-0000c950: 2c20 2263 6c6f 7365 2229 290d 0a0d 0a20  , "close")).... 
-0000c960: 2020 2020 2020 2020 2020 2069 6620 7365             if se
-0000c970: 6c66 2e70 6970 6573 5b69 6478 5d2e 706f  lf.pipes[idx].po
-0000c980: 6c6c 2831 302e 3029 3a0d 0a20 2020 2020  ll(10.0):..     
-0000c990: 2020 2020 2020 2020 2020 206d 7367 203d             msg =
-0000c9a0: 2073 656c 662e 7069 7065 735b 6964 785d   self.pipes[idx]
-0000c9b0: 2e72 6563 7628 290d 0a20 2020 2020 2020  .recv()..       
-0000c9c0: 2020 2020 2020 2020 2069 6620 6d73 6720           if msg 
-0000c9d0: 213d 2022 636c 6f73 6564 223a 0d0a 2020  != "closed":..  
-0000c9e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000c9f0: 2020 7261 6973 6520 5275 6e74 696d 6545    raise RuntimeE
-0000ca00: 7272 6f72 2866 2267 6f74 207b 6d73 677d  rror(f"got {msg}
-0000ca10: 2062 7574 2065 7870 6563 7465 6420 2763   but expected 'c
-0000ca20: 6c6f 7365 2722 290d 0a20 2020 2020 2020  lose'")..       
-0000ca30: 2020 2020 2065 6c73 653a 0d0a 2020 2020       else:..    
-0000ca40: 2020 2020 2020 2020 2020 2020 636f 6e74              cont
-0000ca50: 696e 7565 0d0a 0d0a 2020 2020 2020 2020  inue....        
-0000ca60: 666f 7220 7072 6f63 2069 6e20 7365 6c66  for proc in self
-0000ca70: 2e70 726f 6373 3a0d 0a20 2020 2020 2020  .procs:..       
-0000ca80: 2020 2020 2070 726f 632e 6a6f 696e 2831       proc.join(1
-0000ca90: 302e 3029 0d0a 0d0a 2020 2020 2020 2020  0.0)....        
-0000caa0: 7365 6c66 2e71 7565 7565 5f6f 7574 2e63  self.queue_out.c
-0000cab0: 6c6f 7365 2829 0d0a 2020 2020 2020 2020  lose()..        
-0000cac0: 666f 7220 7069 7065 2069 6e20 7365 6c66  for pipe in self
-0000cad0: 2e70 6970 6573 3a0d 0a20 2020 2020 2020  .pipes:..       
-0000cae0: 2020 2020 2070 6970 652e 636c 6f73 6528       pipe.close(
-0000caf0: 290d 0a0d 0a20 2020 2064 6566 2073 6574  )....    def set
-0000cb00: 5f73 6565 6428 7365 6c66 2c20 7365 6564  _seed(self, seed
-0000cb10: 3a20 696e 742c 2073 7461 7469 635f 7365  : int, static_se
-0000cb20: 6564 3a20 626f 6f6c 203d 2046 616c 7365  ed: bool = False
-0000cb30: 2920 2d3e 2069 6e74 3a0d 0a20 2020 2020  ) -> int:..     
-0000cb40: 2020 2022 2222 5365 7473 2074 6865 2073     """Sets the s
-0000cb50: 6565 6473 206f 6620 7468 6520 656e 7669  eeds of the envi
-0000cb60: 726f 6e6d 656e 7473 2073 746f 7265 6420  ronments stored 
-0000cb70: 696e 2074 6865 2044 6174 6143 6f6c 6c65  in the DataColle
-0000cb80: 6374 6f72 2e0d 0a0d 0a20 2020 2020 2020  ctor.....       
-0000cb90: 2041 7267 733a 0d0a 2020 2020 2020 2020   Args:..        
-0000cba0: 2020 2020 7365 6564 3a20 696e 7465 6765      seed: intege
-0000cbb0: 7220 7265 7072 6573 656e 7469 6e67 2074  r representing t
-0000cbc0: 6865 2073 6565 6420 746f 2062 6520 7573  he seed to be us
-0000cbd0: 6564 2066 6f72 2074 6865 2065 6e76 6972  ed for the envir
-0000cbe0: 6f6e 6d65 6e74 2e0d 0a20 2020 2020 2020  onment...       
-0000cbf0: 2020 2020 2073 7461 7469 635f 7365 6564       static_seed
-0000cc00: 2028 626f 6f6c 2c20 6f70 7469 6f6e 616c   (bool, optional
-0000cc10: 293a 2069 6620 5472 7565 2c20 7468 6520  ): if True, the 
-0000cc20: 7365 6564 2069 7320 6e6f 7420 696e 6372  seed is not incr
-0000cc30: 656d 656e 7465 642e 0d0a 2020 2020 2020  emented...      
-0000cc40: 2020 2020 2020 2020 2020 4465 6661 756c            Defaul
-0000cc50: 7473 2074 6f20 4661 6c73 650d 0a0d 0a20  ts to False.... 
-0000cc60: 2020 2020 2020 2052 6574 7572 6e73 3a0d         Returns:.
-0000cc70: 0a20 2020 2020 2020 2020 2020 204f 7574  .            Out
-0000cc80: 7075 7420 7365 6564 2e20 5468 6973 2069  put seed. This i
-0000cc90: 7320 7573 6566 756c 2077 6865 6e20 6d6f  s useful when mo
-0000cca0: 7265 2074 6861 6e20 6f6e 6520 656e 7669  re than one envi
-0000ccb0: 726f 6e6d 656e 7420 6973 0d0a 2020 2020  ronment is..    
-0000ccc0: 2020 2020 2020 2020 636f 6e74 6169 6e65          containe
-0000ccd0: 6420 696e 2074 6865 2044 6174 6143 6f6c  d in the DataCol
-0000cce0: 6c65 6374 6f72 2c20 6173 2074 6865 2073  lector, as the s
-0000ccf0: 6565 6420 7769 6c6c 2062 6520 696e 6372  eed will be incr
-0000cd00: 656d 656e 7465 6420 666f 720d 0a20 2020  emented for..   
-0000cd10: 2020 2020 2020 2020 2065 6163 6820 6f66           each of
-0000cd20: 2074 6865 7365 2e20 5468 6520 7265 7375   these. The resu
-0000cd30: 6c74 696e 6720 7365 6564 2069 7320 7468  lting seed is th
-0000cd40: 6520 7365 6564 206f 6620 7468 6520 6c61  e seed of the la
-0000cd50: 7374 0d0a 2020 2020 2020 2020 2020 2020  st..            
-0000cd60: 656e 7669 726f 6e6d 656e 742e 0d0a 0d0a  environment.....
-0000cd70: 2020 2020 2020 2020 4578 616d 706c 6573          Examples
-0000cd80: 3a0d 0a20 2020 2020 2020 2020 2020 203e  :..            >
-0000cd90: 3e3e 2065 6e76 5f66 6e20 3d20 6c61 6d62  >> env_fn = lamb
-0000cda0: 6461 3a20 4779 6d45 6e76 2822 5065 6e64  da: GymEnv("Pend
-0000cdb0: 756c 756d 2d76 3022 290d 0a20 2020 2020  ulum-v0")..     
-0000cdc0: 2020 2020 2020 203e 3e3e 2065 6e76 5f66         >>> env_f
-0000cdd0: 6e5f 7061 7261 6c6c 656c 203d 206c 616d  n_parallel = lam
-0000cde0: 6264 613a 2050 6172 616c 6c65 6c45 6e76  bda: ParallelEnv
-0000cdf0: 2836 2c20 656e 765f 666e 290d 0a20 2020  (6, env_fn)..   
-0000ce00: 2020 2020 2020 2020 203e 3e3e 2063 6f6c           >>> col
-0000ce10: 6c65 6374 6f72 203d 2053 796e 6344 6174  lector = SyncDat
-0000ce20: 6143 6f6c 6c65 6374 6f72 2865 6e76 5f66  aCollector(env_f
-0000ce30: 6e5f 7061 7261 6c6c 656c 290d 0a20 2020  n_parallel)..   
-0000ce40: 2020 2020 2020 2020 203e 3e3e 206f 7574           >>> out
-0000ce50: 5f73 6565 6420 3d20 636f 6c6c 6563 746f  _seed = collecto
-0000ce60: 722e 7365 745f 7365 6564 2831 2920 2023  r.set_seed(1)  #
-0000ce70: 206f 7574 5f73 6565 6420 3d20 360d 0a0d   out_seed = 6...
-0000ce80: 0a20 2020 2020 2020 2022 2222 0d0a 2020  .        """..  
-0000ce90: 2020 2020 2020 5f63 6865 636b 5f66 6f72        _check_for
-0000cea0: 5f66 6175 6c74 795f 7072 6f63 6573 7328  _faulty_process(
-0000ceb0: 7365 6c66 2e70 726f 6373 290d 0a20 2020  self.procs)..   
-0000cec0: 2020 2020 2066 6f72 2069 6478 2069 6e20       for idx in 
-0000ced0: 7261 6e67 6528 7365 6c66 2e6e 756d 5f77  range(self.num_w
-0000cee0: 6f72 6b65 7273 293a 0d0a 2020 2020 2020  orkers):..      
-0000cef0: 2020 2020 2020 7365 6c66 2e70 6970 6573        self.pipes
-0000cf00: 5b69 6478 5d2e 7365 6e64 2828 2873 6565  [idx].send(((see
-0000cf10: 642c 2073 7461 7469 635f 7365 6564 292c  d, static_seed),
-0000cf20: 2022 7365 6564 2229 290d 0a20 2020 2020   "seed"))..     
-0000cf30: 2020 2020 2020 206e 6577 5f73 6565 642c         new_seed,
-0000cf40: 206d 7367 203d 2073 656c 662e 7069 7065   msg = self.pipe
-0000cf50: 735b 6964 785d 2e72 6563 7628 290d 0a20  s[idx].recv().. 
-0000cf60: 2020 2020 2020 2020 2020 2069 6620 6d73             if ms
-0000cf70: 6720 213d 2022 7365 6564 6564 223a 0d0a  g != "seeded":..
-0000cf80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000cf90: 7261 6973 6520 5275 6e74 696d 6545 7272  raise RuntimeErr
-0000cfa0: 6f72 2866 2245 7870 6563 7465 6420 6d73  or(f"Expected ms
-0000cfb0: 673d 2773 6565 6465 6427 2c20 676f 7420  g='seeded', got 
-0000cfc0: 7b6d 7367 7d22 290d 0a20 2020 2020 2020  {msg}")..       
-0000cfd0: 2020 2020 2073 6565 6420 3d20 6e65 775f       seed = new_
-0000cfe0: 7365 6564 0d0a 2020 2020 2020 2020 7365  seed..        se
-0000cff0: 6c66 2e72 6573 6574 2829 0d0a 2020 2020  lf.reset()..    
-0000d000: 2020 2020 7265 7475 726e 2073 6565 640d      return seed.
-0000d010: 0a0d 0a20 2020 2064 6566 2072 6573 6574  ...    def reset
-0000d020: 2873 656c 662c 2072 6573 6574 5f69 6478  (self, reset_idx
-0000d030: 3a20 4f70 7469 6f6e 616c 5b53 6571 7565  : Optional[Seque
-0000d040: 6e63 655b 626f 6f6c 5d5d 203d 204e 6f6e  nce[bool]] = Non
-0000d050: 6529 202d 3e20 4e6f 6e65 3a0d 0a20 2020  e) -> None:..   
-0000d060: 2020 2020 2022 2222 5265 7365 7473 2074       """Resets t
-0000d070: 6865 2065 6e76 6972 6f6e 6d65 6e74 7320  he environments 
-0000d080: 746f 2061 206e 6577 2069 6e69 7469 616c  to a new initial
-0000d090: 2073 7461 7465 2e0d 0a0d 0a20 2020 2020   state.....     
-0000d0a0: 2020 2041 7267 733a 0d0a 2020 2020 2020     Args:..      
-0000d0b0: 2020 2020 2020 7265 7365 745f 6964 783a        reset_idx:
-0000d0c0: 204f 7074 696f 6e61 6c2e 2053 6571 7565   Optional. Seque
-0000d0d0: 6e63 6520 696e 6469 6361 7469 6e67 2077  nce indicating w
-0000d0e0: 6869 6368 2065 6e76 6972 6f6e 6d65 6e74  hich environment
-0000d0f0: 7320 6861 7665 0d0a 2020 2020 2020 2020  s have..        
-0000d100: 2020 2020 2020 2020 746f 2062 6520 7265          to be re
-0000d110: 7365 742e 2049 6620 4e6f 6e65 2c20 616c  set. If None, al
-0000d120: 6c20 656e 7669 726f 6e6d 656e 7473 2061  l environments a
-0000d130: 7265 2072 6573 6574 2e0d 0a0d 0a20 2020  re reset.....   
-0000d140: 2020 2020 2022 2222 0d0a 2020 2020 2020       """..      
-0000d150: 2020 5f63 6865 636b 5f66 6f72 5f66 6175    _check_for_fau
-0000d160: 6c74 795f 7072 6f63 6573 7328 7365 6c66  lty_process(self
-0000d170: 2e70 726f 6373 290d 0a0d 0a20 2020 2020  .procs)....     
-0000d180: 2020 2069 6620 7265 7365 745f 6964 7820     if reset_idx 
-0000d190: 6973 204e 6f6e 653a 0d0a 2020 2020 2020  is None:..      
-0000d1a0: 2020 2020 2020 7265 7365 745f 6964 7820        reset_idx 
-0000d1b0: 3d20 5b54 7275 6520 666f 7220 5f20 696e  = [True for _ in
-0000d1c0: 2072 616e 6765 2873 656c 662e 6e75 6d5f   range(self.num_
-0000d1d0: 776f 726b 6572 7329 5d0d 0a20 2020 2020  workers)]..     
-0000d1e0: 2020 2066 6f72 2069 6478 2069 6e20 7261     for idx in ra
-0000d1f0: 6e67 6528 7365 6c66 2e6e 756d 5f77 6f72  nge(self.num_wor
-0000d200: 6b65 7273 293a 0d0a 2020 2020 2020 2020  kers):..        
-0000d210: 2020 2020 6966 2072 6573 6574 5f69 6478      if reset_idx
-0000d220: 5b69 6478 5d3a 0d0a 2020 2020 2020 2020  [idx]:..        
-0000d230: 2020 2020 2020 2020 7365 6c66 2e70 6970          self.pip
-0000d240: 6573 5b69 6478 5d2e 7365 6e64 2828 4e6f  es[idx].send((No
-0000d250: 6e65 2c20 2272 6573 6574 2229 290d 0a20  ne, "reset")).. 
-0000d260: 2020 2020 2020 2066 6f72 2069 6478 2069         for idx i
-0000d270: 6e20 7261 6e67 6528 7365 6c66 2e6e 756d  n range(self.num
-0000d280: 5f77 6f72 6b65 7273 293a 0d0a 2020 2020  _workers):..    
-0000d290: 2020 2020 2020 2020 6966 2072 6573 6574          if reset
-0000d2a0: 5f69 6478 5b69 6478 5d3a 0d0a 2020 2020  _idx[idx]:..    
-0000d2b0: 2020 2020 2020 2020 2020 2020 6a2c 206d              j, m
-0000d2c0: 7367 203d 2073 656c 662e 7069 7065 735b  sg = self.pipes[
-0000d2d0: 6964 785d 2e72 6563 7628 290d 0a20 2020  idx].recv()..   
-0000d2e0: 2020 2020 2020 2020 2020 2020 2069 6620               if 
-0000d2f0: 6d73 6720 213d 2022 7265 7365 7422 3a0d  msg != "reset":.
-0000d300: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000d310: 2020 2020 2072 6169 7365 2052 756e 7469       raise Runti
-0000d320: 6d65 4572 726f 7228 6622 4578 7065 6374  meError(f"Expect
-0000d330: 6564 206d 7367 3d27 7265 7365 7427 2c20  ed msg='reset', 
-0000d340: 676f 7420 7b6d 7367 7d22 290d 0a0d 0a20  got {msg}").... 
-0000d350: 2020 2064 6566 2073 7461 7465 5f64 6963     def state_dic
-0000d360: 7428 7365 6c66 2920 2d3e 204f 7264 6572  t(self) -> Order
-0000d370: 6564 4469 6374 3a0d 0a20 2020 2020 2020  edDict:..       
-0000d380: 2022 2222 5265 7475 726e 7320 7468 6520   """Returns the 
-0000d390: 7374 6174 655f 6469 6374 206f 6620 7468  state_dict of th
-0000d3a0: 6520 6461 7461 2063 6f6c 6c65 6374 6f72  e data collector
-0000d3b0: 2e0d 0a0d 0a20 2020 2020 2020 2045 6163  .....        Eac
-0000d3c0: 6820 6669 656c 6420 7265 7072 6573 656e  h field represen
-0000d3d0: 7473 2061 2077 6f72 6b65 7220 636f 6e74  ts a worker cont
-0000d3e0: 6169 6e69 6e67 2069 7473 206f 776e 2073  aining its own s
-0000d3f0: 7461 7465 5f64 6963 742e 0d0a 0d0a 2020  tate_dict.....  
-0000d400: 2020 2020 2020 2222 220d 0a20 2020 2020        """..     
-0000d410: 2020 2066 6f72 2069 6478 2069 6e20 7261     for idx in ra
-0000d420: 6e67 6528 7365 6c66 2e6e 756d 5f77 6f72  nge(self.num_wor
-0000d430: 6b65 7273 293a 0d0a 2020 2020 2020 2020  kers):..        
-0000d440: 2020 2020 7365 6c66 2e70 6970 6573 5b69      self.pipes[i
-0000d450: 6478 5d2e 7365 6e64 2828 4e6f 6e65 2c20  dx].send((None, 
-0000d460: 2273 7461 7465 5f64 6963 7422 2929 0d0a  "state_dict"))..
-0000d470: 2020 2020 2020 2020 7374 6174 655f 6469          state_di
-0000d480: 6374 203d 204f 7264 6572 6564 4469 6374  ct = OrderedDict
-0000d490: 2829 0d0a 2020 2020 2020 2020 666f 7220  ()..        for 
-0000d4a0: 6964 7820 696e 2072 616e 6765 2873 656c  idx in range(sel
-0000d4b0: 662e 6e75 6d5f 776f 726b 6572 7329 3a0d  f.num_workers):.
-0000d4c0: 0a20 2020 2020 2020 2020 2020 205f 7374  .            _st
-0000d4d0: 6174 655f 6469 6374 2c20 6d73 6720 3d20  ate_dict, msg = 
-0000d4e0: 7365 6c66 2e70 6970 6573 5b69 6478 5d2e  self.pipes[idx].
-0000d4f0: 7265 6376 2829 0d0a 2020 2020 2020 2020  recv()..        
-0000d500: 2020 2020 6966 206d 7367 2021 3d20 2273      if msg != "s
-0000d510: 7461 7465 5f64 6963 7422 3a0d 0a20 2020  tate_dict":..   
-0000d520: 2020 2020 2020 2020 2020 2020 2072 6169               rai
-0000d530: 7365 2052 756e 7469 6d65 4572 726f 7228  se RuntimeError(
-0000d540: 6622 4578 7065 6374 6564 206d 7367 3d27  f"Expected msg='
-0000d550: 7374 6174 655f 6469 6374 272c 2067 6f74  state_dict', got
-0000d560: 207b 6d73 677d 2229 0d0a 2020 2020 2020   {msg}")..      
-0000d570: 2020 2020 2020 7374 6174 655f 6469 6374        state_dict
-0000d580: 5b66 2277 6f72 6b65 727b 6964 787d 225d  [f"worker{idx}"]
-0000d590: 203d 205f 7374 6174 655f 6469 6374 0d0a   = _state_dict..
-0000d5a0: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
-0000d5b0: 2073 7461 7465 5f64 6963 740d 0a0d 0a20   state_dict.... 
-0000d5c0: 2020 2064 6566 206c 6f61 645f 7374 6174     def load_stat
-0000d5d0: 655f 6469 6374 2873 656c 662c 2073 7461  e_dict(self, sta
-0000d5e0: 7465 5f64 6963 743a 204f 7264 6572 6564  te_dict: Ordered
-0000d5f0: 4469 6374 2920 2d3e 204e 6f6e 653a 0d0a  Dict) -> None:..
-0000d600: 2020 2020 2020 2020 2222 224c 6f61 6473          """Loads
-0000d610: 2074 6865 2073 7461 7465 5f64 6963 7420   the state_dict 
-0000d620: 6f6e 2074 6865 2077 6f72 6b65 7273 2e0d  on the workers..
-0000d630: 0a0d 0a20 2020 2020 2020 2041 7267 733a  ...        Args:
-0000d640: 0d0a 2020 2020 2020 2020 2020 2020 7374  ..            st
-0000d650: 6174 655f 6469 6374 2028 4f72 6465 7265  ate_dict (Ordere
-0000d660: 6444 6963 7429 3a20 7374 6174 655f 6469  dDict): state_di
-0000d670: 6374 206f 6620 7468 6520 666f 726d 0d0a  ct of the form..
-0000d680: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000d690: 6060 7b22 776f 726b 6572 3022 3a20 7374  ``{"worker0": st
-0000d6a0: 6174 655f 6469 6374 302c 2022 776f 726b  ate_dict0, "work
-0000d6b0: 6572 3122 3a20 7374 6174 655f 6469 6374  er1": state_dict
-0000d6c0: 317d 6060 2e0d 0a0d 0a20 2020 2020 2020  1}``.....       
-0000d6d0: 2022 2222 0d0a 2020 2020 2020 2020 666f   """..        fo
-0000d6e0: 7220 6964 7820 696e 2072 616e 6765 2873  r idx in range(s
-0000d6f0: 656c 662e 6e75 6d5f 776f 726b 6572 7329  elf.num_workers)
-0000d700: 3a0d 0a20 2020 2020 2020 2020 2020 2073  :..            s
-0000d710: 656c 662e 7069 7065 735b 6964 785d 2e73  elf.pipes[idx].s
-0000d720: 656e 6428 2873 7461 7465 5f64 6963 745b  end((state_dict[
-0000d730: 6622 776f 726b 6572 7b69 6478 7d22 5d2c  f"worker{idx}"],
-0000d740: 2022 6c6f 6164 5f73 7461 7465 5f64 6963   "load_state_dic
-0000d750: 7422 2929 0d0a 2020 2020 2020 2020 666f  t"))..        fo
-0000d760: 7220 6964 7820 696e 2072 616e 6765 2873  r idx in range(s
-0000d770: 656c 662e 6e75 6d5f 776f 726b 6572 7329  elf.num_workers)
-0000d780: 3a0d 0a20 2020 2020 2020 2020 2020 205f  :..            _
-0000d790: 2c20 6d73 6720 3d20 7365 6c66 2e70 6970  , msg = self.pip
-0000d7a0: 6573 5b69 6478 5d2e 7265 6376 2829 0d0a  es[idx].recv()..
-0000d7b0: 2020 2020 2020 2020 2020 2020 6966 206d              if m
-0000d7c0: 7367 2021 3d20 226c 6f61 6465 6422 3a0d  sg != "loaded":.
-0000d7d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000d7e0: 2072 6169 7365 2052 756e 7469 6d65 4572   raise RuntimeEr
-0000d7f0: 726f 7228 6622 4578 7065 6374 6564 206d  ror(f"Expected m
-0000d800: 7367 3d27 6c6f 6164 6564 272c 2067 6f74  sg='loaded', got
-0000d810: 207b 6d73 677d 2229 0d0a 0d0a 0d0a 4061   {msg}")......@a
-0000d820: 6363 6570 745f 7265 6d6f 7465 5f72 7265  ccept_remote_rre
-0000d830: 665f 7564 665f 696e 766f 6361 7469 6f6e  f_udf_invocation
-0000d840: 0d0a 636c 6173 7320 4d75 6c74 6953 796e  ..class MultiSyn
-0000d850: 6344 6174 6143 6f6c 6c65 6374 6f72 285f  cDataCollector(_
-0000d860: 4d75 6c74 6944 6174 6143 6f6c 6c65 6374  MultiDataCollect
-0000d870: 6f72 293a 0d0a 2020 2020 2222 2252 756e  or):..    """Run
-0000d880: 7320 6120 6769 7665 6e20 6e75 6d62 6572  s a given number
-0000d890: 206f 6620 4461 7461 436f 6c6c 6563 746f   of DataCollecto
-0000d8a0: 7273 206f 6e20 7365 7061 7261 7465 2070  rs on separate p
-0000d8b0: 726f 6365 7373 6573 2073 796e 6368 726f  rocesses synchro
-0000d8c0: 6e6f 7573 6c79 2e0d 0a0d 0a20 2020 202e  nously.....    .
-0000d8d0: 2e20 6161 6669 673a 3a0d 0a0d 0a20 2020  . aafig::....   
-0000d8e0: 2020 2020 2020 2020 202b 2d2d 2d2d 2d2d           +------
-0000d8f0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-0000d900: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-0000d910: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-0000d920: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-0000d930: 2b0d 0a20 2020 2020 2020 2020 2020 207c  +..            |
-0000d940: 2020 2020 2020 2020 2020 2020 224d 756c              "Mul
-0000d950: 7469 5379 6e63 4461 7461 436f 6c6c 6563  tiSyncDataCollec
-0000d960: 746f 7222 2020 2020 2020 2020 2020 2020  tor"            
-0000d970: 2020 2020 207c 2020 2020 2020 2020 2020       |          
-0000d980: 2020 2020 2020 7c0d 0a20 2020 2020 2020        |..       
-0000d990: 2020 2020 207c 7e7e 7e7e 7e7e 7e7e 7e7e       |~~~~~~~~~~
-0000d9a0: 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e  ~~~~~~~~~~~~~~~~
-0000d9b0: 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e  ~~~~~~~~~~~~~~~~
-0000d9c0: 7e7e 7e7e 7e7e 7e7e 7e7e 7e7c 2020 2020  ~~~~~~~~~~~|    
-0000d9d0: 2020 2020 2020 2020 2020 2020 7c0d 0a20              |.. 
-0000d9e0: 2020 2020 2020 2020 2020 207c 2020 2022             |   "
-0000d9f0: 436f 6c6c 6563 746f 7220 3122 207c 2020  Collector 1" |  
-0000da00: 2243 6f6c 6c65 6374 6f72 2032 2220 207c  "Collector 2"  |
-0000da10: 2020 2243 6f6c 6c65 6374 6f72 2033 2220    "Collector 3" 
-0000da20: 207c 2020 2020 204d 6169 6e20 2020 2020   |     Main     
-0000da30: 2020 7c0d 0a20 2020 2020 2020 2020 2020    |..           
-0000da40: 207c 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e   |~~~~~~~~~~~~~~
-0000da50: 7e7e 7e7c 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e  ~~~|~~~~~~~~~~~~
-0000da60: 7e7e 7e7e 7e7c 7e7e 7e7e 7e7e 7e7e 7e7e  ~~~~~|~~~~~~~~~~
-0000da70: 7e7e 7e7e 7e7e 7e7c 7e7e 7e7e 7e7e 7e7e  ~~~~~~~|~~~~~~~~
-0000da80: 7e7e 7e7e 7e7e 7e7e 7c0d 0a20 2020 2020  ~~~~~~~~|..     
-0000da90: 2020 2020 2020 207c 2022 656e 7631 2220         | "env1" 
-0000daa0: 7c20 2265 6e76 3222 207c 2022 656e 7633  | "env2" | "env3
-0000dab0: 2220 7c20 2265 6e76 3422 207c 2022 656e  " | "env4" | "en
-0000dac0: 7635 2220 7c20 2265 6e76 3622 207c 2020  v5" | "env6" |  
-0000dad0: 2020 2020 2020 2020 2020 2020 2020 7c0d                |.
-0000dae0: 0a20 2020 2020 2020 2020 2020 207c 7e7e  .            |~~
-0000daf0: 7e7e 7e7e 7e7e 7c7e 7e7e 7e7e 7e7e 7e7c  ~~~~~~|~~~~~~~~|
-0000db00: 7e7e 7e7e 7e7e 7e7e 7c7e 7e7e 7e7e 7e7e  ~~~~~~~~|~~~~~~~
-0000db10: 7e7c 7e7e 7e7e 7e7e 7e7e 7c7e 7e7e 7e7e  ~|~~~~~~~~|~~~~~
-0000db20: 7e7e 7e7c 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e  ~~~|~~~~~~~~~~~~
-0000db30: 7e7e 7e7e 7c0d 0a20 2020 2020 2020 2020  ~~~~|..         
-0000db40: 2020 207c 2272 6573 6574 2220 7c22 7265     |"reset" |"re
-0000db50: 7365 7422 207c 2272 6573 6574 2220 7c22  set" |"reset" |"
-0000db60: 7265 7365 7422 207c 2272 6573 6574 2220  reset" |"reset" 
-0000db70: 7c22 7265 7365 7422 207c 2020 2020 2020  |"reset" |      
-0000db80: 2020 2020 2020 2020 2020 7c0d 0a20 2020            |..   
-0000db90: 2020 2020 2020 2020 207c 2020 2020 2020           |      
-0000dba0: 2020 7c20 2020 2020 2020 207c 2020 2020    |        |    
-0000dbb0: 2020 2020 7c20 2020 2020 2020 207c 2020      |        |  
-0000dbc0: 2020 2020 2020 7c20 2020 2020 2020 207c        |        |
-0000dbd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000dbe0: 7c0d 0a20 2020 2020 2020 2020 2020 207c  |..            |
-0000dbf0: 2020 2020 2020 2022 6163 746f 7222 2020         "actor"  
-0000dc00: 207c 2020 2020 2020 2020 7c20 2020 2020   |        |     
-0000dc10: 2020 207c 2020 2020 2020 2022 6163 746f     |       "acto
-0000dc20: 7222 2020 207c 2020 2020 2020 2020 2020  r"   |          
-0000dc30: 2020 2020 2020 7c0d 0a20 2020 2020 2020        |..       
-0000dc40: 2020 2020 207c 2020 2020 2020 2020 2020       |          
-0000dc50: 2020 2020 2020 207c 2020 2020 2020 2020         |        
-0000dc60: 7c20 2020 2020 2020 207c 2020 2020 2020  |        |      
-0000dc70: 2020 2020 2020 2020 2020 207c 2020 2020             |    
-0000dc80: 2020 2020 2020 2020 2020 2020 7c0d 0a20              |.. 
-0000dc90: 2020 2020 2020 2020 2020 207c 2022 7374             | "st
-0000dca0: 6570 2220 7c20 2273 7465 7022 207c 2020  ep" | "step" |  
-0000dcb0: 2020 2020 2022 6163 746f 7222 2020 207c       "actor"   |
-0000dcc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000dcd0: 207c 2020 2020 2020 2020 2020 2020 2020   |              
-0000dce0: 2020 7c0d 0a20 2020 2020 2020 2020 2020    |..           
-0000dcf0: 207c 2020 2020 2020 2020 7c20 2020 2020   |        |     
-0000dd00: 2020 207c 2020 2020 2020 2020 2020 2020     |            
-0000dd10: 2020 2020 207c 2020 2020 2020 2020 2020       |          
-0000dd20: 2020 2020 2020 207c 2020 2020 2020 2020         |        
-0000dd30: 2020 2020 2020 2020 7c0d 0a20 2020 2020          |..     
-0000dd40: 2020 2020 2020 207c 2020 2020 2020 2020         |        
-0000dd50: 7c20 2020 2020 2020 207c 2020 2020 2020  |        |      
-0000dd60: 2020 2020 2020 2020 2020 207c 2022 7374             | "st
-0000dd70: 6570 2220 7c20 2273 7465 7022 207c 2020  ep" | "step" |  
-0000dd80: 2020 2020 2020 2020 2020 2020 2020 7c0d                |.
-0000dd90: 0a20 2020 2020 2020 2020 2020 207c 2020  .            |  
-0000dda0: 2020 2020 2020 7c20 2020 2020 2020 207c        |        |
-0000ddb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ddc0: 207c 2020 2020 2020 2020 7c20 2020 2020   |        |     
-0000ddd0: 2020 207c 2020 2020 2020 2020 2020 2020     |            
-0000dde0: 2020 2020 7c0d 0a20 2020 2020 2020 2020      |..         
-0000ddf0: 2020 207c 2020 2020 2020 2022 6163 746f     |       "acto
-0000de00: 7222 2020 207c 2022 7374 6570 2220 7c20  r"   | "step" | 
-0000de10: 2273 7465 7022 207c 2020 2020 2020 2022  "step" |       "
-0000de20: 6163 746f 7222 2020 207c 2020 2020 2020  actor"   |      
-0000de30: 2020 2020 2020 2020 2020 7c0d 0a20 2020            |..   
-0000de40: 2020 2020 2020 2020 207c 2020 2020 2020           |      
-0000de50: 2020 2020 2020 2020 2020 207c 2020 2020             |    
-0000de60: 2020 2020 7c20 2020 2020 2020 207c 2020      |        |  
-0000de70: 2020 2020 2020 2020 2020 2020 2020 207c                 |
-0000de80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000de90: 7c0d 0a20 2020 2020 2020 2020 2020 207c  |..            |
-0000dea0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000deb0: 207c 2020 2020 2020 2022 6163 746f 7222   |       "actor"
-0000dec0: 2020 207c 2020 2020 2020 2020 2020 2020     |            
-0000ded0: 2020 2020 207c 2020 2020 2020 2020 2020       |          
-0000dee0: 2020 2020 2020 7c0d 0a20 2020 2020 2020        |..       
-0000def0: 2020 2020 207c 2020 2020 2020 2020 2020       |          
-0000df00: 2020 2020 2020 207c 2020 2020 2020 2020         |        
-0000df10: 2020 2020 2020 2020 207c 2020 2020 2020           |      
-0000df20: 2020 2020 2020 2020 2020 207c 2020 2020             |    
-0000df30: 2020 2020 2020 2020 2020 2020 7c0d 0a20              |.. 
-0000df40: 2020 2020 2020 2020 2020 207c 2020 2020             |    
-0000df50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000df60: 2020 2022 7969 656c 6420 6261 7463 6820     "yield batch 
-0000df70: 6f66 2074 7261 6a20 3122 2d2d 2d2d 2d2d  of traj 1"------
-0000df80: 2d3e 2263 6f6c 6c65 6374 2c20 7472 6169  ->"collect, trai
-0000df90: 6e22 7c0d 0a20 2020 2020 2020 2020 2020  n"|..           
-0000dfa0: 207c 2020 2020 2020 2020 2020 2020 2020   |              
-0000dfb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000dfc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000dfd0: 2020 2020 2020 207c 2020 2020 2020 2020         |        
-0000dfe0: 2020 2020 2020 2020 7c0d 0a20 2020 2020          |..     
-0000dff0: 2020 2020 2020 207c 2022 7374 6570 2220         | "step" 
-0000e000: 7c20 2273 7465 7022 207c 2022 7374 6570  | "step" | "step
-0000e010: 2220 7c20 2273 7465 7022 207c 2022 7374  " | "step" | "st
-0000e020: 6570 2220 7c20 2273 7465 7022 207c 2020  ep" | "step" |  
-0000e030: 2020 2020 2020 2020 2020 2020 2020 7c0d                |.
-0000e040: 0a20 2020 2020 2020 2020 2020 207c 2020  .            |  
-0000e050: 2020 2020 2020 7c20 2020 2020 2020 207c        |        |
-0000e060: 2020 2020 2020 2020 7c20 2020 2020 2020          |       
-0000e070: 207c 2020 2020 2020 2020 7c20 2020 2020   |        |     
-0000e080: 2020 207c 2020 2020 2020 2020 2020 2020     |            
-0000e090: 2020 2020 7c0d 0a20 2020 2020 2020 2020      |..         
-0000e0a0: 2020 207c 2020 2020 2020 2022 6163 746f     |       "acto
-0000e0b0: 7222 2020 207c 2020 2020 2020 2022 6163  r"   |       "ac
-0000e0c0: 746f 7222 2020 207c 2020 2020 2020 2020  tor"   |        
-0000e0d0: 7c20 2020 2020 2020 207c 2020 2020 2020  |        |      
-0000e0e0: 2020 2020 2020 2020 2020 7c0d 0a20 2020            |..   
-0000e0f0: 2020 2020 2020 2020 207c 2020 2020 2020           |      
-0000e100: 2020 2020 2020 2020 2020 207c 2022 7374             | "st
-0000e110: 6570 2220 7c20 2273 7465 7022 207c 2020  ep" | "step" |  
-0000e120: 2020 2020 2022 6163 746f 7222 2020 207c       "actor"   |
-0000e130: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e140: 7c0d 0a20 2020 2020 2020 2020 2020 207c  |..            |
-0000e150: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e160: 207c 2020 2020 2020 2020 7c20 2020 2020   |        |     
-0000e170: 2020 207c 2020 2020 2020 2020 2020 2020     |            
-0000e180: 2020 2020 207c 2020 2020 2020 2020 2020       |          
-0000e190: 2020 2020 2020 7c0d 0a20 2020 2020 2020        |..       
-0000e1a0: 2020 2020 207c 2022 7374 6570 2220 7c20       | "step" | 
-0000e1b0: 2273 7465 7022 207c 2020 2020 2020 2022  "step" |       "
-0000e1c0: 6163 746f 7222 2020 207c 2022 7374 6570  actor"   | "step
-0000e1d0: 2220 7c20 2273 7465 7022 207c 2020 2020  " | "step" |    
-0000e1e0: 2020 2020 2020 2020 2020 2020 7c0d 0a20              |.. 
-0000e1f0: 2020 2020 2020 2020 2020 207c 2020 2020             |    
-0000e200: 2020 2020 7c20 2020 2020 2020 207c 2020      |        |  
-0000e210: 2020 2020 2020 2020 2020 2020 2020 207c                 |
-0000e220: 2020 2020 2020 2020 7c20 2020 2020 2020          |       
-0000e230: 207c 2020 2020 2020 2020 2020 2020 2020   |              
-0000e240: 2020 7c0d 0a20 2020 2020 2020 2020 2020    |..           
-0000e250: 207c 2020 2020 2020 2022 6163 746f 7222   |       "actor"
-0000e260: 2020 207c 2020 2020 2020 2020 2020 2020     |            
-0000e270: 2020 2020 207c 2020 2020 2020 2022 6163       |       "ac
-0000e280: 746f 7222 2020 207c 2020 2020 2020 2020  tor"   |        
-0000e290: 2020 2020 2020 2020 7c0d 0a20 2020 2020          |..     
-0000e2a0: 2020 2020 2020 207c 2020 2020 2020 2020         |        
-0000e2b0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
-0000e2c0: 7969 656c 6420 6261 7463 6820 6f66 2074  yield batch of t
-0000e2d0: 7261 6a20 3222 2d2d 2d2d 2d2d 2d3e 2263  raj 2"------->"c
-0000e2e0: 6f6c 6c65 6374 2c20 7472 6169 6e22 7c0d  ollect, train"|.
-0000e2f0: 0a20 2020 2020 2020 2020 2020 207c 2020  .            |  
-0000e300: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e310: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e320: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e330: 2020 207c 2020 2020 2020 2020 2020 2020     |            
-0000e340: 2020 2020 7c0d 0a20 2020 2020 2020 2020      |..         
-0000e350: 2020 202b 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d     +------------
-0000e360: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-0000e370: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-0000e380: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-0000e390: 2d2d 2d2d 2d2d 2d2d 2d2d 2b0d 0a0d 0a20  ----------+.... 
-0000e3a0: 2020 2045 6e76 7320 6361 6e20 6265 2069     Envs can be i
-0000e3b0: 6465 6e74 6963 616c 206f 7220 6469 6666  dentical or diff
-0000e3c0: 6572 656e 742e 0d0a 0d0a 2020 2020 5468  erent.....    Th
-0000e3d0: 6520 636f 6c6c 6563 7469 6f6e 2073 7461  e collection sta
-0000e3e0: 7274 7320 7768 656e 2074 6865 206e 6578  rts when the nex
-0000e3f0: 7420 6974 656d 206f 6620 7468 6520 636f  t item of the co
-0000e400: 6c6c 6563 746f 7220 6973 2071 7565 7269  llector is queri
-0000e410: 6564 2c0d 0a20 2020 2061 6e64 206e 6f20  ed,..    and no 
-0000e420: 656e 7669 726f 6e6d 656e 7420 7374 6570  environment step
-0000e430: 2069 7320 636f 6d70 7574 6564 2069 6e20   is computed in 
-0000e440: 6265 7477 6565 6e20 7468 6520 7265 6365  between the rece
-0000e450: 7074 696f 6e20 6f66 2061 2062 6174 6368  ption of a batch
-0000e460: 206f 660d 0a20 2020 2074 7261 6a65 6374   of..    traject
-0000e470: 6f72 7920 616e 6420 7468 6520 7374 6172  ory and the star
-0000e480: 7420 6f66 2074 6865 206e 6578 7420 636f  t of the next co
-0000e490: 6c6c 6563 7469 6f6e 2e0d 0a20 2020 2054  llection...    T
-0000e4a0: 6869 7320 636c 6173 7320 6361 6e20 6265  his class can be
-0000e4b0: 2073 6166 656c 7920 7573 6564 2077 6974   safely used wit
-0000e4c0: 6820 6f6e 6c69 6e65 2052 4c20 616c 676f  h online RL algo
-0000e4d0: 7269 7468 6d73 2e0d 0a0d 0a20 2020 2045  rithms.....    E
-0000e4e0: 7861 6d70 6c65 733a 0d0a 2020 2020 2020  xamples:..      
-0000e4f0: 2020 3e3e 3e20 6672 6f6d 2074 6f72 6368    >>> from torch
-0000e500: 726c 2e65 6e76 732e 6c69 6273 2e67 796d  rl.envs.libs.gym
-0000e510: 2069 6d70 6f72 7420 4779 6d45 6e76 0d0a   import GymEnv..
-0000e520: 2020 2020 2020 2020 3e3e 3e20 6672 6f6d          >>> from
-0000e530: 2074 6f72 6368 726c 2e65 6e76 7320 696d   torchrl.envs im
-0000e540: 706f 7274 2053 7465 7043 6f75 6e74 6572  port StepCounter
-0000e550: 0d0a 2020 2020 2020 2020 3e3e 3e20 6672  ..        >>> fr
-0000e560: 6f6d 2074 656e 736f 7264 6963 742e 6e6e  om tensordict.nn
-0000e570: 2069 6d70 6f72 7420 5465 6e73 6f72 4469   import TensorDi
-0000e580: 6374 4d6f 6475 6c65 0d0a 2020 2020 2020  ctModule..      
-0000e590: 2020 3e3e 3e20 6672 6f6d 2074 6f72 6368    >>> from torch
-0000e5a0: 2069 6d70 6f72 7420 6e6e 0d0a 2020 2020   import nn..    
-0000e5b0: 2020 2020 3e3e 3e20 656e 765f 6d61 6b65      >>> env_make
-0000e5c0: 7220 3d20 6c61 6d62 6461 3a20 5472 616e  r = lambda: Tran
-0000e5d0: 7366 6f72 6d65 6445 6e76 2847 796d 456e  sformedEnv(GymEn
-0000e5e0: 7628 2250 656e 6475 6c75 6d2d 7631 222c  v("Pendulum-v1",
-0000e5f0: 2064 6576 6963 653d 2263 7075 2229 2c20   device="cpu"), 
-0000e600: 5374 6570 436f 756e 7465 7228 6d61 785f  StepCounter(max_
-0000e610: 7374 6570 733d 3530 2929 0d0a 2020 2020  steps=50))..    
-0000e620: 2020 2020 3e3e 3e20 706f 6c69 6379 203d      >>> policy =
-0000e630: 2054 656e 736f 7244 6963 744d 6f64 756c   TensorDictModul
-0000e640: 6528 6e6e 2e4c 696e 6561 7228 332c 2031  e(nn.Linear(3, 1
-0000e650: 292c 2069 6e5f 6b65 7973 3d5b 226f 6273  ), in_keys=["obs
-0000e660: 6572 7661 7469 6f6e 225d 2c20 6f75 745f  ervation"], out_
-0000e670: 6b65 7973 3d5b 2261 6374 696f 6e22 5d29  keys=["action"])
-0000e680: 0d0a 2020 2020 2020 2020 3e3e 3e20 636f  ..        >>> co
-0000e690: 6c6c 6563 746f 7220 3d20 4d75 6c74 6953  llector = MultiS
-0000e6a0: 796e 6344 6174 6143 6f6c 6c65 6374 6f72  yncDataCollector
-0000e6b0: 280d 0a20 2020 2020 2020 202e 2e2e 2020  (..        ...  
-0000e6c0: 2020 2063 7265 6174 655f 656e 765f 666e     create_env_fn
-0000e6d0: 3d5b 656e 765f 6d61 6b65 722c 2065 6e76  =[env_maker, env
-0000e6e0: 5f6d 616b 6572 5d2c 0d0a 2020 2020 2020  _maker],..      
-0000e6f0: 2020 2e2e 2e20 2020 2020 706f 6c69 6379    ...     policy
-0000e700: 3d70 6f6c 6963 792c 0d0a 2020 2020 2020  =policy,..      
-0000e710: 2020 2e2e 2e20 2020 2020 746f 7461 6c5f    ...     total_
-0000e720: 6672 616d 6573 3d32 3030 302c 0d0a 2020  frames=2000,..  
-0000e730: 2020 2020 2020 2e2e 2e20 2020 2020 6d61        ...     ma
-0000e740: 785f 6672 616d 6573 5f70 6572 5f74 7261  x_frames_per_tra
-0000e750: 6a3d 3530 2c0d 0a20 2020 2020 2020 202e  j=50,..        .
-0000e760: 2e2e 2020 2020 2066 7261 6d65 735f 7065  ..     frames_pe
-0000e770: 725f 6261 7463 683d 3230 302c 0d0a 2020  r_batch=200,..  
-0000e780: 2020 2020 2020 2e2e 2e20 2020 2020 696e        ...     in
-0000e790: 6974 5f72 616e 646f 6d5f 6672 616d 6573  it_random_frames
-0000e7a0: 3d2d 312c 0d0a 2020 2020 2020 2020 2e2e  =-1,..        ..
-0000e7b0: 2e20 2020 2020 7265 7365 745f 6174 5f65  .     reset_at_e
-0000e7c0: 6163 685f 6974 6572 3d46 616c 7365 2c0d  ach_iter=False,.
-0000e7d0: 0a20 2020 2020 2020 202e 2e2e 2020 2020  .        ...    
-0000e7e0: 2064 6576 6963 6573 3d22 6370 7522 2c0d   devices="cpu",.
-0000e7f0: 0a20 2020 2020 2020 202e 2e2e 2020 2020  .        ...    
-0000e800: 2073 746f 7269 6e67 5f64 6576 6963 6573   storing_devices
-0000e810: 3d22 6370 7522 2c0d 0a20 2020 2020 2020  ="cpu",..       
-0000e820: 202e 2e2e 2029 0d0a 2020 2020 2020 2020   ... )..        
-0000e830: 3e3e 3e20 666f 7220 692c 2064 6174 6120  >>> for i, data 
-0000e840: 696e 2065 6e75 6d65 7261 7465 2863 6f6c  in enumerate(col
-0000e850: 6c65 6374 6f72 293a 0d0a 2020 2020 2020  lector):..      
-0000e860: 2020 2e2e 2e20 2020 2020 6966 2069 203d    ...     if i =
-0000e870: 3d20 323a 0d0a 2020 2020 2020 2020 2e2e  = 2:..        ..
-0000e880: 2e20 2020 2020 2020 2020 7072 696e 7428  .         print(
-0000e890: 6461 7461 290d 0a20 2020 2020 2020 202e  data)..        .
-0000e8a0: 2e2e 2020 2020 2020 2020 2062 7265 616b  ..         break
-0000e8b0: 0d0a 2020 2020 2020 2020 5465 6e73 6f72  ..        Tensor
-0000e8c0: 4469 6374 280d 0a20 2020 2020 2020 2020  Dict(..         
-0000e8d0: 2020 2066 6965 6c64 733d 7b0d 0a20 2020     fields={..   
-0000e8e0: 2020 2020 2020 2020 2020 2020 2061 6374               act
-0000e8f0: 696f 6e3a 2054 656e 736f 7228 7368 6170  ion: Tensor(shap
-0000e900: 653d 746f 7263 682e 5369 7a65 285b 342c  e=torch.Size([4,
-0000e910: 2035 302c 2031 5d29 2c20 6465 7669 6365   50, 1]), device
-0000e920: 3d63 7075 2c20 6474 7970 653d 746f 7263  =cpu, dtype=torc
-0000e930: 682e 666c 6f61 7433 322c 2069 735f 7368  h.float32, is_sh
-0000e940: 6172 6564 3d46 616c 7365 292c 0d0a 2020  ared=False),..  
-0000e950: 2020 2020 2020 2020 2020 2020 2020 636f                co
-0000e960: 6c6c 6563 746f 723a 2054 656e 736f 7244  llector: TensorD
-0000e970: 6963 7428 0d0a 2020 2020 2020 2020 2020  ict(..          
-0000e980: 2020 2020 2020 2020 2020 6669 656c 6473            fields
-0000e990: 3d7b 0d0a 2020 2020 2020 2020 2020 2020  ={..            
-0000e9a0: 2020 2020 2020 2020 2020 2020 7374 6570              step
-0000e9b0: 5f63 6f75 6e74 3a20 5465 6e73 6f72 2873  _count: Tensor(s
-0000e9c0: 6861 7065 3d74 6f72 6368 2e53 697a 6528  hape=torch.Size(
-0000e9d0: 5b34 2c20 3530 5d29 2c20 6465 7669 6365  [4, 50]), device
-0000e9e0: 3d63 7075 2c20 6474 7970 653d 746f 7263  =cpu, dtype=torc
-0000e9f0: 682e 696e 7436 342c 2069 735f 7368 6172  h.int64, is_shar
-0000ea00: 6564 3d46 616c 7365 292c 0d0a 2020 2020  ed=False),..    
-0000ea10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ea20: 2020 2020 7472 616a 5f69 6473 3a20 5465      traj_ids: Te
-0000ea30: 6e73 6f72 2873 6861 7065 3d74 6f72 6368  nsor(shape=torch
-0000ea40: 2e53 697a 6528 5b34 2c20 3530 5d29 2c20  .Size([4, 50]), 
-0000ea50: 6465 7669 6365 3d63 7075 2c20 6474 7970  device=cpu, dtyp
-0000ea60: 653d 746f 7263 682e 696e 7436 342c 2069  e=torch.int64, i
-0000ea70: 735f 7368 6172 6564 3d46 616c 7365 297d  s_shared=False)}
-0000ea80: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
-0000ea90: 2020 2020 2020 2062 6174 6368 5f73 697a         batch_siz
-0000eaa0: 653d 746f 7263 682e 5369 7a65 285b 342c  e=torch.Size([4,
-0000eab0: 2035 305d 292c 0d0a 2020 2020 2020 2020   50]),..        
-0000eac0: 2020 2020 2020 2020 2020 2020 6465 7669              devi
-0000ead0: 6365 3d63 7075 2c0d 0a20 2020 2020 2020  ce=cpu,..       
-0000eae0: 2020 2020 2020 2020 2020 2020 2069 735f               is_
-0000eaf0: 7368 6172 6564 3d46 616c 7365 292c 0d0a  shared=False),..
-0000eb00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000eb10: 646f 6e65 3a20 5465 6e73 6f72 2873 6861  done: Tensor(sha
-0000eb20: 7065 3d74 6f72 6368 2e53 697a 6528 5b34  pe=torch.Size([4
-0000eb30: 2c20 3530 2c20 315d 292c 2064 6576 6963  , 50, 1]), devic
-0000eb40: 653d 6370 752c 2064 7479 7065 3d74 6f72  e=cpu, dtype=tor
-0000eb50: 6368 2e62 6f6f 6c2c 2069 735f 7368 6172  ch.bool, is_shar
-0000eb60: 6564 3d46 616c 7365 292c 0d0a 2020 2020  ed=False),..    
-0000eb70: 2020 2020 2020 2020 2020 2020 6d61 736b              mask
-0000eb80: 3a20 5465 6e73 6f72 2873 6861 7065 3d74  : Tensor(shape=t
-0000eb90: 6f72 6368 2e53 697a 6528 5b34 2c20 3530  orch.Size([4, 50
-0000eba0: 5d29 2c20 6465 7669 6365 3d63 7075 2c20  ]), device=cpu, 
-0000ebb0: 6474 7970 653d 746f 7263 682e 626f 6f6c  dtype=torch.bool
-0000ebc0: 2c20 6973 5f73 6861 7265 643d 4661 6c73  , is_shared=Fals
-0000ebd0: 6529 2c0d 0a20 2020 2020 2020 2020 2020  e),..           
-0000ebe0: 2020 2020 206e 6578 743a 2054 656e 736f       next: Tenso
-0000ebf0: 7244 6963 7428 0d0a 2020 2020 2020 2020  rDict(..        
-0000ec00: 2020 2020 2020 2020 2020 2020 6669 656c              fiel
-0000ec10: 6473 3d7b 0d0a 2020 2020 2020 2020 2020  ds={..          
-0000ec20: 2020 2020 2020 2020 2020 2020 2020 6f62                ob
-0000ec30: 7365 7276 6174 696f 6e3a 2054 656e 736f  servation: Tenso
-0000ec40: 7228 7368 6170 653d 746f 7263 682e 5369  r(shape=torch.Si
-0000ec50: 7a65 285b 342c 2035 302c 2033 5d29 2c20  ze([4, 50, 3]), 
-0000ec60: 6465 7669 6365 3d63 7075 2c20 6474 7970  device=cpu, dtyp
-0000ec70: 653d 746f 7263 682e 666c 6f61 7433 322c  e=torch.float32,
-0000ec80: 2069 735f 7368 6172 6564 3d46 616c 7365   is_shared=False
-0000ec90: 297d 2c0d 0a20 2020 2020 2020 2020 2020  )},..           
-0000eca0: 2020 2020 2020 2020 2062 6174 6368 5f73           batch_s
-0000ecb0: 697a 653d 746f 7263 682e 5369 7a65 285b  ize=torch.Size([
-0000ecc0: 342c 2035 305d 292c 0d0a 2020 2020 2020  4, 50]),..      
-0000ecd0: 2020 2020 2020 2020 2020 2020 2020 6465                de
-0000ece0: 7669 6365 3d63 7075 2c0d 0a20 2020 2020  vice=cpu,..     
-0000ecf0: 2020 2020 2020 2020 2020 2020 2020 2069                 i
-0000ed00: 735f 7368 6172 6564 3d46 616c 7365 292c  s_shared=False),
-0000ed10: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-0000ed20: 2020 6f62 7365 7276 6174 696f 6e3a 2054    observation: T
-0000ed30: 656e 736f 7228 7368 6170 653d 746f 7263  ensor(shape=torc
-0000ed40: 682e 5369 7a65 285b 342c 2035 302c 2033  h.Size([4, 50, 3
-0000ed50: 5d29 2c20 6465 7669 6365 3d63 7075 2c20  ]), device=cpu, 
-0000ed60: 6474 7970 653d 746f 7263 682e 666c 6f61  dtype=torch.floa
-0000ed70: 7433 322c 2069 735f 7368 6172 6564 3d46  t32, is_shared=F
-0000ed80: 616c 7365 292c 0d0a 2020 2020 2020 2020  alse),..        
-0000ed90: 2020 2020 2020 2020 7265 7761 7264 3a20          reward: 
-0000eda0: 5465 6e73 6f72 2873 6861 7065 3d74 6f72  Tensor(shape=tor
-0000edb0: 6368 2e53 697a 6528 5b34 2c20 3530 2c20  ch.Size([4, 50, 
-0000edc0: 315d 292c 2064 6576 6963 653d 6370 752c  1]), device=cpu,
-0000edd0: 2064 7479 7065 3d74 6f72 6368 2e66 6c6f   dtype=torch.flo
-0000ede0: 6174 3332 2c20 6973 5f73 6861 7265 643d  at32, is_shared=
-0000edf0: 4661 6c73 6529 7d2c 0d0a 2020 2020 2020  False)},..      
-0000ee00: 2020 2020 2020 6261 7463 685f 7369 7a65        batch_size
-0000ee10: 3d74 6f72 6368 2e53 697a 6528 5b34 2c20  =torch.Size([4, 
-0000ee20: 3530 5d29 2c0d 0a20 2020 2020 2020 2020  50]),..         
-0000ee30: 2020 2064 6576 6963 653d 6370 752c 0d0a     device=cpu,..
-0000ee40: 2020 2020 2020 2020 2020 2020 6973 5f73              is_s
-0000ee50: 6861 7265 643d 4661 6c73 6529 0d0a 2020  hared=False)..  
-0000ee60: 2020 2020 2020 3e3e 3e20 636f 6c6c 6563        >>> collec
-0000ee70: 746f 722e 7368 7574 646f 776e 2829 0d0a  tor.shutdown()..
-0000ee80: 2020 2020 2020 2020 3e3e 3e20 6465 6c20          >>> del 
-0000ee90: 636f 6c6c 6563 746f 720d 0a0d 0a20 2020  collector....   
-0000eea0: 2022 2222 0d0a 0d0a 2020 2020 5f5f 646f   """....    __do
-0000eeb0: 635f 5f20 2b3d 205f 4d75 6c74 6944 6174  c__ += _MultiDat
-0000eec0: 6143 6f6c 6c65 6374 6f72 2e5f 5f64 6f63  aCollector.__doc
-0000eed0: 5f5f 0d0a 0d0a 2020 2020 2320 666f 7220  __....    # for 
-0000eee0: 5250 430d 0a20 2020 2064 6566 206e 6578  RPC..    def nex
-0000eef0: 7428 7365 6c66 293a 0d0a 2020 2020 2020  t(self):..      
-0000ef00: 2020 7265 7475 726e 2073 7570 6572 2829    return super()
-0000ef10: 2e6e 6578 7428 290d 0a0d 0a20 2020 2023  .next()....    #
-0000ef20: 2066 6f72 2052 5043 0d0a 2020 2020 6465   for RPC..    de
-0000ef30: 6620 7368 7574 646f 776e 2873 656c 6629  f shutdown(self)
-0000ef40: 3a0d 0a20 2020 2020 2020 2072 6574 7572  :..        retur
-0000ef50: 6e20 7375 7065 7228 292e 7368 7574 646f  n super().shutdo
-0000ef60: 776e 2829 0d0a 0d0a 2020 2020 2320 666f  wn()....    # fo
-0000ef70: 7220 5250 430d 0a20 2020 2064 6566 2073  r RPC..    def s
-0000ef80: 6574 5f73 6565 6428 7365 6c66 2c20 7365  et_seed(self, se
-0000ef90: 6564 3a20 696e 742c 2073 7461 7469 635f  ed: int, static_
-0000efa0: 7365 6564 3a20 626f 6f6c 203d 2046 616c  seed: bool = Fal
-0000efb0: 7365 2920 2d3e 2069 6e74 3a0d 0a20 2020  se) -> int:..   
-0000efc0: 2020 2020 2072 6574 7572 6e20 7375 7065       return supe
-0000efd0: 7228 292e 7365 745f 7365 6564 2873 6565  r().set_seed(see
-0000efe0: 642c 2073 7461 7469 635f 7365 6564 290d  d, static_seed).
-0000eff0: 0a0d 0a20 2020 2023 2066 6f72 2052 5043  ...    # for RPC
-0000f000: 0d0a 2020 2020 6465 6620 7374 6174 655f  ..    def state_
-0000f010: 6469 6374 2873 656c 6629 202d 3e20 4f72  dict(self) -> Or
-0000f020: 6465 7265 6444 6963 743a 0d0a 2020 2020  deredDict:..    
-0000f030: 2020 2020 7265 7475 726e 2073 7570 6572      return super
-0000f040: 2829 2e73 7461 7465 5f64 6963 7428 290d  ().state_dict().
-0000f050: 0a0d 0a20 2020 2023 2066 6f72 2052 5043  ...    # for RPC
-0000f060: 0d0a 2020 2020 6465 6620 6c6f 6164 5f73  ..    def load_s
-0000f070: 7461 7465 5f64 6963 7428 7365 6c66 2c20  tate_dict(self, 
-0000f080: 7374 6174 655f 6469 6374 3a20 4f72 6465  state_dict: Orde
-0000f090: 7265 6444 6963 7429 202d 3e20 4e6f 6e65  redDict) -> None
-0000f0a0: 3a0d 0a20 2020 2020 2020 2072 6574 7572  :..        retur
-0000f0b0: 6e20 7375 7065 7228 292e 6c6f 6164 5f73  n super().load_s
-0000f0c0: 7461 7465 5f64 6963 7428 7374 6174 655f  tate_dict(state_
-0000f0d0: 6469 6374 290d 0a0d 0a20 2020 2023 2066  dict)....    # f
-0000f0e0: 6f72 2052 5043 0d0a 2020 2020 6465 6620  or RPC..    def 
-0000f0f0: 7570 6461 7465 5f70 6f6c 6963 795f 7765  update_policy_we
-0000f100: 6967 6874 735f 280d 0a20 2020 2020 2020  ights_(..       
-0000f110: 2073 656c 662c 2070 6f6c 6963 795f 7765   self, policy_we
-0000f120: 6967 6874 733a 204f 7074 696f 6e61 6c5b  ights: Optional[
-0000f130: 5465 6e73 6f72 4469 6374 4261 7365 5d20  TensorDictBase] 
-0000f140: 3d20 4e6f 6e65 0d0a 2020 2020 2920 2d3e  = None..    ) ->
-0000f150: 204e 6f6e 653a 0d0a 2020 2020 2020 2020   None:..        
-0000f160: 7375 7065 7228 292e 7570 6461 7465 5f70  super().update_p
-0000f170: 6f6c 6963 795f 7765 6967 6874 735f 2870  olicy_weights_(p
-0000f180: 6f6c 6963 795f 7765 6967 6874 7329 0d0a  olicy_weights)..
-0000f190: 0d0a 2020 2020 4070 726f 7065 7274 790d  ..    @property.
-0000f1a0: 0a20 2020 2064 6566 2066 7261 6d65 735f  .    def frames_
-0000f1b0: 7065 725f 6261 7463 685f 776f 726b 6572  per_batch_worker
-0000f1c0: 2873 656c 6629 3a0d 0a20 2020 2020 2020  (self):..       
-0000f1d0: 2072 6574 7572 6e20 2d28 2d73 656c 662e   return -(-self.
-0000f1e0: 6672 616d 6573 5f70 6572 5f62 6174 6368  frames_per_batch
-0000f1f0: 202f 2f20 7365 6c66 2e6e 756d 5f77 6f72   // self.num_wor
-0000f200: 6b65 7273 290d 0a0d 0a20 2020 2040 7072  kers)....    @pr
-0000f210: 6f70 6572 7479 0d0a 2020 2020 6465 6620  operty..    def 
-0000f220: 5f71 7565 7565 5f6c 656e 2873 656c 6629  _queue_len(self)
-0000f230: 202d 3e20 696e 743a 0d0a 2020 2020 2020   -> int:..      
-0000f240: 2020 7265 7475 726e 2073 656c 662e 6e75    return self.nu
-0000f250: 6d5f 776f 726b 6572 730d 0a0d 0a20 2020  m_workers....   
-0000f260: 2064 6566 2069 7465 7261 746f 7228 7365   def iterator(se
-0000f270: 6c66 2920 2d3e 2049 7465 7261 746f 725b  lf) -> Iterator[
-0000f280: 5465 6e73 6f72 4469 6374 4261 7365 5d3a  TensorDictBase]:
-0000f290: 0d0a 2020 2020 2020 2020 6920 3d20 2d31  ..        i = -1
-0000f2a0: 0d0a 2020 2020 2020 2020 6672 616d 6573  ..        frames
-0000f2b0: 203d 2030 0d0a 2020 2020 2020 2020 6f75   = 0..        ou
-0000f2c0: 745f 7465 6e73 6f72 6469 6374 735f 7368  t_tensordicts_sh
-0000f2d0: 6172 6564 203d 204f 7264 6572 6564 4469  ared = OrderedDi
-0000f2e0: 6374 2829 0d0a 2020 2020 2020 2020 646f  ct()..        do
-0000f2f0: 6e65 7320 3d20 5b46 616c 7365 2066 6f72  nes = [False for
-0000f300: 205f 2069 6e20 7261 6e67 6528 7365 6c66   _ in range(self
-0000f310: 2e6e 756d 5f77 6f72 6b65 7273 295d 0d0a  .num_workers)]..
-0000f320: 2020 2020 2020 2020 776f 726b 6572 735f          workers_
-0000f330: 6672 616d 6573 203d 205b 3020 666f 7220  frames = [0 for 
-0000f340: 5f20 696e 2072 616e 6765 2873 656c 662e  _ in range(self.
-0000f350: 6e75 6d5f 776f 726b 6572 7329 5d0d 0a20  num_workers)].. 
-0000f360: 2020 2020 2020 2073 616d 655f 6465 7669         same_devi
-0000f370: 6365 203d 204e 6f6e 650d 0a20 2020 2020  ce = None..     
-0000f380: 2020 206f 7574 5f62 7566 6665 7220 3d20     out_buffer = 
-0000f390: 4e6f 6e65 0d0a 2020 2020 2020 2020 7768  None..        wh
-0000f3a0: 696c 6520 6e6f 7420 616c 6c28 646f 6e65  ile not all(done
-0000f3b0: 7329 2061 6e64 2066 7261 6d65 7320 3c20  s) and frames < 
-0000f3c0: 7365 6c66 2e74 6f74 616c 5f66 7261 6d65  self.total_frame
-0000f3d0: 733a 0d0a 2020 2020 2020 2020 2020 2020  s:..            
-0000f3e0: 5f63 6865 636b 5f66 6f72 5f66 6175 6c74  _check_for_fault
-0000f3f0: 795f 7072 6f63 6573 7328 7365 6c66 2e70  y_process(self.p
-0000f400: 726f 6373 290d 0a20 2020 2020 2020 2020  rocs)..         
-0000f410: 2020 2069 6620 7365 6c66 2e75 7064 6174     if self.updat
-0000f420: 655f 6174 5f65 6163 685f 6261 7463 683a  e_at_each_batch:
-0000f430: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-0000f440: 2020 7365 6c66 2e75 7064 6174 655f 706f    self.update_po
-0000f450: 6c69 6379 5f77 6569 6768 7473 5f28 290d  licy_weights_().
-0000f460: 0a0d 0a20 2020 2020 2020 2020 2020 2066  ...            f
-0000f470: 6f72 2069 6478 2069 6e20 7261 6e67 6528  or idx in range(
-0000f480: 7365 6c66 2e6e 756d 5f77 6f72 6b65 7273  self.num_workers
-0000f490: 293a 0d0a 2020 2020 2020 2020 2020 2020  ):..            
-0000f4a0: 2020 2020 6966 2066 7261 6d65 7320 3c20      if frames < 
-0000f4b0: 7365 6c66 2e69 6e69 745f 7261 6e64 6f6d  self.init_random
-0000f4c0: 5f66 7261 6d65 733a 0d0a 2020 2020 2020  _frames:..      
-0000f4d0: 2020 2020 2020 2020 2020 2020 2020 6d73                ms
-0000f4e0: 6720 3d20 2263 6f6e 7469 6e75 655f 7261  g = "continue_ra
-0000f4f0: 6e64 6f6d 220d 0a20 2020 2020 2020 2020  ndom"..         
-0000f500: 2020 2020 2020 2065 6c73 653a 0d0a 2020         else:..  
-0000f510: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f520: 2020 6d73 6720 3d20 2263 6f6e 7469 6e75    msg = "continu
-0000f530: 6522 0d0a 2020 2020 2020 2020 2020 2020  e"..            
-0000f540: 2020 2020 7365 6c66 2e70 6970 6573 5b69      self.pipes[i
-0000f550: 6478 5d2e 7365 6e64 2828 4e6f 6e65 2c20  dx].send((None, 
-0000f560: 6d73 6729 290d 0a0d 0a20 2020 2020 2020  msg))....       
-0000f570: 2020 2020 2069 202b 3d20 310d 0a20 2020       i += 1..   
-0000f580: 2020 2020 2020 2020 206d 6178 5f74 7261           max_tra
-0000f590: 6a5f 6964 7820 3d20 4e6f 6e65 0d0a 2020  j_idx = None..  
-0000f5a0: 2020 2020 2020 2020 2020 666f 7220 5f20            for _ 
-0000f5b0: 696e 2072 616e 6765 2873 656c 662e 6e75  in range(self.nu
-0000f5c0: 6d5f 776f 726b 6572 7329 3a0d 0a20 2020  m_workers):..   
-0000f5d0: 2020 2020 2020 2020 2020 2020 206e 6577               new
-0000f5e0: 5f64 6174 612c 206a 203d 2073 656c 662e  _data, j = self.
-0000f5f0: 7175 6575 655f 6f75 742e 6765 7428 290d  queue_out.get().
-0000f600: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000f610: 2069 6620 6a20 3d3d 2030 3a0d 0a20 2020   if j == 0:..   
-0000f620: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f630: 2064 6174 612c 2069 6478 203d 206e 6577   data, idx = new
-0000f640: 5f64 6174 610d 0a20 2020 2020 2020 2020  _data..         
-0000f650: 2020 2020 2020 2020 2020 206f 7574 5f74             out_t
-0000f660: 656e 736f 7264 6963 7473 5f73 6861 7265  ensordicts_share
-0000f670: 645b 6964 785d 203d 2064 6174 610d 0a20  d[idx] = data.. 
-0000f680: 2020 2020 2020 2020 2020 2020 2020 2065                 e
-0000f690: 6c73 653a 0d0a 2020 2020 2020 2020 2020  lse:..          
-0000f6a0: 2020 2020 2020 2020 2020 6964 7820 3d20            idx = 
-0000f6b0: 6e65 775f 6461 7461 0d0a 2020 2020 2020  new_data..      
-0000f6c0: 2020 2020 2020 2020 2020 776f 726b 6572            worker
-0000f6d0: 735f 6672 616d 6573 5b69 6478 5d20 3d20  s_frames[idx] = 
-0000f6e0: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
-0000f6f0: 2020 2020 2020 2077 6f72 6b65 7273 5f66         workers_f
-0000f700: 7261 6d65 735b 6964 785d 202b 206f 7574  rames[idx] + out
-0000f710: 5f74 656e 736f 7264 6963 7473 5f73 6861  _tensordicts_sha
-0000f720: 7265 645b 6964 785d 2e6e 756d 656c 2829  red[idx].numel()
-0000f730: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-0000f740: 2020 290d 0a0d 0a20 2020 2020 2020 2020    )....         
-0000f750: 2020 2020 2020 2069 6620 776f 726b 6572         if worker
-0000f760: 735f 6672 616d 6573 5b69 6478 5d20 3e3d  s_frames[idx] >=
-0000f770: 2073 656c 662e 746f 7461 6c5f 6672 616d   self.total_fram
-0000f780: 6573 3a0d 0a20 2020 2020 2020 2020 2020  es:..           
-0000f790: 2020 2020 2020 2020 2064 6f6e 6573 5b69           dones[i
-0000f7a0: 6478 5d20 3d20 5472 7565 0d0a 2020 2020  dx] = True..    
-0000f7b0: 2020 2020 2020 2020 2320 7765 2068 6176          # we hav
-0000f7c0: 6520 746f 2063 6f72 7265 6374 2074 6865  e to correct the
-0000f7d0: 2074 7261 6a5f 6964 7320 746f 206d 616b   traj_ids to mak
-0000f7e0: 6520 7375 7265 2074 6861 7420 7468 6579  e sure that they
-0000f7f0: 2064 6f6e 2774 206f 7665 726c 6170 0d0a   don't overlap..
-0000f800: 2020 2020 2020 2020 2020 2020 666f 7220              for 
-0000f810: 6964 7820 696e 2072 616e 6765 2873 656c  idx in range(sel
-0000f820: 662e 6e75 6d5f 776f 726b 6572 7329 3a0d  f.num_workers):.
-0000f830: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000f840: 2074 7261 6a5f 6964 7320 3d20 6f75 745f   traj_ids = out_
-0000f850: 7465 6e73 6f72 6469 6374 735f 7368 6172  tensordicts_shar
-0000f860: 6564 5b69 6478 5d2e 6765 7428 2822 636f  ed[idx].get(("co
-0000f870: 6c6c 6563 746f 7222 2c20 2274 7261 6a5f  llector", "traj_
-0000f880: 6964 7322 2929 0d0a 2020 2020 2020 2020  ids"))..        
-0000f890: 2020 2020 2020 2020 6966 206d 6178 5f74          if max_t
-0000f8a0: 7261 6a5f 6964 7820 6973 206e 6f74 204e  raj_idx is not N
-0000f8b0: 6f6e 653a 0d0a 2020 2020 2020 2020 2020  one:..          
-0000f8c0: 2020 2020 2020 2020 2020 7472 616a 5f69            traj_i
-0000f8d0: 6473 202b 3d20 6d61 785f 7472 616a 5f69  ds += max_traj_i
-0000f8e0: 6478 0d0a 2020 2020 2020 2020 2020 2020  dx..            
-0000f8f0: 2020 2020 2020 2020 2320 6f75 745f 7465          # out_te
-0000f900: 6e73 6f72 6469 6374 735f 7368 6172 6564  nsordicts_shared
-0000f910: 5b69 6478 5d2e 7365 7428 2274 7261 6a5f  [idx].set("traj_
-0000f920: 6964 7322 2c20 7472 616a 5f69 6473 290d  ids", traj_ids).
-0000f930: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000f940: 206d 6178 5f74 7261 6a5f 6964 7820 3d20   max_traj_idx = 
-0000f950: 7472 616a 5f69 6473 2e6d 6178 2829 2e69  traj_ids.max().i
-0000f960: 7465 6d28 2920 2b20 310d 0a20 2020 2020  tem() + 1..     
-0000f970: 2020 2020 2020 2020 2020 2023 206f 7574             # out
-0000f980: 203d 206f 7574 5f74 656e 736f 7264 6963   = out_tensordic
-0000f990: 7473 5f73 6861 7265 645b 6964 785d 0d0a  ts_shared[idx]..
-0000f9a0: 2020 2020 2020 2020 2020 2020 6966 2073              if s
-0000f9b0: 616d 655f 6465 7669 6365 2069 7320 4e6f  ame_device is No
-0000f9c0: 6e65 3a0d 0a20 2020 2020 2020 2020 2020  ne:..           
-0000f9d0: 2020 2020 2070 7265 765f 6465 7669 6365       prev_device
-0000f9e0: 203d 204e 6f6e 650d 0a20 2020 2020 2020   = None..       
-0000f9f0: 2020 2020 2020 2020 2073 616d 655f 6465           same_de
-0000fa00: 7669 6365 203d 2054 7275 650d 0a20 2020  vice = True..   
-0000fa10: 2020 2020 2020 2020 2020 2020 2066 6f72               for
-0000fa20: 2069 7465 6d20 696e 206f 7574 5f74 656e   item in out_ten
-0000fa30: 736f 7264 6963 7473 5f73 6861 7265 642e  sordicts_shared.
-0000fa40: 7661 6c75 6573 2829 3a0d 0a20 2020 2020  values():..     
-0000fa50: 2020 2020 2020 2020 2020 2020 2020 2069                 i
-0000fa60: 6620 7072 6576 5f64 6576 6963 6520 6973  f prev_device is
-0000fa70: 204e 6f6e 653a 0d0a 2020 2020 2020 2020   None:..        
-0000fa80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fa90: 7072 6576 5f64 6576 6963 6520 3d20 6974  prev_device = it
-0000faa0: 656d 2e64 6576 6963 650d 0a20 2020 2020  em.device..     
-0000fab0: 2020 2020 2020 2020 2020 2020 2020 2065                 e
-0000fac0: 6c73 653a 0d0a 2020 2020 2020 2020 2020  lse:..          
-0000fad0: 2020 2020 2020 2020 2020 2020 2020 7361                sa
-0000fae0: 6d65 5f64 6576 6963 6520 3d20 7361 6d65  me_device = same
-0000faf0: 5f64 6576 6963 6520 616e 6420 2869 7465  _device and (ite
-0000fb00: 6d2e 6465 7669 6365 203d 3d20 7072 6576  m.device == prev
-0000fb10: 5f64 6576 6963 6529 0d0a 2020 2020 2020  _device)..      
-0000fb20: 2020 2020 2020 6966 2073 616d 655f 6465        if same_de
-0000fb30: 7669 6365 3a0d 0a20 2020 2020 2020 2020  vice:..         
-0000fb40: 2020 2020 2020 206f 7574 5f62 7566 6665         out_buffe
-0000fb50: 7220 3d20 746f 7263 682e 6361 7428 0d0a  r = torch.cat(..
-0000fb60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fb70: 2020 2020 6c69 7374 286f 7574 5f74 656e      list(out_ten
-0000fb80: 736f 7264 6963 7473 5f73 6861 7265 642e  sordicts_shared.
-0000fb90: 7661 6c75 6573 2829 292c 2030 2c20 6f75  values()), 0, ou
-0000fba0: 743d 6f75 745f 6275 6666 6572 0d0a 2020  t=out_buffer..  
-0000fbb0: 2020 2020 2020 2020 2020 2020 2020 290d                ).
-0000fbc0: 0a20 2020 2020 2020 2020 2020 2065 6c73  .            els
-0000fbd0: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
-0000fbe0: 2020 2020 6f75 745f 6275 6666 6572 203d      out_buffer =
-0000fbf0: 2074 6f72 6368 2e63 6174 280d 0a20 2020   torch.cat(..   
-0000fc00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fc10: 205b 6974 656d 2e63 7075 2829 2066 6f72   [item.cpu() for
-0000fc20: 2069 7465 6d20 696e 206f 7574 5f74 656e   item in out_ten
-0000fc30: 736f 7264 6963 7473 5f73 6861 7265 642e  sordicts_shared.
-0000fc40: 7661 6c75 6573 2829 5d2c 0d0a 2020 2020  values()],..    
-0000fc50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fc60: 302c 0d0a 2020 2020 2020 2020 2020 2020  0,..            
-0000fc70: 2020 2020 2020 2020 6f75 743d 6f75 745f          out=out_
-0000fc80: 6275 6666 6572 2c0d 0a20 2020 2020 2020  buffer,..       
-0000fc90: 2020 2020 2020 2020 2029 0d0a 0d0a 2020           )....  
-0000fca0: 2020 2020 2020 2020 2020 6966 2073 656c            if sel
-0000fcb0: 662e 7370 6c69 745f 7472 616a 733a 0d0a  f.split_trajs:..
-0000fcc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fcd0: 6f75 7420 3d20 7370 6c69 745f 7472 616a  out = split_traj
-0000fce0: 6563 746f 7269 6573 286f 7574 5f62 7566  ectories(out_buf
-0000fcf0: 6665 722c 2070 7265 6669 783d 2263 6f6c  fer, prefix="col
-0000fd00: 6c65 6374 6f72 2229 0d0a 2020 2020 2020  lector")..      
-0000fd10: 2020 2020 2020 2020 2020 6672 616d 6573            frames
-0000fd20: 202b 3d20 6f75 742e 6765 7428 2822 636f   += out.get(("co
-0000fd30: 6c6c 6563 746f 7222 2c20 226d 6173 6b22  llector", "mask"
-0000fd40: 2929 2e73 756d 2829 2e69 7465 6d28 290d  )).sum().item().
-0000fd50: 0a20 2020 2020 2020 2020 2020 2065 6c73  .            els
-0000fd60: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
-0000fd70: 2020 2020 6f75 7420 3d20 6f75 745f 6275      out = out_bu
-0000fd80: 6666 6572 2e63 6c6f 6e65 2829 0d0a 2020  ffer.clone()..  
-0000fd90: 2020 2020 2020 2020 2020 2020 2020 6672                fr
-0000fda0: 616d 6573 202b 3d20 7072 6f64 286f 7574  ames += prod(out
-0000fdb0: 2e73 6861 7065 290d 0a20 2020 2020 2020  .shape)..       
-0000fdc0: 2020 2020 2069 6620 7365 6c66 2e70 6f73       if self.pos
-0000fdd0: 7470 726f 6373 3a0d 0a20 2020 2020 2020  tprocs:..       
-0000fde0: 2020 2020 2020 2020 2073 656c 662e 706f           self.po
-0000fdf0: 7374 7072 6f63 7320 3d20 7365 6c66 2e70  stprocs = self.p
-0000fe00: 6f73 7470 726f 6373 2e74 6f28 6f75 742e  ostprocs.to(out.
-0000fe10: 6465 7669 6365 290d 0a20 2020 2020 2020  device)..       
-0000fe20: 2020 2020 2020 2020 206f 7574 203d 2073           out = s
-0000fe30: 656c 662e 706f 7374 7072 6f63 7328 6f75  elf.postprocs(ou
-0000fe40: 7429 0d0a 2020 2020 2020 2020 2020 2020  t)..            
-0000fe50: 6966 2073 656c 662e 5f65 7863 6c75 6465  if self._exclude
-0000fe60: 5f70 7269 7661 7465 5f6b 6579 733a 0d0a  _private_keys:..
-0000fe70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fe80: 6578 636c 7564 6564 5f6b 6579 7320 3d20  excluded_keys = 
-0000fe90: 5b6b 6579 2066 6f72 206b 6579 2069 6e20  [key for key in 
-0000fea0: 6f75 742e 6b65 7973 2829 2069 6620 6b65  out.keys() if ke
-0000feb0: 792e 7374 6172 7473 7769 7468 2822 5f22  y.startswith("_"
-0000fec0: 295d 0d0a 2020 2020 2020 2020 2020 2020  )]..            
-0000fed0: 2020 2020 6966 2065 7863 6c75 6465 645f      if excluded_
-0000fee0: 6b65 7973 3a0d 0a20 2020 2020 2020 2020  keys:..         
-0000fef0: 2020 2020 2020 2020 2020 206f 7574 203d             out =
-0000ff00: 206f 7574 2e65 7863 6c75 6465 282a 6578   out.exclude(*ex
-0000ff10: 636c 7564 6564 5f6b 6579 7329 0d0a 2020  cluded_keys)..  
-0000ff20: 2020 2020 2020 2020 2020 7969 656c 6420            yield 
-0000ff30: 6f75 740d 0a20 2020 2020 2020 2020 2020  out..           
-0000ff40: 2064 656c 206f 7574 0d0a 0d0a 2020 2020   del out....    
-0000ff50: 2020 2020 6465 6c20 6f75 745f 7465 6e73      del out_tens
-0000ff60: 6f72 6469 6374 735f 7368 6172 6564 0d0a  ordicts_shared..
-0000ff70: 2020 2020 2020 2020 2320 5765 2073 6861          # We sha
-0000ff80: 6c6c 206e 6f74 2063 616c 6c20 7368 7574  ll not call shut
-0000ff90: 646f 776e 206a 7573 7420 7965 7420 6173  down just yet as
-0000ffa0: 2075 7365 7220 6d61 7920 7761 6e74 2074   user may want t
-0000ffb0: 6f20 7265 7472 6965 7665 2073 7461 7465  o retrieve state
-0000ffc0: 5f64 6963 740d 0a20 2020 2020 2020 2023  _dict..        #
-0000ffd0: 2073 656c 662e 5f73 6875 7464 6f77 6e5f   self._shutdown_
-0000ffe0: 6d61 696e 2829 0d0a 0d0a 0d0a 4061 6363  main()......@acc
-0000fff0: 6570 745f 7265 6d6f 7465 5f72 7265 665f  ept_remote_rref_
-00010000: 7564 665f 696e 766f 6361 7469 6f6e 0d0a  udf_invocation..
-00010010: 636c 6173 7320 4d75 6c74 6961 5379 6e63  class MultiaSync
-00010020: 4461 7461 436f 6c6c 6563 746f 7228 5f4d  DataCollector(_M
-00010030: 756c 7469 4461 7461 436f 6c6c 6563 746f  ultiDataCollecto
-00010040: 7229 3a0d 0a20 2020 2022 2222 5275 6e73  r):..    """Runs
-00010050: 2061 2067 6976 656e 206e 756d 6265 7220   a given number 
-00010060: 6f66 2044 6174 6143 6f6c 6c65 6374 6f72  of DataCollector
-00010070: 7320 6f6e 2073 6570 6172 6174 6520 7072  s on separate pr
-00010080: 6f63 6573 7365 7320 6173 796e 6368 726f  ocesses asynchro
-00010090: 6e6f 7573 6c79 2e0d 0a0d 0a20 2020 202e  nously.....    .
-000100a0: 2e20 6161 6669 673a 3a0d 0a0d 0a0d 0a20  . aafig::...... 
-000100b0: 2020 2020 2020 2020 2020 202b 2d2d 2d2d             +----
-000100c0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-000100d0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-000100e0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-000100f0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-00010100: 2d2d 2b0d 0a20 2020 2020 2020 2020 2020  --+..           
-00010110: 207c 2020 2020 2020 2020 2020 2022 4d75   |           "Mu
-00010120: 6c74 6943 6f6e 6375 7272 656e 7443 6f6c  ltiConcurrentCol
-00010130: 6c65 6374 6f72 2220 2020 2020 2020 2020  lector"         
-00010140: 2020 2020 2020 207c 2020 2020 2020 2020         |        
-00010150: 2020 2020 2020 2020 7c0d 0a20 2020 2020          |..     
-00010160: 2020 2020 2020 207c 7e7e 7e7e 7e7e 7e7e         |~~~~~~~~
-00010170: 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e  ~~~~~~~~~~~~~~~~
-00010180: 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e  ~~~~~~~~~~~~~~~~
-00010190: 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7c 2020  ~~~~~~~~~~~~~|  
-000101a0: 2020 2020 2020 2020 2020 2020 2020 7c0d                |.
-000101b0: 0a20 2020 2020 2020 2020 2020 207c 2020  .            |  
-000101c0: 2243 6f6c 6c65 6374 6f72 2031 2220 207c  "Collector 1"  |
-000101d0: 2020 2243 6f6c 6c65 6374 6f72 2032 2220    "Collector 2" 
-000101e0: 207c 2020 2243 6f6c 6c65 6374 6f72 2033   |  "Collector 3
-000101f0: 2220 207c 2020 2020 2022 4d61 696e 2220  "  |     "Main" 
-00010200: 2020 2020 7c0d 0a20 2020 2020 2020 2020      |..         
-00010210: 2020 207c 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e     |~~~~~~~~~~~~
-00010220: 7e7e 7e7e 7e7c 7e7e 7e7e 7e7e 7e7e 7e7e  ~~~~~|~~~~~~~~~~
-00010230: 7e7e 7e7e 7e7e 7e7c 7e7e 7e7e 7e7e 7e7e  ~~~~~~~|~~~~~~~~
-00010240: 7e7e 7e7e 7e7e 7e7e 7e7c 7e7e 7e7e 7e7e  ~~~~~~~~~|~~~~~~
-00010250: 7e7e 7e7e 7e7e 7e7e 7e7e 7c0d 0a20 2020  ~~~~~~~~~~|..   
-00010260: 2020 2020 2020 2020 207c 2022 656e 7631           | "env1
-00010270: 2220 7c20 2265 6e76 3222 207c 2022 656e  " | "env2" | "en
-00010280: 7633 2220 7c20 2265 6e76 3422 207c 2022  v3" | "env4" | "
-00010290: 656e 7635 2220 7c20 2265 6e76 3622 207c  env5" | "env6" |
-000102a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000102b0: 7c0d 0a20 2020 2020 2020 2020 2020 207c  |..            |
-000102c0: 7e7e 7e7e 7e7e 7e7e 7c7e 7e7e 7e7e 7e7e  ~~~~~~~~|~~~~~~~
-000102d0: 7e7c 7e7e 7e7e 7e7e 7e7e 7c7e 7e7e 7e7e  ~|~~~~~~~~|~~~~~
-000102e0: 7e7e 7e7c 7e7e 7e7e 7e7e 7e7e 7c7e 7e7e  ~~~|~~~~~~~~|~~~
-000102f0: 7e7e 7e7e 7e7c 7e7e 7e7e 7e7e 7e7e 7e7e  ~~~~~|~~~~~~~~~~
-00010300: 7e7e 7e7e 7e7e 7c0d 0a20 2020 2020 2020  ~~~~~~|..       
-00010310: 2020 2020 207c 2272 6573 6574 2220 7c22       |"reset" |"
-00010320: 7265 7365 7422 207c 2272 6573 6574 2220  reset" |"reset" 
-00010330: 7c22 7265 7365 7422 207c 2272 6573 6574  |"reset" |"reset
-00010340: 2220 7c22 7265 7365 7422 207c 2020 2020  " |"reset" |    
-00010350: 2020 2020 2020 2020 2020 2020 7c0d 0a20              |.. 
-00010360: 2020 2020 2020 2020 2020 207c 2020 2020             |    
-00010370: 2020 2020 7c20 2020 2020 2020 207c 2020      |        |  
-00010380: 2020 2020 2020 7c20 2020 2020 2020 207c        |        |
-00010390: 2020 2020 2020 2020 7c20 2020 2020 2020          |       
-000103a0: 207c 2020 2020 2020 2020 2020 2020 2020   |              
-000103b0: 2020 7c0d 0a20 2020 2020 2020 2020 2020    |..           
-000103c0: 207c 2020 2020 2020 2022 6163 746f 7222   |       "actor"
-000103d0: 2020 207c 2020 2020 2020 2020 7c20 2020     |        |   
-000103e0: 2020 2020 207c 2020 2020 2020 2022 6163       |       "ac
-000103f0: 746f 7222 2020 207c 2020 2020 2020 2020  tor"   |        
-00010400: 2020 2020 2020 2020 7c0d 0a20 2020 2020          |..     
-00010410: 2020 2020 2020 207c 2020 2020 2020 2020         |        
-00010420: 2020 2020 2020 2020 207c 2020 2020 2020           |      
-00010430: 2020 7c20 2020 2020 2020 207c 2020 2020    |        |    
-00010440: 2020 2020 2020 2020 2020 2020 207c 2020               |  
-00010450: 2020 2020 2020 2020 2020 2020 2020 7c0d                |.
-00010460: 0a20 2020 2020 2020 2020 2020 207c 2022  .            | "
-00010470: 7374 6570 2220 7c20 2273 7465 7022 207c  step" | "step" |
-00010480: 2020 2020 2020 2022 6163 746f 7222 2020         "actor"  
-00010490: 207c 2020 2020 2020 2020 2020 2020 2020   |              
-000104a0: 2020 207c 2020 2020 2020 2020 2020 2020     |            
-000104b0: 2020 2020 7c0d 0a20 2020 2020 2020 2020      |..         
-000104c0: 2020 207c 2020 2020 2020 2020 7c20 2020     |        |   
-000104d0: 2020 2020 207c 2020 2020 2020 2020 2020       |          
-000104e0: 2020 2020 2020 207c 2020 2020 2020 2020         |        
-000104f0: 2020 2020 2020 2020 207c 2020 2020 2020           |      
-00010500: 2020 2020 2020 2020 2020 7c0d 0a20 2020            |..   
-00010510: 2020 2020 2020 2020 207c 2020 2020 2020           |      
-00010520: 2020 7c20 2020 2020 2020 207c 2020 2020    |        |    
-00010530: 2020 2020 2020 2020 2020 2020 207c 2022               | "
-00010540: 7374 6570 2220 7c20 2273 7465 7022 207c  step" | "step" |
-00010550: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010560: 7c0d 0a20 2020 2020 2020 2020 2020 207c  |..            |
-00010570: 2020 2020 2020 2020 7c20 2020 2020 2020          |       
-00010580: 207c 2020 2020 2020 2020 2020 2020 2020   |              
-00010590: 2020 207c 2020 2020 2020 2020 7c20 2020     |        |   
-000105a0: 2020 2020 207c 2020 2020 2020 2020 2020       |          
-000105b0: 2020 2020 2020 7c0d 0a20 2020 2020 2020        |..       
-000105c0: 2020 2020 207c 2020 2020 2020 2022 6163       |       "ac
-000105d0: 746f 7220 2020 207c 2022 7374 6570 2220  tor    | "step" 
-000105e0: 7c20 2273 7465 7022 207c 2020 2020 2020  | "step" |      
-000105f0: 2022 6163 746f 7222 2020 207c 2020 2020   "actor"   |    
-00010600: 2020 2020 2020 2020 2020 2020 7c0d 0a20              |.. 
-00010610: 2020 2020 2020 2020 2020 207c 2020 2020             |    
-00010620: 2020 2020 2020 2020 2020 2020 207c 2020               |  
-00010630: 2020 2020 2020 7c20 2020 2020 2020 207c        |        |
-00010640: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010650: 207c 2020 2020 2020 2020 2020 2020 2020   |              
-00010660: 2020 7c0d 0a20 2020 2020 2020 2020 2020    |..           
-00010670: 207c 2022 7969 656c 6420 6261 7463 6820   | "yield batch 
-00010680: 3122 207c 2020 2020 2020 2022 6163 746f  1" |       "acto
-00010690: 7222 2020 207c 2020 2020 2020 2020 2020  r"   |          
-000106a0: 2020 2020 2020 207c 2263 6f6c 6c65 6374         |"collect
-000106b0: 2c20 7472 6169 6e22 7c0d 0a20 2020 2020  , train"|..     
-000106c0: 2020 2020 2020 207c 2020 2020 2020 2020         |        
-000106d0: 2020 2020 2020 2020 207c 2020 2020 2020           |      
-000106e0: 2020 2020 2020 2020 2020 207c 2020 2020             |    
-000106f0: 2020 2020 2020 2020 2020 2020 207c 2020               |  
-00010700: 2020 2020 2020 2020 2020 2020 2020 7c0d                |.
-00010710: 0a20 2020 2020 2020 2020 2020 207c 2022  .            | "
-00010720: 7374 6570 2220 7c20 2273 7465 7022 207c  step" | "step" |
-00010730: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010740: 207c 2022 7969 656c 6420 6261 7463 6820   | "yield batch 
-00010750: 3222 207c 2263 6f6c 6c65 6374 2c20 7472  2" |"collect, tr
-00010760: 6169 6e22 7c0d 0a20 2020 2020 2020 2020  ain"|..         
-00010770: 2020 207c 2020 2020 2020 2020 7c20 2020     |        |   
-00010780: 2020 2020 207c 2020 2020 2020 2020 2020       |          
-00010790: 2020 2020 2020 207c 2020 2020 2020 2020         |        
-000107a0: 2020 2020 2020 2020 207c 2020 2020 2020           |      
-000107b0: 2020 2020 2020 2020 2020 7c0d 0a20 2020            |..   
-000107c0: 2020 2020 2020 2020 207c 2020 2020 2020           |      
-000107d0: 2020 7c20 2020 2020 2020 207c 2022 7969    |        | "yi
-000107e0: 656c 6420 6261 7463 6820 3322 207c 2020  eld batch 3" |  
-000107f0: 2020 2020 2020 2020 2020 2020 2020 207c                 |
-00010800: 2263 6f6c 6c65 6374 2c20 7472 6169 6e22  "collect, train"
-00010810: 7c0d 0a20 2020 2020 2020 2020 2020 207c  |..            |
-00010820: 2020 2020 2020 2020 7c20 2020 2020 2020          |       
-00010830: 207c 2020 2020 2020 2020 2020 2020 2020   |              
-00010840: 2020 207c 2020 2020 2020 2020 2020 2020     |            
-00010850: 2020 2020 207c 2020 2020 2020 2020 2020       |          
-00010860: 2020 2020 2020 7c0d 0a20 2020 2020 2020        |..       
-00010870: 2020 2020 202b 2d2d 2d2d 2d2d 2d2d 2d2d       +----------
-00010880: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-00010890: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-000108a0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
-000108b0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2b0d 0a0d  ------------+...
-000108c0: 0a20 2020 2045 6e76 6972 6f6e 6d65 6e74  .    Environment
-000108d0: 2074 7970 6573 2063 616e 2062 6520 6964   types can be id
-000108e0: 656e 7469 6361 6c20 6f72 2064 6966 6665  entical or diffe
-000108f0: 7265 6e74 2e0d 0a0d 0a20 2020 2054 6865  rent.....    The
-00010900: 2063 6f6c 6c65 6374 696f 6e20 6b65 6570   collection keep
-00010910: 7320 6f6e 206f 6363 7572 696e 6720 6f6e  s on occuring on
-00010920: 2061 6c6c 2070 726f 6365 7373 6573 2065   all processes e
-00010930: 7665 6e20 6265 7477 6565 6e20 7468 6520  ven between the 
-00010940: 7469 6d65 0d0a 2020 2020 7468 6520 6261  time..    the ba
-00010950: 7463 6820 6f66 2072 6f6c 6c6f 7574 7320  tch of rollouts 
-00010960: 6973 2063 6f6c 6c65 6374 6564 2061 6e64  is collected and
-00010970: 2074 6865 206e 6578 7420 6361 6c6c 2074   the next call t
-00010980: 6f20 7468 6520 6974 6572 6174 6f72 2e0d  o the iterator..
-00010990: 0a20 2020 2054 6869 7320 636c 6173 7320  .    This class 
-000109a0: 6361 6e20 6265 2073 6166 656c 7920 7573  can be safely us
-000109b0: 6564 2077 6974 6820 6f66 666c 696e 6520  ed with offline 
-000109c0: 524c 2061 6c67 6f72 6974 686d 732e 0d0a  RL algorithms...
-000109d0: 0d0a 2020 2020 4578 616d 706c 6573 3a0d  ..    Examples:.
-000109e0: 0a20 2020 2020 2020 203e 3e3e 2066 726f  .        >>> fro
-000109f0: 6d20 746f 7263 6872 6c2e 656e 7673 2e6c  m torchrl.envs.l
-00010a00: 6962 732e 6779 6d20 696d 706f 7274 2047  ibs.gym import G
-00010a10: 796d 456e 760d 0a20 2020 2020 2020 203e  ymEnv..        >
-00010a20: 3e3e 2066 726f 6d20 7465 6e73 6f72 6469  >> from tensordi
-00010a30: 6374 2e6e 6e20 696d 706f 7274 2054 656e  ct.nn import Ten
-00010a40: 736f 7244 6963 744d 6f64 756c 650d 0a20  sorDictModule.. 
-00010a50: 2020 2020 2020 203e 3e3e 2066 726f 6d20         >>> from 
-00010a60: 746f 7263 6820 696d 706f 7274 206e 6e0d  torch import nn.
-00010a70: 0a20 2020 2020 2020 203e 3e3e 2065 6e76  .        >>> env
-00010a80: 5f6d 616b 6572 203d 206c 616d 6264 613a  _maker = lambda:
-00010a90: 2047 796d 456e 7628 2250 656e 6475 6c75   GymEnv("Pendulu
-00010aa0: 6d2d 7631 222c 2064 6576 6963 653d 2263  m-v1", device="c
-00010ab0: 7075 2229 0d0a 2020 2020 2020 2020 3e3e  pu")..        >>
-00010ac0: 3e20 706f 6c69 6379 203d 2054 656e 736f  > policy = Tenso
-00010ad0: 7244 6963 744d 6f64 756c 6528 6e6e 2e4c  rDictModule(nn.L
-00010ae0: 696e 6561 7228 332c 2031 292c 2069 6e5f  inear(3, 1), in_
-00010af0: 6b65 7973 3d5b 226f 6273 6572 7661 7469  keys=["observati
-00010b00: 6f6e 225d 2c20 6f75 745f 6b65 7973 3d5b  on"], out_keys=[
-00010b10: 2261 6374 696f 6e22 5d29 0d0a 2020 2020  "action"])..    
-00010b20: 2020 2020 3e3e 3e20 636f 6c6c 6563 746f      >>> collecto
-00010b30: 7220 3d20 4d75 6c74 6961 5379 6e63 4461  r = MultiaSyncDa
-00010b40: 7461 436f 6c6c 6563 746f 7228 0d0a 2020  taCollector(..  
-00010b50: 2020 2020 2020 2e2e 2e20 2020 2020 6372        ...     cr
-00010b60: 6561 7465 5f65 6e76 5f66 6e3d 5b65 6e76  eate_env_fn=[env
-00010b70: 5f6d 616b 6572 2c20 656e 765f 6d61 6b65  _maker, env_make
-00010b80: 725d 2c0d 0a20 2020 2020 2020 202e 2e2e  r],..        ...
-00010b90: 2020 2020 2070 6f6c 6963 793d 706f 6c69       policy=poli
-00010ba0: 6379 2c0d 0a20 2020 2020 2020 202e 2e2e  cy,..        ...
-00010bb0: 2020 2020 2074 6f74 616c 5f66 7261 6d65       total_frame
-00010bc0: 733d 3230 3030 2c0d 0a20 2020 2020 2020  s=2000,..       
-00010bd0: 202e 2e2e 2020 2020 206d 6178 5f66 7261   ...     max_fra
-00010be0: 6d65 735f 7065 725f 7472 616a 3d35 302c  mes_per_traj=50,
-00010bf0: 0d0a 2020 2020 2020 2020 2e2e 2e20 2020  ..        ...   
-00010c00: 2020 6672 616d 6573 5f70 6572 5f62 6174    frames_per_bat
-00010c10: 6368 3d32 3030 2c0d 0a20 2020 2020 2020  ch=200,..       
-00010c20: 202e 2e2e 2020 2020 2069 6e69 745f 7261   ...     init_ra
-00010c30: 6e64 6f6d 5f66 7261 6d65 733d 2d31 2c0d  ndom_frames=-1,.
-00010c40: 0a20 2020 2020 2020 202e 2e2e 2020 2020  .        ...    
-00010c50: 2072 6573 6574 5f61 745f 6561 6368 5f69   reset_at_each_i
-00010c60: 7465 723d 4661 6c73 652c 0d0a 2020 2020  ter=False,..    
-00010c70: 2020 2020 2e2e 2e20 2020 2020 6465 7669      ...     devi
-00010c80: 6365 733d 2263 7075 222c 0d0a 2020 2020  ces="cpu",..    
-00010c90: 2020 2020 2e2e 2e20 2020 2020 7374 6f72      ...     stor
-00010ca0: 696e 675f 6465 7669 6365 733d 2263 7075  ing_devices="cpu
-00010cb0: 222c 0d0a 2020 2020 2020 2020 2e2e 2e20  ",..        ... 
-00010cc0: 290d 0a20 2020 2020 2020 203e 3e3e 2066  )..        >>> f
-00010cd0: 6f72 2069 2c20 6461 7461 2069 6e20 656e  or i, data in en
-00010ce0: 756d 6572 6174 6528 636f 6c6c 6563 746f  umerate(collecto
-00010cf0: 7229 3a0d 0a20 2020 2020 2020 202e 2e2e  r):..        ...
-00010d00: 2020 2020 2069 6620 6920 3d3d 2032 3a0d       if i == 2:.
-00010d10: 0a20 2020 2020 2020 202e 2e2e 2020 2020  .        ...    
-00010d20: 2020 2020 2070 7269 6e74 2864 6174 6129       print(data)
-00010d30: 0d0a 2020 2020 2020 2020 2e2e 2e20 2020  ..        ...   
-00010d40: 2020 2020 2020 6272 6561 6b0d 0a20 2020        break..   
-00010d50: 2020 2020 2054 656e 736f 7244 6963 7428       TensorDict(
-00010d60: 0d0a 2020 2020 2020 2020 2020 2020 6669  ..            fi
-00010d70: 656c 6473 3d7b 0d0a 2020 2020 2020 2020  elds={..        
-00010d80: 2020 2020 2020 2020 6163 7469 6f6e 3a20          action: 
-00010d90: 5465 6e73 6f72 2873 6861 7065 3d74 6f72  Tensor(shape=tor
-00010da0: 6368 2e53 697a 6528 5b34 2c20 3530 2c20  ch.Size([4, 50, 
-00010db0: 315d 292c 2064 6576 6963 653d 6370 752c  1]), device=cpu,
-00010dc0: 2064 7479 7065 3d74 6f72 6368 2e66 6c6f   dtype=torch.flo
-00010dd0: 6174 3332 2c20 6973 5f73 6861 7265 643d  at32, is_shared=
-00010de0: 4661 6c73 6529 2c0d 0a20 2020 2020 2020  False),..       
-00010df0: 2020 2020 2020 2020 2063 6f6c 6c65 6374           collect
-00010e00: 6f72 3a20 5465 6e73 6f72 4469 6374 280d  or: TensorDict(.
-00010e10: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00010e20: 2020 2020 2066 6965 6c64 733d 7b0d 0a20       fields={.. 
-00010e30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010e40: 2020 2020 2020 2073 7465 705f 636f 756e         step_coun
-00010e50: 743a 2054 656e 736f 7228 7368 6170 653d  t: Tensor(shape=
-00010e60: 746f 7263 682e 5369 7a65 285b 342c 2035  torch.Size([4, 5
-00010e70: 305d 292c 2064 6576 6963 653d 6370 752c  0]), device=cpu,
-00010e80: 2064 7479 7065 3d74 6f72 6368 2e69 6e74   dtype=torch.int
-00010e90: 3634 2c20 6973 5f73 6861 7265 643d 4661  64, is_shared=Fa
-00010ea0: 6c73 6529 2c0d 0a20 2020 2020 2020 2020  lse),..         
-00010eb0: 2020 2020 2020 2020 2020 2020 2020 2074                 t
-00010ec0: 7261 6a5f 6964 733a 2054 656e 736f 7228  raj_ids: Tensor(
-00010ed0: 7368 6170 653d 746f 7263 682e 5369 7a65  shape=torch.Size
-00010ee0: 285b 342c 2035 305d 292c 2064 6576 6963  ([4, 50]), devic
-00010ef0: 653d 6370 752c 2064 7479 7065 3d74 6f72  e=cpu, dtype=tor
-00010f00: 6368 2e69 6e74 3634 2c20 6973 5f73 6861  ch.int64, is_sha
-00010f10: 7265 643d 4661 6c73 6529 7d2c 0d0a 2020  red=False)},..  
-00010f20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010f30: 2020 6261 7463 685f 7369 7a65 3d74 6f72    batch_size=tor
-00010f40: 6368 2e53 697a 6528 5b34 2c20 3530 5d29  ch.Size([4, 50])
-00010f50: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
-00010f60: 2020 2020 2020 2064 6576 6963 653d 6370         device=cp
-00010f70: 752c 0d0a 2020 2020 2020 2020 2020 2020  u,..            
-00010f80: 2020 2020 2020 2020 6973 5f73 6861 7265          is_share
-00010f90: 643d 4661 6c73 6529 2c0d 0a20 2020 2020  d=False),..     
-00010fa0: 2020 2020 2020 2020 2020 2064 6f6e 653a             done:
-00010fb0: 2054 656e 736f 7228 7368 6170 653d 746f   Tensor(shape=to
-00010fc0: 7263 682e 5369 7a65 285b 342c 2035 302c  rch.Size([4, 50,
-00010fd0: 2031 5d29 2c20 6465 7669 6365 3d63 7075   1]), device=cpu
-00010fe0: 2c20 6474 7970 653d 746f 7263 682e 626f  , dtype=torch.bo
-00010ff0: 6f6c 2c20 6973 5f73 6861 7265 643d 4661  ol, is_shared=Fa
-00011000: 6c73 6529 2c0d 0a20 2020 2020 2020 2020  lse),..         
-00011010: 2020 2020 2020 206d 6173 6b3a 2054 656e         mask: Ten
-00011020: 736f 7228 7368 6170 653d 746f 7263 682e  sor(shape=torch.
-00011030: 5369 7a65 285b 342c 2035 305d 292c 2064  Size([4, 50]), d
-00011040: 6576 6963 653d 6370 752c 2064 7479 7065  evice=cpu, dtype
-00011050: 3d74 6f72 6368 2e62 6f6f 6c2c 2069 735f  =torch.bool, is_
-00011060: 7368 6172 6564 3d46 616c 7365 292c 0d0a  shared=False),..
-00011070: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011080: 6e65 7874 3a20 5465 6e73 6f72 4469 6374  next: TensorDict
-00011090: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
-000110a0: 2020 2020 2020 2066 6965 6c64 733d 7b0d         fields={.
-000110b0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000110c0: 2020 2020 2020 2020 206f 6273 6572 7661           observa
-000110d0: 7469 6f6e 3a20 5465 6e73 6f72 2873 6861  tion: Tensor(sha
-000110e0: 7065 3d74 6f72 6368 2e53 697a 6528 5b34  pe=torch.Size([4
-000110f0: 2c20 3530 2c20 335d 292c 2064 6576 6963  , 50, 3]), devic
-00011100: 653d 6370 752c 2064 7479 7065 3d74 6f72  e=cpu, dtype=tor
-00011110: 6368 2e66 6c6f 6174 3332 2c20 6973 5f73  ch.float32, is_s
-00011120: 6861 7265 643d 4661 6c73 6529 7d2c 0d0a  hared=False)},..
-00011130: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011140: 2020 2020 6261 7463 685f 7369 7a65 3d74      batch_size=t
-00011150: 6f72 6368 2e53 697a 6528 5b34 2c20 3530  orch.Size([4, 50
-00011160: 5d29 2c0d 0a20 2020 2020 2020 2020 2020  ]),..           
-00011170: 2020 2020 2020 2020 2064 6576 6963 653d           device=
-00011180: 6370 752c 0d0a 2020 2020 2020 2020 2020  cpu,..          
-00011190: 2020 2020 2020 2020 2020 6973 5f73 6861            is_sha
-000111a0: 7265 643d 4661 6c73 6529 2c0d 0a20 2020  red=False),..   
-000111b0: 2020 2020 2020 2020 2020 2020 206f 6273               obs
-000111c0: 6572 7661 7469 6f6e 3a20 5465 6e73 6f72  ervation: Tensor
-000111d0: 2873 6861 7065 3d74 6f72 6368 2e53 697a  (shape=torch.Siz
-000111e0: 6528 5b34 2c20 3530 2c20 335d 292c 2064  e([4, 50, 3]), d
-000111f0: 6576 6963 653d 6370 752c 2064 7479 7065  evice=cpu, dtype
-00011200: 3d74 6f72 6368 2e66 6c6f 6174 3332 2c20  =torch.float32, 
-00011210: 6973 5f73 6861 7265 643d 4661 6c73 6529  is_shared=False)
-00011220: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
-00011230: 2020 2072 6577 6172 643a 2054 656e 736f     reward: Tenso
-00011240: 7228 7368 6170 653d 746f 7263 682e 5369  r(shape=torch.Si
-00011250: 7a65 285b 342c 2035 302c 2031 5d29 2c20  ze([4, 50, 1]), 
-00011260: 6465 7669 6365 3d63 7075 2c20 6474 7970  device=cpu, dtyp
-00011270: 653d 746f 7263 682e 666c 6f61 7433 322c  e=torch.float32,
-00011280: 2069 735f 7368 6172 6564 3d46 616c 7365   is_shared=False
-00011290: 297d 2c0d 0a20 2020 2020 2020 2020 2020  )},..           
-000112a0: 2062 6174 6368 5f73 697a 653d 746f 7263   batch_size=torc
-000112b0: 682e 5369 7a65 285b 342c 2035 305d 292c  h.Size([4, 50]),
-000112c0: 0d0a 2020 2020 2020 2020 2020 2020 6465  ..            de
-000112d0: 7669 6365 3d63 7075 2c0d 0a20 2020 2020  vice=cpu,..     
-000112e0: 2020 2020 2020 2069 735f 7368 6172 6564         is_shared
-000112f0: 3d46 616c 7365 290d 0a20 2020 2020 2020  =False)..       
-00011300: 203e 3e3e 2063 6f6c 6c65 6374 6f72 2e73   >>> collector.s
-00011310: 6875 7464 6f77 6e28 290d 0a20 2020 2020  hutdown()..     
-00011320: 2020 203e 3e3e 2064 656c 2063 6f6c 6c65     >>> del colle
-00011330: 6374 6f72 0d0a 0d0a 2020 2020 2222 220d  ctor....    """.
-00011340: 0a0d 0a20 2020 205f 5f64 6f63 5f5f 202b  ...    __doc__ +
-00011350: 3d20 5f4d 756c 7469 4461 7461 436f 6c6c  = _MultiDataColl
-00011360: 6563 746f 722e 5f5f 646f 635f 5f0d 0a0d  ector.__doc__...
-00011370: 0a20 2020 2064 6566 205f 5f69 6e69 745f  .    def __init_
-00011380: 5f28 7365 6c66 2c20 2a61 7267 732c 202a  _(self, *args, *
-00011390: 2a6b 7761 7267 7329 3a0d 0a20 2020 2020  *kwargs):..     
-000113a0: 2020 2073 7570 6572 2829 2e5f 5f69 6e69     super().__ini
-000113b0: 745f 5f28 2a61 7267 732c 202a 2a6b 7761  t__(*args, **kwa
-000113c0: 7267 7329 0d0a 2020 2020 2020 2020 7365  rgs)..        se
-000113d0: 6c66 2e6f 7574 5f74 656e 736f 7264 6963  lf.out_tensordic
-000113e0: 7473 203d 207b 7d0d 0a20 2020 2020 2020  ts = {}..       
-000113f0: 2073 656c 662e 7275 6e6e 696e 6720 3d20   self.running = 
-00011400: 4661 6c73 650d 0a0d 0a20 2020 2020 2020  False....       
-00011410: 2069 6620 7365 6c66 2e70 6f73 7470 726f   if self.postpro
-00011420: 6373 2069 7320 6e6f 7420 4e6f 6e65 3a0d  cs is not None:.
-00011430: 0a20 2020 2020 2020 2020 2020 2070 6f73  .            pos
-00011440: 7470 726f 6320 3d20 7365 6c66 2e70 6f73  tproc = self.pos
-00011450: 7470 726f 6373 0d0a 2020 2020 2020 2020  tprocs..        
-00011460: 2020 2020 7365 6c66 2e70 6f73 7470 726f      self.postpro
-00011470: 6373 203d 207b 7d0d 0a20 2020 2020 2020  cs = {}..       
-00011480: 2020 2020 2066 6f72 205f 6465 7669 6365       for _device
-00011490: 2069 6e20 7365 6c66 2e73 746f 7269 6e67   in self.storing
-000114a0: 5f64 6576 6963 653a 0d0a 2020 2020 2020  _device:..      
-000114b0: 2020 2020 2020 2020 2020 6966 205f 6465            if _de
-000114c0: 7669 6365 206e 6f74 2069 6e20 7365 6c66  vice not in self
-000114d0: 2e70 6f73 7470 726f 6373 3a0d 0a20 2020  .postprocs:..   
-000114e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000114f0: 2073 656c 662e 706f 7374 7072 6f63 735b   self.postprocs[
-00011500: 5f64 6576 6963 655d 203d 2064 6565 7063  _device] = deepc
-00011510: 6f70 7928 706f 7374 7072 6f63 292e 746f  opy(postproc).to
-00011520: 285f 6465 7669 6365 290d 0a0d 0a20 2020  (_device)....   
-00011530: 2023 2066 6f72 2052 5043 0d0a 2020 2020   # for RPC..    
-00011540: 6465 6620 6e65 7874 2873 656c 6629 3a0d  def next(self):.
-00011550: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00011560: 7375 7065 7228 292e 6e65 7874 2829 0d0a  super().next()..
-00011570: 0d0a 2020 2020 2320 666f 7220 5250 430d  ..    # for RPC.
-00011580: 0a20 2020 2064 6566 2073 6875 7464 6f77  .    def shutdow
-00011590: 6e28 7365 6c66 293a 0d0a 2020 2020 2020  n(self):..      
-000115a0: 2020 7265 7475 726e 2073 7570 6572 2829    return super()
-000115b0: 2e73 6875 7464 6f77 6e28 290d 0a0d 0a20  .shutdown().... 
-000115c0: 2020 2023 2066 6f72 2052 5043 0d0a 2020     # for RPC..  
-000115d0: 2020 6465 6620 7365 745f 7365 6564 2873    def set_seed(s
-000115e0: 656c 662c 2073 6565 643a 2069 6e74 2c20  elf, seed: int, 
-000115f0: 7374 6174 6963 5f73 6565 643a 2062 6f6f  static_seed: boo
-00011600: 6c20 3d20 4661 6c73 6529 202d 3e20 696e  l = False) -> in
-00011610: 743a 0d0a 2020 2020 2020 2020 7265 7475  t:..        retu
-00011620: 726e 2073 7570 6572 2829 2e73 6574 5f73  rn super().set_s
-00011630: 6565 6428 7365 6564 2c20 7374 6174 6963  eed(seed, static
-00011640: 5f73 6565 6429 0d0a 0d0a 2020 2020 2320  _seed)....    # 
-00011650: 666f 7220 5250 430d 0a20 2020 2064 6566  for RPC..    def
-00011660: 2073 7461 7465 5f64 6963 7428 7365 6c66   state_dict(self
-00011670: 2920 2d3e 204f 7264 6572 6564 4469 6374  ) -> OrderedDict
-00011680: 3a0d 0a20 2020 2020 2020 2072 6574 7572  :..        retur
-00011690: 6e20 7375 7065 7228 292e 7374 6174 655f  n super().state_
-000116a0: 6469 6374 2829 0d0a 0d0a 2020 2020 2320  dict()....    # 
-000116b0: 666f 7220 5250 430d 0a20 2020 2064 6566  for RPC..    def
-000116c0: 206c 6f61 645f 7374 6174 655f 6469 6374   load_state_dict
-000116d0: 2873 656c 662c 2073 7461 7465 5f64 6963  (self, state_dic
-000116e0: 743a 204f 7264 6572 6564 4469 6374 2920  t: OrderedDict) 
-000116f0: 2d3e 204e 6f6e 653a 0d0a 2020 2020 2020  -> None:..      
-00011700: 2020 7265 7475 726e 2073 7570 6572 2829    return super()
-00011710: 2e6c 6f61 645f 7374 6174 655f 6469 6374  .load_state_dict
-00011720: 2873 7461 7465 5f64 6963 7429 0d0a 0d0a  (state_dict)....
-00011730: 2020 2020 2320 666f 7220 5250 430d 0a20      # for RPC.. 
-00011740: 2020 2064 6566 2075 7064 6174 655f 706f     def update_po
-00011750: 6c69 6379 5f77 6569 6768 7473 5f28 0d0a  licy_weights_(..
-00011760: 2020 2020 2020 2020 7365 6c66 2c20 706f          self, po
-00011770: 6c69 6379 5f77 6569 6768 7473 3a20 4f70  licy_weights: Op
-00011780: 7469 6f6e 616c 5b54 656e 736f 7244 6963  tional[TensorDic
-00011790: 7442 6173 655d 203d 204e 6f6e 650d 0a20  tBase] = None.. 
-000117a0: 2020 2029 202d 3e20 4e6f 6e65 3a0d 0a20     ) -> None:.. 
-000117b0: 2020 2020 2020 2073 7570 6572 2829 2e75         super().u
-000117c0: 7064 6174 655f 706f 6c69 6379 5f77 6569  pdate_policy_wei
-000117d0: 6768 7473 5f28 706f 6c69 6379 5f77 6569  ghts_(policy_wei
-000117e0: 6768 7473 290d 0a0d 0a20 2020 2040 7072  ghts)....    @pr
-000117f0: 6f70 6572 7479 0d0a 2020 2020 6465 6620  operty..    def 
-00011800: 6672 616d 6573 5f70 6572 5f62 6174 6368  frames_per_batch
-00011810: 5f77 6f72 6b65 7228 7365 6c66 293a 0d0a  _worker(self):..
-00011820: 2020 2020 2020 2020 7265 7475 726e 2073          return s
-00011830: 656c 662e 6672 616d 6573 5f70 6572 5f62  elf.frames_per_b
-00011840: 6174 6368 0d0a 0d0a 2020 2020 6465 6620  atch....    def 
-00011850: 5f67 6574 5f66 726f 6d5f 7175 6575 6528  _get_from_queue(
-00011860: 7365 6c66 2c20 7469 6d65 6f75 743d 4e6f  self, timeout=No
-00011870: 6e65 2920 2d3e 2054 7570 6c65 5b69 6e74  ne) -> Tuple[int
-00011880: 2c20 696e 742c 2054 656e 736f 7244 6963  , int, TensorDic
-00011890: 7442 6173 655d 3a0d 0a20 2020 2020 2020  tBase]:..       
-000118a0: 206e 6577 5f64 6174 612c 206a 203d 2073   new_data, j = s
-000118b0: 656c 662e 7175 6575 655f 6f75 742e 6765  elf.queue_out.ge
-000118c0: 7428 7469 6d65 6f75 743d 7469 6d65 6f75  t(timeout=timeou
-000118d0: 7429 0d0a 2020 2020 2020 2020 6966 206a  t)..        if j
-000118e0: 203d 3d20 303a 0d0a 2020 2020 2020 2020   == 0:..        
-000118f0: 2020 2020 6461 7461 2c20 6964 7820 3d20      data, idx = 
-00011900: 6e65 775f 6461 7461 0d0a 2020 2020 2020  new_data..      
-00011910: 2020 2020 2020 7365 6c66 2e6f 7574 5f74        self.out_t
-00011920: 656e 736f 7264 6963 7473 5b69 6478 5d20  ensordicts[idx] 
-00011930: 3d20 6461 7461 0d0a 2020 2020 2020 2020  = data..        
-00011940: 656c 7365 3a0d 0a20 2020 2020 2020 2020  else:..         
-00011950: 2020 2069 6478 203d 206e 6577 5f64 6174     idx = new_dat
-00011960: 610d 0a20 2020 2020 2020 2023 2077 6520  a..        # we 
-00011970: 636c 6f6e 6520 7468 6520 6461 7461 2074  clone the data t
-00011980: 6f20 6d61 6b65 2073 7572 6520 7468 6174  o make sure that
-00011990: 2077 6527 6c6c 2062 6520 776f 726b 696e   we'll be workin
-000119a0: 6720 7769 7468 2061 2066 6978 6564 2063  g with a fixed c
-000119b0: 6f70 790d 0a20 2020 2020 2020 206f 7574  opy..        out
-000119c0: 203d 2073 656c 662e 6f75 745f 7465 6e73   = self.out_tens
-000119d0: 6f72 6469 6374 735b 6964 785d 2e63 6c6f  ordicts[idx].clo
-000119e0: 6e65 2829 0d0a 2020 2020 2020 2020 7265  ne()..        re
-000119f0: 7475 726e 2069 6478 2c20 6a2c 206f 7574  turn idx, j, out
-00011a00: 0d0a 0d0a 2020 2020 4070 726f 7065 7274  ....    @propert
-00011a10: 790d 0a20 2020 2064 6566 205f 7175 6575  y..    def _queu
-00011a20: 655f 6c65 6e28 7365 6c66 2920 2d3e 2069  e_len(self) -> i
-00011a30: 6e74 3a0d 0a20 2020 2020 2020 2072 6574  nt:..        ret
-00011a40: 7572 6e20 310d 0a0d 0a20 2020 2064 6566  urn 1....    def
-00011a50: 2069 7465 7261 746f 7228 7365 6c66 2920   iterator(self) 
-00011a60: 2d3e 2049 7465 7261 746f 725b 5465 6e73  -> Iterator[Tens
-00011a70: 6f72 4469 6374 4261 7365 5d3a 0d0a 2020  orDictBase]:..  
-00011a80: 2020 2020 2020 6966 2073 656c 662e 7570        if self.up
-00011a90: 6461 7465 5f61 745f 6561 6368 5f62 6174  date_at_each_bat
-00011aa0: 6368 3a0d 0a20 2020 2020 2020 2020 2020  ch:..           
-00011ab0: 2073 656c 662e 7570 6461 7465 5f70 6f6c   self.update_pol
-00011ac0: 6963 795f 7765 6967 6874 735f 2829 0d0a  icy_weights_()..
-00011ad0: 0d0a 2020 2020 2020 2020 666f 7220 6920  ..        for i 
-00011ae0: 696e 2072 616e 6765 2873 656c 662e 6e75  in range(self.nu
-00011af0: 6d5f 776f 726b 6572 7329 3a0d 0a20 2020  m_workers):..   
-00011b00: 2020 2020 2020 2020 2069 6620 7365 6c66           if self
-00011b10: 2e69 6e69 745f 7261 6e64 6f6d 5f66 7261  .init_random_fra
-00011b20: 6d65 7320 3e20 303a 0d0a 2020 2020 2020  mes > 0:..      
-00011b30: 2020 2020 2020 2020 2020 7365 6c66 2e70            self.p
-00011b40: 6970 6573 5b69 5d2e 7365 6e64 2828 4e6f  ipes[i].send((No
-00011b50: 6e65 2c20 2263 6f6e 7469 6e75 655f 7261  ne, "continue_ra
-00011b60: 6e64 6f6d 2229 290d 0a20 2020 2020 2020  ndom"))..       
-00011b70: 2020 2020 2065 6c73 653a 0d0a 2020 2020       else:..    
-00011b80: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-00011b90: 2e70 6970 6573 5b69 5d2e 7365 6e64 2828  .pipes[i].send((
-00011ba0: 4e6f 6e65 2c20 2263 6f6e 7469 6e75 6522  None, "continue"
-00011bb0: 2929 0d0a 2020 2020 2020 2020 7365 6c66  ))..        self
-00011bc0: 2e72 756e 6e69 6e67 203d 2054 7275 650d  .running = True.
-00011bd0: 0a20 2020 2020 2020 2069 203d 202d 310d  .        i = -1.
-00011be0: 0a20 2020 2020 2020 2073 656c 662e 5f66  .        self._f
-00011bf0: 7261 6d65 7320 3d20 300d 0a0d 0a20 2020  rames = 0....   
-00011c00: 2020 2020 2077 6f72 6b65 7273 5f66 7261       workers_fra
-00011c10: 6d65 7320 3d20 5b30 2066 6f72 205f 2069  mes = [0 for _ i
-00011c20: 6e20 7261 6e67 6528 7365 6c66 2e6e 756d  n range(self.num
-00011c30: 5f77 6f72 6b65 7273 295d 0d0a 2020 2020  _workers)]..    
-00011c40: 2020 2020 7768 696c 6520 7365 6c66 2e5f      while self._
-00011c50: 6672 616d 6573 203c 2073 656c 662e 746f  frames < self.to
-00011c60: 7461 6c5f 6672 616d 6573 3a0d 0a20 2020  tal_frames:..   
-00011c70: 2020 2020 2020 2020 205f 6368 6563 6b5f           _check_
-00011c80: 666f 725f 6661 756c 7479 5f70 726f 6365  for_faulty_proce
-00011c90: 7373 2873 656c 662e 7072 6f63 7329 0d0a  ss(self.procs)..
-00011ca0: 2020 2020 2020 2020 2020 2020 6920 2b3d              i +=
-00011cb0: 2031 0d0a 2020 2020 2020 2020 2020 2020   1..            
-00011cc0: 6964 782c 206a 2c20 6f75 7420 3d20 7365  idx, j, out = se
-00011cd0: 6c66 2e5f 6765 745f 6672 6f6d 5f71 7565  lf._get_from_que
-00011ce0: 7565 2829 0d0a 0d0a 2020 2020 2020 2020  ue()....        
-00011cf0: 2020 2020 776f 726b 6572 5f66 7261 6d65      worker_frame
-00011d00: 7320 3d20 6f75 742e 6e75 6d65 6c28 290d  s = out.numel().
-00011d10: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
-00011d20: 7365 6c66 2e73 706c 6974 5f74 7261 6a73  self.split_trajs
-00011d30: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
-00011d40: 2020 206f 7574 203d 2073 706c 6974 5f74     out = split_t
-00011d50: 7261 6a65 6374 6f72 6965 7328 6f75 742c  rajectories(out,
-00011d60: 2070 7265 6669 783d 2263 6f6c 6c65 6374   prefix="collect
-00011d70: 6f72 2229 0d0a 2020 2020 2020 2020 2020  or")..          
-00011d80: 2020 7365 6c66 2e5f 6672 616d 6573 202b    self._frames +
-00011d90: 3d20 776f 726b 6572 5f66 7261 6d65 730d  = worker_frames.
-00011da0: 0a20 2020 2020 2020 2020 2020 2077 6f72  .            wor
-00011db0: 6b65 7273 5f66 7261 6d65 735b 6964 785d  kers_frames[idx]
-00011dc0: 203d 2077 6f72 6b65 7273 5f66 7261 6d65   = workers_frame
-00011dd0: 735b 6964 785d 202b 2077 6f72 6b65 725f  s[idx] + worker_
-00011de0: 6672 616d 6573 0d0a 2020 2020 2020 2020  frames..        
-00011df0: 2020 2020 6966 2073 656c 662e 706f 7374      if self.post
-00011e00: 7072 6f63 733a 0d0a 2020 2020 2020 2020  procs:..        
-00011e10: 2020 2020 2020 2020 6f75 7420 3d20 7365          out = se
-00011e20: 6c66 2e70 6f73 7470 726f 6373 5b6f 7574  lf.postprocs[out
-00011e30: 2e64 6576 6963 655d 286f 7574 290d 0a0d  .device](out)...
-00011e40: 0a20 2020 2020 2020 2020 2020 2023 2074  .            # t
-00011e50: 6865 2066 756e 6374 696f 6e20 626c 6f63  he function bloc
-00011e60: 6b73 2068 6572 6520 756e 7469 6c20 7468  ks here until th
-00011e70: 6520 6e65 7874 2069 7465 6d20 6973 2061  e next item is a
-00011e80: 736b 6564 2c20 6865 6e63 6520 7765 2073  sked, hence we s
-00011e90: 656e 6420 7468 6520 6d65 7373 6167 6520  end the message 
-00011ea0: 746f 2074 6865 0d0a 2020 2020 2020 2020  to the..        
-00011eb0: 2020 2020 2320 776f 726b 6572 2074 6f20      # worker to 
-00011ec0: 6b65 6570 206f 6e20 776f 726b 696e 6720  keep on working 
-00011ed0: 696e 2074 6865 206d 6561 6e74 696d 6520  in the meantime 
-00011ee0: 6265 666f 7265 2074 6865 2079 6965 6c64  before the yield
-00011ef0: 2073 7461 7465 6d65 6e74 0d0a 2020 2020   statement..    
-00011f00: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
-00011f10: 5f66 7261 6d65 7320 3c20 7365 6c66 2e69  _frames < self.i
-00011f20: 6e69 745f 7261 6e64 6f6d 5f66 7261 6d65  nit_random_frame
-00011f30: 733a 0d0a 2020 2020 2020 2020 2020 2020  s:..            
-00011f40: 2020 2020 6d73 6720 3d20 2263 6f6e 7469      msg = "conti
-00011f50: 6e75 655f 7261 6e64 6f6d 220d 0a20 2020  nue_random"..   
-00011f60: 2020 2020 2020 2020 2065 6c73 653a 0d0a           else:..
-00011f70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011f80: 6d73 6720 3d20 2263 6f6e 7469 6e75 6522  msg = "continue"
-00011f90: 0d0a 2020 2020 2020 2020 2020 2020 7365  ..            se
-00011fa0: 6c66 2e70 6970 6573 5b69 6478 5d2e 7365  lf.pipes[idx].se
-00011fb0: 6e64 2828 6964 782c 206d 7367 2929 0d0a  nd((idx, msg))..
-00011fc0: 2020 2020 2020 2020 2020 2020 6966 2073              if s
-00011fd0: 656c 662e 5f65 7863 6c75 6465 5f70 7269  elf._exclude_pri
-00011fe0: 7661 7465 5f6b 6579 733a 0d0a 2020 2020  vate_keys:..    
-00011ff0: 2020 2020 2020 2020 2020 2020 6578 636c              excl
-00012000: 7564 6564 5f6b 6579 7320 3d20 5b6b 6579  uded_keys = [key
-00012010: 2066 6f72 206b 6579 2069 6e20 6f75 742e   for key in out.
-00012020: 6b65 7973 2829 2069 6620 6b65 792e 7374  keys() if key.st
-00012030: 6172 7473 7769 7468 2822 5f22 295d 0d0a  artswith("_")]..
-00012040: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012050: 6f75 7420 3d20 6f75 742e 6578 636c 7564  out = out.exclud
-00012060: 6528 2a65 7863 6c75 6465 645f 6b65 7973  e(*excluded_keys
-00012070: 290d 0a20 2020 2020 2020 2020 2020 2079  )..            y
-00012080: 6965 6c64 206f 7574 0d0a 0d0a 2020 2020  ield out....    
-00012090: 2020 2020 2320 5765 2064 6f6e 2774 2077      # We don't w
-000120a0: 616e 7420 746f 2073 6875 7464 6f77 6e20  ant to shutdown 
-000120b0: 7965 742c 2074 6865 2075 7365 7220 6d61  yet, the user ma
-000120c0: 7920 7761 6e74 2074 6f20 6361 6c6c 2073  y want to call s
-000120d0: 7461 7465 5f64 6963 7420 6265 666f 7265  tate_dict before
-000120e0: 0d0a 2020 2020 2020 2020 2320 7365 6c66  ..        # self
-000120f0: 2e5f 7368 7574 646f 776e 5f6d 6169 6e28  ._shutdown_main(
-00012100: 290d 0a20 2020 2020 2020 2073 656c 662e  )..        self.
-00012110: 7275 6e6e 696e 6720 3d20 4661 6c73 650d  running = False.
-00012120: 0a0d 0a20 2020 2064 6566 205f 7368 7574  ...    def _shut
-00012130: 646f 776e 5f6d 6169 6e28 7365 6c66 2920  down_main(self) 
-00012140: 2d3e 204e 6f6e 653a 0d0a 2020 2020 2020  -> None:..      
-00012150: 2020 6966 2068 6173 6174 7472 2873 656c    if hasattr(sel
-00012160: 662c 2022 6f75 745f 7465 6e73 6f72 6469  f, "out_tensordi
-00012170: 6374 7322 293a 0d0a 2020 2020 2020 2020  cts"):..        
-00012180: 2020 2020 6465 6c20 7365 6c66 2e6f 7574      del self.out
-00012190: 5f74 656e 736f 7264 6963 7473 0d0a 2020  _tensordicts..  
-000121a0: 2020 2020 2020 7265 7475 726e 2073 7570        return sup
-000121b0: 6572 2829 2e5f 7368 7574 646f 776e 5f6d  er()._shutdown_m
-000121c0: 6169 6e28 290d 0a0d 0a20 2020 2064 6566  ain()....    def
-000121d0: 2072 6573 6574 2873 656c 662c 2072 6573   reset(self, res
-000121e0: 6574 5f69 6478 3a20 4f70 7469 6f6e 616c  et_idx: Optional
-000121f0: 5b53 6571 7565 6e63 655b 626f 6f6c 5d5d  [Sequence[bool]]
-00012200: 203d 204e 6f6e 6529 202d 3e20 4e6f 6e65   = None) -> None
-00012210: 3a0d 0a20 2020 2020 2020 2073 7570 6572  :..        super
-00012220: 2829 2e72 6573 6574 2872 6573 6574 5f69  ().reset(reset_i
-00012230: 6478 290d 0a20 2020 2020 2020 2069 6620  dx)..        if 
-00012240: 7365 6c66 2e71 7565 7565 5f6f 7574 2e66  self.queue_out.f
-00012250: 756c 6c28 293a 0d0a 2020 2020 2020 2020  ull():..        
-00012260: 2020 2020 7469 6d65 2e73 6c65 6570 285f      time.sleep(_
-00012270: 5449 4d45 4f55 5429 2020 2320 7761 6974  TIMEOUT)  # wait
-00012280: 2075 6e74 696c 2071 7565 7565 2069 7320   until queue is 
-00012290: 656d 7074 790d 0a20 2020 2020 2020 2069  empty..        i
-000122a0: 6620 7365 6c66 2e71 7565 7565 5f6f 7574  f self.queue_out
-000122b0: 2e66 756c 6c28 293a 0d0a 2020 2020 2020  .full():..      
-000122c0: 2020 2020 2020 7261 6973 6520 4578 6365        raise Exce
-000122d0: 7074 696f 6e28 2273 656c 662e 7175 6575  ption("self.queu
-000122e0: 655f 6f75 7420 6973 2066 756c 6c22 290d  e_out is full").
-000122f0: 0a20 2020 2020 2020 2069 6620 7365 6c66  .        if self
-00012300: 2e72 756e 6e69 6e67 3a0d 0a20 2020 2020  .running:..     
-00012310: 2020 2020 2020 2066 6f72 2069 6478 2069         for idx i
-00012320: 6e20 7261 6e67 6528 7365 6c66 2e6e 756d  n range(self.num
-00012330: 5f77 6f72 6b65 7273 293a 0d0a 2020 2020  _workers):..    
-00012340: 2020 2020 2020 2020 2020 2020 6966 2073              if s
-00012350: 656c 662e 5f66 7261 6d65 7320 3c20 7365  elf._frames < se
-00012360: 6c66 2e69 6e69 745f 7261 6e64 6f6d 5f66  lf.init_random_f
-00012370: 7261 6d65 733a 0d0a 2020 2020 2020 2020  rames:..        
-00012380: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-00012390: 2e70 6970 6573 5b69 6478 5d2e 7365 6e64  .pipes[idx].send
-000123a0: 2828 6964 782c 2022 636f 6e74 696e 7565  ((idx, "continue
-000123b0: 5f72 616e 646f 6d22 2929 0d0a 2020 2020  _random"))..    
-000123c0: 2020 2020 2020 2020 2020 2020 656c 7365              else
-000123d0: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
-000123e0: 2020 2020 2020 2073 656c 662e 7069 7065         self.pipe
-000123f0: 735b 6964 785d 2e73 656e 6428 2869 6478  s[idx].send((idx
-00012400: 2c20 2263 6f6e 7469 6e75 6522 2929 0d0a  , "continue"))..
-00012410: 0d0a 0d0a 4061 6363 6570 745f 7265 6d6f  ....@accept_remo
-00012420: 7465 5f72 7265 665f 7564 665f 696e 766f  te_rref_udf_invo
-00012430: 6361 7469 6f6e 0d0a 636c 6173 7320 6153  cation..class aS
-00012440: 796e 6344 6174 6143 6f6c 6c65 6374 6f72  yncDataCollector
-00012450: 284d 756c 7469 6153 796e 6344 6174 6143  (MultiaSyncDataC
-00012460: 6f6c 6c65 6374 6f72 293a 0d0a 2020 2020  ollector):..    
-00012470: 2222 2252 756e 7320 6120 7369 6e67 6c65  """Runs a single
-00012480: 2044 6174 6143 6f6c 6c65 6374 6f72 206f   DataCollector o
-00012490: 6e20 6120 7365 7061 7261 7465 2070 726f  n a separate pro
-000124a0: 6365 7373 2e0d 0a0d 0a20 2020 2054 6869  cess.....    Thi
-000124b0: 7320 6973 206d 6f73 746c 7920 7573 6566  s is mostly usef
-000124c0: 756c 2066 6f72 206f 6666 6c69 6e65 2052  ul for offline R
-000124d0: 4c20 7061 7261 6469 676d 7320 7768 6572  L paradigms wher
-000124e0: 6520 7468 6520 706f 6c69 6379 2062 6569  e the policy bei
-000124f0: 6e67 0d0a 2020 2020 7472 6169 6e65 6420  ng..    trained 
-00012500: 6361 6e20 6469 6666 6572 2066 726f 6d20  can differ from 
-00012510: 7468 6520 706f 6c69 6379 2075 7365 6420  the policy used 
-00012520: 746f 2063 6f6c 6c65 6374 2064 6174 612e  to collect data.
-00012530: 2049 6e20 6f6e 6c69 6e65 0d0a 2020 2020   In online..    
-00012540: 7365 7474 696e 6773 2c20 6120 7265 6775  settings, a regu
-00012550: 6c61 7220 4461 7461 436f 6c6c 6563 746f  lar DataCollecto
-00012560: 7220 7368 6f75 6c64 2062 6520 7072 6566  r should be pref
-00012570: 6572 7265 642e 2054 6869 7320 636c 6173  erred. This clas
-00012580: 7320 6973 0d0a 2020 2020 6d65 7265 6c79  s is..    merely
-00012590: 2061 2077 7261 7070 6572 2061 726f 756e   a wrapper aroun
-000125a0: 6420 6120 4d75 6c74 6961 5379 6e63 4461  d a MultiaSyncDa
-000125b0: 7461 436f 6c6c 6563 746f 7220 7768 6572  taCollector wher
-000125c0: 6520 6120 7369 6e67 6c65 2070 726f 6365  e a single proce
-000125d0: 7373 0d0a 2020 2020 6973 2062 6569 6e67  ss..    is being
-000125e0: 2063 7265 6174 6564 2e0d 0a0d 0a20 2020   created.....   
-000125f0: 2041 7267 733a 0d0a 2020 2020 2020 2020   Args:..        
-00012600: 6372 6561 7465 5f65 6e76 5f66 6e20 2843  create_env_fn (C
-00012610: 616c 6c61 626c 6564 293a 2043 616c 6c61  allabled): Calla
-00012620: 626c 6520 7265 7475 726e 696e 6720 616e  ble returning an
-00012630: 2069 6e73 7461 6e63 6520 6f66 2045 6e76   instance of Env
-00012640: 4261 7365 0d0a 2020 2020 2020 2020 706f  Base..        po
-00012650: 6c69 6379 2028 4361 6c6c 6162 6c65 2c20  licy (Callable, 
-00012660: 6f70 7469 6f6e 616c 293a 2049 6e73 7461  optional): Insta
-00012670: 6e63 6520 6f66 2054 656e 736f 7244 6963  nce of TensorDic
-00012680: 744d 6f64 756c 6520 636c 6173 732e 0d0a  tModule class...
-00012690: 2020 2020 2020 2020 2020 2020 4d75 7374              Must
-000126a0: 2061 6363 6570 7420 5465 6e73 6f72 4469   accept TensorDi
-000126b0: 6374 4261 7365 206f 626a 6563 7420 6173  ctBase object as
-000126c0: 2069 6e70 7574 2e0d 0a20 2020 2020 2020   input...       
-000126d0: 2074 6f74 616c 5f66 7261 6d65 7320 2869   total_frames (i
-000126e0: 6e74 293a 206c 6f77 6572 2062 6f75 6e64  nt): lower bound
-000126f0: 206f 6620 7468 6520 746f 7461 6c20 6e75   of the total nu
-00012700: 6d62 6572 206f 6620 6672 616d 6573 2072  mber of frames r
-00012710: 6574 7572 6e65 640d 0a20 2020 2020 2020  eturned..       
-00012720: 2020 2020 2062 7920 7468 6520 636f 6c6c       by the coll
-00012730: 6563 746f 722e 2049 6e20 7061 7261 6c6c  ector. In parall
-00012740: 656c 2073 6574 7469 6e67 732c 2074 6865  el settings, the
-00012750: 2061 6374 7561 6c20 6e75 6d62 6572 206f   actual number o
-00012760: 660d 0a20 2020 2020 2020 2020 2020 2066  f..            f
-00012770: 7261 6d65 7320 6d61 7920 7765 6c6c 2062  rames may well b
-00012780: 6520 6772 6561 7465 7220 7468 616e 2074  e greater than t
-00012790: 6869 7320 6173 2074 6865 2063 6c6f 7369  his as the closi
-000127a0: 6e67 2073 6967 6e61 6c73 2061 7265 0d0a  ng signals are..
-000127b0: 2020 2020 2020 2020 2020 2020 7365 6e74              sent
-000127c0: 2074 6f20 7468 6520 776f 726b 6572 7320   to the workers 
-000127d0: 6f6e 6c79 206f 6e63 6520 7468 6520 746f  only once the to
-000127e0: 7461 6c20 6e75 6d62 6572 206f 6620 6672  tal number of fr
-000127f0: 616d 6573 2068 6173 0d0a 2020 2020 2020  ames has..      
-00012800: 2020 2020 2020 6265 656e 2063 6f6c 6c65        been colle
-00012810: 6374 6564 206f 6e20 7468 6520 7365 7276  cted on the serv
-00012820: 6572 2e0d 0a20 2020 2020 2020 2063 7265  er...        cre
-00012830: 6174 655f 656e 765f 6b77 6172 6773 2028  ate_env_kwargs (
-00012840: 6469 6374 2c20 6f70 7469 6f6e 616c 293a  dict, optional):
-00012850: 2041 2064 6963 7469 6f6e 6172 7920 7769   A dictionary wi
-00012860: 7468 2074 6865 2061 7267 756d 656e 7473  th the arguments
-00012870: 0d0a 2020 2020 2020 2020 2020 2020 7573  ..            us
-00012880: 6564 2074 6f20 6372 6561 7465 2061 6e20  ed to create an 
-00012890: 656e 7669 726f 6e6d 656e 740d 0a20 2020  environment..   
-000128a0: 2020 2020 206d 6178 5f66 7261 6d65 735f       max_frames_
-000128b0: 7065 725f 7472 616a 3a20 4d61 7869 6d75  per_traj: Maximu
-000128c0: 6d20 7374 6570 7320 7065 7220 7472 616a  m steps per traj
-000128d0: 6563 746f 7279 2e20 4e6f 7465 2074 6861  ectory. Note tha
-000128e0: 7420 610d 0a20 2020 2020 2020 2020 2020  t a..           
-000128f0: 2074 7261 6a65 6374 6f72 7920 6361 6e20   trajectory can 
-00012900: 7370 616e 206f 7665 7220 6d75 6c74 6970  span over multip
-00012910: 6c65 2062 6174 6368 6573 2028 756e 6c65  le batches (unle
-00012920: 7373 0d0a 2020 2020 2020 2020 2020 2020  ss..            
-00012930: 7265 7365 745f 6174 5f65 6163 685f 6974  reset_at_each_it
-00012940: 6572 2069 7320 7365 7420 746f 2054 7275  er is set to Tru
-00012950: 652c 2073 6565 2062 656c 6f77 292e 204f  e, see below). O
-00012960: 6e63 6520 6120 7472 616a 6563 746f 7279  nce a trajectory
-00012970: 0d0a 2020 2020 2020 2020 2020 2020 7265  ..            re
-00012980: 6163 6865 7320 6e5f 7374 6570 732c 2074  aches n_steps, t
-00012990: 6865 2065 6e76 6972 6f6e 6d65 6e74 2069  he environment i
-000129a0: 7320 7265 7365 742e 2049 6620 7468 650d  s reset. If the.
-000129b0: 0a20 2020 2020 2020 2020 2020 2065 6e76  .            env
-000129c0: 6972 6f6e 6d65 6e74 2077 7261 7073 206d  ironment wraps m
-000129d0: 756c 7469 706c 6520 656e 7669 726f 6e6d  ultiple environm
-000129e0: 656e 7473 2074 6f67 6574 6865 722c 2074  ents together, t
-000129f0: 6865 206e 756d 6265 7220 6f66 0d0a 2020  he number of..  
-00012a00: 2020 2020 2020 2020 2020 7374 6570 7320            steps 
-00012a10: 6973 2074 7261 636b 6564 2066 6f72 2065  is tracked for e
-00012a20: 6163 6820 656e 7669 726f 6e6d 656e 7420  ach environment 
-00012a30: 696e 6465 7065 6e64 656e 746c 792e 204e  independently. N
-00012a40: 6567 6174 6976 650d 0a20 2020 2020 2020  egative..       
-00012a50: 2020 2020 2076 616c 7565 7320 6172 6520       values are 
-00012a60: 616c 6c6f 7765 642c 2069 6e20 7768 6963  allowed, in whic
-00012a70: 6820 6361 7365 2074 6869 7320 6172 6775  h case this argu
-00012a80: 6d65 6e74 2069 7320 6967 6e6f 7265 642e  ment is ignored.
-00012a90: 0d0a 2020 2020 2020 2020 2020 2020 4465  ..            De
-00012aa0: 6661 756c 7420 6973 202d 3120 2869 2e65  fault is -1 (i.e
-00012ab0: 2e20 6e6f 206d 6178 696d 756d 206e 756d  . no maximum num
-00012ac0: 6265 7220 6f66 2073 7465 7073 290d 0a20  ber of steps).. 
-00012ad0: 2020 2020 2020 2066 7261 6d65 735f 7065         frames_pe
-00012ae0: 725f 6261 7463 6820 2869 6e74 293a 2054  r_batch (int): T
-00012af0: 696d 652d 6c65 6e67 7468 206f 6620 6120  ime-length of a 
-00012b00: 6261 7463 682e 0d0a 2020 2020 2020 2020  batch...        
-00012b10: 2020 2020 7265 7365 745f 6174 5f65 6163      reset_at_eac
-00012b20: 685f 6974 6572 2061 6e64 2066 7261 6d65  h_iter and frame
-00012b30: 735f 7065 725f 6261 7463 6820 3d3d 206e  s_per_batch == n
-00012b40: 5f73 7465 7073 2061 7265 2065 7175 6976  _steps are equiv
-00012b50: 616c 656e 7420 636f 6e66 6967 7572 6174  alent configurat
-00012b60: 696f 6e73 2e0d 0a20 2020 2020 2020 2020  ions...         
-00012b70: 2020 2064 6566 6175 6c74 3a20 3230 300d     default: 200.
-00012b80: 0a20 2020 2020 2020 2069 6e69 745f 7261  .        init_ra
-00012b90: 6e64 6f6d 5f66 7261 6d65 7320 2869 6e74  ndom_frames (int
-00012ba0: 293a 204e 756d 6265 7220 6f66 2066 7261  ): Number of fra
-00012bb0: 6d65 7320 666f 7220 7768 6963 6820 7468  mes for which th
-00012bc0: 6520 706f 6c69 6379 2069 7320 6967 6e6f  e policy is igno
-00012bd0: 7265 6420 6265 666f 7265 2069 7420 6973  red before it is
-00012be0: 2063 616c 6c65 642e 0d0a 2020 2020 2020   called...      
-00012bf0: 2020 2020 2020 5468 6973 2066 6561 7475        This featu
-00012c00: 7265 2069 7320 6d61 696e 6c79 2069 6e74  re is mainly int
-00012c10: 656e 6465 6420 746f 2062 6520 7573 6564  ended to be used
-00012c20: 2069 6e20 6f66 666c 696e 652f 6d6f 6465   in offline/mode
-00012c30: 6c2d 6261 7365 6420 7365 7474 696e 6773  l-based settings
-00012c40: 2c20 7768 6572 6520 6120 6261 7463 6820  , where a batch 
-00012c50: 6f66 2072 616e 646f 6d0d 0a20 2020 2020  of random..     
-00012c60: 2020 2020 2020 2074 7261 6a65 6374 6f72         trajector
-00012c70: 6965 7320 6361 6e20 6265 2075 7365 6420  ies can be used 
-00012c80: 746f 2069 6e69 7469 616c 697a 6520 7472  to initialize tr
-00012c90: 6169 6e69 6e67 2e0d 0a20 2020 2020 2020  aining...       
-00012ca0: 2020 2020 2064 6566 6175 6c74 3d2d 3120       default=-1 
-00012cb0: 2869 2e65 2e20 6e6f 2072 616e 646f 6d20  (i.e. no random 
-00012cc0: 6672 616d 6573 290d 0a20 2020 2020 2020  frames)..       
-00012cd0: 2072 6573 6574 5f61 745f 6561 6368 5f69   reset_at_each_i
-00012ce0: 7465 7220 2862 6f6f 6c29 3a20 5768 6574  ter (bool): Whet
-00012cf0: 6865 7220 6f72 206e 6f74 2065 6e76 6972  her or not envir
-00012d00: 6f6e 6d65 6e74 7320 7368 6f75 6c64 2062  onments should b
-00012d10: 6520 7265 7365 7420 666f 7220 6561 6368  e reset for each
-00012d20: 2062 6174 6368 2e0d 0a20 2020 2020 2020   batch...       
-00012d30: 2020 2020 2064 6566 6175 6c74 3d46 616c       default=Fal
-00012d40: 7365 2e0d 0a20 2020 2020 2020 2070 6f73  se...        pos
-00012d50: 7470 726f 6320 2863 616c 6c61 626c 652c  tproc (callable,
-00012d60: 206f 7074 696f 6e61 6c29 3a20 4120 506f   optional): A Po
-00012d70: 7374 5072 6f63 6573 736f 7220 6973 2061  stProcessor is a
-00012d80: 6e20 6f62 6a65 6374 2074 6861 7420 7769  n object that wi
-00012d90: 6c6c 2072 6561 6420 6120 6261 7463 6820  ll read a batch 
-00012da0: 6f66 2064 6174 6120 616e 6420 7072 6f63  of data and proc
-00012db0: 6573 7320 6974 2069 6e20 610d 0a20 2020  ess it in a..   
-00012dc0: 2020 2020 2020 2020 2075 7365 6675 6c20           useful 
-00012dd0: 666f 726d 6174 2066 6f72 2074 7261 696e  format for train
-00012de0: 696e 672e 0d0a 2020 2020 2020 2020 2020  ing...          
-00012df0: 2020 6465 6661 756c 743a 204e 6f6e 652e    default: None.
-00012e00: 0d0a 2020 2020 2020 2020 7370 6c69 745f  ..        split_
-00012e10: 7472 616a 7320 2862 6f6f 6c29 3a20 426f  trajs (bool): Bo
-00012e20: 6f6c 6561 6e20 696e 6469 6361 7469 6e67  olean indicating
-00012e30: 2077 6865 7468 6572 2074 6865 2072 6573   whether the res
-00012e40: 756c 7469 6e67 2054 656e 736f 7244 6963  ulting TensorDic
-00012e50: 7420 7368 6f75 6c64 2062 6520 7370 6c69  t should be spli
-00012e60: 7420 6163 636f 7264 696e 6720 746f 2074  t according to t
-00012e70: 6865 2074 7261 6a65 6374 6f72 6965 732e  he trajectories.
-00012e80: 0d0a 2020 2020 2020 2020 2020 2020 5365  ..            Se
-00012e90: 6520 7574 696c 732e 7370 6c69 745f 7472  e utils.split_tr
-00012ea0: 616a 6563 746f 7269 6573 2066 6f72 206d  ajectories for m
-00012eb0: 6f72 6520 696e 666f 726d 6174 696f 6e2e  ore information.
-00012ec0: 0d0a 2020 2020 2020 2020 6465 7669 6365  ..        device
-00012ed0: 2028 696e 742c 2073 7472 2c20 746f 7263   (int, str, torc
-00012ee0: 682e 6465 7669 6365 2c20 6f70 7469 6f6e  h.device, option
-00012ef0: 616c 293a 2054 6865 2064 6576 6963 6520  al): The device 
-00012f00: 6f6e 2077 6869 6368 2074 6865 0d0a 2020  on which the..  
-00012f10: 2020 2020 2020 2020 2020 706f 6c69 6379            policy
-00012f20: 2077 696c 6c20 6265 2070 6c61 6365 642e   will be placed.
-00012f30: 2049 6620 6974 2064 6966 6665 7273 2066   If it differs f
-00012f40: 726f 6d20 7468 6520 696e 7075 7420 706f  rom the input po
-00012f50: 6c69 6379 0d0a 2020 2020 2020 2020 2020  licy..          
-00012f60: 2020 6465 7669 6365 2c20 7468 6520 7570    device, the up
-00012f70: 6461 7465 5f70 6f6c 6963 795f 7765 6967  date_policy_weig
-00012f80: 6874 735f 2829 206d 6574 686f 6420 7368  hts_() method sh
-00012f90: 6f75 6c64 2062 6520 7175 6572 6965 640d  ould be queried.
-00012fa0: 0a20 2020 2020 2020 2020 2020 2061 7420  .            at 
-00012fb0: 6170 7072 6f70 7269 6174 6520 7469 6d65  appropriate time
-00012fc0: 7320 6475 7269 6e67 2074 6865 2074 7261  s during the tra
-00012fd0: 696e 696e 6720 6c6f 6f70 2074 6f20 6163  ining loop to ac
-00012fe0: 636f 6d6d 6f64 6174 6520 666f 720d 0a20  commodate for.. 
-00012ff0: 2020 2020 2020 2020 2020 2074 6865 206c             the l
-00013000: 6167 2062 6574 7765 656e 2070 6172 616d  ag between param
-00013010: 6574 6572 2063 6f6e 6669 6775 7261 7469  eter configurati
-00013020: 6f6e 2061 7420 7661 7269 6f75 7320 7469  on at various ti
-00013030: 6d65 732e 0d0a 2020 2020 2020 2020 2020  mes...          
-00013040: 2020 4465 6661 756c 7420 6973 2060 4e6f    Default is `No
-00013050: 6e65 6020 2869 2e65 2e20 706f 6c69 6379  ne` (i.e. policy
-00013060: 2069 7320 6b65 7074 206f 6e20 6974 7320   is kept on its 
-00013070: 6f72 6967 696e 616c 2064 6576 6963 6529  original device)
-00013080: 0d0a 2020 2020 2020 2020 7374 6f72 696e  ..        storin
-00013090: 675f 6465 7669 6365 2028 696e 742c 2073  g_device (int, s
-000130a0: 7472 2c20 746f 7263 682e 6465 7669 6365  tr, torch.device
-000130b0: 2c20 6f70 7469 6f6e 616c 293a 2054 6865  , optional): The
-000130c0: 2064 6576 6963 6520 6f6e 2077 6869 6368   device on which
-000130d0: 0d0a 2020 2020 2020 2020 2020 2020 7468  ..            th
-000130e0: 6520 6f75 7470 7574 2054 656e 736f 7244  e output TensorD
-000130f0: 6963 7420 7769 6c6c 2062 6520 7374 6f72  ict will be stor
-00013100: 6564 2e20 466f 7220 6c6f 6e67 2074 7261  ed. For long tra
-00013110: 6a65 6374 6f72 6965 732c 0d0a 2020 2020  jectories,..    
-00013120: 2020 2020 2020 2020 6974 206d 6179 2062          it may b
-00013130: 6520 6e65 6365 7373 6172 7920 746f 2073  e necessary to s
-00013140: 746f 7265 2074 6865 2064 6174 6120 6f6e  tore the data on
-00013150: 2061 2064 6966 6665 7265 6e74 2e0d 0a20   a different... 
-00013160: 2020 2020 2020 2020 2020 2064 6576 6963             devic
-00013170: 6520 7468 616e 2074 6865 206f 6e65 2077  e than the one w
-00013180: 6865 7265 2074 6865 2070 6f6c 6963 7920  here the policy 
-00013190: 6973 2073 746f 7265 642e 2044 6566 6175  is stored. Defau
-000131a0: 6c74 2069 7320 4e6f 6e65 2e0d 0a20 2020  lt is None...   
-000131b0: 2020 2020 2075 7064 6174 655f 6174 5f65       update_at_e
-000131c0: 6163 685f 6261 7463 6820 2862 6f6f 6c29  ach_batch (bool)
-000131d0: 3a20 6966 2054 7275 652c 2074 6865 2070  : if True, the p
-000131e0: 6f6c 6963 7920 7765 6967 6874 7320 7769  olicy weights wi
-000131f0: 6c6c 2062 6520 7570 6461 7465 6420 6576  ll be updated ev
-00013200: 6572 7920 7469 6d65 2061 2062 6174 6368  ery time a batch
-00013210: 206f 6620 7472 616a 6563 746f 7269 6573   of trajectories
-00013220: 0d0a 2020 2020 2020 2020 2020 2020 6973  ..            is
-00013230: 2063 6f6c 6c65 6374 6564 2e0d 0a20 2020   collected...   
-00013240: 2020 2020 2020 2020 2064 6566 6175 6c74           default
-00013250: 3d46 616c 7365 0d0a 0d0a 2020 2020 2222  =False....    ""
-00013260: 220d 0a0d 0a20 2020 2064 6566 205f 5f69  "....    def __i
-00013270: 6e69 745f 5f28 0d0a 2020 2020 2020 2020  nit__(..        
-00013280: 7365 6c66 2c0d 0a20 2020 2020 2020 2063  self,..        c
-00013290: 7265 6174 655f 656e 765f 666e 3a20 4361  reate_env_fn: Ca
-000132a0: 6c6c 6162 6c65 5b5b 5d2c 2045 6e76 4261  llable[[], EnvBa
-000132b0: 7365 5d2c 0d0a 2020 2020 2020 2020 706f  se],..        po
-000132c0: 6c69 6379 3a20 4f70 7469 6f6e 616c 5b0d  licy: Optional[.
-000132d0: 0a20 2020 2020 2020 2020 2020 2055 6e69  .            Uni
-000132e0: 6f6e 5b0d 0a20 2020 2020 2020 2020 2020  on[..           
-000132f0: 2020 2020 2054 656e 736f 7244 6963 744d       TensorDictM
-00013300: 6f64 756c 652c 0d0a 2020 2020 2020 2020  odule,..        
-00013310: 2020 2020 2020 2020 4361 6c6c 6162 6c65          Callable
-00013320: 5b5b 5465 6e73 6f72 4469 6374 4261 7365  [[TensorDictBase
-00013330: 5d2c 2054 656e 736f 7244 6963 7442 6173  ], TensorDictBas
-00013340: 655d 2c0d 0a20 2020 2020 2020 2020 2020  e],..           
-00013350: 205d 0d0a 2020 2020 2020 2020 5d20 3d20   ]..        ] = 
-00013360: 4e6f 6e65 2c0d 0a20 2020 2020 2020 2074  None,..        t
-00013370: 6f74 616c 5f66 7261 6d65 733a 204f 7074  otal_frames: Opt
-00013380: 696f 6e61 6c5b 696e 745d 203d 202d 312c  ional[int] = -1,
-00013390: 0d0a 2020 2020 2020 2020 6372 6561 7465  ..        create
-000133a0: 5f65 6e76 5f6b 7761 7267 733a 204f 7074  _env_kwargs: Opt
-000133b0: 696f 6e61 6c5b 6469 6374 5d20 3d20 4e6f  ional[dict] = No
-000133c0: 6e65 2c0d 0a20 2020 2020 2020 206d 6178  ne,..        max
-000133d0: 5f66 7261 6d65 735f 7065 725f 7472 616a  _frames_per_traj
-000133e0: 3a20 696e 7420 3d20 2d31 2c0d 0a20 2020  : int = -1,..   
-000133f0: 2020 2020 2066 7261 6d65 735f 7065 725f       frames_per_
-00013400: 6261 7463 683a 2069 6e74 203d 2032 3030  batch: int = 200
-00013410: 2c0d 0a20 2020 2020 2020 2069 6e69 745f  ,..        init_
-00013420: 7261 6e64 6f6d 5f66 7261 6d65 733a 2069  random_frames: i
-00013430: 6e74 203d 202d 312c 0d0a 2020 2020 2020  nt = -1,..      
-00013440: 2020 7265 7365 745f 6174 5f65 6163 685f    reset_at_each_
-00013450: 6974 6572 3a20 626f 6f6c 203d 2046 616c  iter: bool = Fal
-00013460: 7365 2c0d 0a20 2020 2020 2020 2070 6f73  se,..        pos
-00013470: 7470 726f 633a 204f 7074 696f 6e61 6c5b  tproc: Optional[
-00013480: 4361 6c6c 6162 6c65 5b5b 5465 6e73 6f72  Callable[[Tensor
-00013490: 4469 6374 4261 7365 5d2c 2054 656e 736f  DictBase], Tenso
-000134a0: 7244 6963 7442 6173 655d 5d20 3d20 4e6f  rDictBase]] = No
-000134b0: 6e65 2c0d 0a20 2020 2020 2020 2073 706c  ne,..        spl
-000134c0: 6974 5f74 7261 6a73 3a20 4f70 7469 6f6e  it_trajs: Option
-000134d0: 616c 5b62 6f6f 6c5d 203d 204e 6f6e 652c  al[bool] = None,
-000134e0: 0d0a 2020 2020 2020 2020 6465 7669 6365  ..        device
-000134f0: 3a20 4f70 7469 6f6e 616c 5b55 6e69 6f6e  : Optional[Union
-00013500: 5b69 6e74 2c20 7374 722c 2074 6f72 6368  [int, str, torch
-00013510: 2e64 6576 6963 655d 5d20 3d20 4e6f 6e65  .device]] = None
-00013520: 2c0d 0a20 2020 2020 2020 2073 746f 7269  ,..        stori
-00013530: 6e67 5f64 6576 6963 653a 204f 7074 696f  ng_device: Optio
-00013540: 6e61 6c5b 556e 696f 6e5b 696e 742c 2073  nal[Union[int, s
-00013550: 7472 2c20 746f 7263 682e 6465 7669 6365  tr, torch.device
-00013560: 5d5d 203d 204e 6f6e 652c 0d0a 2020 2020  ]] = None,..    
-00013570: 2020 2020 7365 6564 3a20 4f70 7469 6f6e      seed: Option
-00013580: 616c 5b69 6e74 5d20 3d20 4e6f 6e65 2c0d  al[int] = None,.
-00013590: 0a20 2020 2020 2020 2070 696e 5f6d 656d  .        pin_mem
-000135a0: 6f72 793a 2062 6f6f 6c20 3d20 4661 6c73  ory: bool = Fals
-000135b0: 652c 0d0a 2020 2020 2020 2020 2a2a 6b77  e,..        **kw
-000135c0: 6172 6773 2c0d 0a20 2020 2029 3a0d 0a20  args,..    ):.. 
-000135d0: 2020 2020 2020 2073 7570 6572 2829 2e5f         super()._
-000135e0: 5f69 6e69 745f 5f28 0d0a 2020 2020 2020  _init__(..      
-000135f0: 2020 2020 2020 6372 6561 7465 5f65 6e76        create_env
-00013600: 5f66 6e3d 5b63 7265 6174 655f 656e 765f  _fn=[create_env_
-00013610: 666e 5d2c 0d0a 2020 2020 2020 2020 2020  fn],..          
-00013620: 2020 706f 6c69 6379 3d70 6f6c 6963 792c    policy=policy,
-00013630: 0d0a 2020 2020 2020 2020 2020 2020 746f  ..            to
-00013640: 7461 6c5f 6672 616d 6573 3d74 6f74 616c  tal_frames=total
-00013650: 5f66 7261 6d65 732c 0d0a 2020 2020 2020  _frames,..      
-00013660: 2020 2020 2020 6372 6561 7465 5f65 6e76        create_env
-00013670: 5f6b 7761 7267 733d 5b63 7265 6174 655f  _kwargs=[create_
-00013680: 656e 765f 6b77 6172 6773 5d2c 0d0a 2020  env_kwargs],..  
-00013690: 2020 2020 2020 2020 2020 6d61 785f 6672            max_fr
-000136a0: 616d 6573 5f70 6572 5f74 7261 6a3d 6d61  ames_per_traj=ma
-000136b0: 785f 6672 616d 6573 5f70 6572 5f74 7261  x_frames_per_tra
-000136c0: 6a2c 0d0a 2020 2020 2020 2020 2020 2020  j,..            
-000136d0: 6672 616d 6573 5f70 6572 5f62 6174 6368  frames_per_batch
-000136e0: 3d66 7261 6d65 735f 7065 725f 6261 7463  =frames_per_batc
-000136f0: 682c 0d0a 2020 2020 2020 2020 2020 2020  h,..            
-00013700: 7265 7365 745f 6174 5f65 6163 685f 6974  reset_at_each_it
-00013710: 6572 3d72 6573 6574 5f61 745f 6561 6368  er=reset_at_each
-00013720: 5f69 7465 722c 0d0a 2020 2020 2020 2020  _iter,..        
-00013730: 2020 2020 696e 6974 5f72 616e 646f 6d5f      init_random_
-00013740: 6672 616d 6573 3d69 6e69 745f 7261 6e64  frames=init_rand
-00013750: 6f6d 5f66 7261 6d65 732c 0d0a 2020 2020  om_frames,..    
-00013760: 2020 2020 2020 2020 706f 7374 7072 6f63          postproc
-00013770: 3d70 6f73 7470 726f 632c 0d0a 2020 2020  =postproc,..    
-00013780: 2020 2020 2020 2020 7370 6c69 745f 7472          split_tr
-00013790: 616a 733d 7370 6c69 745f 7472 616a 732c  ajs=split_trajs,
-000137a0: 0d0a 2020 2020 2020 2020 2020 2020 6465  ..            de
-000137b0: 7669 6365 733d 5b64 6576 6963 655d 2069  vices=[device] i
-000137c0: 6620 6465 7669 6365 2069 7320 6e6f 7420  f device is not 
-000137d0: 4e6f 6e65 2065 6c73 6520 4e6f 6e65 2c0d  None else None,.
-000137e0: 0a20 2020 2020 2020 2020 2020 2073 746f  .            sto
-000137f0: 7269 6e67 5f64 6576 6963 6573 3d5b 7374  ring_devices=[st
-00013800: 6f72 696e 675f 6465 7669 6365 5d20 6966  oring_device] if
-00013810: 2073 746f 7269 6e67 5f64 6576 6963 6520   storing_device 
-00013820: 6973 206e 6f74 204e 6f6e 6520 656c 7365  is not None else
-00013830: 204e 6f6e 652c 0d0a 2020 2020 2020 2020   None,..        
-00013840: 2020 2020 2a2a 6b77 6172 6773 2c0d 0a20      **kwargs,.. 
-00013850: 2020 2020 2020 2029 0d0a 0d0a 2020 2020         )....    
-00013860: 2320 666f 7220 5250 430d 0a20 2020 2064  # for RPC..    d
-00013870: 6566 206e 6578 7428 7365 6c66 293a 0d0a  ef next(self):..
-00013880: 2020 2020 2020 2020 7265 7475 726e 2073          return s
-00013890: 7570 6572 2829 2e6e 6578 7428 290d 0a0d  uper().next()...
-000138a0: 0a20 2020 2023 2066 6f72 2052 5043 0d0a  .    # for RPC..
-000138b0: 2020 2020 6465 6620 7368 7574 646f 776e      def shutdown
-000138c0: 2873 656c 6629 3a0d 0a20 2020 2020 2020  (self):..       
-000138d0: 2072 6574 7572 6e20 7375 7065 7228 292e   return super().
-000138e0: 7368 7574 646f 776e 2829 0d0a 0d0a 2020  shutdown()....  
-000138f0: 2020 2320 666f 7220 5250 430d 0a20 2020    # for RPC..   
-00013900: 2064 6566 2073 6574 5f73 6565 6428 7365   def set_seed(se
-00013910: 6c66 2c20 7365 6564 3a20 696e 742c 2073  lf, seed: int, s
-00013920: 7461 7469 635f 7365 6564 3a20 626f 6f6c  tatic_seed: bool
-00013930: 203d 2046 616c 7365 2920 2d3e 2069 6e74   = False) -> int
-00013940: 3a0d 0a20 2020 2020 2020 2072 6574 7572  :..        retur
-00013950: 6e20 7375 7065 7228 292e 7365 745f 7365  n super().set_se
-00013960: 6564 2873 6565 642c 2073 7461 7469 635f  ed(seed, static_
-00013970: 7365 6564 290d 0a0d 0a20 2020 2023 2066  seed)....    # f
-00013980: 6f72 2052 5043 0d0a 2020 2020 6465 6620  or RPC..    def 
-00013990: 7374 6174 655f 6469 6374 2873 656c 6629  state_dict(self)
-000139a0: 202d 3e20 4f72 6465 7265 6444 6963 743a   -> OrderedDict:
-000139b0: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
-000139c0: 2073 7570 6572 2829 2e73 7461 7465 5f64   super().state_d
-000139d0: 6963 7428 290d 0a0d 0a20 2020 2023 2066  ict()....    # f
-000139e0: 6f72 2052 5043 0d0a 2020 2020 6465 6620  or RPC..    def 
-000139f0: 6c6f 6164 5f73 7461 7465 5f64 6963 7428  load_state_dict(
-00013a00: 7365 6c66 2c20 7374 6174 655f 6469 6374  self, state_dict
-00013a10: 3a20 4f72 6465 7265 6444 6963 7429 202d  : OrderedDict) -
-00013a20: 3e20 4e6f 6e65 3a0d 0a20 2020 2020 2020  > None:..       
-00013a30: 2072 6574 7572 6e20 7375 7065 7228 292e   return super().
-00013a40: 6c6f 6164 5f73 7461 7465 5f64 6963 7428  load_state_dict(
-00013a50: 7374 6174 655f 6469 6374 290d 0a0d 0a0d  state_dict).....
-00013a60: 0a64 6566 205f 6d61 696e 5f61 7379 6e63  .def _main_async
-00013a70: 5f63 6f6c 6c65 6374 6f72 280d 0a20 2020  _collector(..   
-00013a80: 2070 6970 655f 7061 7265 6e74 3a20 636f   pipe_parent: co
-00013a90: 6e6e 6563 7469 6f6e 2e43 6f6e 6e65 6374  nnection.Connect
-00013aa0: 696f 6e2c 0d0a 2020 2020 7069 7065 5f63  ion,..    pipe_c
-00013ab0: 6869 6c64 3a20 636f 6e6e 6563 7469 6f6e  hild: connection
-00013ac0: 2e43 6f6e 6e65 6374 696f 6e2c 0d0a 2020  .Connection,..  
-00013ad0: 2020 7175 6575 655f 6f75 743a 2071 7565    queue_out: que
-00013ae0: 7565 732e 5175 6575 652c 0d0a 2020 2020  ues.Queue,..    
-00013af0: 6372 6561 7465 5f65 6e76 5f66 6e3a 2055  create_env_fn: U
-00013b00: 6e69 6f6e 5b45 6e76 4261 7365 2c20 2245  nion[EnvBase, "E
-00013b10: 6e76 4372 6561 746f 7222 2c20 4361 6c6c  nvCreator", Call
-00013b20: 6162 6c65 5b5b 5d2c 2045 6e76 4261 7365  able[[], EnvBase
-00013b30: 5d5d 2c20 2023 206e 6f71 613a 2046 3832  ]],  # noqa: F82
-00013b40: 310d 0a20 2020 2063 7265 6174 655f 656e  1..    create_en
-00013b50: 765f 6b77 6172 6773 3a20 4469 6374 5b73  v_kwargs: Dict[s
-00013b60: 7472 2c20 416e 795d 2c0d 0a20 2020 2070  tr, Any],..    p
-00013b70: 6f6c 6963 793a 2043 616c 6c61 626c 655b  olicy: Callable[
-00013b80: 5b54 656e 736f 7244 6963 7442 6173 655d  [TensorDictBase]
-00013b90: 2c20 5465 6e73 6f72 4469 6374 4261 7365  , TensorDictBase
-00013ba0: 5d2c 0d0a 2020 2020 6d61 785f 6672 616d  ],..    max_fram
-00013bb0: 6573 5f70 6572 5f74 7261 6a3a 2069 6e74  es_per_traj: int
-00013bc0: 2c0d 0a20 2020 2066 7261 6d65 735f 7065  ,..    frames_pe
-00013bd0: 725f 6261 7463 683a 2069 6e74 2c0d 0a20  r_batch: int,.. 
-00013be0: 2020 2072 6573 6574 5f61 745f 6561 6368     reset_at_each
-00013bf0: 5f69 7465 723a 2062 6f6f 6c2c 0d0a 2020  _iter: bool,..  
-00013c00: 2020 6465 7669 6365 3a20 4f70 7469 6f6e    device: Option
-00013c10: 616c 5b55 6e69 6f6e 5b74 6f72 6368 2e64  al[Union[torch.d
-00013c20: 6576 6963 652c 2073 7472 2c20 696e 745d  evice, str, int]
-00013c30: 5d2c 0d0a 2020 2020 7374 6f72 696e 675f  ],..    storing_
-00013c40: 6465 7669 6365 3a20 4f70 7469 6f6e 616c  device: Optional
-00013c50: 5b55 6e69 6f6e 5b74 6f72 6368 2e64 6576  [Union[torch.dev
-00013c60: 6963 652c 2073 7472 2c20 696e 745d 5d2c  ice, str, int]],
-00013c70: 0d0a 2020 2020 6964 783a 2069 6e74 203d  ..    idx: int =
-00013c80: 2030 2c0d 0a20 2020 2065 7870 6c6f 7261   0,..    explora
-00013c90: 7469 6f6e 5f6d 6f64 653a 2073 7472 203d  tion_mode: str =
-00013ca0: 2044 4546 4155 4c54 5f45 5850 4c4f 5241   DEFAULT_EXPLORA
-00013cb0: 5449 4f4e 5f4d 4f44 452c 0d0a 2020 2020  TION_MODE,..    
-00013cc0: 7265 7365 745f 7768 656e 5f64 6f6e 653a  reset_when_done:
-00013cd0: 2062 6f6f 6c20 3d20 5472 7565 2c0d 0a20   bool = True,.. 
-00013ce0: 2020 2076 6572 626f 7365 3a20 626f 6f6c     verbose: bool
-00013cf0: 203d 2056 4552 424f 5345 2c0d 0a29 202d   = VERBOSE,..) -
-00013d00: 3e20 4e6f 6e65 3a0d 0a20 2020 2070 6970  > None:..    pip
-00013d10: 655f 7061 7265 6e74 2e63 6c6f 7365 2829  e_parent.close()
-00013d20: 0d0a 2020 2020 2320 c2a0 696e 6974 2076  ..    # ..init v
-00013d30: 6172 6961 626c 6573 2074 6861 7420 7769  ariables that wi
-00013d40: 6c6c 2062 6520 636c 6561 7265 6420 7768  ll be cleared wh
-00013d50: 656e 2063 6c6f 7369 6e67 0d0a 2020 2020  en closing..    
-00013d60: 7465 6e73 6f72 6469 6374 203d 2064 6174  tensordict = dat
-00013d70: 6120 3d20 6420 3d20 6461 7461 5f69 6e20  a = d = data_in 
-00013d80: 3d20 6463 203d 2064 635f 6974 6572 203d  = dc = dc_iter =
-00013d90: 204e 6f6e 650d 0a0d 0a20 2020 2064 6320   None....    dc 
-00013da0: 3d20 5379 6e63 4461 7461 436f 6c6c 6563  = SyncDataCollec
-00013db0: 746f 7228 0d0a 2020 2020 2020 2020 6372  tor(..        cr
-00013dc0: 6561 7465 5f65 6e76 5f66 6e2c 0d0a 2020  eate_env_fn,..  
-00013dd0: 2020 2020 2020 6372 6561 7465 5f65 6e76        create_env
-00013de0: 5f6b 7761 7267 733d 6372 6561 7465 5f65  _kwargs=create_e
-00013df0: 6e76 5f6b 7761 7267 732c 0d0a 2020 2020  nv_kwargs,..    
-00013e00: 2020 2020 706f 6c69 6379 3d70 6f6c 6963      policy=polic
-00013e10: 792c 0d0a 2020 2020 2020 2020 746f 7461  y,..        tota
-00013e20: 6c5f 6672 616d 6573 3d2d 312c 0d0a 2020  l_frames=-1,..  
-00013e30: 2020 2020 2020 6d61 785f 6672 616d 6573        max_frames
-00013e40: 5f70 6572 5f74 7261 6a3d 6d61 785f 6672  _per_traj=max_fr
-00013e50: 616d 6573 5f70 6572 5f74 7261 6a2c 0d0a  ames_per_traj,..
-00013e60: 2020 2020 2020 2020 6672 616d 6573 5f70          frames_p
-00013e70: 6572 5f62 6174 6368 3d66 7261 6d65 735f  er_batch=frames_
-00013e80: 7065 725f 6261 7463 682c 0d0a 2020 2020  per_batch,..    
-00013e90: 2020 2020 7265 7365 745f 6174 5f65 6163      reset_at_eac
-00013ea0: 685f 6974 6572 3d72 6573 6574 5f61 745f  h_iter=reset_at_
-00013eb0: 6561 6368 5f69 7465 722c 0d0a 2020 2020  each_iter,..    
-00013ec0: 2020 2020 706f 7374 7072 6f63 3d4e 6f6e      postproc=Non
-00013ed0: 652c 0d0a 2020 2020 2020 2020 7370 6c69  e,..        spli
-00013ee0: 745f 7472 616a 733d 4661 6c73 652c 0d0a  t_trajs=False,..
-00013ef0: 2020 2020 2020 2020 6465 7669 6365 3d64          device=d
-00013f00: 6576 6963 652c 0d0a 2020 2020 2020 2020  evice,..        
-00013f10: 7374 6f72 696e 675f 6465 7669 6365 3d73  storing_device=s
-00013f20: 746f 7269 6e67 5f64 6576 6963 652c 0d0a  toring_device,..
-00013f30: 2020 2020 2020 2020 6578 706c 6f72 6174          explorat
-00013f40: 696f 6e5f 6d6f 6465 3d65 7870 6c6f 7261  ion_mode=explora
-00013f50: 7469 6f6e 5f6d 6f64 652c 0d0a 2020 2020  tion_mode,..    
-00013f60: 2020 2020 7265 7365 745f 7768 656e 5f64      reset_when_d
-00013f70: 6f6e 653d 7265 7365 745f 7768 656e 5f64  one=reset_when_d
-00013f80: 6f6e 652c 0d0a 2020 2020 2020 2020 7265  one,..        re
-00013f90: 7475 726e 5f73 616d 655f 7464 3d54 7275  turn_same_td=Tru
-00013fa0: 652c 0d0a 2020 2020 290d 0a20 2020 2069  e,..    )..    i
-00013fb0: 6620 7665 7262 6f73 653a 0d0a 2020 2020  f verbose:..    
-00013fc0: 2020 2020 7072 696e 7428 2253 796e 6320      print("Sync 
-00013fd0: 6461 7461 2063 6f6c 6c65 6374 6f72 2063  data collector c
-00013fe0: 7265 6174 6564 2229 0d0a 2020 2020 6463  reated")..    dc
-00013ff0: 5f69 7465 7220 3d20 6974 6572 2864 6329  _iter = iter(dc)
-00014000: 0d0a 2020 2020 6a20 3d20 300d 0a20 2020  ..    j = 0..   
-00014010: 2070 6970 655f 6368 696c 642e 7365 6e64   pipe_child.send
-00014020: 2822 696e 7374 616e 7469 6174 6564 2229  ("instantiated")
-00014030: 0d0a 0d0a 2020 2020 6861 735f 7469 6d65  ....    has_time
-00014040: 645f 6f75 7420 3d20 4661 6c73 650d 0a20  d_out = False.. 
-00014050: 2020 2063 6f75 6e74 6572 203d 2030 0d0a     counter = 0..
-00014060: 2020 2020 7768 696c 6520 5472 7565 3a0d      while True:.
-00014070: 0a20 2020 2020 2020 205f 7469 6d65 6f75  .        _timeou
-00014080: 7420 3d20 5f54 494d 454f 5554 2069 6620  t = _TIMEOUT if 
-00014090: 6e6f 7420 6861 735f 7469 6d65 645f 6f75  not has_timed_ou
-000140a0: 7420 656c 7365 2031 652d 330d 0a20 2020  t else 1e-3..   
-000140b0: 2020 2020 2069 6620 7069 7065 5f63 6869       if pipe_chi
-000140c0: 6c64 2e70 6f6c 6c28 5f74 696d 656f 7574  ld.poll(_timeout
-000140d0: 293a 0d0a 2020 2020 2020 2020 2020 2020  ):..            
-000140e0: 636f 756e 7465 7220 3d20 300d 0a20 2020  counter = 0..   
-000140f0: 2020 2020 2020 2020 2064 6174 615f 696e           data_in
-00014100: 2c20 6d73 6720 3d20 7069 7065 5f63 6869  , msg = pipe_chi
-00014110: 6c64 2e72 6563 7628 290d 0a20 2020 2020  ld.recv()..     
-00014120: 2020 2020 2020 2069 6620 7665 7262 6f73         if verbos
-00014130: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
-00014140: 2020 2020 7072 696e 7428 6622 776f 726b      print(f"work
-00014150: 6572 207b 6964 787d 2072 6563 6569 7665  er {idx} receive
-00014160: 6420 7b6d 7367 7d22 290d 0a20 2020 2020  d {msg}")..     
-00014170: 2020 2065 6c73 653a 0d0a 2020 2020 2020     else:..      
-00014180: 2020 2020 2020 6966 2076 6572 626f 7365        if verbose
-00014190: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
-000141a0: 2020 2070 7269 6e74 2866 2270 6f6c 6c20     print(f"poll 
-000141b0: 6661 696c 6564 2c20 6a3d 7b6a 7d2c 2077  failed, j={j}, w
-000141c0: 6f72 6b65 723d 7b69 6478 7d22 290d 0a20  orker={idx}").. 
-000141d0: 2020 2020 2020 2020 2020 2023 2064 6566             # def
-000141e0: 6175 6c74 2069 7320 2263 6f6e 7469 6e75  ault is "continu
-000141f0: 6522 2028 6166 7465 7220 6669 7273 7420  e" (after first 
-00014200: 6974 6572 6174 696f 6e29 0d0a 2020 2020  iteration)..    
-00014210: 2020 2020 2020 2020 2320 7468 6973 2069          # this i
-00014220: 7320 6578 7065 6374 6564 2074 6f20 6861  s expected to ha
-00014230: 7070 656e 2069 6620 7175 6575 655f 6f75  ppen if queue_ou
-00014240: 7420 7265 6163 6865 6420 7468 6520 7469  t reached the ti
-00014250: 6d65 6f75 742c 2062 7574 206e 6f20 6e65  meout, but no ne
-00014260: 7720 6d73 6720 7761 7320 7761 6974 696e  w msg was waitin
-00014270: 6720 696e 2074 6865 2070 6970 650d 0a20  g in the pipe.. 
-00014280: 2020 2020 2020 2020 2020 2023 2069 6e20             # in 
-00014290: 7468 6174 2063 6173 652c 2074 6865 206d  that case, the m
-000142a0: 6169 6e20 7072 6f63 6573 7320 7072 6f62  ain process prob
-000142b0: 6162 6c79 2065 7870 6563 7473 2074 6865  ably expects the
-000142c0: 2077 6f72 6b65 7220 746f 2063 6f6e 7469   worker to conti
-000142d0: 6e75 6520 636f 6c6c 6563 7420 6461 7461  nue collect data
-000142e0: 0d0a 2020 2020 2020 2020 2020 2020 6966  ..            if
-000142f0: 2068 6173 5f74 696d 6564 5f6f 7574 3a0d   has_timed_out:.
-00014300: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00014310: 2063 6f75 6e74 6572 203d 2030 0d0a 2020   counter = 0..  
-00014320: 2020 2020 2020 2020 2020 2020 2020 2320                # 
-00014330: 6861 735f 7469 6d65 645f 6f75 7420 6973  has_timed_out is
-00014340: 2054 7275 6520 6966 2074 6865 2070 726f   True if the pro
-00014350: 6365 7373 2066 6169 6c65 6420 746f 2073  cess failed to s
-00014360: 656e 6420 6461 7461 2c20 7768 6963 6820  end data, which 
-00014370: 7769 6c6c 0d0a 2020 2020 2020 2020 2020  will..          
-00014380: 2020 2020 2020 2320 7479 7069 6361 6c6c        # typicall
-00014390: 7920 6f63 6375 7220 6966 206d 6169 6e20  y occur if main 
-000143a0: 6861 7320 7461 6b65 6e20 616e 6f74 6865  has taken anothe
-000143b0: 7220 6261 7463 6820 2869 2e65 2e20 7468  r batch (i.e. th
-000143c0: 6520 7175 6575 6520 6973 2046 756c 6c29  e queue is Full)
-000143d0: 2e0d 0a20 2020 2020 2020 2020 2020 2020  ...             
-000143e0: 2020 2023 2049 6e20 7468 6973 2063 6173     # In this cas
-000143f0: 652c 206d 7367 2069 7320 7468 6520 7072  e, msg is the pr
-00014400: 6576 696f 7573 206d 7367 2073 656e 7420  evious msg sent 
-00014410: 6279 206d 6169 6e2c 2077 6869 6368 2077  by main, which w
-00014420: 696c 6c20 7479 7069 6361 6c6c 7920 6265  ill typically be
-00014430: 2022 636f 6e74 696e 7565 220d 0a20 2020   "continue"..   
-00014440: 2020 2020 2020 2020 2020 2020 2023 2049               # I
-00014450: 6620 6974 2773 206e 6f74 2074 6865 2063  f it's not the c
-00014460: 6173 652c 2069 7420 6973 206e 6f74 2065  ase, it is not e
-00014470: 7870 6563 7465 6420 7468 6174 2068 6173  xpected that has
-00014480: 5f74 696d 6564 5f6f 7574 2069 7320 5472  _timed_out is Tr
-00014490: 7565 2e0d 0a20 2020 2020 2020 2020 2020  ue...           
-000144a0: 2020 2020 2069 6620 6d73 6720 6e6f 7420       if msg not 
-000144b0: 696e 2028 2263 6f6e 7469 6e75 6522 2c20  in ("continue", 
-000144c0: 2263 6f6e 7469 6e75 655f 7261 6e64 6f6d  "continue_random
-000144d0: 2229 3a0d 0a20 2020 2020 2020 2020 2020  "):..           
-000144e0: 2020 2020 2020 2020 2072 6169 7365 2052           raise R
-000144f0: 756e 7469 6d65 4572 726f 7228 6622 556e  untimeError(f"Un
-00014500: 6578 7065 6374 6564 206d 6573 7361 6765  expected message
-00014510: 2061 6674 6572 2074 696d 6520 6f75 743a   after time out:
-00014520: 206d 7367 3d7b 6d73 677d 2229 0d0a 2020   msg={msg}")..  
-00014530: 2020 2020 2020 2020 2020 656c 7365 3a0d            else:.
-00014540: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00014550: 2023 2069 6620 6861 735f 7469 6d65 645f   # if has_timed_
-00014560: 6f75 7420 6973 2046 616c 7365 2c20 7468  out is False, th
-00014570: 656e 2074 6865 2074 696d 6520 6f75 7420  en the time out 
-00014580: 646f 6573 206e 6f74 2063 6f6d 6520 6672  does not come fr
-00014590: 6f6d 2074 6865 2066 6163 7420 7468 6174  om the fact that
-000145a0: 2074 6865 2071 7565 7565 2069 7320 4675   the queue is Fu
-000145b0: 6c6c 2e0d 0a20 2020 2020 2020 2020 2020  ll...           
-000145c0: 2020 2020 2023 2074 6869 7320 6d65 616e       # this mean
-000145d0: 7320 7468 6174 206f 7572 2070 726f 6365  s that our proce
-000145e0: 7373 2068 6173 2062 6565 6e20 7761 6974  ss has been wait
-000145f0: 696e 6720 666f 7220 6120 636f 6d6d 616e  ing for a comman
-00014600: 6420 6672 6f6d 206d 6169 6e20 696e 2076  d from main in v
-00014610: 6169 6e2c 2077 6869 6c65 206d 6169 6e20  ain, while main 
-00014620: 7761 7320 6e6f 740d 0a20 2020 2020 2020  was not..       
-00014630: 2020 2020 2020 2020 2023 2072 6563 6569           # recei
-00014640: 7669 6e67 2064 6174 612e 0d0a 2020 2020  ving data...    
-00014650: 2020 2020 2020 2020 2020 2020 2320 5468              # Th
-00014660: 6973 2077 696c 6c20 6f63 6375 7220 6966  is will occur if
-00014670: 206d 6169 6e20 6973 2062 7573 7920 646f   main is busy do
-00014680: 696e 6720 736f 6d65 7468 696e 6720 656c  ing something el
-00014690: 7365 2028 652e 672e 2063 6f6d 7075 7469  se (e.g. computi
-000146a0: 6e67 206c 6f73 7320 6574 6329 2e0d 0a0d  ng loss etc)....
-000146b0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000146c0: 2063 6f75 6e74 6572 202b 3d20 5f74 696d   counter += _tim
-000146d0: 656f 7574 0d0a 2020 2020 2020 2020 2020  eout..          
-000146e0: 2020 2020 2020 6966 2076 6572 626f 7365        if verbose
-000146f0: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
-00014700: 2020 2020 2020 2070 7269 6e74 2866 2277         print(f"w
-00014710: 6f72 6b65 7220 7b69 6478 7d20 6861 7320  orker {idx} has 
-00014720: 636f 756e 7465 7220 7b63 6f75 6e74 6572  counter {counter
-00014730: 7d22 290d 0a20 2020 2020 2020 2020 2020  }")..           
-00014740: 2020 2020 2069 6620 636f 756e 7465 7220       if counter 
-00014750: 3e3d 2028 5f4d 4158 5f49 444c 455f 434f  >= (_MAX_IDLE_CO
-00014760: 554e 5420 2a20 5f54 494d 454f 5554 293a  UNT * _TIMEOUT):
-00014770: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00014780: 2020 2020 2020 7261 6973 6520 5275 6e74        raise Runt
-00014790: 696d 6545 7272 6f72 280d 0a20 2020 2020  imeError(..     
-000147a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000147b0: 2020 2066 2254 6869 7320 7072 6f63 6573     f"This proces
-000147c0: 7320 7761 6974 6564 2066 6f72 207b 636f  s waited for {co
-000147d0: 756e 7465 727d 2073 6563 6f6e 6473 2022  unter} seconds "
-000147e0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-000147f0: 2020 2020 2020 2020 2020 6622 7769 7468            f"with
-00014800: 6f75 7420 7265 6365 6976 696e 6720 6120  out receiving a 
-00014810: 636f 6d6d 616e 6420 6672 6f6d 206d 6169  command from mai
-00014820: 6e2e 2043 6f6e 7369 6465 7220 696e 6372  n. Consider incr
-00014830: 6561 7369 6e67 2074 6865 206d 6178 696d  easing the maxim
-00014840: 756d 2069 646c 6520 636f 756e 7420 220d  um idle count ".
-00014850: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00014860: 2020 2020 2020 2020 2066 2269 6620 7468           f"if th
-00014870: 6973 2069 7320 6578 7065 6374 6564 2076  is is expected v
-00014880: 6961 2074 6865 2065 6e76 6972 6f6e 6d65  ia the environme
-00014890: 6e74 2076 6172 6961 626c 6520 4d41 585f  nt variable MAX_
-000148a0: 4944 4c45 5f43 4f55 4e54 2022 0d0a 2020  IDLE_COUNT "..  
-000148b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000148c0: 2020 2020 2020 6622 2863 7572 7265 6e74        f"(current
-000148d0: 2076 616c 7565 2069 7320 7b5f 4d41 585f   value is {_MAX_
-000148e0: 4944 4c45 5f43 4f55 4e54 7d29 2e22 0d0a  IDLE_COUNT})."..
-000148f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014900: 2020 2020 2020 2020 6622 5c6e 4966 2074          f"\nIf t
-00014910: 6869 7320 6f63 6375 7273 2061 7420 7468  his occurs at th
-00014920: 6520 656e 6420 6f66 2061 2066 756e 6374  e end of a funct
-00014930: 696f 6e20 6f72 2070 726f 6772 616d 2c20  ion or program, 
-00014940: 6974 206d 6561 6e73 2074 6861 7420 796f  it means that yo
-00014950: 7572 2063 6f6c 6c65 6374 6f72 2068 6173  ur collector has
-00014960: 206e 6f74 2062 6565 6e20 220d 0a20 2020   not been "..   
-00014970: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014980: 2020 2020 2066 2263 6f6c 6c65 6374 6564       f"collected
-00014990: 2c20 636f 6e73 6964 6572 2063 616c 6c69  , consider calli
-000149a0: 6e67 2060 636f 6c6c 6563 746f 722e 7368  ng `collector.sh
-000149b0: 7574 646f 776e 2829 6020 6f72 2060 6465  utdown()` or `de
-000149c0: 6c20 636f 6c6c 6563 746f 7260 2062 6566  l collector` bef
-000149d0: 6f72 6520 656e 6469 6e67 2074 6865 2070  ore ending the p
-000149e0: 726f 6772 616d 2e22 0d0a 2020 2020 2020  rogram."..      
-000149f0: 2020 2020 2020 2020 2020 2020 2020 290d                ).
-00014a00: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00014a10: 2063 6f6e 7469 6e75 650d 0a20 2020 2020   continue..     
-00014a20: 2020 2069 6620 6d73 6720 696e 2028 2263     if msg in ("c
-00014a30: 6f6e 7469 6e75 6522 2c20 2263 6f6e 7469  ontinue", "conti
-00014a40: 6e75 655f 7261 6e64 6f6d 2229 3a0d 0a20  nue_random"):.. 
-00014a50: 2020 2020 2020 2020 2020 2069 6620 6d73             if ms
-00014a60: 6720 3d3d 2022 636f 6e74 696e 7565 5f72  g == "continue_r
-00014a70: 616e 646f 6d22 3a0d 0a20 2020 2020 2020  andom":..       
-00014a80: 2020 2020 2020 2020 2064 632e 696e 6974           dc.init
-00014a90: 5f72 616e 646f 6d5f 6672 616d 6573 203d  _random_frames =
-00014aa0: 2066 6c6f 6174 2822 696e 6622 290d 0a20   float("inf").. 
-00014ab0: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
-00014ac0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00014ad0: 2020 6463 2e69 6e69 745f 7261 6e64 6f6d    dc.init_random
-00014ae0: 5f66 7261 6d65 7320 3d20 2d31 0d0a 0d0a  _frames = -1....
-00014af0: 2020 2020 2020 2020 2020 2020 6420 3d20              d = 
-00014b00: 6e65 7874 2864 635f 6974 6572 290d 0a20  next(dc_iter).. 
-00014b10: 2020 2020 2020 2020 2020 2069 6620 7069             if pi
-00014b20: 7065 5f63 6869 6c64 2e70 6f6c 6c28 5f4d  pe_child.poll(_M
-00014b30: 494e 5f54 494d 454f 5554 293a 0d0a 2020  IN_TIMEOUT):..  
-00014b40: 2020 2020 2020 2020 2020 2020 2020 2320                # 
-00014b50: 696e 2074 6869 7320 6361 7365 2c20 6d61  in this case, ma
-00014b60: 696e 2073 656e 6420 6120 6d65 7373 6167  in send a messag
-00014b70: 6520 746f 2074 6865 2077 6f72 6b65 7220  e to the worker 
-00014b80: 7768 696c 6520 6974 2077 6173 2062 7573  while it was bus
-00014b90: 7920 636f 6c6c 6563 7469 6e67 2074 7261  y collecting tra
-00014ba0: 6a65 6374 6f72 6965 732e 0d0a 2020 2020  jectories...    
-00014bb0: 2020 2020 2020 2020 2020 2020 2320 496e              # In
-00014bc0: 2074 6861 7420 6361 7365 2c20 7765 2073   that case, we s
-00014bd0: 6b69 7020 7468 6520 636f 6c6c 6563 7465  kip the collecte
-00014be0: 6420 7472 616a 6563 746f 7279 2061 6e64  d trajectory and
-00014bf0: 2067 6574 2074 6865 206d 6573 7361 6765   get the message
-00014c00: 2066 726f 6d20 6d61 696e 2e20 5468 6973   from main. This
-00014c10: 2069 7320 6661 7374 6572 2074 6861 6e0d   is faster than.
-00014c20: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00014c30: 2023 2073 656e 6469 6e67 2074 6865 2074   # sending the t
-00014c40: 7261 6a65 6374 6f72 7920 696e 2074 6865  rajectory in the
-00014c50: 2071 7565 7565 2075 6e74 696c 2074 696d   queue until tim
-00014c60: 656f 7574 2077 6865 6e20 6974 2773 206e  eout when it's n
-00014c70: 6576 6572 2067 6f69 6e67 2074 6f20 6265  ever going to be
-00014c80: 2072 6563 6569 7665 642e 0d0a 2020 2020   received...    
-00014c90: 2020 2020 2020 2020 2020 2020 636f 6e74              cont
-00014ca0: 696e 7565 0d0a 2020 2020 2020 2020 2020  inue..          
-00014cb0: 2020 6966 206a 203d 3d20 303a 0d0a 2020    if j == 0:..  
-00014cc0: 2020 2020 2020 2020 2020 2020 2020 7465                te
-00014cd0: 6e73 6f72 6469 6374 203d 2064 0d0a 2020  nsordict = d..  
-00014ce0: 2020 2020 2020 2020 2020 2020 2020 6966                if
-00014cf0: 2073 746f 7269 6e67 5f64 6576 6963 6520   storing_device 
-00014d00: 6973 206e 6f74 204e 6f6e 6520 616e 6420  is not None and 
-00014d10: 7465 6e73 6f72 6469 6374 2e64 6576 6963  tensordict.devic
-00014d20: 6520 213d 2073 746f 7269 6e67 5f64 6576  e != storing_dev
-00014d30: 6963 653a 0d0a 2020 2020 2020 2020 2020  ice:..          
-00014d40: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
-00014d50: 5275 6e74 696d 6545 7272 6f72 280d 0a20  RuntimeError(.. 
-00014d60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014d70: 2020 2020 2020 2066 2265 7870 6563 7465         f"expecte
-00014d80: 6420 6465 7669 6365 2074 6f20 6265 207b  d device to be {
-00014d90: 7374 6f72 696e 675f 6465 7669 6365 7d20  storing_device} 
-00014da0: 6275 7420 676f 7420 7b74 656e 736f 7264  but got {tensord
-00014db0: 6963 742e 6465 7669 6365 7d22 0d0a 2020  ict.device}"..  
-00014dc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014dd0: 2020 290d 0a20 2020 2020 2020 2020 2020    )..           
-00014de0: 2020 2020 2074 656e 736f 7264 6963 742e       tensordict.
-00014df0: 7368 6172 655f 6d65 6d6f 7279 5f28 290d  share_memory_().
-00014e00: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00014e10: 2064 6174 6120 3d20 2874 656e 736f 7264   data = (tensord
-00014e20: 6963 742c 2069 6478 290d 0a20 2020 2020  ict, idx)..     
-00014e30: 2020 2020 2020 2065 6c73 653a 0d0a 2020         else:..  
-00014e40: 2020 2020 2020 2020 2020 2020 2020 6966                if
-00014e50: 2064 2069 7320 6e6f 7420 7465 6e73 6f72   d is not tensor
-00014e60: 6469 6374 3a0d 0a20 2020 2020 2020 2020  dict:..         
-00014e70: 2020 2020 2020 2020 2020 2072 6169 7365             raise
-00014e80: 2052 756e 7469 6d65 4572 726f 7228 0d0a   RuntimeError(..
-00014e90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014ea0: 2020 2020 2020 2020 2253 796e 6344 6174          "SyncDat
-00014eb0: 6143 6f6c 6c65 6374 6f72 2073 686f 756c  aCollector shoul
-00014ec0: 6420 7265 7475 726e 2074 6865 2073 616d  d return the sam
-00014ed0: 6520 7465 6e73 6f72 6469 6374 206d 6f64  e tensordict mod
-00014ee0: 6966 6965 6420 696e 2d70 6c61 6365 2e22  ified in-place."
-00014ef0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00014f00: 2020 2020 2020 290d 0a20 2020 2020 2020        )..       
-00014f10: 2020 2020 2020 2020 2064 6174 6120 3d20           data = 
-00014f20: 6964 7820 2023 2066 6c61 6720 7468 6520  idx  # flag the 
-00014f30: 776f 726b 6572 2074 6861 7420 6861 7320  worker that has 
-00014f40: 7365 6e74 2069 7473 2064 6174 610d 0a20  sent its data.. 
-00014f50: 2020 2020 2020 2020 2020 2074 7279 3a0d             try:.
-00014f60: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00014f70: 2071 7565 7565 5f6f 7574 2e70 7574 2828   queue_out.put((
-00014f80: 6461 7461 2c20 6a29 2c20 7469 6d65 6f75  data, j), timeou
-00014f90: 743d 5f54 494d 454f 5554 290d 0a20 2020  t=_TIMEOUT)..   
-00014fa0: 2020 2020 2020 2020 2020 2020 2069 6620               if 
-00014fb0: 7665 7262 6f73 653a 0d0a 2020 2020 2020  verbose:..      
-00014fc0: 2020 2020 2020 2020 2020 2020 2020 7072                pr
-00014fd0: 696e 7428 6622 776f 726b 6572 207b 6964  int(f"worker {id
-00014fe0: 787d 2073 7563 6365 7373 6675 6c6c 7920  x} successfully 
-00014ff0: 7365 6e74 2064 6174 6122 290d 0a20 2020  sent data")..   
-00015000: 2020 2020 2020 2020 2020 2020 206a 202b               j +
-00015010: 3d20 310d 0a20 2020 2020 2020 2020 2020  = 1..           
-00015020: 2020 2020 2068 6173 5f74 696d 6564 5f6f       has_timed_o
-00015030: 7574 203d 2046 616c 7365 0d0a 2020 2020  ut = False..    
-00015040: 2020 2020 2020 2020 2020 2020 636f 6e74              cont
-00015050: 696e 7565 0d0a 2020 2020 2020 2020 2020  inue..          
-00015060: 2020 6578 6365 7074 2071 7565 7565 2e46    except queue.F
-00015070: 756c 6c3a 0d0a 2020 2020 2020 2020 2020  ull:..          
-00015080: 2020 2020 2020 6966 2076 6572 626f 7365        if verbose
-00015090: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
-000150a0: 2020 2020 2020 2070 7269 6e74 2866 2277         print(f"w
-000150b0: 6f72 6b65 7220 7b69 6478 7d20 6861 7320  orker {idx} has 
-000150c0: 7469 6d65 6420 6f75 7422 290d 0a20 2020  timed out")..   
-000150d0: 2020 2020 2020 2020 2020 2020 2068 6173               has
-000150e0: 5f74 696d 6564 5f6f 7574 203d 2054 7275  _timed_out = Tru
-000150f0: 650d 0a20 2020 2020 2020 2020 2020 2020  e..             
-00015100: 2020 2063 6f6e 7469 6e75 650d 0a0d 0a20     continue.... 
-00015110: 2020 2020 2020 2065 6c69 6620 6d73 6720         elif msg 
-00015120: 3d3d 2022 7570 6461 7465 223a 0d0a 2020  == "update":..  
-00015130: 2020 2020 2020 2020 2020 6463 2e75 7064            dc.upd
-00015140: 6174 655f 706f 6c69 6379 5f77 6569 6768  ate_policy_weigh
-00015150: 7473 5f28 290d 0a20 2020 2020 2020 2020  ts_()..         
-00015160: 2020 2070 6970 655f 6368 696c 642e 7365     pipe_child.se
-00015170: 6e64 2828 6a2c 2022 7570 6461 7465 6422  nd((j, "updated"
-00015180: 2929 0d0a 2020 2020 2020 2020 2020 2020  ))..            
-00015190: 6861 735f 7469 6d65 645f 6f75 7420 3d20  has_timed_out = 
-000151a0: 4661 6c73 650d 0a20 2020 2020 2020 2020  False..         
-000151b0: 2020 2063 6f6e 7469 6e75 650d 0a0d 0a20     continue.... 
-000151c0: 2020 2020 2020 2065 6c69 6620 6d73 6720         elif msg 
-000151d0: 3d3d 2022 7365 6564 223a 0d0a 2020 2020  == "seed":..    
-000151e0: 2020 2020 2020 2020 6461 7461 5f69 6e2c          data_in,
-000151f0: 2073 7461 7469 635f 7365 6564 203d 2064   static_seed = d
-00015200: 6174 615f 696e 0d0a 2020 2020 2020 2020  ata_in..        
-00015210: 2020 2020 6e65 775f 7365 6564 203d 2064      new_seed = d
-00015220: 632e 7365 745f 7365 6564 2864 6174 615f  c.set_seed(data_
-00015230: 696e 2c20 7374 6174 6963 5f73 6565 643d  in, static_seed=
-00015240: 7374 6174 6963 5f73 6565 6429 0d0a 2020  static_seed)..  
-00015250: 2020 2020 2020 2020 2020 746f 7263 682e            torch.
-00015260: 6d61 6e75 616c 5f73 6565 6428 6461 7461  manual_seed(data
-00015270: 5f69 6e29 0d0a 2020 2020 2020 2020 2020  _in)..          
-00015280: 2020 6e70 2e72 616e 646f 6d2e 7365 6564    np.random.seed
-00015290: 2864 6174 615f 696e 290d 0a20 2020 2020  (data_in)..     
-000152a0: 2020 2020 2020 2070 6970 655f 6368 696c         pipe_chil
-000152b0: 642e 7365 6e64 2828 6e65 775f 7365 6564  d.send((new_seed
-000152c0: 2c20 2273 6565 6465 6422 2929 0d0a 2020  , "seeded"))..  
-000152d0: 2020 2020 2020 2020 2020 6861 735f 7469            has_ti
-000152e0: 6d65 645f 6f75 7420 3d20 4661 6c73 650d  med_out = False.
-000152f0: 0a20 2020 2020 2020 2020 2020 2063 6f6e  .            con
-00015300: 7469 6e75 650d 0a0d 0a20 2020 2020 2020  tinue....       
-00015310: 2065 6c69 6620 6d73 6720 3d3d 2022 7265   elif msg == "re
-00015320: 7365 7422 3a0d 0a20 2020 2020 2020 2020  set":..         
-00015330: 2020 2064 632e 7265 7365 7428 290d 0a20     dc.reset().. 
-00015340: 2020 2020 2020 2020 2020 2070 6970 655f             pipe_
-00015350: 6368 696c 642e 7365 6e64 2828 6a2c 2022  child.send((j, "
-00015360: 7265 7365 7422 2929 0d0a 2020 2020 2020  reset"))..      
-00015370: 2020 2020 2020 636f 6e74 696e 7565 0d0a        continue..
-00015380: 0d0a 2020 2020 2020 2020 656c 6966 206d  ..        elif m
-00015390: 7367 203d 3d20 2273 7461 7465 5f64 6963  sg == "state_dic
-000153a0: 7422 3a0d 0a20 2020 2020 2020 2020 2020  t":..           
-000153b0: 2073 7461 7465 5f64 6963 7420 3d20 6463   state_dict = dc
-000153c0: 2e73 7461 7465 5f64 6963 7428 290d 0a20  .state_dict().. 
-000153d0: 2020 2020 2020 2020 2020 2023 2073 656e             # sen
-000153e0: 6420 7374 6174 655f 6469 6374 2074 6f20  d state_dict to 
-000153f0: 6370 7520 6669 7273 740d 0a20 2020 2020  cpu first..     
-00015400: 2020 2020 2020 2073 7461 7465 5f64 6963         state_dic
-00015410: 7420 3d20 7265 6375 7273 6976 655f 6d61  t = recursive_ma
-00015420: 705f 746f 5f63 7075 2873 7461 7465 5f64  p_to_cpu(state_d
-00015430: 6963 7429 0d0a 2020 2020 2020 2020 2020  ict)..          
-00015440: 2020 7069 7065 5f63 6869 6c64 2e73 656e    pipe_child.sen
-00015450: 6428 2873 7461 7465 5f64 6963 742c 2022  d((state_dict, "
-00015460: 7374 6174 655f 6469 6374 2229 290d 0a20  state_dict")).. 
-00015470: 2020 2020 2020 2020 2020 2068 6173 5f74             has_t
-00015480: 696d 6564 5f6f 7574 203d 2046 616c 7365  imed_out = False
-00015490: 0d0a 2020 2020 2020 2020 2020 2020 636f  ..            co
-000154a0: 6e74 696e 7565 0d0a 0d0a 2020 2020 2020  ntinue....      
-000154b0: 2020 656c 6966 206d 7367 203d 3d20 226c    elif msg == "l
-000154c0: 6f61 645f 7374 6174 655f 6469 6374 223a  oad_state_dict":
-000154d0: 0d0a 2020 2020 2020 2020 2020 2020 7374  ..            st
-000154e0: 6174 655f 6469 6374 203d 2064 6174 615f  ate_dict = data_
-000154f0: 696e 0d0a 2020 2020 2020 2020 2020 2020  in..            
-00015500: 6463 2e6c 6f61 645f 7374 6174 655f 6469  dc.load_state_di
-00015510: 6374 2873 7461 7465 5f64 6963 7429 0d0a  ct(state_dict)..
-00015520: 2020 2020 2020 2020 2020 2020 7069 7065              pipe
-00015530: 5f63 6869 6c64 2e73 656e 6428 286a 2c20  _child.send((j, 
-00015540: 226c 6f61 6465 6422 2929 0d0a 2020 2020  "loaded"))..    
-00015550: 2020 2020 2020 2020 6861 735f 7469 6d65          has_time
-00015560: 645f 6f75 7420 3d20 4661 6c73 650d 0a20  d_out = False.. 
-00015570: 2020 2020 2020 2020 2020 2063 6f6e 7469             conti
-00015580: 6e75 650d 0a0d 0a20 2020 2020 2020 2065  nue....        e
-00015590: 6c69 6620 6d73 6720 3d3d 2022 636c 6f73  lif msg == "clos
-000155a0: 6522 3a0d 0a20 2020 2020 2020 2020 2020  e":..           
-000155b0: 2064 656c 2074 656e 736f 7264 6963 742c   del tensordict,
-000155c0: 2064 6174 612c 2064 2c20 6461 7461 5f69   data, d, data_i
-000155d0: 6e0d 0a20 2020 2020 2020 2020 2020 2064  n..            d
-000155e0: 632e 7368 7574 646f 776e 2829 0d0a 2020  c.shutdown()..  
-000155f0: 2020 2020 2020 2020 2020 6465 6c20 6463            del dc
-00015600: 2c20 6463 5f69 7465 720d 0a20 2020 2020  , dc_iter..     
-00015610: 2020 2020 2020 2070 6970 655f 6368 696c         pipe_chil
-00015620: 642e 7365 6e64 2822 636c 6f73 6564 2229  d.send("closed")
-00015630: 0d0a 2020 2020 2020 2020 2020 2020 6966  ..            if
-00015640: 2076 6572 626f 7365 3a0d 0a20 2020 2020   verbose:..     
-00015650: 2020 2020 2020 2020 2020 2070 7269 6e74             print
-00015660: 2866 2263 6f6c 6c65 6374 6f72 207b 6964  (f"collector {id
-00015670: 787d 2063 6c6f 7365 6422 290d 0a20 2020  x} closed")..   
-00015680: 2020 2020 2020 2020 2062 7265 616b 0d0a           break..
-00015690: 0d0a 2020 2020 2020 2020 656c 7365 3a0d  ..        else:.
-000156a0: 0a20 2020 2020 2020 2020 2020 2072 6169  .            rai
-000156b0: 7365 2045 7863 6570 7469 6f6e 2866 2255  se Exception(f"U
-000156c0: 6e72 6563 6f67 6e69 7a65 6420 6d65 7373  nrecognized mess
-000156d0: 6167 6520 7b6d 7367 7d22 290d 0a         age {msg}")..
+00004c80: 2020 2020 2020 2022 7472 616a 5f69 6473         "traj_ids
+00004c90: 3a20 5465 6e73 6f72 2873 6861 7065 3d74  : Tensor(shape=t
+00004ca0: 6f72 6368 2e53 697a 6528 5b34 2c20 3530  orch.Size([4, 50
+00004cb0: 5d29 2c20 6465 7669 6365 3d63 7075 2c20  ]), device=cpu, 
+00004cc0: 6474 7970 653d 746f 7263 682e 696e 7436  dtype=torch.int6
+00004cd0: 342c 2069 735f 7368 6172 6564 3d46 616c  4, is_shared=Fal
+00004ce0: 7365 297d 2c0d 0a20 2020 2020 2020 2020  se)},..         
+00004cf0: 2020 2020 2020 2020 2020 2062 6174 6368             batch
+00004d00: 5f73 697a 653d 746f 7263 682e 5369 7a65  _size=torch.Size
+00004d10: 285b 342c 2035 305d 292c 0d0a 2020 2020  ([4, 50]),..    
+00004d20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004d30: 6465 7669 6365 3d63 7075 2c0d 0a20 2020  device=cpu,..   
+00004d40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004d50: 2069 735f 7368 6172 6564 3d46 616c 7365   is_shared=False
+00004d60: 292c 0d0a 2020 2020 2020 2020 2020 2020  ),..            
+00004d70: 2020 2020 646f 6e65 3a20 5465 6e73 6f72      done: Tensor
+00004d80: 2873 6861 7065 3d74 6f72 6368 2e53 697a  (shape=torch.Siz
+00004d90: 6528 5b34 2c20 3530 2c20 315d 292c 2064  e([4, 50, 1]), d
+00004da0: 6576 6963 653d 6370 752c 2064 7479 7065  evice=cpu, dtype
+00004db0: 3d74 6f72 6368 2e62 6f6f 6c2c 2069 735f  =torch.bool, is_
+00004dc0: 7368 6172 6564 3d46 616c 7365 292c 0d0a  shared=False),..
+00004dd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004de0: 6d61 736b 3a20 5465 6e73 6f72 2873 6861  mask: Tensor(sha
+00004df0: 7065 3d74 6f72 6368 2e53 697a 6528 5b34  pe=torch.Size([4
+00004e00: 2c20 3530 5d29 2c20 6465 7669 6365 3d63  , 50]), device=c
+00004e10: 7075 2c20 6474 7970 653d 746f 7263 682e  pu, dtype=torch.
+00004e20: 626f 6f6c 2c20 6973 5f73 6861 7265 643d  bool, is_shared=
+00004e30: 4661 6c73 6529 2c0d 0a20 2020 2020 2020  False),..       
+00004e40: 2020 2020 2020 2020 206e 6578 743a 2054           next: T
+00004e50: 656e 736f 7244 6963 7428 0d0a 2020 2020  ensorDict(..    
+00004e60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004e70: 6669 656c 6473 3d7b 0d0a 2020 2020 2020  fields={..      
+00004e80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004e90: 2020 6f62 7365 7276 6174 696f 6e3a 2054    observation: T
+00004ea0: 656e 736f 7228 7368 6170 653d 746f 7263  ensor(shape=torc
+00004eb0: 682e 5369 7a65 285b 342c 2035 302c 2033  h.Size([4, 50, 3
+00004ec0: 5d29 2c20 6465 7669 6365 3d63 7075 2c20  ]), device=cpu, 
+00004ed0: 6474 7970 653d 746f 7263 682e 666c 6f61  dtype=torch.floa
+00004ee0: 7433 322c 2069 735f 7368 6172 6564 3d46  t32, is_shared=F
+00004ef0: 616c 7365 297d 2c0d 0a20 2020 2020 2020  alse)},..       
+00004f00: 2020 2020 2020 2020 2020 2020 2062 6174               bat
+00004f10: 6368 5f73 697a 653d 746f 7263 682e 5369  ch_size=torch.Si
+00004f20: 7a65 285b 342c 2035 305d 292c 0d0a 2020  ze([4, 50]),..  
+00004f30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004f40: 2020 6465 7669 6365 3d63 7075 2c0d 0a20    device=cpu,.. 
+00004f50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004f60: 2020 2069 735f 7368 6172 6564 3d46 616c     is_shared=Fal
+00004f70: 7365 292c 0d0a 2020 2020 2020 2020 2020  se),..          
+00004f80: 2020 2020 2020 6f62 7365 7276 6174 696f        observatio
+00004f90: 6e3a 2054 656e 736f 7228 7368 6170 653d  n: Tensor(shape=
+00004fa0: 746f 7263 682e 5369 7a65 285b 342c 2035  torch.Size([4, 5
+00004fb0: 302c 2033 5d29 2c20 6465 7669 6365 3d63  0, 3]), device=c
+00004fc0: 7075 2c20 6474 7970 653d 746f 7263 682e  pu, dtype=torch.
+00004fd0: 666c 6f61 7433 322c 2069 735f 7368 6172  float32, is_shar
+00004fe0: 6564 3d46 616c 7365 292c 0d0a 2020 2020  ed=False),..    
+00004ff0: 2020 2020 2020 2020 2020 2020 7265 7761              rewa
+00005000: 7264 3a20 5465 6e73 6f72 2873 6861 7065  rd: Tensor(shape
+00005010: 3d74 6f72 6368 2e53 697a 6528 5b34 2c20  =torch.Size([4, 
+00005020: 3530 2c20 315d 292c 2064 6576 6963 653d  50, 1]), device=
+00005030: 6370 752c 2064 7479 7065 3d74 6f72 6368  cpu, dtype=torch
+00005040: 2e66 6c6f 6174 3332 2c20 6973 5f73 6861  .float32, is_sha
+00005050: 7265 643d 4661 6c73 6529 7d2c 0d0a 2020  red=False)},..  
+00005060: 2020 2020 2020 2020 2020 6261 7463 685f            batch_
+00005070: 7369 7a65 3d74 6f72 6368 2e53 697a 6528  size=torch.Size(
+00005080: 5b34 2c20 3530 5d29 2c0d 0a20 2020 2020  [4, 50]),..     
+00005090: 2020 2020 2020 2064 6576 6963 653d 6370         device=cp
+000050a0: 752c 0d0a 2020 2020 2020 2020 2020 2020  u,..            
+000050b0: 6973 5f73 6861 7265 643d 4661 6c73 6529  is_shared=False)
+000050c0: 0d0a 2020 2020 2020 2020 3e3e 3e20 6465  ..        >>> de
+000050d0: 6c20 636f 6c6c 6563 746f 720d 0a0d 0a20  l collector.... 
+000050e0: 2020 2054 6865 2063 6f6c 6c65 6374 6f72     The collector
+000050f0: 2064 656c 6976 6572 7320 6261 7463 6865   delivers batche
+00005100: 7320 6f66 2064 6174 6120 7468 6174 2061  s of data that a
+00005110: 7265 206d 6172 6b65 6420 7769 7468 2061  re marked with a
+00005120: 2060 6022 7469 6d65 2260 600d 0a20 2020   ``"time"``..   
+00005130: 2064 696d 656e 7369 6f6e 2e0d 0a0d 0a20   dimension..... 
+00005140: 2020 2045 7861 6d70 6c65 733a 0d0a 2020     Examples:..  
+00005150: 2020 2020 2020 3e3e 3e20 6173 7365 7274        >>> assert
+00005160: 2064 6174 612e 6e61 6d65 735b 2d31 5d20   data.names[-1] 
+00005170: 3d3d 2022 7469 6d65 220d 0a0d 0a20 2020  == "time"....   
+00005180: 2022 2222 0d0a 0d0a 2020 2020 6465 6620   """....    def 
+00005190: 5f5f 696e 6974 5f5f 280d 0a20 2020 2020  __init__(..     
+000051a0: 2020 2073 656c 662c 0d0a 2020 2020 2020     self,..      
+000051b0: 2020 6372 6561 7465 5f65 6e76 5f66 6e3a    create_env_fn:
+000051c0: 2055 6e69 6f6e 5b0d 0a20 2020 2020 2020   Union[..       
+000051d0: 2020 2020 2045 6e76 4261 7365 2c20 2245       EnvBase, "E
+000051e0: 6e76 4372 6561 746f 7222 2c20 5365 7175  nvCreator", Sequ
+000051f0: 656e 6365 5b43 616c 6c61 626c 655b 5b5d  ence[Callable[[]
+00005200: 2c20 456e 7642 6173 655d 5d20 2023 206e  , EnvBase]]  # n
+00005210: 6f71 613a 2046 3832 310d 0a20 2020 2020  oqa: F821..     
+00005220: 2020 205d 2c20 2023 206e 6f71 613a 2046     ],  # noqa: F
+00005230: 3832 310d 0a20 2020 2020 2020 2070 6f6c  821..        pol
+00005240: 6963 793a 204f 7074 696f 6e61 6c5b 0d0a  icy: Optional[..
+00005250: 2020 2020 2020 2020 2020 2020 556e 696f              Unio
+00005260: 6e5b 0d0a 2020 2020 2020 2020 2020 2020  n[..            
+00005270: 2020 2020 5465 6e73 6f72 4469 6374 4d6f      TensorDictMo
+00005280: 6475 6c65 2c0d 0a20 2020 2020 2020 2020  dule,..         
+00005290: 2020 2020 2020 2043 616c 6c61 626c 655b         Callable[
+000052a0: 5b54 656e 736f 7244 6963 7442 6173 655d  [TensorDictBase]
+000052b0: 2c20 5465 6e73 6f72 4469 6374 4261 7365  , TensorDictBase
+000052c0: 5d2c 0d0a 2020 2020 2020 2020 2020 2020  ],..            
+000052d0: 5d0d 0a20 2020 2020 2020 205d 2c0d 0a20  ]..        ],.. 
+000052e0: 2020 2020 2020 202a 2c0d 0a20 2020 2020         *,..     
+000052f0: 2020 2066 7261 6d65 735f 7065 725f 6261     frames_per_ba
+00005300: 7463 683a 2069 6e74 2c0d 0a20 2020 2020  tch: int,..     
+00005310: 2020 2074 6f74 616c 5f66 7261 6d65 733a     total_frames:
+00005320: 2069 6e74 2c0d 0a20 2020 2020 2020 2064   int,..        d
+00005330: 6576 6963 653a 2044 4556 4943 455f 5459  evice: DEVICE_TY
+00005340: 5049 4e47 203d 204e 6f6e 652c 0d0a 2020  PING = None,..  
+00005350: 2020 2020 2020 7374 6f72 696e 675f 6465        storing_de
+00005360: 7669 6365 3a20 4445 5649 4345 5f54 5950  vice: DEVICE_TYP
+00005370: 494e 4720 3d20 4e6f 6e65 2c0d 0a20 2020  ING = None,..   
+00005380: 2020 2020 2063 7265 6174 655f 656e 765f       create_env_
+00005390: 6b77 6172 6773 3a20 4f70 7469 6f6e 616c  kwargs: Optional
+000053a0: 5b64 6963 745d 203d 204e 6f6e 652c 0d0a  [dict] = None,..
+000053b0: 2020 2020 2020 2020 6d61 785f 6672 616d          max_fram
+000053c0: 6573 5f70 6572 5f74 7261 6a3a 2069 6e74  es_per_traj: int
+000053d0: 203d 202d 312c 0d0a 2020 2020 2020 2020   = -1,..        
+000053e0: 696e 6974 5f72 616e 646f 6d5f 6672 616d  init_random_fram
+000053f0: 6573 3a20 696e 7420 3d20 2d31 2c0d 0a20  es: int = -1,.. 
+00005400: 2020 2020 2020 2072 6573 6574 5f61 745f         reset_at_
+00005410: 6561 6368 5f69 7465 723a 2062 6f6f 6c20  each_iter: bool 
+00005420: 3d20 4661 6c73 652c 0d0a 2020 2020 2020  = False,..      
+00005430: 2020 706f 7374 7072 6f63 3a20 4f70 7469    postproc: Opti
+00005440: 6f6e 616c 5b43 616c 6c61 626c 655b 5b54  onal[Callable[[T
+00005450: 656e 736f 7244 6963 7442 6173 655d 2c20  ensorDictBase], 
+00005460: 5465 6e73 6f72 4469 6374 4261 7365 5d5d  TensorDictBase]]
+00005470: 203d 204e 6f6e 652c 0d0a 2020 2020 2020   = None,..      
+00005480: 2020 7370 6c69 745f 7472 616a 733a 204f    split_trajs: O
+00005490: 7074 696f 6e61 6c5b 626f 6f6c 5d20 3d20  ptional[bool] = 
+000054a0: 4e6f 6e65 2c0d 0a20 2020 2020 2020 2065  None,..        e
+000054b0: 7870 6c6f 7261 7469 6f6e 5f74 7970 653a  xploration_type:
+000054c0: 2045 7870 6c6f 7261 7469 6f6e 5479 7065   ExplorationType
+000054d0: 203d 2044 4546 4155 4c54 5f45 5850 4c4f   = DEFAULT_EXPLO
+000054e0: 5241 5449 4f4e 5f54 5950 452c 0d0a 2020  RATION_TYPE,..  
+000054f0: 2020 2020 2020 6578 706c 6f72 6174 696f        exploratio
+00005500: 6e5f 6d6f 6465 3d4e 6f6e 652c 0d0a 2020  n_mode=None,..  
+00005510: 2020 2020 2020 7265 7475 726e 5f73 616d        return_sam
+00005520: 655f 7464 3a20 626f 6f6c 203d 2046 616c  e_td: bool = Fal
+00005530: 7365 2c0d 0a20 2020 2020 2020 2072 6573  se,..        res
+00005540: 6574 5f77 6865 6e5f 646f 6e65 3a20 626f  et_when_done: bo
+00005550: 6f6c 203d 2054 7275 652c 0d0a 2020 2020  ol = True,..    
+00005560: 2020 2020 696e 7465 7272 7570 746f 723d      interruptor=
+00005570: 4e6f 6e65 2c0d 0a20 2020 2029 3a0d 0a20  None,..    ):.. 
+00005580: 2020 2020 2020 2073 656c 662e 636c 6f73         self.clos
+00005590: 6564 203d 2054 7275 650d 0a0d 0a20 2020  ed = True....   
+000055a0: 2020 2020 2065 7870 6c6f 7261 7469 6f6e       exploration
+000055b0: 5f74 7970 6520 3d20 5f63 6f6e 7665 7274  _type = _convert
+000055c0: 5f65 7870 6c6f 7261 7469 6f6e 5f74 7970  _exploration_typ
+000055d0: 6528 0d0a 2020 2020 2020 2020 2020 2020  e(..            
+000055e0: 6578 706c 6f72 6174 696f 6e5f 6d6f 6465  exploration_mode
+000055f0: 3d65 7870 6c6f 7261 7469 6f6e 5f6d 6f64  =exploration_mod
+00005600: 652c 2065 7870 6c6f 7261 7469 6f6e 5f74  e, exploration_t
+00005610: 7970 653d 6578 706c 6f72 6174 696f 6e5f  ype=exploration_
+00005620: 7479 7065 0d0a 2020 2020 2020 2020 290d  type..        ).
+00005630: 0a20 2020 2020 2020 2069 6620 6372 6561  .        if crea
+00005640: 7465 5f65 6e76 5f6b 7761 7267 7320 6973  te_env_kwargs is
+00005650: 204e 6f6e 653a 0d0a 2020 2020 2020 2020   None:..        
+00005660: 2020 2020 6372 6561 7465 5f65 6e76 5f6b      create_env_k
+00005670: 7761 7267 7320 3d20 7b7d 0d0a 2020 2020  wargs = {}..    
+00005680: 2020 2020 6966 206e 6f74 2069 7369 6e73      if not isins
+00005690: 7461 6e63 6528 6372 6561 7465 5f65 6e76  tance(create_env
+000056a0: 5f66 6e2c 2045 6e76 4261 7365 293a 0d0a  _fn, EnvBase):..
+000056b0: 2020 2020 2020 2020 2020 2020 656e 7620              env 
+000056c0: 3d20 6372 6561 7465 5f65 6e76 5f66 6e28  = create_env_fn(
+000056d0: 2a2a 6372 6561 7465 5f65 6e76 5f6b 7761  **create_env_kwa
+000056e0: 7267 7329 0d0a 2020 2020 2020 2020 656c  rgs)..        el
+000056f0: 7365 3a0d 0a20 2020 2020 2020 2020 2020  se:..           
+00005700: 2065 6e76 203d 2063 7265 6174 655f 656e   env = create_en
+00005710: 765f 666e 0d0a 2020 2020 2020 2020 2020  v_fn..          
+00005720: 2020 6966 2063 7265 6174 655f 656e 765f    if create_env_
+00005730: 6b77 6172 6773 3a0d 0a20 2020 2020 2020  kwargs:..       
+00005740: 2020 2020 2020 2020 2069 6620 6e6f 7420           if not 
+00005750: 6973 696e 7374 616e 6365 2865 6e76 2c20  isinstance(env, 
+00005760: 5f42 6174 6368 6564 456e 7629 3a0d 0a20  _BatchedEnv):.. 
+00005770: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005780: 2020 2072 6169 7365 2052 756e 7469 6d65     raise Runtime
+00005790: 4572 726f 7228 0d0a 2020 2020 2020 2020  Error(..        
+000057a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000057b0: 226b 7761 7267 7320 7765 7265 2070 6173  "kwargs were pas
+000057c0: 7365 6420 746f 2053 796e 6344 6174 6143  sed to SyncDataC
+000057d0: 6f6c 6c65 6374 6f72 2062 7574 2074 6865  ollector but the
+000057e0: 7920 6361 6e27 7420 6265 2073 6574 2022  y can't be set "
+000057f0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00005800: 2020 2020 2020 2020 2020 6622 6f6e 2065            f"on e
+00005810: 6e76 6972 6f6e 6d65 6e74 206f 6620 7479  nvironment of ty
+00005820: 7065 207b 7479 7065 2863 7265 6174 655f  pe {type(create_
+00005830: 656e 765f 666e 297d 2e22 0d0a 2020 2020  env_fn)}."..    
+00005840: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005850: 290d 0a20 2020 2020 2020 2020 2020 2020  )..             
+00005860: 2020 2065 6e76 2e75 7064 6174 655f 6b77     env.update_kw
+00005870: 6172 6773 2863 7265 6174 655f 656e 765f  args(create_env_
+00005880: 6b77 6172 6773 290d 0a0d 0a20 2020 2020  kwargs)....     
+00005890: 2020 2069 6620 7374 6f72 696e 675f 6465     if storing_de
+000058a0: 7669 6365 2069 7320 4e6f 6e65 3a0d 0a20  vice is None:.. 
+000058b0: 2020 2020 2020 2020 2020 2069 6620 6465             if de
+000058c0: 7669 6365 2069 7320 6e6f 7420 4e6f 6e65  vice is not None
+000058d0: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
+000058e0: 2020 2073 746f 7269 6e67 5f64 6576 6963     storing_devic
+000058f0: 6520 3d20 6465 7669 6365 0d0a 2020 2020  e = device..    
+00005900: 2020 2020 2020 2020 656c 6966 2070 6f6c          elif pol
+00005910: 6963 7920 6973 206e 6f74 204e 6f6e 653a  icy is not None:
+00005920: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00005930: 2020 7472 793a 0d0a 2020 2020 2020 2020    try:..        
+00005940: 2020 2020 2020 2020 2020 2020 706f 6c69              poli
+00005950: 6379 5f64 6576 6963 6520 3d20 6e65 7874  cy_device = next
+00005960: 2870 6f6c 6963 792e 7061 7261 6d65 7465  (policy.paramete
+00005970: 7273 2829 292e 6465 7669 6365 0d0a 2020  rs()).device..  
+00005980: 2020 2020 2020 2020 2020 2020 2020 6578                ex
+00005990: 6365 7074 2028 4174 7472 6962 7574 6545  cept (AttributeE
+000059a0: 7272 6f72 2c20 5374 6f70 4974 6572 6174  rror, StopIterat
+000059b0: 696f 6e29 3a0d 0a20 2020 2020 2020 2020  ion):..         
+000059c0: 2020 2020 2020 2020 2020 2070 6f6c 6963             polic
+000059d0: 795f 6465 7669 6365 203d 2074 6f72 6368  y_device = torch
+000059e0: 2e64 6576 6963 6528 2263 7075 2229 0d0a  .device("cpu")..
+000059f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005a00: 7374 6f72 696e 675f 6465 7669 6365 203d  storing_device =
+00005a10: 2070 6f6c 6963 795f 6465 7669 6365 0d0a   policy_device..
+00005a20: 2020 2020 2020 2020 2020 2020 656c 7365              else
+00005a30: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
+00005a40: 2020 2073 746f 7269 6e67 5f64 6576 6963     storing_devic
+00005a50: 6520 3d20 746f 7263 682e 6465 7669 6365  e = torch.device
+00005a60: 2822 6370 7522 290d 0a0d 0a20 2020 2020  ("cpu")....     
+00005a70: 2020 2073 656c 662e 7374 6f72 696e 675f     self.storing_
+00005a80: 6465 7669 6365 203d 2074 6f72 6368 2e64  device = torch.d
+00005a90: 6576 6963 6528 7374 6f72 696e 675f 6465  evice(storing_de
+00005aa0: 7669 6365 290d 0a20 2020 2020 2020 2073  vice)..        s
+00005ab0: 656c 662e 656e 763a 2045 6e76 4261 7365  elf.env: EnvBase
+00005ac0: 203d 2065 6e76 0d0a 2020 2020 2020 2020   = env..        
+00005ad0: 7365 6c66 2e63 6c6f 7365 6420 3d20 4661  self.closed = Fa
+00005ae0: 6c73 650d 0a20 2020 2020 2020 2073 656c  lse..        sel
+00005af0: 662e 7265 7365 745f 7768 656e 5f64 6f6e  f.reset_when_don
+00005b00: 6520 3d20 7265 7365 745f 7768 656e 5f64  e = reset_when_d
+00005b10: 6f6e 650d 0a20 2020 2020 2020 2073 656c  one..        sel
+00005b20: 662e 6e5f 656e 7620 3d20 7365 6c66 2e65  f.n_env = self.e
+00005b30: 6e76 2e62 6174 6368 5f73 697a 652e 6e75  nv.batch_size.nu
+00005b40: 6d65 6c28 290d 0a0d 0a20 2020 2020 2020  mel()....       
+00005b50: 2028 7365 6c66 2e70 6f6c 6963 792c 2073   (self.policy, s
+00005b60: 656c 662e 6465 7669 6365 2c20 7365 6c66  elf.device, self
+00005b70: 2e67 6574 5f77 6569 6768 7473 5f66 6e2c  .get_weights_fn,
+00005b80: 2920 3d20 7365 6c66 2e5f 6765 745f 706f  ) = self._get_po
+00005b90: 6c69 6379 5f61 6e64 5f64 6576 6963 6528  licy_and_device(
+00005ba0: 0d0a 2020 2020 2020 2020 2020 2020 706f  ..            po
+00005bb0: 6c69 6379 3d70 6f6c 6963 792c 0d0a 2020  licy=policy,..  
+00005bc0: 2020 2020 2020 2020 2020 6465 7669 6365            device
+00005bd0: 3d64 6576 6963 652c 0d0a 2020 2020 2020  =device,..      
+00005be0: 2020 2020 2020 6f62 7365 7276 6174 696f        observatio
+00005bf0: 6e5f 7370 6563 3d73 656c 662e 656e 762e  n_spec=self.env.
+00005c00: 6f62 7365 7276 6174 696f 6e5f 7370 6563  observation_spec
+00005c10: 2c0d 0a20 2020 2020 2020 2029 0d0a 2020  ,..        )..  
+00005c20: 2020 2020 2020 6966 2069 7369 6e73 7461        if isinsta
+00005c30: 6e63 6528 7365 6c66 2e70 6f6c 6963 792c  nce(self.policy,
+00005c40: 206e 6e2e 4d6f 6475 6c65 293a 0d0a 2020   nn.Module):..  
+00005c50: 2020 2020 2020 2020 2020 7365 6c66 2e70            self.p
+00005c60: 6f6c 6963 795f 7765 6967 6874 7320 3d20  olicy_weights = 
+00005c70: 5465 6e73 6f72 4469 6374 2864 6963 7428  TensorDict(dict(
+00005c80: 7365 6c66 2e70 6f6c 6963 792e 6e61 6d65  self.policy.name
+00005c90: 645f 7061 7261 6d65 7465 7273 2829 292c  d_parameters()),
+00005ca0: 205b 5d29 0d0a 2020 2020 2020 2020 656c   [])..        el
+00005cb0: 7365 3a0d 0a20 2020 2020 2020 2020 2020  se:..           
+00005cc0: 2073 656c 662e 706f 6c69 6379 5f77 6569   self.policy_wei
+00005cd0: 6768 7473 203d 2054 656e 736f 7244 6963  ghts = TensorDic
+00005ce0: 7428 7b7d 2c20 5b5d 290d 0a0d 0a20 2020  t({}, [])....   
+00005cf0: 2020 2020 2073 656c 662e 656e 763a 2045       self.env: E
+00005d00: 6e76 4261 7365 203d 2073 656c 662e 656e  nvBase = self.en
+00005d10: 762e 746f 2873 656c 662e 6465 7669 6365  v.to(self.device
+00005d20: 290d 0a20 2020 2020 2020 2073 656c 662e  )..        self.
+00005d30: 6d61 785f 6672 616d 6573 5f70 6572 5f74  max_frames_per_t
+00005d40: 7261 6a20 3d20 6d61 785f 6672 616d 6573  raj = max_frames
+00005d50: 5f70 6572 5f74 7261 6a0d 0a20 2020 2020  _per_traj..     
+00005d60: 2020 2069 6620 7365 6c66 2e6d 6178 5f66     if self.max_f
+00005d70: 7261 6d65 735f 7065 725f 7472 616a 203e  rames_per_traj >
+00005d80: 2030 3a0d 0a20 2020 2020 2020 2020 2020   0:..           
+00005d90: 2023 206c 6574 2773 2063 6865 636b 2074   # let's check t
+00005da0: 6861 7420 7468 6572 6520 6973 206e 6f20  hat there is no 
+00005db0: 5374 6570 436f 756e 7465 7220 7965 740d  StepCounter yet.
+00005dc0: 0a20 2020 2020 2020 2020 2020 2066 6f72  .            for
+00005dd0: 206b 6579 2069 6e20 7365 6c66 2e65 6e76   key in self.env
+00005de0: 2e6f 7574 7075 745f 7370 6563 2e6b 6579  .output_spec.key
+00005df0: 7328 5472 7565 2c20 5472 7565 293a 0d0a  s(True, True):..
+00005e00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005e10: 6966 2069 7369 6e73 7461 6e63 6528 6b65  if isinstance(ke
+00005e20: 792c 2073 7472 293a 0d0a 2020 2020 2020  y, str):..      
+00005e30: 2020 2020 2020 2020 2020 2020 2020 6b65                ke
+00005e40: 7920 3d20 286b 6579 2c29 0d0a 2020 2020  y = (key,)..    
+00005e50: 2020 2020 2020 2020 2020 2020 6966 2022              if "
+00005e60: 7472 756e 6361 7465 6422 2069 6e20 6b65  truncated" in ke
+00005e70: 793a 0d0a 2020 2020 2020 2020 2020 2020  y:..            
+00005e80: 2020 2020 2020 2020 7261 6973 6520 5661          raise Va
+00005e90: 6c75 6545 7272 6f72 280d 0a20 2020 2020  lueError(..     
+00005ea0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005eb0: 2020 2022 4120 2774 7275 6e63 6174 6564     "A 'truncated
+00005ec0: 2720 6b65 7920 6973 2061 6c72 6561 6479  ' key is already
+00005ed0: 2070 7265 7365 6e74 2069 6e20 7468 6520   present in the 
+00005ee0: 656e 7669 726f 6e6d 656e 7420 220d 0a20  environment ".. 
+00005ef0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005f00: 2020 2020 2020 2022 616e 6420 7468 6520         "and the 
+00005f10: 276d 6178 5f66 7261 6d65 735f 7065 725f  'max_frames_per_
+00005f20: 7472 616a 2720 6172 6775 6d65 6e74 206d  traj' argument m
+00005f30: 6179 2063 6f6e 666c 6963 7420 7769 7468  ay conflict with
+00005f40: 2022 0d0a 2020 2020 2020 2020 2020 2020   "..            
+00005f50: 2020 2020 2020 2020 2020 2020 2261 2027              "a '
+00005f60: 5374 6570 436f 756e 7465 7227 2074 6861  StepCounter' tha
+00005f70: 7420 6861 7320 616c 7265 6164 7920 6265  t has already be
+00005f80: 656e 2073 6574 2e20 220d 0a20 2020 2020  en set. "..     
+00005f90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005fa0: 2020 2022 506f 7373 6962 6c65 2073 6f6c     "Possible sol
+00005fb0: 7574 696f 6e73 3a20 5365 7420 6d61 785f  utions: Set max_
+00005fc0: 6672 616d 6573 5f70 6572 5f74 7261 6a20  frames_per_traj 
+00005fd0: 746f 2030 206f 7220 220d 0a20 2020 2020  to 0 or "..     
+00005fe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00005ff0: 2020 2022 7265 6d6f 7665 2074 6865 2053     "remove the S
+00006000: 7465 7043 6f75 6e74 6572 206c 696d 6974  tepCounter limit
+00006010: 2066 726f 6d20 7468 6520 656e 7669 726f   from the enviro
+00006020: 6e6d 656e 7420 7472 616e 7366 6f72 6d73  nment transforms
+00006030: 2e22 0d0a 2020 2020 2020 2020 2020 2020  ."..            
+00006040: 2020 2020 2020 2020 290d 0a20 2020 2020          )..     
+00006050: 2020 2020 2020 2065 6e76 203d 2073 656c         env = sel
+00006060: 662e 656e 7620 3d20 5472 616e 7366 6f72  f.env = Transfor
+00006070: 6d65 6445 6e76 280d 0a20 2020 2020 2020  medEnv(..       
+00006080: 2020 2020 2020 2020 2073 656c 662e 656e           self.en
+00006090: 762c 2053 7465 7043 6f75 6e74 6572 286d  v, StepCounter(m
+000060a0: 6178 5f73 7465 7073 3d73 656c 662e 6d61  ax_steps=self.ma
+000060b0: 785f 6672 616d 6573 5f70 6572 5f74 7261  x_frames_per_tra
+000060c0: 6a29 0d0a 2020 2020 2020 2020 2020 2020  j)..            
+000060d0: 290d 0a0d 0a20 2020 2020 2020 2069 6620  )....        if 
+000060e0: 746f 7461 6c5f 6672 616d 6573 2069 7320  total_frames is 
+000060f0: 4e6f 6e65 206f 7220 746f 7461 6c5f 6672  None or total_fr
+00006100: 616d 6573 203c 2030 3a0d 0a20 2020 2020  ames < 0:..     
+00006110: 2020 2020 2020 2074 6f74 616c 5f66 7261         total_fra
+00006120: 6d65 7320 3d20 666c 6f61 7428 2269 6e66  mes = float("inf
+00006130: 2229 0d0a 2020 2020 2020 2020 656c 7365  ")..        else
+00006140: 3a0d 0a20 2020 2020 2020 2020 2020 2072  :..            r
+00006150: 656d 6169 6e64 6572 203d 2074 6f74 616c  emainder = total
+00006160: 5f66 7261 6d65 7320 2520 6672 616d 6573  _frames % frames
+00006170: 5f70 6572 5f62 6174 6368 0d0a 2020 2020  _per_batch..    
+00006180: 2020 2020 2020 2020 6966 2072 656d 6169          if remai
+00006190: 6e64 6572 2021 3d20 3020 616e 6420 524c  nder != 0 and RL
+000061a0: 5f57 4152 4e49 4e47 533a 0d0a 2020 2020  _WARNINGS:..    
+000061b0: 2020 2020 2020 2020 2020 2020 7761 726e              warn
+000061c0: 696e 6773 2e77 6172 6e28 0d0a 2020 2020  ings.warn(..    
+000061d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000061e0: 6622 746f 7461 6c5f 6672 616d 6573 2028  f"total_frames (
+000061f0: 7b74 6f74 616c 5f66 7261 6d65 737d 2920  {total_frames}) 
+00006200: 6973 206e 6f74 2065 7861 6374 6c79 2064  is not exactly d
+00006210: 6976 6973 6962 6c65 2062 7920 6672 616d  ivisible by fram
+00006220: 6573 5f70 6572 5f62 6174 6368 2028 7b66  es_per_batch ({f
+00006230: 7261 6d65 735f 7065 725f 6261 7463 687d  rames_per_batch}
+00006240: 292e 220d 0a20 2020 2020 2020 2020 2020  )."..           
+00006250: 2020 2020 2020 2020 2066 2254 6869 7320           f"This 
+00006260: 6d65 616e 7320 7b66 7261 6d65 735f 7065  means {frames_pe
+00006270: 725f 6261 7463 6820 2d20 7265 6d61 696e  r_batch - remain
+00006280: 6465 727d 2061 6464 6974 696f 6e61 6c20  der} additional 
+00006290: 6672 616d 6573 2077 696c 6c20 6265 2063  frames will be c
+000062a0: 6f6c 6c65 6374 6564 2e22 0d0a 2020 2020  ollected."..    
+000062b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000062c0: 2254 6f20 7369 6c65 6e63 6520 7468 6973  "To silence this
+000062d0: 206d 6573 7361 6765 2c20 7365 7420 7468   message, set th
+000062e0: 6520 656e 7669 726f 6e6d 656e 7420 7661  e environment va
+000062f0: 7269 6162 6c65 2052 4c5f 5741 524e 494e  riable RL_WARNIN
+00006300: 4753 2074 6f20 4661 6c73 652e 220d 0a20  GS to False.".. 
+00006310: 2020 2020 2020 2020 2020 2020 2020 2029                 )
+00006320: 0d0a 2020 2020 2020 2020 7365 6c66 2e74  ..        self.t
+00006330: 6f74 616c 5f66 7261 6d65 7320 3d20 746f  otal_frames = to
+00006340: 7461 6c5f 6672 616d 6573 0d0a 2020 2020  tal_frames..    
+00006350: 2020 2020 7365 6c66 2e72 6573 6574 5f61      self.reset_a
+00006360: 745f 6561 6368 5f69 7465 7220 3d20 7265  t_each_iter = re
+00006370: 7365 745f 6174 5f65 6163 685f 6974 6572  set_at_each_iter
+00006380: 0d0a 2020 2020 2020 2020 7365 6c66 2e69  ..        self.i
+00006390: 6e69 745f 7261 6e64 6f6d 5f66 7261 6d65  nit_random_frame
+000063a0: 7320 3d20 696e 6974 5f72 616e 646f 6d5f  s = init_random_
+000063b0: 6672 616d 6573 0d0a 2020 2020 2020 2020  frames..        
+000063c0: 7365 6c66 2e70 6f73 7470 726f 6320 3d20  self.postproc = 
+000063d0: 706f 7374 7072 6f63 0d0a 2020 2020 2020  postproc..      
+000063e0: 2020 6966 2073 656c 662e 706f 7374 7072    if self.postpr
+000063f0: 6f63 2069 7320 6e6f 7420 4e6f 6e65 2061  oc is not None a
+00006400: 6e64 2068 6173 6174 7472 2873 656c 662e  nd hasattr(self.
+00006410: 706f 7374 7072 6f63 2c20 2274 6f22 293a  postproc, "to"):
+00006420: 0d0a 2020 2020 2020 2020 2020 2020 7365  ..            se
+00006430: 6c66 2e70 6f73 7470 726f 632e 746f 2873  lf.postproc.to(s
+00006440: 656c 662e 7374 6f72 696e 675f 6465 7669  elf.storing_devi
+00006450: 6365 290d 0a20 2020 2020 2020 2069 6620  ce)..        if 
+00006460: 6672 616d 6573 5f70 6572 5f62 6174 6368  frames_per_batch
+00006470: 2025 2073 656c 662e 6e5f 656e 7620 213d   % self.n_env !=
+00006480: 2030 2061 6e64 2052 4c5f 5741 524e 494e   0 and RL_WARNIN
+00006490: 4753 3a0d 0a20 2020 2020 2020 2020 2020  GS:..           
+000064a0: 2077 6172 6e69 6e67 732e 7761 726e 280d   warnings.warn(.
+000064b0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000064c0: 2066 2266 7261 6d65 735f 7065 725f 6261   f"frames_per_ba
+000064d0: 7463 6820 7b66 7261 6d65 735f 7065 725f  tch {frames_per_
+000064e0: 6261 7463 687d 2069 7320 6e6f 7420 6578  batch} is not ex
+000064f0: 6163 746c 7920 6469 7669 7369 626c 6520  actly divisible 
+00006500: 6279 2074 6865 206e 756d 6265 7220 6f66  by the number of
+00006510: 2062 6174 6368 6564 2065 6e76 6972 6f6e   batched environ
+00006520: 6d65 6e74 7320 7b73 656c 662e 6e5f 656e  ments {self.n_en
+00006530: 767d 2c20 220d 0a20 2020 2020 2020 2020  v}, "..         
+00006540: 2020 2020 2020 2066 2220 7468 6973 2072         f" this r
+00006550: 6573 756c 7473 2069 6e20 6d6f 7265 2066  esults in more f
+00006560: 7261 6d65 735f 7065 725f 6261 7463 6820  rames_per_batch 
+00006570: 7065 7220 6974 6572 6174 696f 6e20 7468  per iteration th
+00006580: 6174 2072 6571 7565 7374 6564 2e22 0d0a  at requested."..
+00006590: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000065a0: 2254 6f20 7369 6c65 6e63 6520 7468 6973  "To silence this
+000065b0: 206d 6573 7361 6765 2c20 7365 7420 7468   message, set th
+000065c0: 6520 656e 7669 726f 6e6d 656e 7420 7661  e environment va
+000065d0: 7269 6162 6c65 2052 4c5f 5741 524e 494e  riable RL_WARNIN
+000065e0: 4753 2074 6f20 4661 6c73 652e 220d 0a20  GS to False.".. 
+000065f0: 2020 2020 2020 2020 2020 2029 0d0a 2020             )..  
+00006600: 2020 2020 2020 7365 6c66 2e72 6571 7565        self.reque
+00006610: 7374 6564 5f66 7261 6d65 735f 7065 725f  sted_frames_per_
+00006620: 6261 7463 6820 3d20 6672 616d 6573 5f70  batch = frames_p
+00006630: 6572 5f62 6174 6368 0d0a 2020 2020 2020  er_batch..      
+00006640: 2020 7365 6c66 2e66 7261 6d65 735f 7065    self.frames_pe
+00006650: 725f 6261 7463 6820 3d20 2d28 2d66 7261  r_batch = -(-fra
+00006660: 6d65 735f 7065 725f 6261 7463 6820 2f2f  mes_per_batch //
+00006670: 2073 656c 662e 6e5f 656e 7629 0d0a 2020   self.n_env)..  
+00006680: 2020 2020 2020 7365 6c66 2e65 7870 6c6f        self.explo
+00006690: 7261 7469 6f6e 5f74 7970 6520 3d20 280d  ration_type = (.
+000066a0: 0a20 2020 2020 2020 2020 2020 2065 7870  .            exp
+000066b0: 6c6f 7261 7469 6f6e 5f74 7970 6520 6966  loration_type if
+000066c0: 2065 7870 6c6f 7261 7469 6f6e 5f74 7970   exploration_typ
+000066d0: 6520 656c 7365 2044 4546 4155 4c54 5f45  e else DEFAULT_E
+000066e0: 5850 4c4f 5241 5449 4f4e 5f54 5950 450d  XPLORATION_TYPE.
+000066f0: 0a20 2020 2020 2020 2029 0d0a 2020 2020  .        )..    
+00006700: 2020 2020 7365 6c66 2e72 6574 7572 6e5f      self.return_
+00006710: 7361 6d65 5f74 6420 3d20 7265 7475 726e  same_td = return
+00006720: 5f73 616d 655f 7464 0d0a 0d0a 2020 2020  _same_td....    
+00006730: 2020 2020 7365 6c66 2e5f 7465 6e73 6f72      self._tensor
+00006740: 6469 6374 203d 2065 6e76 2e72 6573 6574  dict = env.reset
+00006750: 2829 0d0a 2020 2020 2020 2020 7472 616a  ()..        traj
+00006760: 5f69 6473 203d 2074 6f72 6368 2e61 7261  _ids = torch.ara
+00006770: 6e67 6528 7365 6c66 2e6e 5f65 6e76 2c20  nge(self.n_env, 
+00006780: 6465 7669 6365 3d65 6e76 2e64 6576 6963  device=env.devic
+00006790: 6529 2e76 6965 7728 7365 6c66 2e65 6e76  e).view(self.env
+000067a0: 2e62 6174 6368 5f73 697a 6529 0d0a 2020  .batch_size)..  
+000067b0: 2020 2020 2020 7365 6c66 2e5f 7465 6e73        self._tens
+000067c0: 6f72 6469 6374 2e73 6574 280d 0a20 2020  ordict.set(..   
+000067d0: 2020 2020 2020 2020 2028 2263 6f6c 6c65           ("colle
+000067e0: 6374 6f72 222c 2022 7472 616a 5f69 6473  ctor", "traj_ids
+000067f0: 2229 2c0d 0a20 2020 2020 2020 2020 2020  "),..           
+00006800: 2074 7261 6a5f 6964 732c 0d0a 2020 2020   traj_ids,..    
+00006810: 2020 2020 290d 0a0d 0a20 2020 2020 2020      )....       
+00006820: 2077 6974 6820 746f 7263 682e 6e6f 5f67   with torch.no_g
+00006830: 7261 6428 293a 0d0a 2020 2020 2020 2020  rad():..        
+00006840: 2020 2020 7365 6c66 2e5f 7465 6e73 6f72      self._tensor
+00006850: 6469 6374 5f6f 7574 203d 2065 6e76 2e66  dict_out = env.f
+00006860: 616b 655f 7465 6e73 6f72 6469 6374 2829  ake_tensordict()
+00006870: 0d0a 2020 2020 2020 2020 6966 2028 0d0a  ..        if (..
+00006880: 2020 2020 2020 2020 2020 2020 6861 7361              hasa
+00006890: 7474 7228 7365 6c66 2e70 6f6c 6963 792c  ttr(self.policy,
+000068a0: 2022 7370 6563 2229 0d0a 2020 2020 2020   "spec")..      
+000068b0: 2020 2020 2020 616e 6420 7365 6c66 2e70        and self.p
+000068c0: 6f6c 6963 792e 7370 6563 2069 7320 6e6f  olicy.spec is no
+000068d0: 7420 4e6f 6e65 0d0a 2020 2020 2020 2020  t None..        
+000068e0: 2020 2020 616e 6420 616c 6c28 0d0a 2020      and all(..  
+000068f0: 2020 2020 2020 2020 2020 2020 2020 7620                v 
+00006900: 6973 206e 6f74 204e 6f6e 6520 666f 7220  is not None for 
+00006910: 7620 696e 2073 656c 662e 706f 6c69 6379  v in self.policy
+00006920: 2e73 7065 632e 7661 6c75 6573 2854 7275  .spec.values(Tru
+00006930: 652c 2054 7275 6529 0d0a 2020 2020 2020  e, True)..      
+00006940: 2020 2020 2020 2920 2023 2069 6620 6120        )  # if a 
+00006950: 7370 6563 2069 7320 4e6f 6e65 2c20 7765  spec is None, we
+00006960: 2064 6f6e 2774 206b 6e6f 7720 616e 7974   don't know anyt
+00006970: 6869 6e67 2061 626f 7574 2069 740d 0a20  hing about it.. 
+00006980: 2020 2020 2020 2020 2020 2023 2061 6e64             # and
+00006990: 2073 6574 2873 656c 662e 706f 6c69 6379   set(self.policy
+000069a0: 2e73 7065 632e 6b65 7973 2854 7275 652c  .spec.keys(True,
+000069b0: 2054 7275 6529 2920 3d3d 2073 6574 2873   True)) == set(s
+000069c0: 656c 662e 706f 6c69 6379 2e6f 7574 5f6b  elf.policy.out_k
+000069d0: 6579 7329 0d0a 2020 2020 2020 2020 2020  eys)..          
+000069e0: 2020 616e 6420 616e 7928 0d0a 2020 2020    and any(..    
+000069f0: 2020 2020 2020 2020 2020 2020 6b65 7920              key 
+00006a00: 6e6f 7420 696e 2073 656c 662e 5f74 656e  not in self._ten
+00006a10: 736f 7264 6963 745f 6f75 742e 6b65 7973  sordict_out.keys
+00006a20: 2869 7369 6e73 7461 6e63 6528 6b65 792c  (isinstance(key,
+00006a30: 2074 7570 6c65 2929 0d0a 2020 2020 2020   tuple))..      
+00006a40: 2020 2020 2020 2020 2020 666f 7220 6b65            for ke
+00006a50: 7920 696e 2073 656c 662e 706f 6c69 6379  y in self.policy
+00006a60: 2e73 7065 632e 6b65 7973 2854 7275 652c  .spec.keys(True,
+00006a70: 2054 7275 6529 0d0a 2020 2020 2020 2020   True)..        
+00006a80: 2020 2020 290d 0a20 2020 2020 2020 2029      )..        )
+00006a90: 3a0d 0a20 2020 2020 2020 2020 2020 2023  :..            #
+00006aa0: 2069 6620 706f 6c69 6379 2073 7065 6320   if policy spec 
+00006ab0: 6973 206e 6f6e 2d65 6d70 7479 2c20 616c  is non-empty, al
+00006ac0: 6c20 7468 6520 7661 6c75 6573 2061 7265  l the values are
+00006ad0: 206e 6f74 204e 6f6e 6520 616e 6420 7468   not None and th
+00006ae0: 6520 6b65 7973 0d0a 2020 2020 2020 2020  e keys..        
+00006af0: 2020 2020 2320 6d61 7463 6820 7468 6520      # match the 
+00006b00: 6f75 745f 6b65 7973 2077 6520 6173 7375  out_keys we assu
+00006b10: 6d65 2074 6865 2075 7365 7220 6861 7320  me the user has 
+00006b20: 6769 7665 6e20 616c 6c20 7265 6c65 7661  given all releva
+00006b30: 6e74 2069 6e66 6f72 6d61 7469 6f6e 0d0a  nt information..
+00006b40: 2020 2020 2020 2020 2020 2020 2320 7468              # th
+00006b50: 6520 706f 6c69 6379 2063 6f75 6c64 2068  e policy could h
+00006b60: 6176 6520 6d6f 7265 206b 6579 7320 7468  ave more keys th
+00006b70: 616e 2074 6865 2065 6e76 3a0d 0a20 2020  an the env:..   
+00006b80: 2020 2020 2020 2020 2070 6f6c 6963 795f           policy_
+00006b90: 7370 6563 203d 2073 656c 662e 706f 6c69  spec = self.poli
+00006ba0: 6379 2e73 7065 630d 0a20 2020 2020 2020  cy.spec..       
+00006bb0: 2020 2020 2069 6620 706f 6c69 6379 5f73       if policy_s
+00006bc0: 7065 632e 6e64 696d 203c 2073 656c 662e  pec.ndim < self.
+00006bd0: 5f74 656e 736f 7264 6963 745f 6f75 742e  _tensordict_out.
+00006be0: 6e64 696d 3a0d 0a20 2020 2020 2020 2020  ndim:..         
+00006bf0: 2020 2020 2020 2070 6f6c 6963 795f 7370         policy_sp
+00006c00: 6563 203d 2070 6f6c 6963 795f 7370 6563  ec = policy_spec
+00006c10: 2e65 7870 616e 6428 7365 6c66 2e5f 7465  .expand(self._te
+00006c20: 6e73 6f72 6469 6374 5f6f 7574 2e73 6861  nsordict_out.sha
+00006c30: 7065 290d 0a20 2020 2020 2020 2020 2020  pe)..           
+00006c40: 2066 6f72 206b 6579 2c20 7370 6563 2069   for key, spec i
+00006c50: 6e20 706f 6c69 6379 5f73 7065 632e 6974  n policy_spec.it
+00006c60: 656d 7328 5472 7565 2c20 5472 7565 293a  ems(True, True):
+00006c70: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00006c80: 2020 6966 206b 6579 2069 6e20 7365 6c66    if key in self
+00006c90: 2e5f 7465 6e73 6f72 6469 6374 5f6f 7574  ._tensordict_out
+00006ca0: 2e6b 6579 7328 6973 696e 7374 616e 6365  .keys(isinstance
+00006cb0: 286b 6579 2c20 7475 706c 6529 293a 0d0a  (key, tuple)):..
+00006cc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006cd0: 2020 2020 636f 6e74 696e 7565 0d0a 2020      continue..  
+00006ce0: 2020 2020 2020 2020 2020 2020 2020 7365                se
+00006cf0: 6c66 2e5f 7465 6e73 6f72 6469 6374 5f6f  lf._tensordict_o
+00006d00: 7574 2e73 6574 286b 6579 2c20 7370 6563  ut.set(key, spec
+00006d10: 2e7a 6572 6f28 2929 0d0a 2020 2020 2020  .zero())..      
+00006d20: 2020 2020 2020 7365 6c66 2e5f 7465 6e73        self._tens
+00006d30: 6f72 6469 6374 5f6f 7574 203d 2028 0d0a  ordict_out = (..
+00006d40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006d50: 7365 6c66 2e5f 7465 6e73 6f72 6469 6374  self._tensordict
+00006d60: 5f6f 7574 2e75 6e73 7175 6565 7a65 282d  _out.unsqueeze(-
+00006d70: 3129 0d0a 2020 2020 2020 2020 2020 2020  1)..            
+00006d80: 2020 2020 2e65 7870 616e 6428 2a65 6e76      .expand(*env
+00006d90: 2e62 6174 6368 5f73 697a 652c 2073 656c  .batch_size, sel
+00006da0: 662e 6672 616d 6573 5f70 6572 5f62 6174  f.frames_per_bat
+00006db0: 6368 290d 0a20 2020 2020 2020 2020 2020  ch)..           
+00006dc0: 2020 2020 202e 636c 6f6e 6528 290d 0a20       .clone().. 
+00006dd0: 2020 2020 2020 2020 2020 2029 0d0a 2020             )..  
+00006de0: 2020 2020 2020 656c 6966 2028 0d0a 2020        elif (..  
+00006df0: 2020 2020 2020 2020 2020 6861 7361 7474            hasatt
+00006e00: 7228 7365 6c66 2e70 6f6c 6963 792c 2022  r(self.policy, "
+00006e10: 7370 6563 2229 0d0a 2020 2020 2020 2020  spec")..        
+00006e20: 2020 2020 616e 6420 7365 6c66 2e70 6f6c      and self.pol
+00006e30: 6963 792e 7370 6563 2069 7320 6e6f 7420  icy.spec is not 
+00006e40: 4e6f 6e65 0d0a 2020 2020 2020 2020 2020  None..          
+00006e50: 2020 616e 6420 616c 6c28 7620 6973 206e    and all(v is n
+00006e60: 6f74 204e 6f6e 6520 666f 7220 7620 696e  ot None for v in
+00006e70: 2073 656c 662e 706f 6c69 6379 2e73 7065   self.policy.spe
+00006e80: 632e 7661 6c75 6573 2854 7275 652c 2054  c.values(True, T
+00006e90: 7275 6529 290d 0a20 2020 2020 2020 2020  rue))..         
+00006ea0: 2020 2061 6e64 2061 6c6c 280d 0a20 2020     and all(..   
+00006eb0: 2020 2020 2020 2020 2020 2020 206b 6579               key
+00006ec0: 2069 6e20 7365 6c66 2e5f 7465 6e73 6f72   in self._tensor
+00006ed0: 6469 6374 5f6f 7574 2e6b 6579 7328 6973  dict_out.keys(is
+00006ee0: 696e 7374 616e 6365 286b 6579 2c20 7475  instance(key, tu
+00006ef0: 706c 6529 290d 0a20 2020 2020 2020 2020  ple))..         
+00006f00: 2020 2020 2020 2066 6f72 206b 6579 2069         for key i
+00006f10: 6e20 7365 6c66 2e70 6f6c 6963 792e 7370  n self.policy.sp
+00006f20: 6563 2e6b 6579 7328 5472 7565 2c20 5472  ec.keys(True, Tr
+00006f30: 7565 290d 0a20 2020 2020 2020 2020 2020  ue)..           
+00006f40: 2029 0d0a 2020 2020 2020 2020 293a 0d0a   )..        ):..
+00006f50: 2020 2020 2020 2020 2020 2020 2320 7265              # re
+00006f60: 6163 6820 7468 6973 2069 6620 7468 6520  ach this if the 
+00006f70: 706f 6c69 6379 2068 6173 2073 7065 6373  policy has specs
+00006f80: 2061 6e64 2074 6865 7920 6d61 7463 6820   and they match 
+00006f90: 7769 7468 2074 6865 2066 616b 6520 7465  with the fake te
+00006fa0: 6e73 6f72 6469 6374 0d0a 2020 2020 2020  nsordict..      
+00006fb0: 2020 2020 2020 7365 6c66 2e5f 7465 6e73        self._tens
+00006fc0: 6f72 6469 6374 5f6f 7574 203d 2028 0d0a  ordict_out = (..
+00006fd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006fe0: 7365 6c66 2e5f 7465 6e73 6f72 6469 6374  self._tensordict
+00006ff0: 5f6f 7574 2e75 6e73 7175 6565 7a65 282d  _out.unsqueeze(-
+00007000: 3129 0d0a 2020 2020 2020 2020 2020 2020  1)..            
+00007010: 2020 2020 2e65 7870 616e 6428 2a65 6e76      .expand(*env
+00007020: 2e62 6174 6368 5f73 697a 652c 2073 656c  .batch_size, sel
+00007030: 662e 6672 616d 6573 5f70 6572 5f62 6174  f.frames_per_bat
+00007040: 6368 290d 0a20 2020 2020 2020 2020 2020  ch)..           
+00007050: 2020 2020 202e 636c 6f6e 6528 290d 0a20       .clone().. 
+00007060: 2020 2020 2020 2020 2020 2029 0d0a 2020             )..  
+00007070: 2020 2020 2020 656c 7365 3a0d 0a20 2020        else:..   
+00007080: 2020 2020 2020 2020 2023 206f 7468 6572           # other
+00007090: 7769 7365 2c20 7765 2070 6572 666f 726d  wise, we perform
+000070a0: 2061 2073 6d61 6c6c 206e 756d 6265 7220   a small number 
+000070b0: 6f66 2073 7465 7073 2077 6974 6820 7468  of steps with th
+000070c0: 6520 706f 6c69 6379 2074 6f0d 0a20 2020  e policy to..   
+000070d0: 2020 2020 2020 2020 2023 2064 6574 6572           # deter
+000070e0: 6d69 6e65 2074 6865 2072 656c 6576 616e  mine the relevan
+000070f0: 7420 6b65 7973 2077 6974 6820 7768 6963  t keys with whic
+00007100: 6820 746f 2070 7265 2d70 6f70 756c 6174  h to pre-populat
+00007110: 6520 5f74 656e 736f 7264 6963 745f 6f75  e _tensordict_ou
+00007120: 742e 0d0a 2020 2020 2020 2020 2020 2020  t...            
+00007130: 2320 5468 6973 2069 7320 7468 6520 7361  # This is the sa
+00007140: 6665 7374 2074 6869 6e67 2074 6f20 646f  fest thing to do
+00007150: 2069 6620 7468 6520 7370 6563 2068 6173   if the spec has
+00007160: 204e 6f6e 6520 6669 656c 6473 206f 7220   None fields or 
+00007170: 6966 2074 6865 7265 2069 730d 0a20 2020  if there is..   
+00007180: 2020 2020 2020 2020 2023 206e 6f20 7370           # no sp
+00007190: 6563 2061 7420 616c 6c2e 0d0a 2020 2020  ec at all...    
+000071a0: 2020 2020 2020 2020 2320 5365 6520 2335          # See #5
+000071b0: 3035 2066 6f72 2061 6464 6974 696f 6e61  05 for additiona
+000071c0: 6c20 636f 6e74 6578 742e 0d0a 2020 2020  l context...    
+000071d0: 2020 2020 2020 2020 7769 7468 2074 6f72          with tor
+000071e0: 6368 2e6e 6f5f 6772 6164 2829 3a0d 0a20  ch.no_grad():.. 
+000071f0: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+00007200: 656c 662e 5f74 656e 736f 7264 6963 745f  elf._tensordict_
+00007210: 6f75 7420 3d20 7365 6c66 2e5f 7465 6e73  out = self._tens
+00007220: 6f72 6469 6374 5f6f 7574 2e74 6f28 7365  ordict_out.to(se
+00007230: 6c66 2e64 6576 6963 6529 0d0a 2020 2020  lf.device)..    
+00007240: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+00007250: 2e5f 7465 6e73 6f72 6469 6374 5f6f 7574  ._tensordict_out
+00007260: 203d 2073 656c 662e 706f 6c69 6379 2873   = self.policy(s
+00007270: 656c 662e 5f74 656e 736f 7264 6963 745f  elf._tensordict_
+00007280: 6f75 7429 2e75 6e73 7175 6565 7a65 282d  out).unsqueeze(-
+00007290: 3129 0d0a 2020 2020 2020 2020 2020 2020  1)..            
+000072a0: 7365 6c66 2e5f 7465 6e73 6f72 6469 6374  self._tensordict
+000072b0: 5f6f 7574 203d 2028 0d0a 2020 2020 2020  _out = (..      
+000072c0: 2020 2020 2020 2020 2020 7365 6c66 2e5f            self._
+000072d0: 7465 6e73 6f72 6469 6374 5f6f 7574 2e65  tensordict_out.e
+000072e0: 7870 616e 6428 2a65 6e76 2e62 6174 6368  xpand(*env.batch
+000072f0: 5f73 697a 652c 2073 656c 662e 6672 616d  _size, self.fram
+00007300: 6573 5f70 6572 5f62 6174 6368 290d 0a20  es_per_batch).. 
+00007310: 2020 2020 2020 2020 2020 2020 2020 202e                 .
+00007320: 636c 6f6e 6528 290d 0a20 2020 2020 2020  clone()..       
+00007330: 2020 2020 2020 2020 202e 7a65 726f 5f28           .zero_(
+00007340: 290d 0a20 2020 2020 2020 2020 2020 2029  )..            )
+00007350: 0d0a 2020 2020 2020 2020 2320 696e 2061  ..        # in a
+00007360: 6464 6974 696f 6e20 746f 206f 7574 7075  ddition to outpu
+00007370: 7473 206f 6620 7468 6520 706f 6c69 6379  ts of the policy
+00007380: 2c20 7765 2061 6464 2074 7261 6a5f 6964  , we add traj_id
+00007390: 7320 616e 6420 7374 6570 5f63 6f75 6e74  s and step_count
+000073a0: 2074 6f0d 0a20 2020 2020 2020 2023 205f   to..        # _
+000073b0: 7465 6e73 6f72 6469 6374 5f6f 7574 2077  tensordict_out w
+000073c0: 6869 6368 2077 696c 6c20 6265 2063 6f6c  hich will be col
+000073d0: 6c65 6374 6564 2064 7572 696e 6720 726f  lected during ro
+000073e0: 6c6c 6f75 740d 0a20 2020 2020 2020 2073  llout..        s
+000073f0: 656c 662e 5f74 656e 736f 7264 6963 745f  elf._tensordict_
+00007400: 6f75 7420 3d20 7365 6c66 2e5f 7465 6e73  out = self._tens
+00007410: 6f72 6469 6374 5f6f 7574 2e74 6f28 7365  ordict_out.to(se
+00007420: 6c66 2e73 746f 7269 6e67 5f64 6576 6963  lf.storing_devic
+00007430: 6529 0d0a 2020 2020 2020 2020 7365 6c66  e)..        self
+00007440: 2e5f 7465 6e73 6f72 6469 6374 5f6f 7574  ._tensordict_out
+00007450: 2e73 6574 280d 0a20 2020 2020 2020 2020  .set(..         
+00007460: 2020 2028 2263 6f6c 6c65 6374 6f72 222c     ("collector",
+00007470: 2022 7472 616a 5f69 6473 2229 2c0d 0a20   "traj_ids"),.. 
+00007480: 2020 2020 2020 2020 2020 2074 6f72 6368             torch
+00007490: 2e7a 6572 6f73 280d 0a20 2020 2020 2020  .zeros(..       
+000074a0: 2020 2020 2020 2020 202a 7365 6c66 2e5f           *self._
+000074b0: 7465 6e73 6f72 6469 6374 5f6f 7574 2e62  tensordict_out.b
+000074c0: 6174 6368 5f73 697a 652c 0d0a 2020 2020  atch_size,..    
+000074d0: 2020 2020 2020 2020 2020 2020 6474 7970              dtyp
+000074e0: 653d 746f 7263 682e 696e 7436 342c 0d0a  e=torch.int64,..
+000074f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007500: 6465 7669 6365 3d73 656c 662e 7374 6f72  device=self.stor
+00007510: 696e 675f 6465 7669 6365 2c0d 0a20 2020  ing_device,..   
+00007520: 2020 2020 2020 2020 2029 2c0d 0a20 2020           ),..   
+00007530: 2020 2020 2029 0d0a 2020 2020 2020 2020       )..        
+00007540: 7365 6c66 2e5f 7465 6e73 6f72 6469 6374  self._tensordict
+00007550: 5f6f 7574 2e72 6566 696e 655f 6e61 6d65  _out.refine_name
+00007560: 7328 2e2e 2e2c 2022 7469 6d65 2229 0d0a  s(..., "time")..
+00007570: 0d0a 2020 2020 2020 2020 6966 2073 706c  ..        if spl
+00007580: 6974 5f74 7261 6a73 2069 7320 4e6f 6e65  it_trajs is None
+00007590: 3a0d 0a20 2020 2020 2020 2020 2020 2073  :..            s
+000075a0: 706c 6974 5f74 7261 6a73 203d 2046 616c  plit_trajs = Fal
+000075b0: 7365 0d0a 2020 2020 2020 2020 656c 6966  se..        elif
+000075c0: 206e 6f74 2073 656c 662e 7265 7365 745f   not self.reset_
+000075d0: 7768 656e 5f64 6f6e 6520 616e 6420 7370  when_done and sp
+000075e0: 6c69 745f 7472 616a 733a 0d0a 2020 2020  lit_trajs:..    
+000075f0: 2020 2020 2020 2020 7261 6973 6520 5275          raise Ru
+00007600: 6e74 696d 6545 7272 6f72 280d 0a20 2020  ntimeError(..   
+00007610: 2020 2020 2020 2020 2020 2020 2022 4361               "Ca
+00007620: 6e6e 6f74 2073 706c 6974 2074 7261 6a65  nnot split traje
+00007630: 6374 6f72 6965 7320 7768 656e 2072 6573  ctories when res
+00007640: 6574 5f77 6865 6e5f 646f 6e65 2069 7320  et_when_done is 
+00007650: 4661 6c73 652e 220d 0a20 2020 2020 2020  False."..       
+00007660: 2020 2020 2029 0d0a 2020 2020 2020 2020       )..        
+00007670: 7365 6c66 2e73 706c 6974 5f74 7261 6a73  self.split_trajs
+00007680: 203d 2073 706c 6974 5f74 7261 6a73 0d0a   = split_trajs..
+00007690: 2020 2020 2020 2020 7365 6c66 2e5f 6578          self._ex
+000076a0: 636c 7564 655f 7072 6976 6174 655f 6b65  clude_private_ke
+000076b0: 7973 203d 2054 7275 650d 0a20 2020 2020  ys = True..     
+000076c0: 2020 2073 656c 662e 696e 7465 7272 7570     self.interrup
+000076d0: 746f 7220 3d20 696e 7465 7272 7570 746f  tor = interrupto
+000076e0: 720d 0a0d 0a20 2020 2023 2066 6f72 2052  r....    # for R
+000076f0: 5043 0d0a 2020 2020 6465 6620 6e65 7874  PC..    def next
+00007700: 2873 656c 6629 3a0d 0a20 2020 2020 2020  (self):..       
+00007710: 2072 6574 7572 6e20 7375 7065 7228 292e   return super().
+00007720: 6e65 7874 2829 0d0a 0d0a 2020 2020 2320  next()....    # 
+00007730: 666f 7220 5250 430d 0a20 2020 2064 6566  for RPC..    def
+00007740: 2075 7064 6174 655f 706f 6c69 6379 5f77   update_policy_w
+00007750: 6569 6768 7473 5f28 0d0a 2020 2020 2020  eights_(..      
+00007760: 2020 7365 6c66 2c20 706f 6c69 6379 5f77    self, policy_w
+00007770: 6569 6768 7473 3a20 4f70 7469 6f6e 616c  eights: Optional
+00007780: 5b54 656e 736f 7244 6963 7442 6173 655d  [TensorDictBase]
+00007790: 203d 204e 6f6e 650d 0a20 2020 2029 202d   = None..    ) -
+000077a0: 3e20 4e6f 6e65 3a0d 0a20 2020 2020 2020  > None:..       
+000077b0: 2073 7570 6572 2829 2e75 7064 6174 655f   super().update_
+000077c0: 706f 6c69 6379 5f77 6569 6768 7473 5f28  policy_weights_(
+000077d0: 706f 6c69 6379 5f77 6569 6768 7473 290d  policy_weights).
+000077e0: 0a0d 0a20 2020 2064 6566 2073 6574 5f73  ...    def set_s
+000077f0: 6565 6428 7365 6c66 2c20 7365 6564 3a20  eed(self, seed: 
+00007800: 696e 742c 2073 7461 7469 635f 7365 6564  int, static_seed
+00007810: 3a20 626f 6f6c 203d 2046 616c 7365 2920  : bool = False) 
+00007820: 2d3e 2069 6e74 3a0d 0a20 2020 2020 2020  -> int:..       
+00007830: 2022 2222 5365 7473 2074 6865 2073 6565   """Sets the see
+00007840: 6473 206f 6620 7468 6520 656e 7669 726f  ds of the enviro
+00007850: 6e6d 656e 7473 2073 746f 7265 6420 696e  nments stored in
+00007860: 2074 6865 2044 6174 6143 6f6c 6c65 6374   the DataCollect
+00007870: 6f72 2e0d 0a0d 0a20 2020 2020 2020 2041  or.....        A
+00007880: 7267 733a 0d0a 2020 2020 2020 2020 2020  rgs:..          
+00007890: 2020 7365 6564 2028 696e 7429 3a20 696e    seed (int): in
+000078a0: 7465 6765 7220 7265 7072 6573 656e 7469  teger representi
+000078b0: 6e67 2074 6865 2073 6565 6420 746f 2062  ng the seed to b
+000078c0: 6520 7573 6564 2066 6f72 2074 6865 2065  e used for the e
+000078d0: 6e76 6972 6f6e 6d65 6e74 2e0d 0a20 2020  nvironment...   
+000078e0: 2020 2020 2020 2020 2073 7461 7469 635f           static_
+000078f0: 7365 6564 2862 6f6f 6c2c 206f 7074 696f  seed(bool, optio
+00007900: 6e61 6c29 3a20 6966 2060 6054 7275 6560  nal): if ``True`
+00007910: 602c 2074 6865 2073 6565 6420 6973 206e  `, the seed is n
+00007920: 6f74 2069 6e63 7265 6d65 6e74 6564 2e0d  ot incremented..
+00007930: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00007940: 2044 6566 6175 6c74 7320 746f 2046 616c   Defaults to Fal
+00007950: 7365 0d0a 0d0a 2020 2020 2020 2020 5265  se....        Re
+00007960: 7475 726e 733a 0d0a 2020 2020 2020 2020  turns:..        
+00007970: 2020 2020 4f75 7470 7574 2073 6565 642e      Output seed.
+00007980: 2054 6869 7320 6973 2075 7365 6675 6c20   This is useful 
+00007990: 7768 656e 206d 6f72 6520 7468 616e 206f  when more than o
+000079a0: 6e65 2065 6e76 6972 6f6e 6d65 6e74 2069  ne environment i
+000079b0: 7320 636f 6e74 6169 6e65 6420 696e 2074  s contained in t
+000079c0: 6865 2044 6174 6143 6f6c 6c65 6374 6f72  he DataCollector
+000079d0: 2c20 6173 2074 6865 0d0a 2020 2020 2020  , as the..      
+000079e0: 2020 2020 2020 7365 6564 2077 696c 6c20        seed will 
+000079f0: 6265 2069 6e63 7265 6d65 6e74 6564 2066  be incremented f
+00007a00: 6f72 2065 6163 6820 6f66 2074 6865 7365  or each of these
+00007a10: 2e20 5468 6520 7265 7375 6c74 696e 6720  . The resulting 
+00007a20: 7365 6564 2069 7320 7468 6520 7365 6564  seed is the seed
+00007a30: 206f 6620 7468 6520 6c61 7374 2065 6e76   of the last env
+00007a40: 6972 6f6e 6d65 6e74 2e0d 0a0d 0a20 2020  ironment.....   
+00007a50: 2020 2020 2045 7861 6d70 6c65 733a 0d0a       Examples:..
+00007a60: 2020 2020 2020 2020 2020 2020 3e3e 3e20              >>> 
+00007a70: 6672 6f6d 2074 6f72 6368 726c 2e65 6e76  from torchrl.env
+00007a80: 7320 696d 706f 7274 2050 6172 616c 6c65  s import Paralle
+00007a90: 6c45 6e76 0d0a 2020 2020 2020 2020 2020  lEnv..          
+00007aa0: 2020 3e3e 3e20 6672 6f6d 2074 6f72 6368    >>> from torch
+00007ab0: 726c 2e65 6e76 732e 6c69 6273 2e67 796d  rl.envs.libs.gym
+00007ac0: 2069 6d70 6f72 7420 4779 6d45 6e76 0d0a   import GymEnv..
+00007ad0: 2020 2020 2020 2020 2020 2020 3e3e 3e20              >>> 
+00007ae0: 656e 765f 666e 203d 206c 616d 6264 613a  env_fn = lambda:
+00007af0: 2047 796d 456e 7628 2250 656e 6475 6c75   GymEnv("Pendulu
+00007b00: 6d2d 7631 2229 0d0a 2020 2020 2020 2020  m-v1")..        
+00007b10: 2020 2020 3e3e 3e20 656e 765f 666e 5f70      >>> env_fn_p
+00007b20: 6172 616c 6c65 6c20 3d20 5061 7261 6c6c  arallel = Parall
+00007b30: 656c 456e 7628 362c 2065 6e76 5f66 6e29  elEnv(6, env_fn)
+00007b40: 0d0a 2020 2020 2020 2020 2020 2020 3e3e  ..            >>
+00007b50: 3e20 636f 6c6c 6563 746f 7220 3d20 5379  > collector = Sy
+00007b60: 6e63 4461 7461 436f 6c6c 6563 746f 7228  ncDataCollector(
+00007b70: 656e 765f 666e 5f70 6172 616c 6c65 6c29  env_fn_parallel)
+00007b80: 0d0a 2020 2020 2020 2020 2020 2020 3e3e  ..            >>
+00007b90: 3e20 6f75 745f 7365 6564 203d 2063 6f6c  > out_seed = col
+00007ba0: 6c65 6374 6f72 2e73 6574 5f73 6565 6428  lector.set_seed(
+00007bb0: 3129 2020 2320 6f75 745f 7365 6564 203d  1)  # out_seed =
+00007bc0: 2036 0d0a 0d0a 2020 2020 2020 2020 2222   6....        ""
+00007bd0: 220d 0a20 2020 2020 2020 2072 6574 7572  "..        retur
+00007be0: 6e20 7365 6c66 2e65 6e76 2e73 6574 5f73  n self.env.set_s
+00007bf0: 6565 6428 7365 6564 2c20 7374 6174 6963  eed(seed, static
+00007c00: 5f73 6565 643d 7374 6174 6963 5f73 6565  _seed=static_see
+00007c10: 6429 0d0a 0d0a 2020 2020 6465 6620 6974  d)....    def it
+00007c20: 6572 6174 6f72 2873 656c 6629 202d 3e20  erator(self) -> 
+00007c30: 4974 6572 6174 6f72 5b54 656e 736f 7244  Iterator[TensorD
+00007c40: 6963 7442 6173 655d 3a0d 0a20 2020 2020  ictBase]:..     
+00007c50: 2020 2022 2222 4974 6572 6174 6573 2074     """Iterates t
+00007c60: 6872 6f75 6768 2074 6865 2044 6174 6143  hrough the DataC
+00007c70: 6f6c 6c65 6374 6f72 2e0d 0a0d 0a20 2020  ollector.....   
+00007c80: 2020 2020 2059 6965 6c64 733a 2054 656e       Yields: Ten
+00007c90: 736f 7244 6963 7442 6173 6520 6f62 6a65  sorDictBase obje
+00007ca0: 6374 7320 636f 6e74 6169 6e69 6e67 2028  cts containing (
+00007cb0: 6368 756e 6b73 206f 6629 2074 7261 6a65  chunks of) traje
+00007cc0: 6374 6f72 6965 730d 0a0d 0a20 2020 2020  ctories....     
+00007cd0: 2020 2022 2222 0d0a 2020 2020 2020 2020     """..        
+00007ce0: 746f 7461 6c5f 6672 616d 6573 203d 2073  total_frames = s
+00007cf0: 656c 662e 746f 7461 6c5f 6672 616d 6573  elf.total_frames
+00007d00: 0d0a 2020 2020 2020 2020 6920 3d20 2d31  ..        i = -1
+00007d10: 0d0a 2020 2020 2020 2020 7365 6c66 2e5f  ..        self._
+00007d20: 6672 616d 6573 203d 2030 0d0a 2020 2020  frames = 0..    
+00007d30: 2020 2020 7768 696c 6520 5472 7565 3a0d      while True:.
+00007d40: 0a20 2020 2020 2020 2020 2020 2069 202b  .            i +
+00007d50: 3d20 310d 0a20 2020 2020 2020 2020 2020  = 1..           
+00007d60: 2073 656c 662e 5f69 7465 7220 3d20 690d   self._iter = i.
+00007d70: 0a20 2020 2020 2020 2020 2020 2074 656e  .            ten
+00007d80: 736f 7264 6963 745f 6f75 7420 3d20 7365  sordict_out = se
+00007d90: 6c66 2e72 6f6c 6c6f 7574 2829 0d0a 2020  lf.rollout()..  
+00007da0: 2020 2020 2020 2020 2020 7365 6c66 2e5f            self._
+00007db0: 6672 616d 6573 202b 3d20 7465 6e73 6f72  frames += tensor
+00007dc0: 6469 6374 5f6f 7574 2e6e 756d 656c 2829  dict_out.numel()
+00007dd0: 0d0a 2020 2020 2020 2020 2020 2020 6966  ..            if
+00007de0: 2073 656c 662e 5f66 7261 6d65 7320 3e3d   self._frames >=
+00007df0: 2074 6f74 616c 5f66 7261 6d65 733a 0d0a   total_frames:..
+00007e00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007e10: 7365 6c66 2e65 6e76 2e63 6c6f 7365 2829  self.env.close()
+00007e20: 0d0a 0d0a 2020 2020 2020 2020 2020 2020  ....            
+00007e30: 6966 2073 656c 662e 7370 6c69 745f 7472  if self.split_tr
+00007e40: 616a 733a 0d0a 2020 2020 2020 2020 2020  ajs:..          
+00007e50: 2020 2020 2020 7465 6e73 6f72 6469 6374        tensordict
+00007e60: 5f6f 7574 203d 2073 706c 6974 5f74 7261  _out = split_tra
+00007e70: 6a65 6374 6f72 6965 7328 7465 6e73 6f72  jectories(tensor
+00007e80: 6469 6374 5f6f 7574 2c20 7072 6566 6978  dict_out, prefix
+00007e90: 3d22 636f 6c6c 6563 746f 7222 290d 0a20  ="collector").. 
+00007ea0: 2020 2020 2020 2020 2020 2069 6620 7365             if se
+00007eb0: 6c66 2e70 6f73 7470 726f 6320 6973 206e  lf.postproc is n
+00007ec0: 6f74 204e 6f6e 653a 0d0a 2020 2020 2020  ot None:..      
+00007ed0: 2020 2020 2020 2020 2020 7465 6e73 6f72            tensor
+00007ee0: 6469 6374 5f6f 7574 203d 2073 656c 662e  dict_out = self.
+00007ef0: 706f 7374 7072 6f63 2874 656e 736f 7264  postproc(tensord
+00007f00: 6963 745f 6f75 7429 0d0a 2020 2020 2020  ict_out)..      
+00007f10: 2020 2020 2020 6966 2073 656c 662e 5f65        if self._e
+00007f20: 7863 6c75 6465 5f70 7269 7661 7465 5f6b  xclude_private_k
+00007f30: 6579 733a 0d0a 2020 2020 2020 2020 2020  eys:..          
+00007f40: 2020 2020 2020 6578 636c 7564 6564 5f6b        excluded_k
+00007f50: 6579 7320 3d20 5b0d 0a20 2020 2020 2020  eys = [..       
+00007f60: 2020 2020 2020 2020 2020 2020 206b 6579               key
+00007f70: 2066 6f72 206b 6579 2069 6e20 7465 6e73   for key in tens
+00007f80: 6f72 6469 6374 5f6f 7574 2e6b 6579 7328  ordict_out.keys(
+00007f90: 2920 6966 206b 6579 2e73 7461 7274 7377  ) if key.startsw
+00007fa0: 6974 6828 225f 2229 0d0a 2020 2020 2020  ith("_")..      
+00007fb0: 2020 2020 2020 2020 2020 5d0d 0a20 2020            ]..   
+00007fc0: 2020 2020 2020 2020 2020 2020 2074 656e               ten
+00007fd0: 736f 7264 6963 745f 6f75 7420 3d20 7465  sordict_out = te
+00007fe0: 6e73 6f72 6469 6374 5f6f 7574 2e65 7863  nsordict_out.exc
+00007ff0: 6c75 6465 282a 6578 636c 7564 6564 5f6b  lude(*excluded_k
+00008000: 6579 732c 2069 6e70 6c61 6365 3d54 7275  eys, inplace=Tru
+00008010: 6529 0d0a 2020 2020 2020 2020 2020 2020  e)..            
+00008020: 6966 2073 656c 662e 7265 7475 726e 5f73  if self.return_s
+00008030: 616d 655f 7464 3a0d 0a20 2020 2020 2020  ame_td:..       
+00008040: 2020 2020 2020 2020 2079 6965 6c64 2074           yield t
+00008050: 656e 736f 7264 6963 745f 6f75 740d 0a20  ensordict_out.. 
+00008060: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
+00008070: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00008080: 2020 2320 7765 206d 7573 7420 636c 6f6e    # we must clon
+00008090: 6520 7468 6520 7661 6c75 6573 2c20 6173  e the values, as
+000080a0: 2074 6865 2074 656e 736f 7264 6963 7420   the tensordict 
+000080b0: 6973 2075 7064 6174 6564 2069 6e2d 706c  is updated in-pl
+000080c0: 6163 652e 0d0a 2020 2020 2020 2020 2020  ace...          
+000080d0: 2020 2020 2020 2320 6f74 6865 7277 6973        # otherwis
+000080e0: 6520 7468 6520 666f 6c6c 6f77 696e 6720  e the following 
+000080f0: 636f 6465 206d 6179 2062 7265 616b 3a0d  code may break:.
+00008100: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00008110: 2023 203e 3e3e 2066 6f72 2069 2c20 6461   # >>> for i, da
+00008120: 7461 2069 6e20 656e 756d 6572 6174 6528  ta in enumerate(
+00008130: 636f 6c6c 6563 746f 7229 3a0d 0a20 2020  collector):..   
+00008140: 2020 2020 2020 2020 2020 2020 2023 203e               # >
+00008150: 3e3e 2020 2020 2020 6966 2069 203d 3d20  >>      if i == 
+00008160: 303a 0d0a 2020 2020 2020 2020 2020 2020  0:..            
+00008170: 2020 2020 2320 3e3e 3e20 2020 2020 2020      # >>>       
+00008180: 2020 2064 6174 6130 203d 2064 6174 610d     data0 = data.
+00008190: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000081a0: 2023 203e 3e3e 2020 2020 2020 656c 6966   # >>>      elif
+000081b0: 2069 203d 3d20 313a 0d0a 2020 2020 2020   i == 1:..      
+000081c0: 2020 2020 2020 2020 2020 2320 3e3e 3e20            # >>> 
+000081d0: 2020 2020 2020 2020 2064 6174 6131 203d           data1 =
+000081e0: 2064 6174 610d 0a20 2020 2020 2020 2020   data..         
+000081f0: 2020 2020 2020 2023 203e 3e3e 2020 2020         # >>>    
+00008200: 2020 656c 7365 3a0d 0a20 2020 2020 2020    else:..       
+00008210: 2020 2020 2020 2020 2023 203e 3e3e 2020           # >>>  
+00008220: 2020 2020 2020 2020 6272 6561 6b0d 0a20          break.. 
+00008230: 2020 2020 2020 2020 2020 2020 2020 2023                 #
+00008240: 203e 3e3e 2061 7373 6572 7420 6461 7461   >>> assert data
+00008250: 305b 2264 6f6e 6522 5d20 6973 206e 6f74  0["done"] is not
+00008260: 2064 6174 6131 5b22 646f 6e65 225d 0d0a   data1["done"]..
+00008270: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008280: 7969 656c 6420 7465 6e73 6f72 6469 6374  yield tensordict
+00008290: 5f6f 7574 2e63 6c6f 6e65 2829 0d0a 0d0a  _out.clone()....
+000082a0: 2020 2020 2020 2020 2020 2020 6966 2073              if s
+000082b0: 656c 662e 5f66 7261 6d65 7320 3e3d 2073  elf._frames >= s
+000082c0: 656c 662e 746f 7461 6c5f 6672 616d 6573  elf.total_frames
+000082d0: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
+000082e0: 2020 2062 7265 616b 0d0a 0d0a 2020 2020     break....    
+000082f0: 6465 6620 5f73 7465 705f 616e 645f 6d61  def _step_and_ma
+00008300: 7962 655f 7265 7365 7428 7365 6c66 2920  ybe_reset(self) 
+00008310: 2d3e 204e 6f6e 653a 0d0a 2020 2020 2020  -> None:..      
+00008320: 2020 646f 6e65 203d 2073 656c 662e 5f74    done = self._t
+00008330: 656e 736f 7264 6963 742e 6765 7428 2822  ensordict.get(("
+00008340: 6e65 7874 222c 2022 646f 6e65 2229 290d  next", "done")).
+00008350: 0a20 2020 2020 2020 2074 7275 6e63 6174  .        truncat
+00008360: 6564 203d 2073 656c 662e 5f74 656e 736f  ed = self._tenso
+00008370: 7264 6963 742e 6765 7428 2822 6e65 7874  rdict.get(("next
+00008380: 222c 2022 7472 756e 6361 7465 6422 292c  ", "truncated"),
+00008390: 204e 6f6e 6529 0d0a 2020 2020 2020 2020   None)..        
+000083a0: 7472 616a 5f69 6473 203d 2073 656c 662e  traj_ids = self.
+000083b0: 5f74 656e 736f 7264 6963 742e 6765 7428  _tensordict.get(
+000083c0: 2822 636f 6c6c 6563 746f 7222 2c20 2274  ("collector", "t
+000083d0: 7261 6a5f 6964 7322 2929 0d0a 0d0a 2020  raj_ids"))....  
+000083e0: 2020 2020 2020 7365 6c66 2e5f 7465 6e73        self._tens
+000083f0: 6f72 6469 6374 203d 2073 7465 705f 6d64  ordict = step_md
+00008400: 7028 7365 6c66 2e5f 7465 6e73 6f72 6469  p(self._tensordi
+00008410: 6374 290d 0a0d 0a20 2020 2020 2020 2069  ct)....        i
+00008420: 6620 6e6f 7420 7365 6c66 2e72 6573 6574  f not self.reset
+00008430: 5f77 6865 6e5f 646f 6e65 3a0d 0a20 2020  _when_done:..   
+00008440: 2020 2020 2020 2020 2072 6574 7572 6e0d           return.
+00008450: 0a0d 0a20 2020 2020 2020 2064 6f6e 655f  ...        done_
+00008460: 6f72 5f74 6572 6d69 6e61 7465 6420 3d20  or_terminated = 
+00008470: 280d 0a20 2020 2020 2020 2020 2020 2028  (..            (
+00008480: 646f 6e65 207c 2074 7275 6e63 6174 6564  done | truncated
+00008490: 2920 6966 2074 7275 6e63 6174 6564 2069  ) if truncated i
+000084a0: 7320 6e6f 7420 4e6f 6e65 2065 6c73 6520  s not None else 
+000084b0: 646f 6e65 2e63 6c6f 6e65 2829 0d0a 2020  done.clone()..  
+000084c0: 2020 2020 2020 290d 0a0d 0a20 2020 2020        )....     
+000084d0: 2020 2069 6620 646f 6e65 5f6f 725f 7465     if done_or_te
+000084e0: 726d 696e 6174 6564 2e61 6e79 2829 3a0d  rminated.any():.
+000084f0: 0a20 2020 2020 2020 2020 2020 2023 2063  .            # c
+00008500: 6f6c 6c65 6374 6f72 7320 646f 206e 6f74  ollectors do not
+00008510: 2073 7570 706f 7274 2070 6173 7369 6e67   support passing
+00008520: 206f 7468 6572 2074 656e 736f 7273 2074   other tensors t
+00008530: 6861 6e20 6022 5f72 6573 6574 2260 0d0a  han `"_reset"`..
+00008540: 2020 2020 2020 2020 2020 2020 2320 746f              # to
+00008550: 2060 7265 7365 7428 2960 2e0d 0a20 2020   `reset()`...   
+00008560: 2020 2020 2020 2020 205f 7265 7365 7420           _reset 
+00008570: 3d20 646f 6e65 5f6f 725f 7465 726d 696e  = done_or_termin
+00008580: 6174 6564 0d0a 2020 2020 2020 2020 2020  ated..          
+00008590: 2020 7464 5f72 6573 6574 203d 2073 656c    td_reset = sel
+000085a0: 662e 5f74 656e 736f 7264 6963 742e 7365  f._tensordict.se
+000085b0: 6c65 6374 2829 2e73 6574 2822 5f72 6573  lect().set("_res
+000085c0: 6574 222c 205f 7265 7365 7429 0d0a 2020  et", _reset)..  
+000085d0: 2020 2020 2020 2020 2020 7464 5f72 6573            td_res
+000085e0: 6574 203d 2073 656c 662e 656e 762e 7265  et = self.env.re
+000085f0: 7365 7428 7464 5f72 6573 6574 290d 0a20  set(td_reset).. 
+00008600: 2020 2020 2020 2020 2020 2074 7261 6a5f             traj_
+00008610: 646f 6e65 5f6f 725f 7465 726d 696e 6174  done_or_terminat
+00008620: 6564 203d 2064 6f6e 655f 6f72 5f74 6572  ed = done_or_ter
+00008630: 6d69 6e61 7465 642e 7375 6d28 0d0a 2020  minated.sum(..  
+00008640: 2020 2020 2020 2020 2020 2020 2020 7475                tu
+00008650: 706c 6528 7261 6e67 6528 7365 6c66 2e5f  ple(range(self._
+00008660: 7465 6e73 6f72 6469 6374 2e62 6174 6368  tensordict.batch
+00008670: 5f64 696d 732c 2064 6f6e 655f 6f72 5f74  _dims, done_or_t
+00008680: 6572 6d69 6e61 7465 642e 6e64 696d 2929  erminated.ndim))
+00008690: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
+000086a0: 2020 2064 7479 7065 3d74 6f72 6368 2e62     dtype=torch.b
+000086b0: 6f6f 6c2c 0d0a 2020 2020 2020 2020 2020  ool,..          
+000086c0: 2020 290d 0a20 2020 2020 2020 2020 2020    )..           
+000086d0: 2069 6620 7464 5f72 6573 6574 2e62 6174   if td_reset.bat
+000086e0: 6368 5f64 696d 733a 0d0a 2020 2020 2020  ch_dims:..      
+000086f0: 2020 2020 2020 2020 2020 7365 6c66 2e5f            self._
+00008700: 7465 6e73 6f72 6469 6374 2e67 6574 5f73  tensordict.get_s
+00008710: 7562 5f74 656e 736f 7264 6963 7428 7472  ub_tensordict(tr
+00008720: 616a 5f64 6f6e 655f 6f72 5f74 6572 6d69  aj_done_or_termi
+00008730: 6e61 7465 6429 2e75 7064 6174 6528 0d0a  nated).update(..
+00008740: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008750: 2020 2020 7464 5f72 6573 6574 5b74 7261      td_reset[tra
+00008760: 6a5f 646f 6e65 5f6f 725f 7465 726d 696e  j_done_or_termin
+00008770: 6174 6564 5d2c 2069 6e70 6c61 6365 3d54  ated], inplace=T
+00008780: 7275 650d 0a20 2020 2020 2020 2020 2020  rue..           
+00008790: 2020 2020 2029 0d0a 2020 2020 2020 2020       )..        
+000087a0: 2020 2020 656c 7365 3a0d 0a20 2020 2020      else:..     
+000087b0: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+000087c0: 5f74 656e 736f 7264 6963 742e 7570 6461  _tensordict.upda
+000087d0: 7465 2874 645f 7265 7365 742c 2069 6e70  te(td_reset, inp
+000087e0: 6c61 6365 3d54 7275 6529 0d0a 0d0a 2020  lace=True)....  
+000087f0: 2020 2020 2020 2020 2020 646f 6e65 203d            done =
+00008800: 2073 656c 662e 5f74 656e 736f 7264 6963   self._tensordic
+00008810: 742e 6765 7428 2264 6f6e 6522 290d 0a20  t.get("done").. 
+00008820: 2020 2020 2020 2020 2020 2069 6620 646f             if do
+00008830: 6e65 2e61 6e79 2829 3a0d 0a20 2020 2020  ne.any():..     
+00008840: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+00008850: 2052 756e 7469 6d65 4572 726f 7228 0d0a   RuntimeError(..
+00008860: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008870: 2020 2020 6622 456e 7620 7b73 656c 662e      f"Env {self.
+00008880: 656e 767d 2077 6173 2064 6f6e 6520 6166  env} was done af
+00008890: 7465 7220 7265 7365 7420 6f6e 2073 7065  ter reset on spe
+000088a0: 6369 6669 6564 2027 5f72 6573 6574 2720  cified '_reset' 
+000088b0: 6469 6d65 6e73 696f 6e73 2e20 5468 6973  dimensions. This
+000088c0: 2069 7320 2863 7572 7265 6e74 6c79 2920   is (currently) 
+000088d0: 6e6f 7420 616c 6c6f 7765 642e 220d 0a20  not allowed.".. 
+000088e0: 2020 2020 2020 2020 2020 2020 2020 2029                 )
+000088f0: 0d0a 2020 2020 2020 2020 2020 2020 7472  ..            tr
+00008900: 616a 5f69 6473 5b74 7261 6a5f 646f 6e65  aj_ids[traj_done
+00008910: 5f6f 725f 7465 726d 696e 6174 6564 5d20  _or_terminated] 
+00008920: 3d20 7472 616a 5f69 6473 2e6d 6178 2829  = traj_ids.max()
+00008930: 202b 2074 6f72 6368 2e61 7261 6e67 6528   + torch.arange(
+00008940: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00008950: 2020 312c 2074 7261 6a5f 646f 6e65 5f6f    1, traj_done_o
+00008960: 725f 7465 726d 696e 6174 6564 2e73 756d  r_terminated.sum
+00008970: 2829 202b 2031 2c20 6465 7669 6365 3d74  () + 1, device=t
+00008980: 7261 6a5f 6964 732e 6465 7669 6365 0d0a  raj_ids.device..
+00008990: 2020 2020 2020 2020 2020 2020 290d 0a20              ).. 
+000089a0: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+000089b0: 5f74 656e 736f 7264 6963 742e 7365 745f  _tensordict.set_
+000089c0: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
+000089d0: 2020 2028 2263 6f6c 6c65 6374 6f72 222c     ("collector",
+000089e0: 2022 7472 616a 5f69 6473 2229 2c20 7472   "traj_ids"), tr
+000089f0: 616a 5f69 6473 0d0a 2020 2020 2020 2020  aj_ids..        
+00008a00: 2020 2020 2920 2023 206e 6f20 6f70 7320      )  # no ops 
+00008a10: 6966 2074 6865 7920 616c 7265 6164 7920  if they already 
+00008a20: 6d61 7463 680d 0a0d 0a20 2020 2040 746f  match....    @to
+00008a30: 7263 682e 6e6f 5f67 7261 6428 290d 0a20  rch.no_grad().. 
+00008a40: 2020 2064 6566 2072 6f6c 6c6f 7574 2873     def rollout(s
+00008a50: 656c 6629 202d 3e20 5465 6e73 6f72 4469  elf) -> TensorDi
+00008a60: 6374 4261 7365 3a0d 0a20 2020 2020 2020  ctBase:..       
+00008a70: 2022 2222 436f 6d70 7574 6573 2061 2072   """Computes a r
+00008a80: 6f6c 6c6f 7574 2069 6e20 7468 6520 656e  ollout in the en
+00008a90: 7669 726f 6e6d 656e 7420 7573 696e 6720  vironment using 
+00008aa0: 7468 6520 7072 6f76 6964 6564 2070 6f6c  the provided pol
+00008ab0: 6963 792e 0d0a 0d0a 2020 2020 2020 2020  icy.....        
+00008ac0: 5265 7475 726e 733a 0d0a 2020 2020 2020  Returns:..      
+00008ad0: 2020 2020 2020 5465 6e73 6f72 4469 6374        TensorDict
+00008ae0: 4261 7365 2063 6f6e 7461 696e 696e 6720  Base containing 
+00008af0: 7468 6520 636f 6d70 7574 6564 2072 6f6c  the computed rol
+00008b00: 6c6f 7574 2e0d 0a0d 0a20 2020 2020 2020  lout.....       
+00008b10: 2022 2222 0d0a 2020 2020 2020 2020 6966   """..        if
+00008b20: 2073 656c 662e 7265 7365 745f 6174 5f65   self.reset_at_e
+00008b30: 6163 685f 6974 6572 3a0d 0a20 2020 2020  ach_iter:..     
+00008b40: 2020 2020 2020 2073 656c 662e 5f74 656e         self._ten
+00008b50: 736f 7264 6963 742e 7570 6461 7465 2873  sordict.update(s
+00008b60: 656c 662e 656e 762e 7265 7365 7428 292c  elf.env.reset(),
+00008b70: 2069 6e70 6c61 6365 3d54 7275 6529 0d0a   inplace=True)..
+00008b80: 0d0a 2020 2020 2020 2020 2320 7365 6c66  ..        # self
+00008b90: 2e5f 7465 6e73 6f72 6469 6374 2e66 696c  ._tensordict.fil
+00008ba0: 6c5f 2828 2263 6f6c 6c65 6374 6f72 222c  l_(("collector",
+00008bb0: 2022 7374 6570 5f63 6f75 6e74 2229 2c20   "step_count"), 
+00008bc0: 3029 0d0a 2020 2020 2020 2020 7365 6c66  0)..        self
+00008bd0: 2e5f 7465 6e73 6f72 6469 6374 5f6f 7574  ._tensordict_out
+00008be0: 2e66 696c 6c5f 2828 2263 6f6c 6c65 6374  .fill_(("collect
+00008bf0: 6f72 222c 2022 7472 616a 5f69 6473 2229  or", "traj_ids")
+00008c00: 2c20 2d31 290d 0a0d 0a20 2020 2020 2020  , -1)....       
+00008c10: 2077 6974 6820 7365 745f 6578 706c 6f72   with set_explor
+00008c20: 6174 696f 6e5f 7479 7065 2873 656c 662e  ation_type(self.
+00008c30: 6578 706c 6f72 6174 696f 6e5f 7479 7065  exploration_type
+00008c40: 293a 0d0a 2020 2020 2020 2020 2020 2020  ):..            
+00008c50: 666f 7220 6a20 696e 2072 616e 6765 2873  for j in range(s
+00008c60: 656c 662e 6672 616d 6573 5f70 6572 5f62  elf.frames_per_b
+00008c70: 6174 6368 293a 0d0a 2020 2020 2020 2020  atch):..        
+00008c80: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
+00008c90: 5f66 7261 6d65 7320 3c20 7365 6c66 2e69  _frames < self.i
+00008ca0: 6e69 745f 7261 6e64 6f6d 5f66 7261 6d65  nit_random_frame
+00008cb0: 733a 0d0a 2020 2020 2020 2020 2020 2020  s:..            
+00008cc0: 2020 2020 2020 2020 7365 6c66 2e65 6e76          self.env
+00008cd0: 2e72 616e 645f 7374 6570 2873 656c 662e  .rand_step(self.
+00008ce0: 5f74 656e 736f 7264 6963 7429 0d0a 2020  _tensordict)..  
+00008cf0: 2020 2020 2020 2020 2020 2020 2020 656c                el
+00008d00: 7365 3a0d 0a20 2020 2020 2020 2020 2020  se:..           
+00008d10: 2020 2020 2020 2020 2073 656c 662e 706f           self.po
+00008d20: 6c69 6379 2873 656c 662e 5f74 656e 736f  licy(self._tenso
+00008d30: 7264 6963 7429 0d0a 2020 2020 2020 2020  rdict)..        
+00008d40: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+00008d50: 2e65 6e76 2e73 7465 7028 7365 6c66 2e5f  .env.step(self._
+00008d60: 7465 6e73 6f72 6469 6374 290d 0a0d 0a20  tensordict).... 
+00008d70: 2020 2020 2020 2020 2020 2020 2020 2023                 #
+00008d80: 2077 6520 6d75 7374 2063 6c6f 6e65 2061   we must clone a
+00008d90: 6c6c 2074 6865 2076 616c 7565 732c 2073  ll the values, s
+00008da0: 696e 6365 2074 6865 2073 7465 7020 2f20  ince the step / 
+00008db0: 7472 616a 5f69 6420 7570 6461 7465 7320  traj_id updates 
+00008dc0: 6172 6520 646f 6e65 2069 6e2d 706c 6163  are done in-plac
+00008dd0: 650d 0a20 2020 2020 2020 2020 2020 2020  e..             
+00008de0: 2020 2074 7279 3a0d 0a20 2020 2020 2020     try:..       
+00008df0: 2020 2020 2020 2020 2020 2020 2073 656c               sel
+00008e00: 662e 5f74 656e 736f 7264 6963 745f 6f75  f._tensordict_ou
+00008e10: 745b 2e2e 2e2c 206a 5d20 3d20 7365 6c66  t[..., j] = self
+00008e20: 2e5f 7465 6e73 6f72 6469 6374 0d0a 2020  ._tensordict..  
+00008e30: 2020 2020 2020 2020 2020 2020 2020 6578                ex
+00008e40: 6365 7074 2052 756e 7469 6d65 4572 726f  cept RuntimeErro
+00008e50: 723a 0d0a 2020 2020 2020 2020 2020 2020  r:..            
+00008e60: 2020 2020 2020 2020 2320 756e 6c6f 636b          # unlock
+00008e70: 2074 6865 206f 7574 7075 7420 7465 6e73   the output tens
+00008e80: 6f72 6469 6374 2074 6f20 616c 6c6f 7720  ordict to allow 
+00008e90: 666f 7220 6e65 7720 6b65 7973 2074 6f20  for new keys to 
+00008ea0: 6265 2077 7269 7474 656e 0d0a 2020 2020  be written..    
+00008eb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008ec0: 2320 7468 6573 6520 7769 6c6c 2062 6520  # these will be 
+00008ed0: 6d69 7373 6564 2064 7572 696e 6720 7468  missed during th
+00008ee0: 6520 7379 6e63 2062 7574 2061 7420 6c65  e sync but at le
+00008ef0: 6173 7420 7765 2077 6f6e 2774 2067 6574  ast we won't get
+00008f00: 2061 6e20 6572 726f 7220 6475 7269 6e67   an error during
+00008f10: 2074 6865 2075 7064 6174 650d 0a20 2020   the update..   
+00008f20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008f30: 2069 735f 7368 6172 6564 203d 2073 656c   is_shared = sel
+00008f40: 662e 5f74 656e 736f 7264 6963 745f 6f75  f._tensordict_ou
+00008f50: 742e 6973 5f73 6861 7265 6428 290d 0a20  t.is_shared().. 
+00008f60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008f70: 2020 2073 656c 662e 5f74 656e 736f 7264     self._tensord
+00008f80: 6963 745f 6f75 742e 756e 6c6f 636b 5f28  ict_out.unlock_(
+00008f90: 290d 0a20 2020 2020 2020 2020 2020 2020  )..             
+00008fa0: 2020 2020 2020 2073 656c 662e 5f74 656e         self._ten
+00008fb0: 736f 7264 6963 745f 6f75 745b 2e2e 2e2c  sordict_out[...,
+00008fc0: 206a 5d20 3d20 7365 6c66 2e5f 7465 6e73   j] = self._tens
+00008fd0: 6f72 6469 6374 0d0a 2020 2020 2020 2020  ordict..        
+00008fe0: 2020 2020 2020 2020 2020 2020 6966 2069              if i
+00008ff0: 735f 7368 6172 6564 3a0d 0a20 2020 2020  s_shared:..     
+00009000: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009010: 2020 2073 656c 662e 5f74 656e 736f 7264     self._tensord
+00009020: 6963 745f 6f75 742e 7368 6172 655f 6d65  ict_out.share_me
+00009030: 6d6f 7279 5f28 290d 0a20 2020 2020 2020  mory_()..       
+00009040: 2020 2020 2020 2020 2020 2020 2065 6c73               els
+00009050: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
+00009060: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+00009070: 2e5f 7465 6e73 6f72 6469 6374 5f6f 7574  ._tensordict_out
+00009080: 2e6c 6f63 6b28 290d 0a0d 0a20 2020 2020  .lock()....     
+00009090: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+000090a0: 5f73 7465 705f 616e 645f 6d61 7962 655f  _step_and_maybe_
+000090b0: 7265 7365 7428 290d 0a20 2020 2020 2020  reset()..       
+000090c0: 2020 2020 2020 2020 2069 6620 280d 0a20           if (.. 
+000090d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000090e0: 2020 2073 656c 662e 696e 7465 7272 7570     self.interrup
+000090f0: 746f 7220 6973 206e 6f74 204e 6f6e 650d  tor is not None.
+00009100: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00009110: 2020 2020 2061 6e64 2073 656c 662e 696e       and self.in
+00009120: 7465 7272 7570 746f 722e 636f 6c6c 6563  terruptor.collec
+00009130: 7469 6f6e 5f73 746f 7070 6564 2829 0d0a  tion_stopped()..
+00009140: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009150: 293a 0d0a 2020 2020 2020 2020 2020 2020  ):..            
+00009160: 2020 2020 2020 2020 6272 6561 6b0d 0a0d          break...
+00009170: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00009180: 7365 6c66 2e5f 7465 6e73 6f72 6469 6374  self._tensordict
+00009190: 5f6f 7574 0d0a 0d0a 2020 2020 6465 6620  _out....    def 
+000091a0: 7265 7365 7428 7365 6c66 2c20 696e 6465  reset(self, inde
+000091b0: 783d 4e6f 6e65 2c20 2a2a 6b77 6172 6773  x=None, **kwargs
+000091c0: 2920 2d3e 204e 6f6e 653a 0d0a 2020 2020  ) -> None:..    
+000091d0: 2020 2020 2222 2252 6573 6574 7320 7468      """Resets th
+000091e0: 6520 656e 7669 726f 6e6d 656e 7473 2074  e environments t
+000091f0: 6f20 6120 6e65 7720 696e 6974 6961 6c20  o a new initial 
+00009200: 7374 6174 652e 2222 220d 0a20 2020 2020  state."""..     
+00009210: 2020 2023 206d 6574 6164 6174 610d 0a20     # metadata.. 
+00009220: 2020 2020 2020 206d 6420 3d20 7365 6c66         md = self
+00009230: 2e5f 7465 6e73 6f72 6469 6374 5b22 636f  ._tensordict["co
+00009240: 6c6c 6563 746f 7222 5d2e 636c 6f6e 6528  llector"].clone(
+00009250: 290d 0a20 2020 2020 2020 2069 6620 696e  )..        if in
+00009260: 6465 7820 6973 206e 6f74 204e 6f6e 653a  dex is not None:
+00009270: 0d0a 2020 2020 2020 2020 2020 2020 2320  ..            # 
+00009280: 6368 6563 6b20 7468 6174 2074 6865 2065  check that the e
+00009290: 6e76 2073 7570 706f 7274 7320 7061 7274  nv supports part
+000092a0: 6961 6c20 7265 7365 740d 0a20 2020 2020  ial reset..     
+000092b0: 2020 2020 2020 2069 6620 7072 6f64 2873         if prod(s
+000092c0: 656c 662e 656e 762e 6261 7463 685f 7369  elf.env.batch_si
+000092d0: 7a65 2920 3d3d 2030 3a0d 0a20 2020 2020  ze) == 0:..     
+000092e0: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+000092f0: 2052 756e 7469 6d65 4572 726f 7228 2272   RuntimeError("r
+00009300: 6573 6574 7469 6e67 2075 6e69 7175 6520  esetting unique 
+00009310: 656e 7620 7769 7468 2069 6e64 6578 2069  env with index i
+00009320: 7320 6e6f 7420 7065 726d 6974 7465 642e  s not permitted.
+00009330: 2229 0d0a 2020 2020 2020 2020 2020 2020  ")..            
+00009340: 5f72 6573 6574 203d 2074 6f72 6368 2e7a  _reset = torch.z
+00009350: 6572 6f73 280d 0a20 2020 2020 2020 2020  eros(..         
+00009360: 2020 2020 2020 2073 656c 662e 656e 762e         self.env.
+00009370: 646f 6e65 5f73 7065 632e 7368 6170 652c  done_spec.shape,
+00009380: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00009390: 2020 6474 7970 653d 746f 7263 682e 626f    dtype=torch.bo
+000093a0: 6f6c 2c0d 0a20 2020 2020 2020 2020 2020  ol,..           
+000093b0: 2020 2020 2064 6576 6963 653d 7365 6c66       device=self
+000093c0: 2e65 6e76 2e64 6576 6963 652c 0d0a 2020  .env.device,..  
+000093d0: 2020 2020 2020 2020 2020 290d 0a20 2020            )..   
+000093e0: 2020 2020 2020 2020 205f 7265 7365 745b           _reset[
+000093f0: 696e 6465 785d 203d 2031 0d0a 2020 2020  index] = 1..    
+00009400: 2020 2020 2020 2020 7365 6c66 2e5f 7465          self._te
+00009410: 6e73 6f72 6469 6374 5b69 6e64 6578 5d2e  nsordict[index].
+00009420: 7a65 726f 5f28 290d 0a20 2020 2020 2020  zero_()..       
+00009430: 2020 2020 2073 656c 662e 5f74 656e 736f       self._tenso
+00009440: 7264 6963 745b 225f 7265 7365 7422 5d20  rdict["_reset"] 
+00009450: 3d20 5f72 6573 6574 0d0a 2020 2020 2020  = _reset..      
+00009460: 2020 656c 7365 3a0d 0a20 2020 2020 2020    else:..       
+00009470: 2020 2020 205f 7265 7365 7420 3d20 4e6f       _reset = No
+00009480: 6e65 0d0a 2020 2020 2020 2020 2020 2020  ne..            
+00009490: 7365 6c66 2e5f 7465 6e73 6f72 6469 6374  self._tensordict
+000094a0: 2e7a 6572 6f5f 2829 0d0a 0d0a 2020 2020  .zero_()....    
+000094b0: 2020 2020 7365 6c66 2e5f 7465 6e73 6f72      self._tensor
+000094c0: 6469 6374 2e75 7064 6174 6528 7365 6c66  dict.update(self
+000094d0: 2e65 6e76 2e72 6573 6574 282a 2a6b 7761  .env.reset(**kwa
+000094e0: 7267 7329 290d 0a20 2020 2020 2020 206d  rgs))..        m
+000094f0: 645b 2274 7261 6a5f 6964 7322 5d20 3d20  d["traj_ids"] = 
+00009500: 6d64 5b22 7472 616a 5f69 6473 225d 202d  md["traj_ids"] -
+00009510: 206d 645b 2274 7261 6a5f 6964 7322 5d2e   md["traj_ids"].
+00009520: 6d69 6e28 290d 0a20 2020 2020 2020 2073  min()..        s
+00009530: 656c 662e 5f74 656e 736f 7264 6963 745b  elf._tensordict[
+00009540: 2263 6f6c 6c65 6374 6f72 225d 203d 206d  "collector"] = m
+00009550: 640d 0a0d 0a20 2020 2064 6566 2073 6875  d....    def shu
+00009560: 7464 6f77 6e28 7365 6c66 2920 2d3e 204e  tdown(self) -> N
+00009570: 6f6e 653a 0d0a 2020 2020 2020 2020 2222  one:..        ""
+00009580: 2253 6875 7473 2064 6f77 6e20 616c 6c20  "Shuts down all 
+00009590: 776f 726b 6572 7320 616e 642f 6f72 2063  workers and/or c
+000095a0: 6c6f 7365 7320 7468 6520 6c6f 6361 6c20  loses the local 
+000095b0: 656e 7669 726f 6e6d 656e 742e 2222 220d  environment.""".
+000095c0: 0a20 2020 2020 2020 2069 6620 6e6f 7420  .        if not 
+000095d0: 7365 6c66 2e63 6c6f 7365 643a 0d0a 2020  self.closed:..  
+000095e0: 2020 2020 2020 2020 2020 7365 6c66 2e63            self.c
+000095f0: 6c6f 7365 6420 3d20 5472 7565 0d0a 2020  losed = True..  
+00009600: 2020 2020 2020 2020 2020 6465 6c20 7365            del se
+00009610: 6c66 2e5f 7465 6e73 6f72 6469 6374 2c20  lf._tensordict, 
+00009620: 7365 6c66 2e5f 7465 6e73 6f72 6469 6374  self._tensordict
+00009630: 5f6f 7574 0d0a 2020 2020 2020 2020 2020  _out..          
+00009640: 2020 6966 206e 6f74 2073 656c 662e 656e    if not self.en
+00009650: 762e 6973 5f63 6c6f 7365 643a 0d0a 2020  v.is_closed:..  
+00009660: 2020 2020 2020 2020 2020 2020 2020 7365                se
+00009670: 6c66 2e65 6e76 2e63 6c6f 7365 2829 0d0a  lf.env.close()..
+00009680: 2020 2020 2020 2020 2020 2020 6465 6c20              del 
+00009690: 7365 6c66 2e65 6e76 0d0a 2020 2020 2020  self.env..      
+000096a0: 2020 7265 7475 726e 0d0a 0d0a 2020 2020    return....    
+000096b0: 6465 6620 5f5f 6465 6c5f 5f28 7365 6c66  def __del__(self
+000096c0: 293a 0d0a 2020 2020 2020 2020 7472 793a  ):..        try:
+000096d0: 0d0a 2020 2020 2020 2020 2020 2020 7365  ..            se
+000096e0: 6c66 2e73 6875 7464 6f77 6e28 290d 0a20  lf.shutdown().. 
+000096f0: 2020 2020 2020 2065 7863 6570 7420 4578         except Ex
+00009700: 6365 7074 696f 6e3a 0d0a 2020 2020 2020  ception:..      
+00009710: 2020 2020 2020 2320 616e 2041 7474 7269        # an Attri
+00009720: 6275 7465 4572 726f 7220 7769 6c6c 2074  buteError will t
+00009730: 7970 6963 616c 6c79 2062 6520 7261 6973  ypically be rais
+00009740: 6564 2069 6620 7468 6520 636f 6c6c 6563  ed if the collec
+00009750: 746f 7220 6973 2064 656c 6574 6564 2077  tor is deleted w
+00009760: 6865 6e20 7468 6520 7072 6f67 7261 6d20  hen the program 
+00009770: 656e 6473 2e0d 0a20 2020 2020 2020 2020  ends...         
+00009780: 2020 2023 2049 6e20 7468 6520 6675 7475     # In the futu
+00009790: 7265 2c20 696e 7369 676e 6966 6963 616e  re, insignifican
+000097a0: 7420 6368 616e 6765 7320 746f 2074 6865  t changes to the
+000097b0: 2063 6c6f 7365 206d 6574 686f 6420 6d61   close method ma
+000097c0: 7920 6368 616e 6765 2074 6865 2065 7272  y change the err
+000097d0: 6f72 2074 7970 652e 0d0a 2020 2020 2020  or type...      
+000097e0: 2020 2020 2020 2320 5765 2065 7863 706c        # We excpl
+000097f0: 6963 6974 656c 7920 6173 7375 6d65 2074  icitely assume t
+00009800: 6861 7420 616e 7920 6572 726f 7220 7261  hat any error ra
+00009810: 6973 6564 2064 7572 696e 6720 636c 6f73  ised during clos
+00009820: 7572 6520 696e 0d0a 2020 2020 2020 2020  ure in..        
+00009830: 2020 2020 2320 5f5f 6465 6c5f 5f20 7769      # __del__ wi
+00009840: 6c6c 206e 6f74 2061 6666 6563 7420 7468  ll not affect th
+00009850: 6520 7072 6f67 7261 6d2e 0d0a 2020 2020  e program...    
+00009860: 2020 2020 2020 2020 7061 7373 0d0a 0d0a          pass....
+00009870: 2020 2020 6465 6620 7374 6174 655f 6469      def state_di
+00009880: 6374 2873 656c 6629 202d 3e20 4f72 6465  ct(self) -> Orde
+00009890: 7265 6444 6963 743a 0d0a 2020 2020 2020  redDict:..      
+000098a0: 2020 2222 2252 6574 7572 6e73 2074 6865    """Returns the
+000098b0: 206c 6f63 616c 2073 7461 7465 5f64 6963   local state_dic
+000098c0: 7420 6f66 2074 6865 2064 6174 6120 636f  t of the data co
+000098d0: 6c6c 6563 746f 7220 2865 6e76 6972 6f6e  llector (environ
+000098e0: 6d65 6e74 2061 6e64 2070 6f6c 6963 7929  ment and policy)
+000098f0: 2e0d 0a0d 0a20 2020 2020 2020 2052 6574  .....        Ret
+00009900: 7572 6e73 3a0d 0a20 2020 2020 2020 2020  urns:..         
+00009910: 2020 2061 6e20 6f72 6465 7265 6420 6469     an ordered di
+00009920: 6374 696f 6e61 7279 2077 6974 6820 6669  ctionary with fi
+00009930: 656c 6473 203a 6f62 6a3a 6022 706f 6c69  elds :obj:`"poli
+00009940: 6379 5f73 7461 7465 5f64 6963 7422 6020  cy_state_dict"` 
+00009950: 616e 640d 0a20 2020 2020 2020 2020 2020  and..           
+00009960: 2060 2265 6e76 5f73 7461 7465 5f64 6963   `"env_state_dic
+00009970: 7422 602e 0d0a 0d0a 2020 2020 2020 2020  t"`.....        
+00009980: 2222 220d 0a20 2020 2020 2020 2069 6620  """..        if 
+00009990: 6973 696e 7374 616e 6365 2873 656c 662e  isinstance(self.
+000099a0: 656e 762c 2054 7261 6e73 666f 726d 6564  env, Transformed
+000099b0: 456e 7629 3a0d 0a20 2020 2020 2020 2020  Env):..         
+000099c0: 2020 2065 6e76 5f73 7461 7465 5f64 6963     env_state_dic
+000099d0: 7420 3d20 7365 6c66 2e65 6e76 2e74 7261  t = self.env.tra
+000099e0: 6e73 666f 726d 2e73 7461 7465 5f64 6963  nsform.state_dic
+000099f0: 7428 290d 0a20 2020 2020 2020 2065 6c69  t()..        eli
+00009a00: 6620 6973 696e 7374 616e 6365 2873 656c  f isinstance(sel
+00009a10: 662e 656e 762c 205f 4261 7463 6865 6445  f.env, _BatchedE
+00009a20: 6e76 293a 0d0a 2020 2020 2020 2020 2020  nv):..          
+00009a30: 2020 656e 765f 7374 6174 655f 6469 6374    env_state_dict
+00009a40: 203d 2073 656c 662e 656e 762e 7374 6174   = self.env.stat
+00009a50: 655f 6469 6374 2829 0d0a 2020 2020 2020  e_dict()..      
+00009a60: 2020 656c 7365 3a0d 0a20 2020 2020 2020    else:..       
+00009a70: 2020 2020 2065 6e76 5f73 7461 7465 5f64       env_state_d
+00009a80: 6963 7420 3d20 4f72 6465 7265 6444 6963  ict = OrderedDic
+00009a90: 7428 290d 0a0d 0a20 2020 2020 2020 2069  t()....        i
+00009aa0: 6620 6861 7361 7474 7228 7365 6c66 2e70  f hasattr(self.p
+00009ab0: 6f6c 6963 792c 2022 7374 6174 655f 6469  olicy, "state_di
+00009ac0: 6374 2229 3a0d 0a20 2020 2020 2020 2020  ct"):..         
+00009ad0: 2020 2070 6f6c 6963 795f 7374 6174 655f     policy_state_
+00009ae0: 6469 6374 203d 2073 656c 662e 706f 6c69  dict = self.poli
+00009af0: 6379 2e73 7461 7465 5f64 6963 7428 290d  cy.state_dict().
+00009b00: 0a20 2020 2020 2020 2020 2020 2073 7461  .            sta
+00009b10: 7465 5f64 6963 7420 3d20 4f72 6465 7265  te_dict = Ordere
+00009b20: 6444 6963 7428 0d0a 2020 2020 2020 2020  dDict(..        
+00009b30: 2020 2020 2020 2020 706f 6c69 6379 5f73          policy_s
+00009b40: 7461 7465 5f64 6963 743d 706f 6c69 6379  tate_dict=policy
+00009b50: 5f73 7461 7465 5f64 6963 742c 0d0a 2020  _state_dict,..  
+00009b60: 2020 2020 2020 2020 2020 2020 2020 656e                en
+00009b70: 765f 7374 6174 655f 6469 6374 3d65 6e76  v_state_dict=env
+00009b80: 5f73 7461 7465 5f64 6963 742c 0d0a 2020  _state_dict,..  
+00009b90: 2020 2020 2020 2020 2020 290d 0a20 2020            )..   
+00009ba0: 2020 2020 2065 6c73 653a 0d0a 2020 2020       else:..    
+00009bb0: 2020 2020 2020 2020 7374 6174 655f 6469          state_di
+00009bc0: 6374 203d 204f 7264 6572 6564 4469 6374  ct = OrderedDict
+00009bd0: 2865 6e76 5f73 7461 7465 5f64 6963 743d  (env_state_dict=
+00009be0: 656e 765f 7374 6174 655f 6469 6374 290d  env_state_dict).
+00009bf0: 0a0d 0a20 2020 2020 2020 2072 6574 7572  ...        retur
+00009c00: 6e20 7374 6174 655f 6469 6374 0d0a 0d0a  n state_dict....
+00009c10: 2020 2020 6465 6620 6c6f 6164 5f73 7461      def load_sta
+00009c20: 7465 5f64 6963 7428 7365 6c66 2c20 7374  te_dict(self, st
+00009c30: 6174 655f 6469 6374 3a20 4f72 6465 7265  ate_dict: Ordere
+00009c40: 6444 6963 742c 202a 2a6b 7761 7267 7329  dDict, **kwargs)
+00009c50: 202d 3e20 4e6f 6e65 3a0d 0a20 2020 2020   -> None:..     
+00009c60: 2020 2022 2222 4c6f 6164 7320 6120 7374     """Loads a st
+00009c70: 6174 655f 6469 6374 206f 6e20 7468 6520  ate_dict on the 
+00009c80: 656e 7669 726f 6e6d 656e 7420 616e 6420  environment and 
+00009c90: 706f 6c69 6379 2e0d 0a0d 0a20 2020 2020  policy.....     
+00009ca0: 2020 2041 7267 733a 0d0a 2020 2020 2020     Args:..      
+00009cb0: 2020 2020 2020 7374 6174 655f 6469 6374        state_dict
+00009cc0: 2028 4f72 6465 7265 6444 6963 7429 3a20   (OrderedDict): 
+00009cd0: 6f72 6465 7265 6420 6469 6374 696f 6e61  ordered dictiona
+00009ce0: 7279 2063 6f6e 7461 696e 696e 6720 7468  ry containing th
+00009cf0: 6520 6669 656c 6473 0d0a 2020 2020 2020  e fields..      
+00009d00: 2020 2020 2020 2020 2020 6022 706f 6c69            `"poli
+00009d10: 6379 5f73 7461 7465 5f64 6963 7422 6020  cy_state_dict"` 
+00009d20: 616e 6420 3a6f 626a 3a60 2265 6e76 5f73  and :obj:`"env_s
+00009d30: 7461 7465 5f64 6963 7422 602e 0d0a 0d0a  tate_dict"`.....
+00009d40: 2020 2020 2020 2020 2222 220d 0a20 2020          """..   
+00009d50: 2020 2020 2073 7472 6963 7420 3d20 6b77       strict = kw
+00009d60: 6172 6773 2e67 6574 2822 7374 7269 6374  args.get("strict
+00009d70: 222c 2054 7275 6529 0d0a 2020 2020 2020  ", True)..      
+00009d80: 2020 6966 2073 7472 6963 7420 6f72 2022    if strict or "
+00009d90: 656e 765f 7374 6174 655f 6469 6374 2220  env_state_dict" 
+00009da0: 696e 2073 7461 7465 5f64 6963 743a 0d0a  in state_dict:..
+00009db0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+00009dc0: 2e65 6e76 2e6c 6f61 645f 7374 6174 655f  .env.load_state_
+00009dd0: 6469 6374 2873 7461 7465 5f64 6963 745b  dict(state_dict[
+00009de0: 2265 6e76 5f73 7461 7465 5f64 6963 7422  "env_state_dict"
+00009df0: 5d2c 202a 2a6b 7761 7267 7329 0d0a 2020  ], **kwargs)..  
+00009e00: 2020 2020 2020 6966 2073 7472 6963 7420        if strict 
+00009e10: 6f72 2022 706f 6c69 6379 5f73 7461 7465  or "policy_state
+00009e20: 5f64 6963 7422 2069 6e20 7374 6174 655f  _dict" in state_
+00009e30: 6469 6374 3a0d 0a20 2020 2020 2020 2020  dict:..         
+00009e40: 2020 2073 656c 662e 706f 6c69 6379 2e6c     self.policy.l
+00009e50: 6f61 645f 7374 6174 655f 6469 6374 2873  oad_state_dict(s
+00009e60: 7461 7465 5f64 6963 745b 2270 6f6c 6963  tate_dict["polic
+00009e70: 795f 7374 6174 655f 6469 6374 225d 2c20  y_state_dict"], 
+00009e80: 2a2a 6b77 6172 6773 290d 0a0d 0a20 2020  **kwargs)....   
+00009e90: 2064 6566 205f 5f72 6570 725f 5f28 7365   def __repr__(se
+00009ea0: 6c66 2920 2d3e 2073 7472 3a0d 0a20 2020  lf) -> str:..   
+00009eb0: 2020 2020 2065 6e76 5f73 7472 203d 2069       env_str = i
+00009ec0: 6e64 656e 7428 6622 656e 763d 7b73 656c  ndent(f"env={sel
+00009ed0: 662e 656e 767d 222c 2034 202a 2022 2022  f.env}", 4 * " "
+00009ee0: 290d 0a20 2020 2020 2020 2070 6f6c 6963  )..        polic
+00009ef0: 795f 7374 7220 3d20 696e 6465 6e74 2866  y_str = indent(f
+00009f00: 2270 6f6c 6963 793d 7b73 656c 662e 706f  "policy={self.po
+00009f10: 6c69 6379 7d22 2c20 3420 2a20 2220 2229  licy}", 4 * " ")
+00009f20: 0d0a 2020 2020 2020 2020 7464 5f6f 7574  ..        td_out
+00009f30: 5f73 7472 203d 2069 6e64 656e 7428 6622  _str = indent(f"
+00009f40: 7464 5f6f 7574 3d7b 7365 6c66 2e5f 7465  td_out={self._te
+00009f50: 6e73 6f72 6469 6374 5f6f 7574 7d22 2c20  nsordict_out}", 
+00009f60: 3420 2a20 2220 2229 0d0a 2020 2020 2020  4 * " ")..      
+00009f70: 2020 7374 7269 6e67 203d 2028 0d0a 2020    string = (..  
+00009f80: 2020 2020 2020 2020 2020 6622 7b73 656c            f"{sel
+00009f90: 662e 5f5f 636c 6173 735f 5f2e 5f5f 6e61  f.__class__.__na
+00009fa0: 6d65 5f5f 7d28 220d 0a20 2020 2020 2020  me__}("..       
+00009fb0: 2020 2020 2066 225c 6e7b 656e 765f 7374       f"\n{env_st
+00009fc0: 727d 2c22 0d0a 2020 2020 2020 2020 2020  r},"..          
+00009fd0: 2020 6622 5c6e 7b70 6f6c 6963 795f 7374    f"\n{policy_st
+00009fe0: 727d 2c22 0d0a 2020 2020 2020 2020 2020  r},"..          
+00009ff0: 2020 6622 5c6e 7b74 645f 6f75 745f 7374    f"\n{td_out_st
+0000a000: 727d 2c22 0d0a 2020 2020 2020 2020 2020  r},"..          
+0000a010: 2020 6622 5c6e 6578 706c 6f72 6174 696f    f"\nexploratio
+0000a020: 6e3d 7b73 656c 662e 6578 706c 6f72 6174  n={self.explorat
+0000a030: 696f 6e5f 7479 7065 7d29 220d 0a20 2020  ion_type})"..   
+0000a040: 2020 2020 2029 0d0a 2020 2020 2020 2020       )..        
+0000a050: 7265 7475 726e 2073 7472 696e 670d 0a0d  return string...
+0000a060: 0a0d 0a63 6c61 7373 205f 4d75 6c74 6944  ...class _MultiD
+0000a070: 6174 6143 6f6c 6c65 6374 6f72 2844 6174  ataCollector(Dat
+0000a080: 6143 6f6c 6c65 6374 6f72 4261 7365 293a  aCollectorBase):
+0000a090: 0d0a 2020 2020 2222 2252 756e 7320 6120  ..    """Runs a 
+0000a0a0: 6769 7665 6e20 6e75 6d62 6572 206f 6620  given number of 
+0000a0b0: 4461 7461 436f 6c6c 6563 746f 7273 206f  DataCollectors o
+0000a0c0: 6e20 7365 7061 7261 7465 2070 726f 6365  n separate proce
+0000a0d0: 7373 6573 2e0d 0a0d 0a20 2020 2041 7267  sses.....    Arg
+0000a0e0: 733a 0d0a 2020 2020 2020 2020 6372 6561  s:..        crea
+0000a0f0: 7465 5f65 6e76 5f66 6e20 284c 6973 745b  te_env_fn (List[
+0000a100: 4361 6c6c 6162 6c65 645d 293a 206c 6973  Callabled]): lis
+0000a110: 7420 6f66 2043 616c 6c61 626c 6573 2c20  t of Callables, 
+0000a120: 6561 6368 2072 6574 7572 6e69 6e67 2061  each returning a
+0000a130: 6e0d 0a20 2020 2020 2020 2020 2020 2069  n..            i
+0000a140: 6e73 7461 6e63 6520 6f66 203a 636c 6173  nstance of :clas
+0000a150: 733a 607e 746f 7263 6872 6c2e 656e 7673  s:`~torchrl.envs
+0000a160: 2e45 6e76 4261 7365 602e 0d0a 2020 2020  .EnvBase`...    
+0000a170: 2020 2020 706f 6c69 6379 2028 4361 6c6c      policy (Call
+0000a180: 6162 6c65 2c20 6f70 7469 6f6e 616c 293a  able, optional):
+0000a190: 2049 6e73 7461 6e63 6520 6f66 2054 656e   Instance of Ten
+0000a1a0: 736f 7244 6963 744d 6f64 756c 6520 636c  sorDictModule cl
+0000a1b0: 6173 732e 0d0a 2020 2020 2020 2020 2020  ass...          
+0000a1c0: 2020 4d75 7374 2061 6363 6570 7420 5465    Must accept Te
+0000a1d0: 6e73 6f72 4469 6374 4261 7365 206f 626a  nsorDictBase obj
+0000a1e0: 6563 7420 6173 2069 6e70 7574 2e0d 0a20  ect as input... 
+0000a1f0: 2020 2020 2020 2020 2020 2049 6620 6060             If ``
+0000a200: 4e6f 6e65 6060 2069 7320 7072 6f76 6964  None`` is provid
+0000a210: 6564 2c20 7468 6520 706f 6c69 6379 2075  ed, the policy u
+0000a220: 7365 6420 7769 6c6c 2062 6520 610d 0a20  sed will be a.. 
+0000a230: 2020 2020 2020 2020 2020 203a 636c 6173             :clas
+0000a240: 733a 6052 616e 646f 6d50 6f6c 6963 7960  s:`RandomPolicy`
+0000a250: 2069 6e73 7461 6e63 6520 7769 7468 2074   instance with t
+0000a260: 6865 2065 6e76 6972 6f6e 6d65 6e74 0d0a  he environment..
+0000a270: 2020 2020 2020 2020 2020 2020 6060 6163              ``ac
+0000a280: 7469 6f6e 5f73 7065 6360 602e 0d0a 2020  tion_spec``...  
+0000a290: 2020 2020 2020 6672 616d 6573 5f70 6572        frames_per
+0000a2a0: 5f62 6174 6368 2028 696e 7429 3a20 4120  _batch (int): A 
+0000a2b0: 6b65 7977 6f72 642d 6f6e 6c79 2061 7267  keyword-only arg
+0000a2c0: 756d 656e 7420 7265 7072 6573 656e 7469  ument representi
+0000a2d0: 6e67 2074 6865 0d0a 2020 2020 2020 2020  ng the..        
+0000a2e0: 2020 2020 746f 7461 6c20 6e75 6d62 6572      total number
+0000a2f0: 206f 6620 656c 656d 656e 7473 2069 6e20   of elements in 
+0000a300: 6120 6261 7463 682e 0d0a 2020 2020 2020  a batch...      
+0000a310: 2020 746f 7461 6c5f 6672 616d 6573 2028    total_frames (
+0000a320: 696e 7429 3a20 4120 6b65 7977 6f72 642d  int): A keyword-
+0000a330: 6f6e 6c79 2061 7267 756d 656e 7420 7265  only argument re
+0000a340: 7072 6573 656e 7469 6e67 2074 6865 0d0a  presenting the..
+0000a350: 2020 2020 2020 2020 2020 2020 746f 7461              tota
+0000a360: 6c20 6e75 6d62 6572 206f 6620 6672 616d  l number of fram
+0000a370: 6573 2072 6574 7572 6e65 6420 6279 2074  es returned by t
+0000a380: 6865 2063 6f6c 6c65 6374 6f72 0d0a 2020  he collector..  
+0000a390: 2020 2020 2020 2020 2020 6475 7269 6e67            during
+0000a3a0: 2069 7473 206c 6966 6573 7061 6e2e 2049   its lifespan. I
+0000a3b0: 6620 7468 6520 6060 746f 7461 6c5f 6672  f the ``total_fr
+0000a3c0: 616d 6573 6060 2069 7320 6e6f 7420 6469  ames`` is not di
+0000a3d0: 7669 7369 626c 6520 6279 0d0a 2020 2020  visible by..    
+0000a3e0: 2020 2020 2020 2020 6060 6672 616d 6573          ``frames
+0000a3f0: 5f70 6572 5f62 6174 6368 6060 2c20 616e  _per_batch``, an
+0000a400: 2065 7863 6570 7469 6f6e 2069 7320 7261   exception is ra
+0000a410: 6973 6564 2e0d 0a20 2020 2020 2020 2020  ised...         
+0000a420: 2020 2020 456e 646c 6573 7320 636f 6c6c      Endless coll
+0000a430: 6563 746f 7273 2063 616e 2062 6520 6372  ectors can be cr
+0000a440: 6561 7465 6420 6279 2070 6173 7369 6e67  eated by passing
+0000a450: 2060 6074 6f74 616c 5f66 7261 6d65 733d   ``total_frames=
+0000a460: 2d31 6060 2e0d 0a20 2020 2020 2020 2064  -1``...        d
+0000a470: 6576 6963 6520 2869 6e74 2c20 7374 722c  evice (int, str,
+0000a480: 2074 6f72 6368 2e64 6576 6963 6520 6f72   torch.device or
+0000a490: 2073 6571 7565 6e63 6520 6f66 2073 7563   sequence of suc
+0000a4a0: 682c 206f 7074 696f 6e61 6c29 3a0d 0a20  h, optional):.. 
+0000a4b0: 2020 2020 2020 2020 2020 2054 6865 2064             The d
+0000a4c0: 6576 6963 6520 6f6e 2077 6869 6368 2074  evice on which t
+0000a4d0: 6865 2070 6f6c 6963 7920 7769 6c6c 2062  he policy will b
+0000a4e0: 6520 706c 6163 6564 2e0d 0a20 2020 2020  e placed...     
+0000a4f0: 2020 2020 2020 2049 6620 6974 2064 6966         If it dif
+0000a500: 6665 7273 2066 726f 6d20 7468 6520 696e  fers from the in
+0000a510: 7075 7420 706f 6c69 6379 2064 6576 6963  put policy devic
+0000a520: 652c 2074 6865 0d0a 2020 2020 2020 2020  e, the..        
+0000a530: 2020 2020 3a6d 6574 683a 607e 2e75 7064      :meth:`~.upd
+0000a540: 6174 655f 706f 6c69 6379 5f77 6569 6768  ate_policy_weigh
+0000a550: 7473 5f60 206d 6574 686f 6420 7368 6f75  ts_` method shou
+0000a560: 6c64 2062 6520 7175 6572 6965 640d 0a20  ld be queried.. 
+0000a570: 2020 2020 2020 2020 2020 2061 7420 6170             at ap
+0000a580: 7072 6f70 7269 6174 6520 7469 6d65 7320  propriate times 
+0000a590: 6475 7269 6e67 2074 6865 2074 7261 696e  during the train
+0000a5a0: 696e 6720 6c6f 6f70 2074 6f20 6163 636f  ing loop to acco
+0000a5b0: 6d6d 6f64 6174 6520 666f 720d 0a20 2020  mmodate for..   
+0000a5c0: 2020 2020 2020 2020 2074 6865 206c 6167           the lag
+0000a5d0: 2062 6574 7765 656e 2070 6172 616d 6574   between paramet
+0000a5e0: 6572 2063 6f6e 6669 6775 7261 7469 6f6e  er configuration
+0000a5f0: 2061 7420 7661 7269 6f75 7320 7469 6d65   at various time
+0000a600: 732e 0d0a 2020 2020 2020 2020 2020 2020  s...            
+0000a610: 4966 206e 6563 6573 7361 7279 2c20 6120  If necessary, a 
+0000a620: 6c69 7374 206f 6620 6465 7669 6365 7320  list of devices 
+0000a630: 6361 6e20 6265 2070 6173 7365 6420 696e  can be passed in
+0000a640: 2077 6869 6368 2063 6173 6520 6561 6368   which case each
+0000a650: 0d0a 2020 2020 2020 2020 2020 2020 656c  ..            el
+0000a660: 656d 656e 7420 7769 6c6c 2063 6f72 7265  ement will corre
+0000a670: 7370 6f6e 6420 746f 2074 6865 2064 6573  spond to the des
+0000a680: 6967 6e61 7465 6420 6465 7669 6365 206f  ignated device o
+0000a690: 6620 6120 7375 622d 636f 6c6c 6563 746f  f a sub-collecto
+0000a6a0: 722e 0d0a 2020 2020 2020 2020 2020 2020  r...            
+0000a6b0: 4465 6661 756c 7473 2074 6f20 6060 4e6f  Defaults to ``No
+0000a6c0: 6e65 6060 2028 692e 652e 2070 6f6c 6963  ne`` (i.e. polic
+0000a6d0: 7920 6973 206b 6570 7420 6f6e 2069 7473  y is kept on its
+0000a6e0: 206f 7269 6769 6e61 6c20 6465 7669 6365   original device
+0000a6f0: 292e 0d0a 2020 2020 2020 2020 7374 6f72  )...        stor
+0000a700: 696e 675f 6465 7669 6365 2028 696e 742c  ing_device (int,
+0000a710: 2073 7472 2c20 746f 7263 682e 6465 7669   str, torch.devi
+0000a720: 6365 206f 7220 7365 7175 656e 6365 206f  ce or sequence o
+0000a730: 6620 7375 6368 2c20 6f70 7469 6f6e 616c  f such, optional
+0000a740: 293a 0d0a 2020 2020 2020 2020 2020 2020  ):..            
+0000a750: 5468 6520 6465 7669 6365 206f 6e20 7768  The device on wh
+0000a760: 6963 6820 7468 6520 6f75 7470 7574 203a  ich the output :
+0000a770: 636c 6173 733a 6074 656e 736f 7264 6963  class:`tensordic
+0000a780: 742e 5465 6e73 6f72 4469 6374 6020 7769  t.TensorDict` wi
+0000a790: 6c6c 0d0a 2020 2020 2020 2020 2020 2020  ll..            
+0000a7a0: 6265 2073 746f 7265 642e 2046 6f72 206c  be stored. For l
+0000a7b0: 6f6e 6720 7472 616a 6563 746f 7269 6573  ong trajectories
+0000a7c0: 2c20 6974 206d 6179 2062 6520 6e65 6365  , it may be nece
+0000a7d0: 7373 6172 7920 746f 2073 746f 7265 2074  ssary to store t
+0000a7e0: 6865 0d0a 2020 2020 2020 2020 2020 2020  he..            
+0000a7f0: 6461 7461 206f 6e20 6120 6469 6666 6572  data on a differ
+0000a800: 656e 7420 6465 7669 6365 2074 6861 6e20  ent device than 
+0000a810: 7468 6520 6f6e 6520 7768 6572 6520 7468  the one where th
+0000a820: 6520 706f 6c69 6379 2061 6e64 2065 6e76  e policy and env
+0000a830: 0d0a 2020 2020 2020 2020 2020 2020 6172  ..            ar
+0000a840: 6520 6578 6563 7574 6564 2e0d 0a20 2020  e executed...   
+0000a850: 2020 2020 2020 2020 2049 6620 6e65 6365           If nece
+0000a860: 7373 6172 792c 2061 206c 6973 7420 6f66  ssary, a list of
+0000a870: 2064 6576 6963 6573 2063 616e 2062 6520   devices can be 
+0000a880: 7061 7373 6564 2069 6e20 7768 6963 6820  passed in which 
+0000a890: 6361 7365 2065 6163 680d 0a20 2020 2020  case each..     
+0000a8a0: 2020 2020 2020 2065 6c65 6d65 6e74 2077         element w
+0000a8b0: 696c 6c20 636f 7272 6573 706f 6e64 2074  ill correspond t
+0000a8c0: 6f20 7468 6520 6465 7369 676e 6174 6564  o the designated
+0000a8d0: 2073 746f 7269 6e67 2064 6576 6963 6520   storing device 
+0000a8e0: 6f66 2061 0d0a 2020 2020 2020 2020 2020  of a..          
+0000a8f0: 2020 7375 622d 636f 6c6c 6563 746f 722e    sub-collector.
+0000a900: 0d0a 2020 2020 2020 2020 2020 2020 4465  ..            De
+0000a910: 6661 756c 7473 2074 6f20 6060 2263 7075  faults to ``"cpu
+0000a920: 2260 602e 0d0a 2020 2020 2020 2020 6372  "``...        cr
+0000a930: 6561 7465 5f65 6e76 5f6b 7761 7267 7320  eate_env_kwargs 
+0000a940: 2864 6963 742c 206f 7074 696f 6e61 6c29  (dict, optional)
+0000a950: 3a20 4120 6469 6374 696f 6e61 7279 2077  : A dictionary w
+0000a960: 6974 6820 7468 650d 0a20 2020 2020 2020  ith the..       
+0000a970: 2020 2020 206b 6579 776f 7264 2061 7267       keyword arg
+0000a980: 756d 656e 7473 2075 7365 6420 746f 2063  uments used to c
+0000a990: 7265 6174 6520 616e 2065 6e76 6972 6f6e  reate an environ
+0000a9a0: 6d65 6e74 2e20 4966 2061 206c 6973 7420  ment. If a list 
+0000a9b0: 6973 0d0a 2020 2020 2020 2020 2020 2020  is..            
+0000a9c0: 7072 6f76 6964 6564 2c20 6561 6368 206f  provided, each o
+0000a9d0: 6620 6974 7320 656c 656d 656e 7473 2077  f its elements w
+0000a9e0: 696c 6c20 6265 2061 7373 6967 6e65 6420  ill be assigned 
+0000a9f0: 746f 2061 2073 7562 2d63 6f6c 6c65 6374  to a sub-collect
+0000aa00: 6f72 2e0d 0a20 2020 2020 2020 206d 6178  or...        max
+0000aa10: 5f66 7261 6d65 735f 7065 725f 7472 616a  _frames_per_traj
+0000aa20: 2028 696e 742c 206f 7074 696f 6e61 6c29   (int, optional)
+0000aa30: 3a20 4d61 7869 6d75 6d20 7374 6570 7320  : Maximum steps 
+0000aa40: 7065 7220 7472 616a 6563 746f 7279 2e0d  per trajectory..
+0000aa50: 0a20 2020 2020 2020 2020 2020 204e 6f74  .            Not
+0000aa60: 6520 7468 6174 2061 2074 7261 6a65 6374  e that a traject
+0000aa70: 6f72 7920 6361 6e20 7370 616e 206f 7665  ory can span ove
+0000aa80: 7220 6d75 6c74 6970 6c65 2062 6174 6368  r multiple batch
+0000aa90: 6573 2028 756e 6c65 7373 0d0a 2020 2020  es (unless..    
+0000aaa0: 2020 2020 2020 2020 6060 7265 7365 745f          ``reset_
+0000aab0: 6174 5f65 6163 685f 6974 6572 6060 2069  at_each_iter`` i
+0000aac0: 7320 7365 7420 746f 2060 6054 7275 6560  s set to ``True`
+0000aad0: 602c 2073 6565 2062 656c 6f77 292e 0d0a  `, see below)...
+0000aae0: 2020 2020 2020 2020 2020 2020 4f6e 6365              Once
+0000aaf0: 2061 2074 7261 6a65 6374 6f72 7920 7265   a trajectory re
+0000ab00: 6163 6865 7320 6060 6e5f 7374 6570 7360  aches ``n_steps`
+0000ab10: 602c 2074 6865 2065 6e76 6972 6f6e 6d65  `, the environme
+0000ab20: 6e74 2069 7320 7265 7365 742e 0d0a 2020  nt is reset...  
+0000ab30: 2020 2020 2020 2020 2020 4966 2074 6865            If the
+0000ab40: 2065 6e76 6972 6f6e 6d65 6e74 2077 7261   environment wra
+0000ab50: 7073 206d 756c 7469 706c 6520 656e 7669  ps multiple envi
+0000ab60: 726f 6e6d 656e 7473 2074 6f67 6574 6865  ronments togethe
+0000ab70: 722c 2074 6865 206e 756d 6265 720d 0a20  r, the number.. 
+0000ab80: 2020 2020 2020 2020 2020 206f 6620 7374             of st
+0000ab90: 6570 7320 6973 2074 7261 636b 6564 2066  eps is tracked f
+0000aba0: 6f72 2065 6163 6820 656e 7669 726f 6e6d  or each environm
+0000abb0: 656e 7420 696e 6465 7065 6e64 656e 746c  ent independentl
+0000abc0: 792e 204e 6567 6174 6976 650d 0a20 2020  y. Negative..   
+0000abd0: 2020 2020 2020 2020 2076 616c 7565 7320           values 
+0000abe0: 6172 6520 616c 6c6f 7765 642c 2069 6e20  are allowed, in 
+0000abf0: 7768 6963 6820 6361 7365 2074 6869 7320  which case this 
+0000ac00: 6172 6775 6d65 6e74 2069 7320 6967 6e6f  argument is igno
+0000ac10: 7265 642e 0d0a 2020 2020 2020 2020 2020  red...          
+0000ac20: 2020 4465 6661 756c 7473 2074 6f20 6060    Defaults to ``
+0000ac30: 2d31 6060 2028 692e 652e 206e 6f20 6d61  -1`` (i.e. no ma
+0000ac40: 7869 6d75 6d20 6e75 6d62 6572 206f 6620  ximum number of 
+0000ac50: 7374 6570 7329 2e0d 0a20 2020 2020 2020  steps)...       
+0000ac60: 2069 6e69 745f 7261 6e64 6f6d 5f66 7261   init_random_fra
+0000ac70: 6d65 7320 2869 6e74 2c20 6f70 7469 6f6e  mes (int, option
+0000ac80: 616c 293a 204e 756d 6265 7220 6f66 2066  al): Number of f
+0000ac90: 7261 6d65 7320 666f 7220 7768 6963 6820  rames for which 
+0000aca0: 7468 650d 0a20 2020 2020 2020 2020 2020  the..           
+0000acb0: 2070 6f6c 6963 7920 6973 2069 676e 6f72   policy is ignor
+0000acc0: 6564 2062 6566 6f72 6520 6974 2069 7320  ed before it is 
+0000acd0: 6361 6c6c 6564 2e20 5468 6973 2066 6561  called. This fea
+0000ace0: 7475 7265 2069 7320 6d61 696e 6c79 0d0a  ture is mainly..
+0000acf0: 2020 2020 2020 2020 2020 2020 696e 7465              inte
+0000ad00: 6e64 6564 2074 6f20 6265 2075 7365 6420  nded to be used 
+0000ad10: 696e 206f 6666 6c69 6e65 2f6d 6f64 656c  in offline/model
+0000ad20: 2d62 6173 6564 2073 6574 7469 6e67 732c  -based settings,
+0000ad30: 2077 6865 7265 2061 0d0a 2020 2020 2020   where a..      
+0000ad40: 2020 2020 2020 6261 7463 6820 6f66 2072        batch of r
+0000ad50: 616e 646f 6d20 7472 616a 6563 746f 7269  andom trajectori
+0000ad60: 6573 2063 616e 2062 6520 7573 6564 2074  es can be used t
+0000ad70: 6f20 696e 6974 6961 6c69 7a65 2074 7261  o initialize tra
+0000ad80: 696e 696e 672e 0d0a 2020 2020 2020 2020  ining...        
+0000ad90: 2020 2020 4465 6661 756c 7473 2074 6f20      Defaults to 
+0000ada0: 6060 2d31 6060 2028 692e 652e 206e 6f20  ``-1`` (i.e. no 
+0000adb0: 7261 6e64 6f6d 2066 7261 6d65 7329 2e0d  random frames)..
+0000adc0: 0a20 2020 2020 2020 2072 6573 6574 5f61  .        reset_a
+0000add0: 745f 6561 6368 5f69 7465 7220 2862 6f6f  t_each_iter (boo
+0000ade0: 6c2c 206f 7074 696f 6e61 6c29 3a20 5768  l, optional): Wh
+0000adf0: 6574 6865 7220 656e 7669 726f 6e6d 656e  ether environmen
+0000ae00: 7473 2073 686f 756c 6420 6265 2072 6573  ts should be res
+0000ae10: 6574 0d0a 2020 2020 2020 2020 2020 2020  et..            
+0000ae20: 6174 2074 6865 2062 6567 696e 6e69 6e67  at the beginning
+0000ae30: 206f 6620 6120 6261 7463 6820 636f 6c6c   of a batch coll
+0000ae40: 6563 7469 6f6e 2e0d 0a20 2020 2020 2020  ection...       
+0000ae50: 2020 2020 2044 6566 6175 6c74 7320 746f       Defaults to
+0000ae60: 2060 6046 616c 7365 6060 2e0d 0a20 2020   ``False``...   
+0000ae70: 2020 2020 2070 6f73 7470 726f 6320 2843       postproc (C
+0000ae80: 616c 6c61 626c 652c 206f 7074 696f 6e61  allable, optiona
+0000ae90: 6c29 3a20 4120 706f 7374 2d70 726f 6365  l): A post-proce
+0000aea0: 7373 696e 6720 7472 616e 7366 6f72 6d2c  ssing transform,
+0000aeb0: 2073 7563 6820 6173 0d0a 2020 2020 2020   such as..      
+0000aec0: 2020 2020 2020 6120 3a63 6c61 7373 3a60        a :class:`
+0000aed0: 7e74 6f72 6368 726c 2e65 6e76 732e 5472  ~torchrl.envs.Tr
+0000aee0: 616e 7366 6f72 6d60 206f 7220 6120 3a63  ansform` or a :c
+0000aef0: 6c61 7373 3a60 7e74 6f72 6368 726c 2e64  lass:`~torchrl.d
+0000af00: 6174 612e 706f 7374 7072 6f63 732e 4d75  ata.postprocs.Mu
+0000af10: 6c74 6953 7465 7060 0d0a 2020 2020 2020  ltiStep`..      
+0000af20: 2020 2020 2020 696e 7374 616e 6365 2e0d        instance..
+0000af30: 0a20 2020 2020 2020 2020 2020 2044 6566  .            Def
+0000af40: 6175 6c74 7320 746f 2060 604e 6f6e 6560  aults to ``None`
+0000af50: 602e 0d0a 2020 2020 2020 2020 7370 6c69  `...        spli
+0000af60: 745f 7472 616a 7320 2862 6f6f 6c2c 206f  t_trajs (bool, o
+0000af70: 7074 696f 6e61 6c29 3a20 426f 6f6c 6561  ptional): Boolea
+0000af80: 6e20 696e 6469 6361 7469 6e67 2077 6865  n indicating whe
+0000af90: 7468 6572 2074 6865 2072 6573 756c 7469  ther the resulti
+0000afa0: 6e67 0d0a 2020 2020 2020 2020 2020 2020  ng..            
+0000afb0: 5465 6e73 6f72 4469 6374 2073 686f 756c  TensorDict shoul
+0000afc0: 6420 6265 2073 706c 6974 2061 6363 6f72  d be split accor
+0000afd0: 6469 6e67 2074 6f20 7468 6520 7472 616a  ding to the traj
+0000afe0: 6563 746f 7269 6573 2e0d 0a20 2020 2020  ectories...     
+0000aff0: 2020 2020 2020 2053 6565 203a 6675 6e63         See :func
+0000b000: 3a60 7e74 6f72 6368 726c 2e63 6f6c 6c65  :`~torchrl.colle
+0000b010: 6374 6f72 732e 7574 696c 732e 7370 6c69  ctors.utils.spli
+0000b020: 745f 7472 616a 6563 746f 7269 6573 6020  t_trajectories` 
+0000b030: 666f 7220 6d6f 7265 0d0a 2020 2020 2020  for more..      
+0000b040: 2020 2020 2020 696e 666f 726d 6174 696f        informatio
+0000b050: 6e2e 0d0a 2020 2020 2020 2020 2020 2020  n...            
+0000b060: 4465 6661 756c 7473 2074 6f20 6060 4661  Defaults to ``Fa
+0000b070: 6c73 6560 602e 0d0a 2020 2020 2020 2020  lse``...        
+0000b080: 6578 706c 6f72 6174 696f 6e5f 7479 7065  exploration_type
+0000b090: 2028 4578 706c 6f72 6174 696f 6e54 7970   (ExplorationTyp
+0000b0a0: 652c 206f 7074 696f 6e61 6c29 3a20 696e  e, optional): in
+0000b0b0: 7465 7261 6374 696f 6e20 6d6f 6465 2074  teraction mode t
+0000b0c0: 6f20 6265 2075 7365 6420 7768 656e 0d0a  o be used when..
+0000b0d0: 2020 2020 2020 2020 2020 2020 636f 6c6c              coll
+0000b0e0: 6563 7469 6e67 2064 6174 612e 204d 7573  ecting data. Mus
+0000b0f0: 7420 6265 206f 6e65 206f 6620 6060 4578  t be one of ``Ex
+0000b100: 706c 6f72 6174 696f 6e54 7970 652e 5241  plorationType.RA
+0000b110: 4e44 4f4d 6060 2c20 6060 4578 706c 6f72  NDOM``, ``Explor
+0000b120: 6174 696f 6e54 7970 652e 4d4f 4445 6060  ationType.MODE``
+0000b130: 206f 720d 0a20 2020 2020 2020 2020 2020   or..           
+0000b140: 2060 6045 7870 6c6f 7261 7469 6f6e 5479   ``ExplorationTy
+0000b150: 7065 2e4d 4541 4e60 602e 0d0a 2020 2020  pe.MEAN``...    
+0000b160: 2020 2020 2020 2020 4465 6661 756c 7473          Defaults
+0000b170: 2074 6f20 6060 4578 706c 6f72 6174 696f   to ``Exploratio
+0000b180: 6e54 7970 652e 5241 4e44 4f4d 6060 0d0a  nType.RANDOM``..
+0000b190: 2020 2020 2020 2020 7265 7475 726e 5f73          return_s
+0000b1a0: 616d 655f 7464 2028 626f 6f6c 2c20 6f70  ame_td (bool, op
+0000b1b0: 7469 6f6e 616c 293a 2069 6620 6060 5472  tional): if ``Tr
+0000b1c0: 7565 6060 2c20 7468 6520 7361 6d65 2054  ue``, the same T
+0000b1d0: 656e 736f 7244 6963 740d 0a20 2020 2020  ensorDict..     
+0000b1e0: 2020 2020 2020 2077 696c 6c20 6265 2072         will be r
+0000b1f0: 6574 7572 6e65 6420 6174 2065 6163 6820  eturned at each 
+0000b200: 6974 6572 6174 696f 6e2c 2077 6974 6820  iteration, with 
+0000b210: 6974 7320 7661 6c75 6573 0d0a 2020 2020  its values..    
+0000b220: 2020 2020 2020 2020 7570 6461 7465 642e          updated.
+0000b230: 2054 6869 7320 6665 6174 7572 6520 7368   This feature sh
+0000b240: 6f75 6c64 2062 6520 7573 6564 2063 6175  ould be used cau
+0000b250: 7469 6f75 736c 793a 2069 6620 7468 6520  tiously: if the 
+0000b260: 7361 6d65 0d0a 2020 2020 2020 2020 2020  same..          
+0000b270: 2020 7465 6e73 6f72 6469 6374 2069 7320    tensordict is 
+0000b280: 6164 6465 6420 746f 2061 2072 6570 6c61  added to a repla
+0000b290: 7920 6275 6666 6572 2066 6f72 2069 6e73  y buffer for ins
+0000b2a0: 7461 6e63 652c 0d0a 2020 2020 2020 2020  tance,..        
+0000b2b0: 2020 2020 7468 6520 7768 6f6c 6520 636f      the whole co
+0000b2c0: 6e74 656e 7420 6f66 2074 6865 2062 7566  ntent of the buf
+0000b2d0: 6665 7220 7769 6c6c 2062 6520 6964 656e  fer will be iden
+0000b2e0: 7469 6361 6c2e 0d0a 2020 2020 2020 2020  tical...        
+0000b2f0: 2020 2020 4465 6661 756c 7420 6973 2060      Default is `
+0000b300: 6046 616c 7365 6060 2e0d 0a20 2020 2020  `False``...     
+0000b310: 2020 2072 6573 6574 5f77 6865 6e5f 646f     reset_when_do
+0000b320: 6e65 2028 626f 6f6c 2c20 6f70 7469 6f6e  ne (bool, option
+0000b330: 616c 293a 2069 6620 6060 5472 7565 6060  al): if ``True``
+0000b340: 2028 6465 6661 756c 7429 2c20 616e 2065   (default), an e
+0000b350: 6e76 6972 6f6e 6d65 6e74 0d0a 2020 2020  nvironment..    
+0000b360: 2020 2020 2020 2020 7468 6174 2072 6574          that ret
+0000b370: 7572 6e20 6120 6060 5472 7565 6060 2076  urn a ``True`` v
+0000b380: 616c 7565 2069 6e20 6974 7320 6060 2264  alue in its ``"d
+0000b390: 6f6e 6522 6060 206f 7220 6060 2274 7275  one"`` or ``"tru
+0000b3a0: 6e63 6174 6564 2260 600d 0a20 2020 2020  ncated"``..     
+0000b3b0: 2020 2020 2020 2065 6e74 7279 2077 696c         entry wil
+0000b3c0: 6c20 6265 2072 6573 6574 2061 7420 7468  l be reset at th
+0000b3d0: 6520 636f 7272 6573 706f 6e64 696e 6720  e corresponding 
+0000b3e0: 696e 6469 6365 732e 0d0a 2020 2020 2020  indices...      
+0000b3f0: 2020 7570 6461 7465 5f61 745f 6561 6368    update_at_each
+0000b400: 5f62 6174 6368 2028 626f 6f6c 6d20 6f70  _batch (boolm op
+0000b410: 7469 6f6e 616c 293a 2069 6620 6060 5472  tional): if ``Tr
+0000b420: 7565 6060 2c20 3a6d 6574 683a 607e 2e75  ue``, :meth:`~.u
+0000b430: 7064 6174 655f 706f 6c69 6379 5f77 6569  pdate_policy_wei
+0000b440: 6768 745f 2829 600d 0a20 2020 2020 2020  ght_()`..       
+0000b450: 2020 2020 2077 696c 6c20 6265 2063 616c       will be cal
+0000b460: 6c65 6420 6265 666f 7265 2028 7379 6e63  led before (sync
+0000b470: 2920 6f72 2061 6674 6572 2028 6173 796e  ) or after (asyn
+0000b480: 6329 2065 6163 6820 6461 7461 2063 6f6c  c) each data col
+0000b490: 6c65 6374 696f 6e2e 0d0a 2020 2020 2020  lection...      
+0000b4a0: 2020 2020 2020 4465 6661 756c 7473 2074        Defaults t
+0000b4b0: 6f20 6060 4661 6c73 6560 602e 0d0a 2020  o ``False``...  
+0000b4c0: 2020 2020 2020 7072 6565 6d70 7469 7665        preemptive
+0000b4d0: 5f74 6872 6573 686f 6c64 2028 666c 6f61  _threshold (floa
+0000b4e0: 742c 206f 7074 696f 6e61 6c29 3a20 6120  t, optional): a 
+0000b4f0: 7661 6c75 6520 6265 7477 6565 6e20 302e  value between 0.
+0000b500: 3020 616e 6420 312e 3020 7468 6174 2073  0 and 1.0 that s
+0000b510: 7065 6369 6669 6573 2074 6865 2072 6174  pecifies the rat
+0000b520: 696f 206f 6620 776f 726b 6572 730d 0a20  io of workers.. 
+0000b530: 2020 2020 2020 2020 2020 2074 6861 7420             that 
+0000b540: 7769 6c6c 2062 6520 616c 6c6f 7765 6420  will be allowed 
+0000b550: 746f 2066 696e 6973 6865 6420 636f 6c6c  to finished coll
+0000b560: 6563 7469 6e67 2074 6865 6972 2072 6f6c  ecting their rol
+0000b570: 6c6f 7574 2062 6566 6f72 6520 7468 6520  lout before the 
+0000b580: 7265 7374 2061 7265 2066 6f72 6365 6420  rest are forced 
+0000b590: 746f 2065 6e64 2065 6172 6c79 2e0d 0a20  to end early... 
+0000b5a0: 2020 2022 2222 0d0a 0d0a 2020 2020 6465     """....    de
+0000b5b0: 6620 5f5f 696e 6974 5f5f 280d 0a20 2020  f __init__(..   
+0000b5c0: 2020 2020 2073 656c 662c 0d0a 2020 2020       self,..    
+0000b5d0: 2020 2020 6372 6561 7465 5f65 6e76 5f66      create_env_f
+0000b5e0: 6e3a 2053 6571 7565 6e63 655b 4361 6c6c  n: Sequence[Call
+0000b5f0: 6162 6c65 5b5b 5d2c 2045 6e76 4261 7365  able[[], EnvBase
+0000b600: 5d5d 2c0d 0a20 2020 2020 2020 2070 6f6c  ]],..        pol
+0000b610: 6963 793a 204f 7074 696f 6e61 6c5b 0d0a  icy: Optional[..
+0000b620: 2020 2020 2020 2020 2020 2020 556e 696f              Unio
+0000b630: 6e5b 0d0a 2020 2020 2020 2020 2020 2020  n[..            
+0000b640: 2020 2020 5465 6e73 6f72 4469 6374 4d6f      TensorDictMo
+0000b650: 6475 6c65 2c0d 0a20 2020 2020 2020 2020  dule,..         
+0000b660: 2020 2020 2020 2043 616c 6c61 626c 655b         Callable[
+0000b670: 5b54 656e 736f 7244 6963 7442 6173 655d  [TensorDictBase]
+0000b680: 2c20 5465 6e73 6f72 4469 6374 4261 7365  , TensorDictBase
+0000b690: 5d2c 0d0a 2020 2020 2020 2020 2020 2020  ],..            
+0000b6a0: 5d0d 0a20 2020 2020 2020 205d 2c0d 0a20  ]..        ],.. 
+0000b6b0: 2020 2020 2020 202a 2c0d 0a20 2020 2020         *,..     
+0000b6c0: 2020 2066 7261 6d65 735f 7065 725f 6261     frames_per_ba
+0000b6d0: 7463 683a 2069 6e74 203d 2032 3030 2c0d  tch: int = 200,.
+0000b6e0: 0a20 2020 2020 2020 2074 6f74 616c 5f66  .        total_f
+0000b6f0: 7261 6d65 733a 204f 7074 696f 6e61 6c5b  rames: Optional[
+0000b700: 696e 745d 203d 202d 312c 0d0a 2020 2020  int] = -1,..    
+0000b710: 2020 2020 6465 7669 6365 3a20 4445 5649      device: DEVI
+0000b720: 4345 5f54 5950 494e 4720 3d20 4e6f 6e65  CE_TYPING = None
+0000b730: 2c0d 0a20 2020 2020 2020 2073 746f 7269  ,..        stori
+0000b740: 6e67 5f64 6576 6963 653a 204f 7074 696f  ng_device: Optio
+0000b750: 6e61 6c5b 556e 696f 6e5b 4445 5649 4345  nal[Union[DEVICE
+0000b760: 5f54 5950 494e 472c 2053 6571 7565 6e63  _TYPING, Sequenc
+0000b770: 655b 4445 5649 4345 5f54 5950 494e 475d  e[DEVICE_TYPING]
+0000b780: 5d5d 203d 204e 6f6e 652c 0d0a 2020 2020  ]] = None,..    
+0000b790: 2020 2020 6372 6561 7465 5f65 6e76 5f6b      create_env_k
+0000b7a0: 7761 7267 733a 204f 7074 696f 6e61 6c5b  wargs: Optional[
+0000b7b0: 5365 7175 656e 6365 5b64 6963 745d 5d20  Sequence[dict]] 
+0000b7c0: 3d20 4e6f 6e65 2c0d 0a20 2020 2020 2020  = None,..       
+0000b7d0: 206d 6178 5f66 7261 6d65 735f 7065 725f   max_frames_per_
+0000b7e0: 7472 616a 3a20 696e 7420 3d20 2d31 2c0d  traj: int = -1,.
+0000b7f0: 0a20 2020 2020 2020 2069 6e69 745f 7261  .        init_ra
+0000b800: 6e64 6f6d 5f66 7261 6d65 733a 2069 6e74  ndom_frames: int
+0000b810: 203d 202d 312c 0d0a 2020 2020 2020 2020   = -1,..        
+0000b820: 7265 7365 745f 6174 5f65 6163 685f 6974  reset_at_each_it
+0000b830: 6572 3a20 626f 6f6c 203d 2046 616c 7365  er: bool = False
+0000b840: 2c0d 0a20 2020 2020 2020 2070 6f73 7470  ,..        postp
+0000b850: 726f 633a 204f 7074 696f 6e61 6c5b 4361  roc: Optional[Ca
+0000b860: 6c6c 6162 6c65 5b5b 5465 6e73 6f72 4469  llable[[TensorDi
+0000b870: 6374 4261 7365 5d2c 2054 656e 736f 7244  ctBase], TensorD
+0000b880: 6963 7442 6173 655d 5d20 3d20 4e6f 6e65  ictBase]] = None
+0000b890: 2c0d 0a20 2020 2020 2020 2073 706c 6974  ,..        split
+0000b8a0: 5f74 7261 6a73 3a20 4f70 7469 6f6e 616c  _trajs: Optional
+0000b8b0: 5b62 6f6f 6c5d 203d 204e 6f6e 652c 0d0a  [bool] = None,..
+0000b8c0: 2020 2020 2020 2020 6578 706c 6f72 6174          explorat
+0000b8d0: 696f 6e5f 7479 7065 3a20 4578 706c 6f72  ion_type: Explor
+0000b8e0: 6174 696f 6e54 7970 6520 3d20 4445 4641  ationType = DEFA
+0000b8f0: 554c 545f 4558 504c 4f52 4154 494f 4e5f  ULT_EXPLORATION_
+0000b900: 5459 5045 2c0d 0a20 2020 2020 2020 2065  TYPE,..        e
+0000b910: 7870 6c6f 7261 7469 6f6e 5f6d 6f64 653d  xploration_mode=
+0000b920: 4e6f 6e65 2c0d 0a20 2020 2020 2020 2072  None,..        r
+0000b930: 6573 6574 5f77 6865 6e5f 646f 6e65 3a20  eset_when_done: 
+0000b940: 626f 6f6c 203d 2054 7275 652c 0d0a 2020  bool = True,..  
+0000b950: 2020 2020 2020 7072 6565 6d70 7469 7665        preemptive
+0000b960: 5f74 6872 6573 686f 6c64 3a20 666c 6f61  _threshold: floa
+0000b970: 7420 3d20 4e6f 6e65 2c0d 0a20 2020 2020  t = None,..     
+0000b980: 2020 2075 7064 6174 655f 6174 5f65 6163     update_at_eac
+0000b990: 685f 6261 7463 683a 2062 6f6f 6c20 3d20  h_batch: bool = 
+0000b9a0: 4661 6c73 652c 0d0a 2020 2020 2020 2020  False,..        
+0000b9b0: 6465 7669 6365 733d 4e6f 6e65 2c0d 0a20  devices=None,.. 
+0000b9c0: 2020 2020 2020 2073 746f 7269 6e67 5f64         storing_d
+0000b9d0: 6576 6963 6573 3d4e 6f6e 652c 0d0a 2020  evices=None,..  
+0000b9e0: 2020 293a 0d0a 2020 2020 2020 2020 6578    ):..        ex
+0000b9f0: 706c 6f72 6174 696f 6e5f 7479 7065 203d  ploration_type =
+0000ba00: 205f 636f 6e76 6572 745f 6578 706c 6f72   _convert_explor
+0000ba10: 6174 696f 6e5f 7479 7065 280d 0a20 2020  ation_type(..   
+0000ba20: 2020 2020 2020 2020 2065 7870 6c6f 7261           explora
+0000ba30: 7469 6f6e 5f6d 6f64 653d 6578 706c 6f72  tion_mode=explor
+0000ba40: 6174 696f 6e5f 6d6f 6465 2c20 6578 706c  ation_mode, expl
+0000ba50: 6f72 6174 696f 6e5f 7479 7065 3d65 7870  oration_type=exp
+0000ba60: 6c6f 7261 7469 6f6e 5f74 7970 650d 0a20  loration_type.. 
+0000ba70: 2020 2020 2020 2029 0d0a 2020 2020 2020         )..      
+0000ba80: 2020 7365 6c66 2e63 6c6f 7365 6420 3d20    self.closed = 
+0000ba90: 5472 7565 0d0a 2020 2020 2020 2020 7365  True..        se
+0000baa0: 6c66 2e63 7265 6174 655f 656e 765f 666e  lf.create_env_fn
+0000bab0: 203d 2063 7265 6174 655f 656e 765f 666e   = create_env_fn
+0000bac0: 0d0a 2020 2020 2020 2020 7365 6c66 2e6e  ..        self.n
+0000bad0: 756d 5f77 6f72 6b65 7273 203d 206c 656e  um_workers = len
+0000bae0: 2863 7265 6174 655f 656e 765f 666e 290d  (create_env_fn).
+0000baf0: 0a20 2020 2020 2020 2073 656c 662e 6372  .        self.cr
+0000bb00: 6561 7465 5f65 6e76 5f6b 7761 7267 7320  eate_env_kwargs 
+0000bb10: 3d20 280d 0a20 2020 2020 2020 2020 2020  = (..           
+0000bb20: 2063 7265 6174 655f 656e 765f 6b77 6172   create_env_kwar
+0000bb30: 6773 0d0a 2020 2020 2020 2020 2020 2020  gs..            
+0000bb40: 6966 2063 7265 6174 655f 656e 765f 6b77  if create_env_kw
+0000bb50: 6172 6773 2069 7320 6e6f 7420 4e6f 6e65  args is not None
+0000bb60: 0d0a 2020 2020 2020 2020 2020 2020 656c  ..            el
+0000bb70: 7365 205b 7b7d 2066 6f72 205f 2069 6e20  se [{} for _ in 
+0000bb80: 7261 6e67 6528 7365 6c66 2e6e 756d 5f77  range(self.num_w
+0000bb90: 6f72 6b65 7273 295d 0d0a 2020 2020 2020  orkers)]..      
+0000bba0: 2020 290d 0a20 2020 2020 2020 2023 2050    )..        # P
+0000bbb0: 7265 7061 7269 6e67 2064 6576 6963 6573  reparing devices
+0000bbc0: 3a0d 0a20 2020 2020 2020 2023 2057 6520  :..        # We 
+0000bbd0: 7761 6e74 2074 6865 2075 7365 7220 746f  want the user to
+0000bbe0: 2062 6520 6162 6c65 2074 6f20 6368 6f6f   be able to choo
+0000bbf0: 7365 2c20 666f 7220 6561 6368 2077 6f72  se, for each wor
+0000bc00: 6b65 722c 206f 6e20 7768 6963 680d 0a20  ker, on which.. 
+0000bc10: 2020 2020 2020 2023 2064 6576 6963 6520         # device 
+0000bc20: 7769 6c6c 2074 6865 2070 6f6c 6963 7920  will the policy 
+0000bc30: 6c69 7665 2061 6e64 2077 6869 6368 2064  live and which d
+0000bc40: 6576 6963 6520 7769 6c6c 2062 6520 7573  evice will be us
+0000bc50: 6564 2074 6f20 7374 6f72 650d 0a20 2020  ed to store..   
+0000bc60: 2020 2020 2023 2064 6174 612e 2054 686f       # data. Tho
+0000bc70: 7365 2064 6576 6963 6573 206d 6179 206f  se devices may o
+0000bc80: 7220 6d61 7920 6e6f 7420 6d61 7463 682e  r may not match.
+0000bc90: 0d0a 2020 2020 2020 2020 2320 4f6e 6520  ..        # One 
+0000bca0: 6361 7665 6174 2069 7320 7468 6174 2c20  caveat is that, 
+0000bcb0: 6966 2074 6865 7265 2069 7320 6f6e 6c79  if there is only
+0000bcc0: 206f 6e65 2064 6576 6963 6520 666f 7220   one device for 
+0000bcd0: 7468 6520 706f 6c69 6379 2c20 616e 640d  the policy, and.
+0000bce0: 0a20 2020 2020 2020 2023 2069 6620 7468  .        # if th
+0000bcf0: 6572 6520 6172 6520 6d75 6c74 6970 6c65  ere are multiple
+0000bd00: 2077 6f72 6b65 7273 2c20 7365 6e64 696e   workers, sendin
+0000bd10: 6720 7468 6520 7361 6d65 2064 6576 6963  g the same devic
+0000bd20: 6520 616e 6420 706f 6c69 6379 0d0a 2020  e and policy..  
+0000bd30: 2020 2020 2020 2320 746f 2062 6520 636f        # to be co
+0000bd40: 7069 6564 2074 6f20 6561 6368 2077 6f72  pied to each wor
+0000bd50: 6b65 7220 7769 6c6c 2072 6573 756c 7420  ker will result 
+0000bd60: 696e 206d 756c 7469 706c 6520 636f 7069  in multiple copi
+0000bd70: 6573 206f 6620 7468 650d 0a20 2020 2020  es of the..     
+0000bd80: 2020 2023 2073 616d 6520 706f 6c69 6379     # same policy
+0000bd90: 206f 6e20 7468 6520 7361 6d65 2064 6576   on the same dev
+0000bda0: 6963 652e 0d0a 2020 2020 2020 2020 2320  ice...        # 
+0000bdb0: 546f 2067 6f20 6172 6f75 6e64 2074 6869  To go around thi
+0000bdc0: 732c 2077 6520 646f 2074 6865 2063 6f70  s, we do the cop
+0000bdd0: 6965 7320 6f66 2074 6865 2070 6f6c 6963  ies of the polic
+0000bde0: 7920 696e 2074 6865 2073 6572 7665 720d  y in the server.
+0000bdf0: 0a20 2020 2020 2020 2023 2028 7468 6973  .        # (this
+0000be00: 206f 626a 6563 7429 2074 6f20 6561 6368   object) to each
+0000be10: 2070 6f73 7369 626c 6520 6465 7669 6365   possible device
+0000be20: 2c20 616e 6420 7365 6e64 2074 6f20 616c  , and send to al
+0000be30: 6c20 7468 650d 0a20 2020 2020 2020 2023  l the..        #
+0000be40: 2070 726f 6365 7373 6573 2074 6865 6972   processes their
+0000be50: 2063 6f70 7920 6f66 2074 6865 2070 6f6c   copy of the pol
+0000be60: 6963 792e 0d0a 2020 2020 2020 2020 6966  icy...        if
+0000be70: 2064 6576 6963 6573 2069 7320 6e6f 7420   devices is not 
+0000be80: 4e6f 6e65 3a0d 0a20 2020 2020 2020 2020  None:..         
+0000be90: 2020 2069 6620 6465 7669 6365 2069 7320     if device is 
+0000bea0: 6e6f 7420 4e6f 6e65 3a0d 0a20 2020 2020  not None:..     
+0000beb0: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+0000bec0: 2056 616c 7565 4572 726f 7228 2243 616e   ValueError("Can
+0000bed0: 6e6f 7420 7061 7373 2062 6f74 6820 6465  not pass both de
+0000bee0: 7669 6365 7320 616e 6420 6465 7669 6365  vices and device
+0000bef0: 2229 0d0a 2020 2020 2020 2020 2020 2020  ")..            
+0000bf00: 7761 726e 696e 6773 2e77 6172 6e28 0d0a  warnings.warn(..
+0000bf10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000bf20: 2260 6465 7669 6365 7360 206b 6579 776f  "`devices` keywo
+0000bf30: 7264 2061 7267 756d 656e 7420 7769 6c6c  rd argument will
+0000bf40: 2073 6f6f 6e20 6265 2064 6570 7265 6361   soon be depreca
+0000bf50: 7465 6420 6672 6f6d 206d 756c 7469 7072  ted from multipr
+0000bf60: 6f63 6573 7365 6420 636f 6c6c 6563 746f  ocessed collecto
+0000bf70: 7273 2e20 220d 0a20 2020 2020 2020 2020  rs. "..         
+0000bf80: 2020 2020 2020 2022 506c 6561 7365 2075         "Please u
+0000bf90: 7365 2060 6465 7669 6365 6020 696e 7374  se `device` inst
+0000bfa0: 6561 642e 220d 0a20 2020 2020 2020 2020  ead."..         
+0000bfb0: 2020 2029 0d0a 2020 2020 2020 2020 2020     )..          
+0000bfc0: 2020 6465 7669 6365 203d 2064 6576 6963    device = devic
+0000bfd0: 6573 0d0a 2020 2020 2020 2020 6966 2073  es..        if s
+0000bfe0: 746f 7269 6e67 5f64 6576 6963 6573 2069  toring_devices i
+0000bff0: 7320 6e6f 7420 4e6f 6e65 3a0d 0a20 2020  s not None:..   
+0000c000: 2020 2020 2020 2020 2069 6620 7374 6f72           if stor
+0000c010: 696e 675f 6465 7669 6365 2069 7320 6e6f  ing_device is no
+0000c020: 7420 4e6f 6e65 3a0d 0a20 2020 2020 2020  t None:..       
+0000c030: 2020 2020 2020 2020 2072 6169 7365 2056           raise V
+0000c040: 616c 7565 4572 726f 7228 2243 616e 6e6f  alueError("Canno
+0000c050: 7420 7061 7373 2062 6f74 6820 7374 6f72  t pass both stor
+0000c060: 696e 675f 6465 7669 6365 7320 616e 6420  ing_devices and 
+0000c070: 7374 6f72 696e 675f 6465 7669 6365 2229  storing_device")
+0000c080: 0d0a 2020 2020 2020 2020 2020 2020 7761  ..            wa
+0000c090: 726e 696e 6773 2e77 6172 6e28 0d0a 2020  rnings.warn(..  
+0000c0a0: 2020 2020 2020 2020 2020 2020 2020 2260                "`
+0000c0b0: 7374 6f72 696e 675f 6465 7669 6365 7360  storing_devices`
+0000c0c0: 206b 6579 776f 7264 2061 7267 756d 656e   keyword argumen
+0000c0d0: 7420 7769 6c6c 2073 6f6f 6e20 6265 2064  t will soon be d
+0000c0e0: 6570 7265 6361 7465 6420 6672 6f6d 206d  eprecated from m
+0000c0f0: 756c 7469 7072 6f63 6573 7365 6420 636f  ultiprocessed co
+0000c100: 6c6c 6563 746f 7273 2e20 220d 0a20 2020  llectors. "..   
+0000c110: 2020 2020 2020 2020 2020 2020 2022 506c               "Pl
+0000c120: 6561 7365 2075 7365 2060 7374 6f72 696e  ease use `storin
+0000c130: 675f 6465 7669 6365 6020 696e 7374 6561  g_device` instea
+0000c140: 642e 220d 0a20 2020 2020 2020 2020 2020  d."..           
+0000c150: 2029 0d0a 2020 2020 2020 2020 2020 2020   )..            
+0000c160: 7374 6f72 696e 675f 6465 7669 6365 203d  storing_device =
+0000c170: 2073 746f 7269 6e67 5f64 6576 6963 6573   storing_devices
+0000c180: 0d0a 0d0a 2020 2020 2020 2020 6465 6620  ....        def 
+0000c190: 6465 7669 6365 5f65 7272 5f6d 7367 2864  device_err_msg(d
+0000c1a0: 6576 6963 655f 6e61 6d65 2c20 6465 7669  evice_name, devi
+0000c1b0: 6365 735f 6c69 7374 293a 0d0a 2020 2020  ces_list):..    
+0000c1c0: 2020 2020 2020 2020 7265 7475 726e 2028          return (
+0000c1d0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+0000c1e0: 2020 6622 5468 6520 6c65 6e67 7468 206f    f"The length o
+0000c1f0: 6620 7468 6520 7b64 6576 6963 655f 6e61  f the {device_na
+0000c200: 6d65 7d20 6172 6775 6d65 6e74 2073 686f  me} argument sho
+0000c210: 756c 6420 6d61 7463 6820 7468 6520 220d  uld match the ".
+0000c220: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000c230: 2066 226e 756d 6265 7220 6f66 2077 6f72   f"number of wor
+0000c240: 6b65 7273 206f 6620 7468 6520 636f 6c6c  kers of the coll
+0000c250: 6563 746f 722e 2047 6f74 206c 656e 2822  ector. Got len("
+0000c260: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+0000c270: 2020 6622 6372 6561 7465 5f65 6e76 5f66    f"create_env_f
+0000c280: 6e29 3d7b 7365 6c66 2e6e 756d 5f77 6f72  n)={self.num_wor
+0000c290: 6b65 7273 7d20 616e 6420 6c65 6e28 220d  kers} and len(".
+0000c2a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000c2b0: 2066 2273 746f 7269 6e67 5f64 6576 6963   f"storing_devic
+0000c2c0: 6529 3d7b 6c65 6e28 6465 7669 6365 735f  e)={len(devices_
+0000c2d0: 6c69 7374 297d 220d 0a20 2020 2020 2020  list)}"..       
+0000c2e0: 2020 2020 2029 0d0a 0d0a 2020 2020 2020       )....      
+0000c2f0: 2020 6966 2069 7369 6e73 7461 6e63 6528    if isinstance(
+0000c300: 6465 7669 6365 2c20 2873 7472 2c20 696e  device, (str, in
+0000c310: 742c 2074 6f72 6368 2e64 6576 6963 6529  t, torch.device)
+0000c320: 293a 0d0a 2020 2020 2020 2020 2020 2020  ):..            
+0000c330: 6465 7669 6365 203d 205b 746f 7263 682e  device = [torch.
+0000c340: 6465 7669 6365 2864 6576 6963 6529 2066  device(device) f
+0000c350: 6f72 205f 2069 6e20 7261 6e67 6528 7365  or _ in range(se
+0000c360: 6c66 2e6e 756d 5f77 6f72 6b65 7273 295d  lf.num_workers)]
+0000c370: 0d0a 2020 2020 2020 2020 656c 6966 2064  ..        elif d
+0000c380: 6576 6963 6520 6973 204e 6f6e 653a 0d0a  evice is None:..
+0000c390: 2020 2020 2020 2020 2020 2020 6465 7669              devi
+0000c3a0: 6365 203d 205b 4e6f 6e65 2066 6f72 205f  ce = [None for _
+0000c3b0: 2069 6e20 7261 6e67 6528 7365 6c66 2e6e   in range(self.n
+0000c3c0: 756d 5f77 6f72 6b65 7273 295d 0d0a 2020  um_workers)]..  
+0000c3d0: 2020 2020 2020 656c 6966 2069 7369 6e73        elif isins
+0000c3e0: 7461 6e63 6528 6465 7669 6365 2c20 5365  tance(device, Se
+0000c3f0: 7175 656e 6365 293a 0d0a 2020 2020 2020  quence):..      
+0000c400: 2020 2020 2020 6966 206c 656e 2864 6576        if len(dev
+0000c410: 6963 6529 2021 3d20 7365 6c66 2e6e 756d  ice) != self.num
+0000c420: 5f77 6f72 6b65 7273 3a0d 0a20 2020 2020  _workers:..     
+0000c430: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+0000c440: 2052 756e 7469 6d65 4572 726f 7228 6465   RuntimeError(de
+0000c450: 7669 6365 5f65 7272 5f6d 7367 2822 6465  vice_err_msg("de
+0000c460: 7669 6365 7322 2c20 6465 7669 6365 2929  vices", device))
+0000c470: 0d0a 2020 2020 2020 2020 2020 2020 6465  ..            de
+0000c480: 7669 6365 203d 205b 746f 7263 682e 6465  vice = [torch.de
+0000c490: 7669 6365 285f 6465 7669 6365 2920 666f  vice(_device) fo
+0000c4a0: 7220 5f64 6576 6963 6520 696e 2064 6576  r _device in dev
+0000c4b0: 6963 655d 0d0a 2020 2020 2020 2020 656c  ice]..        el
+0000c4c0: 7365 3a0d 0a20 2020 2020 2020 2020 2020  se:..           
+0000c4d0: 2072 6169 7365 2056 616c 7565 4572 726f   raise ValueErro
+0000c4e0: 7228 0d0a 2020 2020 2020 2020 2020 2020  r(..            
+0000c4f0: 2020 2020 2264 6576 6963 6573 2073 686f      "devices sho
+0000c500: 756c 6420 6265 2065 6974 6865 7220 4e6f  uld be either No
+0000c510: 6e65 2c20 6120 746f 7263 682e 6465 7669  ne, a torch.devi
+0000c520: 6365 206f 7220 6571 7569 7661 6c65 6e74  ce or equivalent
+0000c530: 2022 0d0a 2020 2020 2020 2020 2020 2020   "..            
+0000c540: 2020 2020 226f 7220 616e 2069 7465 7261      "or an itera
+0000c550: 626c 6520 6f66 2064 6576 6963 6573 2e20  ble of devices. 
+0000c560: 220d 0a20 2020 2020 2020 2020 2020 2020  "..             
+0000c570: 2020 2066 2246 6f75 6e64 207b 7479 7065     f"Found {type
+0000c580: 2864 6576 6963 6529 7d20 696e 7374 6561  (device)} instea
+0000c590: 642e 220d 0a20 2020 2020 2020 2020 2020  d."..           
+0000c5a0: 2029 0d0a 2020 2020 2020 2020 7365 6c66   )..        self
+0000c5b0: 2e5f 706f 6c69 6379 5f64 6963 7420 3d20  ._policy_dict = 
+0000c5c0: 7b7d 0d0a 2020 2020 2020 2020 7365 6c66  {}..        self
+0000c5d0: 2e5f 706f 6c69 6379 5f77 6569 6768 7473  ._policy_weights
+0000c5e0: 5f64 6963 7420 3d20 7b7d 0d0a 2020 2020  _dict = {}..    
+0000c5f0: 2020 2020 7365 6c66 2e5f 6765 745f 7765      self._get_we
+0000c600: 6967 6874 735f 666e 5f64 6963 7420 3d20  ights_fn_dict = 
+0000c610: 7b7d 0d0a 0d0a 2020 2020 2020 2020 666f  {}....        fo
+0000c620: 7220 692c 2028 5f64 6576 6963 652c 2063  r i, (_device, c
+0000c630: 7265 6174 655f 656e 762c 206b 7761 7267  reate_env, kwarg
+0000c640: 7329 2069 6e20 656e 756d 6572 6174 6528  s) in enumerate(
+0000c650: 0d0a 2020 2020 2020 2020 2020 2020 7a69  ..            zi
+0000c660: 7028 6465 7669 6365 2c20 7365 6c66 2e63  p(device, self.c
+0000c670: 7265 6174 655f 656e 765f 666e 2c20 7365  reate_env_fn, se
+0000c680: 6c66 2e63 7265 6174 655f 656e 765f 6b77  lf.create_env_kw
+0000c690: 6172 6773 290d 0a20 2020 2020 2020 2029  args)..        )
+0000c6a0: 3a0d 0a20 2020 2020 2020 2020 2020 2069  :..            i
+0000c6b0: 6620 5f64 6576 6963 6520 696e 2073 656c  f _device in sel
+0000c6c0: 662e 5f70 6f6c 6963 795f 6469 6374 3a0d  f._policy_dict:.
+0000c6d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000c6e0: 2064 6576 6963 655b 695d 203d 205f 6465   device[i] = _de
+0000c6f0: 7669 6365 0d0a 2020 2020 2020 2020 2020  vice..          
+0000c700: 2020 2020 2020 636f 6e74 696e 7565 0d0a        continue..
+0000c710: 0d0a 2020 2020 2020 2020 2020 2020 6966  ..            if
+0000c720: 2068 6173 6174 7472 2863 7265 6174 655f   hasattr(create_
+0000c730: 656e 762c 2022 6f62 7365 7276 6174 696f  env, "observatio
+0000c740: 6e5f 7370 6563 2229 3a0d 0a20 2020 2020  n_spec"):..     
+0000c750: 2020 2020 2020 2020 2020 206f 6273 6572             obser
+0000c760: 7661 7469 6f6e 5f73 7065 6320 3d20 6372  vation_spec = cr
+0000c770: 6561 7465 5f65 6e76 2e6f 6273 6572 7661  eate_env.observa
+0000c780: 7469 6f6e 5f73 7065 630d 0a20 2020 2020  tion_spec..     
+0000c790: 2020 2020 2020 2065 6c73 653a 0d0a 2020         else:..  
+0000c7a0: 2020 2020 2020 2020 2020 2020 2020 7472                tr
+0000c7b0: 793a 0d0a 2020 2020 2020 2020 2020 2020  y:..            
+0000c7c0: 2020 2020 2020 2020 6f62 7365 7276 6174          observat
+0000c7d0: 696f 6e5f 7370 6563 203d 2063 7265 6174  ion_spec = creat
+0000c7e0: 655f 656e 7628 2a2a 6b77 6172 6773 292e  e_env(**kwargs).
+0000c7f0: 6f62 7365 7276 6174 696f 6e5f 7370 6563  observation_spec
+0000c800: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+0000c810: 2020 6578 6365 7074 3a20 2023 206e 6f71    except:  # noq
+0000c820: 610d 0a20 2020 2020 2020 2020 2020 2020  a..             
+0000c830: 2020 2020 2020 206f 6273 6572 7661 7469         observati
+0000c840: 6f6e 5f73 7065 6320 3d20 4e6f 6e65 0d0a  on_spec = None..
+0000c850: 0d0a 2020 2020 2020 2020 2020 2020 5f70  ..            _p
+0000c860: 6f6c 6963 792c 205f 6465 7669 6365 2c20  olicy, _device, 
+0000c870: 5f67 6574 5f77 6569 6768 745f 666e 203d  _get_weight_fn =
+0000c880: 2073 656c 662e 5f67 6574 5f70 6f6c 6963   self._get_polic
+0000c890: 795f 616e 645f 6465 7669 6365 280d 0a20  y_and_device(.. 
+0000c8a0: 2020 2020 2020 2020 2020 2020 2020 2070                 p
+0000c8b0: 6f6c 6963 793d 706f 6c69 6379 2c20 6465  olicy=policy, de
+0000c8c0: 7669 6365 3d5f 6465 7669 6365 2c20 6f62  vice=_device, ob
+0000c8d0: 7365 7276 6174 696f 6e5f 7370 6563 3d6f  servation_spec=o
+0000c8e0: 6273 6572 7661 7469 6f6e 5f73 7065 630d  bservation_spec.
+0000c8f0: 0a20 2020 2020 2020 2020 2020 2029 0d0a  .            )..
+0000c900: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+0000c910: 2e5f 706f 6c69 6379 5f64 6963 745b 5f64  ._policy_dict[_d
+0000c920: 6576 6963 655d 203d 205f 706f 6c69 6379  evice] = _policy
+0000c930: 0d0a 2020 2020 2020 2020 2020 2020 6966  ..            if
+0000c940: 2069 7369 6e73 7461 6e63 6528 5f70 6f6c   isinstance(_pol
+0000c950: 6963 792c 206e 6e2e 4d6f 6475 6c65 293a  icy, nn.Module):
+0000c960: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+0000c970: 2020 7061 7261 6d5f 6469 6374 203d 2064    param_dict = d
+0000c980: 6963 7428 5f70 6f6c 6963 792e 6e61 6d65  ict(_policy.name
+0000c990: 645f 7061 7261 6d65 7465 7273 2829 290d  d_parameters()).
+0000c9a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000c9b0: 2070 6172 616d 5f64 6963 742e 7570 6461   param_dict.upda
+0000c9c0: 7465 285f 706f 6c69 6379 2e6e 616d 6564  te(_policy.named
+0000c9d0: 5f62 7566 6665 7273 2829 290d 0a20 2020  _buffers())..   
+0000c9e0: 2020 2020 2020 2020 2020 2020 2073 656c               sel
+0000c9f0: 662e 5f70 6f6c 6963 795f 7765 6967 6874  f._policy_weight
+0000ca00: 735f 6469 6374 5b5f 6465 7669 6365 5d20  s_dict[_device] 
+0000ca10: 3d20 5465 6e73 6f72 4469 6374 2870 6172  = TensorDict(par
+0000ca20: 616d 5f64 6963 742c 205b 5d29 0d0a 2020  am_dict, [])..  
+0000ca30: 2020 2020 2020 2020 2020 656c 7365 3a0d            else:.
+0000ca40: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000ca50: 2073 656c 662e 5f70 6f6c 6963 795f 7765   self._policy_we
+0000ca60: 6967 6874 735f 6469 6374 5b5f 6465 7669  ights_dict[_devi
+0000ca70: 6365 5d20 3d20 5465 6e73 6f72 4469 6374  ce] = TensorDict
+0000ca80: 287b 7d2c 205b 5d29 0d0a 0d0a 2020 2020  ({}, [])....    
+0000ca90: 2020 2020 2020 2020 7365 6c66 2e5f 6765          self._ge
+0000caa0: 745f 7765 6967 6874 735f 666e 5f64 6963  t_weights_fn_dic
+0000cab0: 745b 5f64 6576 6963 655d 203d 205f 6765  t[_device] = _ge
+0000cac0: 745f 7765 6967 6874 5f66 6e0d 0a20 2020  t_weight_fn..   
+0000cad0: 2020 2020 2020 2020 2064 6576 6963 655b           device[
+0000cae0: 695d 203d 205f 6465 7669 6365 0d0a 2020  i] = _device..  
+0000caf0: 2020 2020 2020 7365 6c66 2e64 6576 6963        self.devic
+0000cb00: 6520 3d20 6465 7669 6365 0d0a 0d0a 2020  e = device....  
+0000cb10: 2020 2020 2020 6966 2073 746f 7269 6e67        if storing
+0000cb20: 5f64 6576 6963 6520 6973 204e 6f6e 653a  _device is None:
+0000cb30: 0d0a 2020 2020 2020 2020 2020 2020 7365  ..            se
+0000cb40: 6c66 2e73 746f 7269 6e67 5f64 6576 6963  lf.storing_devic
+0000cb50: 6520 3d20 7365 6c66 2e64 6576 6963 650d  e = self.device.
+0000cb60: 0a20 2020 2020 2020 2065 6c73 653a 0d0a  .        else:..
+0000cb70: 2020 2020 2020 2020 2020 2020 6966 2069              if i
+0000cb80: 7369 6e73 7461 6e63 6528 7374 6f72 696e  sinstance(storin
+0000cb90: 675f 6465 7669 6365 2c20 2873 7472 2c20  g_device, (str, 
+0000cba0: 696e 742c 2074 6f72 6368 2e64 6576 6963  int, torch.devic
+0000cbb0: 6529 293a 0d0a 2020 2020 2020 2020 2020  e)):..          
+0000cbc0: 2020 2020 2020 7365 6c66 2e73 746f 7269        self.stori
+0000cbd0: 6e67 5f64 6576 6963 6520 3d20 5b0d 0a20  ng_device = [.. 
+0000cbe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cbf0: 2020 2074 6f72 6368 2e64 6576 6963 6528     torch.device(
+0000cc00: 7374 6f72 696e 675f 6465 7669 6365 2920  storing_device) 
+0000cc10: 666f 7220 5f20 696e 2072 616e 6765 2873  for _ in range(s
+0000cc20: 656c 662e 6e75 6d5f 776f 726b 6572 7329  elf.num_workers)
+0000cc30: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+0000cc40: 2020 5d0d 0a20 2020 2020 2020 2020 2020    ]..           
+0000cc50: 2065 6c69 6620 6973 696e 7374 616e 6365   elif isinstance
+0000cc60: 2873 746f 7269 6e67 5f64 6576 6963 652c  (storing_device,
+0000cc70: 2053 6571 7565 6e63 6529 3a0d 0a20 2020   Sequence):..   
+0000cc80: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+0000cc90: 6c65 6e28 7374 6f72 696e 675f 6465 7669  len(storing_devi
+0000cca0: 6365 2920 213d 2073 656c 662e 6e75 6d5f  ce) != self.num_
+0000ccb0: 776f 726b 6572 733a 0d0a 2020 2020 2020  workers:..      
+0000ccc0: 2020 2020 2020 2020 2020 2020 2020 7261                ra
+0000ccd0: 6973 6520 5275 6e74 696d 6545 7272 6f72  ise RuntimeError
+0000cce0: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
+0000ccf0: 2020 2020 2020 2020 2020 2064 6576 6963             devic
+0000cd00: 655f 6572 725f 6d73 6728 2273 746f 7269  e_err_msg("stori
+0000cd10: 6e67 5f64 6576 6963 6573 222c 2073 746f  ng_devices", sto
+0000cd20: 7269 6e67 5f64 6576 6963 6529 0d0a 2020  ring_device)..  
+0000cd30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cd40: 2020 290d 0a20 2020 2020 2020 2020 2020    )..           
+0000cd50: 2020 2020 2073 656c 662e 7374 6f72 696e       self.storin
+0000cd60: 675f 6465 7669 6365 203d 205b 0d0a 2020  g_device = [..  
+0000cd70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cd80: 2020 746f 7263 682e 6465 7669 6365 285f    torch.device(_
+0000cd90: 7374 6f72 696e 675f 6465 7669 6365 2920  storing_device) 
+0000cda0: 666f 7220 5f73 746f 7269 6e67 5f64 6576  for _storing_dev
+0000cdb0: 6963 6520 696e 2073 746f 7269 6e67 5f64  ice in storing_d
+0000cdc0: 6576 6963 650d 0a20 2020 2020 2020 2020  evice..         
+0000cdd0: 2020 2020 2020 205d 0d0a 2020 2020 2020         ]..      
+0000cde0: 2020 2020 2020 656c 7365 3a0d 0a20 2020        else:..   
+0000cdf0: 2020 2020 2020 2020 2020 2020 2072 6169               rai
+0000ce00: 7365 2056 616c 7565 4572 726f 7228 0d0a  se ValueError(..
+0000ce10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ce20: 2020 2020 2273 746f 7269 6e67 5f64 6576      "storing_dev
+0000ce30: 6963 6573 2073 686f 756c 6420 6265 2065  ices should be e
+0000ce40: 6974 6865 7220 6120 746f 7263 682e 6465  ither a torch.de
+0000ce50: 7669 6365 206f 7220 6571 7569 7661 6c65  vice or equivale
+0000ce60: 6e74 206f 7220 616e 2069 7465 7261 626c  nt or an iterabl
+0000ce70: 6520 6f66 2064 6576 6963 6573 2e20 220d  e of devices. ".
+0000ce80: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000ce90: 2020 2020 2066 2246 6f75 6e64 207b 7479       f"Found {ty
+0000cea0: 7065 2873 746f 7269 6e67 5f64 6576 6963  pe(storing_devic
+0000ceb0: 6529 7d20 696e 7374 6561 642e 220d 0a20  e)} instead.".. 
+0000cec0: 2020 2020 2020 2020 2020 2020 2020 2029                 )
+0000ced0: 0d0a 0d0a 2020 2020 2020 2020 6966 2074  ....        if t
+0000cee0: 6f74 616c 5f66 7261 6d65 7320 6973 204e  otal_frames is N
+0000cef0: 6f6e 6520 6f72 2074 6f74 616c 5f66 7261  one or total_fra
+0000cf00: 6d65 7320 3c20 303a 0d0a 2020 2020 2020  mes < 0:..      
+0000cf10: 2020 2020 2020 746f 7461 6c5f 6672 616d        total_fram
+0000cf20: 6573 203d 2066 6c6f 6174 2822 696e 6622  es = float("inf"
+0000cf30: 290d 0a20 2020 2020 2020 2065 6c73 653a  )..        else:
+0000cf40: 0d0a 2020 2020 2020 2020 2020 2020 7265  ..            re
+0000cf50: 6d61 696e 6465 7220 3d20 746f 7461 6c5f  mainder = total_
+0000cf60: 6672 616d 6573 2025 2066 7261 6d65 735f  frames % frames_
+0000cf70: 7065 725f 6261 7463 680d 0a20 2020 2020  per_batch..     
+0000cf80: 2020 2020 2020 2069 6620 7265 6d61 696e         if remain
+0000cf90: 6465 7220 213d 2030 2061 6e64 2052 4c5f  der != 0 and RL_
+0000cfa0: 5741 524e 494e 4753 3a0d 0a20 2020 2020  WARNINGS:..     
+0000cfb0: 2020 2020 2020 2020 2020 2077 6172 6e69             warni
+0000cfc0: 6e67 732e 7761 726e 280d 0a20 2020 2020  ngs.warn(..     
+0000cfd0: 2020 2020 2020 2020 2020 2020 2020 2066                 f
+0000cfe0: 2274 6f74 616c 5f66 7261 6d65 7320 287b  "total_frames ({
+0000cff0: 746f 7461 6c5f 6672 616d 6573 7d29 2069  total_frames}) i
+0000d000: 7320 6e6f 7420 6578 6163 746c 7920 6469  s not exactly di
+0000d010: 7669 7369 626c 6520 6279 2066 7261 6d65  visible by frame
+0000d020: 735f 7065 725f 6261 7463 6820 287b 6672  s_per_batch ({fr
+0000d030: 616d 6573 5f70 6572 5f62 6174 6368 7d29  ames_per_batch})
+0000d040: 2e22 0d0a 2020 2020 2020 2020 2020 2020  ."..            
+0000d050: 2020 2020 2020 2020 6622 5468 6973 206d          f"This m
+0000d060: 6561 6e73 207b 6672 616d 6573 5f70 6572  eans {frames_per
+0000d070: 5f62 6174 6368 202d 2072 656d 6169 6e64  _batch - remaind
+0000d080: 6572 7d20 6164 6469 7469 6f6e 616c 2066  er} additional f
+0000d090: 7261 6d65 7320 7769 6c6c 2062 6520 636f  rames will be co
+0000d0a0: 6c6c 6563 7465 642e 220d 0a20 2020 2020  llected."..     
+0000d0b0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+0000d0c0: 546f 2073 696c 656e 6365 2074 6869 7320  To silence this 
+0000d0d0: 6d65 7373 6167 652c 2073 6574 2074 6865  message, set the
+0000d0e0: 2065 6e76 6972 6f6e 6d65 6e74 2076 6172   environment var
+0000d0f0: 6961 626c 6520 524c 5f57 4152 4e49 4e47  iable RL_WARNING
+0000d100: 5320 746f 2046 616c 7365 2e22 0d0a 2020  S to False."..  
+0000d110: 2020 2020 2020 2020 2020 2020 2020 290d                ).
+0000d120: 0a20 2020 2020 2020 2073 656c 662e 746f  .        self.to
+0000d130: 7461 6c5f 6672 616d 6573 203d 2074 6f74  tal_frames = tot
+0000d140: 616c 5f66 7261 6d65 730d 0a20 2020 2020  al_frames..     
+0000d150: 2020 2073 656c 662e 7265 7365 745f 6174     self.reset_at
+0000d160: 5f65 6163 685f 6974 6572 203d 2072 6573  _each_iter = res
+0000d170: 6574 5f61 745f 6561 6368 5f69 7465 720d  et_at_each_iter.
+0000d180: 0a20 2020 2020 2020 2073 656c 662e 706f  .        self.po
+0000d190: 7374 7072 6f63 7320 3d20 706f 7374 7072  stprocs = postpr
+0000d1a0: 6f63 0d0a 2020 2020 2020 2020 7365 6c66  oc..        self
+0000d1b0: 2e6d 6178 5f66 7261 6d65 735f 7065 725f  .max_frames_per_
+0000d1c0: 7472 616a 203d 206d 6178 5f66 7261 6d65  traj = max_frame
+0000d1d0: 735f 7065 725f 7472 616a 0d0a 2020 2020  s_per_traj..    
+0000d1e0: 2020 2020 7365 6c66 2e72 6571 7565 7374      self.request
+0000d1f0: 6564 5f66 7261 6d65 735f 7065 725f 6261  ed_frames_per_ba
+0000d200: 7463 6820 3d20 6672 616d 6573 5f70 6572  tch = frames_per
+0000d210: 5f62 6174 6368 0d0a 2020 2020 2020 2020  _batch..        
+0000d220: 7365 6c66 2e72 6573 6574 5f77 6865 6e5f  self.reset_when_
+0000d230: 646f 6e65 203d 2072 6573 6574 5f77 6865  done = reset_whe
+0000d240: 6e5f 646f 6e65 0d0a 2020 2020 2020 2020  n_done..        
+0000d250: 6966 2073 706c 6974 5f74 7261 6a73 2069  if split_trajs i
+0000d260: 7320 4e6f 6e65 3a0d 0a20 2020 2020 2020  s None:..       
+0000d270: 2020 2020 2073 706c 6974 5f74 7261 6a73       split_trajs
+0000d280: 203d 2046 616c 7365 0d0a 2020 2020 2020   = False..      
+0000d290: 2020 656c 6966 206e 6f74 2073 656c 662e    elif not self.
+0000d2a0: 7265 7365 745f 7768 656e 5f64 6f6e 6520  reset_when_done 
+0000d2b0: 616e 6420 7370 6c69 745f 7472 616a 733a  and split_trajs:
+0000d2c0: 0d0a 2020 2020 2020 2020 2020 2020 7261  ..            ra
+0000d2d0: 6973 6520 5275 6e74 696d 6545 7272 6f72  ise RuntimeError
+0000d2e0: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
+0000d2f0: 2020 2022 4361 6e6e 6f74 2073 706c 6974     "Cannot split
+0000d300: 2074 7261 6a65 6374 6f72 6965 7320 7768   trajectories wh
+0000d310: 656e 2072 6573 6574 5f77 6865 6e5f 646f  en reset_when_do
+0000d320: 6e65 2069 7320 4661 6c73 652e 220d 0a20  ne is False.".. 
+0000d330: 2020 2020 2020 2020 2020 2029 0d0a 2020             )..  
+0000d340: 2020 2020 2020 7365 6c66 2e73 706c 6974        self.split
+0000d350: 5f74 7261 6a73 203d 2073 706c 6974 5f74  _trajs = split_t
+0000d360: 7261 6a73 0d0a 2020 2020 2020 2020 7365  rajs..        se
+0000d370: 6c66 2e69 6e69 745f 7261 6e64 6f6d 5f66  lf.init_random_f
+0000d380: 7261 6d65 7320 3d20 696e 6974 5f72 616e  rames = init_ran
+0000d390: 646f 6d5f 6672 616d 6573 0d0a 2020 2020  dom_frames..    
+0000d3a0: 2020 2020 7365 6c66 2e75 7064 6174 655f      self.update_
+0000d3b0: 6174 5f65 6163 685f 6261 7463 6820 3d20  at_each_batch = 
+0000d3c0: 7570 6461 7465 5f61 745f 6561 6368 5f62  update_at_each_b
+0000d3d0: 6174 6368 0d0a 2020 2020 2020 2020 7365  atch..        se
+0000d3e0: 6c66 2e65 7870 6c6f 7261 7469 6f6e 5f74  lf.exploration_t
+0000d3f0: 7970 6520 3d20 6578 706c 6f72 6174 696f  ype = exploratio
+0000d400: 6e5f 7479 7065 0d0a 2020 2020 2020 2020  n_type..        
+0000d410: 7365 6c66 2e66 7261 6d65 735f 7065 725f  self.frames_per_
+0000d420: 776f 726b 6572 203d 206e 702e 696e 660d  worker = np.inf.
+0000d430: 0a20 2020 2020 2020 2069 6620 7072 6565  .        if pree
+0000d440: 6d70 7469 7665 5f74 6872 6573 686f 6c64  mptive_threshold
+0000d450: 2069 7320 6e6f 7420 4e6f 6e65 3a0d 0a20   is not None:.. 
+0000d460: 2020 2020 2020 2020 2020 2069 6620 5f69             if _i
+0000d470: 735f 6f73 783a 0d0a 2020 2020 2020 2020  s_osx:..        
+0000d480: 2020 2020 2020 2020 7261 6973 6520 4e6f          raise No
+0000d490: 7449 6d70 6c65 6d65 6e74 6564 4572 726f  tImplementedErro
+0000d4a0: 7228 0d0a 2020 2020 2020 2020 2020 2020  r(..            
+0000d4b0: 2020 2020 2020 2020 2243 616e 6e6f 7420          "Cannot 
+0000d4c0: 7573 6520 7072 6565 6d70 7469 6f6e 206f  use preemption o
+0000d4d0: 6e20 4f53 5820 6475 6520 746f 2051 7565  n OSX due to Que
+0000d4e0: 7565 2e71 7369 7a65 2829 206e 6f74 2062  ue.qsize() not b
+0000d4f0: 6569 6e67 2069 6d70 6c65 6d65 6e74 6564  eing implemented
+0000d500: 206f 6e20 7468 6973 2070 6c61 7466 6f72   on this platfor
+0000d510: 6d2e 220d 0a20 2020 2020 2020 2020 2020  m."..           
+0000d520: 2020 2020 2029 0d0a 2020 2020 2020 2020       )..        
+0000d530: 2020 2020 7365 6c66 2e70 7265 656d 7074      self.preempt
+0000d540: 6976 655f 7468 7265 7368 6f6c 6420 3d20  ive_threshold = 
+0000d550: 6e70 2e63 6c69 7028 7072 6565 6d70 7469  np.clip(preempti
+0000d560: 7665 5f74 6872 6573 686f 6c64 2c20 302e  ve_threshold, 0.
+0000d570: 302c 2031 2e30 290d 0a20 2020 2020 2020  0, 1.0)..       
+0000d580: 2020 2020 206d 616e 6167 6572 203d 205f       manager = _
+0000d590: 496e 7465 7272 7570 746f 724d 616e 6167  InterruptorManag
+0000d5a0: 6572 2829 0d0a 2020 2020 2020 2020 2020  er()..          
+0000d5b0: 2020 6d61 6e61 6765 722e 7374 6172 7428    manager.start(
+0000d5c0: 290d 0a20 2020 2020 2020 2020 2020 2073  )..            s
+0000d5d0: 656c 662e 696e 7465 7272 7570 746f 7220  elf.interruptor 
+0000d5e0: 3d20 6d61 6e61 6765 722e 5f49 6e74 6572  = manager._Inter
+0000d5f0: 7275 7074 6f72 2829 0d0a 2020 2020 2020  ruptor()..      
+0000d600: 2020 656c 7365 3a0d 0a20 2020 2020 2020    else:..       
+0000d610: 2020 2020 2073 656c 662e 7072 6565 6d70       self.preemp
+0000d620: 7469 7665 5f74 6872 6573 686f 6c64 203d  tive_threshold =
+0000d630: 2031 2e30 0d0a 2020 2020 2020 2020 2020   1.0..          
+0000d640: 2020 7365 6c66 2e69 6e74 6572 7275 7074    self.interrupt
+0000d650: 6f72 203d 204e 6f6e 650d 0a20 2020 2020  or = None..     
+0000d660: 2020 2073 656c 662e 5f72 756e 5f70 726f     self._run_pro
+0000d670: 6365 7373 6573 2829 0d0a 2020 2020 2020  cesses()..      
+0000d680: 2020 7365 6c66 2e5f 6578 636c 7564 655f    self._exclude_
+0000d690: 7072 6976 6174 655f 6b65 7973 203d 2054  private_keys = T
+0000d6a0: 7275 650d 0a0d 0a20 2020 2040 7072 6f70  rue....    @prop
+0000d6b0: 6572 7479 0d0a 2020 2020 6465 6620 6672  erty..    def fr
+0000d6c0: 616d 6573 5f70 6572 5f62 6174 6368 5f77  ames_per_batch_w
+0000d6d0: 6f72 6b65 7228 7365 6c66 293a 0d0a 2020  orker(self):..  
+0000d6e0: 2020 2020 2020 7261 6973 6520 4e6f 7449        raise NotI
+0000d6f0: 6d70 6c65 6d65 6e74 6564 4572 726f 720d  mplementedError.
+0000d700: 0a0d 0a20 2020 2064 6566 2075 7064 6174  ...    def updat
+0000d710: 655f 706f 6c69 6379 5f77 6569 6768 7473  e_policy_weights
+0000d720: 5f28 7365 6c66 2c20 706f 6c69 6379 5f77  _(self, policy_w
+0000d730: 6569 6768 7473 3d4e 6f6e 6529 202d 3e20  eights=None) -> 
+0000d740: 4e6f 6e65 3a0d 0a20 2020 2020 2020 2066  None:..        f
+0000d750: 6f72 205f 6465 7669 6365 2069 6e20 7365  or _device in se
+0000d760: 6c66 2e5f 706f 6c69 6379 5f64 6963 743a  lf._policy_dict:
+0000d770: 0d0a 2020 2020 2020 2020 2020 2020 6966  ..            if
+0000d780: 2070 6f6c 6963 795f 7765 6967 6874 7320   policy_weights 
+0000d790: 6973 206e 6f74 204e 6f6e 653a 0d0a 2020  is not None:..  
+0000d7a0: 2020 2020 2020 2020 2020 2020 2020 7365                se
+0000d7b0: 6c66 2e5f 706f 6c69 6379 5f77 6569 6768  lf._policy_weigh
+0000d7c0: 7473 5f64 6963 745b 5f64 6576 6963 655d  ts_dict[_device]
+0000d7d0: 2e61 7070 6c79 286c 616d 6264 6120 783a  .apply(lambda x:
+0000d7e0: 2078 2e64 6174 6129 2e75 7064 6174 655f   x.data).update_
+0000d7f0: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
+0000d800: 2020 2020 2020 2070 6f6c 6963 795f 7765         policy_we
+0000d810: 6967 6874 730d 0a20 2020 2020 2020 2020  ights..         
+0000d820: 2020 2020 2020 2029 0d0a 2020 2020 2020         )..      
+0000d830: 2020 2020 2020 656c 6966 2073 656c 662e        elif self.
+0000d840: 5f67 6574 5f77 6569 6768 7473 5f66 6e5f  _get_weights_fn_
+0000d850: 6469 6374 5b5f 6465 7669 6365 5d20 6973  dict[_device] is
+0000d860: 206e 6f74 204e 6f6e 653a 0d0a 2020 2020   not None:..    
+0000d870: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+0000d880: 2e5f 706f 6c69 6379 5f77 6569 6768 7473  ._policy_weights
+0000d890: 5f64 6963 745b 5f64 6576 6963 655d 2e75  _dict[_device].u
+0000d8a0: 7064 6174 655f 280d 0a20 2020 2020 2020  pdate_(..       
+0000d8b0: 2020 2020 2020 2020 2020 2020 2073 656c               sel
+0000d8c0: 662e 5f67 6574 5f77 6569 6768 7473 5f66  f._get_weights_f
+0000d8d0: 6e5f 6469 6374 5b5f 6465 7669 6365 5d28  n_dict[_device](
+0000d8e0: 290d 0a20 2020 2020 2020 2020 2020 2020  )..             
+0000d8f0: 2020 2029 0d0a 0d0a 2020 2020 4070 726f     )....    @pro
+0000d900: 7065 7274 790d 0a20 2020 2064 6566 205f  perty..    def _
+0000d910: 7175 6575 655f 6c65 6e28 7365 6c66 2920  queue_len(self) 
+0000d920: 2d3e 2069 6e74 3a0d 0a20 2020 2020 2020  -> int:..       
+0000d930: 2072 6169 7365 204e 6f74 496d 706c 656d   raise NotImplem
+0000d940: 656e 7465 6445 7272 6f72 0d0a 0d0a 2020  entedError....  
+0000d950: 2020 6465 6620 5f72 756e 5f70 726f 6365    def _run_proce
+0000d960: 7373 6573 2873 656c 6629 202d 3e20 4e6f  sses(self) -> No
+0000d970: 6e65 3a0d 0a20 2020 2020 2020 2071 7565  ne:..        que
+0000d980: 7565 5f6f 7574 203d 206d 702e 5175 6575  ue_out = mp.Queu
+0000d990: 6528 7365 6c66 2e5f 7175 6575 655f 6c65  e(self._queue_le
+0000d9a0: 6e29 2020 2320 7365 6e64 7320 6461 7461  n)  # sends data
+0000d9b0: 2066 726f 6d20 7072 6f63 2074 6f20 6d61   from proc to ma
+0000d9c0: 696e 0d0a 2020 2020 2020 2020 7365 6c66  in..        self
+0000d9d0: 2e70 726f 6373 203d 205b 5d0d 0a20 2020  .procs = []..   
+0000d9e0: 2020 2020 2073 656c 662e 7069 7065 7320       self.pipes 
+0000d9f0: 3d20 5b5d 0d0a 2020 2020 2020 2020 666f  = []..        fo
+0000da00: 7220 692c 2028 656e 765f 6675 6e2c 2065  r i, (env_fun, e
+0000da10: 6e76 5f66 756e 5f6b 7761 7267 7329 2069  nv_fun_kwargs) i
+0000da20: 6e20 656e 756d 6572 6174 6528 0d0a 2020  n enumerate(..  
+0000da30: 2020 2020 2020 2020 2020 7a69 7028 7365            zip(se
+0000da40: 6c66 2e63 7265 6174 655f 656e 765f 666e  lf.create_env_fn
+0000da50: 2c20 7365 6c66 2e63 7265 6174 655f 656e  , self.create_en
+0000da60: 765f 6b77 6172 6773 290d 0a20 2020 2020  v_kwargs)..     
+0000da70: 2020 2029 3a0d 0a20 2020 2020 2020 2020     ):..         
+0000da80: 2020 205f 6465 7669 6365 203d 2073 656c     _device = sel
+0000da90: 662e 6465 7669 6365 5b69 5d0d 0a20 2020  f.device[i]..   
+0000daa0: 2020 2020 2020 2020 205f 7374 6f72 696e           _storin
+0000dab0: 675f 6465 7669 6365 203d 2073 656c 662e  g_device = self.
+0000dac0: 7374 6f72 696e 675f 6465 7669 6365 5b69  storing_device[i
+0000dad0: 5d0d 0a20 2020 2020 2020 2020 2020 2070  ]..            p
+0000dae0: 6970 655f 7061 7265 6e74 2c20 7069 7065  ipe_parent, pipe
+0000daf0: 5f63 6869 6c64 203d 206d 702e 5069 7065  _child = mp.Pipe
+0000db00: 2829 2020 2320 7365 6e64 206d 6573 7361  ()  # send messa
+0000db10: 6765 7320 746f 2070 726f 6373 0d0a 2020  ges to procs..  
+0000db20: 2020 2020 2020 2020 2020 6966 2065 6e76            if env
+0000db30: 5f66 756e 2e5f 5f63 6c61 7373 5f5f 2e5f  _fun.__class__._
+0000db40: 5f6e 616d 655f 5f20 213d 2022 456e 7643  _name__ != "EnvC
+0000db50: 7265 6174 6f72 2220 616e 6420 6e6f 7420  reator" and not 
+0000db60: 6973 696e 7374 616e 6365 280d 0a20 2020  isinstance(..   
+0000db70: 2020 2020 2020 2020 2020 2020 2065 6e76               env
+0000db80: 5f66 756e 2c20 456e 7642 6173 650d 0a20  _fun, EnvBase.. 
+0000db90: 2020 2020 2020 2020 2020 2029 3a20 2023             ):  #
+0000dba0: 2074 6f20 6176 6f69 6420 6369 7263 756c   to avoid circul
+0000dbb0: 6172 2069 6d70 6f72 7473 0d0a 2020 2020  ar imports..    
+0000dbc0: 2020 2020 2020 2020 2020 2020 656e 765f              env_
+0000dbd0: 6675 6e20 3d20 436c 6f75 6470 6963 6b6c  fun = Cloudpickl
+0000dbe0: 6557 7261 7070 6572 2865 6e76 5f66 756e  eWrapper(env_fun
+0000dbf0: 290d 0a0d 0a20 2020 2020 2020 2020 2020  )....           
+0000dc00: 206b 7761 7267 7320 3d20 7b0d 0a20 2020   kwargs = {..   
+0000dc10: 2020 2020 2020 2020 2020 2020 2022 7069               "pi
+0000dc20: 7065 5f70 6172 656e 7422 3a20 7069 7065  pe_parent": pipe
+0000dc30: 5f70 6172 656e 742c 0d0a 2020 2020 2020  _parent,..      
+0000dc40: 2020 2020 2020 2020 2020 2270 6970 655f            "pipe_
+0000dc50: 6368 696c 6422 3a20 7069 7065 5f63 6869  child": pipe_chi
+0000dc60: 6c64 2c0d 0a20 2020 2020 2020 2020 2020  ld,..           
+0000dc70: 2020 2020 2022 7175 6575 655f 6f75 7422       "queue_out"
+0000dc80: 3a20 7175 6575 655f 6f75 742c 0d0a 2020  : queue_out,..  
+0000dc90: 2020 2020 2020 2020 2020 2020 2020 2263                "c
+0000dca0: 7265 6174 655f 656e 765f 666e 223a 2065  reate_env_fn": e
+0000dcb0: 6e76 5f66 756e 2c0d 0a20 2020 2020 2020  nv_fun,..       
+0000dcc0: 2020 2020 2020 2020 2022 6372 6561 7465           "create
+0000dcd0: 5f65 6e76 5f6b 7761 7267 7322 3a20 656e  _env_kwargs": en
+0000dce0: 765f 6675 6e5f 6b77 6172 6773 2c0d 0a20  v_fun_kwargs,.. 
+0000dcf0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+0000dd00: 706f 6c69 6379 223a 2073 656c 662e 5f70  policy": self._p
+0000dd10: 6f6c 6963 795f 6469 6374 5b5f 6465 7669  olicy_dict[_devi
+0000dd20: 6365 5d2c 0d0a 2020 2020 2020 2020 2020  ce],..          
+0000dd30: 2020 2020 2020 226d 6178 5f66 7261 6d65        "max_frame
+0000dd40: 735f 7065 725f 7472 616a 223a 2073 656c  s_per_traj": sel
+0000dd50: 662e 6d61 785f 6672 616d 6573 5f70 6572  f.max_frames_per
+0000dd60: 5f74 7261 6a2c 0d0a 2020 2020 2020 2020  _traj,..        
+0000dd70: 2020 2020 2020 2020 2266 7261 6d65 735f          "frames_
+0000dd80: 7065 725f 6261 7463 6822 3a20 7365 6c66  per_batch": self
+0000dd90: 2e66 7261 6d65 735f 7065 725f 6261 7463  .frames_per_batc
+0000dda0: 685f 776f 726b 6572 2c0d 0a20 2020 2020  h_worker,..     
+0000ddb0: 2020 2020 2020 2020 2020 2022 7265 7365             "rese
+0000ddc0: 745f 6174 5f65 6163 685f 6974 6572 223a  t_at_each_iter":
+0000ddd0: 2073 656c 662e 7265 7365 745f 6174 5f65   self.reset_at_e
+0000dde0: 6163 685f 6974 6572 2c0d 0a20 2020 2020  ach_iter,..     
+0000ddf0: 2020 2020 2020 2020 2020 2022 6465 7669             "devi
+0000de00: 6365 223a 205f 6465 7669 6365 2c0d 0a20  ce": _device,.. 
+0000de10: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+0000de20: 7374 6f72 696e 675f 6465 7669 6365 223a  storing_device":
+0000de30: 205f 7374 6f72 696e 675f 6465 7669 6365   _storing_device
+0000de40: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
+0000de50: 2020 2022 6578 706c 6f72 6174 696f 6e5f     "exploration_
+0000de60: 7479 7065 223a 2073 656c 662e 6578 706c  type": self.expl
+0000de70: 6f72 6174 696f 6e5f 7479 7065 2c0d 0a20  oration_type,.. 
+0000de80: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+0000de90: 7265 7365 745f 7768 656e 5f64 6f6e 6522  reset_when_done"
+0000dea0: 3a20 7365 6c66 2e72 6573 6574 5f77 6865  : self.reset_whe
+0000deb0: 6e5f 646f 6e65 2c0d 0a20 2020 2020 2020  n_done,..       
+0000dec0: 2020 2020 2020 2020 2022 6964 7822 3a20           "idx": 
+0000ded0: 692c 0d0a 2020 2020 2020 2020 2020 2020  i,..            
+0000dee0: 2020 2020 2269 6e74 6572 7275 7074 6f72      "interruptor
+0000def0: 223a 2073 656c 662e 696e 7465 7272 7570  ": self.interrup
+0000df00: 746f 722c 0d0a 2020 2020 2020 2020 2020  tor,..          
+0000df10: 2020 7d0d 0a20 2020 2020 2020 2020 2020    }..           
+0000df20: 2070 726f 6320 3d20 6d70 2e50 726f 6365   proc = mp.Proce
+0000df30: 7373 2874 6172 6765 743d 5f6d 6169 6e5f  ss(target=_main_
+0000df40: 6173 796e 635f 636f 6c6c 6563 746f 722c  async_collector,
+0000df50: 206b 7761 7267 733d 6b77 6172 6773 290d   kwargs=kwargs).
+0000df60: 0a20 2020 2020 2020 2020 2020 2023 2070  .            # p
+0000df70: 726f 632e 6461 656d 6f6e 2063 616e 2774  roc.daemon can't
+0000df80: 2062 6520 7365 7420 6173 2064 6165 6d6f   be set as daemo
+0000df90: 6e69 6320 7072 6f63 6573 7365 7320 6d61  nic processes ma
+0000dfa0: 7920 6265 206c 6175 6e63 6865 6420 6279  y be launched by
+0000dfb0: 2074 6865 2070 726f 6365 7373 2069 7473   the process its
+0000dfc0: 656c 660d 0a20 2020 2020 2020 2020 2020  elf..           
+0000dfd0: 2074 7279 3a0d 0a20 2020 2020 2020 2020   try:..         
+0000dfe0: 2020 2020 2020 2070 726f 632e 7374 6172         proc.star
+0000dff0: 7428 290d 0a20 2020 2020 2020 2020 2020  t()..           
+0000e000: 2065 7863 6570 7420 5f70 6963 6b6c 652e   except _pickle.
+0000e010: 5069 636b 6c69 6e67 4572 726f 7220 6173  PicklingError as
+0000e020: 2065 7272 3a0d 0a20 2020 2020 2020 2020   err:..         
+0000e030: 2020 2020 2020 2069 6620 223c 6c61 6d62         if "<lamb
+0000e040: 6461 3e22 2069 6e20 7374 7228 6572 7229  da>" in str(err)
+0000e050: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
+0000e060: 2020 2020 2020 2072 6169 7365 2052 756e         raise Run
+0000e070: 7469 6d65 4572 726f 7228 0d0a 2020 2020  timeError(..    
+0000e080: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e090: 2020 2020 2222 2243 616e 2774 206f 7065      """Can't ope
+0000e0a0: 6e20 6120 7072 6f63 6573 7320 7769 7468  n a process with
+0000e0b0: 2064 6f75 626c 7920 636c 6f75 642d 7069   doubly cloud-pi
+0000e0c0: 636b 6c65 6420 6c61 6d62 6461 2066 756e  ckled lambda fun
+0000e0d0: 6374 696f 6e2e 0d0a 5468 6973 2065 7272  ction...This err
+0000e0e0: 6f72 2069 7320 6c69 6b65 6c79 2064 7565  or is likely due
+0000e0f0: 2074 6f20 616e 2061 7474 656d 7074 2074   to an attempt t
+0000e100: 6f20 7573 6520 6120 5061 7261 6c6c 656c  o use a Parallel
+0000e110: 456e 7620 696e 2061 0d0a 6d75 6c74 6970  Env in a..multip
+0000e120: 726f 6365 7373 6564 2064 6174 6120 636f  rocessed data co
+0000e130: 6c6c 6563 746f 722e 2054 6f20 646f 2074  llector. To do t
+0000e140: 6869 732c 2063 6f6e 7369 6465 7220 7772  his, consider wr
+0000e150: 6170 7069 6e67 2079 6f75 720d 0a6c 616d  apping your..lam
+0000e160: 6264 6120 6675 6e63 7469 6f6e 2069 6e20  bda function in 
+0000e170: 616e 2060 746f 7263 6872 6c2e 656e 7673  an `torchrl.envs
+0000e180: 2e45 6e76 4372 6561 746f 7260 2077 7261  .EnvCreator` wra
+0000e190: 7070 6572 2061 7320 666f 6c6c 6f77 733a  pper as follows:
+0000e1a0: 0d0a 6065 6e76 203d 2050 6172 616c 6c65  ..`env = Paralle
+0000e1b0: 6c45 6e76 284e 2c20 456e 7643 7265 6174  lEnv(N, EnvCreat
+0000e1c0: 6f72 286d 795f 6c61 6d62 6461 5f66 756e  or(my_lambda_fun
+0000e1d0: 6374 696f 6e29 2960 2e0d 0a54 6869 7320  ction))`...This 
+0000e1e0: 7769 6c6c 206e 6f74 206f 6e6c 7920 656e  will not only en
+0000e1f0: 7375 7265 2074 6861 7420 796f 7572 206c  sure that your l
+0000e200: 616d 6264 6120 6675 6e63 7469 6f6e 2069  ambda function i
+0000e210: 7320 636c 6f75 642d 7069 636b 6c65 6420  s cloud-pickled 
+0000e220: 6f6e 6365 2c20 6275 740d 0a61 6c73 6f20  once, but..also 
+0000e230: 7468 6174 2074 6865 2073 7461 7465 2064  that the state d
+0000e240: 6963 7420 6973 2073 796e 6368 726f 6e69  ict is synchroni
+0000e250: 7365 6420 6163 726f 7373 2070 726f 6365  sed across proce
+0000e260: 7373 6573 2069 6620 6e65 6564 6564 2e22  sses if needed."
+0000e270: 2222 0d0a 2020 2020 2020 2020 2020 2020  ""..            
+0000e280: 2020 2020 2020 2020 2920 6672 6f6d 2065          ) from e
+0000e290: 7272 0d0a 2020 2020 2020 2020 2020 2020  rr..            
+0000e2a0: 7069 7065 5f63 6869 6c64 2e63 6c6f 7365  pipe_child.close
+0000e2b0: 2829 0d0a 2020 2020 2020 2020 2020 2020  ()..            
+0000e2c0: 7365 6c66 2e70 726f 6373 2e61 7070 656e  self.procs.appen
+0000e2d0: 6428 7072 6f63 290d 0a20 2020 2020 2020  d(proc)..       
+0000e2e0: 2020 2020 2073 656c 662e 7069 7065 732e       self.pipes.
+0000e2f0: 6170 7065 6e64 2870 6970 655f 7061 7265  append(pipe_pare
+0000e300: 6e74 290d 0a20 2020 2020 2020 2020 2020  nt)..           
+0000e310: 206d 7367 203d 2070 6970 655f 7061 7265   msg = pipe_pare
+0000e320: 6e74 2e72 6563 7628 290d 0a20 2020 2020  nt.recv()..     
+0000e330: 2020 2020 2020 2069 6620 6d73 6720 213d         if msg !=
+0000e340: 2022 696e 7374 616e 7469 6174 6564 223a   "instantiated":
+0000e350: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+0000e360: 2020 7261 6973 6520 5275 6e74 696d 6545    raise RuntimeE
+0000e370: 7272 6f72 286d 7367 290d 0a20 2020 2020  rror(msg)..     
+0000e380: 2020 2073 656c 662e 7175 6575 655f 6f75     self.queue_ou
+0000e390: 7420 3d20 7175 6575 655f 6f75 740d 0a20  t = queue_out.. 
+0000e3a0: 2020 2020 2020 2073 656c 662e 636c 6f73         self.clos
+0000e3b0: 6564 203d 2046 616c 7365 0d0a 0d0a 2020  ed = False....  
+0000e3c0: 2020 6465 6620 5f5f 6465 6c5f 5f28 7365    def __del__(se
+0000e3d0: 6c66 293a 0d0a 2020 2020 2020 2020 7472  lf):..        tr
+0000e3e0: 793a 0d0a 2020 2020 2020 2020 2020 2020  y:..            
+0000e3f0: 7365 6c66 2e73 6875 7464 6f77 6e28 290d  self.shutdown().
+0000e400: 0a20 2020 2020 2020 2065 7863 6570 7420  .        except 
+0000e410: 4578 6365 7074 696f 6e3a 0d0a 2020 2020  Exception:..    
+0000e420: 2020 2020 2020 2020 2320 616e 2041 7474          # an Att
+0000e430: 7269 6275 7465 4572 726f 7220 7769 6c6c  ributeError will
+0000e440: 2074 7970 6963 616c 6c79 2062 6520 7261   typically be ra
+0000e450: 6973 6564 2069 6620 7468 6520 636f 6c6c  ised if the coll
+0000e460: 6563 746f 7220 6973 2064 656c 6574 6564  ector is deleted
+0000e470: 2077 6865 6e20 7468 6520 7072 6f67 7261   when the progra
+0000e480: 6d20 656e 6473 2e0d 0a20 2020 2020 2020  m ends...       
+0000e490: 2020 2020 2023 2049 6e20 7468 6520 6675       # In the fu
+0000e4a0: 7475 7265 2c20 696e 7369 676e 6966 6963  ture, insignific
+0000e4b0: 616e 7420 6368 616e 6765 7320 746f 2074  ant changes to t
+0000e4c0: 6865 2063 6c6f 7365 206d 6574 686f 6420  he close method 
+0000e4d0: 6d61 7920 6368 616e 6765 2074 6865 2065  may change the e
+0000e4e0: 7272 6f72 2074 7970 652e 0d0a 2020 2020  rror type...    
+0000e4f0: 2020 2020 2020 2020 2320 5765 2065 7863          # We exc
+0000e500: 706c 6963 6974 656c 7920 6173 7375 6d65  plicitely assume
+0000e510: 2074 6861 7420 616e 7920 6572 726f 7220   that any error 
+0000e520: 7261 6973 6564 2064 7572 696e 6720 636c  raised during cl
+0000e530: 6f73 7572 6520 696e 0d0a 2020 2020 2020  osure in..      
+0000e540: 2020 2020 2020 2320 5f5f 6465 6c5f 5f20        # __del__ 
+0000e550: 7769 6c6c 206e 6f74 2061 6666 6563 7420  will not affect 
+0000e560: 7468 6520 7072 6f67 7261 6d2e 0d0a 2020  the program...  
+0000e570: 2020 2020 2020 2020 2020 7061 7373 0d0a            pass..
+0000e580: 0d0a 2020 2020 6465 6620 7368 7574 646f  ..    def shutdo
+0000e590: 776e 2873 656c 6629 202d 3e20 4e6f 6e65  wn(self) -> None
+0000e5a0: 3a0d 0a20 2020 2020 2020 2022 2222 5368  :..        """Sh
+0000e5b0: 7574 7320 646f 776e 2061 6c6c 2070 726f  uts down all pro
+0000e5c0: 6365 7373 6573 2e20 5468 6973 206f 7065  cesses. This ope
+0000e5d0: 7261 7469 6f6e 2069 7320 6972 7265 7665  ration is irreve
+0000e5e0: 7273 6962 6c65 2e22 2222 0d0a 2020 2020  rsible."""..    
+0000e5f0: 2020 2020 7365 6c66 2e5f 7368 7574 646f      self._shutdo
+0000e600: 776e 5f6d 6169 6e28 290d 0a0d 0a20 2020  wn_main()....   
+0000e610: 2064 6566 205f 7368 7574 646f 776e 5f6d   def _shutdown_m
+0000e620: 6169 6e28 7365 6c66 2920 2d3e 204e 6f6e  ain(self) -> Non
+0000e630: 653a 0d0a 2020 2020 2020 2020 6966 2073  e:..        if s
+0000e640: 656c 662e 636c 6f73 6564 3a0d 0a20 2020  elf.closed:..   
+0000e650: 2020 2020 2020 2020 2072 6574 7572 6e0d           return.
+0000e660: 0a20 2020 2020 2020 205f 6368 6563 6b5f  .        _check_
+0000e670: 666f 725f 6661 756c 7479 5f70 726f 6365  for_faulty_proce
+0000e680: 7373 2873 656c 662e 7072 6f63 7329 0d0a  ss(self.procs)..
+0000e690: 2020 2020 2020 2020 7365 6c66 2e63 6c6f          self.clo
+0000e6a0: 7365 6420 3d20 5472 7565 0d0a 2020 2020  sed = True..    
+0000e6b0: 2020 2020 666f 7220 6964 7820 696e 2072      for idx in r
+0000e6c0: 616e 6765 2873 656c 662e 6e75 6d5f 776f  ange(self.num_wo
+0000e6d0: 726b 6572 7329 3a0d 0a20 2020 2020 2020  rkers):..       
+0000e6e0: 2020 2020 2069 6620 6e6f 7420 7365 6c66       if not self
+0000e6f0: 2e70 726f 6373 5b69 6478 5d2e 6973 5f61  .procs[idx].is_a
+0000e700: 6c69 7665 2829 3a0d 0a20 2020 2020 2020  live():..       
+0000e710: 2020 2020 2020 2020 2063 6f6e 7469 6e75           continu
+0000e720: 650d 0a20 2020 2020 2020 2020 2020 2074  e..            t
+0000e730: 7279 3a0d 0a20 2020 2020 2020 2020 2020  ry:..           
+0000e740: 2020 2020 2073 656c 662e 7069 7065 735b       self.pipes[
+0000e750: 6964 785d 2e73 656e 6428 284e 6f6e 652c  idx].send((None,
+0000e760: 2022 636c 6f73 6522 2929 0d0a 0d0a 2020   "close"))....  
+0000e770: 2020 2020 2020 2020 2020 2020 2020 6966                if
+0000e780: 2073 656c 662e 7069 7065 735b 6964 785d   self.pipes[idx]
+0000e790: 2e70 6f6c 6c28 3130 2e30 293a 0d0a 2020  .poll(10.0):..  
+0000e7a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e7b0: 2020 6d73 6720 3d20 7365 6c66 2e70 6970    msg = self.pip
+0000e7c0: 6573 5b69 6478 5d2e 7265 6376 2829 0d0a  es[idx].recv()..
+0000e7d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e7e0: 2020 2020 6966 206d 7367 2021 3d20 2263      if msg != "c
+0000e7f0: 6c6f 7365 6422 3a0d 0a20 2020 2020 2020  losed":..       
+0000e800: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e810: 2072 6169 7365 2052 756e 7469 6d65 4572   raise RuntimeEr
+0000e820: 726f 7228 6622 676f 7420 7b6d 7367 7d20  ror(f"got {msg} 
+0000e830: 6275 7420 6578 7065 6374 6564 2027 636c  but expected 'cl
+0000e840: 6f73 6527 2229 0d0a 2020 2020 2020 2020  ose'")..        
+0000e850: 2020 2020 2020 2020 656c 7365 3a0d 0a20          else:.. 
+0000e860: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e870: 2020 2063 6f6e 7469 6e75 650d 0a20 2020     continue..   
+0000e880: 2020 2020 2020 2020 2065 7863 6570 7420           except 
+0000e890: 4272 6f6b 656e 5069 7065 4572 726f 723a  BrokenPipeError:
+0000e8a0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+0000e8b0: 2020 636f 6e74 696e 7565 0d0a 0d0a 2020    continue....  
+0000e8c0: 2020 2020 2020 666f 7220 7072 6f63 2069        for proc i
+0000e8d0: 6e20 7365 6c66 2e70 726f 6373 3a0d 0a20  n self.procs:.. 
+0000e8e0: 2020 2020 2020 2020 2020 2070 726f 632e             proc.
+0000e8f0: 6a6f 696e 2831 302e 3029 0d0a 2020 2020  join(10.0)..    
+0000e900: 2020 2020 7365 6c66 2e71 7565 7565 5f6f      self.queue_o
+0000e910: 7574 2e63 6c6f 7365 2829 0d0a 2020 2020  ut.close()..    
+0000e920: 2020 2020 666f 7220 7069 7065 2069 6e20      for pipe in 
+0000e930: 7365 6c66 2e70 6970 6573 3a0d 0a20 2020  self.pipes:..   
+0000e940: 2020 2020 2020 2020 2070 6970 652e 636c           pipe.cl
+0000e950: 6f73 6528 290d 0a0d 0a20 2020 2064 6566  ose()....    def
+0000e960: 2073 6574 5f73 6565 6428 7365 6c66 2c20   set_seed(self, 
+0000e970: 7365 6564 3a20 696e 742c 2073 7461 7469  seed: int, stati
+0000e980: 635f 7365 6564 3a20 626f 6f6c 203d 2046  c_seed: bool = F
+0000e990: 616c 7365 2920 2d3e 2069 6e74 3a0d 0a20  alse) -> int:.. 
+0000e9a0: 2020 2020 2020 2022 2222 5365 7473 2074         """Sets t
+0000e9b0: 6865 2073 6565 6473 206f 6620 7468 6520  he seeds of the 
+0000e9c0: 656e 7669 726f 6e6d 656e 7473 2073 746f  environments sto
+0000e9d0: 7265 6420 696e 2074 6865 2044 6174 6143  red in the DataC
+0000e9e0: 6f6c 6c65 6374 6f72 2e0d 0a0d 0a20 2020  ollector.....   
+0000e9f0: 2020 2020 2041 7267 733a 0d0a 2020 2020       Args:..    
+0000ea00: 2020 2020 2020 2020 7365 6564 3a20 696e          seed: in
+0000ea10: 7465 6765 7220 7265 7072 6573 656e 7469  teger representi
+0000ea20: 6e67 2074 6865 2073 6565 6420 746f 2062  ng the seed to b
+0000ea30: 6520 7573 6564 2066 6f72 2074 6865 2065  e used for the e
+0000ea40: 6e76 6972 6f6e 6d65 6e74 2e0d 0a20 2020  nvironment...   
+0000ea50: 2020 2020 2020 2020 2073 7461 7469 635f           static_
+0000ea60: 7365 6564 2028 626f 6f6c 2c20 6f70 7469  seed (bool, opti
+0000ea70: 6f6e 616c 293a 2069 6620 6060 5472 7565  onal): if ``True
+0000ea80: 6060 2c20 7468 6520 7365 6564 2069 7320  ``, the seed is 
+0000ea90: 6e6f 7420 696e 6372 656d 656e 7465 642e  not incremented.
+0000eaa0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+0000eab0: 2020 4465 6661 756c 7473 2074 6f20 4661    Defaults to Fa
+0000eac0: 6c73 650d 0a0d 0a20 2020 2020 2020 2052  lse....        R
+0000ead0: 6574 7572 6e73 3a0d 0a20 2020 2020 2020  eturns:..       
+0000eae0: 2020 2020 204f 7574 7075 7420 7365 6564       Output seed
+0000eaf0: 2e20 5468 6973 2069 7320 7573 6566 756c  . This is useful
+0000eb00: 2077 6865 6e20 6d6f 7265 2074 6861 6e20   when more than 
+0000eb10: 6f6e 6520 656e 7669 726f 6e6d 656e 7420  one environment 
+0000eb20: 6973 0d0a 2020 2020 2020 2020 2020 2020  is..            
+0000eb30: 636f 6e74 6169 6e65 6420 696e 2074 6865  contained in the
+0000eb40: 2044 6174 6143 6f6c 6c65 6374 6f72 2c20   DataCollector, 
+0000eb50: 6173 2074 6865 2073 6565 6420 7769 6c6c  as the seed will
+0000eb60: 2062 6520 696e 6372 656d 656e 7465 6420   be incremented 
+0000eb70: 666f 720d 0a20 2020 2020 2020 2020 2020  for..           
+0000eb80: 2065 6163 6820 6f66 2074 6865 7365 2e20   each of these. 
+0000eb90: 5468 6520 7265 7375 6c74 696e 6720 7365  The resulting se
+0000eba0: 6564 2069 7320 7468 6520 7365 6564 206f  ed is the seed o
+0000ebb0: 6620 7468 6520 6c61 7374 0d0a 2020 2020  f the last..    
+0000ebc0: 2020 2020 2020 2020 656e 7669 726f 6e6d          environm
+0000ebd0: 656e 742e 0d0a 0d0a 2020 2020 2020 2020  ent.....        
+0000ebe0: 4578 616d 706c 6573 3a0d 0a20 2020 2020  Examples:..     
+0000ebf0: 2020 2020 2020 203e 3e3e 2065 6e76 5f66         >>> env_f
+0000ec00: 6e20 3d20 6c61 6d62 6461 3a20 4779 6d45  n = lambda: GymE
+0000ec10: 6e76 2822 5065 6e64 756c 756d 2d76 3022  nv("Pendulum-v0"
+0000ec20: 290d 0a20 2020 2020 2020 2020 2020 203e  )..            >
+0000ec30: 3e3e 2065 6e76 5f66 6e5f 7061 7261 6c6c  >> env_fn_parall
+0000ec40: 656c 203d 206c 616d 6264 613a 2050 6172  el = lambda: Par
+0000ec50: 616c 6c65 6c45 6e76 2836 2c20 656e 765f  allelEnv(6, env_
+0000ec60: 666e 290d 0a20 2020 2020 2020 2020 2020  fn)..           
+0000ec70: 203e 3e3e 2063 6f6c 6c65 6374 6f72 203d   >>> collector =
+0000ec80: 2053 796e 6344 6174 6143 6f6c 6c65 6374   SyncDataCollect
+0000ec90: 6f72 2865 6e76 5f66 6e5f 7061 7261 6c6c  or(env_fn_parall
+0000eca0: 656c 290d 0a20 2020 2020 2020 2020 2020  el)..           
+0000ecb0: 203e 3e3e 206f 7574 5f73 6565 6420 3d20   >>> out_seed = 
+0000ecc0: 636f 6c6c 6563 746f 722e 7365 745f 7365  collector.set_se
+0000ecd0: 6564 2831 2920 2023 206f 7574 5f73 6565  ed(1)  # out_see
+0000ece0: 6420 3d20 360d 0a0d 0a20 2020 2020 2020  d = 6....       
+0000ecf0: 2022 2222 0d0a 2020 2020 2020 2020 5f63   """..        _c
+0000ed00: 6865 636b 5f66 6f72 5f66 6175 6c74 795f  heck_for_faulty_
+0000ed10: 7072 6f63 6573 7328 7365 6c66 2e70 726f  process(self.pro
+0000ed20: 6373 290d 0a20 2020 2020 2020 2066 6f72  cs)..        for
+0000ed30: 2069 6478 2069 6e20 7261 6e67 6528 7365   idx in range(se
+0000ed40: 6c66 2e6e 756d 5f77 6f72 6b65 7273 293a  lf.num_workers):
+0000ed50: 0d0a 2020 2020 2020 2020 2020 2020 7365  ..            se
+0000ed60: 6c66 2e70 6970 6573 5b69 6478 5d2e 7365  lf.pipes[idx].se
+0000ed70: 6e64 2828 2873 6565 642c 2073 7461 7469  nd(((seed, stati
+0000ed80: 635f 7365 6564 292c 2022 7365 6564 2229  c_seed), "seed")
+0000ed90: 290d 0a20 2020 2020 2020 2020 2020 206e  )..            n
+0000eda0: 6577 5f73 6565 642c 206d 7367 203d 2073  ew_seed, msg = s
+0000edb0: 656c 662e 7069 7065 735b 6964 785d 2e72  elf.pipes[idx].r
+0000edc0: 6563 7628 290d 0a20 2020 2020 2020 2020  ecv()..         
+0000edd0: 2020 2069 6620 6d73 6720 213d 2022 7365     if msg != "se
+0000ede0: 6564 6564 223a 0d0a 2020 2020 2020 2020  eded":..        
+0000edf0: 2020 2020 2020 2020 7261 6973 6520 5275          raise Ru
+0000ee00: 6e74 696d 6545 7272 6f72 2866 2245 7870  ntimeError(f"Exp
+0000ee10: 6563 7465 6420 6d73 673d 2773 6565 6465  ected msg='seede
+0000ee20: 6427 2c20 676f 7420 7b6d 7367 7d22 290d  d', got {msg}").
+0000ee30: 0a20 2020 2020 2020 2020 2020 2073 6565  .            see
+0000ee40: 6420 3d20 6e65 775f 7365 6564 0d0a 2020  d = new_seed..  
+0000ee50: 2020 2020 2020 7365 6c66 2e72 6573 6574        self.reset
+0000ee60: 2829 0d0a 2020 2020 2020 2020 7265 7475  ()..        retu
+0000ee70: 726e 2073 6565 640d 0a0d 0a20 2020 2064  rn seed....    d
+0000ee80: 6566 2072 6573 6574 2873 656c 662c 2072  ef reset(self, r
+0000ee90: 6573 6574 5f69 6478 3a20 4f70 7469 6f6e  eset_idx: Option
+0000eea0: 616c 5b53 6571 7565 6e63 655b 626f 6f6c  al[Sequence[bool
+0000eeb0: 5d5d 203d 204e 6f6e 6529 202d 3e20 4e6f  ]] = None) -> No
+0000eec0: 6e65 3a0d 0a20 2020 2020 2020 2022 2222  ne:..        """
+0000eed0: 5265 7365 7473 2074 6865 2065 6e76 6972  Resets the envir
+0000eee0: 6f6e 6d65 6e74 7320 746f 2061 206e 6577  onments to a new
+0000eef0: 2069 6e69 7469 616c 2073 7461 7465 2e0d   initial state..
+0000ef00: 0a0d 0a20 2020 2020 2020 2041 7267 733a  ...        Args:
+0000ef10: 0d0a 2020 2020 2020 2020 2020 2020 7265  ..            re
+0000ef20: 7365 745f 6964 783a 204f 7074 696f 6e61  set_idx: Optiona
+0000ef30: 6c2e 2053 6571 7565 6e63 6520 696e 6469  l. Sequence indi
+0000ef40: 6361 7469 6e67 2077 6869 6368 2065 6e76  cating which env
+0000ef50: 6972 6f6e 6d65 6e74 7320 6861 7665 0d0a  ironments have..
+0000ef60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ef70: 746f 2062 6520 7265 7365 742e 2049 6620  to be reset. If 
+0000ef80: 4e6f 6e65 2c20 616c 6c20 656e 7669 726f  None, all enviro
+0000ef90: 6e6d 656e 7473 2061 7265 2072 6573 6574  nments are reset
+0000efa0: 2e0d 0a0d 0a20 2020 2020 2020 2022 2222  .....        """
+0000efb0: 0d0a 2020 2020 2020 2020 5f63 6865 636b  ..        _check
+0000efc0: 5f66 6f72 5f66 6175 6c74 795f 7072 6f63  _for_faulty_proc
+0000efd0: 6573 7328 7365 6c66 2e70 726f 6373 290d  ess(self.procs).
+0000efe0: 0a0d 0a20 2020 2020 2020 2069 6620 7265  ...        if re
+0000eff0: 7365 745f 6964 7820 6973 204e 6f6e 653a  set_idx is None:
+0000f000: 0d0a 2020 2020 2020 2020 2020 2020 7265  ..            re
+0000f010: 7365 745f 6964 7820 3d20 5b54 7275 6520  set_idx = [True 
+0000f020: 666f 7220 5f20 696e 2072 616e 6765 2873  for _ in range(s
+0000f030: 656c 662e 6e75 6d5f 776f 726b 6572 7329  elf.num_workers)
+0000f040: 5d0d 0a20 2020 2020 2020 2066 6f72 2069  ]..        for i
+0000f050: 6478 2069 6e20 7261 6e67 6528 7365 6c66  dx in range(self
+0000f060: 2e6e 756d 5f77 6f72 6b65 7273 293a 0d0a  .num_workers):..
+0000f070: 2020 2020 2020 2020 2020 2020 6966 2072              if r
+0000f080: 6573 6574 5f69 6478 5b69 6478 5d3a 0d0a  eset_idx[idx]:..
+0000f090: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f0a0: 7365 6c66 2e70 6970 6573 5b69 6478 5d2e  self.pipes[idx].
+0000f0b0: 7365 6e64 2828 4e6f 6e65 2c20 2272 6573  send((None, "res
+0000f0c0: 6574 2229 290d 0a20 2020 2020 2020 2066  et"))..        f
+0000f0d0: 6f72 2069 6478 2069 6e20 7261 6e67 6528  or idx in range(
+0000f0e0: 7365 6c66 2e6e 756d 5f77 6f72 6b65 7273  self.num_workers
+0000f0f0: 293a 0d0a 2020 2020 2020 2020 2020 2020  ):..            
+0000f100: 6966 2072 6573 6574 5f69 6478 5b69 6478  if reset_idx[idx
+0000f110: 5d3a 0d0a 2020 2020 2020 2020 2020 2020  ]:..            
+0000f120: 2020 2020 6a2c 206d 7367 203d 2073 656c      j, msg = sel
+0000f130: 662e 7069 7065 735b 6964 785d 2e72 6563  f.pipes[idx].rec
+0000f140: 7628 290d 0a20 2020 2020 2020 2020 2020  v()..           
+0000f150: 2020 2020 2069 6620 6d73 6720 213d 2022       if msg != "
+0000f160: 7265 7365 7422 3a0d 0a20 2020 2020 2020  reset":..       
+0000f170: 2020 2020 2020 2020 2020 2020 2072 6169               rai
+0000f180: 7365 2052 756e 7469 6d65 4572 726f 7228  se RuntimeError(
+0000f190: 6622 4578 7065 6374 6564 206d 7367 3d27  f"Expected msg='
+0000f1a0: 7265 7365 7427 2c20 676f 7420 7b6d 7367  reset', got {msg
+0000f1b0: 7d22 290d 0a0d 0a20 2020 2064 6566 2073  }")....    def s
+0000f1c0: 7461 7465 5f64 6963 7428 7365 6c66 2920  tate_dict(self) 
+0000f1d0: 2d3e 204f 7264 6572 6564 4469 6374 3a0d  -> OrderedDict:.
+0000f1e0: 0a20 2020 2020 2020 2022 2222 5265 7475  .        """Retu
+0000f1f0: 726e 7320 7468 6520 7374 6174 655f 6469  rns the state_di
+0000f200: 6374 206f 6620 7468 6520 6461 7461 2063  ct of the data c
+0000f210: 6f6c 6c65 6374 6f72 2e0d 0a0d 0a20 2020  ollector.....   
+0000f220: 2020 2020 2045 6163 6820 6669 656c 6420       Each field 
+0000f230: 7265 7072 6573 656e 7473 2061 2077 6f72  represents a wor
+0000f240: 6b65 7220 636f 6e74 6169 6e69 6e67 2069  ker containing i
+0000f250: 7473 206f 776e 2073 7461 7465 5f64 6963  ts own state_dic
+0000f260: 742e 0d0a 0d0a 2020 2020 2020 2020 2222  t.....        ""
+0000f270: 220d 0a20 2020 2020 2020 2066 6f72 2069  "..        for i
+0000f280: 6478 2069 6e20 7261 6e67 6528 7365 6c66  dx in range(self
+0000f290: 2e6e 756d 5f77 6f72 6b65 7273 293a 0d0a  .num_workers):..
+0000f2a0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+0000f2b0: 2e70 6970 6573 5b69 6478 5d2e 7365 6e64  .pipes[idx].send
+0000f2c0: 2828 4e6f 6e65 2c20 2273 7461 7465 5f64  ((None, "state_d
+0000f2d0: 6963 7422 2929 0d0a 2020 2020 2020 2020  ict"))..        
+0000f2e0: 7374 6174 655f 6469 6374 203d 204f 7264  state_dict = Ord
+0000f2f0: 6572 6564 4469 6374 2829 0d0a 2020 2020  eredDict()..    
+0000f300: 2020 2020 666f 7220 6964 7820 696e 2072      for idx in r
+0000f310: 616e 6765 2873 656c 662e 6e75 6d5f 776f  ange(self.num_wo
+0000f320: 726b 6572 7329 3a0d 0a20 2020 2020 2020  rkers):..       
+0000f330: 2020 2020 205f 7374 6174 655f 6469 6374       _state_dict
+0000f340: 2c20 6d73 6720 3d20 7365 6c66 2e70 6970  , msg = self.pip
+0000f350: 6573 5b69 6478 5d2e 7265 6376 2829 0d0a  es[idx].recv()..
+0000f360: 2020 2020 2020 2020 2020 2020 6966 206d              if m
+0000f370: 7367 2021 3d20 2273 7461 7465 5f64 6963  sg != "state_dic
+0000f380: 7422 3a0d 0a20 2020 2020 2020 2020 2020  t":..           
+0000f390: 2020 2020 2072 6169 7365 2052 756e 7469       raise Runti
+0000f3a0: 6d65 4572 726f 7228 6622 4578 7065 6374  meError(f"Expect
+0000f3b0: 6564 206d 7367 3d27 7374 6174 655f 6469  ed msg='state_di
+0000f3c0: 6374 272c 2067 6f74 207b 6d73 677d 2229  ct', got {msg}")
+0000f3d0: 0d0a 2020 2020 2020 2020 2020 2020 7374  ..            st
+0000f3e0: 6174 655f 6469 6374 5b66 2277 6f72 6b65  ate_dict[f"worke
+0000f3f0: 727b 6964 787d 225d 203d 205f 7374 6174  r{idx}"] = _stat
+0000f400: 655f 6469 6374 0d0a 0d0a 2020 2020 2020  e_dict....      
+0000f410: 2020 7265 7475 726e 2073 7461 7465 5f64    return state_d
+0000f420: 6963 740d 0a0d 0a20 2020 2064 6566 206c  ict....    def l
+0000f430: 6f61 645f 7374 6174 655f 6469 6374 2873  oad_state_dict(s
+0000f440: 656c 662c 2073 7461 7465 5f64 6963 743a  elf, state_dict:
+0000f450: 204f 7264 6572 6564 4469 6374 2920 2d3e   OrderedDict) ->
+0000f460: 204e 6f6e 653a 0d0a 2020 2020 2020 2020   None:..        
+0000f470: 2222 224c 6f61 6473 2074 6865 2073 7461  """Loads the sta
+0000f480: 7465 5f64 6963 7420 6f6e 2074 6865 2077  te_dict on the w
+0000f490: 6f72 6b65 7273 2e0d 0a0d 0a20 2020 2020  orkers.....     
+0000f4a0: 2020 2041 7267 733a 0d0a 2020 2020 2020     Args:..      
+0000f4b0: 2020 2020 2020 7374 6174 655f 6469 6374        state_dict
+0000f4c0: 2028 4f72 6465 7265 6444 6963 7429 3a20   (OrderedDict): 
+0000f4d0: 7374 6174 655f 6469 6374 206f 6620 7468  state_dict of th
+0000f4e0: 6520 666f 726d 0d0a 2020 2020 2020 2020  e form..        
+0000f4f0: 2020 2020 2020 2020 6060 7b22 776f 726b          ``{"work
+0000f500: 6572 3022 3a20 7374 6174 655f 6469 6374  er0": state_dict
+0000f510: 302c 2022 776f 726b 6572 3122 3a20 7374  0, "worker1": st
+0000f520: 6174 655f 6469 6374 317d 6060 2e0d 0a0d  ate_dict1}``....
+0000f530: 0a20 2020 2020 2020 2022 2222 0d0a 2020  .        """..  
+0000f540: 2020 2020 2020 666f 7220 6964 7820 696e        for idx in
+0000f550: 2072 616e 6765 2873 656c 662e 6e75 6d5f   range(self.num_
+0000f560: 776f 726b 6572 7329 3a0d 0a20 2020 2020  workers):..     
+0000f570: 2020 2020 2020 2073 656c 662e 7069 7065         self.pipe
+0000f580: 735b 6964 785d 2e73 656e 6428 2873 7461  s[idx].send((sta
+0000f590: 7465 5f64 6963 745b 6622 776f 726b 6572  te_dict[f"worker
+0000f5a0: 7b69 6478 7d22 5d2c 2022 6c6f 6164 5f73  {idx}"], "load_s
+0000f5b0: 7461 7465 5f64 6963 7422 2929 0d0a 2020  tate_dict"))..  
+0000f5c0: 2020 2020 2020 666f 7220 6964 7820 696e        for idx in
+0000f5d0: 2072 616e 6765 2873 656c 662e 6e75 6d5f   range(self.num_
+0000f5e0: 776f 726b 6572 7329 3a0d 0a20 2020 2020  workers):..     
+0000f5f0: 2020 2020 2020 205f 2c20 6d73 6720 3d20         _, msg = 
+0000f600: 7365 6c66 2e70 6970 6573 5b69 6478 5d2e  self.pipes[idx].
+0000f610: 7265 6376 2829 0d0a 2020 2020 2020 2020  recv()..        
+0000f620: 2020 2020 6966 206d 7367 2021 3d20 226c      if msg != "l
+0000f630: 6f61 6465 6422 3a0d 0a20 2020 2020 2020  oaded":..       
+0000f640: 2020 2020 2020 2020 2072 6169 7365 2052           raise R
+0000f650: 756e 7469 6d65 4572 726f 7228 6622 4578  untimeError(f"Ex
+0000f660: 7065 6374 6564 206d 7367 3d27 6c6f 6164  pected msg='load
+0000f670: 6564 272c 2067 6f74 207b 6d73 677d 2229  ed', got {msg}")
+0000f680: 0d0a 0d0a 0d0a 4061 6363 6570 745f 7265  ......@accept_re
+0000f690: 6d6f 7465 5f72 7265 665f 7564 665f 696e  mote_rref_udf_in
+0000f6a0: 766f 6361 7469 6f6e 0d0a 636c 6173 7320  vocation..class 
+0000f6b0: 4d75 6c74 6953 796e 6344 6174 6143 6f6c  MultiSyncDataCol
+0000f6c0: 6c65 6374 6f72 285f 4d75 6c74 6944 6174  lector(_MultiDat
+0000f6d0: 6143 6f6c 6c65 6374 6f72 293a 0d0a 2020  aCollector):..  
+0000f6e0: 2020 2222 2252 756e 7320 6120 6769 7665    """Runs a give
+0000f6f0: 6e20 6e75 6d62 6572 206f 6620 4461 7461  n number of Data
+0000f700: 436f 6c6c 6563 746f 7273 206f 6e20 7365  Collectors on se
+0000f710: 7061 7261 7465 2070 726f 6365 7373 6573  parate processes
+0000f720: 2073 796e 6368 726f 6e6f 7573 6c79 2e0d   synchronously..
+0000f730: 0a0d 0a20 2020 202e 2e20 6161 6669 673a  ...    .. aafig:
+0000f740: 3a0d 0a0d 0a20 2020 2020 2020 2020 2020  :....           
+0000f750: 202b 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d   +--------------
+0000f760: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+0000f770: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+0000f780: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+0000f790: 2d2d 2d2d 2d2d 2d2d 2b0d 0a20 2020 2020  --------+..     
+0000f7a0: 2020 2020 2020 207c 2020 2020 2020 2020         |        
+0000f7b0: 2020 2020 224d 756c 7469 5379 6e63 4461      "MultiSyncDa
+0000f7c0: 7461 436f 6c6c 6563 746f 7222 2020 2020  taCollector"    
+0000f7d0: 2020 2020 2020 2020 2020 2020 207c 2020               |  
+0000f7e0: 2020 2020 2020 2020 2020 2020 2020 7c0d                |.
+0000f7f0: 0a20 2020 2020 2020 2020 2020 207c 7e7e  .            |~~
+0000f800: 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e  ~~~~~~~~~~~~~~~~
+0000f810: 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e  ~~~~~~~~~~~~~~~~
+0000f820: 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e  ~~~~~~~~~~~~~~~~
+0000f830: 7e7e 7e7c 2020 2020 2020 2020 2020 2020  ~~~|            
+0000f840: 2020 2020 7c0d 0a20 2020 2020 2020 2020      |..         
+0000f850: 2020 207c 2020 2022 436f 6c6c 6563 746f     |   "Collecto
+0000f860: 7220 3122 207c 2020 2243 6f6c 6c65 6374  r 1" |  "Collect
+0000f870: 6f72 2032 2220 207c 2020 2243 6f6c 6c65  or 2"  |  "Colle
+0000f880: 6374 6f72 2033 2220 207c 2020 2020 204d  ctor 3"  |     M
+0000f890: 6169 6e20 2020 2020 2020 7c0d 0a20 2020  ain       |..   
+0000f8a0: 2020 2020 2020 2020 207c 7e7e 7e7e 7e7e           |~~~~~~
+0000f8b0: 7e7e 7e7e 7e7e 7e7e 7e7e 7e7c 7e7e 7e7e  ~~~~~~~~~~~|~~~~
+0000f8c0: 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7c 7e7e  ~~~~~~~~~~~~~|~~
+0000f8d0: 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7c  ~~~~~~~~~~~~~~~|
+0000f8e0: 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e  ~~~~~~~~~~~~~~~~
+0000f8f0: 7c0d 0a20 2020 2020 2020 2020 2020 207c  |..            |
+0000f900: 2022 656e 7631 2220 7c20 2265 6e76 3222   "env1" | "env2"
+0000f910: 207c 2022 656e 7633 2220 7c20 2265 6e76   | "env3" | "env
+0000f920: 3422 207c 2022 656e 7635 2220 7c20 2265  4" | "env5" | "e
+0000f930: 6e76 3622 207c 2020 2020 2020 2020 2020  nv6" |          
+0000f940: 2020 2020 2020 7c0d 0a20 2020 2020 2020        |..       
+0000f950: 2020 2020 207c 7e7e 7e7e 7e7e 7e7e 7c7e       |~~~~~~~~|~
+0000f960: 7e7e 7e7e 7e7e 7e7c 7e7e 7e7e 7e7e 7e7e  ~~~~~~~|~~~~~~~~
+0000f970: 7c7e 7e7e 7e7e 7e7e 7e7c 7e7e 7e7e 7e7e  |~~~~~~~~|~~~~~~
+0000f980: 7e7e 7c7e 7e7e 7e7e 7e7e 7e7c 7e7e 7e7e  ~~|~~~~~~~~|~~~~
+0000f990: 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7c0d 0a20  ~~~~~~~~~~~~|.. 
+0000f9a0: 2020 2020 2020 2020 2020 207c 2272 6573             |"res
+0000f9b0: 6574 2220 7c22 7265 7365 7422 207c 2272  et" |"reset" |"r
+0000f9c0: 6573 6574 2220 7c22 7265 7365 7422 207c  eset" |"reset" |
+0000f9d0: 2272 6573 6574 2220 7c22 7265 7365 7422  "reset" |"reset"
+0000f9e0: 207c 2020 2020 2020 2020 2020 2020 2020   |              
+0000f9f0: 2020 7c0d 0a20 2020 2020 2020 2020 2020    |..           
+0000fa00: 207c 2020 2020 2020 2020 7c20 2020 2020   |        |     
+0000fa10: 2020 207c 2020 2020 2020 2020 7c20 2020     |        |   
+0000fa20: 2020 2020 207c 2020 2020 2020 2020 7c20       |        | 
+0000fa30: 2020 2020 2020 207c 2020 2020 2020 2020         |        
+0000fa40: 2020 2020 2020 2020 7c0d 0a20 2020 2020          |..     
+0000fa50: 2020 2020 2020 207c 2020 2020 2020 2022         |       "
+0000fa60: 6163 746f 7222 2020 207c 2020 2020 2020  actor"   |      
+0000fa70: 2020 7c20 2020 2020 2020 207c 2020 2020    |        |    
+0000fa80: 2020 2022 6163 746f 7222 2020 207c 2020     "actor"   |  
+0000fa90: 2020 2020 2020 2020 2020 2020 2020 7c0d                |.
+0000faa0: 0a20 2020 2020 2020 2020 2020 207c 2020  .            |  
+0000fab0: 2020 2020 2020 2020 2020 2020 2020 207c                 |
+0000fac0: 2020 2020 2020 2020 7c20 2020 2020 2020          |       
+0000fad0: 207c 2020 2020 2020 2020 2020 2020 2020   |              
+0000fae0: 2020 207c 2020 2020 2020 2020 2020 2020     |            
+0000faf0: 2020 2020 7c0d 0a20 2020 2020 2020 2020      |..         
+0000fb00: 2020 207c 2022 7374 6570 2220 7c20 2273     | "step" | "s
+0000fb10: 7465 7022 207c 2020 2020 2020 2022 6163  tep" |       "ac
+0000fb20: 746f 7222 2020 207c 2020 2020 2020 2020  tor"   |        
+0000fb30: 2020 2020 2020 2020 207c 2020 2020 2020           |      
+0000fb40: 2020 2020 2020 2020 2020 7c0d 0a20 2020            |..   
+0000fb50: 2020 2020 2020 2020 207c 2020 2020 2020           |      
+0000fb60: 2020 7c20 2020 2020 2020 207c 2020 2020    |        |    
+0000fb70: 2020 2020 2020 2020 2020 2020 207c 2020               |  
+0000fb80: 2020 2020 2020 2020 2020 2020 2020 207c                 |
+0000fb90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fba0: 7c0d 0a20 2020 2020 2020 2020 2020 207c  |..            |
+0000fbb0: 2020 2020 2020 2020 7c20 2020 2020 2020          |       
+0000fbc0: 207c 2020 2020 2020 2020 2020 2020 2020   |              
+0000fbd0: 2020 207c 2022 7374 6570 2220 7c20 2273     | "step" | "s
+0000fbe0: 7465 7022 207c 2020 2020 2020 2020 2020  tep" |          
+0000fbf0: 2020 2020 2020 7c0d 0a20 2020 2020 2020        |..       
+0000fc00: 2020 2020 207c 2020 2020 2020 2020 7c20       |        | 
+0000fc10: 2020 2020 2020 207c 2020 2020 2020 2020         |        
+0000fc20: 2020 2020 2020 2020 207c 2020 2020 2020           |      
+0000fc30: 2020 7c20 2020 2020 2020 207c 2020 2020    |        |    
+0000fc40: 2020 2020 2020 2020 2020 2020 7c0d 0a20              |.. 
+0000fc50: 2020 2020 2020 2020 2020 207c 2020 2020             |    
+0000fc60: 2020 2022 6163 746f 7222 2020 207c 2022     "actor"   | "
+0000fc70: 7374 6570 2220 7c20 2273 7465 7022 207c  step" | "step" |
+0000fc80: 2020 2020 2020 2022 6163 746f 7222 2020         "actor"  
+0000fc90: 207c 2020 2020 2020 2020 2020 2020 2020   |              
+0000fca0: 2020 7c0d 0a20 2020 2020 2020 2020 2020    |..           
+0000fcb0: 207c 2020 2020 2020 2020 2020 2020 2020   |              
+0000fcc0: 2020 207c 2020 2020 2020 2020 7c20 2020     |        |   
+0000fcd0: 2020 2020 207c 2020 2020 2020 2020 2020       |          
+0000fce0: 2020 2020 2020 207c 2020 2020 2020 2020         |        
+0000fcf0: 2020 2020 2020 2020 7c0d 0a20 2020 2020          |..     
+0000fd00: 2020 2020 2020 207c 2020 2020 2020 2020         |        
+0000fd10: 2020 2020 2020 2020 207c 2020 2020 2020           |      
+0000fd20: 2022 6163 746f 7222 2020 207c 2020 2020   "actor"   |    
+0000fd30: 2020 2020 2020 2020 2020 2020 207c 2020               |  
+0000fd40: 2020 2020 2020 2020 2020 2020 2020 7c0d                |.
+0000fd50: 0a20 2020 2020 2020 2020 2020 207c 2020  .            |  
+0000fd60: 2020 2020 2020 2020 2020 2020 2020 207c                 |
+0000fd70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fd80: 207c 2020 2020 2020 2020 2020 2020 2020   |              
+0000fd90: 2020 207c 2020 2020 2020 2020 2020 2020     |            
+0000fda0: 2020 2020 7c0d 0a20 2020 2020 2020 2020      |..         
+0000fdb0: 2020 207c 2020 2020 2020 2020 2020 2020     |            
+0000fdc0: 2020 2020 2020 2020 2020 2022 7969 656c             "yiel
+0000fdd0: 6420 6261 7463 6820 6f66 2074 7261 6a20  d batch of traj 
+0000fde0: 3122 2d2d 2d2d 2d2d 2d3e 2263 6f6c 6c65  1"------->"colle
+0000fdf0: 6374 2c20 7472 6169 6e22 7c0d 0a20 2020  ct, train"|..   
+0000fe00: 2020 2020 2020 2020 207c 2020 2020 2020           |      
+0000fe10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fe20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fe30: 2020 2020 2020 2020 2020 2020 2020 207c                 |
+0000fe40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000fe50: 7c0d 0a20 2020 2020 2020 2020 2020 207c  |..            |
+0000fe60: 2022 7374 6570 2220 7c20 2273 7465 7022   "step" | "step"
+0000fe70: 207c 2022 7374 6570 2220 7c20 2273 7465   | "step" | "ste
+0000fe80: 7022 207c 2022 7374 6570 2220 7c20 2273  p" | "step" | "s
+0000fe90: 7465 7022 207c 2020 2020 2020 2020 2020  tep" |          
+0000fea0: 2020 2020 2020 7c0d 0a20 2020 2020 2020        |..       
+0000feb0: 2020 2020 207c 2020 2020 2020 2020 7c20       |        | 
+0000fec0: 2020 2020 2020 207c 2020 2020 2020 2020         |        
+0000fed0: 7c20 2020 2020 2020 207c 2020 2020 2020  |        |      
+0000fee0: 2020 7c20 2020 2020 2020 207c 2020 2020    |        |    
+0000fef0: 2020 2020 2020 2020 2020 2020 7c0d 0a20              |.. 
+0000ff00: 2020 2020 2020 2020 2020 207c 2020 2020             |    
+0000ff10: 2020 2022 6163 746f 7222 2020 207c 2020     "actor"   |  
+0000ff20: 2020 2020 2022 6163 746f 7222 2020 207c       "actor"   |
+0000ff30: 2020 2020 2020 2020 7c20 2020 2020 2020          |       
+0000ff40: 207c 2020 2020 2020 2020 2020 2020 2020   |              
+0000ff50: 2020 7c0d 0a20 2020 2020 2020 2020 2020    |..           
+0000ff60: 207c 2020 2020 2020 2020 2020 2020 2020   |              
+0000ff70: 2020 207c 2022 7374 6570 2220 7c20 2273     | "step" | "s
+0000ff80: 7465 7022 207c 2020 2020 2020 2022 6163  tep" |       "ac
+0000ff90: 746f 7222 2020 207c 2020 2020 2020 2020  tor"   |        
+0000ffa0: 2020 2020 2020 2020 7c0d 0a20 2020 2020          |..     
+0000ffb0: 2020 2020 2020 207c 2020 2020 2020 2020         |        
+0000ffc0: 2020 2020 2020 2020 207c 2020 2020 2020           |      
+0000ffd0: 2020 7c20 2020 2020 2020 207c 2020 2020    |        |    
+0000ffe0: 2020 2020 2020 2020 2020 2020 207c 2020               |  
+0000fff0: 2020 2020 2020 2020 2020 2020 2020 7c0d                |.
+00010000: 0a20 2020 2020 2020 2020 2020 207c 2022  .            | "
+00010010: 7374 6570 2220 7c20 2273 7465 7022 207c  step" | "step" |
+00010020: 2020 2020 2020 2022 6163 746f 7222 2020         "actor"  
+00010030: 207c 2022 7374 6570 2220 7c20 2273 7465   | "step" | "ste
+00010040: 7022 207c 2020 2020 2020 2020 2020 2020  p" |            
+00010050: 2020 2020 7c0d 0a20 2020 2020 2020 2020      |..         
+00010060: 2020 207c 2020 2020 2020 2020 7c20 2020     |        |   
+00010070: 2020 2020 207c 2020 2020 2020 2020 2020       |          
+00010080: 2020 2020 2020 207c 2020 2020 2020 2020         |        
+00010090: 7c20 2020 2020 2020 207c 2020 2020 2020  |        |      
+000100a0: 2020 2020 2020 2020 2020 7c0d 0a20 2020            |..   
+000100b0: 2020 2020 2020 2020 207c 2020 2020 2020           |      
+000100c0: 2022 6163 746f 7222 2020 207c 2020 2020   "actor"   |    
+000100d0: 2020 2020 2020 2020 2020 2020 207c 2020               |  
+000100e0: 2020 2020 2022 6163 746f 7222 2020 207c       "actor"   |
+000100f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010100: 7c0d 0a20 2020 2020 2020 2020 2020 207c  |..            |
+00010110: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010120: 2020 2020 2020 2022 7969 656c 6420 6261         "yield ba
+00010130: 7463 6820 6f66 2074 7261 6a20 3222 2d2d  tch of traj 2"--
+00010140: 2d2d 2d2d 2d3e 2263 6f6c 6c65 6374 2c20  ----->"collect, 
+00010150: 7472 6169 6e22 7c0d 0a20 2020 2020 2020  train"|..       
+00010160: 2020 2020 207c 2020 2020 2020 2020 2020       |          
+00010170: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010180: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010190: 2020 2020 2020 2020 2020 207c 2020 2020             |    
+000101a0: 2020 2020 2020 2020 2020 2020 7c0d 0a20              |.. 
+000101b0: 2020 2020 2020 2020 2020 202b 2d2d 2d2d             +----
+000101c0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+000101d0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+000101e0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+000101f0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+00010200: 2d2d 2b0d 0a0d 0a20 2020 2045 6e76 7320  --+....    Envs 
+00010210: 6361 6e20 6265 2069 6465 6e74 6963 616c  can be identical
+00010220: 206f 7220 6469 6666 6572 656e 742e 0d0a   or different...
+00010230: 0d0a 2020 2020 5468 6520 636f 6c6c 6563  ..    The collec
+00010240: 7469 6f6e 2073 7461 7274 7320 7768 656e  tion starts when
+00010250: 2074 6865 206e 6578 7420 6974 656d 206f   the next item o
+00010260: 6620 7468 6520 636f 6c6c 6563 746f 7220  f the collector 
+00010270: 6973 2071 7565 7269 6564 2c0d 0a20 2020  is queried,..   
+00010280: 2061 6e64 206e 6f20 656e 7669 726f 6e6d   and no environm
+00010290: 656e 7420 7374 6570 2069 7320 636f 6d70  ent step is comp
+000102a0: 7574 6564 2069 6e20 6265 7477 6565 6e20  uted in between 
+000102b0: 7468 6520 7265 6365 7074 696f 6e20 6f66  the reception of
+000102c0: 2061 2062 6174 6368 206f 660d 0a20 2020   a batch of..   
+000102d0: 2074 7261 6a65 6374 6f72 7920 616e 6420   trajectory and 
+000102e0: 7468 6520 7374 6172 7420 6f66 2074 6865  the start of the
+000102f0: 206e 6578 7420 636f 6c6c 6563 7469 6f6e   next collection
+00010300: 2e0d 0a20 2020 2054 6869 7320 636c 6173  ...    This clas
+00010310: 7320 6361 6e20 6265 2073 6166 656c 7920  s can be safely 
+00010320: 7573 6564 2077 6974 6820 6f6e 6c69 6e65  used with online
+00010330: 2052 4c20 616c 676f 7269 7468 6d73 2e0d   RL algorithms..
+00010340: 0a0d 0a20 2020 2045 7861 6d70 6c65 733a  ...    Examples:
+00010350: 0d0a 2020 2020 2020 2020 3e3e 3e20 6672  ..        >>> fr
+00010360: 6f6d 2074 6f72 6368 726c 2e65 6e76 732e  om torchrl.envs.
+00010370: 6c69 6273 2e67 796d 2069 6d70 6f72 7420  libs.gym import 
+00010380: 4779 6d45 6e76 0d0a 2020 2020 2020 2020  GymEnv..        
+00010390: 3e3e 3e20 6672 6f6d 2074 6f72 6368 726c  >>> from torchrl
+000103a0: 2e65 6e76 7320 696d 706f 7274 2053 7465  .envs import Ste
+000103b0: 7043 6f75 6e74 6572 0d0a 2020 2020 2020  pCounter..      
+000103c0: 2020 3e3e 3e20 6672 6f6d 2074 656e 736f    >>> from tenso
+000103d0: 7264 6963 742e 6e6e 2069 6d70 6f72 7420  rdict.nn import 
+000103e0: 5465 6e73 6f72 4469 6374 4d6f 6475 6c65  TensorDictModule
+000103f0: 0d0a 2020 2020 2020 2020 3e3e 3e20 6672  ..        >>> fr
+00010400: 6f6d 2074 6f72 6368 2069 6d70 6f72 7420  om torch import 
+00010410: 6e6e 0d0a 2020 2020 2020 2020 3e3e 3e20  nn..        >>> 
+00010420: 656e 765f 6d61 6b65 7220 3d20 6c61 6d62  env_maker = lamb
+00010430: 6461 3a20 5472 616e 7366 6f72 6d65 6445  da: TransformedE
+00010440: 6e76 2847 796d 456e 7628 2250 656e 6475  nv(GymEnv("Pendu
+00010450: 6c75 6d2d 7631 222c 2064 6576 6963 653d  lum-v1", device=
+00010460: 2263 7075 2229 2c20 5374 6570 436f 756e  "cpu"), StepCoun
+00010470: 7465 7228 6d61 785f 7374 6570 733d 3530  ter(max_steps=50
+00010480: 2929 0d0a 2020 2020 2020 2020 3e3e 3e20  ))..        >>> 
+00010490: 706f 6c69 6379 203d 2054 656e 736f 7244  policy = TensorD
+000104a0: 6963 744d 6f64 756c 6528 6e6e 2e4c 696e  ictModule(nn.Lin
+000104b0: 6561 7228 332c 2031 292c 2069 6e5f 6b65  ear(3, 1), in_ke
+000104c0: 7973 3d5b 226f 6273 6572 7661 7469 6f6e  ys=["observation
+000104d0: 225d 2c20 6f75 745f 6b65 7973 3d5b 2261  "], out_keys=["a
+000104e0: 6374 696f 6e22 5d29 0d0a 2020 2020 2020  ction"])..      
+000104f0: 2020 3e3e 3e20 636f 6c6c 6563 746f 7220    >>> collector 
+00010500: 3d20 4d75 6c74 6953 796e 6344 6174 6143  = MultiSyncDataC
+00010510: 6f6c 6c65 6374 6f72 280d 0a20 2020 2020  ollector(..     
+00010520: 2020 202e 2e2e 2020 2020 2063 7265 6174     ...     creat
+00010530: 655f 656e 765f 666e 3d5b 656e 765f 6d61  e_env_fn=[env_ma
+00010540: 6b65 722c 2065 6e76 5f6d 616b 6572 5d2c  ker, env_maker],
+00010550: 0d0a 2020 2020 2020 2020 2e2e 2e20 2020  ..        ...   
+00010560: 2020 706f 6c69 6379 3d70 6f6c 6963 792c    policy=policy,
+00010570: 0d0a 2020 2020 2020 2020 2e2e 2e20 2020  ..        ...   
+00010580: 2020 746f 7461 6c5f 6672 616d 6573 3d32    total_frames=2
+00010590: 3030 302c 0d0a 2020 2020 2020 2020 2e2e  000,..        ..
+000105a0: 2e20 2020 2020 6d61 785f 6672 616d 6573  .     max_frames
+000105b0: 5f70 6572 5f74 7261 6a3d 3530 2c0d 0a20  _per_traj=50,.. 
+000105c0: 2020 2020 2020 202e 2e2e 2020 2020 2066         ...     f
+000105d0: 7261 6d65 735f 7065 725f 6261 7463 683d  rames_per_batch=
+000105e0: 3230 302c 0d0a 2020 2020 2020 2020 2e2e  200,..        ..
+000105f0: 2e20 2020 2020 696e 6974 5f72 616e 646f  .     init_rando
+00010600: 6d5f 6672 616d 6573 3d2d 312c 0d0a 2020  m_frames=-1,..  
+00010610: 2020 2020 2020 2e2e 2e20 2020 2020 7265        ...     re
+00010620: 7365 745f 6174 5f65 6163 685f 6974 6572  set_at_each_iter
+00010630: 3d46 616c 7365 2c0d 0a20 2020 2020 2020  =False,..       
+00010640: 202e 2e2e 2020 2020 2064 6576 6963 6573   ...     devices
+00010650: 3d22 6370 7522 2c0d 0a20 2020 2020 2020  ="cpu",..       
+00010660: 202e 2e2e 2020 2020 2073 746f 7269 6e67   ...     storing
+00010670: 5f64 6576 6963 6573 3d22 6370 7522 2c0d  _devices="cpu",.
+00010680: 0a20 2020 2020 2020 202e 2e2e 2029 0d0a  .        ... )..
+00010690: 2020 2020 2020 2020 3e3e 3e20 666f 7220          >>> for 
+000106a0: 692c 2064 6174 6120 696e 2065 6e75 6d65  i, data in enume
+000106b0: 7261 7465 2863 6f6c 6c65 6374 6f72 293a  rate(collector):
+000106c0: 0d0a 2020 2020 2020 2020 2e2e 2e20 2020  ..        ...   
+000106d0: 2020 6966 2069 203d 3d20 323a 0d0a 2020    if i == 2:..  
+000106e0: 2020 2020 2020 2e2e 2e20 2020 2020 2020        ...       
+000106f0: 2020 7072 696e 7428 6461 7461 290d 0a20    print(data).. 
+00010700: 2020 2020 2020 202e 2e2e 2020 2020 2020         ...      
+00010710: 2020 2062 7265 616b 0d0a 2020 2020 2020     break..      
+00010720: 2020 5465 6e73 6f72 4469 6374 280d 0a20    TensorDict(.. 
+00010730: 2020 2020 2020 2020 2020 2066 6965 6c64             field
+00010740: 733d 7b0d 0a20 2020 2020 2020 2020 2020  s={..           
+00010750: 2020 2020 2061 6374 696f 6e3a 2054 656e       action: Ten
+00010760: 736f 7228 7368 6170 653d 746f 7263 682e  sor(shape=torch.
+00010770: 5369 7a65 285b 342c 2035 302c 2031 5d29  Size([4, 50, 1])
+00010780: 2c20 6465 7669 6365 3d63 7075 2c20 6474  , device=cpu, dt
+00010790: 7970 653d 746f 7263 682e 666c 6f61 7433  ype=torch.float3
+000107a0: 322c 2069 735f 7368 6172 6564 3d46 616c  2, is_shared=Fal
+000107b0: 7365 292c 0d0a 2020 2020 2020 2020 2020  se),..          
+000107c0: 2020 2020 2020 636f 6c6c 6563 746f 723a        collector:
+000107d0: 2054 656e 736f 7244 6963 7428 0d0a 2020   TensorDict(..  
+000107e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000107f0: 2020 6669 656c 6473 3d7b 0d0a 2020 2020    fields={..    
+00010800: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010810: 2020 2020 7374 6570 5f63 6f75 6e74 3a20      step_count: 
+00010820: 5465 6e73 6f72 2873 6861 7065 3d74 6f72  Tensor(shape=tor
+00010830: 6368 2e53 697a 6528 5b34 2c20 3530 5d29  ch.Size([4, 50])
+00010840: 2c20 6465 7669 6365 3d63 7075 2c20 6474  , device=cpu, dt
+00010850: 7970 653d 746f 7263 682e 696e 7436 342c  ype=torch.int64,
+00010860: 2069 735f 7368 6172 6564 3d46 616c 7365   is_shared=False
+00010870: 292c 0d0a 2020 2020 2020 2020 2020 2020  ),..            
+00010880: 2020 2020 2020 2020 2020 2020 7472 616a              traj
+00010890: 5f69 6473 3a20 5465 6e73 6f72 2873 6861  _ids: Tensor(sha
+000108a0: 7065 3d74 6f72 6368 2e53 697a 6528 5b34  pe=torch.Size([4
+000108b0: 2c20 3530 5d29 2c20 6465 7669 6365 3d63  , 50]), device=c
+000108c0: 7075 2c20 6474 7970 653d 746f 7263 682e  pu, dtype=torch.
+000108d0: 696e 7436 342c 2069 735f 7368 6172 6564  int64, is_shared
+000108e0: 3d46 616c 7365 297d 2c0d 0a20 2020 2020  =False)},..     
+000108f0: 2020 2020 2020 2020 2020 2020 2020 2062                 b
+00010900: 6174 6368 5f73 697a 653d 746f 7263 682e  atch_size=torch.
+00010910: 5369 7a65 285b 342c 2035 305d 292c 0d0a  Size([4, 50]),..
+00010920: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010930: 2020 2020 6465 7669 6365 3d63 7075 2c0d      device=cpu,.
+00010940: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00010950: 2020 2020 2069 735f 7368 6172 6564 3d46       is_shared=F
+00010960: 616c 7365 292c 0d0a 2020 2020 2020 2020  alse),..        
+00010970: 2020 2020 2020 2020 646f 6e65 3a20 5465          done: Te
+00010980: 6e73 6f72 2873 6861 7065 3d74 6f72 6368  nsor(shape=torch
+00010990: 2e53 697a 6528 5b34 2c20 3530 2c20 315d  .Size([4, 50, 1]
+000109a0: 292c 2064 6576 6963 653d 6370 752c 2064  ), device=cpu, d
+000109b0: 7479 7065 3d74 6f72 6368 2e62 6f6f 6c2c  type=torch.bool,
+000109c0: 2069 735f 7368 6172 6564 3d46 616c 7365   is_shared=False
+000109d0: 292c 0d0a 2020 2020 2020 2020 2020 2020  ),..            
+000109e0: 2020 2020 6d61 736b 3a20 5465 6e73 6f72      mask: Tensor
+000109f0: 2873 6861 7065 3d74 6f72 6368 2e53 697a  (shape=torch.Siz
+00010a00: 6528 5b34 2c20 3530 5d29 2c20 6465 7669  e([4, 50]), devi
+00010a10: 6365 3d63 7075 2c20 6474 7970 653d 746f  ce=cpu, dtype=to
+00010a20: 7263 682e 626f 6f6c 2c20 6973 5f73 6861  rch.bool, is_sha
+00010a30: 7265 643d 4661 6c73 6529 2c0d 0a20 2020  red=False),..   
+00010a40: 2020 2020 2020 2020 2020 2020 206e 6578               nex
+00010a50: 743a 2054 656e 736f 7244 6963 7428 0d0a  t: TensorDict(..
+00010a60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010a70: 2020 2020 6669 656c 6473 3d7b 0d0a 2020      fields={..  
+00010a80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010a90: 2020 2020 2020 6f62 7365 7276 6174 696f        observatio
+00010aa0: 6e3a 2054 656e 736f 7228 7368 6170 653d  n: Tensor(shape=
+00010ab0: 746f 7263 682e 5369 7a65 285b 342c 2035  torch.Size([4, 5
+00010ac0: 302c 2033 5d29 2c20 6465 7669 6365 3d63  0, 3]), device=c
+00010ad0: 7075 2c20 6474 7970 653d 746f 7263 682e  pu, dtype=torch.
+00010ae0: 666c 6f61 7433 322c 2069 735f 7368 6172  float32, is_shar
+00010af0: 6564 3d46 616c 7365 297d 2c0d 0a20 2020  ed=False)},..   
+00010b00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010b10: 2062 6174 6368 5f73 697a 653d 746f 7263   batch_size=torc
+00010b20: 682e 5369 7a65 285b 342c 2035 305d 292c  h.Size([4, 50]),
+00010b30: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00010b40: 2020 2020 2020 6465 7669 6365 3d63 7075        device=cpu
+00010b50: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
+00010b60: 2020 2020 2020 2069 735f 7368 6172 6564         is_shared
+00010b70: 3d46 616c 7365 292c 0d0a 2020 2020 2020  =False),..      
+00010b80: 2020 2020 2020 2020 2020 6f62 7365 7276            observ
+00010b90: 6174 696f 6e3a 2054 656e 736f 7228 7368  ation: Tensor(sh
+00010ba0: 6170 653d 746f 7263 682e 5369 7a65 285b  ape=torch.Size([
+00010bb0: 342c 2035 302c 2033 5d29 2c20 6465 7669  4, 50, 3]), devi
+00010bc0: 6365 3d63 7075 2c20 6474 7970 653d 746f  ce=cpu, dtype=to
+00010bd0: 7263 682e 666c 6f61 7433 322c 2069 735f  rch.float32, is_
+00010be0: 7368 6172 6564 3d46 616c 7365 292c 0d0a  shared=False),..
+00010bf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010c00: 7265 7761 7264 3a20 5465 6e73 6f72 2873  reward: Tensor(s
+00010c10: 6861 7065 3d74 6f72 6368 2e53 697a 6528  hape=torch.Size(
+00010c20: 5b34 2c20 3530 2c20 315d 292c 2064 6576  [4, 50, 1]), dev
+00010c30: 6963 653d 6370 752c 2064 7479 7065 3d74  ice=cpu, dtype=t
+00010c40: 6f72 6368 2e66 6c6f 6174 3332 2c20 6973  orch.float32, is
+00010c50: 5f73 6861 7265 643d 4661 6c73 6529 7d2c  _shared=False)},
+00010c60: 0d0a 2020 2020 2020 2020 2020 2020 6261  ..            ba
+00010c70: 7463 685f 7369 7a65 3d74 6f72 6368 2e53  tch_size=torch.S
+00010c80: 697a 6528 5b34 2c20 3530 5d29 2c0d 0a20  ize([4, 50]),.. 
+00010c90: 2020 2020 2020 2020 2020 2064 6576 6963             devic
+00010ca0: 653d 6370 752c 0d0a 2020 2020 2020 2020  e=cpu,..        
+00010cb0: 2020 2020 6973 5f73 6861 7265 643d 4661      is_shared=Fa
+00010cc0: 6c73 6529 0d0a 2020 2020 2020 2020 3e3e  lse)..        >>
+00010cd0: 3e20 636f 6c6c 6563 746f 722e 7368 7574  > collector.shut
+00010ce0: 646f 776e 2829 0d0a 2020 2020 2020 2020  down()..        
+00010cf0: 3e3e 3e20 6465 6c20 636f 6c6c 6563 746f  >>> del collecto
+00010d00: 720d 0a0d 0a20 2020 2022 2222 0d0a 0d0a  r....    """....
+00010d10: 2020 2020 5f5f 646f 635f 5f20 2b3d 205f      __doc__ += _
+00010d20: 4d75 6c74 6944 6174 6143 6f6c 6c65 6374  MultiDataCollect
+00010d30: 6f72 2e5f 5f64 6f63 5f5f 0d0a 0d0a 2020  or.__doc__....  
+00010d40: 2020 2320 666f 7220 5250 430d 0a20 2020    # for RPC..   
+00010d50: 2064 6566 206e 6578 7428 7365 6c66 293a   def next(self):
+00010d60: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
+00010d70: 2073 7570 6572 2829 2e6e 6578 7428 290d   super().next().
+00010d80: 0a0d 0a20 2020 2023 2066 6f72 2052 5043  ...    # for RPC
+00010d90: 0d0a 2020 2020 6465 6620 7368 7574 646f  ..    def shutdo
+00010da0: 776e 2873 656c 6629 3a0d 0a20 2020 2020  wn(self):..     
+00010db0: 2020 2072 6574 7572 6e20 7375 7065 7228     return super(
+00010dc0: 292e 7368 7574 646f 776e 2829 0d0a 0d0a  ).shutdown()....
+00010dd0: 2020 2020 2320 666f 7220 5250 430d 0a20      # for RPC.. 
+00010de0: 2020 2064 6566 2073 6574 5f73 6565 6428     def set_seed(
+00010df0: 7365 6c66 2c20 7365 6564 3a20 696e 742c  self, seed: int,
+00010e00: 2073 7461 7469 635f 7365 6564 3a20 626f   static_seed: bo
+00010e10: 6f6c 203d 2046 616c 7365 2920 2d3e 2069  ol = False) -> i
+00010e20: 6e74 3a0d 0a20 2020 2020 2020 2072 6574  nt:..        ret
+00010e30: 7572 6e20 7375 7065 7228 292e 7365 745f  urn super().set_
+00010e40: 7365 6564 2873 6565 642c 2073 7461 7469  seed(seed, stati
+00010e50: 635f 7365 6564 290d 0a0d 0a20 2020 2023  c_seed)....    #
+00010e60: 2066 6f72 2052 5043 0d0a 2020 2020 6465   for RPC..    de
+00010e70: 6620 7374 6174 655f 6469 6374 2873 656c  f state_dict(sel
+00010e80: 6629 202d 3e20 4f72 6465 7265 6444 6963  f) -> OrderedDic
+00010e90: 743a 0d0a 2020 2020 2020 2020 7265 7475  t:..        retu
+00010ea0: 726e 2073 7570 6572 2829 2e73 7461 7465  rn super().state
+00010eb0: 5f64 6963 7428 290d 0a0d 0a20 2020 2023  _dict()....    #
+00010ec0: 2066 6f72 2052 5043 0d0a 2020 2020 6465   for RPC..    de
+00010ed0: 6620 6c6f 6164 5f73 7461 7465 5f64 6963  f load_state_dic
+00010ee0: 7428 7365 6c66 2c20 7374 6174 655f 6469  t(self, state_di
+00010ef0: 6374 3a20 4f72 6465 7265 6444 6963 7429  ct: OrderedDict)
+00010f00: 202d 3e20 4e6f 6e65 3a0d 0a20 2020 2020   -> None:..     
+00010f10: 2020 2072 6574 7572 6e20 7375 7065 7228     return super(
+00010f20: 292e 6c6f 6164 5f73 7461 7465 5f64 6963  ).load_state_dic
+00010f30: 7428 7374 6174 655f 6469 6374 290d 0a0d  t(state_dict)...
+00010f40: 0a20 2020 2023 2066 6f72 2052 5043 0d0a  .    # for RPC..
+00010f50: 2020 2020 6465 6620 7570 6461 7465 5f70      def update_p
+00010f60: 6f6c 6963 795f 7765 6967 6874 735f 280d  olicy_weights_(.
+00010f70: 0a20 2020 2020 2020 2073 656c 662c 2070  .        self, p
+00010f80: 6f6c 6963 795f 7765 6967 6874 733a 204f  olicy_weights: O
+00010f90: 7074 696f 6e61 6c5b 5465 6e73 6f72 4469  ptional[TensorDi
+00010fa0: 6374 4261 7365 5d20 3d20 4e6f 6e65 0d0a  ctBase] = None..
+00010fb0: 2020 2020 2920 2d3e 204e 6f6e 653a 0d0a      ) -> None:..
+00010fc0: 2020 2020 2020 2020 7375 7065 7228 292e          super().
+00010fd0: 7570 6461 7465 5f70 6f6c 6963 795f 7765  update_policy_we
+00010fe0: 6967 6874 735f 2870 6f6c 6963 795f 7765  ights_(policy_we
+00010ff0: 6967 6874 7329 0d0a 0d0a 2020 2020 4070  ights)....    @p
+00011000: 726f 7065 7274 790d 0a20 2020 2064 6566  roperty..    def
+00011010: 2066 7261 6d65 735f 7065 725f 6261 7463   frames_per_batc
+00011020: 685f 776f 726b 6572 2873 656c 6629 3a0d  h_worker(self):.
+00011030: 0a20 2020 2020 2020 2069 6620 7365 6c66  .        if self
+00011040: 2e72 6571 7565 7374 6564 5f66 7261 6d65  .requested_frame
+00011050: 735f 7065 725f 6261 7463 6820 2520 7365  s_per_batch % se
+00011060: 6c66 2e6e 756d 5f77 6f72 6b65 7273 2021  lf.num_workers !
+00011070: 3d20 3020 616e 6420 524c 5f57 4152 4e49  = 0 and RL_WARNI
+00011080: 4e47 533a 0d0a 2020 2020 2020 2020 2020  NGS:..          
+00011090: 2020 7761 726e 696e 6773 2e77 6172 6e28    warnings.warn(
+000110a0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+000110b0: 2020 6622 6672 616d 6573 5f70 6572 5f62    f"frames_per_b
+000110c0: 6174 6368 207b 7365 6c66 2e72 6571 7565  atch {self.reque
+000110d0: 7374 6564 5f66 7261 6d65 735f 7065 725f  sted_frames_per_
+000110e0: 6261 7463 687d 2069 7320 6e6f 7420 6578  batch} is not ex
+000110f0: 6163 746c 7920 6469 7669 7369 626c 6520  actly divisible 
+00011100: 6279 2074 6865 206e 756d 6265 7220 6f66  by the number of
+00011110: 2063 6f6c 6c65 6374 6f72 2077 6f72 6b65   collector worke
+00011120: 7273 207b 7365 6c66 2e6e 756d 5f77 6f72  rs {self.num_wor
+00011130: 6b65 7273 7d2c 220d 0a20 2020 2020 2020  kers},"..       
+00011140: 2020 2020 2020 2020 2066 2220 7468 6973           f" this
+00011150: 2072 6573 756c 7473 2069 6e20 6d6f 7265   results in more
+00011160: 2066 7261 6d65 735f 7065 725f 6261 7463   frames_per_batc
+00011170: 6820 7065 7220 6974 6572 6174 696f 6e20  h per iteration 
+00011180: 7468 6174 2072 6571 7565 7374 6564 2e22  that requested."
+00011190: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+000111a0: 2020 2254 6f20 7369 6c65 6e63 6520 7468    "To silence th
+000111b0: 6973 206d 6573 7361 6765 2c20 7365 7420  is message, set 
+000111c0: 7468 6520 656e 7669 726f 6e6d 656e 7420  the environment 
+000111d0: 7661 7269 6162 6c65 2052 4c5f 5741 524e  variable RL_WARN
+000111e0: 494e 4753 2074 6f20 4661 6c73 652e 220d  INGS to False.".
+000111f0: 0a20 2020 2020 2020 2020 2020 2029 0d0a  .            )..
+00011200: 2020 2020 2020 2020 6672 616d 6573 5f70          frames_p
+00011210: 6572 5f62 6174 6368 5f77 6f72 6b65 7220  er_batch_worker 
+00011220: 3d20 2d28 0d0a 2020 2020 2020 2020 2020  = -(..          
+00011230: 2020 2d73 656c 662e 7265 7175 6573 7465    -self.requeste
+00011240: 645f 6672 616d 6573 5f70 6572 5f62 6174  d_frames_per_bat
+00011250: 6368 202f 2f20 7365 6c66 2e6e 756d 5f77  ch // self.num_w
+00011260: 6f72 6b65 7273 0d0a 2020 2020 2020 2020  orkers..        
+00011270: 290d 0a20 2020 2020 2020 2072 6574 7572  )..        retur
+00011280: 6e20 6672 616d 6573 5f70 6572 5f62 6174  n frames_per_bat
+00011290: 6368 5f77 6f72 6b65 720d 0a0d 0a20 2020  ch_worker....   
+000112a0: 2040 7072 6f70 6572 7479 0d0a 2020 2020   @property..    
+000112b0: 6465 6620 5f71 7565 7565 5f6c 656e 2873  def _queue_len(s
+000112c0: 656c 6629 202d 3e20 696e 743a 0d0a 2020  elf) -> int:..  
+000112d0: 2020 2020 2020 7265 7475 726e 2073 656c        return sel
+000112e0: 662e 6e75 6d5f 776f 726b 6572 730d 0a0d  f.num_workers...
+000112f0: 0a20 2020 2064 6566 2069 7465 7261 746f  .    def iterato
+00011300: 7228 7365 6c66 2920 2d3e 2049 7465 7261  r(self) -> Itera
+00011310: 746f 725b 5465 6e73 6f72 4469 6374 4261  tor[TensorDictBa
+00011320: 7365 5d3a 0d0a 2020 2020 2020 2020 6920  se]:..        i 
+00011330: 3d20 2d31 0d0a 2020 2020 2020 2020 6672  = -1..        fr
+00011340: 616d 6573 203d 2030 0d0a 2020 2020 2020  ames = 0..      
+00011350: 2020 6f75 745f 7465 6e73 6f72 6469 6374    out_tensordict
+00011360: 735f 7368 6172 6564 203d 204f 7264 6572  s_shared = Order
+00011370: 6564 4469 6374 2829 0d0a 2020 2020 2020  edDict()..      
+00011380: 2020 646f 6e65 7320 3d20 5b46 616c 7365    dones = [False
+00011390: 2066 6f72 205f 2069 6e20 7261 6e67 6528   for _ in range(
+000113a0: 7365 6c66 2e6e 756d 5f77 6f72 6b65 7273  self.num_workers
+000113b0: 295d 0d0a 2020 2020 2020 2020 776f 726b  )]..        work
+000113c0: 6572 735f 6672 616d 6573 203d 205b 3020  ers_frames = [0 
+000113d0: 666f 7220 5f20 696e 2072 616e 6765 2873  for _ in range(s
+000113e0: 656c 662e 6e75 6d5f 776f 726b 6572 7329  elf.num_workers)
+000113f0: 5d0d 0a20 2020 2020 2020 2073 616d 655f  ]..        same_
+00011400: 6465 7669 6365 203d 204e 6f6e 650d 0a20  device = None.. 
+00011410: 2020 2020 2020 206f 7574 5f62 7566 6665         out_buffe
+00011420: 7220 3d20 4e6f 6e65 0d0a 2020 2020 2020  r = None..      
+00011430: 2020 7768 696c 6520 6e6f 7420 616c 6c28    while not all(
+00011440: 646f 6e65 7329 2061 6e64 2066 7261 6d65  dones) and frame
+00011450: 7320 3c20 7365 6c66 2e74 6f74 616c 5f66  s < self.total_f
+00011460: 7261 6d65 733a 0d0a 2020 2020 2020 2020  rames:..        
+00011470: 2020 2020 5f63 6865 636b 5f66 6f72 5f66      _check_for_f
+00011480: 6175 6c74 795f 7072 6f63 6573 7328 7365  aulty_process(se
+00011490: 6c66 2e70 726f 6373 290d 0a20 2020 2020  lf.procs)..     
+000114a0: 2020 2020 2020 2069 6620 7365 6c66 2e75         if self.u
+000114b0: 7064 6174 655f 6174 5f65 6163 685f 6261  pdate_at_each_ba
+000114c0: 7463 683a 0d0a 2020 2020 2020 2020 2020  tch:..          
+000114d0: 2020 2020 2020 7365 6c66 2e75 7064 6174        self.updat
+000114e0: 655f 706f 6c69 6379 5f77 6569 6768 7473  e_policy_weights
+000114f0: 5f28 290d 0a0d 0a20 2020 2020 2020 2020  _()....         
+00011500: 2020 2066 6f72 2069 6478 2069 6e20 7261     for idx in ra
+00011510: 6e67 6528 7365 6c66 2e6e 756d 5f77 6f72  nge(self.num_wor
+00011520: 6b65 7273 293a 0d0a 2020 2020 2020 2020  kers):..        
+00011530: 2020 2020 2020 2020 6966 2066 7261 6d65          if frame
+00011540: 7320 3c20 7365 6c66 2e69 6e69 745f 7261  s < self.init_ra
+00011550: 6e64 6f6d 5f66 7261 6d65 733a 0d0a 2020  ndom_frames:..  
+00011560: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011570: 2020 6d73 6720 3d20 2263 6f6e 7469 6e75    msg = "continu
+00011580: 655f 7261 6e64 6f6d 220d 0a20 2020 2020  e_random"..     
+00011590: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
+000115a0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+000115b0: 2020 2020 2020 6d73 6720 3d20 2263 6f6e        msg = "con
+000115c0: 7469 6e75 6522 0d0a 2020 2020 2020 2020  tinue"..        
+000115d0: 2020 2020 2020 2020 7365 6c66 2e70 6970          self.pip
+000115e0: 6573 5b69 6478 5d2e 7365 6e64 2828 4e6f  es[idx].send((No
+000115f0: 6e65 2c20 6d73 6729 290d 0a0d 0a20 2020  ne, msg))....   
+00011600: 2020 2020 2020 2020 2069 202b 3d20 310d           i += 1.
+00011610: 0a20 2020 2020 2020 2020 2020 206d 6178  .            max
+00011620: 5f74 7261 6a5f 6964 7820 3d20 4e6f 6e65  _traj_idx = None
+00011630: 0d0a 0d0a 2020 2020 2020 2020 2020 2020  ....            
+00011640: 6966 2073 656c 662e 696e 7465 7272 7570  if self.interrup
+00011650: 746f 7220 6973 206e 6f74 204e 6f6e 6520  tor is not None 
+00011660: 616e 6420 7365 6c66 2e70 7265 656d 7074  and self.preempt
+00011670: 6976 655f 7468 7265 7368 6f6c 6420 3c20  ive_threshold < 
+00011680: 312e 303a 0d0a 2020 2020 2020 2020 2020  1.0:..          
+00011690: 2020 2020 2020 7365 6c66 2e69 6e74 6572        self.inter
+000116a0: 7275 7074 6f72 2e73 7461 7274 5f63 6f6c  ruptor.start_col
+000116b0: 6c65 6374 696f 6e28 290d 0a20 2020 2020  lection()..     
+000116c0: 2020 2020 2020 2020 2020 2077 6869 6c65             while
+000116d0: 2073 656c 662e 7175 6575 655f 6f75 742e   self.queue_out.
+000116e0: 7173 697a 6528 2920 3c20 696e 7428 0d0a  qsize() < int(..
+000116f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011700: 2020 2020 7365 6c66 2e6e 756d 5f77 6f72      self.num_wor
+00011710: 6b65 7273 202a 2073 656c 662e 7072 6565  kers * self.pree
+00011720: 6d70 7469 7665 5f74 6872 6573 686f 6c64  mptive_threshold
+00011730: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00011740: 2020 293a 0d0a 2020 2020 2020 2020 2020    ):..          
+00011750: 2020 2020 2020 2020 2020 636f 6e74 696e            contin
+00011760: 7565 0d0a 2020 2020 2020 2020 2020 2020  ue..            
+00011770: 2020 2020 7365 6c66 2e69 6e74 6572 7275      self.interru
+00011780: 7074 6f72 2e73 746f 705f 636f 6c6c 6563  ptor.stop_collec
+00011790: 7469 6f6e 2829 0d0a 2020 2020 2020 2020  tion()..        
+000117a0: 2020 2020 2020 2020 2320 4e6f 7720 7761          # Now wa
+000117b0: 6974 2066 6f72 2073 7472 6167 676c 6572  it for straggler
+000117c0: 7320 746f 2072 6574 7572 6e0d 0a20 2020  s to return..   
+000117d0: 2020 2020 2020 2020 2020 2020 2077 6869               whi
+000117e0: 6c65 2073 656c 662e 7175 6575 655f 6f75  le self.queue_ou
+000117f0: 742e 7173 697a 6528 2920 3c20 696e 7428  t.qsize() < int(
+00011800: 7365 6c66 2e6e 756d 5f77 6f72 6b65 7273  self.num_workers
+00011810: 293a 0d0a 2020 2020 2020 2020 2020 2020  ):..            
+00011820: 2020 2020 2020 2020 636f 6e74 696e 7565          continue
+00011830: 0d0a 0d0a 2020 2020 2020 2020 2020 2020  ....            
+00011840: 666f 7220 5f20 696e 2072 616e 6765 2873  for _ in range(s
+00011850: 656c 662e 6e75 6d5f 776f 726b 6572 7329  elf.num_workers)
+00011860: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
+00011870: 2020 206e 6577 5f64 6174 612c 206a 203d     new_data, j =
+00011880: 2073 656c 662e 7175 6575 655f 6f75 742e   self.queue_out.
+00011890: 6765 7428 290d 0a20 2020 2020 2020 2020  get()..         
+000118a0: 2020 2020 2020 2069 6620 6a20 3d3d 2030         if j == 0
+000118b0: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
+000118c0: 2020 2020 2020 2064 6174 612c 2069 6478         data, idx
+000118d0: 203d 206e 6577 5f64 6174 610d 0a20 2020   = new_data..   
+000118e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000118f0: 206f 7574 5f74 656e 736f 7264 6963 7473   out_tensordicts
+00011900: 5f73 6861 7265 645b 6964 785d 203d 2064  _shared[idx] = d
+00011910: 6174 610d 0a20 2020 2020 2020 2020 2020  ata..           
+00011920: 2020 2020 2065 6c73 653a 0d0a 2020 2020       else:..    
+00011930: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011940: 6964 7820 3d20 6e65 775f 6461 7461 0d0a  idx = new_data..
+00011950: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011960: 776f 726b 6572 735f 6672 616d 6573 5b69  workers_frames[i
+00011970: 6478 5d20 3d20 280d 0a20 2020 2020 2020  dx] = (..       
+00011980: 2020 2020 2020 2020 2020 2020 2077 6f72               wor
+00011990: 6b65 7273 5f66 7261 6d65 735b 6964 785d  kers_frames[idx]
+000119a0: 202b 206f 7574 5f74 656e 736f 7264 6963   + out_tensordic
+000119b0: 7473 5f73 6861 7265 645b 6964 785d 2e6e  ts_shared[idx].n
+000119c0: 756d 656c 2829 0d0a 2020 2020 2020 2020  umel()..        
+000119d0: 2020 2020 2020 2020 290d 0a0d 0a20 2020          )....   
+000119e0: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+000119f0: 776f 726b 6572 735f 6672 616d 6573 5b69  workers_frames[i
+00011a00: 6478 5d20 3e3d 2073 656c 662e 746f 7461  dx] >= self.tota
+00011a10: 6c5f 6672 616d 6573 3a0d 0a20 2020 2020  l_frames:..     
+00011a20: 2020 2020 2020 2020 2020 2020 2020 2064                 d
+00011a30: 6f6e 6573 5b69 6478 5d20 3d20 5472 7565  ones[idx] = True
+00011a40: 0d0a 2020 2020 2020 2020 2020 2020 2320  ..            # 
+00011a50: 7765 2068 6176 6520 746f 2063 6f72 7265  we have to corre
+00011a60: 6374 2074 6865 2074 7261 6a5f 6964 7320  ct the traj_ids 
+00011a70: 746f 206d 616b 6520 7375 7265 2074 6861  to make sure tha
+00011a80: 7420 7468 6579 2064 6f6e 2774 206f 7665  t they don't ove
+00011a90: 726c 6170 0d0a 2020 2020 2020 2020 2020  rlap..          
+00011aa0: 2020 666f 7220 6964 7820 696e 2072 616e    for idx in ran
+00011ab0: 6765 2873 656c 662e 6e75 6d5f 776f 726b  ge(self.num_work
+00011ac0: 6572 7329 3a0d 0a20 2020 2020 2020 2020  ers):..         
+00011ad0: 2020 2020 2020 2074 7261 6a5f 6964 7320         traj_ids 
+00011ae0: 3d20 6f75 745f 7465 6e73 6f72 6469 6374  = out_tensordict
+00011af0: 735f 7368 6172 6564 5b69 6478 5d2e 6765  s_shared[idx].ge
+00011b00: 7428 2822 636f 6c6c 6563 746f 7222 2c20  t(("collector", 
+00011b10: 2274 7261 6a5f 6964 7322 2929 0d0a 2020  "traj_ids"))..  
+00011b20: 2020 2020 2020 2020 2020 2020 2020 6966                if
+00011b30: 206d 6178 5f74 7261 6a5f 6964 7820 6973   max_traj_idx is
+00011b40: 206e 6f74 204e 6f6e 653a 0d0a 2020 2020   not None:..    
+00011b50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011b60: 7472 616a 5f69 6473 5b74 7261 6a5f 6964  traj_ids[traj_id
+00011b70: 7320 213d 202d 315d 202b 3d20 6d61 785f  s != -1] += max_
+00011b80: 7472 616a 5f69 6478 0d0a 2020 2020 2020  traj_idx..      
+00011b90: 2020 2020 2020 2020 2020 2020 2020 2320                # 
+00011ba0: 6f75 745f 7465 6e73 6f72 6469 6374 735f  out_tensordicts_
+00011bb0: 7368 6172 6564 5b69 6478 5d2e 7365 7428  shared[idx].set(
+00011bc0: 2274 7261 6a5f 6964 7322 2c20 7472 616a  "traj_ids", traj
+00011bd0: 5f69 6473 290d 0a20 2020 2020 2020 2020  _ids)..         
+00011be0: 2020 2020 2020 206d 6178 5f74 7261 6a5f         max_traj_
+00011bf0: 6964 7820 3d20 7472 616a 5f69 6473 2e6d  idx = traj_ids.m
+00011c00: 6178 2829 2e69 7465 6d28 2920 2b20 310d  ax().item() + 1.
+00011c10: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00011c20: 2023 206f 7574 203d 206f 7574 5f74 656e   # out = out_ten
+00011c30: 736f 7264 6963 7473 5f73 6861 7265 645b  sordicts_shared[
+00011c40: 6964 785d 0d0a 2020 2020 2020 2020 2020  idx]..          
+00011c50: 2020 6966 2073 616d 655f 6465 7669 6365    if same_device
+00011c60: 2069 7320 4e6f 6e65 3a0d 0a20 2020 2020   is None:..     
+00011c70: 2020 2020 2020 2020 2020 2070 7265 765f             prev_
+00011c80: 6465 7669 6365 203d 204e 6f6e 650d 0a20  device = None.. 
+00011c90: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+00011ca0: 616d 655f 6465 7669 6365 203d 2054 7275  ame_device = Tru
+00011cb0: 650d 0a20 2020 2020 2020 2020 2020 2020  e..             
+00011cc0: 2020 2066 6f72 2069 7465 6d20 696e 206f     for item in o
+00011cd0: 7574 5f74 656e 736f 7264 6963 7473 5f73  ut_tensordicts_s
+00011ce0: 6861 7265 642e 7661 6c75 6573 2829 3a0d  hared.values():.
+00011cf0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00011d00: 2020 2020 2069 6620 7072 6576 5f64 6576       if prev_dev
+00011d10: 6963 6520 6973 204e 6f6e 653a 0d0a 2020  ice is None:..  
+00011d20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011d30: 2020 2020 2020 7072 6576 5f64 6576 6963        prev_devic
+00011d40: 6520 3d20 6974 656d 2e64 6576 6963 650d  e = item.device.
+00011d50: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00011d60: 2020 2020 2065 6c73 653a 0d0a 2020 2020       else:..    
+00011d70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011d80: 2020 2020 7361 6d65 5f64 6576 6963 6520      same_device 
+00011d90: 3d20 7361 6d65 5f64 6576 6963 6520 616e  = same_device an
+00011da0: 6420 2869 7465 6d2e 6465 7669 6365 203d  d (item.device =
+00011db0: 3d20 7072 6576 5f64 6576 6963 6529 0d0a  = prev_device)..
+00011dc0: 0d0a 2020 2020 2020 2020 2020 2020 6966  ..            if
+00011dd0: 2073 616d 655f 6465 7669 6365 3a0d 0a20   same_device:.. 
+00011de0: 2020 2020 2020 2020 2020 2020 2020 206f                 o
+00011df0: 7574 5f62 7566 6665 7220 3d20 746f 7263  ut_buffer = torc
+00011e00: 682e 6361 7428 0d0a 2020 2020 2020 2020  h.cat(..        
+00011e10: 2020 2020 2020 2020 2020 2020 6c69 7374              list
+00011e20: 286f 7574 5f74 656e 736f 7264 6963 7473  (out_tensordicts
+00011e30: 5f73 6861 7265 642e 7661 6c75 6573 2829  _shared.values()
+00011e40: 292c 2030 2c20 6f75 743d 6f75 745f 6275  ), 0, out=out_bu
+00011e50: 6666 6572 0d0a 2020 2020 2020 2020 2020  ffer..          
+00011e60: 2020 2020 2020 290d 0a20 2020 2020 2020        )..       
+00011e70: 2020 2020 2065 6c73 653a 0d0a 2020 2020       else:..    
+00011e80: 2020 2020 2020 2020 2020 2020 6f75 745f              out_
+00011e90: 6275 6666 6572 203d 2074 6f72 6368 2e63  buffer = torch.c
+00011ea0: 6174 280d 0a20 2020 2020 2020 2020 2020  at(..           
+00011eb0: 2020 2020 2020 2020 205b 6974 656d 2e63           [item.c
+00011ec0: 7075 2829 2066 6f72 2069 7465 6d20 696e  pu() for item in
+00011ed0: 206f 7574 5f74 656e 736f 7264 6963 7473   out_tensordicts
+00011ee0: 5f73 6861 7265 642e 7661 6c75 6573 2829  _shared.values()
+00011ef0: 5d2c 0d0a 2020 2020 2020 2020 2020 2020  ],..            
+00011f00: 2020 2020 2020 2020 302c 0d0a 2020 2020          0,..    
+00011f10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011f20: 6f75 743d 6f75 745f 6275 6666 6572 2c0d  out=out_buffer,.
+00011f30: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00011f40: 2029 0d0a 0d0a 2020 2020 2020 2020 2020   )....          
+00011f50: 2020 6966 2073 656c 662e 7370 6c69 745f    if self.split_
+00011f60: 7472 616a 733a 0d0a 2020 2020 2020 2020  trajs:..        
+00011f70: 2020 2020 2020 2020 6f75 7420 3d20 7370          out = sp
+00011f80: 6c69 745f 7472 616a 6563 746f 7269 6573  lit_trajectories
+00011f90: 286f 7574 5f62 7566 6665 722c 2070 7265  (out_buffer, pre
+00011fa0: 6669 783d 2263 6f6c 6c65 6374 6f72 2229  fix="collector")
+00011fb0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00011fc0: 2020 6672 616d 6573 202b 3d20 6f75 742e    frames += out.
+00011fd0: 6765 7428 2822 636f 6c6c 6563 746f 7222  get(("collector"
+00011fe0: 2c20 226d 6173 6b22 2929 2e73 756d 2829  , "mask")).sum()
+00011ff0: 2e69 7465 6d28 290d 0a20 2020 2020 2020  .item()..       
+00012000: 2020 2020 2065 6c73 653a 0d0a 2020 2020       else:..    
+00012010: 2020 2020 2020 2020 2020 2020 6f75 7420              out 
+00012020: 3d20 6f75 745f 6275 6666 6572 2e63 6c6f  = out_buffer.clo
+00012030: 6e65 2829 0d0a 2020 2020 2020 2020 2020  ne()..          
+00012040: 2020 2020 2020 6672 616d 6573 202b 3d20        frames += 
+00012050: 7072 6f64 286f 7574 2e73 6861 7065 290d  prod(out.shape).
+00012060: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
+00012070: 7365 6c66 2e70 6f73 7470 726f 6373 3a0d  self.postprocs:.
+00012080: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00012090: 2073 656c 662e 706f 7374 7072 6f63 7320   self.postprocs 
+000120a0: 3d20 7365 6c66 2e70 6f73 7470 726f 6373  = self.postprocs
+000120b0: 2e74 6f28 6f75 742e 6465 7669 6365 290d  .to(out.device).
+000120c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000120d0: 206f 7574 203d 2073 656c 662e 706f 7374   out = self.post
+000120e0: 7072 6f63 7328 6f75 7429 0d0a 2020 2020  procs(out)..    
+000120f0: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
+00012100: 5f65 7863 6c75 6465 5f70 7269 7661 7465  _exclude_private
+00012110: 5f6b 6579 733a 0d0a 2020 2020 2020 2020  _keys:..        
+00012120: 2020 2020 2020 2020 6578 636c 7564 6564          excluded
+00012130: 5f6b 6579 7320 3d20 5b6b 6579 2066 6f72  _keys = [key for
+00012140: 206b 6579 2069 6e20 6f75 742e 6b65 7973   key in out.keys
+00012150: 2829 2069 6620 6b65 792e 7374 6172 7473  () if key.starts
+00012160: 7769 7468 2822 5f22 295d 0d0a 2020 2020  with("_")]..    
+00012170: 2020 2020 2020 2020 2020 2020 6966 2065              if e
+00012180: 7863 6c75 6465 645f 6b65 7973 3a0d 0a20  xcluded_keys:.. 
+00012190: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000121a0: 2020 206f 7574 203d 206f 7574 2e65 7863     out = out.exc
+000121b0: 6c75 6465 282a 6578 636c 7564 6564 5f6b  lude(*excluded_k
+000121c0: 6579 7329 0d0a 2020 2020 2020 2020 2020  eys)..          
+000121d0: 2020 7969 656c 6420 6f75 740d 0a20 2020    yield out..   
+000121e0: 2020 2020 2020 2020 2064 656c 206f 7574           del out
+000121f0: 0d0a 0d0a 2020 2020 2020 2020 6465 6c20  ....        del 
+00012200: 6f75 745f 7465 6e73 6f72 6469 6374 735f  out_tensordicts_
+00012210: 7368 6172 6564 0d0a 2020 2020 2020 2020  shared..        
+00012220: 2320 5765 2073 6861 6c6c 206e 6f74 2063  # We shall not c
+00012230: 616c 6c20 7368 7574 646f 776e 206a 7573  all shutdown jus
+00012240: 7420 7965 7420 6173 2075 7365 7220 6d61  t yet as user ma
+00012250: 7920 7761 6e74 2074 6f20 7265 7472 6965  y want to retrie
+00012260: 7665 2073 7461 7465 5f64 6963 740d 0a20  ve state_dict.. 
+00012270: 2020 2020 2020 2023 2073 656c 662e 5f73         # self._s
+00012280: 6875 7464 6f77 6e5f 6d61 696e 2829 0d0a  hutdown_main()..
+00012290: 0d0a 0d0a 4061 6363 6570 745f 7265 6d6f  ....@accept_remo
+000122a0: 7465 5f72 7265 665f 7564 665f 696e 766f  te_rref_udf_invo
+000122b0: 6361 7469 6f6e 0d0a 636c 6173 7320 4d75  cation..class Mu
+000122c0: 6c74 6961 5379 6e63 4461 7461 436f 6c6c  ltiaSyncDataColl
+000122d0: 6563 746f 7228 5f4d 756c 7469 4461 7461  ector(_MultiData
+000122e0: 436f 6c6c 6563 746f 7229 3a0d 0a20 2020  Collector):..   
+000122f0: 2022 2222 5275 6e73 2061 2067 6976 656e   """Runs a given
+00012300: 206e 756d 6265 7220 6f66 2044 6174 6143   number of DataC
+00012310: 6f6c 6c65 6374 6f72 7320 6f6e 2073 6570  ollectors on sep
+00012320: 6172 6174 6520 7072 6f63 6573 7365 7320  arate processes 
+00012330: 6173 796e 6368 726f 6e6f 7573 6c79 2e0d  asynchronously..
+00012340: 0a0d 0a20 2020 202e 2e20 6161 6669 673a  ...    .. aafig:
+00012350: 3a0d 0a0d 0a0d 0a20 2020 2020 2020 2020  :......         
+00012360: 2020 202b 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d     +------------
+00012370: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+00012380: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+00012390: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+000123a0: 2d2d 2d2d 2d2d 2d2d 2d2d 2b0d 0a20 2020  ----------+..   
+000123b0: 2020 2020 2020 2020 207c 2020 2020 2020           |      
+000123c0: 2020 2020 2022 4d75 6c74 6943 6f6e 6375       "MultiConcu
+000123d0: 7272 656e 7443 6f6c 6c65 6374 6f72 2220  rrentCollector" 
+000123e0: 2020 2020 2020 2020 2020 2020 2020 207c                 |
+000123f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012400: 7c0d 0a20 2020 2020 2020 2020 2020 207c  |..            |
+00012410: 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e  ~~~~~~~~~~~~~~~~
+00012420: 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e  ~~~~~~~~~~~~~~~~
+00012430: 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e  ~~~~~~~~~~~~~~~~
+00012440: 7e7e 7e7e 7e7c 2020 2020 2020 2020 2020  ~~~~~|          
+00012450: 2020 2020 2020 7c0d 0a20 2020 2020 2020        |..       
+00012460: 2020 2020 207c 2020 2243 6f6c 6c65 6374       |  "Collect
+00012470: 6f72 2031 2220 207c 2020 2243 6f6c 6c65  or 1"  |  "Colle
+00012480: 6374 6f72 2032 2220 207c 2020 2243 6f6c  ctor 2"  |  "Col
+00012490: 6c65 6374 6f72 2033 2220 207c 2020 2020  lector 3"  |    
+000124a0: 2022 4d61 696e 2220 2020 2020 7c0d 0a20   "Main"     |.. 
+000124b0: 2020 2020 2020 2020 2020 207c 7e7e 7e7e             |~~~~
+000124c0: 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7c 7e7e  ~~~~~~~~~~~~~|~~
+000124d0: 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7c  ~~~~~~~~~~~~~~~|
+000124e0: 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e  ~~~~~~~~~~~~~~~~
+000124f0: 7e7c 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e  ~|~~~~~~~~~~~~~~
+00012500: 7e7e 7c0d 0a20 2020 2020 2020 2020 2020  ~~|..           
+00012510: 207c 2022 656e 7631 2220 7c20 2265 6e76   | "env1" | "env
+00012520: 3222 207c 2022 656e 7633 2220 7c20 2265  2" | "env3" | "e
+00012530: 6e76 3422 207c 2022 656e 7635 2220 7c20  nv4" | "env5" | 
+00012540: 2265 6e76 3622 207c 2020 2020 2020 2020  "env6" |        
+00012550: 2020 2020 2020 2020 7c0d 0a20 2020 2020          |..     
+00012560: 2020 2020 2020 207c 7e7e 7e7e 7e7e 7e7e         |~~~~~~~~
+00012570: 7c7e 7e7e 7e7e 7e7e 7e7c 7e7e 7e7e 7e7e  |~~~~~~~~|~~~~~~
+00012580: 7e7e 7c7e 7e7e 7e7e 7e7e 7e7c 7e7e 7e7e  ~~|~~~~~~~~|~~~~
+00012590: 7e7e 7e7e 7c7e 7e7e 7e7e 7e7e 7e7c 7e7e  ~~~~|~~~~~~~~|~~
+000125a0: 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7e7e 7c0d  ~~~~~~~~~~~~~~|.
+000125b0: 0a20 2020 2020 2020 2020 2020 207c 2272  .            |"r
+000125c0: 6573 6574 2220 7c22 7265 7365 7422 207c  eset" |"reset" |
+000125d0: 2272 6573 6574 2220 7c22 7265 7365 7422  "reset" |"reset"
+000125e0: 207c 2272 6573 6574 2220 7c22 7265 7365   |"reset" |"rese
+000125f0: 7422 207c 2020 2020 2020 2020 2020 2020  t" |            
+00012600: 2020 2020 7c0d 0a20 2020 2020 2020 2020      |..         
+00012610: 2020 207c 2020 2020 2020 2020 7c20 2020     |        |   
+00012620: 2020 2020 207c 2020 2020 2020 2020 7c20       |        | 
+00012630: 2020 2020 2020 207c 2020 2020 2020 2020         |        
+00012640: 7c20 2020 2020 2020 207c 2020 2020 2020  |        |      
+00012650: 2020 2020 2020 2020 2020 7c0d 0a20 2020            |..   
+00012660: 2020 2020 2020 2020 207c 2020 2020 2020           |      
+00012670: 2022 6163 746f 7222 2020 207c 2020 2020   "actor"   |    
+00012680: 2020 2020 7c20 2020 2020 2020 207c 2020      |        |  
+00012690: 2020 2020 2022 6163 746f 7222 2020 207c       "actor"   |
+000126a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000126b0: 7c0d 0a20 2020 2020 2020 2020 2020 207c  |..            |
+000126c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000126d0: 207c 2020 2020 2020 2020 7c20 2020 2020   |        |     
+000126e0: 2020 207c 2020 2020 2020 2020 2020 2020     |            
+000126f0: 2020 2020 207c 2020 2020 2020 2020 2020       |          
+00012700: 2020 2020 2020 7c0d 0a20 2020 2020 2020        |..       
+00012710: 2020 2020 207c 2022 7374 6570 2220 7c20       | "step" | 
+00012720: 2273 7465 7022 207c 2020 2020 2020 2022  "step" |       "
+00012730: 6163 746f 7222 2020 207c 2020 2020 2020  actor"   |      
+00012740: 2020 2020 2020 2020 2020 207c 2020 2020             |    
+00012750: 2020 2020 2020 2020 2020 2020 7c0d 0a20              |.. 
+00012760: 2020 2020 2020 2020 2020 207c 2020 2020             |    
+00012770: 2020 2020 7c20 2020 2020 2020 207c 2020      |        |  
+00012780: 2020 2020 2020 2020 2020 2020 2020 207c                 |
+00012790: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000127a0: 207c 2020 2020 2020 2020 2020 2020 2020   |              
+000127b0: 2020 7c0d 0a20 2020 2020 2020 2020 2020    |..           
+000127c0: 207c 2020 2020 2020 2020 7c20 2020 2020   |        |     
+000127d0: 2020 207c 2020 2020 2020 2020 2020 2020     |            
+000127e0: 2020 2020 207c 2022 7374 6570 2220 7c20       | "step" | 
+000127f0: 2273 7465 7022 207c 2020 2020 2020 2020  "step" |        
+00012800: 2020 2020 2020 2020 7c0d 0a20 2020 2020          |..     
+00012810: 2020 2020 2020 207c 2020 2020 2020 2020         |        
+00012820: 7c20 2020 2020 2020 207c 2020 2020 2020  |        |      
+00012830: 2020 2020 2020 2020 2020 207c 2020 2020             |    
+00012840: 2020 2020 7c20 2020 2020 2020 207c 2020      |        |  
+00012850: 2020 2020 2020 2020 2020 2020 2020 7c0d                |.
+00012860: 0a20 2020 2020 2020 2020 2020 207c 2020  .            |  
+00012870: 2020 2020 2022 6163 746f 7220 2020 207c       "actor    |
+00012880: 2022 7374 6570 2220 7c20 2273 7465 7022   "step" | "step"
+00012890: 207c 2020 2020 2020 2022 6163 746f 7222   |       "actor"
+000128a0: 2020 207c 2020 2020 2020 2020 2020 2020     |            
+000128b0: 2020 2020 7c0d 0a20 2020 2020 2020 2020      |..         
+000128c0: 2020 207c 2020 2020 2020 2020 2020 2020     |            
+000128d0: 2020 2020 207c 2020 2020 2020 2020 7c20       |        | 
+000128e0: 2020 2020 2020 207c 2020 2020 2020 2020         |        
+000128f0: 2020 2020 2020 2020 207c 2020 2020 2020           |      
+00012900: 2020 2020 2020 2020 2020 7c0d 0a20 2020            |..   
+00012910: 2020 2020 2020 2020 207c 2022 7969 656c           | "yiel
+00012920: 6420 6261 7463 6820 3122 207c 2020 2020  d batch 1" |    
+00012930: 2020 2022 6163 746f 7222 2020 207c 2020     "actor"   |  
+00012940: 2020 2020 2020 2020 2020 2020 2020 207c                 |
+00012950: 2263 6f6c 6c65 6374 2c20 7472 6169 6e22  "collect, train"
+00012960: 7c0d 0a20 2020 2020 2020 2020 2020 207c  |..            |
+00012970: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012980: 207c 2020 2020 2020 2020 2020 2020 2020   |              
+00012990: 2020 207c 2020 2020 2020 2020 2020 2020     |            
+000129a0: 2020 2020 207c 2020 2020 2020 2020 2020       |          
+000129b0: 2020 2020 2020 7c0d 0a20 2020 2020 2020        |..       
+000129c0: 2020 2020 207c 2022 7374 6570 2220 7c20       | "step" | 
+000129d0: 2273 7465 7022 207c 2020 2020 2020 2020  "step" |        
+000129e0: 2020 2020 2020 2020 207c 2022 7969 656c           | "yiel
+000129f0: 6420 6261 7463 6820 3222 207c 2263 6f6c  d batch 2" |"col
+00012a00: 6c65 6374 2c20 7472 6169 6e22 7c0d 0a20  lect, train"|.. 
+00012a10: 2020 2020 2020 2020 2020 207c 2020 2020             |    
+00012a20: 2020 2020 7c20 2020 2020 2020 207c 2020      |        |  
+00012a30: 2020 2020 2020 2020 2020 2020 2020 207c                 |
+00012a40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012a50: 207c 2020 2020 2020 2020 2020 2020 2020   |              
+00012a60: 2020 7c0d 0a20 2020 2020 2020 2020 2020    |..           
+00012a70: 207c 2020 2020 2020 2020 7c20 2020 2020   |        |     
+00012a80: 2020 207c 2022 7969 656c 6420 6261 7463     | "yield batc
+00012a90: 6820 3322 207c 2020 2020 2020 2020 2020  h 3" |          
+00012aa0: 2020 2020 2020 207c 2263 6f6c 6c65 6374         |"collect
+00012ab0: 2c20 7472 6169 6e22 7c0d 0a20 2020 2020  , train"|..     
+00012ac0: 2020 2020 2020 207c 2020 2020 2020 2020         |        
+00012ad0: 7c20 2020 2020 2020 207c 2020 2020 2020  |        |      
+00012ae0: 2020 2020 2020 2020 2020 207c 2020 2020             |    
+00012af0: 2020 2020 2020 2020 2020 2020 207c 2020               |  
+00012b00: 2020 2020 2020 2020 2020 2020 2020 7c0d                |.
+00012b10: 0a20 2020 2020 2020 2020 2020 202b 2d2d  .            +--
+00012b20: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+00012b30: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+00012b40: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+00012b50: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+00012b60: 2d2d 2d2d 2b0d 0a0d 0a20 2020 2045 6e76  ----+....    Env
+00012b70: 6972 6f6e 6d65 6e74 2074 7970 6573 2063  ironment types c
+00012b80: 616e 2062 6520 6964 656e 7469 6361 6c20  an be identical 
+00012b90: 6f72 2064 6966 6665 7265 6e74 2e0d 0a0d  or different....
+00012ba0: 0a20 2020 2054 6865 2063 6f6c 6c65 6374  .    The collect
+00012bb0: 696f 6e20 6b65 6570 7320 6f6e 206f 6363  ion keeps on occ
+00012bc0: 7572 696e 6720 6f6e 2061 6c6c 2070 726f  uring on all pro
+00012bd0: 6365 7373 6573 2065 7665 6e20 6265 7477  cesses even betw
+00012be0: 6565 6e20 7468 6520 7469 6d65 0d0a 2020  een the time..  
+00012bf0: 2020 7468 6520 6261 7463 6820 6f66 2072    the batch of r
+00012c00: 6f6c 6c6f 7574 7320 6973 2063 6f6c 6c65  ollouts is colle
+00012c10: 6374 6564 2061 6e64 2074 6865 206e 6578  cted and the nex
+00012c20: 7420 6361 6c6c 2074 6f20 7468 6520 6974  t call to the it
+00012c30: 6572 6174 6f72 2e0d 0a20 2020 2054 6869  erator...    Thi
+00012c40: 7320 636c 6173 7320 6361 6e20 6265 2073  s class can be s
+00012c50: 6166 656c 7920 7573 6564 2077 6974 6820  afely used with 
+00012c60: 6f66 666c 696e 6520 524c 2061 6c67 6f72  offline RL algor
+00012c70: 6974 686d 732e 0d0a 0d0a 2020 2020 4578  ithms.....    Ex
+00012c80: 616d 706c 6573 3a0d 0a20 2020 2020 2020  amples:..       
+00012c90: 203e 3e3e 2066 726f 6d20 746f 7263 6872   >>> from torchr
+00012ca0: 6c2e 656e 7673 2e6c 6962 732e 6779 6d20  l.envs.libs.gym 
+00012cb0: 696d 706f 7274 2047 796d 456e 760d 0a20  import GymEnv.. 
+00012cc0: 2020 2020 2020 203e 3e3e 2066 726f 6d20         >>> from 
+00012cd0: 7465 6e73 6f72 6469 6374 2e6e 6e20 696d  tensordict.nn im
+00012ce0: 706f 7274 2054 656e 736f 7244 6963 744d  port TensorDictM
+00012cf0: 6f64 756c 650d 0a20 2020 2020 2020 203e  odule..        >
+00012d00: 3e3e 2066 726f 6d20 746f 7263 6820 696d  >> from torch im
+00012d10: 706f 7274 206e 6e0d 0a20 2020 2020 2020  port nn..       
+00012d20: 203e 3e3e 2065 6e76 5f6d 616b 6572 203d   >>> env_maker =
+00012d30: 206c 616d 6264 613a 2047 796d 456e 7628   lambda: GymEnv(
+00012d40: 2250 656e 6475 6c75 6d2d 7631 222c 2064  "Pendulum-v1", d
+00012d50: 6576 6963 653d 2263 7075 2229 0d0a 2020  evice="cpu")..  
+00012d60: 2020 2020 2020 3e3e 3e20 706f 6c69 6379        >>> policy
+00012d70: 203d 2054 656e 736f 7244 6963 744d 6f64   = TensorDictMod
+00012d80: 756c 6528 6e6e 2e4c 696e 6561 7228 332c  ule(nn.Linear(3,
+00012d90: 2031 292c 2069 6e5f 6b65 7973 3d5b 226f   1), in_keys=["o
+00012da0: 6273 6572 7661 7469 6f6e 225d 2c20 6f75  bservation"], ou
+00012db0: 745f 6b65 7973 3d5b 2261 6374 696f 6e22  t_keys=["action"
+00012dc0: 5d29 0d0a 2020 2020 2020 2020 3e3e 3e20  ])..        >>> 
+00012dd0: 636f 6c6c 6563 746f 7220 3d20 4d75 6c74  collector = Mult
+00012de0: 6961 5379 6e63 4461 7461 436f 6c6c 6563  iaSyncDataCollec
+00012df0: 746f 7228 0d0a 2020 2020 2020 2020 2e2e  tor(..        ..
+00012e00: 2e20 2020 2020 6372 6561 7465 5f65 6e76  .     create_env
+00012e10: 5f66 6e3d 5b65 6e76 5f6d 616b 6572 2c20  _fn=[env_maker, 
+00012e20: 656e 765f 6d61 6b65 725d 2c0d 0a20 2020  env_maker],..   
+00012e30: 2020 2020 202e 2e2e 2020 2020 2070 6f6c       ...     pol
+00012e40: 6963 793d 706f 6c69 6379 2c0d 0a20 2020  icy=policy,..   
+00012e50: 2020 2020 202e 2e2e 2020 2020 2074 6f74       ...     tot
+00012e60: 616c 5f66 7261 6d65 733d 3230 3030 2c0d  al_frames=2000,.
+00012e70: 0a20 2020 2020 2020 202e 2e2e 2020 2020  .        ...    
+00012e80: 206d 6178 5f66 7261 6d65 735f 7065 725f   max_frames_per_
+00012e90: 7472 616a 3d35 302c 0d0a 2020 2020 2020  traj=50,..      
+00012ea0: 2020 2e2e 2e20 2020 2020 6672 616d 6573    ...     frames
+00012eb0: 5f70 6572 5f62 6174 6368 3d32 3030 2c0d  _per_batch=200,.
+00012ec0: 0a20 2020 2020 2020 202e 2e2e 2020 2020  .        ...    
+00012ed0: 2069 6e69 745f 7261 6e64 6f6d 5f66 7261   init_random_fra
+00012ee0: 6d65 733d 2d31 2c0d 0a20 2020 2020 2020  mes=-1,..       
+00012ef0: 202e 2e2e 2020 2020 2072 6573 6574 5f61   ...     reset_a
+00012f00: 745f 6561 6368 5f69 7465 723d 4661 6c73  t_each_iter=Fals
+00012f10: 652c 0d0a 2020 2020 2020 2020 2e2e 2e20  e,..        ... 
+00012f20: 2020 2020 6465 7669 6365 733d 2263 7075      devices="cpu
+00012f30: 222c 0d0a 2020 2020 2020 2020 2e2e 2e20  ",..        ... 
+00012f40: 2020 2020 7374 6f72 696e 675f 6465 7669      storing_devi
+00012f50: 6365 733d 2263 7075 222c 0d0a 2020 2020  ces="cpu",..    
+00012f60: 2020 2020 2e2e 2e20 290d 0a20 2020 2020      ... )..     
+00012f70: 2020 203e 3e3e 2066 6f72 2069 2c20 6461     >>> for i, da
+00012f80: 7461 2069 6e20 656e 756d 6572 6174 6528  ta in enumerate(
+00012f90: 636f 6c6c 6563 746f 7229 3a0d 0a20 2020  collector):..   
+00012fa0: 2020 2020 202e 2e2e 2020 2020 2069 6620       ...     if 
+00012fb0: 6920 3d3d 2032 3a0d 0a20 2020 2020 2020  i == 2:..       
+00012fc0: 202e 2e2e 2020 2020 2020 2020 2070 7269   ...         pri
+00012fd0: 6e74 2864 6174 6129 0d0a 2020 2020 2020  nt(data)..      
+00012fe0: 2020 2e2e 2e20 2020 2020 2020 2020 6272    ...         br
+00012ff0: 6561 6b0d 0a20 2020 2020 2020 2054 656e  eak..        Ten
+00013000: 736f 7244 6963 7428 0d0a 2020 2020 2020  sorDict(..      
+00013010: 2020 2020 2020 6669 656c 6473 3d7b 0d0a        fields={..
+00013020: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013030: 6163 7469 6f6e 3a20 5465 6e73 6f72 2873  action: Tensor(s
+00013040: 6861 7065 3d74 6f72 6368 2e53 697a 6528  hape=torch.Size(
+00013050: 5b34 2c20 3530 2c20 315d 292c 2064 6576  [4, 50, 1]), dev
+00013060: 6963 653d 6370 752c 2064 7479 7065 3d74  ice=cpu, dtype=t
+00013070: 6f72 6368 2e66 6c6f 6174 3332 2c20 6973  orch.float32, is
+00013080: 5f73 6861 7265 643d 4661 6c73 6529 2c0d  _shared=False),.
+00013090: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000130a0: 2063 6f6c 6c65 6374 6f72 3a20 5465 6e73   collector: Tens
+000130b0: 6f72 4469 6374 280d 0a20 2020 2020 2020  orDict(..       
+000130c0: 2020 2020 2020 2020 2020 2020 2066 6965               fie
+000130d0: 6c64 733d 7b0d 0a20 2020 2020 2020 2020  lds={..         
+000130e0: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+000130f0: 7465 705f 636f 756e 743a 2054 656e 736f  tep_count: Tenso
+00013100: 7228 7368 6170 653d 746f 7263 682e 5369  r(shape=torch.Si
+00013110: 7a65 285b 342c 2035 305d 292c 2064 6576  ze([4, 50]), dev
+00013120: 6963 653d 6370 752c 2064 7479 7065 3d74  ice=cpu, dtype=t
+00013130: 6f72 6368 2e69 6e74 3634 2c20 6973 5f73  orch.int64, is_s
+00013140: 6861 7265 643d 4661 6c73 6529 2c0d 0a20  hared=False),.. 
+00013150: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013160: 2020 2020 2020 2074 7261 6a5f 6964 733a         traj_ids:
+00013170: 2054 656e 736f 7228 7368 6170 653d 746f   Tensor(shape=to
+00013180: 7263 682e 5369 7a65 285b 342c 2035 305d  rch.Size([4, 50]
+00013190: 292c 2064 6576 6963 653d 6370 752c 2064  ), device=cpu, d
+000131a0: 7479 7065 3d74 6f72 6368 2e69 6e74 3634  type=torch.int64
+000131b0: 2c20 6973 5f73 6861 7265 643d 4661 6c73  , is_shared=Fals
+000131c0: 6529 7d2c 0d0a 2020 2020 2020 2020 2020  e)},..          
+000131d0: 2020 2020 2020 2020 2020 6261 7463 685f            batch_
+000131e0: 7369 7a65 3d74 6f72 6368 2e53 697a 6528  size=torch.Size(
+000131f0: 5b34 2c20 3530 5d29 2c0d 0a20 2020 2020  [4, 50]),..     
+00013200: 2020 2020 2020 2020 2020 2020 2020 2064                 d
+00013210: 6576 6963 653d 6370 752c 0d0a 2020 2020  evice=cpu,..    
+00013220: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013230: 6973 5f73 6861 7265 643d 4661 6c73 6529  is_shared=False)
+00013240: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
+00013250: 2020 2064 6f6e 653a 2054 656e 736f 7228     done: Tensor(
+00013260: 7368 6170 653d 746f 7263 682e 5369 7a65  shape=torch.Size
+00013270: 285b 342c 2035 302c 2031 5d29 2c20 6465  ([4, 50, 1]), de
+00013280: 7669 6365 3d63 7075 2c20 6474 7970 653d  vice=cpu, dtype=
+00013290: 746f 7263 682e 626f 6f6c 2c20 6973 5f73  torch.bool, is_s
+000132a0: 6861 7265 643d 4661 6c73 6529 2c0d 0a20  hared=False),.. 
+000132b0: 2020 2020 2020 2020 2020 2020 2020 206d                 m
+000132c0: 6173 6b3a 2054 656e 736f 7228 7368 6170  ask: Tensor(shap
+000132d0: 653d 746f 7263 682e 5369 7a65 285b 342c  e=torch.Size([4,
+000132e0: 2035 305d 292c 2064 6576 6963 653d 6370   50]), device=cp
+000132f0: 752c 2064 7479 7065 3d74 6f72 6368 2e62  u, dtype=torch.b
+00013300: 6f6f 6c2c 2069 735f 7368 6172 6564 3d46  ool, is_shared=F
+00013310: 616c 7365 292c 0d0a 2020 2020 2020 2020  alse),..        
+00013320: 2020 2020 2020 2020 6e65 7874 3a20 5465          next: Te
+00013330: 6e73 6f72 4469 6374 280d 0a20 2020 2020  nsorDict(..     
+00013340: 2020 2020 2020 2020 2020 2020 2020 2066                 f
+00013350: 6965 6c64 733d 7b0d 0a20 2020 2020 2020  ields={..       
+00013360: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013370: 206f 6273 6572 7661 7469 6f6e 3a20 5465   observation: Te
+00013380: 6e73 6f72 2873 6861 7065 3d74 6f72 6368  nsor(shape=torch
+00013390: 2e53 697a 6528 5b34 2c20 3530 2c20 335d  .Size([4, 50, 3]
+000133a0: 292c 2064 6576 6963 653d 6370 752c 2064  ), device=cpu, d
+000133b0: 7479 7065 3d74 6f72 6368 2e66 6c6f 6174  type=torch.float
+000133c0: 3332 2c20 6973 5f73 6861 7265 643d 4661  32, is_shared=Fa
+000133d0: 6c73 6529 7d2c 0d0a 2020 2020 2020 2020  lse)},..        
+000133e0: 2020 2020 2020 2020 2020 2020 6261 7463              batc
+000133f0: 685f 7369 7a65 3d74 6f72 6368 2e53 697a  h_size=torch.Siz
+00013400: 6528 5b34 2c20 3530 5d29 2c0d 0a20 2020  e([4, 50]),..   
+00013410: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013420: 2064 6576 6963 653d 6370 752c 0d0a 2020   device=cpu,..  
+00013430: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00013440: 2020 6973 5f73 6861 7265 643d 4661 6c73    is_shared=Fals
+00013450: 6529 2c0d 0a20 2020 2020 2020 2020 2020  e),..           
+00013460: 2020 2020 206f 6273 6572 7661 7469 6f6e       observation
+00013470: 3a20 5465 6e73 6f72 2873 6861 7065 3d74  : Tensor(shape=t
+00013480: 6f72 6368 2e53 697a 6528 5b34 2c20 3530  orch.Size([4, 50
+00013490: 2c20 335d 292c 2064 6576 6963 653d 6370  , 3]), device=cp
+000134a0: 752c 2064 7479 7065 3d74 6f72 6368 2e66  u, dtype=torch.f
+000134b0: 6c6f 6174 3332 2c20 6973 5f73 6861 7265  loat32, is_share
+000134c0: 643d 4661 6c73 6529 2c0d 0a20 2020 2020  d=False),..     
+000134d0: 2020 2020 2020 2020 2020 2072 6577 6172             rewar
+000134e0: 643a 2054 656e 736f 7228 7368 6170 653d  d: Tensor(shape=
+000134f0: 746f 7263 682e 5369 7a65 285b 342c 2035  torch.Size([4, 5
+00013500: 302c 2031 5d29 2c20 6465 7669 6365 3d63  0, 1]), device=c
+00013510: 7075 2c20 6474 7970 653d 746f 7263 682e  pu, dtype=torch.
+00013520: 666c 6f61 7433 322c 2069 735f 7368 6172  float32, is_shar
+00013530: 6564 3d46 616c 7365 297d 2c0d 0a20 2020  ed=False)},..   
+00013540: 2020 2020 2020 2020 2062 6174 6368 5f73           batch_s
+00013550: 697a 653d 746f 7263 682e 5369 7a65 285b  ize=torch.Size([
+00013560: 342c 2035 305d 292c 0d0a 2020 2020 2020  4, 50]),..      
+00013570: 2020 2020 2020 6465 7669 6365 3d63 7075        device=cpu
+00013580: 2c0d 0a20 2020 2020 2020 2020 2020 2069  ,..            i
+00013590: 735f 7368 6172 6564 3d46 616c 7365 290d  s_shared=False).
+000135a0: 0a20 2020 2020 2020 203e 3e3e 2063 6f6c  .        >>> col
+000135b0: 6c65 6374 6f72 2e73 6875 7464 6f77 6e28  lector.shutdown(
+000135c0: 290d 0a20 2020 2020 2020 203e 3e3e 2064  )..        >>> d
+000135d0: 656c 2063 6f6c 6c65 6374 6f72 0d0a 0d0a  el collector....
+000135e0: 2020 2020 2222 220d 0a0d 0a20 2020 205f      """....    _
+000135f0: 5f64 6f63 5f5f 202b 3d20 5f4d 756c 7469  _doc__ += _Multi
+00013600: 4461 7461 436f 6c6c 6563 746f 722e 5f5f  DataCollector.__
+00013610: 646f 635f 5f0d 0a0d 0a20 2020 2064 6566  doc__....    def
+00013620: 205f 5f69 6e69 745f 5f28 7365 6c66 2c20   __init__(self, 
+00013630: 2a61 7267 732c 202a 2a6b 7761 7267 7329  *args, **kwargs)
+00013640: 3a0d 0a20 2020 2020 2020 2073 7570 6572  :..        super
+00013650: 2829 2e5f 5f69 6e69 745f 5f28 2a61 7267  ().__init__(*arg
+00013660: 732c 202a 2a6b 7761 7267 7329 0d0a 2020  s, **kwargs)..  
+00013670: 2020 2020 2020 7365 6c66 2e6f 7574 5f74        self.out_t
+00013680: 656e 736f 7264 6963 7473 203d 207b 7d0d  ensordicts = {}.
+00013690: 0a20 2020 2020 2020 2073 656c 662e 7275  .        self.ru
+000136a0: 6e6e 696e 6720 3d20 4661 6c73 650d 0a0d  nning = False...
+000136b0: 0a20 2020 2020 2020 2069 6620 7365 6c66  .        if self
+000136c0: 2e70 6f73 7470 726f 6373 2069 7320 6e6f  .postprocs is no
+000136d0: 7420 4e6f 6e65 3a0d 0a20 2020 2020 2020  t None:..       
+000136e0: 2020 2020 2070 6f73 7470 726f 6320 3d20       postproc = 
+000136f0: 7365 6c66 2e70 6f73 7470 726f 6373 0d0a  self.postprocs..
+00013700: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+00013710: 2e70 6f73 7470 726f 6373 203d 207b 7d0d  .postprocs = {}.
+00013720: 0a20 2020 2020 2020 2020 2020 2066 6f72  .            for
+00013730: 205f 6465 7669 6365 2069 6e20 7365 6c66   _device in self
+00013740: 2e73 746f 7269 6e67 5f64 6576 6963 653a  .storing_device:
+00013750: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00013760: 2020 6966 205f 6465 7669 6365 206e 6f74    if _device not
+00013770: 2069 6e20 7365 6c66 2e70 6f73 7470 726f   in self.postpro
+00013780: 6373 3a0d 0a20 2020 2020 2020 2020 2020  cs:..           
+00013790: 2020 2020 2020 2020 2073 656c 662e 706f           self.po
+000137a0: 7374 7072 6f63 735b 5f64 6576 6963 655d  stprocs[_device]
+000137b0: 203d 2064 6565 7063 6f70 7928 706f 7374   = deepcopy(post
+000137c0: 7072 6f63 292e 746f 285f 6465 7669 6365  proc).to(_device
+000137d0: 290d 0a0d 0a20 2020 2023 2066 6f72 2052  )....    # for R
+000137e0: 5043 0d0a 2020 2020 6465 6620 6e65 7874  PC..    def next
+000137f0: 2873 656c 6629 3a0d 0a20 2020 2020 2020  (self):..       
+00013800: 2072 6574 7572 6e20 7375 7065 7228 292e   return super().
+00013810: 6e65 7874 2829 0d0a 0d0a 2020 2020 2320  next()....    # 
+00013820: 666f 7220 5250 430d 0a20 2020 2064 6566  for RPC..    def
+00013830: 2073 6875 7464 6f77 6e28 7365 6c66 293a   shutdown(self):
+00013840: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
+00013850: 2073 7570 6572 2829 2e73 6875 7464 6f77   super().shutdow
+00013860: 6e28 290d 0a0d 0a20 2020 2023 2066 6f72  n()....    # for
+00013870: 2052 5043 0d0a 2020 2020 6465 6620 7365   RPC..    def se
+00013880: 745f 7365 6564 2873 656c 662c 2073 6565  t_seed(self, see
+00013890: 643a 2069 6e74 2c20 7374 6174 6963 5f73  d: int, static_s
+000138a0: 6565 643a 2062 6f6f 6c20 3d20 4661 6c73  eed: bool = Fals
+000138b0: 6529 202d 3e20 696e 743a 0d0a 2020 2020  e) -> int:..    
+000138c0: 2020 2020 7265 7475 726e 2073 7570 6572      return super
+000138d0: 2829 2e73 6574 5f73 6565 6428 7365 6564  ().set_seed(seed
+000138e0: 2c20 7374 6174 6963 5f73 6565 6429 0d0a  , static_seed)..
+000138f0: 0d0a 2020 2020 2320 666f 7220 5250 430d  ..    # for RPC.
+00013900: 0a20 2020 2064 6566 2073 7461 7465 5f64  .    def state_d
+00013910: 6963 7428 7365 6c66 2920 2d3e 204f 7264  ict(self) -> Ord
+00013920: 6572 6564 4469 6374 3a0d 0a20 2020 2020  eredDict:..     
+00013930: 2020 2072 6574 7572 6e20 7375 7065 7228     return super(
+00013940: 292e 7374 6174 655f 6469 6374 2829 0d0a  ).state_dict()..
+00013950: 0d0a 2020 2020 2320 666f 7220 5250 430d  ..    # for RPC.
+00013960: 0a20 2020 2064 6566 206c 6f61 645f 7374  .    def load_st
+00013970: 6174 655f 6469 6374 2873 656c 662c 2073  ate_dict(self, s
+00013980: 7461 7465 5f64 6963 743a 204f 7264 6572  tate_dict: Order
+00013990: 6564 4469 6374 2920 2d3e 204e 6f6e 653a  edDict) -> None:
+000139a0: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
+000139b0: 2073 7570 6572 2829 2e6c 6f61 645f 7374   super().load_st
+000139c0: 6174 655f 6469 6374 2873 7461 7465 5f64  ate_dict(state_d
+000139d0: 6963 7429 0d0a 0d0a 2020 2020 2320 666f  ict)....    # fo
+000139e0: 7220 5250 430d 0a20 2020 2064 6566 2075  r RPC..    def u
+000139f0: 7064 6174 655f 706f 6c69 6379 5f77 6569  pdate_policy_wei
+00013a00: 6768 7473 5f28 0d0a 2020 2020 2020 2020  ghts_(..        
+00013a10: 7365 6c66 2c20 706f 6c69 6379 5f77 6569  self, policy_wei
+00013a20: 6768 7473 3a20 4f70 7469 6f6e 616c 5b54  ghts: Optional[T
+00013a30: 656e 736f 7244 6963 7442 6173 655d 203d  ensorDictBase] =
+00013a40: 204e 6f6e 650d 0a20 2020 2029 202d 3e20   None..    ) -> 
+00013a50: 4e6f 6e65 3a0d 0a20 2020 2020 2020 2073  None:..        s
+00013a60: 7570 6572 2829 2e75 7064 6174 655f 706f  uper().update_po
+00013a70: 6c69 6379 5f77 6569 6768 7473 5f28 706f  licy_weights_(po
+00013a80: 6c69 6379 5f77 6569 6768 7473 290d 0a0d  licy_weights)...
+00013a90: 0a20 2020 2040 7072 6f70 6572 7479 0d0a  .    @property..
+00013aa0: 2020 2020 6465 6620 6672 616d 6573 5f70      def frames_p
+00013ab0: 6572 5f62 6174 6368 5f77 6f72 6b65 7228  er_batch_worker(
+00013ac0: 7365 6c66 293a 0d0a 2020 2020 2020 2020  self):..        
+00013ad0: 7265 7475 726e 2073 656c 662e 7265 7175  return self.requ
+00013ae0: 6573 7465 645f 6672 616d 6573 5f70 6572  ested_frames_per
+00013af0: 5f62 6174 6368 0d0a 0d0a 2020 2020 6465  _batch....    de
+00013b00: 6620 5f67 6574 5f66 726f 6d5f 7175 6575  f _get_from_queu
+00013b10: 6528 7365 6c66 2c20 7469 6d65 6f75 743d  e(self, timeout=
+00013b20: 4e6f 6e65 2920 2d3e 2054 7570 6c65 5b69  None) -> Tuple[i
+00013b30: 6e74 2c20 696e 742c 2054 656e 736f 7244  nt, int, TensorD
+00013b40: 6963 7442 6173 655d 3a0d 0a20 2020 2020  ictBase]:..     
+00013b50: 2020 206e 6577 5f64 6174 612c 206a 203d     new_data, j =
+00013b60: 2073 656c 662e 7175 6575 655f 6f75 742e   self.queue_out.
+00013b70: 6765 7428 7469 6d65 6f75 743d 7469 6d65  get(timeout=time
+00013b80: 6f75 7429 0d0a 2020 2020 2020 2020 6966  out)..        if
+00013b90: 206a 203d 3d20 303a 0d0a 2020 2020 2020   j == 0:..      
+00013ba0: 2020 2020 2020 6461 7461 2c20 6964 7820        data, idx 
+00013bb0: 3d20 6e65 775f 6461 7461 0d0a 2020 2020  = new_data..    
+00013bc0: 2020 2020 2020 2020 7365 6c66 2e6f 7574          self.out
+00013bd0: 5f74 656e 736f 7264 6963 7473 5b69 6478  _tensordicts[idx
+00013be0: 5d20 3d20 6461 7461 0d0a 2020 2020 2020  ] = data..      
+00013bf0: 2020 656c 7365 3a0d 0a20 2020 2020 2020    else:..       
+00013c00: 2020 2020 2069 6478 203d 206e 6577 5f64       idx = new_d
+00013c10: 6174 610d 0a20 2020 2020 2020 2023 2077  ata..        # w
+00013c20: 6520 636c 6f6e 6520 7468 6520 6461 7461  e clone the data
+00013c30: 2074 6f20 6d61 6b65 2073 7572 6520 7468   to make sure th
+00013c40: 6174 2077 6527 6c6c 2062 6520 776f 726b  at we'll be work
+00013c50: 696e 6720 7769 7468 2061 2066 6978 6564  ing with a fixed
+00013c60: 2063 6f70 790d 0a20 2020 2020 2020 206f   copy..        o
+00013c70: 7574 203d 2073 656c 662e 6f75 745f 7465  ut = self.out_te
+00013c80: 6e73 6f72 6469 6374 735b 6964 785d 2e63  nsordicts[idx].c
+00013c90: 6c6f 6e65 2829 0d0a 2020 2020 2020 2020  lone()..        
+00013ca0: 7265 7475 726e 2069 6478 2c20 6a2c 206f  return idx, j, o
+00013cb0: 7574 0d0a 0d0a 2020 2020 4070 726f 7065  ut....    @prope
+00013cc0: 7274 790d 0a20 2020 2064 6566 205f 7175  rty..    def _qu
+00013cd0: 6575 655f 6c65 6e28 7365 6c66 2920 2d3e  eue_len(self) ->
+00013ce0: 2069 6e74 3a0d 0a20 2020 2020 2020 2072   int:..        r
+00013cf0: 6574 7572 6e20 310d 0a0d 0a20 2020 2064  eturn 1....    d
+00013d00: 6566 2069 7465 7261 746f 7228 7365 6c66  ef iterator(self
+00013d10: 2920 2d3e 2049 7465 7261 746f 725b 5465  ) -> Iterator[Te
+00013d20: 6e73 6f72 4469 6374 4261 7365 5d3a 0d0a  nsorDictBase]:..
+00013d30: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
+00013d40: 7570 6461 7465 5f61 745f 6561 6368 5f62  update_at_each_b
+00013d50: 6174 6368 3a0d 0a20 2020 2020 2020 2020  atch:..         
+00013d60: 2020 2073 656c 662e 7570 6461 7465 5f70     self.update_p
+00013d70: 6f6c 6963 795f 7765 6967 6874 735f 2829  olicy_weights_()
+00013d80: 0d0a 0d0a 2020 2020 2020 2020 666f 7220  ....        for 
+00013d90: 6920 696e 2072 616e 6765 2873 656c 662e  i in range(self.
+00013da0: 6e75 6d5f 776f 726b 6572 7329 3a0d 0a20  num_workers):.. 
+00013db0: 2020 2020 2020 2020 2020 2069 6620 7365             if se
+00013dc0: 6c66 2e69 6e69 745f 7261 6e64 6f6d 5f66  lf.init_random_f
+00013dd0: 7261 6d65 7320 3e20 303a 0d0a 2020 2020  rames > 0:..    
+00013de0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+00013df0: 2e70 6970 6573 5b69 5d2e 7365 6e64 2828  .pipes[i].send((
+00013e00: 4e6f 6e65 2c20 2263 6f6e 7469 6e75 655f  None, "continue_
+00013e10: 7261 6e64 6f6d 2229 290d 0a20 2020 2020  random"))..     
+00013e20: 2020 2020 2020 2065 6c73 653a 0d0a 2020         else:..  
+00013e30: 2020 2020 2020 2020 2020 2020 2020 7365                se
+00013e40: 6c66 2e70 6970 6573 5b69 5d2e 7365 6e64  lf.pipes[i].send
+00013e50: 2828 4e6f 6e65 2c20 2263 6f6e 7469 6e75  ((None, "continu
+00013e60: 6522 2929 0d0a 2020 2020 2020 2020 7365  e"))..        se
+00013e70: 6c66 2e72 756e 6e69 6e67 203d 2054 7275  lf.running = Tru
+00013e80: 650d 0a20 2020 2020 2020 2069 203d 202d  e..        i = -
+00013e90: 310d 0a20 2020 2020 2020 2073 656c 662e  1..        self.
+00013ea0: 5f66 7261 6d65 7320 3d20 300d 0a0d 0a20  _frames = 0.... 
+00013eb0: 2020 2020 2020 2077 6f72 6b65 7273 5f66         workers_f
+00013ec0: 7261 6d65 7320 3d20 5b30 2066 6f72 205f  rames = [0 for _
+00013ed0: 2069 6e20 7261 6e67 6528 7365 6c66 2e6e   in range(self.n
+00013ee0: 756d 5f77 6f72 6b65 7273 295d 0d0a 2020  um_workers)]..  
+00013ef0: 2020 2020 2020 7768 696c 6520 7365 6c66        while self
+00013f00: 2e5f 6672 616d 6573 203c 2073 656c 662e  ._frames < self.
+00013f10: 746f 7461 6c5f 6672 616d 6573 3a0d 0a20  total_frames:.. 
+00013f20: 2020 2020 2020 2020 2020 205f 6368 6563             _chec
+00013f30: 6b5f 666f 725f 6661 756c 7479 5f70 726f  k_for_faulty_pro
+00013f40: 6365 7373 2873 656c 662e 7072 6f63 7329  cess(self.procs)
+00013f50: 0d0a 2020 2020 2020 2020 2020 2020 6920  ..            i 
+00013f60: 2b3d 2031 0d0a 2020 2020 2020 2020 2020  += 1..          
+00013f70: 2020 6964 782c 206a 2c20 6f75 7420 3d20    idx, j, out = 
+00013f80: 7365 6c66 2e5f 6765 745f 6672 6f6d 5f71  self._get_from_q
+00013f90: 7565 7565 2829 0d0a 0d0a 2020 2020 2020  ueue()....      
+00013fa0: 2020 2020 2020 776f 726b 6572 5f66 7261        worker_fra
+00013fb0: 6d65 7320 3d20 6f75 742e 6e75 6d65 6c28  mes = out.numel(
+00013fc0: 290d 0a20 2020 2020 2020 2020 2020 2069  )..            i
+00013fd0: 6620 7365 6c66 2e73 706c 6974 5f74 7261  f self.split_tra
+00013fe0: 6a73 3a0d 0a20 2020 2020 2020 2020 2020  js:..           
+00013ff0: 2020 2020 206f 7574 203d 2073 706c 6974       out = split
+00014000: 5f74 7261 6a65 6374 6f72 6965 7328 6f75  _trajectories(ou
+00014010: 742c 2070 7265 6669 783d 2263 6f6c 6c65  t, prefix="colle
+00014020: 6374 6f72 2229 0d0a 2020 2020 2020 2020  ctor")..        
+00014030: 2020 2020 7365 6c66 2e5f 6672 616d 6573      self._frames
+00014040: 202b 3d20 776f 726b 6572 5f66 7261 6d65   += worker_frame
+00014050: 730d 0a20 2020 2020 2020 2020 2020 2077  s..            w
+00014060: 6f72 6b65 7273 5f66 7261 6d65 735b 6964  orkers_frames[id
+00014070: 785d 203d 2077 6f72 6b65 7273 5f66 7261  x] = workers_fra
+00014080: 6d65 735b 6964 785d 202b 2077 6f72 6b65  mes[idx] + worke
+00014090: 725f 6672 616d 6573 0d0a 2020 2020 2020  r_frames..      
+000140a0: 2020 2020 2020 6966 2073 656c 662e 706f        if self.po
+000140b0: 7374 7072 6f63 733a 0d0a 2020 2020 2020  stprocs:..      
+000140c0: 2020 2020 2020 2020 2020 6f75 7420 3d20            out = 
+000140d0: 7365 6c66 2e70 6f73 7470 726f 6373 5b6f  self.postprocs[o
+000140e0: 7574 2e64 6576 6963 655d 286f 7574 290d  ut.device](out).
+000140f0: 0a0d 0a20 2020 2020 2020 2020 2020 2023  ...            #
+00014100: 2074 6865 2066 756e 6374 696f 6e20 626c   the function bl
+00014110: 6f63 6b73 2068 6572 6520 756e 7469 6c20  ocks here until 
+00014120: 7468 6520 6e65 7874 2069 7465 6d20 6973  the next item is
+00014130: 2061 736b 6564 2c20 6865 6e63 6520 7765   asked, hence we
+00014140: 2073 656e 6420 7468 6520 6d65 7373 6167   send the messag
+00014150: 6520 746f 2074 6865 0d0a 2020 2020 2020  e to the..      
+00014160: 2020 2020 2020 2320 776f 726b 6572 2074        # worker t
+00014170: 6f20 6b65 6570 206f 6e20 776f 726b 696e  o keep on workin
+00014180: 6720 696e 2074 6865 206d 6561 6e74 696d  g in the meantim
+00014190: 6520 6265 666f 7265 2074 6865 2079 6965  e before the yie
+000141a0: 6c64 2073 7461 7465 6d65 6e74 0d0a 2020  ld statement..  
+000141b0: 2020 2020 2020 2020 2020 6966 2073 656c            if sel
+000141c0: 662e 5f66 7261 6d65 7320 3c20 7365 6c66  f._frames < self
+000141d0: 2e69 6e69 745f 7261 6e64 6f6d 5f66 7261  .init_random_fra
+000141e0: 6d65 733a 0d0a 2020 2020 2020 2020 2020  mes:..          
+000141f0: 2020 2020 2020 6d73 6720 3d20 2263 6f6e        msg = "con
+00014200: 7469 6e75 655f 7261 6e64 6f6d 220d 0a20  tinue_random".. 
+00014210: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
+00014220: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00014230: 2020 6d73 6720 3d20 2263 6f6e 7469 6e75    msg = "continu
+00014240: 6522 0d0a 2020 2020 2020 2020 2020 2020  e"..            
+00014250: 7365 6c66 2e70 6970 6573 5b69 6478 5d2e  self.pipes[idx].
+00014260: 7365 6e64 2828 6964 782c 206d 7367 2929  send((idx, msg))
+00014270: 0d0a 2020 2020 2020 2020 2020 2020 6966  ..            if
+00014280: 2073 656c 662e 5f65 7863 6c75 6465 5f70   self._exclude_p
+00014290: 7269 7661 7465 5f6b 6579 733a 0d0a 2020  rivate_keys:..  
+000142a0: 2020 2020 2020 2020 2020 2020 2020 6578                ex
+000142b0: 636c 7564 6564 5f6b 6579 7320 3d20 5b6b  cluded_keys = [k
+000142c0: 6579 2066 6f72 206b 6579 2069 6e20 6f75  ey for key in ou
+000142d0: 742e 6b65 7973 2829 2069 6620 6b65 792e  t.keys() if key.
+000142e0: 7374 6172 7473 7769 7468 2822 5f22 295d  startswith("_")]
+000142f0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00014300: 2020 6f75 7420 3d20 6f75 742e 6578 636c    out = out.excl
+00014310: 7564 6528 2a65 7863 6c75 6465 645f 6b65  ude(*excluded_ke
+00014320: 7973 290d 0a20 2020 2020 2020 2020 2020  ys)..           
+00014330: 2079 6965 6c64 206f 7574 0d0a 0d0a 2020   yield out....  
+00014340: 2020 2020 2020 2320 5765 2064 6f6e 2774        # We don't
+00014350: 2077 616e 7420 746f 2073 6875 7464 6f77   want to shutdow
+00014360: 6e20 7965 742c 2074 6865 2075 7365 7220  n yet, the user 
+00014370: 6d61 7920 7761 6e74 2074 6f20 6361 6c6c  may want to call
+00014380: 2073 7461 7465 5f64 6963 7420 6265 666f   state_dict befo
+00014390: 7265 0d0a 2020 2020 2020 2020 2320 7365  re..        # se
+000143a0: 6c66 2e5f 7368 7574 646f 776e 5f6d 6169  lf._shutdown_mai
+000143b0: 6e28 290d 0a20 2020 2020 2020 2073 656c  n()..        sel
+000143c0: 662e 7275 6e6e 696e 6720 3d20 4661 6c73  f.running = Fals
+000143d0: 650d 0a0d 0a20 2020 2064 6566 205f 7368  e....    def _sh
+000143e0: 7574 646f 776e 5f6d 6169 6e28 7365 6c66  utdown_main(self
+000143f0: 2920 2d3e 204e 6f6e 653a 0d0a 2020 2020  ) -> None:..    
+00014400: 2020 2020 6966 2068 6173 6174 7472 2873      if hasattr(s
+00014410: 656c 662c 2022 6f75 745f 7465 6e73 6f72  elf, "out_tensor
+00014420: 6469 6374 7322 293a 0d0a 2020 2020 2020  dicts"):..      
+00014430: 2020 2020 2020 6465 6c20 7365 6c66 2e6f        del self.o
+00014440: 7574 5f74 656e 736f 7264 6963 7473 0d0a  ut_tensordicts..
+00014450: 2020 2020 2020 2020 7265 7475 726e 2073          return s
+00014460: 7570 6572 2829 2e5f 7368 7574 646f 776e  uper()._shutdown
+00014470: 5f6d 6169 6e28 290d 0a0d 0a20 2020 2064  _main()....    d
+00014480: 6566 2072 6573 6574 2873 656c 662c 2072  ef reset(self, r
+00014490: 6573 6574 5f69 6478 3a20 4f70 7469 6f6e  eset_idx: Option
+000144a0: 616c 5b53 6571 7565 6e63 655b 626f 6f6c  al[Sequence[bool
+000144b0: 5d5d 203d 204e 6f6e 6529 202d 3e20 4e6f  ]] = None) -> No
+000144c0: 6e65 3a0d 0a20 2020 2020 2020 2073 7570  ne:..        sup
+000144d0: 6572 2829 2e72 6573 6574 2872 6573 6574  er().reset(reset
+000144e0: 5f69 6478 290d 0a20 2020 2020 2020 2069  _idx)..        i
+000144f0: 6620 7365 6c66 2e71 7565 7565 5f6f 7574  f self.queue_out
+00014500: 2e66 756c 6c28 293a 0d0a 2020 2020 2020  .full():..      
+00014510: 2020 2020 2020 7469 6d65 2e73 6c65 6570        time.sleep
+00014520: 285f 5449 4d45 4f55 5429 2020 2320 7761  (_TIMEOUT)  # wa
+00014530: 6974 2075 6e74 696c 2071 7565 7565 2069  it until queue i
+00014540: 7320 656d 7074 790d 0a20 2020 2020 2020  s empty..       
+00014550: 2069 6620 7365 6c66 2e71 7565 7565 5f6f   if self.queue_o
+00014560: 7574 2e66 756c 6c28 293a 0d0a 2020 2020  ut.full():..    
+00014570: 2020 2020 2020 2020 7261 6973 6520 4578          raise Ex
+00014580: 6365 7074 696f 6e28 2273 656c 662e 7175  ception("self.qu
+00014590: 6575 655f 6f75 7420 6973 2066 756c 6c22  eue_out is full"
+000145a0: 290d 0a20 2020 2020 2020 2069 6620 7365  )..        if se
+000145b0: 6c66 2e72 756e 6e69 6e67 3a0d 0a20 2020  lf.running:..   
+000145c0: 2020 2020 2020 2020 2066 6f72 2069 6478           for idx
+000145d0: 2069 6e20 7261 6e67 6528 7365 6c66 2e6e   in range(self.n
+000145e0: 756d 5f77 6f72 6b65 7273 293a 0d0a 2020  um_workers):..  
+000145f0: 2020 2020 2020 2020 2020 2020 2020 6966                if
+00014600: 2073 656c 662e 5f66 7261 6d65 7320 3c20   self._frames < 
+00014610: 7365 6c66 2e69 6e69 745f 7261 6e64 6f6d  self.init_random
+00014620: 5f66 7261 6d65 733a 0d0a 2020 2020 2020  _frames:..      
+00014630: 2020 2020 2020 2020 2020 2020 2020 7365                se
+00014640: 6c66 2e70 6970 6573 5b69 6478 5d2e 7365  lf.pipes[idx].se
+00014650: 6e64 2828 6964 782c 2022 636f 6e74 696e  nd((idx, "contin
+00014660: 7565 5f72 616e 646f 6d22 2929 0d0a 2020  ue_random"))..  
+00014670: 2020 2020 2020 2020 2020 2020 2020 656c                el
+00014680: 7365 3a0d 0a20 2020 2020 2020 2020 2020  se:..           
+00014690: 2020 2020 2020 2020 2073 656c 662e 7069           self.pi
+000146a0: 7065 735b 6964 785d 2e73 656e 6428 2869  pes[idx].send((i
+000146b0: 6478 2c20 2263 6f6e 7469 6e75 6522 2929  dx, "continue"))
+000146c0: 0d0a 0d0a 0d0a 4061 6363 6570 745f 7265  ......@accept_re
+000146d0: 6d6f 7465 5f72 7265 665f 7564 665f 696e  mote_rref_udf_in
+000146e0: 766f 6361 7469 6f6e 0d0a 636c 6173 7320  vocation..class 
+000146f0: 6153 796e 6344 6174 6143 6f6c 6c65 6374  aSyncDataCollect
+00014700: 6f72 284d 756c 7469 6153 796e 6344 6174  or(MultiaSyncDat
+00014710: 6143 6f6c 6c65 6374 6f72 293a 0d0a 2020  aCollector):..  
+00014720: 2020 2222 2252 756e 7320 6120 7369 6e67    """Runs a sing
+00014730: 6c65 2044 6174 6143 6f6c 6c65 6374 6f72  le DataCollector
+00014740: 206f 6e20 6120 7365 7061 7261 7465 2070   on a separate p
+00014750: 726f 6365 7373 2e0d 0a0d 0a20 2020 2054  rocess.....    T
+00014760: 6869 7320 6973 206d 6f73 746c 7920 7573  his is mostly us
+00014770: 6566 756c 2066 6f72 206f 6666 6c69 6e65  eful for offline
+00014780: 2052 4c20 7061 7261 6469 676d 7320 7768   RL paradigms wh
+00014790: 6572 6520 7468 6520 706f 6c69 6379 2062  ere the policy b
+000147a0: 6569 6e67 0d0a 2020 2020 7472 6169 6e65  eing..    traine
+000147b0: 6420 6361 6e20 6469 6666 6572 2066 726f  d can differ fro
+000147c0: 6d20 7468 6520 706f 6c69 6379 2075 7365  m the policy use
+000147d0: 6420 746f 2063 6f6c 6c65 6374 2064 6174  d to collect dat
+000147e0: 612e 2049 6e20 6f6e 6c69 6e65 0d0a 2020  a. In online..  
+000147f0: 2020 7365 7474 696e 6773 2c20 6120 7265    settings, a re
+00014800: 6775 6c61 7220 4461 7461 436f 6c6c 6563  gular DataCollec
+00014810: 746f 7220 7368 6f75 6c64 2062 6520 7072  tor should be pr
+00014820: 6566 6572 7265 642e 2054 6869 7320 636c  eferred. This cl
+00014830: 6173 7320 6973 0d0a 2020 2020 6d65 7265  ass is..    mere
+00014840: 6c79 2061 2077 7261 7070 6572 2061 726f  ly a wrapper aro
+00014850: 756e 6420 6120 4d75 6c74 6961 5379 6e63  und a MultiaSync
+00014860: 4461 7461 436f 6c6c 6563 746f 7220 7768  DataCollector wh
+00014870: 6572 6520 6120 7369 6e67 6c65 2070 726f  ere a single pro
+00014880: 6365 7373 0d0a 2020 2020 6973 2062 6569  cess..    is bei
+00014890: 6e67 2063 7265 6174 6564 2e0d 0a0d 0a20  ng created..... 
+000148a0: 2020 2041 7267 733a 0d0a 2020 2020 2020     Args:..      
+000148b0: 2020 6372 6561 7465 5f65 6e76 5f66 6e20    create_env_fn 
+000148c0: 2843 616c 6c61 626c 6564 293a 2043 616c  (Callabled): Cal
+000148d0: 6c61 626c 6520 7265 7475 726e 696e 6720  lable returning 
+000148e0: 616e 2069 6e73 7461 6e63 6520 6f66 2045  an instance of E
+000148f0: 6e76 4261 7365 0d0a 2020 2020 2020 2020  nvBase..        
+00014900: 706f 6c69 6379 2028 4361 6c6c 6162 6c65  policy (Callable
+00014910: 2c20 6f70 7469 6f6e 616c 293a 2049 6e73  , optional): Ins
+00014920: 7461 6e63 6520 6f66 2054 656e 736f 7244  tance of TensorD
+00014930: 6963 744d 6f64 756c 6520 636c 6173 732e  ictModule class.
+00014940: 0d0a 2020 2020 2020 2020 2020 2020 4d75  ..            Mu
+00014950: 7374 2061 6363 6570 7420 5465 6e73 6f72  st accept Tensor
+00014960: 4469 6374 4261 7365 206f 626a 6563 7420  DictBase object 
+00014970: 6173 2069 6e70 7574 2e0d 0a20 2020 2020  as input...     
+00014980: 2020 2074 6f74 616c 5f66 7261 6d65 7320     total_frames 
+00014990: 2869 6e74 293a 206c 6f77 6572 2062 6f75  (int): lower bou
+000149a0: 6e64 206f 6620 7468 6520 746f 7461 6c20  nd of the total 
+000149b0: 6e75 6d62 6572 206f 6620 6672 616d 6573  number of frames
+000149c0: 2072 6574 7572 6e65 640d 0a20 2020 2020   returned..     
+000149d0: 2020 2020 2020 2062 7920 7468 6520 636f         by the co
+000149e0: 6c6c 6563 746f 722e 2049 6e20 7061 7261  llector. In para
+000149f0: 6c6c 656c 2073 6574 7469 6e67 732c 2074  llel settings, t
+00014a00: 6865 2061 6374 7561 6c20 6e75 6d62 6572  he actual number
+00014a10: 206f 660d 0a20 2020 2020 2020 2020 2020   of..           
+00014a20: 2066 7261 6d65 7320 6d61 7920 7765 6c6c   frames may well
+00014a30: 2062 6520 6772 6561 7465 7220 7468 616e   be greater than
+00014a40: 2074 6869 7320 6173 2074 6865 2063 6c6f   this as the clo
+00014a50: 7369 6e67 2073 6967 6e61 6c73 2061 7265  sing signals are
+00014a60: 0d0a 2020 2020 2020 2020 2020 2020 7365  ..            se
+00014a70: 6e74 2074 6f20 7468 6520 776f 726b 6572  nt to the worker
+00014a80: 7320 6f6e 6c79 206f 6e63 6520 7468 6520  s only once the 
+00014a90: 746f 7461 6c20 6e75 6d62 6572 206f 6620  total number of 
+00014aa0: 6672 616d 6573 2068 6173 0d0a 2020 2020  frames has..    
+00014ab0: 2020 2020 2020 2020 6265 656e 2063 6f6c          been col
+00014ac0: 6c65 6374 6564 206f 6e20 7468 6520 7365  lected on the se
+00014ad0: 7276 6572 2e0d 0a20 2020 2020 2020 2063  rver...        c
+00014ae0: 7265 6174 655f 656e 765f 6b77 6172 6773  reate_env_kwargs
+00014af0: 2028 6469 6374 2c20 6f70 7469 6f6e 616c   (dict, optional
+00014b00: 293a 2041 2064 6963 7469 6f6e 6172 7920  ): A dictionary 
+00014b10: 7769 7468 2074 6865 2061 7267 756d 656e  with the argumen
+00014b20: 7473 0d0a 2020 2020 2020 2020 2020 2020  ts..            
+00014b30: 7573 6564 2074 6f20 6372 6561 7465 2061  used to create a
+00014b40: 6e20 656e 7669 726f 6e6d 656e 740d 0a20  n environment.. 
+00014b50: 2020 2020 2020 206d 6178 5f66 7261 6d65         max_frame
+00014b60: 735f 7065 725f 7472 616a 3a20 4d61 7869  s_per_traj: Maxi
+00014b70: 6d75 6d20 7374 6570 7320 7065 7220 7472  mum steps per tr
+00014b80: 616a 6563 746f 7279 2e20 4e6f 7465 2074  ajectory. Note t
+00014b90: 6861 7420 610d 0a20 2020 2020 2020 2020  hat a..         
+00014ba0: 2020 2074 7261 6a65 6374 6f72 7920 6361     trajectory ca
+00014bb0: 6e20 7370 616e 206f 7665 7220 6d75 6c74  n span over mult
+00014bc0: 6970 6c65 2062 6174 6368 6573 2028 756e  iple batches (un
+00014bd0: 6c65 7373 0d0a 2020 2020 2020 2020 2020  less..          
+00014be0: 2020 7265 7365 745f 6174 5f65 6163 685f    reset_at_each_
+00014bf0: 6974 6572 2069 7320 7365 7420 746f 2054  iter is set to T
+00014c00: 7275 652c 2073 6565 2062 656c 6f77 292e  rue, see below).
+00014c10: 204f 6e63 6520 6120 7472 616a 6563 746f   Once a trajecto
+00014c20: 7279 0d0a 2020 2020 2020 2020 2020 2020  ry..            
+00014c30: 7265 6163 6865 7320 6e5f 7374 6570 732c  reaches n_steps,
+00014c40: 2074 6865 2065 6e76 6972 6f6e 6d65 6e74   the environment
+00014c50: 2069 7320 7265 7365 742e 2049 6620 7468   is reset. If th
+00014c60: 650d 0a20 2020 2020 2020 2020 2020 2065  e..            e
+00014c70: 6e76 6972 6f6e 6d65 6e74 2077 7261 7073  nvironment wraps
+00014c80: 206d 756c 7469 706c 6520 656e 7669 726f   multiple enviro
+00014c90: 6e6d 656e 7473 2074 6f67 6574 6865 722c  nments together,
+00014ca0: 2074 6865 206e 756d 6265 7220 6f66 0d0a   the number of..
+00014cb0: 2020 2020 2020 2020 2020 2020 7374 6570              step
+00014cc0: 7320 6973 2074 7261 636b 6564 2066 6f72  s is tracked for
+00014cd0: 2065 6163 6820 656e 7669 726f 6e6d 656e   each environmen
+00014ce0: 7420 696e 6465 7065 6e64 656e 746c 792e  t independently.
+00014cf0: 204e 6567 6174 6976 650d 0a20 2020 2020   Negative..     
+00014d00: 2020 2020 2020 2076 616c 7565 7320 6172         values ar
+00014d10: 6520 616c 6c6f 7765 642c 2069 6e20 7768  e allowed, in wh
+00014d20: 6963 6820 6361 7365 2074 6869 7320 6172  ich case this ar
+00014d30: 6775 6d65 6e74 2069 7320 6967 6e6f 7265  gument is ignore
+00014d40: 642e 0d0a 2020 2020 2020 2020 2020 2020  d...            
+00014d50: 4465 6661 756c 7420 6973 202d 3120 2869  Default is -1 (i
+00014d60: 2e65 2e20 6e6f 206d 6178 696d 756d 206e  .e. no maximum n
+00014d70: 756d 6265 7220 6f66 2073 7465 7073 290d  umber of steps).
+00014d80: 0a20 2020 2020 2020 2066 7261 6d65 735f  .        frames_
+00014d90: 7065 725f 6261 7463 6820 2869 6e74 293a  per_batch (int):
+00014da0: 2054 696d 652d 6c65 6e67 7468 206f 6620   Time-length of 
+00014db0: 6120 6261 7463 682e 0d0a 2020 2020 2020  a batch...      
+00014dc0: 2020 2020 2020 7265 7365 745f 6174 5f65        reset_at_e
+00014dd0: 6163 685f 6974 6572 2061 6e64 2066 7261  ach_iter and fra
+00014de0: 6d65 735f 7065 725f 6261 7463 6820 3d3d  mes_per_batch ==
+00014df0: 206e 5f73 7465 7073 2061 7265 2065 7175   n_steps are equ
+00014e00: 6976 616c 656e 7420 636f 6e66 6967 7572  ivalent configur
+00014e10: 6174 696f 6e73 2e0d 0a20 2020 2020 2020  ations...       
+00014e20: 2020 2020 2064 6566 6175 6c74 3a20 3230       default: 20
+00014e30: 300d 0a20 2020 2020 2020 2069 6e69 745f  0..        init_
+00014e40: 7261 6e64 6f6d 5f66 7261 6d65 7320 2869  random_frames (i
+00014e50: 6e74 293a 204e 756d 6265 7220 6f66 2066  nt): Number of f
+00014e60: 7261 6d65 7320 666f 7220 7768 6963 6820  rames for which 
+00014e70: 7468 6520 706f 6c69 6379 2069 7320 6967  the policy is ig
+00014e80: 6e6f 7265 6420 6265 666f 7265 2069 7420  nored before it 
+00014e90: 6973 2063 616c 6c65 642e 0d0a 2020 2020  is called...    
+00014ea0: 2020 2020 2020 2020 5468 6973 2066 6561          This fea
+00014eb0: 7475 7265 2069 7320 6d61 696e 6c79 2069  ture is mainly i
+00014ec0: 6e74 656e 6465 6420 746f 2062 6520 7573  ntended to be us
+00014ed0: 6564 2069 6e20 6f66 666c 696e 652f 6d6f  ed in offline/mo
+00014ee0: 6465 6c2d 6261 7365 6420 7365 7474 696e  del-based settin
+00014ef0: 6773 2c20 7768 6572 6520 6120 6261 7463  gs, where a batc
+00014f00: 6820 6f66 2072 616e 646f 6d0d 0a20 2020  h of random..   
+00014f10: 2020 2020 2020 2020 2074 7261 6a65 6374           traject
+00014f20: 6f72 6965 7320 6361 6e20 6265 2075 7365  ories can be use
+00014f30: 6420 746f 2069 6e69 7469 616c 697a 6520  d to initialize 
+00014f40: 7472 6169 6e69 6e67 2e0d 0a20 2020 2020  training...     
+00014f50: 2020 2020 2020 2064 6566 6175 6c74 3d2d         default=-
+00014f60: 3120 2869 2e65 2e20 6e6f 2072 616e 646f  1 (i.e. no rando
+00014f70: 6d20 6672 616d 6573 290d 0a20 2020 2020  m frames)..     
+00014f80: 2020 2072 6573 6574 5f61 745f 6561 6368     reset_at_each
+00014f90: 5f69 7465 7220 2862 6f6f 6c29 3a20 5768  _iter (bool): Wh
+00014fa0: 6574 6865 7220 6f72 206e 6f74 2065 6e76  ether or not env
+00014fb0: 6972 6f6e 6d65 6e74 7320 7368 6f75 6c64  ironments should
+00014fc0: 2062 6520 7265 7365 7420 666f 7220 6561   be reset for ea
+00014fd0: 6368 2062 6174 6368 2e0d 0a20 2020 2020  ch batch...     
+00014fe0: 2020 2020 2020 2064 6566 6175 6c74 3d46         default=F
+00014ff0: 616c 7365 2e0d 0a20 2020 2020 2020 2070  alse...        p
+00015000: 6f73 7470 726f 6320 2863 616c 6c61 626c  ostproc (callabl
+00015010: 652c 206f 7074 696f 6e61 6c29 3a20 4120  e, optional): A 
+00015020: 506f 7374 5072 6f63 6573 736f 7220 6973  PostProcessor is
+00015030: 2061 6e20 6f62 6a65 6374 2074 6861 7420   an object that 
+00015040: 7769 6c6c 2072 6561 6420 6120 6261 7463  will read a batc
+00015050: 6820 6f66 2064 6174 6120 616e 6420 7072  h of data and pr
+00015060: 6f63 6573 7320 6974 2069 6e20 610d 0a20  ocess it in a.. 
+00015070: 2020 2020 2020 2020 2020 2075 7365 6675             usefu
+00015080: 6c20 666f 726d 6174 2066 6f72 2074 7261  l format for tra
+00015090: 696e 696e 672e 0d0a 2020 2020 2020 2020  ining...        
+000150a0: 2020 2020 6465 6661 756c 743a 204e 6f6e      default: Non
+000150b0: 652e 0d0a 2020 2020 2020 2020 7370 6c69  e...        spli
+000150c0: 745f 7472 616a 7320 2862 6f6f 6c29 3a20  t_trajs (bool): 
+000150d0: 426f 6f6c 6561 6e20 696e 6469 6361 7469  Boolean indicati
+000150e0: 6e67 2077 6865 7468 6572 2074 6865 2072  ng whether the r
+000150f0: 6573 756c 7469 6e67 2054 656e 736f 7244  esulting TensorD
+00015100: 6963 7420 7368 6f75 6c64 2062 6520 7370  ict should be sp
+00015110: 6c69 7420 6163 636f 7264 696e 6720 746f  lit according to
+00015120: 2074 6865 2074 7261 6a65 6374 6f72 6965   the trajectorie
+00015130: 732e 0d0a 2020 2020 2020 2020 2020 2020  s...            
+00015140: 5365 6520 7574 696c 732e 7370 6c69 745f  See utils.split_
+00015150: 7472 616a 6563 746f 7269 6573 2066 6f72  trajectories for
+00015160: 206d 6f72 6520 696e 666f 726d 6174 696f   more informatio
+00015170: 6e2e 0d0a 2020 2020 2020 2020 6465 7669  n...        devi
+00015180: 6365 2028 696e 742c 2073 7472 2c20 746f  ce (int, str, to
+00015190: 7263 682e 6465 7669 6365 2c20 6f70 7469  rch.device, opti
+000151a0: 6f6e 616c 293a 2054 6865 2064 6576 6963  onal): The devic
+000151b0: 6520 6f6e 2077 6869 6368 2074 6865 0d0a  e on which the..
+000151c0: 2020 2020 2020 2020 2020 2020 706f 6c69              poli
+000151d0: 6379 2077 696c 6c20 6265 2070 6c61 6365  cy will be place
+000151e0: 642e 2049 6620 6974 2064 6966 6665 7273  d. If it differs
+000151f0: 2066 726f 6d20 7468 6520 696e 7075 7420   from the input 
+00015200: 706f 6c69 6379 0d0a 2020 2020 2020 2020  policy..        
+00015210: 2020 2020 6465 7669 6365 2c20 7468 6520      device, the 
+00015220: 7570 6461 7465 5f70 6f6c 6963 795f 7765  update_policy_we
+00015230: 6967 6874 735f 2829 206d 6574 686f 6420  ights_() method 
+00015240: 7368 6f75 6c64 2062 6520 7175 6572 6965  should be querie
+00015250: 640d 0a20 2020 2020 2020 2020 2020 2061  d..            a
+00015260: 7420 6170 7072 6f70 7269 6174 6520 7469  t appropriate ti
+00015270: 6d65 7320 6475 7269 6e67 2074 6865 2074  mes during the t
+00015280: 7261 696e 696e 6720 6c6f 6f70 2074 6f20  raining loop to 
+00015290: 6163 636f 6d6d 6f64 6174 6520 666f 720d  accommodate for.
+000152a0: 0a20 2020 2020 2020 2020 2020 2074 6865  .            the
+000152b0: 206c 6167 2062 6574 7765 656e 2070 6172   lag between par
+000152c0: 616d 6574 6572 2063 6f6e 6669 6775 7261  ameter configura
+000152d0: 7469 6f6e 2061 7420 7661 7269 6f75 7320  tion at various 
+000152e0: 7469 6d65 732e 0d0a 2020 2020 2020 2020  times...        
+000152f0: 2020 2020 4465 6661 756c 7420 6973 2060      Default is `
+00015300: 4e6f 6e65 6020 2869 2e65 2e20 706f 6c69  None` (i.e. poli
+00015310: 6379 2069 7320 6b65 7074 206f 6e20 6974  cy is kept on it
+00015320: 7320 6f72 6967 696e 616c 2064 6576 6963  s original devic
+00015330: 6529 0d0a 2020 2020 2020 2020 7374 6f72  e)..        stor
+00015340: 696e 675f 6465 7669 6365 2028 696e 742c  ing_device (int,
+00015350: 2073 7472 2c20 746f 7263 682e 6465 7669   str, torch.devi
+00015360: 6365 2c20 6f70 7469 6f6e 616c 293a 2054  ce, optional): T
+00015370: 6865 2064 6576 6963 6520 6f6e 2077 6869  he device on whi
+00015380: 6368 0d0a 2020 2020 2020 2020 2020 2020  ch..            
+00015390: 7468 6520 6f75 7470 7574 2054 656e 736f  the output Tenso
+000153a0: 7244 6963 7420 7769 6c6c 2062 6520 7374  rDict will be st
+000153b0: 6f72 6564 2e20 466f 7220 6c6f 6e67 2074  ored. For long t
+000153c0: 7261 6a65 6374 6f72 6965 732c 0d0a 2020  rajectories,..  
+000153d0: 2020 2020 2020 2020 2020 6974 206d 6179            it may
+000153e0: 2062 6520 6e65 6365 7373 6172 7920 746f   be necessary to
+000153f0: 2073 746f 7265 2074 6865 2064 6174 6120   store the data 
+00015400: 6f6e 2061 2064 6966 6665 7265 6e74 2e0d  on a different..
+00015410: 0a20 2020 2020 2020 2020 2020 2064 6576  .            dev
+00015420: 6963 6520 7468 616e 2074 6865 206f 6e65  ice than the one
+00015430: 2077 6865 7265 2074 6865 2070 6f6c 6963   where the polic
+00015440: 7920 6973 2073 746f 7265 642e 2044 6566  y is stored. Def
+00015450: 6175 6c74 2069 7320 4e6f 6e65 2e0d 0a20  ault is None... 
+00015460: 2020 2020 2020 2075 7064 6174 655f 6174         update_at
+00015470: 5f65 6163 685f 6261 7463 6820 2862 6f6f  _each_batch (boo
+00015480: 6c29 3a20 6966 2060 6054 7275 6560 602c  l): if ``True``,
+00015490: 2074 6865 2070 6f6c 6963 7920 7765 6967   the policy weig
+000154a0: 6874 7320 7769 6c6c 2062 6520 7570 6461  hts will be upda
+000154b0: 7465 6420 6576 6572 7920 7469 6d65 2061  ted every time a
+000154c0: 2062 6174 6368 206f 6620 7472 616a 6563   batch of trajec
+000154d0: 746f 7269 6573 0d0a 2020 2020 2020 2020  tories..        
+000154e0: 2020 2020 6973 2063 6f6c 6c65 6374 6564      is collected
+000154f0: 2e0d 0a20 2020 2020 2020 2020 2020 2064  ...            d
+00015500: 6566 6175 6c74 3d46 616c 7365 0d0a 0d0a  efault=False....
+00015510: 2020 2020 2222 220d 0a0d 0a20 2020 2064      """....    d
+00015520: 6566 205f 5f69 6e69 745f 5f28 0d0a 2020  ef __init__(..  
+00015530: 2020 2020 2020 7365 6c66 2c0d 0a20 2020        self,..   
+00015540: 2020 2020 2063 7265 6174 655f 656e 765f       create_env_
+00015550: 666e 3a20 4361 6c6c 6162 6c65 5b5b 5d2c  fn: Callable[[],
+00015560: 2045 6e76 4261 7365 5d2c 0d0a 2020 2020   EnvBase],..    
+00015570: 2020 2020 706f 6c69 6379 3a20 4f70 7469      policy: Opti
+00015580: 6f6e 616c 5b0d 0a20 2020 2020 2020 2020  onal[..         
+00015590: 2020 2055 6e69 6f6e 5b0d 0a20 2020 2020     Union[..     
+000155a0: 2020 2020 2020 2020 2020 2054 656e 736f             Tenso
+000155b0: 7244 6963 744d 6f64 756c 652c 0d0a 2020  rDictModule,..  
+000155c0: 2020 2020 2020 2020 2020 2020 2020 4361                Ca
+000155d0: 6c6c 6162 6c65 5b5b 5465 6e73 6f72 4469  llable[[TensorDi
+000155e0: 6374 4261 7365 5d2c 2054 656e 736f 7244  ctBase], TensorD
+000155f0: 6963 7442 6173 655d 2c0d 0a20 2020 2020  ictBase],..     
+00015600: 2020 2020 2020 205d 0d0a 2020 2020 2020         ]..      
+00015610: 2020 5d20 3d20 4e6f 6e65 2c0d 0a20 2020    ] = None,..   
+00015620: 2020 2020 2074 6f74 616c 5f66 7261 6d65       total_frame
+00015630: 733a 204f 7074 696f 6e61 6c5b 696e 745d  s: Optional[int]
+00015640: 203d 202d 312c 0d0a 2020 2020 2020 2020   = -1,..        
+00015650: 6372 6561 7465 5f65 6e76 5f6b 7761 7267  create_env_kwarg
+00015660: 733a 204f 7074 696f 6e61 6c5b 6469 6374  s: Optional[dict
+00015670: 5d20 3d20 4e6f 6e65 2c0d 0a20 2020 2020  ] = None,..     
+00015680: 2020 206d 6178 5f66 7261 6d65 735f 7065     max_frames_pe
+00015690: 725f 7472 616a 3a20 696e 7420 3d20 2d31  r_traj: int = -1
+000156a0: 2c0d 0a20 2020 2020 2020 2066 7261 6d65  ,..        frame
+000156b0: 735f 7065 725f 6261 7463 683a 2069 6e74  s_per_batch: int
+000156c0: 203d 2032 3030 2c0d 0a20 2020 2020 2020   = 200,..       
+000156d0: 2069 6e69 745f 7261 6e64 6f6d 5f66 7261   init_random_fra
+000156e0: 6d65 733a 2069 6e74 203d 202d 312c 0d0a  mes: int = -1,..
+000156f0: 2020 2020 2020 2020 7265 7365 745f 6174          reset_at
+00015700: 5f65 6163 685f 6974 6572 3a20 626f 6f6c  _each_iter: bool
+00015710: 203d 2046 616c 7365 2c0d 0a20 2020 2020   = False,..     
+00015720: 2020 2070 6f73 7470 726f 633a 204f 7074     postproc: Opt
+00015730: 696f 6e61 6c5b 4361 6c6c 6162 6c65 5b5b  ional[Callable[[
+00015740: 5465 6e73 6f72 4469 6374 4261 7365 5d2c  TensorDictBase],
+00015750: 2054 656e 736f 7244 6963 7442 6173 655d   TensorDictBase]
+00015760: 5d20 3d20 4e6f 6e65 2c0d 0a20 2020 2020  ] = None,..     
+00015770: 2020 2073 706c 6974 5f74 7261 6a73 3a20     split_trajs: 
+00015780: 4f70 7469 6f6e 616c 5b62 6f6f 6c5d 203d  Optional[bool] =
+00015790: 204e 6f6e 652c 0d0a 2020 2020 2020 2020   None,..        
+000157a0: 6465 7669 6365 3a20 4f70 7469 6f6e 616c  device: Optional
+000157b0: 5b55 6e69 6f6e 5b69 6e74 2c20 7374 722c  [Union[int, str,
+000157c0: 2074 6f72 6368 2e64 6576 6963 655d 5d20   torch.device]] 
+000157d0: 3d20 4e6f 6e65 2c0d 0a20 2020 2020 2020  = None,..       
+000157e0: 2073 746f 7269 6e67 5f64 6576 6963 653a   storing_device:
+000157f0: 204f 7074 696f 6e61 6c5b 556e 696f 6e5b   Optional[Union[
+00015800: 696e 742c 2073 7472 2c20 746f 7263 682e  int, str, torch.
+00015810: 6465 7669 6365 5d5d 203d 204e 6f6e 652c  device]] = None,
+00015820: 0d0a 2020 2020 2020 2020 7365 6564 3a20  ..        seed: 
+00015830: 4f70 7469 6f6e 616c 5b69 6e74 5d20 3d20  Optional[int] = 
+00015840: 4e6f 6e65 2c0d 0a20 2020 2020 2020 2070  None,..        p
+00015850: 696e 5f6d 656d 6f72 793a 2062 6f6f 6c20  in_memory: bool 
+00015860: 3d20 4661 6c73 652c 0d0a 2020 2020 2020  = False,..      
+00015870: 2020 2a2a 6b77 6172 6773 2c0d 0a20 2020    **kwargs,..   
+00015880: 2029 3a0d 0a20 2020 2020 2020 2073 7570   ):..        sup
+00015890: 6572 2829 2e5f 5f69 6e69 745f 5f28 0d0a  er().__init__(..
+000158a0: 2020 2020 2020 2020 2020 2020 6372 6561              crea
+000158b0: 7465 5f65 6e76 5f66 6e3d 5b63 7265 6174  te_env_fn=[creat
+000158c0: 655f 656e 765f 666e 5d2c 0d0a 2020 2020  e_env_fn],..    
+000158d0: 2020 2020 2020 2020 706f 6c69 6379 3d70          policy=p
+000158e0: 6f6c 6963 792c 0d0a 2020 2020 2020 2020  olicy,..        
+000158f0: 2020 2020 746f 7461 6c5f 6672 616d 6573      total_frames
+00015900: 3d74 6f74 616c 5f66 7261 6d65 732c 0d0a  =total_frames,..
+00015910: 2020 2020 2020 2020 2020 2020 6372 6561              crea
+00015920: 7465 5f65 6e76 5f6b 7761 7267 733d 5b63  te_env_kwargs=[c
+00015930: 7265 6174 655f 656e 765f 6b77 6172 6773  reate_env_kwargs
+00015940: 5d2c 0d0a 2020 2020 2020 2020 2020 2020  ],..            
+00015950: 6d61 785f 6672 616d 6573 5f70 6572 5f74  max_frames_per_t
+00015960: 7261 6a3d 6d61 785f 6672 616d 6573 5f70  raj=max_frames_p
+00015970: 6572 5f74 7261 6a2c 0d0a 2020 2020 2020  er_traj,..      
+00015980: 2020 2020 2020 6672 616d 6573 5f70 6572        frames_per
+00015990: 5f62 6174 6368 3d66 7261 6d65 735f 7065  _batch=frames_pe
+000159a0: 725f 6261 7463 682c 0d0a 2020 2020 2020  r_batch,..      
+000159b0: 2020 2020 2020 7265 7365 745f 6174 5f65        reset_at_e
+000159c0: 6163 685f 6974 6572 3d72 6573 6574 5f61  ach_iter=reset_a
+000159d0: 745f 6561 6368 5f69 7465 722c 0d0a 2020  t_each_iter,..  
+000159e0: 2020 2020 2020 2020 2020 696e 6974 5f72            init_r
+000159f0: 616e 646f 6d5f 6672 616d 6573 3d69 6e69  andom_frames=ini
+00015a00: 745f 7261 6e64 6f6d 5f66 7261 6d65 732c  t_random_frames,
+00015a10: 0d0a 2020 2020 2020 2020 2020 2020 706f  ..            po
+00015a20: 7374 7072 6f63 3d70 6f73 7470 726f 632c  stproc=postproc,
+00015a30: 0d0a 2020 2020 2020 2020 2020 2020 7370  ..            sp
+00015a40: 6c69 745f 7472 616a 733d 7370 6c69 745f  lit_trajs=split_
+00015a50: 7472 616a 732c 0d0a 2020 2020 2020 2020  trajs,..        
+00015a60: 2020 2020 6465 7669 6365 733d 5b64 6576      devices=[dev
+00015a70: 6963 655d 2069 6620 6465 7669 6365 2069  ice] if device i
+00015a80: 7320 6e6f 7420 4e6f 6e65 2065 6c73 6520  s not None else 
+00015a90: 4e6f 6e65 2c0d 0a20 2020 2020 2020 2020  None,..         
+00015aa0: 2020 2073 746f 7269 6e67 5f64 6576 6963     storing_devic
+00015ab0: 6573 3d5b 7374 6f72 696e 675f 6465 7669  es=[storing_devi
+00015ac0: 6365 5d20 6966 2073 746f 7269 6e67 5f64  ce] if storing_d
+00015ad0: 6576 6963 6520 6973 206e 6f74 204e 6f6e  evice is not Non
+00015ae0: 6520 656c 7365 204e 6f6e 652c 0d0a 2020  e else None,..  
+00015af0: 2020 2020 2020 2020 2020 2a2a 6b77 6172            **kwar
+00015b00: 6773 2c0d 0a20 2020 2020 2020 2029 0d0a  gs,..        )..
+00015b10: 0d0a 2020 2020 2320 666f 7220 5250 430d  ..    # for RPC.
+00015b20: 0a20 2020 2064 6566 206e 6578 7428 7365  .    def next(se
+00015b30: 6c66 293a 0d0a 2020 2020 2020 2020 7265  lf):..        re
+00015b40: 7475 726e 2073 7570 6572 2829 2e6e 6578  turn super().nex
+00015b50: 7428 290d 0a0d 0a20 2020 2023 2066 6f72  t()....    # for
+00015b60: 2052 5043 0d0a 2020 2020 6465 6620 7368   RPC..    def sh
+00015b70: 7574 646f 776e 2873 656c 6629 3a0d 0a20  utdown(self):.. 
+00015b80: 2020 2020 2020 2072 6574 7572 6e20 7375         return su
+00015b90: 7065 7228 292e 7368 7574 646f 776e 2829  per().shutdown()
+00015ba0: 0d0a 0d0a 2020 2020 2320 666f 7220 5250  ....    # for RP
+00015bb0: 430d 0a20 2020 2064 6566 2073 6574 5f73  C..    def set_s
+00015bc0: 6565 6428 7365 6c66 2c20 7365 6564 3a20  eed(self, seed: 
+00015bd0: 696e 742c 2073 7461 7469 635f 7365 6564  int, static_seed
+00015be0: 3a20 626f 6f6c 203d 2046 616c 7365 2920  : bool = False) 
+00015bf0: 2d3e 2069 6e74 3a0d 0a20 2020 2020 2020  -> int:..       
+00015c00: 2072 6574 7572 6e20 7375 7065 7228 292e   return super().
+00015c10: 7365 745f 7365 6564 2873 6565 642c 2073  set_seed(seed, s
+00015c20: 7461 7469 635f 7365 6564 290d 0a0d 0a20  tatic_seed).... 
+00015c30: 2020 2023 2066 6f72 2052 5043 0d0a 2020     # for RPC..  
+00015c40: 2020 6465 6620 7374 6174 655f 6469 6374    def state_dict
+00015c50: 2873 656c 6629 202d 3e20 4f72 6465 7265  (self) -> Ordere
+00015c60: 6444 6963 743a 0d0a 2020 2020 2020 2020  dDict:..        
+00015c70: 7265 7475 726e 2073 7570 6572 2829 2e73  return super().s
+00015c80: 7461 7465 5f64 6963 7428 290d 0a0d 0a20  tate_dict().... 
+00015c90: 2020 2023 2066 6f72 2052 5043 0d0a 2020     # for RPC..  
+00015ca0: 2020 6465 6620 6c6f 6164 5f73 7461 7465    def load_state
+00015cb0: 5f64 6963 7428 7365 6c66 2c20 7374 6174  _dict(self, stat
+00015cc0: 655f 6469 6374 3a20 4f72 6465 7265 6444  e_dict: OrderedD
+00015cd0: 6963 7429 202d 3e20 4e6f 6e65 3a0d 0a20  ict) -> None:.. 
+00015ce0: 2020 2020 2020 2072 6574 7572 6e20 7375         return su
+00015cf0: 7065 7228 292e 6c6f 6164 5f73 7461 7465  per().load_state
+00015d00: 5f64 6963 7428 7374 6174 655f 6469 6374  _dict(state_dict
+00015d10: 290d 0a0d 0a0d 0a64 6566 205f 6d61 696e  )......def _main
+00015d20: 5f61 7379 6e63 5f63 6f6c 6c65 6374 6f72  _async_collector
+00015d30: 280d 0a20 2020 2070 6970 655f 7061 7265  (..    pipe_pare
+00015d40: 6e74 3a20 636f 6e6e 6563 7469 6f6e 2e43  nt: connection.C
+00015d50: 6f6e 6e65 6374 696f 6e2c 0d0a 2020 2020  onnection,..    
+00015d60: 7069 7065 5f63 6869 6c64 3a20 636f 6e6e  pipe_child: conn
+00015d70: 6563 7469 6f6e 2e43 6f6e 6e65 6374 696f  ection.Connectio
+00015d80: 6e2c 0d0a 2020 2020 7175 6575 655f 6f75  n,..    queue_ou
+00015d90: 743a 2071 7565 7565 732e 5175 6575 652c  t: queues.Queue,
+00015da0: 0d0a 2020 2020 6372 6561 7465 5f65 6e76  ..    create_env
+00015db0: 5f66 6e3a 2055 6e69 6f6e 5b45 6e76 4261  _fn: Union[EnvBa
+00015dc0: 7365 2c20 2245 6e76 4372 6561 746f 7222  se, "EnvCreator"
+00015dd0: 2c20 4361 6c6c 6162 6c65 5b5b 5d2c 2045  , Callable[[], E
+00015de0: 6e76 4261 7365 5d5d 2c20 2023 206e 6f71  nvBase]],  # noq
+00015df0: 613a 2046 3832 310d 0a20 2020 2063 7265  a: F821..    cre
+00015e00: 6174 655f 656e 765f 6b77 6172 6773 3a20  ate_env_kwargs: 
+00015e10: 4469 6374 5b73 7472 2c20 416e 795d 2c0d  Dict[str, Any],.
+00015e20: 0a20 2020 2070 6f6c 6963 793a 2043 616c  .    policy: Cal
+00015e30: 6c61 626c 655b 5b54 656e 736f 7244 6963  lable[[TensorDic
+00015e40: 7442 6173 655d 2c20 5465 6e73 6f72 4469  tBase], TensorDi
+00015e50: 6374 4261 7365 5d2c 0d0a 2020 2020 6d61  ctBase],..    ma
+00015e60: 785f 6672 616d 6573 5f70 6572 5f74 7261  x_frames_per_tra
+00015e70: 6a3a 2069 6e74 2c0d 0a20 2020 2066 7261  j: int,..    fra
+00015e80: 6d65 735f 7065 725f 6261 7463 683a 2069  mes_per_batch: i
+00015e90: 6e74 2c0d 0a20 2020 2072 6573 6574 5f61  nt,..    reset_a
+00015ea0: 745f 6561 6368 5f69 7465 723a 2062 6f6f  t_each_iter: boo
+00015eb0: 6c2c 0d0a 2020 2020 6465 7669 6365 3a20  l,..    device: 
+00015ec0: 4f70 7469 6f6e 616c 5b55 6e69 6f6e 5b74  Optional[Union[t
+00015ed0: 6f72 6368 2e64 6576 6963 652c 2073 7472  orch.device, str
+00015ee0: 2c20 696e 745d 5d2c 0d0a 2020 2020 7374  , int]],..    st
+00015ef0: 6f72 696e 675f 6465 7669 6365 3a20 4f70  oring_device: Op
+00015f00: 7469 6f6e 616c 5b55 6e69 6f6e 5b74 6f72  tional[Union[tor
+00015f10: 6368 2e64 6576 6963 652c 2073 7472 2c20  ch.device, str, 
+00015f20: 696e 745d 5d2c 0d0a 2020 2020 6964 783a  int]],..    idx:
+00015f30: 2069 6e74 203d 2030 2c0d 0a20 2020 2065   int = 0,..    e
+00015f40: 7870 6c6f 7261 7469 6f6e 5f74 7970 653a  xploration_type:
+00015f50: 2045 7870 6c6f 7261 7469 6f6e 5479 7065   ExplorationType
+00015f60: 203d 2044 4546 4155 4c54 5f45 5850 4c4f   = DEFAULT_EXPLO
+00015f70: 5241 5449 4f4e 5f54 5950 452c 0d0a 2020  RATION_TYPE,..  
+00015f80: 2020 7265 7365 745f 7768 656e 5f64 6f6e    reset_when_don
+00015f90: 653a 2062 6f6f 6c20 3d20 5472 7565 2c0d  e: bool = True,.
+00015fa0: 0a20 2020 2076 6572 626f 7365 3a20 626f  .    verbose: bo
+00015fb0: 6f6c 203d 2056 4552 424f 5345 2c0d 0a20  ol = VERBOSE,.. 
+00015fc0: 2020 2069 6e74 6572 7275 7074 6f72 3d4e     interruptor=N
+00015fd0: 6f6e 652c 0d0a 2920 2d3e 204e 6f6e 653a  one,..) -> None:
+00015fe0: 0d0a 2020 2020 7069 7065 5f70 6172 656e  ..    pipe_paren
+00015ff0: 742e 636c 6f73 6528 290d 0a20 2020 2023  t.close()..    #
+00016000: 2069 6e69 7420 7661 7269 6162 6c65 7320   init variables 
+00016010: 7468 6174 2077 696c 6c20 6265 2063 6c65  that will be cle
+00016020: 6172 6564 2077 6865 6e20 636c 6f73 696e  ared when closin
+00016030: 670d 0a20 2020 2074 656e 736f 7264 6963  g..    tensordic
+00016040: 7420 3d20 6461 7461 203d 2064 203d 2064  t = data = d = d
+00016050: 6174 615f 696e 203d 2069 6e6e 6572 5f63  ata_in = inner_c
+00016060: 6f6c 6c65 6374 6f72 203d 2064 635f 6974  ollector = dc_it
+00016070: 6572 203d 204e 6f6e 650d 0a0d 0a20 2020  er = None....   
+00016080: 2023 2073 656e 6420 7468 6520 706f 6c69   # send the poli
+00016090: 6379 2074 6f20 6465 7669 6365 0d0a 2020  cy to device..  
+000160a0: 2020 7472 793a 0d0a 2020 2020 2020 2020    try:..        
+000160b0: 706f 6c69 6379 203d 2070 6f6c 6963 792e  policy = policy.
+000160c0: 746f 2864 6576 6963 6529 0d0a 2020 2020  to(device)..    
+000160d0: 6578 6365 7074 2045 7863 6570 7469 6f6e  except Exception
+000160e0: 3a0d 0a20 2020 2020 2020 2069 6620 524c  :..        if RL
+000160f0: 5f57 4152 4e49 4e47 533a 0d0a 2020 2020  _WARNINGS:..    
+00016100: 2020 2020 2020 2020 7761 726e 696e 6773          warnings
+00016110: 2e77 6172 6e28 0d0a 2020 2020 2020 2020  .warn(..        
+00016120: 2020 2020 2020 2020 2243 6f75 6c64 6e27          "Couldn'
+00016130: 7420 6361 7374 2074 6865 2070 6f6c 6963  t cast the polic
+00016140: 7920 6f6e 746f 2074 6865 2064 6573 6972  y onto the desir
+00016150: 6564 2064 6576 6963 6520 6f6e 2072 656d  ed device on rem
+00016160: 6f74 6520 7072 6f63 6573 732e 2022 0d0a  ote process. "..
+00016170: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016180: 2249 6620 796f 7572 2070 6f6c 6963 7920  "If your policy 
+00016190: 6973 206e 6f74 2061 206e 6e2e 4d6f 6475  is not a nn.Modu
+000161a0: 6c65 2069 6e73 7461 6e63 6520 796f 7520  le instance you 
+000161b0: 6361 6e20 7072 6f62 6162 6c79 2069 676e  can probably ign
+000161c0: 6f72 6520 7468 6973 2077 6172 6e69 6e67  ore this warning
+000161d0: 2e22 0d0a 2020 2020 2020 2020 2020 2020  ."..            
+000161e0: 290d 0a20 2020 2069 6e6e 6572 5f63 6f6c  )..    inner_col
+000161f0: 6c65 6374 6f72 203d 2053 796e 6344 6174  lector = SyncDat
+00016200: 6143 6f6c 6c65 6374 6f72 280d 0a20 2020  aCollector(..   
+00016210: 2020 2020 2063 7265 6174 655f 656e 765f       create_env_
+00016220: 666e 2c0d 0a20 2020 2020 2020 2063 7265  fn,..        cre
+00016230: 6174 655f 656e 765f 6b77 6172 6773 3d63  ate_env_kwargs=c
+00016240: 7265 6174 655f 656e 765f 6b77 6172 6773  reate_env_kwargs
+00016250: 2c0d 0a20 2020 2020 2020 2070 6f6c 6963  ,..        polic
+00016260: 793d 706f 6c69 6379 2c0d 0a20 2020 2020  y=policy,..     
+00016270: 2020 2074 6f74 616c 5f66 7261 6d65 733d     total_frames=
+00016280: 2d31 2c0d 0a20 2020 2020 2020 206d 6178  -1,..        max
+00016290: 5f66 7261 6d65 735f 7065 725f 7472 616a  _frames_per_traj
+000162a0: 3d6d 6178 5f66 7261 6d65 735f 7065 725f  =max_frames_per_
+000162b0: 7472 616a 2c0d 0a20 2020 2020 2020 2066  traj,..        f
+000162c0: 7261 6d65 735f 7065 725f 6261 7463 683d  rames_per_batch=
+000162d0: 6672 616d 6573 5f70 6572 5f62 6174 6368  frames_per_batch
+000162e0: 2c0d 0a20 2020 2020 2020 2072 6573 6574  ,..        reset
+000162f0: 5f61 745f 6561 6368 5f69 7465 723d 7265  _at_each_iter=re
+00016300: 7365 745f 6174 5f65 6163 685f 6974 6572  set_at_each_iter
+00016310: 2c0d 0a20 2020 2020 2020 2070 6f73 7470  ,..        postp
+00016320: 726f 633d 4e6f 6e65 2c0d 0a20 2020 2020  roc=None,..     
+00016330: 2020 2073 706c 6974 5f74 7261 6a73 3d46     split_trajs=F
+00016340: 616c 7365 2c0d 0a20 2020 2020 2020 2064  alse,..        d
+00016350: 6576 6963 653d 6465 7669 6365 2c0d 0a20  evice=device,.. 
+00016360: 2020 2020 2020 2073 746f 7269 6e67 5f64         storing_d
+00016370: 6576 6963 653d 7374 6f72 696e 675f 6465  evice=storing_de
+00016380: 7669 6365 2c0d 0a20 2020 2020 2020 2065  vice,..        e
+00016390: 7870 6c6f 7261 7469 6f6e 5f74 7970 653d  xploration_type=
+000163a0: 6578 706c 6f72 6174 696f 6e5f 7479 7065  exploration_type
+000163b0: 2c0d 0a20 2020 2020 2020 2072 6573 6574  ,..        reset
+000163c0: 5f77 6865 6e5f 646f 6e65 3d72 6573 6574  _when_done=reset
+000163d0: 5f77 6865 6e5f 646f 6e65 2c0d 0a20 2020  _when_done,..   
+000163e0: 2020 2020 2072 6574 7572 6e5f 7361 6d65       return_same
+000163f0: 5f74 643d 5472 7565 2c0d 0a20 2020 2020  _td=True,..     
+00016400: 2020 2069 6e74 6572 7275 7074 6f72 3d69     interruptor=i
+00016410: 6e74 6572 7275 7074 6f72 2c0d 0a20 2020  nterruptor,..   
+00016420: 2029 0d0a 2020 2020 6966 2076 6572 626f   )..    if verbo
+00016430: 7365 3a0d 0a20 2020 2020 2020 2070 7269  se:..        pri
+00016440: 6e74 2822 5379 6e63 2064 6174 6120 636f  nt("Sync data co
+00016450: 6c6c 6563 746f 7220 6372 6561 7465 6422  llector created"
+00016460: 290d 0a20 2020 2064 635f 6974 6572 203d  )..    dc_iter =
+00016470: 2069 7465 7228 696e 6e65 725f 636f 6c6c   iter(inner_coll
+00016480: 6563 746f 7229 0d0a 2020 2020 6a20 3d20  ector)..    j = 
+00016490: 300d 0a20 2020 2070 6970 655f 6368 696c  0..    pipe_chil
+000164a0: 642e 7365 6e64 2822 696e 7374 616e 7469  d.send("instanti
+000164b0: 6174 6564 2229 0d0a 0d0a 2020 2020 6861  ated")....    ha
+000164c0: 735f 7469 6d65 645f 6f75 7420 3d20 4661  s_timed_out = Fa
+000164d0: 6c73 650d 0a20 2020 2063 6f75 6e74 6572  lse..    counter
+000164e0: 203d 2030 0d0a 2020 2020 7768 696c 6520   = 0..    while 
+000164f0: 5472 7565 3a0d 0a20 2020 2020 2020 205f  True:..        _
+00016500: 7469 6d65 6f75 7420 3d20 5f54 494d 454f  timeout = _TIMEO
+00016510: 5554 2069 6620 6e6f 7420 6861 735f 7469  UT if not has_ti
+00016520: 6d65 645f 6f75 7420 656c 7365 2031 652d  med_out else 1e-
+00016530: 330d 0a20 2020 2020 2020 2069 6620 7069  3..        if pi
+00016540: 7065 5f63 6869 6c64 2e70 6f6c 6c28 5f74  pe_child.poll(_t
+00016550: 696d 656f 7574 293a 0d0a 2020 2020 2020  imeout):..      
+00016560: 2020 2020 2020 636f 756e 7465 7220 3d20        counter = 
+00016570: 300d 0a20 2020 2020 2020 2020 2020 2064  0..            d
+00016580: 6174 615f 696e 2c20 6d73 6720 3d20 7069  ata_in, msg = pi
+00016590: 7065 5f63 6869 6c64 2e72 6563 7628 290d  pe_child.recv().
+000165a0: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
+000165b0: 7665 7262 6f73 653a 0d0a 2020 2020 2020  verbose:..      
+000165c0: 2020 2020 2020 2020 2020 7072 696e 7428            print(
+000165d0: 6622 776f 726b 6572 207b 6964 787d 2072  f"worker {idx} r
+000165e0: 6563 6569 7665 6420 7b6d 7367 7d22 290d  eceived {msg}").
+000165f0: 0a20 2020 2020 2020 2065 6c73 653a 0d0a  .        else:..
+00016600: 2020 2020 2020 2020 2020 2020 6966 2076              if v
+00016610: 6572 626f 7365 3a0d 0a20 2020 2020 2020  erbose:..       
+00016620: 2020 2020 2020 2020 2070 7269 6e74 2866           print(f
+00016630: 2270 6f6c 6c20 6661 696c 6564 2c20 6a3d  "poll failed, j=
+00016640: 7b6a 7d2c 2077 6f72 6b65 723d 7b69 6478  {j}, worker={idx
+00016650: 7d22 290d 0a20 2020 2020 2020 2020 2020  }")..           
+00016660: 2023 2064 6566 6175 6c74 2069 7320 2263   # default is "c
+00016670: 6f6e 7469 6e75 6522 2028 6166 7465 7220  ontinue" (after 
+00016680: 6669 7273 7420 6974 6572 6174 696f 6e29  first iteration)
+00016690: 0d0a 2020 2020 2020 2020 2020 2020 2320  ..            # 
+000166a0: 7468 6973 2069 7320 6578 7065 6374 6564  this is expected
+000166b0: 2074 6f20 6861 7070 656e 2069 6620 7175   to happen if qu
+000166c0: 6575 655f 6f75 7420 7265 6163 6865 6420  eue_out reached 
+000166d0: 7468 6520 7469 6d65 6f75 742c 2062 7574  the timeout, but
+000166e0: 206e 6f20 6e65 7720 6d73 6720 7761 7320   no new msg was 
+000166f0: 7761 6974 696e 6720 696e 2074 6865 2070  waiting in the p
+00016700: 6970 650d 0a20 2020 2020 2020 2020 2020  ipe..           
+00016710: 2023 2069 6e20 7468 6174 2063 6173 652c   # in that case,
+00016720: 2074 6865 206d 6169 6e20 7072 6f63 6573   the main proces
+00016730: 7320 7072 6f62 6162 6c79 2065 7870 6563  s probably expec
+00016740: 7473 2074 6865 2077 6f72 6b65 7220 746f  ts the worker to
+00016750: 2063 6f6e 7469 6e75 6520 636f 6c6c 6563   continue collec
+00016760: 7420 6461 7461 0d0a 2020 2020 2020 2020  t data..        
+00016770: 2020 2020 6966 2068 6173 5f74 696d 6564      if has_timed
+00016780: 5f6f 7574 3a0d 0a20 2020 2020 2020 2020  _out:..         
+00016790: 2020 2020 2020 2063 6f75 6e74 6572 203d         counter =
+000167a0: 2030 0d0a 2020 2020 2020 2020 2020 2020   0..            
+000167b0: 2020 2020 2320 6861 735f 7469 6d65 645f      # has_timed_
+000167c0: 6f75 7420 6973 2054 7275 6520 6966 2074  out is True if t
+000167d0: 6865 2070 726f 6365 7373 2066 6169 6c65  he process faile
+000167e0: 6420 746f 2073 656e 6420 6461 7461 2c20  d to send data, 
+000167f0: 7768 6963 6820 7769 6c6c 0d0a 2020 2020  which will..    
+00016800: 2020 2020 2020 2020 2020 2020 2320 7479              # ty
+00016810: 7069 6361 6c6c 7920 6f63 6375 7220 6966  pically occur if
+00016820: 206d 6169 6e20 6861 7320 7461 6b65 6e20   main has taken 
+00016830: 616e 6f74 6865 7220 6261 7463 6820 2869  another batch (i
+00016840: 2e65 2e20 7468 6520 7175 6575 6520 6973  .e. the queue is
+00016850: 2046 756c 6c29 2e0d 0a20 2020 2020 2020   Full)...       
+00016860: 2020 2020 2020 2020 2023 2049 6e20 7468           # In th
+00016870: 6973 2063 6173 652c 206d 7367 2069 7320  is case, msg is 
+00016880: 7468 6520 7072 6576 696f 7573 206d 7367  the previous msg
+00016890: 2073 656e 7420 6279 206d 6169 6e2c 2077   sent by main, w
+000168a0: 6869 6368 2077 696c 6c20 7479 7069 6361  hich will typica
+000168b0: 6c6c 7920 6265 2022 636f 6e74 696e 7565  lly be "continue
+000168c0: 220d 0a20 2020 2020 2020 2020 2020 2020  "..             
+000168d0: 2020 2023 2049 6620 6974 2773 206e 6f74     # If it's not
+000168e0: 2074 6865 2063 6173 652c 2069 7420 6973   the case, it is
+000168f0: 206e 6f74 2065 7870 6563 7465 6420 7468   not expected th
+00016900: 6174 2068 6173 5f74 696d 6564 5f6f 7574  at has_timed_out
+00016910: 2069 7320 5472 7565 2e0d 0a20 2020 2020   is True...     
+00016920: 2020 2020 2020 2020 2020 2069 6620 6d73             if ms
+00016930: 6720 6e6f 7420 696e 2028 2263 6f6e 7469  g not in ("conti
+00016940: 6e75 6522 2c20 2263 6f6e 7469 6e75 655f  nue", "continue_
+00016950: 7261 6e64 6f6d 2229 3a0d 0a20 2020 2020  random"):..     
+00016960: 2020 2020 2020 2020 2020 2020 2020 2072                 r
+00016970: 6169 7365 2052 756e 7469 6d65 4572 726f  aise RuntimeErro
+00016980: 7228 6622 556e 6578 7065 6374 6564 206d  r(f"Unexpected m
+00016990: 6573 7361 6765 2061 6674 6572 2074 696d  essage after tim
+000169a0: 6520 6f75 743a 206d 7367 3d7b 6d73 677d  e out: msg={msg}
+000169b0: 2229 0d0a 2020 2020 2020 2020 2020 2020  ")..            
+000169c0: 656c 7365 3a0d 0a20 2020 2020 2020 2020  else:..         
+000169d0: 2020 2020 2020 2023 2069 6620 6861 735f         # if has_
+000169e0: 7469 6d65 645f 6f75 7420 6973 2046 616c  timed_out is Fal
+000169f0: 7365 2c20 7468 656e 2074 6865 2074 696d  se, then the tim
+00016a00: 6520 6f75 7420 646f 6573 206e 6f74 2063  e out does not c
+00016a10: 6f6d 6520 6672 6f6d 2074 6865 2066 6163  ome from the fac
+00016a20: 7420 7468 6174 2074 6865 2071 7565 7565  t that the queue
+00016a30: 2069 7320 4675 6c6c 2e0d 0a20 2020 2020   is Full...     
+00016a40: 2020 2020 2020 2020 2020 2023 2074 6869             # thi
+00016a50: 7320 6d65 616e 7320 7468 6174 206f 7572  s means that our
+00016a60: 2070 726f 6365 7373 2068 6173 2062 6565   process has bee
+00016a70: 6e20 7761 6974 696e 6720 666f 7220 6120  n waiting for a 
+00016a80: 636f 6d6d 616e 6420 6672 6f6d 206d 6169  command from mai
+00016a90: 6e20 696e 2076 6169 6e2c 2077 6869 6c65  n in vain, while
+00016aa0: 206d 6169 6e20 7761 7320 6e6f 740d 0a20   main was not.. 
+00016ab0: 2020 2020 2020 2020 2020 2020 2020 2023                 #
+00016ac0: 2072 6563 6569 7669 6e67 2064 6174 612e   receiving data.
+00016ad0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00016ae0: 2020 2320 5468 6973 2077 696c 6c20 6f63    # This will oc
+00016af0: 6375 7220 6966 206d 6169 6e20 6973 2062  cur if main is b
+00016b00: 7573 7920 646f 696e 6720 736f 6d65 7468  usy doing someth
+00016b10: 696e 6720 656c 7365 2028 652e 672e 2063  ing else (e.g. c
+00016b20: 6f6d 7075 7469 6e67 206c 6f73 7320 6574  omputing loss et
+00016b30: 6329 2e0d 0a0d 0a20 2020 2020 2020 2020  c).....         
+00016b40: 2020 2020 2020 2063 6f75 6e74 6572 202b         counter +
+00016b50: 3d20 5f74 696d 656f 7574 0d0a 2020 2020  = _timeout..    
+00016b60: 2020 2020 2020 2020 2020 2020 6966 2076              if v
+00016b70: 6572 626f 7365 3a0d 0a20 2020 2020 2020  erbose:..       
+00016b80: 2020 2020 2020 2020 2020 2020 2070 7269               pri
+00016b90: 6e74 2866 2277 6f72 6b65 7220 7b69 6478  nt(f"worker {idx
+00016ba0: 7d20 6861 7320 636f 756e 7465 7220 7b63  } has counter {c
+00016bb0: 6f75 6e74 6572 7d22 290d 0a20 2020 2020  ounter}")..     
+00016bc0: 2020 2020 2020 2020 2020 2069 6620 636f             if co
+00016bd0: 756e 7465 7220 3e3d 2028 5f4d 4158 5f49  unter >= (_MAX_I
+00016be0: 444c 455f 434f 554e 5420 2a20 5f54 494d  DLE_COUNT * _TIM
+00016bf0: 454f 5554 293a 0d0a 2020 2020 2020 2020  EOUT):..        
+00016c00: 2020 2020 2020 2020 2020 2020 7261 6973              rais
+00016c10: 6520 5275 6e74 696d 6545 7272 6f72 280d  e RuntimeError(.
+00016c20: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00016c30: 2020 2020 2020 2020 2066 2254 6869 7320           f"This 
+00016c40: 7072 6f63 6573 7320 7761 6974 6564 2066  process waited f
+00016c50: 6f72 207b 636f 756e 7465 727d 2073 6563  or {counter} sec
+00016c60: 6f6e 6473 2022 0d0a 2020 2020 2020 2020  onds "..        
+00016c70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016c80: 6622 7769 7468 6f75 7420 7265 6365 6976  f"without receiv
+00016c90: 696e 6720 6120 636f 6d6d 616e 6420 6672  ing a command fr
+00016ca0: 6f6d 206d 6169 6e2e 2043 6f6e 7369 6465  om main. Conside
+00016cb0: 7220 696e 6372 6561 7369 6e67 2074 6865  r increasing the
+00016cc0: 206d 6178 696d 756d 2069 646c 6520 636f   maximum idle co
+00016cd0: 756e 7420 220d 0a20 2020 2020 2020 2020  unt "..         
+00016ce0: 2020 2020 2020 2020 2020 2020 2020 2066                 f
+00016cf0: 2269 6620 7468 6973 2069 7320 6578 7065  "if this is expe
+00016d00: 6374 6564 2076 6961 2074 6865 2065 6e76  cted via the env
+00016d10: 6972 6f6e 6d65 6e74 2076 6172 6961 626c  ironment variabl
+00016d20: 6520 4d41 585f 4944 4c45 5f43 4f55 4e54  e MAX_IDLE_COUNT
+00016d30: 2022 0d0a 2020 2020 2020 2020 2020 2020   "..            
+00016d40: 2020 2020 2020 2020 2020 2020 6622 2863              f"(c
+00016d50: 7572 7265 6e74 2076 616c 7565 2069 7320  urrent value is 
+00016d60: 7b5f 4d41 585f 4944 4c45 5f43 4f55 4e54  {_MAX_IDLE_COUNT
+00016d70: 7d29 2e22 0d0a 2020 2020 2020 2020 2020  })."..          
+00016d80: 2020 2020 2020 2020 2020 2020 2020 6622                f"
+00016d90: 5c6e 4966 2074 6869 7320 6f63 6375 7273  \nIf this occurs
+00016da0: 2061 7420 7468 6520 656e 6420 6f66 2061   at the end of a
+00016db0: 2066 756e 6374 696f 6e20 6f72 2070 726f   function or pro
+00016dc0: 6772 616d 2c20 6974 206d 6561 6e73 2074  gram, it means t
+00016dd0: 6861 7420 796f 7572 2063 6f6c 6c65 6374  hat your collect
+00016de0: 6f72 2068 6173 206e 6f74 2062 6565 6e20  or has not been 
+00016df0: 220d 0a20 2020 2020 2020 2020 2020 2020  "..             
+00016e00: 2020 2020 2020 2020 2020 2066 2263 6f6c             f"col
+00016e10: 6c65 6374 6564 2c20 636f 6e73 6964 6572  lected, consider
+00016e20: 2063 616c 6c69 6e67 2060 636f 6c6c 6563   calling `collec
+00016e30: 746f 722e 7368 7574 646f 776e 2829 6020  tor.shutdown()` 
+00016e40: 6f72 2060 6465 6c20 636f 6c6c 6563 746f  or `del collecto
+00016e50: 7260 2062 6566 6f72 6520 656e 6469 6e67  r` before ending
+00016e60: 2074 6865 2070 726f 6772 616d 2e22 0d0a   the program."..
+00016e70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016e80: 2020 2020 290d 0a20 2020 2020 2020 2020      )..         
+00016e90: 2020 2020 2020 2063 6f6e 7469 6e75 650d         continue.
+00016ea0: 0a20 2020 2020 2020 2069 6620 6d73 6720  .        if msg 
+00016eb0: 696e 2028 2263 6f6e 7469 6e75 6522 2c20  in ("continue", 
+00016ec0: 2263 6f6e 7469 6e75 655f 7261 6e64 6f6d  "continue_random
+00016ed0: 2229 3a0d 0a20 2020 2020 2020 2020 2020  "):..           
+00016ee0: 2069 6620 6d73 6720 3d3d 2022 636f 6e74   if msg == "cont
+00016ef0: 696e 7565 5f72 616e 646f 6d22 3a0d 0a20  inue_random":.. 
+00016f00: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+00016f10: 6e6e 6572 5f63 6f6c 6c65 6374 6f72 2e69  nner_collector.i
+00016f20: 6e69 745f 7261 6e64 6f6d 5f66 7261 6d65  nit_random_frame
+00016f30: 7320 3d20 666c 6f61 7428 2269 6e66 2229  s = float("inf")
+00016f40: 0d0a 2020 2020 2020 2020 2020 2020 656c  ..            el
+00016f50: 7365 3a0d 0a20 2020 2020 2020 2020 2020  se:..           
+00016f60: 2020 2020 2069 6e6e 6572 5f63 6f6c 6c65       inner_colle
+00016f70: 6374 6f72 2e69 6e69 745f 7261 6e64 6f6d  ctor.init_random
+00016f80: 5f66 7261 6d65 7320 3d20 2d31 0d0a 0d0a  _frames = -1....
+00016f90: 2020 2020 2020 2020 2020 2020 6420 3d20              d = 
+00016fa0: 6e65 7874 2864 635f 6974 6572 290d 0a20  next(dc_iter).. 
+00016fb0: 2020 2020 2020 2020 2020 2069 6620 7069             if pi
+00016fc0: 7065 5f63 6869 6c64 2e70 6f6c 6c28 5f4d  pe_child.poll(_M
+00016fd0: 494e 5f54 494d 454f 5554 293a 0d0a 2020  IN_TIMEOUT):..  
+00016fe0: 2020 2020 2020 2020 2020 2020 2020 2320                # 
+00016ff0: 696e 2074 6869 7320 6361 7365 2c20 6d61  in this case, ma
+00017000: 696e 2073 656e 6420 6120 6d65 7373 6167  in send a messag
+00017010: 6520 746f 2074 6865 2077 6f72 6b65 7220  e to the worker 
+00017020: 7768 696c 6520 6974 2077 6173 2062 7573  while it was bus
+00017030: 7920 636f 6c6c 6563 7469 6e67 2074 7261  y collecting tra
+00017040: 6a65 6374 6f72 6965 732e 0d0a 2020 2020  jectories...    
+00017050: 2020 2020 2020 2020 2020 2020 2320 496e              # In
+00017060: 2074 6861 7420 6361 7365 2c20 7765 2073   that case, we s
+00017070: 6b69 7020 7468 6520 636f 6c6c 6563 7465  kip the collecte
+00017080: 6420 7472 616a 6563 746f 7279 2061 6e64  d trajectory and
+00017090: 2067 6574 2074 6865 206d 6573 7361 6765   get the message
+000170a0: 2066 726f 6d20 6d61 696e 2e20 5468 6973   from main. This
+000170b0: 2069 7320 6661 7374 6572 2074 6861 6e0d   is faster than.
+000170c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000170d0: 2023 2073 656e 6469 6e67 2074 6865 2074   # sending the t
+000170e0: 7261 6a65 6374 6f72 7920 696e 2074 6865  rajectory in the
+000170f0: 2071 7565 7565 2075 6e74 696c 2074 696d   queue until tim
+00017100: 656f 7574 2077 6865 6e20 6974 2773 206e  eout when it's n
+00017110: 6576 6572 2067 6f69 6e67 2074 6f20 6265  ever going to be
+00017120: 2072 6563 6569 7665 642e 0d0a 2020 2020   received...    
+00017130: 2020 2020 2020 2020 2020 2020 636f 6e74              cont
+00017140: 696e 7565 0d0a 2020 2020 2020 2020 2020  inue..          
+00017150: 2020 6966 206a 203d 3d20 303a 0d0a 2020    if j == 0:..  
+00017160: 2020 2020 2020 2020 2020 2020 2020 7465                te
+00017170: 6e73 6f72 6469 6374 203d 2064 0d0a 2020  nsordict = d..  
+00017180: 2020 2020 2020 2020 2020 2020 2020 6966                if
+00017190: 2073 746f 7269 6e67 5f64 6576 6963 6520   storing_device 
+000171a0: 6973 206e 6f74 204e 6f6e 6520 616e 6420  is not None and 
+000171b0: 7465 6e73 6f72 6469 6374 2e64 6576 6963  tensordict.devic
+000171c0: 6520 213d 2073 746f 7269 6e67 5f64 6576  e != storing_dev
+000171d0: 6963 653a 0d0a 2020 2020 2020 2020 2020  ice:..          
+000171e0: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
+000171f0: 5275 6e74 696d 6545 7272 6f72 280d 0a20  RuntimeError(.. 
+00017200: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017210: 2020 2020 2020 2066 2265 7870 6563 7465         f"expecte
+00017220: 6420 6465 7669 6365 2074 6f20 6265 207b  d device to be {
+00017230: 7374 6f72 696e 675f 6465 7669 6365 7d20  storing_device} 
+00017240: 6275 7420 676f 7420 7b74 656e 736f 7264  but got {tensord
+00017250: 6963 742e 6465 7669 6365 7d22 0d0a 2020  ict.device}"..  
+00017260: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017270: 2020 290d 0a20 2020 2020 2020 2020 2020    )..           
+00017280: 2020 2020 2074 656e 736f 7264 6963 742e       tensordict.
+00017290: 7368 6172 655f 6d65 6d6f 7279 5f28 290d  share_memory_().
+000172a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000172b0: 2064 6174 6120 3d20 2874 656e 736f 7264   data = (tensord
+000172c0: 6963 742c 2069 6478 290d 0a20 2020 2020  ict, idx)..     
+000172d0: 2020 2020 2020 2065 6c73 653a 0d0a 2020         else:..  
+000172e0: 2020 2020 2020 2020 2020 2020 2020 6966                if
+000172f0: 2064 2069 7320 6e6f 7420 7465 6e73 6f72   d is not tensor
+00017300: 6469 6374 3a0d 0a20 2020 2020 2020 2020  dict:..         
+00017310: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+00017320: 2052 756e 7469 6d65 4572 726f 7228 0d0a   RuntimeError(..
+00017330: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017340: 2020 2020 2020 2020 2253 796e 6344 6174          "SyncDat
+00017350: 6143 6f6c 6c65 6374 6f72 2073 686f 756c  aCollector shoul
+00017360: 6420 7265 7475 726e 2074 6865 2073 616d  d return the sam
+00017370: 6520 7465 6e73 6f72 6469 6374 206d 6f64  e tensordict mod
+00017380: 6966 6965 6420 696e 2d70 6c61 6365 2e22  ified in-place."
+00017390: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+000173a0: 2020 2020 2020 290d 0a20 2020 2020 2020        )..       
+000173b0: 2020 2020 2020 2020 2064 6174 6120 3d20           data = 
+000173c0: 6964 7820 2023 2066 6c61 6720 7468 6520  idx  # flag the 
+000173d0: 776f 726b 6572 2074 6861 7420 6861 7320  worker that has 
+000173e0: 7365 6e74 2069 7473 2064 6174 610d 0a20  sent its data.. 
+000173f0: 2020 2020 2020 2020 2020 2074 7279 3a0d             try:.
+00017400: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00017410: 2071 7565 7565 5f6f 7574 2e70 7574 2828   queue_out.put((
+00017420: 6461 7461 2c20 6a29 2c20 7469 6d65 6f75  data, j), timeou
+00017430: 743d 5f54 494d 454f 5554 290d 0a20 2020  t=_TIMEOUT)..   
+00017440: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+00017450: 7665 7262 6f73 653a 0d0a 2020 2020 2020  verbose:..      
+00017460: 2020 2020 2020 2020 2020 2020 2020 7072                pr
+00017470: 696e 7428 6622 776f 726b 6572 207b 6964  int(f"worker {id
+00017480: 787d 2073 7563 6365 7373 6675 6c6c 7920  x} successfully 
+00017490: 7365 6e74 2064 6174 6122 290d 0a20 2020  sent data")..   
+000174a0: 2020 2020 2020 2020 2020 2020 206a 202b               j +
+000174b0: 3d20 310d 0a20 2020 2020 2020 2020 2020  = 1..           
+000174c0: 2020 2020 2068 6173 5f74 696d 6564 5f6f       has_timed_o
+000174d0: 7574 203d 2046 616c 7365 0d0a 2020 2020  ut = False..    
+000174e0: 2020 2020 2020 2020 2020 2020 636f 6e74              cont
+000174f0: 696e 7565 0d0a 2020 2020 2020 2020 2020  inue..          
+00017500: 2020 6578 6365 7074 2071 7565 7565 2e46    except queue.F
+00017510: 756c 6c3a 0d0a 2020 2020 2020 2020 2020  ull:..          
+00017520: 2020 2020 2020 6966 2076 6572 626f 7365        if verbose
+00017530: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
+00017540: 2020 2020 2020 2070 7269 6e74 2866 2277         print(f"w
+00017550: 6f72 6b65 7220 7b69 6478 7d20 6861 7320  orker {idx} has 
+00017560: 7469 6d65 6420 6f75 7422 290d 0a20 2020  timed out")..   
+00017570: 2020 2020 2020 2020 2020 2020 2068 6173               has
+00017580: 5f74 696d 6564 5f6f 7574 203d 2054 7275  _timed_out = Tru
+00017590: 650d 0a20 2020 2020 2020 2020 2020 2020  e..             
+000175a0: 2020 2063 6f6e 7469 6e75 650d 0a0d 0a20     continue.... 
+000175b0: 2020 2020 2020 2065 6c69 6620 6d73 6720         elif msg 
+000175c0: 3d3d 2022 7570 6461 7465 223a 0d0a 2020  == "update":..  
+000175d0: 2020 2020 2020 2020 2020 696e 6e65 725f            inner_
+000175e0: 636f 6c6c 6563 746f 722e 7570 6461 7465  collector.update
+000175f0: 5f70 6f6c 6963 795f 7765 6967 6874 735f  _policy_weights_
+00017600: 2829 0d0a 2020 2020 2020 2020 2020 2020  ()..            
+00017610: 7069 7065 5f63 6869 6c64 2e73 656e 6428  pipe_child.send(
+00017620: 286a 2c20 2275 7064 6174 6564 2229 290d  (j, "updated")).
+00017630: 0a20 2020 2020 2020 2020 2020 2068 6173  .            has
+00017640: 5f74 696d 6564 5f6f 7574 203d 2046 616c  _timed_out = Fal
+00017650: 7365 0d0a 2020 2020 2020 2020 2020 2020  se..            
+00017660: 636f 6e74 696e 7565 0d0a 0d0a 2020 2020  continue....    
+00017670: 2020 2020 656c 6966 206d 7367 203d 3d20      elif msg == 
+00017680: 2273 6565 6422 3a0d 0a20 2020 2020 2020  "seed":..       
+00017690: 2020 2020 2064 6174 615f 696e 2c20 7374       data_in, st
+000176a0: 6174 6963 5f73 6565 6420 3d20 6461 7461  atic_seed = data
+000176b0: 5f69 6e0d 0a20 2020 2020 2020 2020 2020  _in..           
+000176c0: 206e 6577 5f73 6565 6420 3d20 696e 6e65   new_seed = inne
+000176d0: 725f 636f 6c6c 6563 746f 722e 7365 745f  r_collector.set_
+000176e0: 7365 6564 2864 6174 615f 696e 2c20 7374  seed(data_in, st
+000176f0: 6174 6963 5f73 6565 643d 7374 6174 6963  atic_seed=static
+00017700: 5f73 6565 6429 0d0a 2020 2020 2020 2020  _seed)..        
+00017710: 2020 2020 746f 7263 682e 6d61 6e75 616c      torch.manual
+00017720: 5f73 6565 6428 6461 7461 5f69 6e29 0d0a  _seed(data_in)..
+00017730: 2020 2020 2020 2020 2020 2020 6e70 2e72              np.r
+00017740: 616e 646f 6d2e 7365 6564 2864 6174 615f  andom.seed(data_
+00017750: 696e 290d 0a20 2020 2020 2020 2020 2020  in)..           
+00017760: 2070 6970 655f 6368 696c 642e 7365 6e64   pipe_child.send
+00017770: 2828 6e65 775f 7365 6564 2c20 2273 6565  ((new_seed, "see
+00017780: 6465 6422 2929 0d0a 2020 2020 2020 2020  ded"))..        
+00017790: 2020 2020 6861 735f 7469 6d65 645f 6f75      has_timed_ou
+000177a0: 7420 3d20 4661 6c73 650d 0a20 2020 2020  t = False..     
+000177b0: 2020 2020 2020 2063 6f6e 7469 6e75 650d         continue.
+000177c0: 0a0d 0a20 2020 2020 2020 2065 6c69 6620  ...        elif 
+000177d0: 6d73 6720 3d3d 2022 7265 7365 7422 3a0d  msg == "reset":.
+000177e0: 0a20 2020 2020 2020 2020 2020 2069 6e6e  .            inn
+000177f0: 6572 5f63 6f6c 6c65 6374 6f72 2e72 6573  er_collector.res
+00017800: 6574 2829 0d0a 2020 2020 2020 2020 2020  et()..          
+00017810: 2020 7069 7065 5f63 6869 6c64 2e73 656e    pipe_child.sen
+00017820: 6428 286a 2c20 2272 6573 6574 2229 290d  d((j, "reset")).
+00017830: 0a20 2020 2020 2020 2020 2020 2063 6f6e  .            con
+00017840: 7469 6e75 650d 0a0d 0a20 2020 2020 2020  tinue....       
+00017850: 2065 6c69 6620 6d73 6720 3d3d 2022 7374   elif msg == "st
+00017860: 6174 655f 6469 6374 223a 0d0a 2020 2020  ate_dict":..    
+00017870: 2020 2020 2020 2020 7374 6174 655f 6469          state_di
+00017880: 6374 203d 2069 6e6e 6572 5f63 6f6c 6c65  ct = inner_colle
+00017890: 6374 6f72 2e73 7461 7465 5f64 6963 7428  ctor.state_dict(
+000178a0: 290d 0a20 2020 2020 2020 2020 2020 2023  )..            #
+000178b0: 2073 656e 6420 7374 6174 655f 6469 6374   send state_dict
+000178c0: 2074 6f20 6370 7520 6669 7273 740d 0a20   to cpu first.. 
+000178d0: 2020 2020 2020 2020 2020 2073 7461 7465             state
+000178e0: 5f64 6963 7420 3d20 7265 6375 7273 6976  _dict = recursiv
+000178f0: 655f 6d61 705f 746f 5f63 7075 2873 7461  e_map_to_cpu(sta
+00017900: 7465 5f64 6963 7429 0d0a 2020 2020 2020  te_dict)..      
+00017910: 2020 2020 2020 7069 7065 5f63 6869 6c64        pipe_child
+00017920: 2e73 656e 6428 2873 7461 7465 5f64 6963  .send((state_dic
+00017930: 742c 2022 7374 6174 655f 6469 6374 2229  t, "state_dict")
+00017940: 290d 0a20 2020 2020 2020 2020 2020 2068  )..            h
+00017950: 6173 5f74 696d 6564 5f6f 7574 203d 2046  as_timed_out = F
+00017960: 616c 7365 0d0a 2020 2020 2020 2020 2020  alse..          
+00017970: 2020 636f 6e74 696e 7565 0d0a 0d0a 2020    continue....  
+00017980: 2020 2020 2020 656c 6966 206d 7367 203d        elif msg =
+00017990: 3d20 226c 6f61 645f 7374 6174 655f 6469  = "load_state_di
+000179a0: 6374 223a 0d0a 2020 2020 2020 2020 2020  ct":..          
+000179b0: 2020 7374 6174 655f 6469 6374 203d 2064    state_dict = d
+000179c0: 6174 615f 696e 0d0a 2020 2020 2020 2020  ata_in..        
+000179d0: 2020 2020 696e 6e65 725f 636f 6c6c 6563      inner_collec
+000179e0: 746f 722e 6c6f 6164 5f73 7461 7465 5f64  tor.load_state_d
+000179f0: 6963 7428 7374 6174 655f 6469 6374 290d  ict(state_dict).
+00017a00: 0a20 2020 2020 2020 2020 2020 2070 6970  .            pip
+00017a10: 655f 6368 696c 642e 7365 6e64 2828 6a2c  e_child.send((j,
+00017a20: 2022 6c6f 6164 6564 2229 290d 0a20 2020   "loaded"))..   
+00017a30: 2020 2020 2020 2020 2068 6173 5f74 696d           has_tim
+00017a40: 6564 5f6f 7574 203d 2046 616c 7365 0d0a  ed_out = False..
+00017a50: 2020 2020 2020 2020 2020 2020 636f 6e74              cont
+00017a60: 696e 7565 0d0a 0d0a 2020 2020 2020 2020  inue....        
+00017a70: 656c 6966 206d 7367 203d 3d20 2263 6c6f  elif msg == "clo
+00017a80: 7365 223a 0d0a 2020 2020 2020 2020 2020  se":..          
+00017a90: 2020 6465 6c20 7465 6e73 6f72 6469 6374    del tensordict
+00017aa0: 2c20 6461 7461 2c20 642c 2064 6174 615f  , data, d, data_
+00017ab0: 696e 0d0a 2020 2020 2020 2020 2020 2020  in..            
+00017ac0: 696e 6e65 725f 636f 6c6c 6563 746f 722e  inner_collector.
+00017ad0: 7368 7574 646f 776e 2829 0d0a 2020 2020  shutdown()..    
+00017ae0: 2020 2020 2020 2020 6465 6c20 696e 6e65          del inne
+00017af0: 725f 636f 6c6c 6563 746f 722c 2064 635f  r_collector, dc_
+00017b00: 6974 6572 0d0a 2020 2020 2020 2020 2020  iter..          
+00017b10: 2020 7069 7065 5f63 6869 6c64 2e73 656e    pipe_child.sen
+00017b20: 6428 2263 6c6f 7365 6422 290d 0a20 2020  d("closed")..   
+00017b30: 2020 2020 2020 2020 2069 6620 7665 7262           if verb
+00017b40: 6f73 653a 0d0a 2020 2020 2020 2020 2020  ose:..          
+00017b50: 2020 2020 2020 7072 696e 7428 6622 636f        print(f"co
+00017b60: 6c6c 6563 746f 7220 7b69 6478 7d20 636c  llector {idx} cl
+00017b70: 6f73 6564 2229 0d0a 2020 2020 2020 2020  osed")..        
+00017b80: 2020 2020 6272 6561 6b0d 0a0d 0a20 2020      break....   
+00017b90: 2020 2020 2065 6c73 653a 0d0a 2020 2020       else:..    
+00017ba0: 2020 2020 2020 2020 7261 6973 6520 4578          raise Ex
+00017bb0: 6365 7074 696f 6e28 6622 556e 7265 636f  ception(f"Unreco
+00017bc0: 676e 697a 6564 206d 6573 7361 6765 207b  gnized message {
+00017bd0: 6d73 677d 2229 0d0a                      msg}")..
```

## torchrl/collectors/distributed/__init__.py

```diff
@@ -1,9 +1,10 @@
 # Copyright (c) Meta Platforms, Inc. and affiliates.
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
 
 from .generic import DEFAULT_SLURM_CONF, DistributedDataCollector
+from .ray import RayCollector
 from .rpc import RPCDataCollector
 from .sync import DistributedSyncDataCollector
 from .utils import submitit_delayed_launcher
```

## torchrl/collectors/distributed/generic.py

```diff
@@ -12,29 +12,31 @@
 from datetime import timedelta
 from typing import OrderedDict
 
 import torch.cuda
 from tensordict import TensorDict
 from torch import multiprocessing as mp, nn
 
+from torchrl._utils import VERBOSE
 from torchrl.collectors import MultiaSyncDataCollector
 from torchrl.collectors.collectors import (
-    _DataCollector,
-    DEFAULT_EXPLORATION_MODE,
+    DataCollectorBase,
+    DEFAULT_EXPLORATION_TYPE,
     MultiSyncDataCollector,
     SyncDataCollector,
 )
 from torchrl.collectors.distributed.default_configs import (
     DEFAULT_SLURM_CONF,
     MAX_TIME_TO_CONNECT,
     TCP_PORT,
 )
 from torchrl.collectors.utils import split_trajectories
 from torchrl.data.utils import CloudpickleWrapper
 from torchrl.envs import EnvBase, EnvCreator
+from torchrl.envs.utils import _convert_exploration_type
 
 SUBMITIT_ERR = None
 try:
     import submitit
 
     _has_submitit = True
 except ModuleNotFoundError as err:
@@ -43,22 +45,26 @@
 
 
 def _node_init_dist(rank, world_size, backend, rank0_ip, tcpport, verbose):
     os.environ["MASTER_ADDR"] = str(rank0_ip)
     os.environ["MASTER_PORT"] = str(tcpport)
 
     if verbose:
-        print("Rank0 IP address:", rank0_ip, "\ttcp port:", tcpport)
-        print(f"node with rank {rank} -- launching distributed")
+        print(
+            f"Rank0 IP address: '{rank0_ip}' \ttcp port: '{tcpport}', backend={backend}."
+        )
+        print(
+            f"node with rank {rank} with world_size {world_size} -- launching distributed"
+        )
     torch.distributed.init_process_group(
         backend,
         rank=rank,
         world_size=world_size,
         timeout=timedelta(MAX_TIME_TO_CONNECT),
-        # init_method=f"tcp://{rank0_ip}:{tcpport}",
+        init_method=f"tcp://{rank0_ip}:{tcpport}",
     )
     if verbose:
         print(f"Connected!\nNode with rank {rank} -- creating store")
     # The store carries instructions for the node
     _store = torch.distributed.TCPStore(
         host_name=rank0_ip,
         port=tcpport + 1,
@@ -234,22 +240,22 @@
             raise RuntimeError(f"Instruction {instruction} is not recognised")
     if not collector.closed:
         collector.shutdown()
     del collector
     return
 
 
-class DistributedDataCollector(_DataCollector):
+class DistributedDataCollector(DataCollectorBase):
     """A distributed data collector with torch.distributed backend.
 
     Supports sync and async data collection.
 
     Args:
         create_env_fn (Callable or List[Callabled]): list of Callables, each returning an
-            instance of :class:`torchrl.envs.EnvBase`.
+            instance of :class:`~torchrl.envs.EnvBase`.
         policy (Callable): Policy to be executed in the environment.
             Must accept :class:`tensordict.tensordict.TensorDictBase` object as input.
             If ``None`` is provided, the policy used will be a
             :class:`RandomPolicy` instance with the environment
             ``action_spec``.
         frames_per_batch (int): A keyword-only argument representing the total
             number of elements in a batch.
@@ -271,36 +277,36 @@
             intended to be used in offline/model-based settings, where a
             batch of random trajectories can be used to initialize training.
             Defaults to ``-1`` (i.e. no random frames).
         reset_at_each_iter (bool, optional): Whether environments should be reset
             at the beginning of a batch collection.
             Defaults to ``False``.
         postproc (Callable, optional): A post-processing transform, such as
-            a :class:`torchrl.envs.Transform` or a :class:`torchrl.data.postprocs.MultiStep`
+            a :class:`~torchrl.envs.Transform` or a :class:`~torchrl.data.postprocs.MultiStep`
             instance.
             Defaults to ``None``.
         split_trajs (bool, optional): Boolean indicating whether the resulting
             TensorDict should be split according to the trajectories.
-            See :func:`torchrl.collectors.utils.split_trajectories` for more
+            See :func:`~torchrl.collectors.utils.split_trajectories` for more
             information.
             Defaults to ``False``.
-        exploration_mode (str, optional): interaction mode to be used when
+        exploration_type (str, optional): interaction mode to be used when
             collecting data. Must be one of ``"random"``, ``"mode"`` or
             ``"mean"``.
             Defaults to ``"random"``
         reset_when_done (bool, optional): if ``True`` (default), an environment
             that return a ``True`` value in its ``"done"`` or ``"truncated"``
             entry will be reset at the corresponding indices.
         collector_class (type or str, optional): a collector class for the remote node. Can be
-            :class:`torchrl.collectors.SyncDataCollector`,
-            :class:`torchrl.collectors.MultiSyncDataCollector`,
-            :class:`torchrl.collectors.MultiaSyncDataCollector`
+            :class:`~torchrl.collectors.SyncDataCollector`,
+            :class:`~torchrl.collectors.MultiSyncDataCollector`,
+            :class:`~torchrl.collectors.MultiaSyncDataCollector`
             or a derived class of these. The strings "single", "sync" and
             "async" correspond to respective class.
-            Defaults to :class:`torchrl.collectors.SyncDataCollector`.
+            Defaults to :class:`~torchrl.collectors.SyncDataCollector`.
         collector_kwargs (dict or list, optional): a dictionary of parameters to be passed to the
             remote data-collector. If a list is provided, each element will
             correspond to an individual set of keyword arguments for the
             dedicated collector.
         num_workers_per_collector (int, optional): the number of copies of the
             env constructor that is to be used on the remote nodes.
             Defaults to 1 (a single env per collector).
@@ -323,15 +329,15 @@
         update_after_each_batch (bool, optional): if ``True``, the weights will
             be updated after each collection. For ``sync=True``, this means that
             all workers will see their weights updated. For ``sync=False``,
             only the worker from which the data has been gathered will be
             updated.
             Defaults to ``False``, ie. updates have to be executed manually
             through
-            :meth:`torchrl.collectors.distributed.DistributedDataCollector.update_policy_weights_`.
+            :meth:`~torchrl.collectors.distributed.DistributedDataCollector.update_policy_weights_`.
         max_weight_update_interval (int, optional): the maximum number of
             batches that can be collected before the policy weights of a worker
             is updated.
             For sync collections, this parameter is overwritten by ``update_after_each_batch``.
             For async collections, it may be that one worker has not seen its
             parameters being updated for a certain time even if ``update_after_each_batch``
             is turned on.
@@ -346,42 +352,47 @@
             To find more about submitit, visit
             https://github.com/facebookincubator/submitit and check our examples
             to learn more.
             Defaults to ``"submitit"``.
         tcp_port (int, optional): the TCP port to be used. Defaults to 10003.
     """
 
-    _VERBOSE = False  # for debugging
+    _VERBOSE = VERBOSE  # for debugging
 
     def __init__(
         self,
         create_env_fn,
         policy,
         *,
         frames_per_batch,
         total_frames,
         max_frames_per_traj=-1,
         init_random_frames=-1,
         reset_at_each_iter=False,
         postproc=None,
         split_trajs=False,
-        exploration_mode=DEFAULT_EXPLORATION_MODE,
+        exploration_type=DEFAULT_EXPLORATION_TYPE,
+        exploration_mode=None,
         reset_when_done=True,
         collector_class=SyncDataCollector,
         collector_kwargs=None,
         num_workers_per_collector=1,
         sync=False,
         slurm_kwargs=None,
         backend="gloo",
         storing_device="cpu",
         update_after_each_batch=False,
         max_weight_update_interval=-1,
         launcher="submitit",
         tcp_port=None,
     ):
+        exploration_type = _convert_exploration_type(
+            exploration_mode=exploration_mode, exploration_type=exploration_type
+        )
+
         if collector_class == "async":
             collector_class = MultiaSyncDataCollector
         elif collector_class == "sync":
             collector_class = MultiSyncDataCollector
         elif collector_class == "single":
             collector_class = SyncDataCollector
         self.collector_class = collector_class
@@ -420,18 +431,17 @@
                 )
             self._frames_per_batch_corrected = self.frames_per_batch // self.num_workers
         else:
             self._frames_per_batch_corrected = self.frames_per_batch
 
         self.num_workers_per_collector = num_workers_per_collector
         self.total_frames = total_frames
-        if slurm_kwargs is None:
-            self.slurm_kwargs = copy(DEFAULT_SLURM_CONF)
-        else:
-            self.slurm_kwargs = copy(DEFAULT_SLURM_CONF).update(slurm_kwargs)
+        self.slurm_kwargs = copy(DEFAULT_SLURM_CONF)
+        if slurm_kwargs is not None:
+            self.slurm_kwargs.update(slurm_kwargs)
         collector_kwargs = collector_kwargs if collector_kwargs is not None else {}
         self.collector_kwargs = (
             deepcopy(collector_kwargs)
             if isinstance(collector_kwargs, (list, tuple))
             else [copy(collector_kwargs) for _ in range(self.num_workers)]
         )
 
@@ -446,15 +456,15 @@
                     "async distributed data collection with init_random_frames > 0 "
                     "may have unforeseen consequences as we do not control that once "
                     "non-random data is being collected all nodes are returning non-random data. "
                     "If this is a feature that you feel should be fixed, please raise an issue on "
                     "torchrl's repo."
                 )
             collector_kwarg["reset_at_each_iter"] = reset_at_each_iter
-            collector_kwarg["exploration_mode"] = exploration_mode
+            collector_kwarg["exploration_type"] = exploration_type
             collector_kwarg["reset_when_done"] = reset_when_done
 
         if postproc is not None and hasattr(postproc, "to"):
             self.postproc = postproc.to(self.storing_device)
         else:
             self.postproc = postproc
         self.split_trajs = split_trajs
@@ -469,17 +479,20 @@
     def _init_master_dist(
         self,
         world_size,
         backend,
     ):
         if self._VERBOSE:
             print(
-                f"launching main node with tcp port {self.tcp_port} and "
-                f"IP {self.IPAddr}."
+                f"launching main node with tcp port '{self.tcp_port}' and "
+                f"IP '{self.IPAddr}'. rank: 0, world_size: {world_size}, backend={backend}."
             )
+        os.environ["MASTER_ADDR"] = str(self.IPAddr)
+        os.environ["MASTER_PORT"] = str(self.tcp_port)
+
         TCP_PORT = self.tcp_port
         torch.distributed.init_process_group(
             backend,
             rank=0,
             world_size=world_size,
             timeout=timedelta(MAX_TIME_TO_CONNECT),
             init_method=f"tcp://{self.IPAddr}:{TCP_PORT}",
@@ -616,16 +629,16 @@
             ),
         )
         job.start()
         return job
 
     def _init_workers(self):
 
-        hostname = socket.gethostname()
         if self.launcher != "mp":
+            hostname = socket.gethostname()
             IPAddr = socket.gethostbyname(hostname)
         else:
             IPAddr = "localhost"
         if self._VERBOSE:
             print("Server IP address:", IPAddr)
         self.IPAddr = IPAddr
         os.environ["MASTER_ADDR"] = str(self.IPAddr)
```

## torchrl/collectors/distributed/rpc.py

```diff
@@ -16,47 +16,49 @@
 from torchrl.collectors.distributed.default_configs import (
     DEFAULT_TENSORPIPE_OPTIONS,
     IDLE_TIMEOUT,
     TCP_PORT,
 )
 from torchrl.collectors.utils import split_trajectories
 from torchrl.data.utils import CloudpickleWrapper
+from torchrl.envs.utils import _convert_exploration_type
 
 SUBMITIT_ERR = None
 try:
     import submitit
 
     _has_submitit = True
 except ModuleNotFoundError as err:
     _has_submitit = False
     SUBMITIT_ERR = err
 import torch.cuda
 from tensordict import TensorDict
 from torch import multiprocessing as mp, nn
 
 from torch.distributed import rpc
+from torchrl._utils import VERBOSE
 
 from torchrl.collectors import MultiaSyncDataCollector
 from torchrl.collectors.collectors import (
-    _DataCollector,
-    DEFAULT_EXPLORATION_MODE,
+    DataCollectorBase,
+    DEFAULT_EXPLORATION_TYPE,
     MultiSyncDataCollector,
     SyncDataCollector,
 )
 from torchrl.envs import EnvBase, EnvCreator
 
 
 def _rpc_init_collection_node(
     rank,
     rank0_ip,
     tcp_port,
     world_size,
     visible_device,
     tensorpipe_options,
-    verbose=False,
+    verbose=VERBOSE,
 ):
     os.environ["MASTER_ADDR"] = str(rank0_ip)
     os.environ["MASTER_PORT"] = str(tcp_port)
 
     if isinstance(visible_device, list):
         pass
     elif isinstance(visible_device, (str, int, torch.device)):
@@ -80,22 +82,22 @@
         backend=rpc.BackendType.TENSORPIPE,
         rpc_backend_options=options,
         world_size=world_size,
     )
     rpc.shutdown()
 
 
-class RPCDataCollector(_DataCollector):
+class RPCDataCollector(DataCollectorBase):
     """An RPC-based distributed data collector.
 
     Supports sync and async data collection.
 
     Args:
         create_env_fn (Callable or List[Callabled]): list of Callables, each returning an
-            instance of :class:`torchrl.envs.EnvBase`.
+            instance of :class:`~torchrl.envs.EnvBase`.
         policy (Callable, optional): Instance of TensorDictModule class.
             Must accept TensorDictBase object as input.
             If ``None`` is provided, the policy used will be a
             :class:`RandomPolicy` instance with the environment
             ``action_spec``.
         frames_per_batch (int): A keyword-only argument representing the
             total number of elements in a batch.
@@ -117,44 +119,45 @@
             intended to be used in offline/model-based settings, where a
             batch of random trajectories can be used to initialize training.
             Defaults to ``-1`` (i.e. no random frames).
         reset_at_each_iter (bool, optional): Whether environments should be reset
             at the beginning of a batch collection.
             Defaults to ``False``.
         postproc (Callable, optional): A post-processing transform, such as
-            a :class:`torchrl.envs.Transform` or a :class:`torchrl.data.postprocs.MultiStep`
+            a :class:`~torchrl.envs.Transform` or a :class:`~torchrl.data.postprocs.MultiStep`
             instance.
             Defaults to ``None``.
         split_trajs (bool, optional): Boolean indicating whether the resulting
             TensorDict should be split according to the trajectories.
-            See :func:`torchrl.collectors.utils.split_trajectories` for more
+            See :func:`~torchrl.collectors.utils.split_trajectories` for more
             information.
             Defaults to ``False``.
-        exploration_mode (str, optional): interaction mode to be used when
-            collecting data. Must be one of ``"random"``, ``"mode"`` or
-            ``"mean"``.
-            Defaults to ``"random"``
+        exploration_type (str, optional): interaction mode to be used when
+            collecting data. Must be one of ``ExplorationType.RANDOM``,
+            ``ExplorationType.MODE`` or
+            ``ExplorationType.MEAN``.
+            Defaults to ``ExplorationType.RANDOM``
         reset_when_done (bool, optional): if ``True`` (default), an environment
             that return a ``True`` value in its ``"done"`` or ``"truncated"``
             entry will be reset at the corresponding indices.
         collector_class (type or str, optional): a collector class for the remote node. Can be
-            :class:`torchrl.collectors.SyncDataCollector`,
-            :class:`torchrl.collectors.MultiSyncDataCollector`,
-            :class:`torchrl.collectors.MultiaSyncDataCollector`
+            :class:`~torchrl.collectors.SyncDataCollector`,
+            :class:`~torchrl.collectors.MultiSyncDataCollector`,
+            :class:`~torchrl.collectors.MultiaSyncDataCollector`
             or a derived class of these. The strings "single", "sync" and
             "async" correspond to respective class.
-            Defaults to :class:`torchrl.collectors.SyncDataCollector`.
+            Defaults to :class:`~torchrl.collectors.SyncDataCollector`.
 
             .. note::
 
               Support for :class:`MultiSyncDataCollector` and :class:`MultiaSyncDataCollector`
-              is experimental, and :class:`torchrl.collectors.SyncDataCollector`
+              is experimental, and :class:`~torchrl.collectors.SyncDataCollector`
               should always be preferred. If multiple simultaneous environment
               need to be executed on a single node, consider using a
-              :class:`torchrl.envs.ParallelEnv` instance.
+              :class:`~torchrl.envs.ParallelEnv` instance.
 
         collector_kwargs (dict or list, optional): a dictionary of parameters to be passed to the
             remote data-collector. If a list is provided, each element will
             correspond to an individual set of keyword arguments for the
             dedicated collector.
         num_workers_per_collector (int, optional): the number of copies of the
             env constructor that is to be used on the remote nodes.
@@ -175,15 +178,15 @@
         update_after_each_batch (bool, optional): if ``True``, the weights will
             be updated after each collection. For ``sync=True``, this means that
             all workers will see their weights updated. For ``sync=False``,
             only the worker from which the data has been gathered will be
             updated.
             Defaults to ``False``, ie. updates have to be executed manually
             through
-            :meth:`torchrl.collectors.distributed.DistributedDataCollector.update_policy_weights_`.
+            :meth:`~torchrl.collectors.distributed.DistributedDataCollector.update_policy_weights_`.
         max_weight_update_interval (int, optional): the maximum number of
             batches that can be collected before the policy weights of a worker
             is updated.
             For sync collections, this parameter is overwritten by ``update_after_each_batch``.
             For async collections, it may be that one worker has not seen its
             parameters being updated for a certain time even if ``update_after_each_batch``
             is turned on.
@@ -201,43 +204,47 @@
             list of the same length as the number of nodes containing the
             device used to pass data to main.
         tensorpipe_options (dict, optional): a dictionary of keyword argument
             to pass to :class:`torch.distributed.rpc.TensorPipeRpcBackendOption`.
 
     """
 
-    _VERBOSE = False  # for debugging
+    _VERBOSE = VERBOSE  # for debugging
 
     def __init__(
         self,
         create_env_fn,
         policy,
         *,
         frames_per_batch,
         total_frames,
         max_frames_per_traj=-1,
         init_random_frames=-1,
         reset_at_each_iter=False,
         postproc=None,
         split_trajs=False,
-        exploration_mode=DEFAULT_EXPLORATION_MODE,
+        exploration_type=DEFAULT_EXPLORATION_TYPE,
+        exploration_mode=None,
         reset_when_done=True,
         collector_class=SyncDataCollector,
         collector_kwargs=None,
         num_workers_per_collector=1,
         sync=False,
         slurm_kwargs=None,
         storing_device="cpu",
         update_after_each_batch=False,
         max_weight_update_interval=-1,
         launcher="submitit",
         tcp_port=None,
         visible_devices=None,
         tensorpipe_options=None,
     ):
+        exploration_type = _convert_exploration_type(
+            exploration_mode=exploration_mode, exploration_type=exploration_type
+        )
         if collector_class == "async":
             collector_class = MultiaSyncDataCollector
         elif collector_class == "sync":
             collector_class = MultiSyncDataCollector
         elif collector_class == "single":
             collector_class = SyncDataCollector
         self.collector_class = collector_class
@@ -275,18 +282,18 @@
                 )
             self._frames_per_batch_corrected = self.frames_per_batch // self.num_workers
         else:
             self._frames_per_batch_corrected = self.frames_per_batch
 
         self.num_workers_per_collector = num_workers_per_collector
         self.total_frames = total_frames
-        if slurm_kwargs is None:
-            self.slurm_kwargs = copy(DEFAULT_SLURM_CONF)
-        else:
-            self.slurm_kwargs = copy(DEFAULT_SLURM_CONF).update(slurm_kwargs)
+        self.slurm_kwargs = copy(DEFAULT_SLURM_CONF)
+        if slurm_kwargs is not None:
+            self.slurm_kwargs.update(slurm_kwargs)
+
         collector_kwargs = collector_kwargs if collector_kwargs is not None else {}
         self.collector_kwargs = (
             deepcopy(collector_kwargs)
             if isinstance(collector_kwargs, (list, tuple))
             else [copy(collector_kwargs) for _ in range(self.num_workers)]
         )
 
@@ -301,15 +308,15 @@
                     "async distributed data collection with init_random_frames > 0 "
                     "may have unforeseen consequences as we do not control that once "
                     "non-random data is being collected all nodes are returning non-random data. "
                     "If this is a feature that you feel should be fixed, please raise an issue on "
                     "torchrl's repo."
                 )
             collector_kwarg["reset_at_each_iter"] = reset_at_each_iter
-            collector_kwarg["exploration_mode"] = exploration_mode
+            collector_kwarg["exploration_type"] = exploration_type
             collector_kwarg["reset_when_done"] = reset_when_done
 
         if postproc is not None and hasattr(postproc, "to"):
             self.postproc = postproc.to(self.storing_device)
         else:
             self.postproc = postproc
         self.split_trajs = split_trajs
```

## torchrl/collectors/distributed/sync.py

```diff
@@ -10,29 +10,31 @@
 from copy import copy, deepcopy
 from datetime import timedelta
 from typing import OrderedDict
 
 import torch.cuda
 from tensordict import TensorDict
 from torch import multiprocessing as mp, nn
+from torchrl._utils import VERBOSE
 
 from torchrl.collectors import MultiaSyncDataCollector
 from torchrl.collectors.collectors import (
-    _DataCollector,
-    DEFAULT_EXPLORATION_MODE,
+    DataCollectorBase,
+    DEFAULT_EXPLORATION_TYPE,
     MultiSyncDataCollector,
     SyncDataCollector,
 )
 from torchrl.collectors.distributed.default_configs import (
     DEFAULT_SLURM_CONF,
     MAX_TIME_TO_CONNECT,
 )
 from torchrl.collectors.utils import split_trajectories
 from torchrl.data.utils import CloudpickleWrapper
 from torchrl.envs import EnvBase, EnvCreator
+from torchrl.envs.utils import _convert_exploration_type
 
 SUBMITIT_ERR = None
 try:
     import submitit
 
     _has_submitit = True
 except ModuleNotFoundError as err:
@@ -50,15 +52,15 @@
     num_workers,
     env_make,
     policy,
     frames_per_batch,
     collector_kwargs,
     update_interval,
     total_frames,
-    verbose=False,
+    verbose=VERBOSE,
 ):
     os.environ["MASTER_ADDR"] = str(rank0_ip)
     os.environ["MASTER_PORT"] = str(tcpport)
 
     if verbose:
         print(f"node with rank {rank} -- creating collector of type {collector_class}")
     if not issubclass(collector_class, SyncDataCollector):
@@ -121,20 +123,20 @@
 
     if not collector.closed:
         collector.shutdown()
     del collector
     return
 
 
-class DistributedSyncDataCollector(_DataCollector):
+class DistributedSyncDataCollector(DataCollectorBase):
     """A distributed synchronous data collector with torch.distributed backend.
 
     Args:
         create_env_fn (Callable or List[Callabled]): list of Callables, each returning an
-            instance of :class:`torchrl.envs.EnvBase`.
+            instance of :class:`~torchrl.envs.EnvBase`.
         policy (Callable): Policy to be executed in the environment.
             Must accept :class:`tensordict.tensordict.TensorDictBase` object as input.
             If ``None`` is provided, the policy used will be a
             :class:`RandomPolicy` instance with the environment
             ``action_spec``.
         frames_per_batch (int): A keyword-only argument representing the total
             number of elements in a batch.
@@ -156,36 +158,36 @@
             intended to be used in offline/model-based settings, where a
             batch of random trajectories can be used to initialize training.
             Defaults to ``-1`` (i.e. no random frames).
         reset_at_each_iter (bool, optional): Whether environments should be reset
             at the beginning of a batch collection.
             Defaults to ``False``.
         postproc (Callable, optional): A post-processing transform, such as
-            a :class:`torchrl.envs.Transform` or a :class:`torchrl.data.postprocs.MultiStep`
+            a :class:`~torchrl.envs.Transform` or a :class:`~torchrl.data.postprocs.MultiStep`
             instance.
             Defaults to ``None``.
         split_trajs (bool, optional): Boolean indicating whether the resulting
             TensorDict should be split according to the trajectories.
-            See :func:`torchrl.collectors.utils.split_trajectories` for more
+            See :func:`~torchrl.collectors.utils.split_trajectories` for more
             information.
             Defaults to ``False``.
-        exploration_mode (str, optional): interaction mode to be used when
+        exploration_type (str, optional): interaction mode to be used when
             collecting data. Must be one of ``"random"``, ``"mode"`` or
             ``"mean"``.
             Defaults to ``"random"``
         reset_when_done (bool, optional): if ``True`` (default), an environment
             that return a ``True`` value in its ``"done"`` or ``"truncated"``
             entry will be reset at the corresponding indices.
         collector_class (type or str, optional): a collector class for the remote node. Can be
-            :class:`torchrl.collectors.SyncDataCollector`,
-            :class:`torchrl.collectors.MultiSyncDataCollector`,
-            :class:`torchrl.collectors.MultiaSyncDataCollector`
+            :class:`~torchrl.collectors.SyncDataCollector`,
+            :class:`~torchrl.collectors.MultiSyncDataCollector`,
+            :class:`~torchrl.collectors.MultiaSyncDataCollector`
             or a derived class of these. The strings "single", "sync" and
             "async" correspond to respective class.
-            Defaults to :class:`torchrl.collectors.SyncDataCollector`.
+            Defaults to :class:`~torchrl.collectors.SyncDataCollector`.
         collector_kwargs (dict or list, optional): a dictionary of parameters to be passed to the
             remote data-collector. If a list is provided, each element will
             correspond to an individual set of keyword arguments for the
             dedicated collector.
         num_workers_per_collector (int, optional): the number of copies of the
             env constructor that is to be used on the remote nodes.
             Defaults to 1 (a single env per collector).
@@ -222,27 +224,32 @@
         frames_per_batch,
         total_frames,
         max_frames_per_traj=-1,
         init_random_frames=-1,
         reset_at_each_iter=False,
         postproc=None,
         split_trajs=False,
-        exploration_mode=DEFAULT_EXPLORATION_MODE,
+        exploration_type=DEFAULT_EXPLORATION_TYPE,
+        exploration_mode=None,
         reset_when_done=True,
         collector_class=SyncDataCollector,
         collector_kwargs=None,
         num_workers_per_collector=1,
         slurm_kwargs=None,
         backend="gloo",
         storing_device="cpu",
         max_weight_update_interval=-1,
         update_interval=1,
         launcher="submitit",
         tcp_port=None,
     ):
+        exploration_type = _convert_exploration_type(
+            exploration_mode=exploration_mode, exploration_type=exploration_type
+        )
+
         if collector_class == "async":
             collector_class = MultiaSyncDataCollector
         elif collector_class == "sync":
             collector_class = MultiSyncDataCollector
         elif collector_class == "single":
             collector_class = SyncDataCollector
         self.collector_class = collector_class
@@ -278,33 +285,32 @@
                 f"Cannot dispatch {self.frames_per_batch} frames across {self.num_workers}. "
                 f"Consider using a number of frames per batch that is divisible by the number of workers."
             )
         self._frames_per_batch_corrected = self.frames_per_batch // self.num_workers
 
         self.num_workers_per_collector = num_workers_per_collector
         self.total_frames = total_frames
-        if slurm_kwargs is None:
-            self.slurm_kwargs = copy(DEFAULT_SLURM_CONF)
-        else:
-            self.slurm_kwargs = copy(DEFAULT_SLURM_CONF).update(slurm_kwargs)
+        self.slurm_kwargs = copy(DEFAULT_SLURM_CONF)
+        if slurm_kwargs is not None:
+            self.slurm_kwargs.update(slurm_kwargs)
         collector_kwargs = collector_kwargs if collector_kwargs is not None else {}
         self.collector_kwargs = (
             deepcopy(collector_kwargs)
             if isinstance(collector_kwargs, (list, tuple))
             else [copy(collector_kwargs) for _ in range(self.num_workers)]
         )
 
         # update collector kwargs
         for collector_kwarg in self.collector_kwargs:
             collector_kwarg["max_frames_per_traj"] = max_frames_per_traj
             collector_kwarg["init_random_frames"] = (
                 init_random_frames // self.num_workers
             )
             collector_kwarg["reset_at_each_iter"] = reset_at_each_iter
-            collector_kwarg["exploration_mode"] = exploration_mode
+            collector_kwarg["exploration_type"] = exploration_type
             collector_kwarg["reset_when_done"] = reset_when_done
 
         if postproc is not None and hasattr(postproc, "to"):
             self.postproc = postproc.to(self.storing_device)
         else:
             self.postproc = postproc
         self.split_trajs = split_trajs
```

## torchrl/collectors/distributed/utils.py

```diff
@@ -1,10 +1,11 @@
 import subprocess
 import time
 
+from torchrl._utils import VERBOSE
 from torchrl.collectors.distributed.default_configs import (
     DEFAULT_SLURM_CONF,
     DEFAULT_SLURM_CONF_MAIN,
     TCP_PORT,
 )
 from torchrl.collectors.distributed.generic import _distributed_init_delayed
 from torchrl.collectors.distributed.rpc import _rpc_init_collection_node
@@ -31,15 +32,17 @@
     Args:
         num_jobs (int): the number of collection jobs to be launched.
         framework (str, optional): the framework to use. Can be either ``"distributed"``
             or ``"rpc"``. ``"distributed"`` requires a :class:`~.DistributedDataCollector`
             collector whereas ``"rpc"`` requires a :class:`RPCDataCollector`.
             Defaults to ``"distributed"``.
         backend (str, optional): torch.distributed backend in case ``framework``
-            points to ``"distributed"``.
+            points to ``"distributed"``. This value must match the one passed to
+            the collector, otherwise main and satellite nodes will fail to
+            reach the rendezvous and hang forever (ie no exception will be raised!)
             Defaults to ``'gloo'``.
         tcpport (int or str, optional): the TCP port to use.
             Defaults to :obj:`torchrl.collectors.distributed.default_configs.TCP_PORT`
         submitit_main_conf (dict, optional): the main node configuration to be passed to submitit.
             Defaults to :obj:`torchrl.collectors.distributed.default_configs.DEFAULT_SLURM_CONF_MAIN`
         submitit_collection_conf (dict, optional): the configuration to be passed to submitit.
             Defaults to :obj:`torchrl.collectors.distributed.default_configs.DEFAULT_SLURM_CONF`
@@ -60,15 +63,15 @@
         ...         print(data)
         ...
         >>> if __name__ == "__main__":
         ...     main()
         ...
     """
 
-    _VERBOSE = False  # for debugging
+    _VERBOSE = VERBOSE  # for debugging
 
     def __init__(
         self,
         num_jobs,
         framework="distributed",
         backend="gloo",
         tcpport=TCP_PORT,
```

## torchrl/data/__init__.py

```diff
@@ -1,12 +1,13 @@
 # Copyright (c) Meta Platforms, Inc. and affiliates.
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
 
+from . import datasets
 from .postprocs import MultiStep
 from .replay_buffers import (
     LazyMemmapStorage,
     LazyTensorStorage,
     ListStorage,
     PrioritizedReplayBuffer,
     RemoteTensorDictReplayBuffer,
@@ -17,14 +18,16 @@
 )
 from .tensor_specs import (
     BinaryDiscreteTensorSpec,
     BoundedTensorSpec,
     CompositeSpec,
     DEVICE_TYPING,
     DiscreteTensorSpec,
+    LazyStackedCompositeSpec,
+    LazyStackedTensorSpec,
     MultiDiscreteTensorSpec,
     MultiOneHotDiscreteTensorSpec,
     OneHotDiscreteTensorSpec,
     TensorSpec,
     UnboundedContinuousTensorSpec,
     UnboundedDiscreteTensorSpec,
 )
```

## torchrl/data/tensor_specs.py

```diff
@@ -2,45 +2,73 @@
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
 
 from __future__ import annotations
 
 import abc
+import math
 import warnings
+from collections.abc import Iterable
 from copy import deepcopy
 from dataclasses import dataclass
+from functools import wraps
 from textwrap import indent
 from typing import (
     Any,
+    Callable,
     Dict,
+    Generic,
     ItemsView,
     KeysView,
     List,
     Optional,
     Sequence,
     Tuple,
+    TypeVar,
     Union,
     ValuesView,
 )
 
 import numpy as np
 import torch
 from tensordict.tensordict import TensorDict, TensorDictBase
+from tensordict.utils import _getitem_batch_size
 
 from torchrl._utils import get_binary_env_var
 
 DEVICE_TYPING = Union[torch.device, str, int]
 
 INDEX_TYPING = Union[int, torch.Tensor, np.ndarray, slice, List]
 
+SHAPE_INDEX_TYPING = Union[
+    int,
+    range,
+    List[int],
+    np.ndarray,
+    slice,
+    None,
+    torch.Tensor,
+    type(...),
+    Tuple[
+        int,
+        range,
+        List[int],
+        np.ndarray,
+        slice,
+        None,
+        torch.Tensor,
+        type(...),
+        Tuple[Any],
+    ],
+]
+
 # By default, we do not check that an obs is in the domain. THis should be done when validating the env beforehand
 _CHECK_SPEC_ENCODE = get_binary_env_var("CHECK_SPEC_ENCODE")
 
-
 _DEFAULT_SHAPE = torch.Size((1,))
 
 DEVICE_ERR_MSG = "device of empty CompositeSpec is not defined."
 
 
 def _default_dtype_and_device(
     dtype: Union[None, torch.dtype],
@@ -50,14 +78,222 @@
         dtype = torch.get_default_dtype()
     if device is None:
         device = torch.device("cpu")
     device = torch.device(device)
     return dtype, device
 
 
+def _validate_idx(shape: list[int], idx: int, axis: int = 0):
+    """Raise an IndexError if idx is out of bounds for shape[axis].
+
+    Args:
+        shape (list[int]): Input shape
+        idx (int): Index, may be negative
+        axis (int): Shape axis to check
+    """
+    if idx >= shape[axis] or idx < 0 and -idx > shape[axis]:
+        raise IndexError(
+            f"index {idx} is out of bounds for axis {axis} with size {shape[axis]}"
+        )
+
+
+def _validate_iterable(
+    idx: Iterable[Any], expected_type: type, iterable_classname: str
+):
+    """Raise an IndexError if the iterable contains a type different from the expected type or Iterable.
+
+    Args:
+        idx (Iterable[Any]): Iterable, may contain nested iterables
+        expected_type (type): Required item type in the Iterable (e.g. int)
+        iterable_classname (str): Iterable type as a string (e.g. 'List'). Logging purpose only.
+    """
+    for item in idx:
+        if isinstance(item, Iterable):
+            _validate_iterable(item, expected_type, iterable_classname)
+        else:
+            if not isinstance(item, expected_type):
+                raise IndexError(
+                    f"{iterable_classname} indexing expects {expected_type} indices"
+                )
+
+
+def _slice_indexing(shape: list[int], idx: slice) -> List[int]:
+    """Given an input shape and a slice index, returns the new indexed shape.
+
+    Args:
+        shape (list[int]): Input shape
+        idx (slice): Index
+    Returns:
+        Indexed shape
+    Examples:
+        >>> _slice_indexing([3, 4], slice(None, 2))
+        [2, 4]
+        >>> list(torch.rand(3, 4)[:2].shape)
+        [2, 4]
+    """
+    if idx.step == 0:
+        raise ValueError("slice step cannot be zero")
+    # Slicing an empty shape returns the shape
+    if len(shape) == 0:
+        return shape
+
+    if idx.start is None:
+        start = 0
+    else:
+        start = idx.start if idx.start >= 0 else max(shape[0] + idx.start, 0)
+
+    if idx.stop is None:
+        stop = shape[0]
+    else:
+        stop = idx.stop if idx.stop >= 0 else max(shape[0] + idx.stop, 0)
+
+    step = 1 if idx.step is None else idx.step
+    if step > 0:
+        if start >= stop:
+            n_items = 0
+        else:
+            stop = min(stop, shape[0])
+            n_items = math.ceil((stop - start) / step)
+    else:
+        if start <= stop:
+            n_items = 0
+        else:
+            start = min(start, shape[0] - 1)
+            n_items = math.ceil((stop - start) / step)
+    return [n_items] + shape[1:]
+
+
+def _shape_indexing(
+    shape: Union[list[int], torch.Size, tuple[int]], idx: SHAPE_INDEX_TYPING
+) -> List[int]:
+    """Given an input shape and an index, returns the size of the resulting indexed spec.
+
+    This function includes indexing checks and may raise IndexErrors.
+
+    Args:
+        shape (list[int], torch.Size, tuple[int): Input shape
+        idx (SHAPE_INDEX_TYPING): Index
+    Returns:
+        Shape of the resulting spec
+    Examples:
+        >>> idx = (2, ..., None)
+        >>> DiscreteTensorSpec(2, shape=(3, 4))[idx].shape
+        torch.Size([4, 1])
+        >>> _shape_indexing([3, 4], idx)
+        torch.Size([4, 1])
+    """
+    if not isinstance(shape, list):
+        shape = list(shape)
+
+    if idx is Ellipsis or (
+        isinstance(idx, slice) and (idx.step is idx.start is idx.stop is None)
+    ):
+        return shape
+
+    if idx is None:
+        return [1] + shape
+
+    if len(shape) == 0 and (
+        isinstance(idx, int)
+        or isinstance(idx, range)
+        or isinstance(idx, list)
+        and len(idx) > 0
+    ):
+        raise IndexError(
+            f"cannot use integer indices on 0-dimensional shape. `{idx}` received"
+        )
+
+    if isinstance(idx, int):
+        _validate_idx(shape, idx)
+        return shape[1:]
+
+    if isinstance(idx, range):
+        if len(idx) > 0 and (idx.start >= shape[0] or idx.stop > shape[0]):
+            raise IndexError(f"index out of bounds for axis 0 with size {shape[0]}")
+        return [len(idx)] + shape[1:]
+
+    if isinstance(idx, slice):
+        return _slice_indexing(shape, idx)
+
+    if isinstance(idx, tuple):
+        # Supports int, None, slice and ellipsis indices
+        # Index on the current shape dimension
+        shape_idx = 0
+        none_dims = 0
+        ellipsis = False
+        prev_is_list = False
+        shape_len = len(shape)
+        for item_idx, item in enumerate(idx):
+            if item is None:
+                shape = shape[:shape_idx] + [1] + shape[shape_idx:]
+                shape_idx += 1
+                none_dims += 1
+            elif isinstance(item, int):
+                _validate_idx(shape, item, shape_idx)
+                del shape[shape_idx]
+            elif isinstance(item, slice):
+                shape[shape_idx] = _slice_indexing([shape[shape_idx]], item)[0]
+                shape_idx += 1
+            elif item is Ellipsis:
+                if ellipsis:
+                    raise IndexError("an index can only have a single ellipsis (`...`)")
+                # Move to the end of the shape, subtracted by the number of future indices impacting the dimensions (i.e. all except None and ...)
+                shape_idx = len(shape) - len(
+                    [i for i in idx[item_idx + 1 :] if not (i is None or i is Ellipsis)]
+                )
+                ellipsis = True
+            elif any(
+                isinstance(item, _type)
+                for _type in [list, tuple, range, np.ndarray, torch.Tensor]
+            ):
+                while isinstance(idx, tuple) and len(idx) == 1:
+                    idx = idx[0]
+
+                # Nested tuples are handled as a list. Numpy behavior
+                if isinstance(item, tuple):
+                    item = list(item)
+
+                if prev_is_list and isinstance(item, list):
+                    del shape[shape_idx]
+                    continue
+
+                if isinstance(item, list):
+                    prev_is_list = True
+
+                if shape_idx >= len(shape):
+                    raise IndexError("Raise IndexError: too many indices for array")
+
+                res = _shape_indexing([shape[shape_idx]], item)
+                shape = shape[:shape_idx] + res + shape[shape_idx + 1 :]
+                shape_idx += len(res)
+            else:
+                raise IndexError(
+                    f"tuple indexing only supports integers, ranges, slices (`:`), ellipsis (`...`), new axis (`None`), tuples, list, tensor and ndarray indices. {str(type(idx))} received"
+                )
+
+        if len(idx) - none_dims - int(ellipsis) > shape_len:
+            raise IndexError(
+                f"shape is {shape_len}-dimensional, but {len(idx) - none_dims - int(ellipsis)} dimensions were indexed"
+            )
+        return shape
+
+    if isinstance(idx, list):
+        # int indexing only
+        _validate_iterable(idx, int, "list")
+        for item in np.array(idx).reshape(-1):
+            _validate_idx(shape, item, 0)
+        return list(np.array(idx).shape) + shape[1:]
+
+    if isinstance(idx, np.ndarray) or isinstance(idx, torch.Tensor):
+        # Out of bounds check
+        for item in idx.reshape(-1):
+            _validate_idx(shape, item)
+        return list(_getitem_batch_size(shape, idx))
+
+
 class invertible_dict(dict):
     """An invertible dictionary.
 
     Examples:
         >>> my_dict = invertible_dict(a=3, b=2)
         >>> inv_dict = my_dict.invert()
         >>> assert {2, 3} == set(inv_dict.keys())
@@ -229,14 +465,27 @@
 
     shape: torch.Size
     space: Union[None, Box]
     device: torch.device = torch.device("cpu")
     dtype: torch.dtype = torch.float
     domain: str = ""
 
+    SPEC_HANDLED_FUNCTIONS = {}
+
+    @classmethod
+    def implements_for_spec(cls, torch_function: Callable) -> Callable:
+        """Register a torch function override for TensorSpec."""
+
+        @wraps(torch_function)
+        def decorator(func):
+            cls.SPEC_HANDLED_FUNCTIONS[torch_function] = func
+            return func
+
+        return decorator
+
     def encode(self, val: Union[np.ndarray, torch.Tensor]) -> torch.Tensor:
         """Encodes a value given the specified spec, and return the corresponding tensor.
 
         Args:
             val (np.ndarray or torch.Tensor): value to be encoded as tensor.
 
         Returns:
@@ -325,14 +574,32 @@
                 its length must be at least as long as the current shape length,
                 and its last values must be complient too; ie they can only differ
                 from it if the current dimension is a singleton.
 
         """
         raise NotImplementedError
 
+    def squeeze(self, dim: int | None = None):
+        """Returns a new Spec with all the dimensions of size ``1`` removed.
+
+        When ``dim`` is given, a squeeze operation is done only in that dimension.
+
+        Args:
+            dim (int or None): the dimension to apply the squeeze operation to
+
+        """
+        shape = _squeezed_shape(self.shape, dim)
+        if shape is None:
+            return self
+        return self.__class__(shape=shape, device=self.device, dtype=self.dtype)
+
+    def unsqueeze(self, dim: int):
+        shape = _unsqueezed_shape(self.shape, dim)
+        return self.__class__(shape=shape, device=self.device, dtype=self.dtype)
+
     def _project(self, val: torch.Tensor) -> torch.Tensor:
         raise NotImplementedError
 
     @abc.abstractmethod
     def is_in(self, val: torch.Tensor) -> bool:
         """If the value :obj:`val` is in the box defined by the TensorSpec, returns True, otherwise False.
 
@@ -432,14 +699,268 @@
         domain_str = "domain=" + str(self.domain)
         sub_string = ", ".join(
             [shape_str, space_str, device_str, dtype_str, domain_str]
         )
         string = f"{self.__class__.__name__}(\n     {sub_string})"
         return string
 
+    @classmethod
+    def __torch_function__(
+        cls,
+        func: Callable,
+        types,
+        args: Tuple = (),
+        kwargs: Optional[dict] = None,
+    ) -> Callable:
+        if kwargs is None:
+            kwargs = {}
+        if func not in cls.SPEC_HANDLED_FUNCTIONS or not all(
+            issubclass(t, (TensorSpec,)) for t in types
+        ):
+            return NotImplemented(
+                f"func {func} for spec {cls} with handles {cls.SPEC_HANDLED_FUNCTIONS}"
+            )
+        return cls.SPEC_HANDLED_FUNCTIONS[func](*args, **kwargs)
+
+
+T = TypeVar("T")
+
+
+class _LazyStackedMixin(Generic[T]):
+    def __init__(self, *specs: tuple[T, ...], dim: int) -> None:
+        self._specs = specs
+        self.dim = dim
+        if self.dim < 0:
+            self.dim = len(self.shape) + self.dim
+
+    def __getitem__(self, item):
+        is_key = isinstance(item, str) or (
+            isinstance(item, tuple) and all(isinstance(_item, str) for _item in item)
+        )
+        if is_key:
+            return torch.stack(
+                [composite_spec[item] for composite_spec in self._specs], dim=self.dim
+            )
+        elif isinstance(item, tuple):
+            # quick check that the index is along the stacked dim
+            # case 1: index is a tuple, and the first arg is an ellipsis. Then dim must be the last dim of all composite_specs
+            if item[0] is Ellipsis:
+                if len(item) == 1:
+                    return self
+                elif self.dim == len(self.shape) - 1 and len(item) == 2:
+                    # we can return
+                    return self._specs[item[1]]
+                elif len(item) > 2:
+                    # check that there is only one non-slice index
+                    assigned = False
+                    dim_idx = self.dim
+                    for i, _item in enumerate(item[1:]):
+                        if (
+                            isinstance(_item, slice)
+                            and not (
+                                _item.start is None
+                                and _item.stop is None
+                                and _item.step is None
+                            )
+                        ) or not isinstance(_item, slice):
+                            if assigned:
+                                raise RuntimeError(
+                                    "Found more than one meaningful index in a stacked composite spec."
+                                )
+                            item = _item
+                            dim_idx = i + 1
+                            assigned = True
+                        if not assigned:
+                            return self
+                        if dim_idx != self.dim:
+                            raise RuntimeError(
+                                f"Indexing occured along dimension {dim_idx} but stacking was done along dim {self.dim}."
+                            )
+                        out = self._specs[item]
+                        if isinstance(out, TensorSpec):
+                            return out
+                        return torch.stack(list(out), 0)
+                else:
+                    raise IndexError(
+                        f"Indexing a {self.__class__.__name__} with [..., idx] is only permitted if the stack dimension is the last dimension. "
+                        f"Got self.dim={self.dim} and self.shape={self.shape}."
+                    )
+            elif len(item) >= 2 and item[-1] is Ellipsis:
+                return self[item[:-1]]
+            elif any(_item is Ellipsis for _item in item):
+                raise IndexError("Cannot index along multiple dimensions.")
+            # Ellipsis is now ruled out
+            elif any(_item is None for _item in item):
+                raise IndexError(
+                    f"Cannot index a {self.__class__.__name__} with None values"
+                )
+            # Must be an index with slices then
+            else:
+                for i, _item in enumerate(item):
+                    if i == self.dim:
+                        out = self._specs[_item]
+                        if isinstance(out, TensorSpec):
+                            return out
+                        return torch.stack(list(out), 0)
+                    elif isinstance(_item, slice):
+                        # then the slice must be trivial
+                        if not (_item.step is _item.start is _item.stop is None):
+                            raise IndexError(
+                                f"Got a non-trivial index at dim {i} when only the dim {self.dim} could be indexed."
+                            )
+                else:
+                    return self
+        else:
+            if not self.dim == 0:
+                raise IndexError(
+                    f"Trying to index a {self.__class__.__name__} along dimension 0 when the stack dimension is {self.dim}."
+                )
+            out = self._specs[item]
+            if isinstance(out, TensorSpec):
+                return out
+            return torch.stack(list(out), 0)
+
+    @property
+    def shape(self):
+        shape = list(self._specs[0].shape)
+        dim = self.dim
+        if dim < 0:
+            dim = len(shape) + dim + 1
+        shape.insert(dim, len(self._specs))
+        return torch.Size(shape)
+
+    def clone(self) -> T:
+        return torch.stack([spec.clone() for spec in self._specs], 0)
+
+    def expand(self, *shape):
+        if len(shape) == 1 and not isinstance(shape[0], (int,)):
+            return self.expand(*shape[0])
+        expand_shape = shape[: -len(self.shape)]
+        existing_shape = self.shape
+        shape_check = shape[-len(self.shape) :]
+        for _i, (size1, size2) in enumerate(zip(existing_shape, shape_check)):
+            if size1 != size2 and size1 != 1:
+                raise RuntimeError(
+                    f"Expanding a non-singletom dimension: existing shape={size1} vs expand={size2}"
+                )
+            elif size1 != size2 and size1 == 1 and _i == self.dim:
+                # if we're expanding along the stack dim we just need to clone the existing spec
+                return torch.stack(
+                    [self._specs[0].clone() for _ in range(size2)], self.dim
+                ).expand(*shape)
+        if _i != len(self.shape) - 1:
+            raise RuntimeError(
+                f"Trying to expand non-congruent shapes: received {shape} when the shape is {self.shape}."
+            )
+        # remove the stack dim from the expanded shape, which we know to match
+        unstack_shape = list(expand_shape) + [
+            s for i, s in enumerate(shape_check) if i != self.dim
+        ]
+        return torch.stack(
+            [spec.expand(unstack_shape) for spec in self._specs],
+            self.dim + len(expand_shape),
+        )
+
+    def zero(self, shape=None) -> TensorDictBase:
+        if shape is not None:
+            dim = self.dim + len(shape)
+        else:
+            dim = self.dim
+        return torch.stack([spec.zero(shape) for spec in self._specs], dim)
+
+    def rand(self, shape=None) -> TensorDictBase:
+        if shape is not None:
+            dim = self.dim + len(shape)
+        else:
+            dim = self.dim
+        return torch.stack([spec.rand(shape) for spec in self._specs], dim)
+
+    def to(self, dest: Union[torch.dtype, DEVICE_TYPING]) -> T:
+        return torch.stack([spec.to(dest) for spec in self._specs], self.dim)
+
+
+class LazyStackedTensorSpec(_LazyStackedMixin[TensorSpec], TensorSpec):
+    """A lazy representation of a stack of tensor specs.
+
+    Stacks tensor-specs together along one dimension.
+    When random samples are drawn, a stack of samples is returned if possible.
+    If not, an error is thrown.
+
+    Indexing is allowed but only along the stack dimension.
+
+    This class is aimed to be used in multi-task and multi-agent settings, where
+    heterogeneous specs may occur (same semantic but different shape).
+
+    """
+
+    @property
+    def space(self):
+        return self._specs[0].space
+
+    def __eq__(self, other):
+        # requires unbind to be implemented
+        pass
+
+    def to_numpy(self, val: torch.Tensor, safe: bool = True) -> dict:
+        if safe:
+            if val.shape[self.dim] != len(self._specs):
+                raise ValueError(
+                    "Size of LazyStackedTensorSpec and val differ along the stacking "
+                    "dimension"
+                )
+            for spec, v in zip(self._specs, torch.unbind(val, dim=self.dim)):
+                spec.assert_is_in(v)
+        return val.detach().cpu().numpy()
+
+    def __len__(self):
+        pass
+
+    def project(self, val: TensorDictBase) -> TensorDictBase:
+        pass
+
+    def __repr__(self):
+        shape_str = "shape=" + str(self.shape)
+        space_str = "space=" + str(self._specs[0].space)
+        device_str = "device=" + str(self.device)
+        dtype_str = "dtype=" + str(self.dtype)
+        domain_str = "domain=" + str(self._specs[0].domain)
+        sub_string = ", ".join(
+            [shape_str, space_str, device_str, dtype_str, domain_str]
+        )
+        string = f"{self.__class__.__name__}(\n     {sub_string})"
+        return string
+
+    def __iter__(self):
+        pass
+
+    def __setitem__(self, key, value):
+        pass
+
+    @property
+    def device(self) -> DEVICE_TYPING:
+        return self._specs[0].device
+
+    @property
+    def ndim(self):
+        return self.ndimension()
+
+    def ndimension(self):
+        return len(self.shape)
+
+    def set(self, name, spec):
+        if spec is not None:
+            shape = spec.shape
+            if shape[: self.ndim] != self.shape:
+                raise ValueError(
+                    "The shape of the spec and the CompositeSpec mismatch: the first "
+                    f"{self.ndim} dimensions should match but got spec.shape={spec.shape} and "
+                    f"CompositeSpec.shape={self.shape}."
+                )
+        self._specs[name] = spec
+
 
 @dataclass(repr=False)
 class OneHotDiscreteTensorSpec(TensorSpec):
     """A unidimensional, one-hot discrete tensor spec.
 
     By default, TorchRL assumes that categorical variables are encoded as
     one-hot encodings of the variable. This allows for simple indexing of
@@ -450,14 +971,16 @@
         >>> action_value = action_value.view(batch, size).to(torch.float)
         >>> action = (action_value == action_value.max(-1,
         ...    keepdim=True)[0]).to(torch.long)
         >>> chosen_action_value = (action * action_value).sum(-1)
         >>> print(chosen_action_value)
         tensor([ 3.,  7., 11.])
 
+    The last dimension of the shape (variable domain) cannot be indexed.
+
     Args:
         n (int): number of possible outcomes.
         shape (torch.Size, optional): total shape of the sampled tensors.
             If provided, the last dimension must match n.
         device (str, int or torch.device, optional): device of the tensors.
         dtype (str or torch.dtype, optional): dtype of the tensors.
         user_register (bool): experimental feature. If True, every integer
@@ -472,28 +995,28 @@
 
     shape: torch.Size
     space: DiscreteBox
     device: torch.device = torch.device("cpu")
     dtype: torch.dtype = torch.float
     domain: str = ""
 
+    # SPEC_HANDLED_FUNCTIONS = {}
+
     def __init__(
         self,
         n: int,
         shape: Optional[torch.Size] = None,
         device: Optional[DEVICE_TYPING] = None,
         dtype: Optional[Union[str, torch.dtype]] = torch.long,
         use_register: bool = False,
     ):
 
         dtype, device = _default_dtype_and_device(dtype, device)
         self.use_register = use_register
-        space = DiscreteBox(
-            n,
-        )
+        space = DiscreteBox(n)
         if shape is None:
             shape = torch.Size((space.n,))
         else:
             shape = torch.Size(shape)
             if not len(shape) or shape[-1] != space.n:
                 raise ValueError(
                     f"The last value of the shape must match n for transform of type {self.__class__}. "
@@ -528,25 +1051,58 @@
         )
 
     def expand(self, *shape):
         if len(shape) == 1 and isinstance(shape[0], (tuple, list, torch.Size)):
             shape = shape[0]
         if any(val < 0 for val in shape):
             raise ValueError(
-                f"{self.__class__.__name__}.extend does not support negative shapes."
+                f"{self.__class__.__name__}.expand does not support negative shapes."
             )
         if any(s1 != s2 and s2 != 1 for s1, s2 in zip(shape[-self.ndim :], self.shape)):
             raise ValueError(
-                f"The last {self.ndim} of the extended shape must match the"
-                f"shape of the CompositeSpec in CompositeSpec.extend."
+                f"The last {self.ndim} of the expanded shape {shape} must match the"
+                f"shape of the {self.__class__.__name__} spec in expand()."
             )
         return self.__class__(
             n=shape[-1], shape=shape, device=self.device, dtype=self.dtype
         )
 
+    def squeeze(self, dim=None):
+        if self.shape[-1] == 1 and dim in (len(self.shape), -1, None):
+            raise ValueError(
+                "Final dimension of OneHotDiscreteTensorSpec must remain unchanged"
+            )
+
+        shape = _squeezed_shape(self.shape, dim)
+        if shape is None:
+            return self
+
+        return self.__class__(
+            n=shape[-1],
+            shape=shape,
+            device=self.device,
+            dtype=self.dtype,
+            use_register=self.use_register,
+        )
+
+    def unsqueeze(self, dim: int):
+        if dim in (len(self.shape), -1):
+            raise ValueError(
+                "Final dimension of OneHotDiscreteTensorSpec must remain unchanged"
+            )
+
+        shape = _unsqueezed_shape(self.shape, dim)
+        return self.__class__(
+            n=shape[-1],
+            shape=shape,
+            device=self.device,
+            dtype=self.dtype,
+            use_register=self.use_register,
+        )
+
     def rand(self, shape=None) -> torch.Tensor:
         if shape is None:
             shape = self.shape[:-1]
         else:
             shape = torch.Size([*shape, *self.shape[:-1]])
         return torch.nn.functional.gumbel_softmax(
             torch.rand(torch.Size([*shape, self.space.n]), device=self.device),
@@ -596,14 +1152,28 @@
                 f"Only tensors are allowed for indexing using "
                 f"{self.__class__.__name__}.index(...)"
             )
         index = index.nonzero().squeeze()
         index = index.expand((*tensor_to_index.shape[:-1], index.shape[-1]))
         return tensor_to_index.gather(-1, index)
 
+    def __getitem__(self, idx: SHAPE_INDEX_TYPING):
+        """Indexes the current TensorSpec based on the provided index.
+
+        The last dimension of the spec corresponding to the variable domain cannot be indexed.
+        """
+        indexed_shape = _shape_indexing(self.shape[:-1], idx)
+        return self.__class__(
+            n=self.space.n,
+            shape=torch.Size(indexed_shape + [self.shape[-1]]),
+            device=self.device,
+            dtype=self.dtype,
+            use_register=self.use_register,
+        )
+
     def _project(self, val: torch.Tensor) -> torch.Tensor:
         # idx = val.sum(-1) != 1
         out = torch.nn.functional.gumbel_softmax(val.to(torch.float))
         out = (out == out.max(dim=-1, keepdim=True)[0]).to(torch.long)
         return out
 
     def is_in(self, val: torch.Tensor) -> bool:
@@ -653,14 +1223,16 @@
         minimum (np.ndarray, torch.Tensor or number): lower bound of the box.
         maximum (np.ndarray, torch.Tensor or number): upper bound of the box.
         device (str, int or torch.device, optional): device of the tensors.
         dtype (str or torch.dtype, optional): dtype of the tensors.
 
     """
 
+    # SPEC_HANDLED_FUNCTIONS = {}
+
     def __init__(
         self,
         minimum: Union[float, torch.Tensor, np.ndarray],
         maximum: Union[float, torch.Tensor, np.ndarray],
         shape: Optional[Union[torch.Size, int]] = None,
         device: Optional[DEVICE_TYPING] = None,
         dtype: Optional[Union[torch.dtype, str]] = None,
@@ -737,29 +1309,59 @@
         )
 
     def expand(self, *shape):
         if len(shape) == 1 and isinstance(shape[0], (tuple, list, torch.Size)):
             shape = shape[0]
         if any(val < 0 for val in shape):
             raise ValueError(
-                f"{self.__class__.__name__}.extend does not support negative shapes."
+                f"{self.__class__.__name__}.expand does not support negative shapes."
             )
         if any(s1 != s2 and s2 != 1 for s1, s2 in zip(shape[-self.ndim :], self.shape)):
             raise ValueError(
-                f"The last {self.ndim} of the extended shape must match the"
-                f"shape of the CompositeSpec in CompositeSpec.extend."
+                f"The last {self.ndim} of the expanded shape {shape} must match the"
+                f"shape of the {self.__class__.__name__} spec in expand()."
             )
         return self.__class__(
             minimum=self.space.minimum.expand(shape).clone(),
             maximum=self.space.maximum.expand(shape).clone(),
             shape=shape,
             device=self.device,
             dtype=self.dtype,
         )
 
+    def squeeze(self, dim: int | None = None):
+        shape = _squeezed_shape(self.shape, dim)
+        if shape is None:
+            return self
+
+        if dim is None:
+            minimum = self.space.minimum.squeeze().clone()
+            maximum = self.space.maximum.squeeze().clone()
+        else:
+            minimum = self.space.minimum.squeeze(dim).clone()
+            maximum = self.space.maximum.squeeze(dim).clone()
+
+        return self.__class__(
+            minimum=minimum,
+            maximum=maximum,
+            shape=shape,
+            device=self.device,
+            dtype=self.dtype,
+        )
+
+    def unsqueeze(self, dim: int):
+        shape = _unsqueezed_shape(self.shape, dim)
+        return self.__class__(
+            minimum=self.space.minimum.unsqueeze(dim).clone(),
+            maximum=self.space.maximum.unsqueeze(dim).clone(),
+            shape=shape,
+            device=self.device,
+            dtype=self.dtype,
+        )
+
     def rand(self, shape=None) -> torch.Tensor:
         if shape is None:
             shape = torch.Size([])
         a, b = self.space
         if self.dtype in (torch.float, torch.double, torch.half):
             shape = [*shape, *self.shape]
             out = (
@@ -838,25 +1440,43 @@
             minimum=self.space.minimum.clone(),
             maximum=self.space.maximum.clone(),
             shape=self.shape,
             device=self.device,
             dtype=self.dtype,
         )
 
+    def __getitem__(self, idx: SHAPE_INDEX_TYPING):
+        """Indexes the current TensorSpec based on the provided index."""
+        raise NotImplementedError(
+            "Pending resolution of https://github.com/pytorch/pytorch/issues/100080."
+        )
+
+        indexed_shape = torch.Size(_shape_indexing(self.shape, idx))
+        # Expand is required as pytorch.tensor indexing
+        return self.__class__(
+            minimum=self.space.minimum[idx].clone().expand(indexed_shape),
+            maximum=self.space.maximum[idx].clone().expand(indexed_shape),
+            shape=indexed_shape,
+            device=self.device,
+            dtype=self.dtype,
+        )
+
 
 @dataclass(repr=False)
 class UnboundedContinuousTensorSpec(TensorSpec):
     """An unbounded continuous tensor spec.
 
     Args:
         device (str, int or torch.device, optional): device of the tensors.
         dtype (str or torch.dtype, optional): dtype of the tensors
             (should be an floating point dtype such as float, double etc.)
     """
 
+    # SPEC_HANDLED_FUNCTIONS = {}
+
     def __init__(
         self,
         shape: Union[torch.Size, int] = _DEFAULT_SHAPE,
         device: Optional[DEVICE_TYPING] = None,
         dtype: Optional[Union[str, torch.dtype]] = None,
     ):
         if isinstance(shape, int):
@@ -900,34 +1520,41 @@
         return True
 
     def expand(self, *shape):
         if len(shape) == 1 and isinstance(shape[0], (tuple, list, torch.Size)):
             shape = shape[0]
         if any(val < 0 for val in shape):
             raise ValueError(
-                f"{self.__class__.__name__}.extend does not support negative shapes."
+                f"{self.__class__.__name__}.expand does not support negative shapes."
             )
         if any(s1 != s2 and s2 != 1 for s1, s2 in zip(shape[-self.ndim :], self.shape)):
             raise ValueError(
-                f"The last {self.ndim} of the extended shape must match the"
-                f"shape of the CompositeSpec in CompositeSpec.extend."
+                f"The last {self.ndim} of the expanded shape {shape} must match the"
+                f"shape of the {self.__class__.__name__} spec in expand()."
             )
         return self.__class__(shape=shape, device=self.device, dtype=self.dtype)
 
+    def __getitem__(self, idx: SHAPE_INDEX_TYPING):
+        """Indexes the current TensorSpec based on the provided index."""
+        indexed_shape = torch.Size(_shape_indexing(self.shape, idx))
+        return self.__class__(shape=indexed_shape, device=self.device, dtype=self.dtype)
+
 
 @dataclass(repr=False)
 class UnboundedDiscreteTensorSpec(TensorSpec):
     """An unbounded discrete tensor spec.
 
     Args:
         device (str, int or torch.device, optional): device of the tensors.
         dtype (str or torch.dtype, optional): dtype of the tensors
             (should be an integer dtype such as long, uint8 etc.)
     """
 
+    # SPEC_HANDLED_FUNCTIONS = {}
+
     def __init__(
         self,
         shape: Union[torch.Size, int] = _DEFAULT_SHAPE,
         device: Optional[DEVICE_TYPING] = None,
         dtype: Optional[Union[str, torch.dtype]] = None,
     ):
         if isinstance(shape, int):
@@ -985,125 +1612,35 @@
         return True
 
     def expand(self, *shape):
         if len(shape) == 1 and isinstance(shape[0], (tuple, list, torch.Size)):
             shape = shape[0]
         if any(val < 0 for val in shape):
             raise ValueError(
-                f"{self.__class__.__name__}.extend does not support negative shapes."
+                f"{self.__class__.__name__}.expand does not support negative shapes."
             )
         if any(s1 != s2 and s2 != 1 for s1, s2 in zip(shape[-self.ndim :], self.shape)):
             raise ValueError(
-                f"The last {self.ndim} of the extended shape must match the"
-                f"shape of the CompositeSpec in CompositeSpec.extend."
+                f"The last {self.ndim} of the expanded shape {shape} must match the"
+                f"shape of the {self.__class__.__name__} spec in expand()."
             )
         return self.__class__(shape=shape, device=self.device, dtype=self.dtype)
 
-
-@dataclass(repr=False)
-class BinaryDiscreteTensorSpec(TensorSpec):
-    """A binary discrete tensor spec.
-
-    Args:
-        n (int): length of the binary vector.
-        shape (torch.Size, optional): total shape of the sampled tensors.
-            If provided, the last dimension must match n.
-        device (str, int or torch.device, optional): device of the tensors.
-        dtype (str or torch.dtype, optional): dtype of the tensors. Defaults to torch.long.
-
-    Examples:
-        >>> spec = BinaryDiscreteTensorSpec(n=4, shape=(5, 4), device="cpu", dtype=torch.bool)
-        >>> print(spec.zero())
-    """
-
-    shape: torch.Size
-    space: BinaryBox
-    device: torch.device = torch.device("cpu")
-    dtype: torch.dtype = torch.float
-    domain: str = ""
-
-    def __init__(
-        self,
-        n: int,
-        shape: Optional[torch.Size] = None,
-        device: Optional[DEVICE_TYPING] = None,
-        dtype: Union[str, torch.dtype] = torch.long,
-    ):
-        dtype, device = _default_dtype_and_device(dtype, device)
-        box = BinaryBox(n)
-        if shape is None:
-            shape = torch.Size((n,))
-        else:
-            shape = torch.Size(shape)
-            if shape[-1] != box.n:
-                raise ValueError(
-                    f"The last value of the shape must match n for transform of type {self.__class__}. "
-                    f"Got n={box.n} and shape={shape}."
-                )
-
-        super().__init__(shape, box, device, dtype, domain="discrete")
-
-    def rand(self, shape=None) -> torch.Tensor:
-        if shape is None:
-            shape = torch.Size([])
-        shape = [*shape, *self.shape]
-        return torch.zeros(shape, device=self.device, dtype=self.dtype).bernoulli_()
-
-    def index(self, index: INDEX_TYPING, tensor_to_index: torch.Tensor) -> torch.Tensor:
-        if not isinstance(index, torch.Tensor):
-            raise ValueError(
-                f"Only tensors are allowed for indexing using"
-                f" {self.__class__.__name__}.index(...)"
-            )
-        index = index.nonzero().squeeze()
-        index = index.expand((*tensor_to_index.shape[:-1], index.shape[-1]))
-        return tensor_to_index.gather(-1, index)
-
-    def is_in(self, val: torch.Tensor) -> bool:
-        return ((val == 0) | (val == 1)).all()
-
-    def expand(self, *shape):
-        if len(shape) == 1 and isinstance(shape[0], (tuple, list, torch.Size)):
-            shape = shape[0]
-        if any(val < 0 for val in shape):
-            raise ValueError(
-                f"{self.__class__.__name__}.extend does not support negative shapes."
-            )
-        if any(s1 != s2 and s2 != 1 for s1, s2 in zip(shape[-self.ndim :], self.shape)):
-            raise ValueError(
-                f"The last {self.ndim} of the extended shape must match the"
-                f"shape of the CompositeSpec in CompositeSpec.extend."
-            )
-        return self.__class__(
-            n=shape[-1], shape=shape, device=self.device, dtype=self.dtype
-        )
-
-    def to(self, dest: Union[torch.dtype, DEVICE_TYPING]) -> CompositeSpec:
-        if isinstance(dest, torch.dtype):
-            dest_dtype = dest
-            dest_device = self.device
-        else:
-            dest_dtype = self.dtype
-            dest_device = torch.device(dest)
-        if dest_device == self.device and dest_dtype == self.dtype:
-            return self
-        return self.__class__(
-            n=self.space.n, shape=self.shape, device=dest_device, dtype=dest_dtype
-        )
-
-    def clone(self) -> CompositeSpec:
-        return self.__class__(
-            n=self.space.n, shape=self.shape, device=self.device, dtype=self.dtype
-        )
+    def __getitem__(self, idx: SHAPE_INDEX_TYPING):
+        """Indexes the current TensorSpec based on the provided index."""
+        indexed_shape = torch.Size(_shape_indexing(self.shape, idx))
+        return self.__class__(shape=indexed_shape, device=self.device, dtype=self.dtype)
 
 
 @dataclass(repr=False)
 class MultiOneHotDiscreteTensorSpec(OneHotDiscreteTensorSpec):
     """A concatenation of one-hot discrete tensor spec.
 
+    The last dimension of the shape (domain of the tensor elements) cannot be indexed.
+
     Args:
         nvec (iterable of integers): cardinality of each of the elements of
             the tensor.
         shape (torch.Size, optional): total shape of the sampled tensors.
             If provided, the last dimension must match sum(nvec).
         device (str, int or torch.device, optional): device of
             the tensors.
@@ -1118,14 +1655,16 @@
         >>> ts.is_in(torch.tensor([1,0,1,
         ...                        0,1,
         ...                        1,0,0])) # False
         False
 
     """
 
+    # SPEC_HANDLED_FUNCTIONS = {}
+
     def __init__(
         self,
         nvec: Sequence[int],
         shape: Optional[torch.Size] = None,
         device=None,
         dtype=torch.long,
         use_register=False,
@@ -1270,32 +1809,69 @@
 
     def expand(self, *shape):
         nvecs = [space.n for space in self.space]
         if len(shape) == 1 and isinstance(shape[0], (tuple, list, torch.Size)):
             shape = shape[0]
         if any(val < 0 for val in shape):
             raise ValueError(
-                f"{self.__class__.__name__}.extend does not support negative shapes."
+                f"{self.__class__.__name__}.expand does not support negative shapes."
             )
         if any(s1 != s2 and s2 != 1 for s1, s2 in zip(shape[-self.ndim :], self.shape)):
             raise ValueError(
-                f"The last {self.ndim} of the extended shape must match the"
-                f"shape of the CompositeSpec in CompositeSpec.extend."
+                f"The last {self.ndim} of the expanded shape {shape} must match the"
+                f"shape of the {self.__class__.__name__} spec in expand()."
             )
         return self.__class__(
             nvec=nvecs, shape=shape, device=self.device, dtype=self.dtype
         )
 
+    def squeeze(self, dim=None):
+        if self.shape[-1] == 1 and dim in (len(self.shape), -1, None):
+            raise ValueError(
+                "Final dimension of MultiOneHotDiscreteTensorSpec must remain unchanged"
+            )
+
+        shape = _squeezed_shape(self.shape, dim)
+        if shape is None:
+            return self
+        return self.__class__(
+            nvec=self.nvec, shape=shape, device=self.device, dtype=self.dtype
+        )
+
+    def unsqueeze(self, dim: int):
+        if dim in (len(self.shape), -1):
+            raise ValueError(
+                "Final dimension of MultiOneHotDiscreteTensorSpec must remain unchanged"
+            )
+        shape = _unsqueezed_shape(self.shape, dim)
+        return self.__class__(
+            nvec=self.nvec, shape=shape, device=self.device, dtype=self.dtype
+        )
+
+    def __getitem__(self, idx: SHAPE_INDEX_TYPING):
+        """Indexes the current TensorSpec based on the provided index.
+
+        The last dimension of the spec corresponding to the domain of the tensor elements is non-indexable.
+        """
+        indexed_shape = _shape_indexing(self.shape[:-1], idx)
+        return self.__class__(
+            nvec=self.nvec,
+            shape=torch.Size(indexed_shape + [self.shape[-1]]),
+            device=self.device,
+            dtype=self.dtype,
+        )
+
 
 class DiscreteTensorSpec(TensorSpec):
     """A discrete tensor spec.
 
     An alternative to OneHotTensorSpec for categorical variables in TorchRL. Instead of
     using multiplication, categorical variables perform indexing which can speed up
     computation and reduce memory cost for large categorical variables.
+    The last dimension of the spec (length n of the binary vector) cannot be indexed
 
     Example:
         >>> batch, size = 3, 4
         >>> action_value = torch.arange(batch*size)
         >>> action_value = action_value.view(batch, size).to(torch.float)
         >>> action = torch.argmax(action_value, dim=-1).to(torch.long)
         >>> chosen_action_value = action_value[range(batch), action]
@@ -1312,14 +1888,16 @@
 
     shape: torch.Size
     space: DiscreteBox
     device: torch.device = torch.device("cpu")
     dtype: torch.dtype = torch.float
     domain: str = ""
 
+    # SPEC_HANDLED_FUNCTIONS = {}
+
     def __init__(
         self,
         n: int,
         shape: Optional[torch.Size] = None,
         device: Optional[DEVICE_TYPING] = None,
         dtype: Optional[Union[str, torch.dtype]] = torch.long,
     ):
@@ -1344,14 +1922,24 @@
         if val.dtype not in (torch.int, torch.long):
             val = torch.round(val)
         return val.clamp_(min=0, max=self.space.n - 1)
 
     def is_in(self, val: torch.Tensor) -> bool:
         return (0 <= val).all() and (val < self.space.n).all()
 
+    def __getitem__(self, idx: SHAPE_INDEX_TYPING):
+        """Indexes the current TensorSpec based on the provided index."""
+        indexed_shape = torch.Size(_shape_indexing(self.shape, idx))
+        return self.__class__(
+            n=self.space.n,
+            shape=indexed_shape,
+            device=self.device,
+            dtype=self.dtype,
+        )
+
     def __eq__(self, other):
         return (
             type(self) == type(other)
             and self.shape == other.shape
             and self.space == other.space
             and self.device == other.device
             and self.dtype == other.dtype
@@ -1384,25 +1972,39 @@
         )
 
     def expand(self, *shape):
         if len(shape) == 1 and isinstance(shape[0], (tuple, list, torch.Size)):
             shape = shape[0]
         if any(val < 0 for val in shape):
             raise ValueError(
-                f"{self.__class__.__name__}.extend does not support negative shapes."
+                f"{self.__class__.__name__}.expand does not support negative shapes."
             )
         if any(s1 != s2 and s2 != 1 for s1, s2 in zip(shape[-self.ndim :], self.shape)):
             raise ValueError(
-                f"The last {self.ndim} of the extended shape must match the"
-                f"shape of the CompositeSpec in CompositeSpec.extend."
+                f"The last {self.ndim} of the expanded shape {shape} must match the"
+                f"shape of the {self.__class__.__name__} spec in expand()."
             )
         return self.__class__(
             n=self.space.n, shape=shape, device=self.device, dtype=self.dtype
         )
 
+    def squeeze(self, dim=None):
+        shape = _squeezed_shape(self.shape, dim)
+        if shape is None:
+            return self
+        return self.__class__(
+            n=self.space.n, shape=shape, device=self.device, dtype=self.dtype
+        )
+
+    def unsqueeze(self, dim: int):
+        shape = _unsqueezed_shape(self.shape, dim)
+        return self.__class__(
+            n=self.space.n, shape=shape, device=self.device, dtype=self.dtype
+        )
+
     def to(self, dest: Union[torch.dtype, DEVICE_TYPING]) -> CompositeSpec:
         if isinstance(dest, torch.dtype):
             dest_dtype = dest
             dest_device = self.device
         else:
             dest_dtype = self.dtype
             dest_device = torch.device(dest)
@@ -1418,34 +2020,135 @@
             shape=self.shape,
             device=self.device,
             dtype=self.dtype,
         )
 
 
 @dataclass(repr=False)
+class BinaryDiscreteTensorSpec(DiscreteTensorSpec):
+    """A binary discrete tensor spec.
+
+    Args:
+        n (int): length of the binary vector.
+        shape (torch.Size, optional): total shape of the sampled tensors.
+            If provided, the last dimension must match n.
+        device (str, int or torch.device, optional): device of the tensors.
+        dtype (str or torch.dtype, optional): dtype of the tensors. Defaults to torch.long.
+
+    Examples:
+        >>> spec = BinaryDiscreteTensorSpec(n=4, shape=(5, 4), device="cpu", dtype=torch.bool)
+        >>> print(spec.zero())
+    """
+
+    def __init__(
+        self,
+        n: int,
+        shape: Optional[torch.Size] = None,
+        device: Optional[DEVICE_TYPING] = None,
+        dtype: Union[str, torch.dtype] = torch.long,
+    ):
+        if shape is None or not len(shape):
+            shape = torch.Size((n,))
+        else:
+            shape = torch.Size(shape)
+            if shape[-1] != n:
+                raise ValueError(
+                    f"The last value of the shape must match n for spec {self.__class__}. "
+                    f"Got n={n} and shape={shape}."
+                )
+        super().__init__(n=2, shape=shape, device=device, dtype=dtype)
+
+    def expand(self, *shape):
+        if len(shape) == 1 and isinstance(shape[0], (tuple, list, torch.Size)):
+            shape = shape[0]
+        if any(val < 0 for val in shape):
+            raise ValueError(
+                f"{self.__class__.__name__}.expand does not support negative shapes."
+            )
+        if any(s1 != s2 and s2 != 1 for s1, s2 in zip(shape[-self.ndim :], self.shape)):
+            raise ValueError(
+                f"The last {self.ndim} of the expanded shape {shape} must match the"
+                f"shape of the {self.__class__.__name__} spec in expand()."
+            )
+        return self.__class__(
+            n=shape[-1], shape=shape, device=self.device, dtype=self.dtype
+        )
+
+    def squeeze(self, dim=None):
+        shape = _squeezed_shape(self.shape, dim)
+        if shape is None:
+            return self
+        return self.__class__(
+            n=shape[-1], shape=shape, device=self.device, dtype=self.dtype
+        )
+
+    def unsqueeze(self, dim: int):
+        shape = _unsqueezed_shape(self.shape, dim)
+        return self.__class__(
+            n=shape[-1], shape=shape, device=self.device, dtype=self.dtype
+        )
+
+    def to(self, dest: Union[torch.dtype, DEVICE_TYPING]) -> CompositeSpec:
+        if isinstance(dest, torch.dtype):
+            dest_dtype = dest
+            dest_device = self.device
+        else:
+            dest_dtype = self.dtype
+            dest_device = torch.device(dest)
+        if dest_device == self.device and dest_dtype == self.dtype:
+            return self
+        return self.__class__(
+            n=self.shape[-1], shape=self.shape, device=dest_device, dtype=dest_dtype
+        )
+
+    def clone(self) -> CompositeSpec:
+        return self.__class__(
+            n=self.shape[-1],
+            shape=self.shape,
+            device=self.device,
+            dtype=self.dtype,
+        )
+
+    def __getitem__(self, idx: SHAPE_INDEX_TYPING):
+        """Indexes the current TensorSpec based on the provided index.
+
+        The last dimension of the spec (length n of the binary vector) cannot be indexed.
+        """
+        indexed_shape = _shape_indexing(self.shape[:-1], idx)
+        return self.__class__(
+            n=self.shape[-1],
+            shape=torch.Size(indexed_shape + [self.shape[-1]]),
+            device=self.device,
+            dtype=self.dtype,
+        )
+
+
+@dataclass(repr=False)
 class MultiDiscreteTensorSpec(DiscreteTensorSpec):
     """A concatenation of discrete tensor spec.
 
     Args:
         nvec (iterable of integers or torch.Tensor): cardinality of each of the elements of
             the tensor. Can have several axes.
         shape (torch.Size, optional): total shape of the sampled tensors.
-            If provided, the last dimension must match nvec.shape[-1].
+            If provided, the last m dimensions must match nvec.shape.
         device (str, int or torch.device, optional): device of
             the tensors.
         dtype (str or torch.dtype, optional): dtype of the tensors.
 
     Examples:
         >>> ts = MultiDiscreteTensorSpec((3,2,3))
         >>> ts.is_in(torch.tensor([2, 0, 1]))
         True
         >>> ts.is_in(torch.tensor([2, 2, 1]))
         False
     """
 
+    # SPEC_HANDLED_FUNCTIONS = {}
+
     def __init__(
         self,
         nvec: Union[Sequence[int], torch.Tensor, int],
         shape: Optional[torch.Size] = None,
         device: Optional[DEVICE_TYPING] = None,
         dtype: Optional[Union[str, torch.dtype]] = torch.long,
     ):
@@ -1460,14 +2163,15 @@
         else:
             shape = torch.Size(shape)
             if shape[-1] != nvec.shape[-1]:
                 raise ValueError(
                     f"The last value of the shape must match nvec.shape[-1] for transform of type {self.__class__}. "
                     f"Got nvec.shape[-1]={sum(nvec)} and shape={shape}."
                 )
+
         self.nvec = self.nvec.expand(shape)
 
         space = BoxList.from_nvec(self.nvec)
         super(DiscreteTensorSpec, self).__init__(
             shape, space, device, dtype, domain="discrete"
         )
 
@@ -1587,25 +2291,68 @@
         )
 
     def expand(self, *shape):
         if len(shape) == 1 and isinstance(shape[0], (tuple, list, torch.Size)):
             shape = shape[0]
         if any(val < 0 for val in shape):
             raise ValueError(
-                f"{self.__class__.__name__}.extend does not support negative shapes."
+                f"{self.__class__.__name__}.expand does not support negative shapes."
             )
         if any(s1 != s2 and s2 != 1 for s1, s2 in zip(shape[-self.ndim :], self.shape)):
             raise ValueError(
-                f"The last {self.ndim} of the extended shape must match the"
-                f"shape of the CompositeSpec in CompositeSpec.extend."
+                f"The last {self.ndim} of the expanded shape {shape} must match the"
+                f"shape of the {self.__class__.__name__} spec in expand()."
             )
         return self.__class__(
             nvec=self.nvec, shape=shape, device=self.device, dtype=self.dtype
         )
 
+    def squeeze(self, dim: int | None = None):
+        if self.shape[-1] == 1 and dim in (len(self.shape), -1, None):
+            raise ValueError(
+                "Final dimension of MultiDiscreteTensorSpec must remain unchanged"
+            )
+
+        shape = _squeezed_shape(self.shape, dim)
+        if shape is None:
+            return self
+
+        if dim is None:
+            nvec = self.nvec.squeeze()
+        else:
+            nvec = self.nvec.squeeze(dim)
+
+        return self.__class__(
+            nvec=nvec, shape=shape, device=self.device, dtype=self.dtype
+        )
+
+    def unsqueeze(self, dim: int):
+        if dim in (len(self.shape), -1):
+            raise ValueError(
+                "Final dimension of MultiDiscreteTensorSpec must remain unchanged"
+            )
+        shape = _unsqueezed_shape(self.shape, dim)
+        nvec = self.nvec.unsqueeze(dim)
+        return self.__class__(
+            nvec=nvec, shape=shape, device=self.device, dtype=self.dtype
+        )
+
+    def __getitem__(self, idx: SHAPE_INDEX_TYPING):
+        """Indexes the current TensorSpec based on the provided index."""
+        raise NotImplementedError(
+            "Pending resolution of https://github.com/pytorch/pytorch/issues/100080."
+        )
+
+        return self.__class__(
+            nvec=self.nvec[idx].clone(),
+            shape=None,
+            device=self.device,
+            dtype=self.dtype,
+        )
+
 
 class CompositeSpec(TensorSpec):
     """A composition of TensorSpecs.
 
     Args:
         *args: if an unnamed argument is passed, it must be a dictionary with keys
             matching the expected keys to be found in the :obj:`CompositeSpec` object.
@@ -1666,14 +2413,16 @@
             x: None)
 
     """
 
     shape: torch.Size
     domain: str = "composite"
 
+    SPEC_HANDLED_FUNCTIONS = {}
+
     @classmethod
     def __new__(cls, *args, **kwargs):
         cls._device = torch.device("cpu")
         return super().__new__(cls)
 
     @property
     def shape(self):
@@ -1716,15 +2465,15 @@
             #               "batch size of your CompositeSpec as you would do for a tensordict.")
             shape = []
         self._shape = torch.Size(shape)
         self._specs = {}
         for key, value in kwargs.items():
             self.set(key, value)
 
-        _device = device
+        _device = torch.device(device) if device is not None else device
         if len(kwargs):
             for key, item in self.items():
                 if item is None:
                     continue
 
                 try:
                     item_device = item.device
@@ -1735,34 +2484,34 @@
                     else:
                         raise err
 
                 if _device is None:
                     _device = item_device
                 elif item_device != _device:
                     raise RuntimeError(
-                        f"Setting a new attribute ({key}) on another device ({item.device} against {_device}). "
-                        f"All devices of CompositeSpec must match."
+                        f"Setting a new attribute ({key}) on another device "
+                        f"({item.device} against {_device}). All devices of "
+                        "CompositeSpec must match."
                     )
         self._device = _device
         if len(args):
             if len(args) > 1:
                 raise RuntimeError(
                     "Got multiple arguments, when at most one is expected for CompositeSpec."
                 )
             argdict = args[0]
             if not isinstance(argdict, (dict, CompositeSpec)):
                 raise RuntimeError(
                     f"Expected a dictionary of specs, but got an argument of type {type(argdict)}."
                 )
             for k, item in argdict.items():
-                if item is None:
-                    continue
-                if self._device is None:
-                    self._device = item.device
-                self[k] = item
+                if item is not None:
+                    if self._device is None:
+                        self._device = item.device
+                    self[k] = item
 
     @property
     def device(self) -> DEVICE_TYPING:
         if self._device is None:
             # try to replace device by the true device
             _device = None
             for value in self.values():
@@ -1778,23 +2527,61 @@
         return self._device
 
     @device.setter
     def device(self, device: DEVICE_TYPING):
         device = torch.device(device)
         self.to(device)
 
-    def __getitem__(self, item):
-        if isinstance(item, tuple) and len(item) > 1:
-            return self[item[0]][item[1:]]
-        elif isinstance(item, tuple):
-            return self[item[0]]
+    def __getitem__(self, idx):
+        """Indexes the current CompositeSpec based on the provided index."""
+        if (
+            isinstance(idx, str)
+            or isinstance(idx, tuple)
+            and all(isinstance(item, str) for item in idx)
+        ):
+            if isinstance(idx, tuple) and len(idx) > 1:
+                return self[idx[0]][idx[1:]]
+            elif isinstance(idx, tuple):
+                return self[idx[0]]
+
+            if idx in {"shape", "device", "dtype", "space"}:
+                raise AttributeError(f"CompositeSpec has no key {idx}")
+            return self._specs[idx]
+
+        indexed_shape = _shape_indexing(self.shape, idx)
+        indexed_specs = {}
+        for k, v in self._specs.items():
+            _idx = idx
+            if isinstance(idx, tuple):
+                protected_dims = 0
+                if any(
+                    isinstance(v, spec_class)
+                    for spec_class in [
+                        BinaryDiscreteTensorSpec,
+                        MultiDiscreteTensorSpec,
+                        OneHotDiscreteTensorSpec,
+                    ]
+                ):
+                    protected_dims = 1
+                # TensorSpecs dims which are not part of the composite shape cannot be indexed
+                _idx = idx + (slice(None),) * (
+                    len(v.shape) - len(self.shape) - protected_dims
+                )
+            indexed_specs[k] = v[_idx]
 
-        if item in {"shape", "device", "dtype", "space"}:
-            raise AttributeError(f"CompositeSpec has no key {item}")
-        return self._specs[item]
+        try:
+            device = self.device
+        except RuntimeError:
+            device = self._device
+
+        return self.__class__(
+            indexed_specs,
+            shape=indexed_shape,
+            device=device,
+        )
 
     def __setitem__(self, key, value):
         if isinstance(key, tuple) and len(key) > 1:
             if key[0] not in self.keys(True):
                 self[key[0]] = CompositeSpec()
             self[key[0]][key[1:]] = value
             return
@@ -1831,21 +2618,34 @@
         self.set(key, value)
 
     def __iter__(self):
         for k in self._specs:
             yield k
 
     def __delitem__(self, key: str) -> None:
+        if isinstance(key, tuple) and len(key) > 1:
+            del self._specs[key[0]][key[1:]]
+            return
+        elif isinstance(key, tuple):
+            del self._specs[key[0]]
+            return
+        elif not isinstance(key, str):
+            raise TypeError(
+                f"Got key of type {type(key)} when a string or a tuple of strings was expected."
+            )
+
+        if key in {"shape", "device", "dtype", "space"}:
+            raise AttributeError(f"CompositeSpec has no key {key}")
         del self._specs[key]
 
     def encode(self, vals: Dict[str, Any]) -> Dict[str, torch.Tensor]:
         if isinstance(vals, TensorDict):
             out = vals.select()  # create and empty tensordict similar to vals
         else:
-            out = TensorDict({}, [], _run_checks=False)
+            out = TensorDict({}, torch.Size([]), _run_checks=False)
         for key, item in vals.items():
             if item is None:
                 raise RuntimeError(
                     "CompositeSpec.encode cannot be used with missing values."
                 )
             try:
                 out[key] = self[key].encode(item)
@@ -1900,15 +2700,15 @@
         _dict = {
             key: self[key].rand(shape)
             for key in self.keys(True)
             if isinstance(key, str) and self[key] is not None
         }
         return TensorDict(
             _dict,
-            batch_size=shape,
+            batch_size=[*shape, *self.shape],
             device=self._device,
         )
 
     def keys(
         self,
         include_nested: bool = False,
         leaves_only: bool = False,
@@ -1919,23 +2719,21 @@
 
         Args:
             include_nested (bool, optional): if ``False``, the returned keys will not be nested. They will
                 represent only the immediate children of the root, and not the whole nested sequence, i.e. a
                 :obj:`CompositeSpec(next=CompositeSpec(obs=None))` will lead to the keys
                 :obj:`["next"]. Default is ``False``, i.e. nested keys will not
                 be returned.
-            leaves_only (bool, optional): if :obj:`False`, the values returned
+            leaves_only (bool, optional): if ``False``, the values returned
                 will contain every level of nesting, i.e. a :obj:`CompositeSpec(next=CompositeSpec(obs=None))`
                 will lead to the keys :obj:`["next", ("next", "obs")]`.
                 Default is ``False``.
         """
         return _CompositeSpecKeysView(
-            self,
-            include_nested=include_nested,
-            leaves_only=leaves_only,
+            self, include_nested=include_nested, leaves_only=leaves_only
         )
 
     def items(
         self,
         include_nested: bool = False,
         leaves_only: bool = False,
     ) -> ItemsView:
@@ -1943,15 +2741,15 @@
 
         Args:
             include_nested (bool, optional): if ``False``, the returned keys will not be nested. They will
                 represent only the immediate children of the root, and not the whole nested sequence, i.e. a
                 :obj:`CompositeSpec(next=CompositeSpec(obs=None))` will lead to the keys
                 :obj:`["next"]. Default is ``False``, i.e. nested keys will not
                 be returned.
-            leaves_only (bool, optional): if :obj:`False`, the values returned
+            leaves_only (bool, optional): if ``False``, the values returned
                 will contain every level of nesting, i.e. a :obj:`CompositeSpec(next=CompositeSpec(obs=None))`
                 will lead to the keys :obj:`["next", ("next", "obs")]`.
                 Default is ``False``.
         """
         if not include_nested and not leaves_only:
             yield from self._specs.items()
         else:
@@ -1971,15 +2769,15 @@
 
         Args:
             include_nested (bool, optional): if ``False``, the returned keys will not be nested. They will
                 represent only the immediate children of the root, and not the whole nested sequence, i.e. a
                 :obj:`CompositeSpec(next=CompositeSpec(obs=None))` will lead to the keys
                 :obj:`["next"]. Default is ``False``, i.e. nested keys will not
                 be returned.
-            leaves_only (bool, optional): if :obj:`False`, the values returned
+            leaves_only (bool, optional): if ``False``, the values returned
                 will contain every level of nesting, i.e. a :obj:`CompositeSpec(next=CompositeSpec(obs=None))`
                 will lead to the keys :obj:`["next", ("next", "obs")]`.
                 Default is ``False``.
         """
         if not include_nested and not leaves_only:
             yield from self._specs.values()
         else:
@@ -2013,15 +2811,18 @@
 
     def clone(self) -> CompositeSpec:
         try:
             device = self.device
         except RuntimeError:
             device = self._device
         return self.__class__(
-            {key: item.clone() for key, item in self.items()},
+            {
+                key: item.clone() if item is not None else None
+                for key, item in self.items()
+            },
             device=device,
             shape=self.shape,
         )
 
     def to_numpy(self, val: TensorDict, safe: bool = True) -> dict:
         return {key: self[key].to_numpy(val) for key, val in val.items()}
 
@@ -2052,15 +2853,17 @@
     def update(self, dict_or_spec: Union[CompositeSpec, Dict[str, TensorSpec]]) -> None:
         for key, item in dict_or_spec.items():
             if key in self.keys(True) and isinstance(self[key], CompositeSpec):
                 self[key].update(item)
                 continue
             try:
                 if isinstance(item, TensorSpec) and item.device != self.device:
-                    item = deepcopy(item).to(self.device)
+                    item = deepcopy(item)
+                    if self.device is not None:
+                        item = item.to(self.device)
             except RuntimeError as err:
                 if DEVICE_ERR_MSG in str(err):
                     try:
                         item_device = item.device
                         self.device = item_device
                     except RuntimeError as suberr:
                         if DEVICE_ERR_MSG in str(suberr):
@@ -2072,19 +2875,19 @@
             self[key] = item
         return self
 
     def expand(self, *shape):
         if len(shape) == 1 and isinstance(shape[0], (tuple, list, torch.Size)):
             shape = shape[0]
         if any(val < 0 for val in shape):
-            raise ValueError("CompositeSpec.extend does not support negative shapes.")
+            raise ValueError("CompositeSpec.expand does not support negative shapes.")
         if any(s1 != s2 and s2 != 1 for s1, s2 in zip(shape[-self.ndim :], self.shape)):
             raise ValueError(
-                f"The last {self.ndim} of the extended shape must match the"
-                f"shape of the CompositeSpec in CompositeSpec.extend."
+                f"The last {self.ndim} of the expanded shape {shape} must match the"
+                f"shape of the {self.__class__.__name__} spec in expand()."
             )
         try:
             device = self.device
         except RuntimeError:
             device = self._device
         out = CompositeSpec(
             {
@@ -2092,14 +2895,255 @@
                 for key, value in tuple(self.items())
             },
             shape=shape,
             device=device,
         )
         return out
 
+    def squeeze(self, dim: int | None = None):
+        if dim is not None:
+            if dim < 0:
+                dim += len(self.shape)
+
+            shape = _squeezed_shape(self.shape, dim)
+            if shape is None:
+                return self
+
+            try:
+                device = self.device
+            except RuntimeError:
+                device = self._device
+
+            return CompositeSpec(
+                {key: value.squeeze(dim) for key, value in self.items()},
+                shape=shape,
+                device=device,
+            )
+
+        if self.shape.count(1) == 0:
+            return self
+
+        # we can't just recursively apply squeeze with dim=None because we don't want
+        # to squeeze non-batch dims of the values. Instead we find the first dim in
+        # the batch dims with size 1, squeeze that, then recurse on the root spec
+        out = self.squeeze(self.shape.index(1))
+        return out.squeeze()
+
+    def unsqueeze(self, dim: int):
+        if dim < 0:
+            dim += len(self.shape)
+
+        shape = _unsqueezed_shape(self.shape, dim)
+
+        try:
+            device = self.device
+        except RuntimeError:
+            device = self._device
+
+        return CompositeSpec(
+            {key: value.unsqueeze(dim) for key, value in self.items()},
+            shape=shape,
+            device=device,
+        )
+
+
+class LazyStackedCompositeSpec(_LazyStackedMixin[CompositeSpec], CompositeSpec):
+    """A lazy representation of a stack of composite specs.
+
+    Stacks composite specs together along one dimension.
+    When random samples are drawn, a LazyStackedTensorDict is returned.
+
+    Indexing is allowed but only along the stack dimension.
+
+    This class is aimed to be used in multi-task and multi-agent settings, where
+    heterogeneous specs may occur (same semantic but different shape).
+
+    """
+
+    def update(self, dict_or_spec: Union[CompositeSpec, Dict[str, TensorSpec]]) -> None:
+        pass
+
+    def __eq__(self, other):
+        pass
+
+    def to_numpy(self, val: TensorDict, safe: bool = True) -> dict:
+        if safe:
+            if val.shape[self.dim] != len(self._specs):
+                raise ValueError(
+                    "Size of LazyStackedCompositeSpec and val differ along the "
+                    "stacking dimension"
+                )
+            for spec, v in zip(self._specs, torch.unbind(val, dim=self.dim)):
+                spec.assert_is_in(v)
+        return {key: self[key].to_numpy(val) for key, val in val.items()}
+
+    def __len__(self):
+        pass
+
+    def values(self):
+        for key in self.keys():
+            yield self[key]
+
+    def items(self):
+        for key in self.keys():
+            yield key, self[key]
+
+    def keys(
+        self,
+        include_nested: bool = False,
+        leaves_only: bool = False,
+    ) -> KeysView:
+        return self._specs[0].keys(
+            include_nested=include_nested, leaves_only=leaves_only
+        )
+
+    def project(self, val: TensorDictBase) -> TensorDictBase:
+        pass
+
+    def is_in(self, val: Union[dict, TensorDictBase]) -> bool:
+        pass
+
+    def type_check(
+        self,
+        value: Union[torch.Tensor, TensorDictBase],
+        selected_keys: Union[str, Optional[Sequence[str]]] = None,
+    ):
+        pass
+
+    def __repr__(self) -> str:
+        sub_str = ",\n".join(
+            [indent(f"{k}: {repr(item)}", 4 * " ") for k, item in self.items()]
+        )
+        device_str = f"device={self._specs[0].device}"
+        shape_str = f"shape={self.shape}"
+        sub_str = ", ".join([sub_str, device_str, shape_str])
+        return (
+            f"LazyStackedCompositeSpec(\n{', '.join([sub_str, device_str, shape_str])})"
+        )
+
+    def encode(self, vals: Dict[str, Any]) -> Dict[str, torch.Tensor]:
+        pass
+
+    def __delitem__(self, key):
+        pass
+
+    def __iter__(self):
+        pass
+
+    def __setitem__(self, key, value):
+        pass
+
+    @property
+    def device(self) -> DEVICE_TYPING:
+        return self._specs[0].device
+
+    @property
+    def ndim(self):
+        return self.ndimension()
+
+    def ndimension(self):
+        return len(self.shape)
+
+    def set(self, name, spec):
+        if spec is not None:
+            shape = spec.shape
+            if shape[: self.ndim] != self.shape:
+                raise ValueError(
+                    "The shape of the spec and the CompositeSpec mismatch: the first "
+                    f"{self.ndim} dimensions should match but got spec.shape={spec.shape} and "
+                    f"CompositeSpec.shape={self.shape}."
+                )
+        self._specs[name] = spec
+
+
+# for SPEC_CLASS in [BinaryDiscreteTensorSpec, BoundedTensorSpec, DiscreteTensorSpec, MultiDiscreteTensorSpec, MultiOneHotDiscreteTensorSpec, OneHotDiscreteTensorSpec, UnboundedContinuousTensorSpec, UnboundedDiscreteTensorSpec]:
+@TensorSpec.implements_for_spec(torch.stack)
+def _stack_specs(list_of_spec, dim, out=None):
+    if out is not None:
+        raise NotImplementedError(
+            "In-place spec modification is not a feature of torchrl, hence "
+            "torch.stack(list_of_specs, dim, out=spec) is not implemented."
+        )
+    if not len(list_of_spec):
+        raise ValueError("Cannot stack an empty list of specs.")
+    spec0 = list_of_spec[0]
+    if isinstance(spec0, TensorSpec):
+        device = spec0.device
+        all_equal = True
+        for spec in list_of_spec[1:]:
+            if not isinstance(spec, TensorSpec):
+                raise RuntimeError(
+                    "Stacking specs cannot occur: Found more than one type of specs in the list."
+                )
+            if device != spec.device:
+                raise RuntimeError(f"Devices differ, got {device} and {spec.device}")
+            all_equal = all_equal and spec == spec0
+        if all_equal:
+            shape = list(spec0.shape)
+            if dim < 0:
+                dim += len(shape) + 1
+            shape.insert(dim, len(list_of_spec))
+            return spec0.clone().unsqueeze(dim).expand(shape)
+        return LazyStackedTensorSpec(*list_of_spec, dim=dim)
+    else:
+        raise NotImplementedError
+
+
+@CompositeSpec.implements_for_spec(torch.stack)
+def _stack_composite_specs(list_of_spec, dim, out=None):
+    if out is not None:
+        raise NotImplementedError(
+            "In-place spec modification is not a feature of torchrl, hence "
+            "torch.stack(list_of_specs, dim, out=spec) is not implemented."
+        )
+    if not len(list_of_spec):
+        raise ValueError("Cannot stack an empty list of specs.")
+    spec0 = list_of_spec[0]
+    if isinstance(spec0, CompositeSpec):
+        device = spec0.device
+        all_equal = True
+        for spec in list_of_spec[1:]:
+            if not isinstance(spec, CompositeSpec):
+                raise RuntimeError(
+                    "Stacking specs cannot occur: Found more than one type of spec in "
+                    "the list."
+                )
+            if device != spec.device:
+                raise RuntimeError(f"Devices differ, got {device} and {spec.device}")
+            all_equal = all_equal and spec == spec0
+        if all_equal:
+            shape = list(spec0.shape)
+            if dim < 0:
+                dim += len(shape) + 1
+            shape.insert(dim, len(list_of_spec))
+            return spec0.clone().unsqueeze(dim).expand(shape)
+        return LazyStackedCompositeSpec(*list_of_spec, dim=dim)
+    else:
+        raise NotImplementedError
+
+
+@TensorSpec.implements_for_spec(torch.squeeze)
+def _squeeze_spec(spec: TensorSpec, *args, **kwargs) -> TensorSpec:
+    return spec.squeeze(*args, **kwargs)
+
+
+@CompositeSpec.implements_for_spec(torch.squeeze)
+def _squeeze_composite_spec(spec: CompositeSpec, *args, **kwargs) -> CompositeSpec:
+    return spec.squeeze(*args, **kwargs)
+
+
+@TensorSpec.implements_for_spec(torch.unsqueeze)
+def _unsqueeze_spec(spec: TensorSpec, *args, **kwargs) -> TensorSpec:
+    return spec.unsqueeze(*args, **kwargs)
+
+
+@CompositeSpec.implements_for_spec(torch.unsqueeze)
+def _unsqueeze_composite_spec(spec: CompositeSpec, *args, **kwargs) -> CompositeSpec:
+    return spec.unsqueeze(*args, **kwargs)
+
 
 def _keys_to_empty_composite_spec(keys):
     """Given a list of keys, creates a CompositeSpec tree where each leaf is assigned a None value."""
     if not len(keys):
         return
     c = CompositeSpec()
     for key in keys:
@@ -2117,30 +3161,59 @@
             else:
                 raise RuntimeError("Conflicting keys")
         else:
             c[key[0]] = _keys_to_empty_composite_spec(key[1:])
     return c
 
 
+def _squeezed_shape(shape: torch.Size, dim: int | None) -> torch.Size | None:
+    if dim is None:
+        if len(shape) == 1 or shape.count(1) == 0:
+            return None
+        new_shape = torch.Size([s for s in shape if s != 1])
+    else:
+        if dim < 0:
+            dim += len(shape)
+
+        if shape[dim] != 1:
+            return None
+
+        new_shape = torch.Size([s for i, s in enumerate(shape) if i != dim])
+    return new_shape
+
+
+def _unsqueezed_shape(shape: torch.Size, dim: int) -> torch.Size:
+    n = len(shape)
+    if dim < -(n + 1) or dim > n:
+        raise ValueError(
+            f"Dimension out of range, expected value in the range [{-(n+1)}, {n}], but "
+            f"got {dim}"
+        )
+    if dim < 0:
+        dim += n + 1
+
+    new_shape = list(shape)
+    new_shape.insert(dim, 1)
+    return torch.Size(new_shape)
+
+
 class _CompositeSpecKeysView:
     """Wrapper class that enables richer behaviour of `key in tensordict.keys()`."""
 
     def __init__(
         self,
         composite: CompositeSpec,
         include_nested,
         leaves_only,
     ):
         self.composite = composite
         self.leaves_only = leaves_only
         self.include_nested = include_nested
 
-    def __iter__(
-        self,
-    ):
+    def __iter__(self):
         for key, item in self.composite.items():
             if self.include_nested and isinstance(item, CompositeSpec):
                 for subkey in item.keys(
                     include_nested=True, leaves_only=self.leaves_only
                 ):
                     if not isinstance(subkey, tuple):
                         subkey = (subkey,)
```

## torchrl/data/datasets/__init__.py

```diff
@@ -1 +1,2 @@
 from .d4rl import D4RLExperienceReplay
+from .openml import OpenMLExperienceReplay
```

## torchrl/data/datasets/d4rl.py

```diff
@@ -12,23 +12,14 @@
 
 from torchrl.collectors.utils import split_trajectories
 from torchrl.data.replay_buffers import TensorDictReplayBuffer
 from torchrl.data.replay_buffers.samplers import Sampler
 from torchrl.data.replay_buffers.storages import LazyMemmapStorage
 from torchrl.data.replay_buffers.writers import Writer
 
-D4RL_ERR = None
-try:
-    import d4rl, gym  # noqa
-
-    _has_d4rl = True
-except ModuleNotFoundError as err:
-    _has_d4rl = False
-    D4RL_ERR = err
-
 
 class D4RLExperienceReplay(TensorDictReplayBuffer):
     """An Experience replay class for D4RL.
 
     To install D4RL, follow the instructions on the
     `official repo <https://github.com/Farama-Foundation/D4RL>`__.
 
@@ -52,15 +43,15 @@
             loading from a map-style dataset.
         pin_memory (bool): whether pin_memory() should be called on the rb
             samples.
         prefetch (int, optional): number of next batches to be prefetched
             using multithreading.
         transform (Transform, optional): Transform to be executed when sample() is called.
             To chain transforms use the :obj:`Compose` class.
-        split_trajs (bool, optional): if True, the trajectories will be split
+        split_trajs (bool, optional): if ``True``, the trajectories will be split
             along the first dimension and padded to have a matching shape.
             To split the trajectories, the ``"done"`` signal will be used, which
             is recovered via ``done = timeout | terminal``. In other words,
             it is assumed that any ``timeout`` or ``terminal`` signal is
             equivalent to the end of a trajectory. For some datasets from
             ``D4RL``, this may not be true. It is up to the user to make
             accurate choices regarding this usage of ``split_trajs``.
@@ -74,14 +65,23 @@
               Using ``from_env=False`` will provide less data than ``from_env=True``.
               For instance, the info keys will be left out.
               Usually, ``from_env=False`` with ``terminate_on_end=True`` will
               lead to the same result as ``from_env=True``, with the latter
               containing meta-data and info entries that the former does
               not possess.
 
+            .. note::
+
+              The keys in ``from_env=True`` and ``from_env=False`` *may* unexpectedly
+              differ. In particular, the ``"timeout"`` key (used to determine the
+              end of an episode) may be absent when ``from_env=False`` but present
+              otherwise, leading to a different slicing when ``traj_splits`` is enabled.
+
+        use_timeout_as_done (bool, optional): if ``True``, ``done = terminal | timeout``.
+            Otherwise, only the ``terminal`` key is used. Defaults to ``True``.
         **env_kwargs (key-value pairs): additional kwargs for
             :func:`d4rl.qlearning_dataset`. Supports ``terminate_on_end``
             (``False`` by default) or other kwargs if defined by D4RL library.
 
 
     Examples:
         >>> from torchrl.data.datasets.d4rl import D4RLExperienceReplay
@@ -89,36 +89,54 @@
         >>> data = D4RLExperienceReplay("maze2d-umaze-v1")
         >>> # we can append transforms to the dataset
         >>> data.append_transform(ObservationNorm(loc=-1, scale=1.0))
         >>> data.sample(128)
 
     """
 
+    D4RL_ERR = None
+
+    @classmethod
+    def _import_d4rl(cls):
+        try:
+            import d4rl  # noqa
+
+            cls._has_d4rl = True
+        except ModuleNotFoundError as err:
+            cls._has_d4rl = False
+            cls.D4RL_ERR = err
+
     def __init__(
         self,
         name,
         batch_size: int,
         sampler: Optional[Sampler] = None,
         writer: Optional[Writer] = None,
         collate_fn: Optional[Callable] = None,
         pin_memory: bool = False,
         prefetch: Optional[int] = None,
         transform: Optional["Transform"] = None,  # noqa-F821
         split_trajs: bool = False,
         from_env: bool = True,
+        use_timeout_as_done: bool = True,
         **env_kwargs,
     ):
 
-        if not _has_d4rl:
-            raise ImportError("Could not import d4rl") from D4RL_ERR
+        type(self)._import_d4rl()
+
+        if not self._has_d4rl:
+            raise ImportError("Could not import d4rl") from self.D4RL_ERR
         self.from_env = from_env
+        self.use_timeout_as_done = use_timeout_as_done
         if from_env:
             dataset = self._get_dataset_from_env(name, env_kwargs)
         else:
             dataset = self._get_dataset_direct(name, env_kwargs)
+        # Fill unknown next states with 0
+        dataset["next", "observation"][dataset["next", "done"].squeeze()] = 0
 
         if split_trajs:
             dataset = split_trajectories(dataset)
         storage = LazyMemmapStorage(dataset.shape[0])
         super().__init__(
             batch_size=batch_size,
             storage=storage,
@@ -130,14 +148,21 @@
             transform=transform,
         )
         self.extend(dataset)
 
     def _get_dataset_direct(self, name, env_kwargs):
         from torchrl.envs.libs.gym import GymWrapper
 
+        type(self)._import_d4rl()
+
+        if not self._has_d4rl:
+            raise ImportError("Could not import d4rl") from self.D4RL_ERR
+        import d4rl
+        import gym
+
         env = GymWrapper(gym.make(name))
         dataset = d4rl.qlearning_dataset(env._env, **env_kwargs)
 
         dataset = make_tensordict(
             {
                 k: torch.from_numpy(item)
                 for k, item in dataset.items()
@@ -156,19 +181,22 @@
             self.metadata = {}
         dataset.rename_key("observations", "observation")
         dataset.set("next", dataset.select())
         dataset.rename_key("next_observations", ("next", "observation"))
         dataset.rename_key("terminals", "terminal")
         if "timeouts" in dataset.keys():
             dataset.rename_key("timeouts", "timeout")
-        dataset.set(
-            "done",
-            dataset.get("terminal")
-            | dataset.get("timeout", torch.zeros((), dtype=torch.bool)),
-        )
+        if self.use_timeout_as_done:
+            dataset.set(
+                "done",
+                dataset.get("terminal")
+                | dataset.get("timeout", torch.zeros((), dtype=torch.bool)),
+            )
+        else:
+            dataset.set("done", dataset.get("terminal"))
         dataset.rename_key("rewards", "reward")
         dataset.rename_key("actions", "action")
 
         # let's make sure that the dtypes match what's expected
         for key, spec in env.observation_spec.items(True, True):
             dataset[key] = dataset[key].to(spec.dtype)
             dataset["next", key] = dataset["next", key].to(spec.dtype)
@@ -179,28 +207,31 @@
 
         dataset["done"] = dataset["done"].unsqueeze(-1)
         # dataset.rename_key("next_observations", "next/observation")
         dataset["reward"] = dataset["reward"].unsqueeze(-1)
         dataset["next"].update(
             dataset.select("reward", "done", "terminal", "timeout", strict=False)
         )
+        dataset = (
+            dataset.clone()
+        )  # make sure that all tensors have a different data_ptr
         self._shift_reward_done(dataset)
-        # Fill unknown next states with 0
-        dataset["next", "observation"][dataset["next", "done"].squeeze()] = 0
         self.specs = env.specs.clone()
         return dataset
 
     def _get_dataset_from_env(self, name, env_kwargs):
         """Creates an environment and retrieves the dataset using env.get_dataset().
 
         This method does not accept extra arguments.
 
         """
         if env_kwargs:
             raise RuntimeError("env_kwargs cannot be passed with using from_env=True")
+        import gym
+
         # we do a local import to avoid circular import issues
         from torchrl.envs.libs.gym import GymWrapper
 
         env = GymWrapper(gym.make(name))
         dataset = make_tensordict(
             {
                 k: torch.from_numpy(item)
@@ -219,19 +250,22 @@
         else:
             self.metadata = {}
 
         dataset.rename_key("observations", "observation")
         dataset.rename_key("terminals", "terminal")
         if "timeouts" in dataset.keys():
             dataset.rename_key("timeouts", "timeout")
-        dataset.set(
-            "done",
-            dataset.get("terminal")
-            | dataset.get("timeout", torch.zeros((), dtype=torch.bool)),
-        )
+        if self.use_timeout_as_done:
+            dataset.set(
+                "done",
+                dataset.get("terminal")
+                | dataset.get("timeout", torch.zeros((), dtype=torch.bool)),
+            )
+        else:
+            dataset.set("done", dataset.get("terminal"))
         dataset.rename_key("rewards", "reward")
         dataset.rename_key("actions", "action")
         try:
             dataset.rename_key("infos", "info")
         except KeyError:
             pass
 
@@ -249,17 +283,18 @@
         dataset = dataset[:-1].set(
             "next",
             dataset.select("observation", "info", strict=False)[1:],
         )
         dataset["next"].update(
             dataset.select("reward", "done", "terminal", "timeout", strict=False)
         )
+        dataset = (
+            dataset.clone()
+        )  # make sure that all tensors have a different data_ptr
         self._shift_reward_done(dataset)
-        # Fill unknown next states with 0
-        dataset["next", "observation"][dataset["next", "done"].squeeze()] = 0
         self.specs = env.specs.clone()
         return dataset
 
     def _shift_reward_done(self, dataset):
         dataset["reward"] = dataset["reward"].clone()
         dataset["done"] = dataset["done"].clone()
         dataset["reward"][1:] = dataset["reward"][:-1].clone()
```

## torchrl/data/postprocs/postprocs.py

```diff
@@ -78,17 +78,17 @@
     time_to_obs = time_to_obs - 1
     return summed_rewards, time_to_obs
 
 
 class MultiStep(nn.Module):
     """Multistep reward transform.
 
-    Presented in 'Sutton, R. S. 1988. Learning to
-    predict by the methods of temporal differences. Machine learning 3(
-    1):9–44.'
+    Presented in
+
+    | Sutton, R. S. 1988. Learning to predict by the methods of temporal differences. Machine learning 3(1):9–44.
 
     This module maps the "next" observation to the t + n "next" observation.
     It is an identity transform whenever :attr:`n_steps` is 0.
 
     Args:
         gamma (float): Discount factor for return computation
         n_steps (integer): maximum look-ahead steps.
@@ -149,14 +149,18 @@
 
         Returns:
             in-place transformation of the input tensordict.
 
         """
         tensordict = tensordict.clone(False)
         done = tensordict.get(("next", "done"))
+        truncated = tensordict.get(
+            ("next", "truncated"), torch.zeros((), dtype=done.dtype, device=done.device)
+        )
+        done = done | truncated
 
         # we'll be using the done states to index the tensordict.
         # if the shapes don't match we're in trouble.
         ndim = tensordict.ndim
         if done.shape != tensordict.shape:
             if done.shape[-1] == 1 and done.shape[:-1] == tensordict.shape:
                 done = done.squeeze(-1)
@@ -171,18 +175,14 @@
                     done = tensordict.get(("next", "done"))
                 except Exception as err:
                     raise RuntimeError(
                         "tensordict shape must be compatible with the done's shape "
                         "(trailing singleton dimension excluded)."
                     ) from err
 
-        truncated = tensordict.get(
-            ("next", "truncated"), torch.zeros((), dtype=done.dtype, device=done.device)
-        )
-        done = done | truncated
         mask = tensordict.get(("collector", "mask"), None)
         reward = tensordict.get(("next", "reward"))
         *batch, T = tensordict.batch_size
 
         # sum rewards
         summed_rewards, time_to_obs = _get_reward(
             self.gamma, reward, done, self.n_steps
@@ -197,15 +197,15 @@
         # The fifth remains the fifth as it is terminal
         tensordict_gather = (
             tensordict["next"].exclude("reward", "done").gather(-1, idx_to_gather)
         )
 
         tensordict.set("steps_to_next_obs", time_to_obs + 1)
         tensordict.rename_key_(("next", "reward"), ("next", "original_reward"))
-        tensordict["next"].update(tensordict_gather)
+        tensordict.get("next").update(tensordict_gather)
         tensordict.set(("next", "reward"), summed_rewards)
         tensordict.set("gamma", self.gamma ** (time_to_obs + 1))
         nonterminal = time_to_obs != 0
         if mask is not None:
             mask = mask.view(*batch, T)
             nonterminal[~mask] = False
         tensordict.set("nonterminal", nonterminal)
```

## torchrl/data/replay_buffers/replay_buffers.py

```diff
@@ -6,25 +6,40 @@
 import collections
 import threading
 import warnings
 from concurrent.futures import ThreadPoolExecutor
 from typing import Any, Callable, Dict, List, Optional, Sequence, Tuple, Union
 
 import torch
-from tensordict.tensordict import LazyStackedTensorDict, TensorDict, TensorDictBase
-from tensordict.utils import expand_right
 
-from torchrl.data.utils import DEVICE_TYPING
-
-from ..._utils import accept_remote_rref_udf_invocation
+from tensordict import is_tensorclass
+from tensordict.tensordict import (
+    is_tensor_collection,
+    LazyStackedTensorDict,
+    TensorDict,
+    TensorDictBase,
+)
+from tensordict.utils import expand_as_right
+
+from torchrl._utils import accept_remote_rref_udf_invocation
+
+from torchrl.data.replay_buffers.samplers import (
+    PrioritizedSampler,
+    RandomSampler,
+    Sampler,
+)
+from torchrl.data.replay_buffers.storages import (
+    _get_default_collate,
+    ListStorage,
+    Storage,
+)
+from torchrl.data.replay_buffers.utils import _to_numpy, _to_torch, INT_CLASSES
+from torchrl.data.replay_buffers.writers import RoundRobinWriter, Writer
 
-from .samplers import PrioritizedSampler, RandomSampler, Sampler
-from .storages import _get_default_collate, ListStorage, Storage
-from .utils import _to_numpy, INT_CLASSES
-from .writers import RoundRobinWriter, Writer
+from torchrl.data.utils import DEVICE_TYPING
 
 
 def stack_tensors(list_of_tensor_iterators: List) -> Tuple[torch.Tensor]:
     """Zips a list of iterables containing tensor-like objects and stacks the resulting lists of tensors together.
 
     Args:
         list_of_tensor_iterators (list): Sequence containing similar iterators,
@@ -78,40 +93,97 @@
 
     return decorated_fun
 
 
 class ReplayBuffer:
     """A generic, composable replay buffer class.
 
-    Args:
+    Keyword Args:
         storage (Storage, optional): the storage to be used. If none is provided
-            a default ListStorage with max_size of 1_000 will be created.
-        sampler (Sampler, optional): the sampler to be used. If none is provided
-            a default RandomSampler() will be used.
+            a default :class:`~torchrl.data.replay_buffers.ListStorage` with
+            ``max_size`` of ``1_000`` will be created.
+        sampler (Sampler, optional): the sampler to be used. If none is provided,
+            a default :class:`~torchrl.data.replay_buffers.RandomSampler`
+            will be used.
         writer (Writer, optional): the writer to be used. If none is provided
-            a default RoundRobinWriter() will be used.
+            a default :class:`~torchrl.data.replay_buffers.RoundRobinWriter`
+            will be used.
         collate_fn (callable, optional): merges a list of samples to form a
             mini-batch of Tensor(s)/outputs.  Used when using batched
-            loading from a map-style dataset.
+            loading from a map-style dataset. The default value will be decided
+            based on the storage type.
         pin_memory (bool): whether pin_memory() should be called on the rb
             samples.
         prefetch (int, optional): number of next batches to be prefetched
-            using multithreading.
-        transform (Transform, optional): Transform to be executed when sample() is called.
-            To chain transforms use the :obj:`Compose` class.
+            using multithreading. Defaults to None (no prefetching).
+        transform (Transform, optional): Transform to be executed when
+            sample() is called.
+            To chain transforms use the :class:`~torchrl.envs.Compose` class.
             Transforms should be used with :class:`tensordict.TensorDict`
             content. If used with other structures, the transforms should be
-            encoded with a `"data"` leading key that will be used to
+            encoded with a ``"data"`` leading key that will be used to
             construct a tensordict from the non-tensordict content.
-        batch_size (int, optional): the batch size to be used when sample() is called.
+        batch_size (int, optional): the batch size to be used when sample() is
+            called.
+            .. note::
+              The batch-size can be specified at construction time via the
+              ``batch_size`` argument, or at sampling time. The former should
+              be preferred whenever the batch-size is consistent across the
+              experiment. If the batch-size is likely to change, it can be
+              passed to the :meth:`~.sample` method. This option is
+              incompatible with prefetching (since this requires to know the
+              batch-size in advance) as well as with samplers that have a
+              ``drop_last`` argument.
+
+    Examples:
+        >>> import torch
+        >>>
+        >>> from torchrl.data import ReplayBuffer, ListStorage
+        >>>
+        >>> torch.manual_seed(0)
+        >>> rb = ReplayBuffer(
+        ...     storage=ListStorage(max_size=1000),
+        ...     batch_size=5,
+        ... )
+        >>> # populate the replay buffer and get the item indices
+        >>> data = range(10)
+        >>> indices = rb.extend(data)
+        >>> # sample will return as many elements as specified in the constructor
+        >>> sample = rb.sample()
+        >>> print(sample)
+        tensor([4, 9, 3, 0, 3])
+        >>> # Passing the batch-size to the sample method overrides the one in the constructor
+        >>> sample = rb.sample(batch_size=3)
+        >>> print(sample)
+        tensor([9, 7, 3])
+        >>> # one cans sample using the ``sample`` method or iterate over the buffer
+        >>> for i, batch in enumerate(rb):
+        ...     print(i, batch)
+        ...     if i == 3:
+        ...         break
+        0 tensor([7, 3, 1, 6, 6])
+        1 tensor([9, 8, 6, 6, 8])
+        2 tensor([4, 3, 6, 9, 1])
+        3 tensor([4, 4, 1, 9, 9])
+
+    Replay buffers accept *any* kind of data. Not all storage types
+    will work, as some expect numerical data only, but the default
+    :class:`torchrl.data.ListStorage` will:
 
+    Examples:
+        >>> torch.manual_seed(0)
+        >>> buffer = ReplayBuffer(storage=ListStorage(100), collate_fn=lambda x: x)
+        >>> indices = buffer.extend(["a", 1, None])
+        >>> buffer.sample(3)
+        [None, 'a', None]
     """
 
     def __init__(
         self,
+        *,
         storage: Optional[Storage] = None,
         sampler: Optional[Sampler] = None,
         writer: Optional[Writer] = None,
         collate_fn: Optional[Callable] = None,
         pin_memory: bool = False,
         prefetch: Optional[int] = None,
         transform: Optional["Transform"] = None,  # noqa-F821
@@ -122,15 +194,17 @@
         self._sampler = sampler if sampler is not None else RandomSampler()
         self._writer = writer if writer is not None else RoundRobinWriter()
         self._writer.register_storage(self._storage)
 
         self._collate_fn = (
             collate_fn
             if collate_fn is not None
-            else _get_default_collate(self._storage)
+            else _get_default_collate(
+                self._storage, _is_tensordict=isinstance(self, TensorDictReplayBuffer)
+            )
         )
         self._pin_memory = pin_memory
 
         self._prefetch = bool(prefetch)
         self._prefetch_cap = prefetch or 0
         self._prefetch_queue = collections.deque()
         if self._prefetch_cap:
@@ -143,18 +217,29 @@
         if transform is None:
             transform = Compose()
         elif not isinstance(transform, Compose):
             transform = Compose(transform)
         transform.eval()
         self._transform = transform
 
-        if batch_size is None:
-            warnings.warn(
-                "Constructing replay buffer without specifying behaviour is no longer "
-                "recommended, and will be deprecated in the future."
+        if batch_size is None and prefetch:
+            raise ValueError(
+                "Dynamic batch-size specification is incompatible "
+                "with multithreaded sampling. "
+                "When using prefetch, the batch-size must be specified in "
+                "advance. "
+            )
+        if (
+            batch_size is None
+            and hasattr(self._sampler, "drop_last")
+            and self._sampler.drop_last
+        ):
+            raise ValueError(
+                "Samplers with drop_last=True must work with a predictible batch-size. "
+                "Please pass the batch-size to the ReplayBuffer constructor."
             )
         self._batch_size = batch_size
 
     def __len__(self) -> int:
         with self._replay_lock:
             return len(self._storage)
 
@@ -172,14 +257,23 @@
         index = _to_numpy(index)
         with self._replay_lock:
             data = self._storage[index]
 
         if not isinstance(index, INT_CLASSES):
             data = self._collate_fn(data)
 
+        if self._transform is not None and len(self._transform):
+            is_td = True
+            if not is_tensor_collection(data):
+                data = TensorDict({"data": data}, [])
+                is_td = False
+            data = self._transform(data)
+            if not is_td:
+                data = data["data"]
+
         return data
 
     def state_dict(self) -> Dict[str, Any]:
         return {
             "_storage": self._storage.state_dict(),
             "_sampler": self._sampler.state_dict(),
             "_writer": self._writer.state_dict(),
@@ -210,19 +304,19 @@
         """Extends the replay buffer with one or more elements contained in an iterable.
 
         Args:
             data (iterable): collection of data to be added to the replay
                 buffer.
 
         Returns:
-            Indices of the data aded to the replay buffer.
+            Indices of the data added to the replay buffer.
         """
-        if self._transform is not None and isinstance(data, TensorDictBase):
+        if self._transform is not None and is_tensor_collection(data):
             data = self._transform.inv(data)
-        elif self._transform is not None:
+        elif self._transform is not None and len(self._transform):
             # Accepts transforms that act on "data" key
             data = self._transform.inv(TensorDict({"data": data}, [])).get("data")
         with self._replay_lock:
             index = self._writer.extend(data)
             self._sampler.extend(index)
         return index
 
@@ -234,23 +328,29 @@
         with self._replay_lock:
             self._sampler.update_priority(index, priority)
 
     @pin_memory_output
     def _sample(self, batch_size: int) -> Tuple[Any, dict]:
         with self._replay_lock:
             index, info = self._sampler.sample(self._storage, batch_size)
+            info["index"] = index
             data = self._storage[index]
         if not isinstance(index, INT_CLASSES):
             data = self._collate_fn(data)
-        if self._transform is not None:
+        if self._transform is not None and len(self._transform):
             is_td = True
-            if not isinstance(data, TensorDictBase):
+            if not is_tensor_collection(data):
                 data = TensorDict({"data": data}, [])
                 is_td = False
+            is_locked = data.is_locked
+            if is_locked:
+                data.unlock_()
             data = self._transform(data)
+            if is_locked:
+                data.lock_()
             if not is_td:
                 data = data["data"]
 
         return data, info
 
     def sample(
         self, batch_size: Optional[int] = None, return_info: bool = False
@@ -266,25 +366,34 @@
             return_info (bool): whether to return info. If True, the result
                 is a tuple (data, info). If False, the result is the data.
 
         Returns:
             A batch of data selected in the replay buffer.
             A tuple containing this batch and info if return_info flag is set to True.
         """
-        if batch_size is not None:
+        if (
+            batch_size is not None
+            and self._batch_size is not None
+            and batch_size != self._batch_size
+        ):
             warnings.warn(
-                "batch_size argument in sample has been deprecated. Set the batch_size "
-                "when constructing the replay buffer instead."
+                f"Got conflicting batch_sizes in constructor ({self._batch_size}) "
+                f"and `sample` ({batch_size}). Refer to the ReplayBuffer documentation "
+                "for a proper usage of the batch-size arguments. "
+                "The batch-size provided to the sample method "
+                "will prevail."
             )
-        elif self._batch_size is not None:
+        elif batch_size is None and self._batch_size is not None:
             batch_size = self._batch_size
-        else:
+        elif batch_size is None:
             raise RuntimeError(
                 "batch_size not specified. You can specify the batch_size when "
-                "constructing the replay buffer"
+                "constructing the replay buffer, or pass it to the sample method. "
+                "Refer to the ReplayBuffer documentation "
+                "for a proper usage of the batch-size arguments."
             )
         if not self._prefetch:
             ret = self._sample(batch_size)
         else:
             if len(self._prefetch_queue) == 0:
                 ret = self._sample(batch_size)
             else:
@@ -323,53 +432,111 @@
             index (int): Position to insert the transform.
             transform (Transform): The transform to be appended
         """
         transform.eval()
         self._transform.insert(index, transform)
 
     def __iter__(self):
+        if self._sampler.ran_out:
+            self._sampler.ran_out = False
         if self._batch_size is None:
             raise RuntimeError(
-                "batch_size was not specified during construction of the replay buffer"
+                "Cannot iterate over the replay buffer. "
+                "Batch_size was not specified during construction of the replay buffer."
             )
         while not self._sampler.ran_out:
             data = self.sample()
             yield data
 
 
 class PrioritizedReplayBuffer(ReplayBuffer):
     """Prioritized replay buffer.
 
+    All arguments are keyword-only arguments.
+
     Presented in
         "Schaul, T.; Quan, J.; Antonoglou, I.; and Silver, D. 2015.
         Prioritized experience replay."
         (https://arxiv.org/abs/1511.05952)
 
     Args:
         alpha (float): exponent α determines how much prioritization is used,
             with α = 0 corresponding to the uniform case.
         beta (float): importance sampling negative exponent.
         eps (float): delta added to the priorities to ensure that the buffer
             does not contain null priorities.
-        dtype (torch.dtype): type of the data. Can be torch.float or torch.double.
         storage (Storage, optional): the storage to be used. If none is provided
-            a default ListStorage with max_size of 1_000 will be created.
+            a default :class:`~torchrl.data.replay_buffers.ListStorage` with
+            ``max_size`` of ``1_000`` will be created.
         collate_fn (callable, optional): merges a list of samples to form a
             mini-batch of Tensor(s)/outputs.  Used when using batched
-            loading from a map-style dataset.
+            loading from a map-style dataset. The default value will be decided
+            based on the storage type.
         pin_memory (bool): whether pin_memory() should be called on the rb
             samples.
         prefetch (int, optional): number of next batches to be prefetched
-            using multithreading.
-        transform (Transform, optional): Transform to be executed when sample() is called.
-            To chain transforms use the :obj:`Compose` class.
+            using multithreading. Defaults to None (no prefetching).
+        transform (Transform, optional): Transform to be executed when
+            sample() is called.
+            To chain transforms use the :class:`~torchrl.envs.Compose` class.
+            Transforms should be used with :class:`tensordict.TensorDict`
+            content. If used with other structures, the transforms should be
+            encoded with a ``"data"`` leading key that will be used to
+            construct a tensordict from the non-tensordict content.
+        batch_size (int, optional): the batch size to be used when sample() is
+            called.
+            .. note::
+              The batch-size can be specified at construction time via the
+              ``batch_size`` argument, or at sampling time. The former should
+              be preferred whenever the batch-size is consistent across the
+              experiment. If the batch-size is likely to change, it can be
+              passed to the :meth:`~.sample` method. This option is
+              incompatible with prefetching (since this requires to know the
+              batch-size in advance) as well as with samplers that have a
+              ``drop_last`` argument.
+
+    .. note::
+        Generic prioritized replay buffers (ie. non-tensordict backed) require
+        calling :meth:`~.sample` with the ``return_info`` argument set to
+        ``True`` to have access to the indices, and hence update the priority.
+        Using :class:`tensordict.TensorDict` and the related
+        :class:`~torchrl.data.TensorDictPrioritizedReplayBuffer` simplifies this
+        process.
+
+    Examples:
+        >>> import torch
+        >>>
+        >>> from torchrl.data import ListStorage, PrioritizedReplayBuffer
+        >>>
+        >>> torch.manual_seed(0)
+        >>>
+        >>> rb = PrioritizedReplayBuffer(alpha=0.7, beta=0.9, storage=ListStorage(10))
+        >>> data = range(10)
+        >>> rb.extend(data)
+        >>> sample = rb.sample(3)
+        >>> print(sample)
+        tensor([1, 0, 1])
+        >>> # get the info to find what the indices are
+        >>> sample, info = rb.sample(5, return_info=True)
+        >>> print(sample, info)
+        tensor([2, 7, 4, 3, 5]) {'_weight': array([1., 1., 1., 1., 1.], dtype=float32), 'index': array([2, 7, 4, 3, 5])}
+        >>> # update priority
+        >>> priority = torch.ones(5) * 5
+        >>> rb.update_priority(info["index"], priority)
+        >>> # and now a new sample, the weights should be updated
+        >>> sample, info = rb.sample(5, return_info=True)
+        >>> print(sample, info)
+        tensor([2, 5, 2, 2, 5]) {'_weight': array([0.36278465, 0.36278465, 0.36278465, 0.36278465, 0.36278465],
+              dtype=float32), 'index': array([2, 5, 2, 2, 5])}
+
     """
 
     def __init__(
         self,
+        *,
         alpha: float,
         beta: float,
         eps: float = 1e-8,
         dtype: torch.dtype = torch.float,
         storage: Optional[Storage] = None,
         collate_fn: Optional[Callable] = None,
         pin_memory: bool = False,
@@ -388,31 +555,128 @@
             prefetch=prefetch,
             transform=transform,
             batch_size=batch_size,
         )
 
 
 class TensorDictReplayBuffer(ReplayBuffer):
-    """TensorDict-specific wrapper around the ReplayBuffer class.
+    """TensorDict-specific wrapper around the :class:`~torchrl.data.ReplayBuffer` class.
+
+    Keyword Args:
+        storage (Storage, optional): the storage to be used. If none is provided
+            a default :class:`~torchrl.data.replay_buffers.ListStorage` with
+            ``max_size`` of ``1_000`` will be created.
+        sampler (Sampler, optional): the sampler to be used. If none is provided
+            a default RandomSampler() will be used.
+        writer (Writer, optional): the writer to be used. If none is provided
+            a default :class:`~torchrl.data.replay_buffers.RoundRobinWriter`
+            will be used.
+        collate_fn (callable, optional): merges a list of samples to form a
+            mini-batch of Tensor(s)/outputs.  Used when using batched
+            loading from a map-style dataset. The default value will be decided
+            based on the storage type.
+        pin_memory (bool): whether pin_memory() should be called on the rb
+            samples.
+        prefetch (int, optional): number of next batches to be prefetched
+            using multithreading. Defaults to None (no prefetching).
+        transform (Transform, optional): Transform to be executed when
+            sample() is called.
+            To chain transforms use the :class:`~torchrl.envs.Compose` class.
+            Transforms should be used with :class:`tensordict.TensorDict`
+            content. If used with other structures, the transforms should be
+            encoded with a ``"data"`` leading key that will be used to
+            construct a tensordict from the non-tensordict content.
+        batch_size (int, optional): the batch size to be used when sample() is
+            called.
+            .. note::
+              The batch-size can be specified at construction time via the
+              ``batch_size`` argument, or at sampling time. The former should
+              be preferred whenever the batch-size is consistent across the
+              experiment. If the batch-size is likely to change, it can be
+              passed to the :meth:`~.sample` method. This option is
+              incompatible with prefetching (since this requires to know the
+              batch-size in advance) as well as with samplers that have a
+              ``drop_last`` argument.
+        priority_key (str, optional): the key at which priority is assumed to
+            be stored within TensorDicts added to this ReplayBuffer.
+            This is to be used when the sampler is of type
+            :class:`~torchrl.data.PrioritizedSampler`.
+            Defaults to ``"td_error"``.
+
+    Examples:
+        >>> import torch
+        >>>
+        >>> from torchrl.data import LazyTensorStorage, TensorDictReplayBuffer
+        >>> from tensordict import TensorDict
+        >>>
+        >>> torch.manual_seed(0)
+        >>>
+        >>> rb = TensorDictReplayBuffer(storage=LazyTensorStorage(10), batch_size=5)
+        >>> data = TensorDict({"a": torch.ones(10, 3), ("b", "c"): torch.zeros(10, 1, 1)}, [10])
+        >>> rb.extend(data)
+        >>> sample = rb.sample(3)
+        >>> # samples keep track of the index
+        >>> print(sample)
+        TensorDict(
+            fields={
+                a: Tensor(shape=torch.Size([3, 3]), device=cpu, dtype=torch.float32, is_shared=False),
+                b: TensorDict(
+                    fields={
+                        c: Tensor(shape=torch.Size([3, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False)},
+                    batch_size=torch.Size([3]),
+                    device=cpu,
+                    is_shared=False),
+                index: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.int32, is_shared=False)},
+            batch_size=torch.Size([3]),
+            device=cpu,
+            is_shared=False)
+        >>> # we can iterate over the buffer
+        >>> for i, data in enumerate(rb):
+        ...     print(i, data)
+        ...     if i == 2:
+        ...         break
+        0 TensorDict(
+            fields={
+                a: Tensor(shape=torch.Size([5, 3]), device=cpu, dtype=torch.float32, is_shared=False),
+                b: TensorDict(
+                    fields={
+                        c: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False)},
+                    batch_size=torch.Size([5]),
+                    device=cpu,
+                    is_shared=False),
+                index: Tensor(shape=torch.Size([5]), device=cpu, dtype=torch.int32, is_shared=False)},
+            batch_size=torch.Size([5]),
+            device=cpu,
+            is_shared=False)
+        1 TensorDict(
+            fields={
+                a: Tensor(shape=torch.Size([5, 3]), device=cpu, dtype=torch.float32, is_shared=False),
+                b: TensorDict(
+                    fields={
+                        c: Tensor(shape=torch.Size([5, 1, 1]), device=cpu, dtype=torch.float32, is_shared=False)},
+                    batch_size=torch.Size([5]),
+                    device=cpu,
+                    is_shared=False),
+                index: Tensor(shape=torch.Size([5]), device=cpu, dtype=torch.int32, is_shared=False)},
+            batch_size=torch.Size([5]),
+            device=cpu,
+            is_shared=False)
 
-    Args:
-        priority_key (str): the key at which priority is assumed to be stored
-            within TensorDicts added to this ReplayBuffer.
     """
 
-    def __init__(self, *args, priority_key: str = "td_error", **kw) -> None:
-        super().__init__(*args, **kw)
+    def __init__(self, *, priority_key: str = "td_error", **kw) -> None:
+
+        super().__init__(**kw)
         self.priority_key = priority_key
 
     def _get_priority(self, tensordict: TensorDictBase) -> Optional[torch.Tensor]:
+        if "_data" in tensordict.keys():
+            tensordict = tensordict.get("_data")
         if self.priority_key not in tensordict.keys():
             return self._sampler.default_priority
-        if tensordict.batch_dims:
-            tensordict = tensordict.clone(recurse=False)
-            tensordict.batch_size = []
         try:
             priority = tensordict.get(self.priority_key)
             if priority.numel() > 1:
                 priority = _reduce(priority, self._sampler.reduction)
             else:
                 priority = priority.item()
         except ValueError:
@@ -420,24 +684,40 @@
                 f"Found a priority key of size"
                 f" {tensordict.get(self.priority_key).shape} but expected "
                 f"scalar value"
             )
         return priority
 
     def add(self, data: TensorDictBase) -> int:
-        index = super().add(data)
-        data.set("index", index)
+        if is_tensor_collection(data):
+            data_add = TensorDict(
+                {
+                    "_data": data,
+                },
+                batch_size=[],
+            )
+            if data.batch_size:
+                data_add["_batch_size"] = torch.tensor(data.batch_size)
 
-        priority = self._get_priority(data)
-        if priority:
-            self.update_priority(index, priority)
+        else:
+            data_add = data
+        index = super().add(data_add)
+        if is_tensor_collection(data_add):
+            data_add.set("index", index)
+
+        # priority = self._get_priority(data)
+        # if priority:
+        self.update_tensordict_priority(data_add)
         return index
 
     def extend(self, tensordicts: Union[List, TensorDictBase]) -> torch.Tensor:
-        if isinstance(tensordicts, TensorDictBase):
+        if is_tensor_collection(tensordicts):
+            tensordicts = TensorDict(
+                {"_data": tensordicts}, batch_size=tensordicts.batch_size[:1]
+            )
             if tensordicts.batch_dims > 1:
                 # we want the tensordict to have one dimension only. The batch size
                 # of the sampled tensordicts can be changed thereafter
                 if not isinstance(tensordicts, LazyStackedTensorDict):
                     tensordicts = tensordicts.clone(recurse=False)
                 else:
                     tensordicts = tensordicts.contiguous()
@@ -445,129 +725,210 @@
                 if "_batch_size" in tensordicts.keys():
                     raise KeyError(
                         "conflicting key '_batch_size'. Consider removing from data."
                     )
                 shape = torch.tensor(tensordicts.batch_size[1:]).expand(
                     tensordicts.batch_size[0], tensordicts.batch_dims - 1
                 )
-                tensordicts.batch_size = tensordicts.batch_size[:1]
                 tensordicts.set("_batch_size", shape)
             tensordicts.set(
                 "index",
                 torch.zeros(
                     tensordicts.shape, device=tensordicts.device, dtype=torch.int
                 ),
             )
 
-        if not isinstance(tensordicts, TensorDictBase):
+        if not is_tensor_collection(tensordicts):
             stacked_td = torch.stack(tensordicts, 0)
         else:
             stacked_td = tensordicts
 
         index = super().extend(stacked_td)
         stacked_td.set(
             "index",
             torch.tensor(index, dtype=torch.int, device=stacked_td.device),
             inplace=True,
         )
         self.update_tensordict_priority(stacked_td)
         return index
 
     def update_tensordict_priority(self, data: TensorDictBase) -> None:
-        priority = torch.tensor(
-            [self._get_priority(td) for td in data],
-            dtype=torch.float,
-            device=data.device,
-        )
+        if not isinstance(self._sampler, PrioritizedSampler):
+            return
+        if data.ndim:
+            priority = torch.tensor(
+                [self._get_priority(td) for td in data],
+                dtype=torch.float,
+                device=data.device,
+            )
+        else:
+            priority = self._get_priority(data)
         # if the index shape does not match the priority shape, we have expanded it.
         # we just take the first value
         index = data.get("index")
         while index.shape != priority.shape:
             # reduce index
             index = index[..., 0]
         self.update_priority(index, priority)
 
     def sample(
         self,
         batch_size: Optional[int] = None,
-        include_info: bool = False,
         return_info: bool = False,
+        include_info: bool = None,
     ) -> TensorDictBase:
         """Samples a batch of data from the replay buffer.
 
         Uses Sampler to sample indices, and retrieves them from Storage.
 
         Args:
             batch_size (int, optional): size of data to be collected. If none
                 is provided, this method will sample a batch-size as indicated
                 by the sampler.
-            include_info (bool): whether to add info to the returned tensordict.
             return_info (bool): whether to return info. If True, the result
                 is a tuple (data, info). If False, the result is the data.
 
         Returns:
             A tensordict containing a batch of data selected in the replay buffer.
             A tuple containing this tensordict and info if return_info flag is set to True.
         """
+        if include_info is not None:
+            warnings.warn(
+                "include_info is going to be deprecated soon."
+                "The default behaviour has changed to `include_info=True` "
+                "to avoid bugs linked to wrongly preassigned values in the "
+                "output tensordict."
+            )
+
         data, info = super().sample(batch_size, return_info=True)
-        if include_info:
+        if not is_tensorclass(data) and include_info in (True, None):
+            is_locked = data.is_locked
+            if is_locked:
+                data.unlock_()
             for k, v in info.items():
-                data.set(k, torch.tensor(v, device=data.device), inplace=True)
-        if "_batch_size" in data.keys():
-            # we need to reset the batch-size
-            shape = data.pop("_batch_size")
-            shape = shape[0]
-            shape = torch.Size([data.shape[0], *shape])
-            # we may need to update some values in the data
-            for key, value in data.items():
-                if value.ndim >= len(shape):
-                    continue
-                value = expand_right(value, shape)
-                data.set(key, value)
-            data.batch_size = shape
+                data.set(k, expand_as_right(_to_torch(v, data.device), data))
+            if is_locked:
+                data.lock_()
         if return_info:
             return data, info
         return data
 
 
 class TensorDictPrioritizedReplayBuffer(TensorDictReplayBuffer):
-    """TensorDict-specific wrapper around the PrioritizedReplayBuffer class.
+    """TensorDict-specific wrapper around the :class:`~torchrl.data.PrioritizedReplayBuffer` class.
 
-    This class returns tensordicts with a new key "index" that represents
+    This class returns tensordicts with a new key ``"index"`` that represents
     the index of each element in the replay buffer. It also provides the
-    'update_tensordict_priority' method that only requires for the
+    :meth:`~.update_tensordict_priority` method that only requires for the
     tensordict to be passed to it with its new priority value.
 
-    Args:
-        alpha (float): exponent α determines how much prioritization is
-            used, with α = 0 corresponding to the uniform case.
+    Keyword Args:
+        alpha (float): exponent α determines how much prioritization is used,
+            with α = 0 corresponding to the uniform case.
         beta (float): importance sampling negative exponent.
-        priority_key (str, optional): key where the priority value can be
-            found in the stored tensordicts. Default is :obj:`"td_error"`
-        eps (float, optional): delta added to the priorities to ensure that the
-            buffer does not contain null priorities.
-        dtype (torch.dtype): type of the data. Can be torch.float or torch.double.
+        eps (float): delta added to the priorities to ensure that the buffer
+            does not contain null priorities.
         storage (Storage, optional): the storage to be used. If none is provided
-            a default ListStorage with max_size of 1_000 will be created.
+            a default :class:`~torchrl.data.replay_buffers.ListStorage` with
+            ``max_size`` of ``1_000`` will be created.
         collate_fn (callable, optional): merges a list of samples to form a
-            mini-batch of Tensor(s)/outputs.  Used when using batched loading
-            from a map-style dataset.
-        pin_memory (bool, optional): whether pin_memory() should be called on
-            the rb samples. Default is :obj:`False`.
+            mini-batch of Tensor(s)/outputs.  Used when using batched
+            loading from a map-style dataset. The default value will be decided
+            based on the storage type.
+        pin_memory (bool): whether pin_memory() should be called on the rb
+            samples.
         prefetch (int, optional): number of next batches to be prefetched
-            using multithreading.
-        transform (Transform, optional): Transform to be executed when sample() is called.
-            To chain transforms use the :obj:`Compose` class.
+            using multithreading. Defaults to None (no prefetching).
+        transform (Transform, optional): Transform to be executed when
+            sample() is called.
+            To chain transforms use the :class:`~torchrl.envs.Compose` class.
+            Transforms should be used with :class:`tensordict.TensorDict`
+            content. If used with other structures, the transforms should be
+            encoded with a ``"data"`` leading key that will be used to
+            construct a tensordict from the non-tensordict content.
+        batch_size (int, optional): the batch size to be used when sample() is
+            called.
+            .. note::
+              The batch-size can be specified at construction time via the
+              ``batch_size`` argument, or at sampling time. The former should
+              be preferred whenever the batch-size is consistent across the
+              experiment. If the batch-size is likely to change, it can be
+              passed to the :meth:`~.sample` method. This option is
+              incompatible with prefetching (since this requires to know the
+              batch-size in advance) as well as with samplers that have a
+              ``drop_last`` argument.
+        priority_key (str, optional): the key at which priority is assumed to
+            be stored within TensorDicts added to this ReplayBuffer.
+            This is to be used when the sampler is of type
+            :class:`~torchrl.data.PrioritizedSampler`.
+            Defaults to ``"td_error"``.
         reduction (str, optional): the reduction method for multidimensional
             tensordicts (ie stored trajectories). Can be one of "max", "min",
             "median" or "mean".
+
+    Examples:
+        >>> import torch
+        >>>
+        >>> from torchrl.data import LazyTensorStorage, TensorDictPrioritizedReplayBuffer
+        >>> from tensordict import TensorDict
+        >>>
+        >>> torch.manual_seed(0)
+        >>>
+        >>> rb = TensorDictPrioritizedReplayBuffer(alpha=0.7, beta=1.1, storage=LazyTensorStorage(10), batch_size=5)
+        >>> data = TensorDict({"a": torch.ones(10, 3), ("b", "c"): torch.zeros(10, 3, 1)}, [10])
+        >>> rb.extend(data)
+        >>> print("len of rb", len(rb))
+        len of rb 10
+        >>> sample = rb.sample(5)
+        >>> print(sample)
+        TensorDict(
+            fields={
+                _weight: Tensor(shape=torch.Size([5]), device=cpu, dtype=torch.float32, is_shared=False),
+                a: Tensor(shape=torch.Size([5, 3]), device=cpu, dtype=torch.float32, is_shared=False),
+                b: TensorDict(
+                    fields={
+                        c: Tensor(shape=torch.Size([5, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},
+                    batch_size=torch.Size([5]),
+                    device=cpu,
+                    is_shared=False),
+                index: Tensor(shape=torch.Size([5]), device=cpu, dtype=torch.int64, is_shared=False)},
+            batch_size=torch.Size([5]),
+            device=cpu,
+            is_shared=False)
+        >>> print("index", sample["index"])
+        index tensor([9, 5, 2, 2, 7])
+        >>> # give a high priority to these samples...
+        >>> sample.set("td_error", 100*torch.ones(sample.shape))
+        >>> # and update priority
+        >>> rb.update_tensordict_priority(sample)
+        >>> # the new sample should have a high overlap with the previous one
+        >>> sample = rb.sample(5)
+        >>> print(sample)
+        TensorDict(
+            fields={
+                _weight: Tensor(shape=torch.Size([5]), device=cpu, dtype=torch.float32, is_shared=False),
+                a: Tensor(shape=torch.Size([5, 3]), device=cpu, dtype=torch.float32, is_shared=False),
+                b: TensorDict(
+                    fields={
+                        c: Tensor(shape=torch.Size([5, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},
+                    batch_size=torch.Size([5]),
+                    device=cpu,
+                    is_shared=False),
+                index: Tensor(shape=torch.Size([5]), device=cpu, dtype=torch.int64, is_shared=False)},
+            batch_size=torch.Size([5]),
+            device=cpu,
+            is_shared=False)
+        >>> print("index", sample["index"])
+        index tensor([2, 5, 5, 9, 7])
+
     """
 
     def __init__(
         self,
+        *,
         alpha: float,
         beta: float,
         priority_key: str = "td_error",
         eps: float = 1e-8,
         storage: Optional[Storage] = None,
         collate_fn: Optional[Callable] = None,
         pin_memory: bool = False,
@@ -599,18 +960,20 @@
 
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
 
     def sample(
         self,
         batch_size: Optional[int] = None,
-        include_info: bool = False,
+        include_info: bool = None,
         return_info: bool = False,
     ) -> TensorDictBase:
-        return super().sample(batch_size, include_info, return_info)
+        return super().sample(
+            batch_size=batch_size, include_info=include_info, return_info=return_info
+        )
 
     def add(self, data: TensorDictBase) -> int:
         return super().add(data)
 
     def extend(self, tensordicts: Union[List, TensorDictBase]) -> torch.Tensor:
         return super().extend(tensordicts)
```

## torchrl/data/replay_buffers/samplers.py

```diff
@@ -72,15 +72,15 @@
         return index, {}
 
 
 class SamplerWithoutReplacement(Sampler):
     """A data-consuming sampler that ensures that the same sample is not present in consecutive batches.
 
     Args:
-        drop_last (bool, optional): if True, the last incomplete sample (if any) will be dropped.
+        drop_last (bool, optional): if ``True``, the last incomplete sample (if any) will be dropped.
             If False, this last sample will be kept and (unlike with torch dataloaders)
             completed with other samples from a fresh indices permutation.
 
     *Caution*: If the size of the storage changes in between two calls, the samples will be re-shuffled
     (as we can't generally keep track of which samples have been sampled before and which haven't).
 
     Similarly, it is expected that the storage content remains the same in between two calls,
@@ -133,14 +133,18 @@
         # as a signal for an early break of the __iter__().
         return index, {}
 
     @property
     def ran_out(self):
         return self._ran_out
 
+    @ran_out.setter
+    def ran_out(self, value):
+        self._ran_out = value
+
 
 class PrioritizedSampler(Sampler):
     """Prioritized sampler for replay buffer.
 
     Presented in "Schaul, T.; Quan, J.; Antonoglou, I.; and Silver, D. 2015.
         Prioritized experience replay."
         (https://arxiv.org/abs/1511.05952)
@@ -199,14 +203,16 @@
         p_min = self._min_tree.query(0, len(storage))
         if p_sum <= 0:
             raise RuntimeError("negative p_sum")
         if p_min <= 0:
             raise RuntimeError("negative p_min")
         mass = np.random.uniform(0.0, p_sum, size=batch_size)
         index = self._sum_tree.scan_lower_bound(mass)
+        if not isinstance(index, np.ndarray):
+            index = np.array([index])
         if isinstance(index, torch.Tensor):
             index.clamp_max_(len(storage) - 1)
         else:
             index = np.clip(index, None, len(storage) - 1)
         weight = self._sum_tree[index]
 
         # Importance sampling weight formula:
```

## torchrl/data/replay_buffers/storages.py

```diff
@@ -7,17 +7,18 @@
 import os
 import warnings
 from collections import OrderedDict
 from copy import copy
 from typing import Any, Dict, Sequence, Union
 
 import torch
+from tensordict import is_tensorclass
 from tensordict.memmap import MemmapTensor
-from tensordict.prototype import is_tensorclass
 from tensordict.tensordict import is_tensor_collection, TensorDict, TensorDictBase
+from tensordict.utils import expand_right
 
 from torchrl._utils import _CKPT_BACKEND, VERBOSE
 from torchrl.data.replay_buffers.utils import INT_CLASSES
 
 try:
     from torchsnapshot.serialization import tensor_from_memoryview
 
@@ -269,14 +270,17 @@
 
     def get(self, index: Union[int, Sequence[int], slice]) -> Any:
         if not self.initialized:
             raise RuntimeError(
                 "Cannot get an item from an unitialized LazyMemmapStorage"
             )
         out = self._storage[index]
+        if is_tensor_collection(out):
+            out = _reset_batch_size(out)
+            return out.unlock_()
         return out
 
     def __len__(self):
         return self._len
 
 
 class LazyMemmapStorage(LazyTensorStorage):
@@ -419,32 +423,61 @@
             shape=list(mem_map_tensor.shape),
             mv=memoryview(mem_map_tensor._memmap_array),
         )
     elif _CKPT_BACKEND == "torch":
         return mem_map_tensor._tensor
 
 
+def _reset_batch_size(x):
+    """Resets the batch size of a tensordict.
+
+    In some cases we save the original shape of the tensordict as a tensor (or memmap tensor).
+
+    This function will read that tensor, extract its items and reset the shape
+    of the tensordict to it. If items have an incompatible shape (e.g. "index")
+    they will be expanded to the right to match it.
+
+    """
+    shape = x.pop("_batch_size", None)
+    data = x.pop("_data", None)
+    if shape is not None:
+        # we need to reset the batch-size
+        if isinstance(shape, MemmapTensor):
+            shape = shape.as_tensor()
+        locked = data.is_locked
+        if locked:
+            data.unlock_()
+        shape = [s.item() for s in shape[0]]
+        shape = torch.Size([x.shape[0], *shape])
+        # we may need to update some values in the data
+        for key, value in x.items():
+            if value.ndim >= len(shape):
+                continue
+            value = expand_right(value, shape)
+            data.set(key, value)
+        if locked:
+            data.lock_()
+        return data
+    if data is not None:
+        return data
+    return x
+
+
 def _collate_list_tensordict(x):
     out = torch.stack(x, 0)
-    if isinstance(out, TensorDictBase):
-        return out.to_tensordict()
+    if is_tensor_collection(out):
+        return _reset_batch_size(out)
     return out
 
 
-def _collate_list_tensors(*x):
-    return tuple(torch.stack(_x, 0) for _x in zip(*x))
-
-
 def _collate_contiguous(x):
-    if isinstance(x, TensorDictBase):
-        return x.to_tensordict()
-    return x.clone()
+    return x
 
 
-def _get_default_collate(storage, _is_tensordict=True):
+def _get_default_collate(storage, _is_tensordict=False):
     if isinstance(storage, ListStorage):
         if _is_tensordict:
             return _collate_list_tensordict
         else:
-            return _collate_list_tensors
+            return torch.utils.data._utils.collate.default_collate
     elif isinstance(storage, (LazyTensorStorage, LazyMemmapStorage)):
         return _collate_contiguous
```

## torchrl/envs/__init__.py

```diff
@@ -26,24 +26,36 @@
     ObservationNorm,
     ObservationTransform,
     PinMemoryTransform,
     R3MTransform,
     RandomCropTensorDict,
     RenameTransform,
     Resize,
+    Reward2GoTransform,
     RewardClipping,
     RewardScaling,
     RewardSum,
     SelectTransform,
     SqueezeTransform,
     StepCounter,
+    TargetReturn,
     TensorDictPrimer,
     TimeMaxPool,
     ToTensorImage,
     Transform,
     TransformedEnv,
     UnsqueezeTransform,
     VecNorm,
     VIPRewardTransform,
     VIPTransform,
 )
+from .utils import (
+    check_env_specs,
+    exploration_mode,
+    exploration_type,
+    ExplorationType,
+    make_composite_from_td,
+    set_exploration_mode,
+    set_exploration_type,
+    step_mdp,
+)
 from .vec_env import MultiThreadedEnv, ParallelEnv, SerialEnv
```

## torchrl/envs/common.py

```diff
@@ -10,25 +10,25 @@
 from numbers import Number
 from typing import Any, Callable, Dict, Iterator, Optional, Union
 
 import numpy as np
 import torch
 import torch.nn as nn
 from tensordict.tensordict import TensorDict, TensorDictBase
+
+from torchrl._utils import prod, seed_generator
+
 from torchrl.data.tensor_specs import (
     CompositeSpec,
     DiscreteTensorSpec,
     TensorSpec,
     UnboundedContinuousTensorSpec,
 )
-
-from .._utils import prod, seed_generator
-from ..data.utils import DEVICE_TYPING
-
-from .utils import get_available_libraries, step_mdp
+from torchrl.data.utils import DEVICE_TYPING
+from torchrl.envs.utils import get_available_libraries, step_mdp
 
 LIBRARIES = get_available_libraries()
 
 
 def _tensor_to_np(t):
     return t.detach().cpu().numpy()
 
@@ -123,15 +123,15 @@
     Properties:
         - observation_spec (CompositeSpec): sampling spec of the observations;
         - action_spec (TensorSpec): sampling spec of the actions;
         - input_spec (CompositeSpec): sampling spec of the actions and/or other inputs;
         - reward_spec (TensorSpec): sampling spec of the rewards;
         - batch_size (torch.Size): number of environments contained in the instance;
         - device (torch.device): device where the env input and output are expected to live
-        - run_type_checks (bool): if True, the observation and reward dtypes
+        - run_type_checks (bool): if ``True``, the observation and reward dtypes
             will be compared against their respective spec and an exception
             will be raised if they don't match.
             Defaults to False.
 
     Methods:
         step (TensorDictBase -> TensorDictBase): step in the environment
         reset (TensorDictBase, optional -> TensorDictBase): reset the environment
@@ -215,14 +215,21 @@
             self._batch_size = torch.Size([])
         return self._batch_size
 
     @batch_size.setter
     def batch_size(self, value: torch.Size) -> None:
         self._batch_size = torch.Size(value)
 
+    def ndimension(self):
+        return len(self.batch_size)
+
+    @property
+    def ndim(self):
+        return self.ndimension()
+
     # Parent specs: input and output spec.
     @property
     def input_spec(self) -> TensorSpec:
         return self._input_spec
 
     @input_spec.setter
     def input_spec(self, value: TensorSpec) -> None:
@@ -427,15 +434,16 @@
                     f"but got {tensordict_out.get('reward').dtype}"
                 )
 
             if next_tensordict_out.get("done").dtype is not self.done_spec.dtype:
                 raise TypeError(
                     f"expected done.dtype to be torch.bool but got {tensordict_out.get('done').dtype}"
                 )
-        tensordict.set("next", tensordict_out.get("next"))
+        # tensordict could already have a "next" key
+        tensordict.update(tensordict_out)
 
         return tensordict
 
     def _get_in_keys_to_exclude(self, tensordict):
         if self._cache_in_keys is None:
             self._cache_in_keys = list(
                 set(self.input_spec.keys(True)).intersection(
@@ -476,14 +484,18 @@
         Returns:
             a tensordict (or the input tensordict, if any), modified in place with the resulting observations.
 
         """
         if tensordict is not None and "_reset" in tensordict.keys():
             self._assert_tensordict_shape(tensordict)
             _reset = tensordict.get("_reset")
+            if _reset.shape[-len(self.done_spec.shape) :] != self.done_spec.shape:
+                raise RuntimeError(
+                    "_reset flag in tensordict should follow env.done_spec"
+                )
         else:
             _reset = None
 
         tensordict_reset = self._reset(tensordict, **kwargs)
         if tensordict_reset.device != self.device:
             tensordict_reset = tensordict_reset.to(self.device)
         if tensordict_reset is tensordict:
@@ -502,19 +514,14 @@
         else:
             leading_dim = tensordict_reset.shape
         if self.done_spec is not None and "done" not in tensordict_reset.keys():
             tensordict_reset.set(
                 "done",
                 self.done_spec.zero(leading_dim),
             )
-        if self.reward_spec is not None and "reward" not in tensordict_reset.keys():
-            tensordict_reset.set(
-                "reward",
-                self.reward_spec.zero(leading_dim),
-            )
 
         if (_reset is None and tensordict_reset.get("done").any()) or (
             _reset is not None and tensordict_reset.get("done")[_reset].any()
         ):
             raise RuntimeError(
                 f"Env {self} was done after reset on specified '_reset' dimensions. This is (currently) not allowed."
             )
@@ -530,15 +537,15 @@
     def set_seed(
         self, seed: Optional[int] = None, static_seed: bool = False
     ) -> Optional[int]:
         """Sets the seed of the environment and returns the next seed to be used (which is the input seed if a single environment is present).
 
         Args:
             seed (int): seed to be set
-            static_seed (bool, optional): if True, the seed is not incremented.
+            static_seed (bool, optional): if ``True``, the seed is not incremented.
                 Defaults to False
 
         Returns:
             integer representing the "next seed": i.e. the seed that should be
             used for another environment if created concomittently to this environment.
 
         """
@@ -643,33 +650,124 @@
         Args:
             max_steps (int): maximum number of steps to be executed. The actual number of steps can be smaller if
                 the environment reaches a done state before max_steps have been executed.
             policy (callable, optional): callable to be called to compute the desired action. If no policy is provided,
                 actions will be called using :obj:`env.rand_step()`
                 default = None
             callback (callable, optional): function to be called at each iteration with the given TensorDict.
-            auto_reset (bool, optional): if True, resets automatically the environment
+            auto_reset (bool, optional): if ``True``, resets automatically the environment
                 if it is in a done state when the rollout is initiated.
                 Default is :obj:`True`.
-            auto_cast_to_device (bool, optional): if True, the device of the tensordict is automatically cast to the
-                policy device before the policy is used. Default is :obj:`False`.
+            auto_cast_to_device (bool, optional): if ``True``, the device of the tensordict is automatically cast to the
+                policy device before the policy is used. Default is ``False``.
             break_when_any_done (bool): breaks if any of the done state is True. If False, a reset() is
                 called on the sub-envs that are done. Default is True.
             return_contiguous (bool): if False, a LazyStackedTensorDict will be returned. Default is True.
             tensordict (TensorDict, optional): if auto_reset is False, an initial
                 tensordict must be provided.
 
         Returns:
             TensorDict object containing the resulting trajectory.
 
+        The data returned will be marked with a "time" dimension name for the last
+        dimension of the tensordict (at the ``env.ndim`` index).
+
+        Examples:
+            >>> from torchrl.envs.libs.gym import GymEnv
+            >>> from torchrl.envs.transforms import TransformedEnv, StepCounter
+            >>> env = TransformedEnv(GymEnv("Pendulum-v1"), StepCounter(max_steps=20))
+            >>> rollout = env.rollout(max_steps=1000)
+            >>> print(rollout)
+            TensorDict(
+                fields={
+                    action: Tensor(shape=torch.Size([20, 1]), device=cpu, dtype=torch.float32, is_shared=False),
+                    done: Tensor(shape=torch.Size([20, 1]), device=cpu, dtype=torch.bool, is_shared=False),
+                    next: TensorDict(
+                        fields={
+                            done: Tensor(shape=torch.Size([20, 1]), device=cpu, dtype=torch.bool, is_shared=False),
+                            observation: Tensor(shape=torch.Size([20, 3]), device=cpu, dtype=torch.float32, is_shared=False),
+                            reward: Tensor(shape=torch.Size([20, 1]), device=cpu, dtype=torch.float32, is_shared=False),
+                            step_count: Tensor(shape=torch.Size([20, 1]), device=cpu, dtype=torch.int64, is_shared=False),
+                            truncated: Tensor(shape=torch.Size([20, 1]), device=cpu, dtype=torch.bool, is_shared=False)},
+                        batch_size=torch.Size([20]),
+                        device=cpu,
+                        is_shared=False),
+                    observation: Tensor(shape=torch.Size([20, 3]), device=cpu, dtype=torch.float32, is_shared=False),
+                    step_count: Tensor(shape=torch.Size([20, 1]), device=cpu, dtype=torch.int64, is_shared=False),
+                    truncated: Tensor(shape=torch.Size([20, 1]), device=cpu, dtype=torch.bool, is_shared=False)},
+                batch_size=torch.Size([20]),
+                device=cpu,
+                is_shared=False)
+            >>> print(rollout.names)
+            ['time']
+            >>> # with envs that contain more dimensions
+            >>> from torchrl.envs import SerialEnv
+            >>> env = SerialEnv(3, lambda: TransformedEnv(GymEnv("Pendulum-v1"), StepCounter(max_steps=20)))
+            >>> rollout = env.rollout(max_steps=1000)
+            >>> print(rollout)
+            TensorDict(
+                fields={
+                    action: Tensor(shape=torch.Size([3, 20, 1]), device=cpu, dtype=torch.float32, is_shared=False),
+                    done: Tensor(shape=torch.Size([3, 20, 1]), device=cpu, dtype=torch.bool, is_shared=False),
+                    next: TensorDict(
+                        fields={
+                            done: Tensor(shape=torch.Size([3, 20, 1]), device=cpu, dtype=torch.bool, is_shared=False),
+                            observation: Tensor(shape=torch.Size([3, 20, 3]), device=cpu, dtype=torch.float32, is_shared=False),
+                            reward: Tensor(shape=torch.Size([3, 20, 1]), device=cpu, dtype=torch.float32, is_shared=False),
+                            step_count: Tensor(shape=torch.Size([3, 20, 1]), device=cpu, dtype=torch.int64, is_shared=False),
+                            truncated: Tensor(shape=torch.Size([3, 20, 1]), device=cpu, dtype=torch.bool, is_shared=False)},
+                        batch_size=torch.Size([3, 20]),
+                        device=cpu,
+                        is_shared=False),
+                    observation: Tensor(shape=torch.Size([3, 20, 3]), device=cpu, dtype=torch.float32, is_shared=False),
+                    step_count: Tensor(shape=torch.Size([3, 20, 1]), device=cpu, dtype=torch.int64, is_shared=False),
+                    truncated: Tensor(shape=torch.Size([3, 20, 1]), device=cpu, dtype=torch.bool, is_shared=False)},
+                batch_size=torch.Size([3, 20]),
+                device=cpu,
+                is_shared=False)
+            >>> print(rollout.names)
+            [None, 'time']
+
+        In some instances, contiguous tensordict cannot be obtained because
+        they cannot be stacked. This can happen when the data returned at
+        each step may have a different shape, or when different environments
+        are executed together. In that case, ``return_contiguous=False``
+        will cause the returned tensordict to be a lazy stack of tensordicts:
+
+        Examples:
+            >>> rollout = env.rollout(4, return_contiguous=False)
+            >>> print(rollout)
+        LazyStackedTensorDict(
+            fields={
+                action: Tensor(shape=torch.Size([3, 4, 1]), device=cpu, dtype=torch.float32, is_shared=False),
+                done: Tensor(shape=torch.Size([3, 4, 1]), device=cpu, dtype=torch.bool, is_shared=False),
+                next: LazyStackedTensorDict(
+                    fields={
+                        done: Tensor(shape=torch.Size([3, 4, 1]), device=cpu, dtype=torch.bool, is_shared=False),
+                        observation: Tensor(shape=torch.Size([3, 4, 3]), device=cpu, dtype=torch.float32, is_shared=False),
+                        reward: Tensor(shape=torch.Size([3, 4, 1]), device=cpu, dtype=torch.float32, is_shared=False),
+                        step_count: Tensor(shape=torch.Size([3, 4, 1]), device=cpu, dtype=torch.int64, is_shared=False),
+                        truncated: Tensor(shape=torch.Size([3, 4, 1]), device=cpu, dtype=torch.bool, is_shared=False)},
+                    batch_size=torch.Size([3, 4]),
+                    device=cpu,
+                    is_shared=False),
+                observation: Tensor(shape=torch.Size([3, 4, 3]), device=cpu, dtype=torch.float32, is_shared=False),
+                step_count: Tensor(shape=torch.Size([3, 4, 1]), device=cpu, dtype=torch.int64, is_shared=False),
+                truncated: Tensor(shape=torch.Size([3, 4, 1]), device=cpu, dtype=torch.bool, is_shared=False)},
+            batch_size=torch.Size([3, 4]),
+            device=cpu,
+            is_shared=False)
+            >>> print(rollout.names)
+            [None, 'time']
+
         """
         try:
             policy_device = next(policy.parameters()).device
-        except AttributeError:
-            policy_device = "cpu"
+        except (StopIteration, AttributeError):
+            policy_device = self.device
 
         env_device = self.device
 
         if auto_reset:
             if tensordict is not None:
                 raise RuntimeError(
                     "tensordict cannot be provided when auto_reset is True"
@@ -704,24 +802,25 @@
                 break
             tensordict = step_mdp(
                 tensordict,
                 keep_other=True,
                 exclude_action=False,
             )
             if not break_when_any_done and done.any():
-                _reset = done.view(tensordict.shape)
+                _reset = done.clone()
                 tensordict.set("_reset", _reset)
                 self.reset(tensordict)
 
             if callback is not None:
                 callback(self, tensordict)
 
         batch_size = self.batch_size if tensordict is None else tensordict.batch_size
 
         out_td = torch.stack(tensordicts, len(batch_size))
+        out_td.refine_names(..., "time")
         if return_contiguous:
             return out_td.contiguous()
         return out_td
 
     def _select_observation_keys(self, tensordict: TensorDictBase) -> Iterator[str]:
         for key in tensordict.keys():
             if key.rfind("observation") >= 0:
@@ -805,15 +904,14 @@
         next_output = fake_obs.clone()
         next_output["reward"] = fake_reward
         next_output["done"] = fake_done
         fake_td = TensorDict(
             {
                 **fake_in_out,
                 "done": fake_done.clone(),
-                "reward": fake_reward.clone(),
                 "next": next_output,
             },
             batch_size=self.batch_size,
             device=self.device,
         )
         return fake_td
```

## torchrl/envs/gym_like.py

```diff
@@ -243,15 +243,15 @@
     ) -> TensorDictBase:
         reset_data = self._env.reset(**kwargs)
         if not isinstance(reset_data, tuple):
             reset_data = (reset_data,)
         obs, *other = self._output_transform(reset_data)
         info = None
         if len(other) == 1:
-            info = other
+            info = other[0]
 
         tensordict_out = TensorDict(
             source=self.read_obs(obs),
             batch_size=self.batch_size,
             device=self.device,
         )
         if self.info_dict_reader is not None and info is not None:
```

## torchrl/envs/utils.py

```diff
@@ -3,57 +3,79 @@
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
 from __future__ import annotations
 
 import pkg_resources
 import torch
 from tensordict.nn.probabilistic import (  # noqa
+    # Note: the `set_interaction_mode` and their associated arg `default_interaction_mode` are being deprecated!
+    #       Please use the `set_/interaction_type` ones above with the InteractionType enum instead.
+    #       See more details: https://github.com/pytorch/rl/issues/1016
     interaction_mode as exploration_mode,
+    interaction_type as exploration_type,
+    InteractionType as ExplorationType,
     set_interaction_mode as set_exploration_mode,
+    set_interaction_type as set_exploration_type,
 )
 from tensordict.tensordict import TensorDictBase
 
+__all__ = [
+    "exploration_mode",
+    "exploration_type",
+    "set_exploration_mode",
+    "set_exploration_type",
+    "ExplorationType",
+    "check_env_specs",
+    "step_mdp",
+    "make_composite_from_td",
+]
 AVAILABLE_LIBRARIES = {pkg.key for pkg in pkg_resources.working_set}
 
 
+def _convert_exploration_type(*, exploration_mode, exploration_type):
+    if exploration_mode is not None:
+        return ExplorationType.from_str(exploration_mode)
+    return exploration_type
+
+
 class _classproperty(property):
     def __get__(self, cls, owner):
         return classmethod(self.fget).__get__(None, owner)()
 
 
 def step_mdp(
     tensordict: TensorDictBase,
     next_tensordict: TensorDictBase = None,
     keep_other: bool = True,
-    exclude_reward: bool = False,
+    exclude_reward: bool = True,
     exclude_done: bool = False,
     exclude_action: bool = True,
 ) -> TensorDictBase:
     """Creates a new tensordict that reflects a step in time of the input tensordict.
 
     Given a tensordict retrieved after a step, returns the :obj:`"next"` indexed-tensordict.
     THe arguments allow for a precise control over what should be kept and what
     should be copied from the ``"next"`` entry. The default behaviour is:
     move the observation entries, reward and done states to the root, exclude
     the current action and keep all extra keys (non-action, non-done, non-reward).
 
     Args:
         tensordict (TensorDictBase): tensordict with keys to be renamed
         next_tensordict (TensorDictBase, optional): destination tensordict
-        keep_other (bool, optional): if True, all keys that do not start with :obj:`'next_'` will be kept.
+        keep_other (bool, optional): if ``True``, all keys that do not start with :obj:`'next_'` will be kept.
             Default is ``True``.
-        exclude_reward (bool, optional): if True, the :obj:`"reward"` key will be discarded
+        exclude_reward (bool, optional): if ``True``, the :obj:`"reward"` key will be discarded
             from the resulting tensordict. If ``False``, it will be copied (and replaced)
             from the ``"next"`` entry (if present).
-            Default is ``False``.
-        exclude_done (bool, optional): if True, the :obj:`"done"` key will be discarded
+            Default is ``True``.
+        exclude_done (bool, optional): if ``True``, the :obj:`"done"` key will be discarded
             from the resulting tensordict. If ``False``, it will be copied (and replaced)
             from the ``"next"`` entry (if present).
             Default is ``False``.
-        exclude_action (bool, optional): if True, the :obj:`"action"` key will
+        exclude_action (bool, optional): if ``True``, the :obj:`"action"` key will
             be discarded from the resulting tensordict. If ``False``, it will
             be kept in the root tensordict (since it should not be present in
             the ``"next"`` entry).
             Default is ``True``.
 
     Returns:
          A new tensordict (or next_tensordict) containing the tensors of the t+1 step.
@@ -228,15 +250,15 @@
     the data collected should raise an assertion error.
 
     A broken environment spec will likely make it impossible to use parallel
     environments.
 
     Args:
         env (EnvBase): the env for which the specs have to be checked against data.
-        return_contiguous (bool, optional): if True, the random rollout will be called with
+        return_contiguous (bool, optional): if ``True``, the random rollout will be called with
             return_contiguous=True. This will fail in some cases (e.g. heterogeneous shapes
             of inputs/outputs). Defaults to True.
         check_dtype (bool, optional): if False, dtype checks will be skipped.
             Defaults to True.
         seed (int, optional): for reproducibility, a seed is set.
 
     Caution: this function resets the env seed. It should be used "offline" to
@@ -357,7 +379,52 @@
         return self.fget(owner_cls)
 
 
 def _sort_keys(element):
     if isinstance(element, tuple):
         return "_-|-_".join(element)
     return element
+
+
+def make_composite_from_td(data):
+    """Creates a CompositeSpec instance from a tensordict, assuming all values are unbounded.
+
+    Args:
+        data (tensordict.TensorDict): a tensordict to be mapped onto a CompositeSpec.
+
+    Examples:
+        >>> from tensordict import TensorDict
+        >>> data = TensorDict({
+        ...     "obs": torch.randn(3),
+        ...     "action": torch.zeros(2, dtype=torch.int),
+        ...     "next": {"obs": torch.randn(3), "reward": torch.randn(1)}
+        ... }, [])
+        >>> spec = make_composite_from_td(data)
+        >>> print(spec)
+        CompositeSpec(
+            obs: UnboundedContinuousTensorSpec(
+                 shape=torch.Size([3]), space=None, device=cpu, dtype=torch.float32, domain=continuous),
+            action: UnboundedContinuousTensorSpec(
+                 shape=torch.Size([2]), space=None, device=cpu, dtype=torch.int32, domain=continuous),
+            next: CompositeSpec(
+                obs: UnboundedContinuousTensorSpec(
+                     shape=torch.Size([3]), space=None, device=cpu, dtype=torch.float32, domain=continuous),
+                reward: UnboundedContinuousTensorSpec(
+                     shape=torch.Size([1]), space=ContinuousBox(minimum=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True), maximum=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True)), device=cpu, dtype=torch.float32, domain=continuous), device=cpu, shape=torch.Size([])), device=cpu, shape=torch.Size([]))
+        >>> assert (spec.zero() == data.zero_()).all()
+    """
+    from torchrl.data import CompositeSpec, UnboundedContinuousTensorSpec
+
+    # custom funtion to convert a tensordict in a similar spec structure
+    # of unbounded values.
+    composite = CompositeSpec(
+        {
+            key: make_composite_from_td(tensor)
+            if isinstance(tensor, TensorDictBase)
+            else UnboundedContinuousTensorSpec(
+                dtype=tensor.dtype, device=tensor.device, shape=tensor.shape
+            )
+            for key, tensor in data.items()
+        },
+        shape=data.shape,
+    )
+    return composite
```

## torchrl/envs/vec_env.py

```diff
@@ -1,55 +1,47 @@
 # Copyright (c) Meta Platforms, Inc. and affiliates.
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
 
 from __future__ import annotations
 
+import importlib
 import logging
-
 import os
 from collections import OrderedDict
 from copy import deepcopy
 from multiprocessing import connection
 from multiprocessing.synchronize import Lock as MpLock
 from typing import Any, Callable, Dict, List, Optional, Sequence, Tuple, Union
 from warnings import warn
 
 import numpy as np
 import torch
-
 from tensordict import TensorDict
 from tensordict.tensordict import LazyStackedTensorDict, TensorDictBase
 from torch import multiprocessing as mp
+
 from torchrl._utils import _check_for_faulty_process, VERBOSE
 from torchrl.data.tensor_specs import (
     CompositeSpec,
     DiscreteTensorSpec,
     TensorSpec,
     UnboundedContinuousTensorSpec,
 )
 from torchrl.data.utils import CloudpickleWrapper, DEVICE_TYPING
 from torchrl.envs.common import _EnvWrapper, EnvBase
 from torchrl.envs.env_creator import get_env_metadata
-from torchrl.envs.libs.gym import _gym_to_torchrl_spec_transform
 
-try:
-    # Libraries necessary for MultiThreadedEnv
-    import envpool
-
-    import treevalue
-
-    _has_envpool = True
-except ImportError as err:
-    _has_envpool = False
-    IMPORT_ERR_ENVPOOL = err
 from torchrl.envs.utils import _sort_keys
 
 
+_has_envpool = importlib.util.find_spec("envpool")
+
+
 def _check_start(fun):
     def decorated_fun(self: _BatchedEnv, *args, **kwargs):
         if self.is_closed:
             self._create_td()
             self._start_workers()
         else:
             if isinstance(self, ParallelEnv):
@@ -104,29 +96,29 @@
         create_env_fn (callable or list of callables): function (or list of functions) to be used for the environment
             creation.
             If a single task is used, a callable should be used and not a list of identical callables:
             if a list of callable is provided, the environment will be executed as if multiple, diverse tasks were
             needed, which comes with a slight compute overhead;
         create_env_kwargs (dict or list of dicts, optional): kwargs to be used with the environments being created;
         pin_memory (bool): if True and device is "cpu", calls :obj:`pin_memory` on the tensordicts when created.
-        share_individual_td (bool, optional): if True, a different tensordict is created for every process/worker and a lazy
+        share_individual_td (bool, optional): if ``True``, a different tensordict is created for every process/worker and a lazy
             stack is returned.
             default = None (False if single task);
         shared_memory (bool): whether or not the returned tensordict will be placed in shared memory;
         memmap (bool): whether or not the returned tensordict will be placed in memory map.
         policy_proof (callable, optional): if provided, it'll be used to get the list of
             tensors to return through the :obj:`step()` and :obj:`reset()` methods, such as :obj:`"hidden"` etc.
         device (str, int, torch.device): for consistency, this argument is kept. However this
             argument should not be passed, as the device will be inferred from the environments.
             It is assumed that all environments will run on the same device as a common shared
             tensordict will be used to pass data from process to process. The device can be
             changed after instantiation using :obj:`env.to(device)`.
-        allow_step_when_done (bool, optional): if True, batched environments can
+        allow_step_when_done (bool, optional): if ``True``, batched environments can
             execute steps after a done state is encountered.
-            Defaults to :obj:`False`.
+            Defaults to ``False``.
 
     """
 
     _verbose: bool = VERBOSE
     _excluded_wrapped_keys = [
         "is_closed",
         "parent_channels",
@@ -564,20 +556,23 @@
         for env in self._envs:
             new_seed = env.set_seed(seed, static_seed=static_seed)
             seed = new_seed
         return seed
 
     @_check_start
     def _reset(self, tensordict: TensorDictBase, **kwargs) -> TensorDictBase:
-
         if tensordict is not None and "_reset" in tensordict.keys():
             self._assert_tensordict_shape(tensordict)
             _reset = tensordict.get("_reset")
+            if _reset.shape[-len(self.done_spec.shape) :] != self.done_spec.shape:
+                raise RuntimeError(
+                    "_reset flag in tensordict should follow env.done_spec"
+                )
         else:
-            _reset = torch.ones(self.batch_size, dtype=torch.bool)
+            _reset = torch.ones(self.done_spec.shape, dtype=torch.bool)
 
         for i, _env in enumerate(self._envs):
             if tensordict is not None:
                 tensordict_ = tensordict[i]
                 if tensordict_.is_empty():
                     tensordict_ = None
             else:
@@ -652,15 +647,14 @@
     TensorDicts are passed via shared memory or memory map.
 
     """
 
     __doc__ += _BatchedEnv.__doc__
 
     def _start_workers(self) -> None:
-
         _num_workers = self.num_workers
         ctx = mp.get_context("spawn")
 
         self.parent_channels = []
         self._workers = []
 
         for idx in range(_num_workers):
@@ -733,19 +727,21 @@
             tensordict.select(*self.env_input_keys, strict=False)
         )
         for i in range(self.num_workers):
             self.parent_channels[i].send(("step", None))
 
         # keys = set()
         for i in range(self.num_workers):
-            msg, _ = self.parent_channels[i].recv()
+            msg, data = self.parent_channels[i].recv()
             if msg != "step_result":
                 raise RuntimeError(
                     f"Expected 'step_result' but received {msg} from worker {i}"
                 )
+            if data is not None:
+                self.shared_tensordicts[i].update_(data)
         # We must pass a clone of the tensordict, as the values of this tensordict
         # will be modified in-place at further steps
         return self.shared_tensordict_parent.select(*self._selected_step_keys).clone()
 
     @_check_start
     def _shutdown_workers(self) -> None:
         if self.is_closed:
@@ -790,16 +786,22 @@
 
     @_check_start
     def _reset(self, tensordict: TensorDictBase, **kwargs) -> TensorDictBase:
         cmd_out = "reset"
         if tensordict is not None and "_reset" in tensordict.keys():
             self._assert_tensordict_shape(tensordict)
             _reset = tensordict.get("_reset")
+            if _reset.shape[-len(self.done_spec.shape) :] != self.done_spec.shape:
+                raise RuntimeError(
+                    "_reset flag in tensordict should follow env.done_spec"
+                )
         else:
-            _reset = torch.ones(self.batch_size, dtype=torch.bool, device=self.device)
+            _reset = torch.ones(
+                self.done_spec.shape, dtype=torch.bool, device=self.device
+            )
 
         for i, channel in enumerate(self.parent_channels):
             if tensordict is not None:
                 tensordict_ = tensordict[i]
                 if tensordict_.is_empty():
                     tensordict_ = None
             else:
@@ -820,17 +822,20 @@
                 # we must update the
                 continue
             channel.send((cmd_out, kwargs))
 
         for i, channel in enumerate(self.parent_channels):
             if not _reset[i].any():
                 continue
-            cmd_in, _ = channel.recv()
+            cmd_in, data = channel.recv()
             if cmd_in != "reset_obs":
                 raise RuntimeError(f"received cmd {cmd_in} instead of reset_obs")
+            if data is not None:
+                self.shared_tensordicts[i].update_(data)
+
         return self.shared_tensordict_parent.select(*self._selected_reset_keys).clone()
 
     def __reduce__(self):
         if not self.is_closed:
             # ParallelEnv contains non-instantiated envs, thus it can be
             # closed and serialized if the environment building functions
             # permit it
@@ -909,24 +914,24 @@
         env = env_fun(**env_fun_kwargs)
     else:
         if env_fun_kwargs:
             raise RuntimeError(
                 "env_fun_kwargs must be empty if an environment is passed to a process."
             )
         env = env_fun
+    is_cuda = torch.device(device).type == "cuda"
     env = env.to(device)
+
     i = -1
     initialized = False
 
     # make sure that process can be closed
     tensordict = None
     _td = None
 
-    reset_keys = None
-
     while True:
         try:
             cmd, data = child_pipe.recv()
         except EOFError as err:
             raise EOFError(f"proc {pid} failed, last command: {cmd}.") from err
         if cmd == "seed":
             if not initialized:
@@ -958,34 +963,48 @@
             # _td = tensordict.select("observation").to(env.device).clone()
             _td = env._reset(**reset_kwargs)
 
             if "_reset" in _td.keys():
                 _td.del_("_reset")
             if pin_memory:
                 _td.pin_memory()
-            tensordict.update_(_td.select(*tensordict.keys(True, True), strict=False))
-            child_pipe.send(("reset_obs", reset_keys))
+            if not is_cuda:
+                tensordict.update_(
+                    _td.select(*tensordict.keys(True, True), strict=False)
+                )
+                child_pipe.send(("reset_obs", None))
+            else:
+                child_pipe.send(
+                    (
+                        "reset_obs",
+                        _td.select(*tensordict.keys(True, True), strict=False),
+                    )
+                )
 
         elif cmd == "step":
             if not initialized:
                 raise RuntimeError("called 'init' before step")
             i += 1
             if _td is not None:
                 _td = _td.update(
                     tensordict.select(*env_input_keys),
                 )
             else:
                 _td = tensordict.clone(recurse=False)
             _td = env._step(_td)
             if pin_memory:
                 _td.pin_memory()
-            tensordict.update_(_td.select("next"))
             msg = "step_result"
-            data = (msg, None)
-            child_pipe.send(data)
+            if not is_cuda:
+                tensordict.update_(_td.select("next"))
+                data = (msg, None)
+                child_pipe.send(data)
+            else:
+                data = (msg, _td.select("next"))
+                child_pipe.send(data)
 
         elif cmd == "close":
             del tensordict, _td, data
             if not initialized:
                 raise RuntimeError("call 'init' before closing")
             env.close()
             del env
@@ -1033,21 +1052,21 @@
 class MultiThreadedEnvWrapper(_EnvWrapper):
     """Wrapper for envpool-based multithreaded environments."""
 
     _verbose: bool = False
 
     def __init__(
         self,
-        env: Optional["envpool.python.envpool.EnvPoolMixin"] = None,
+        env: Optional["envpool.python.envpool.EnvPoolMixin"] = None,  # noqa: F821
         **kwargs,
     ):
         if not _has_envpool:
             raise ImportError(
                 "envpool python package or one of its dependencies (gym, treevalue) were not found. Please install these dependencies."
-            ) from IMPORT_ERR_ENVPOOL
+            )
         if env is not None:
             kwargs["env"] = env
             self.num_workers = env.config["num_envs"]
             # For synchronous mode batch size is equal to the number of workers
             self.batch_size = torch.Size([self.num_workers])
         super().__init__(**kwargs)
 
@@ -1055,22 +1074,24 @@
         # It's a TensorDict when the observation consists of several variables, e.g. "position" and "velocity"
         self.obs: Union[torch.tensor, TensorDict] = self.observation_spec.zero()
 
     def _check_kwargs(self, kwargs: Dict):
         if "env" not in kwargs:
             raise TypeError("Could not find environment key 'env' in kwargs.")
         env = kwargs["env"]
+        import envpool
+
         if not isinstance(env, (envpool.python.envpool.EnvPoolMixin,)):
             raise TypeError("env is not of type 'envpool.python.envpool.EnvPoolMixin'.")
 
-    def _build_env(self, env: "envpool.python.envpool.EnvPoolMixin"):
+    def _build_env(self, env: "envpool.python.envpool.EnvPoolMixin"):  # noqa: F821
         return env
 
     def _make_specs(
-        self, env: "envpool.python.envpool.EnvPoolMixin"
+        self, env: "envpool.python.envpool.EnvPoolMixin"  # noqa: F821
     ) -> None:  # noqa: F821
         self.input_spec = self._get_input_spec()
         self.output_spec = self._get_output_spec()
 
     def _init_env(self) -> Optional[int]:
         pass
 
@@ -1093,14 +1114,17 @@
         # Action needs to be moved to CPU and converted to numpy before being passed to envpool
         action = action.to(torch.device("cpu"))
         step_output = self._env.step(action.numpy())
         tensordict_out = self._transform_step_output(step_output)
         return tensordict_out.select().set("next", tensordict_out)
 
     def _get_input_spec(self) -> TensorSpec:
+        # local import to avoid importing gym in the script
+        from torchrl.envs.libs.gym import _gym_to_torchrl_spec_transform
+
         # Envpool provides Gym-compatible specs as env.spec.action_space and
         # DM_Control-compatible specs as env.spec.action_spec(). We use the Gym ones.
 
         # Gym specs produced by EnvPool don't contain batch_size, we add it to satisfy checks in EnvBase
         action_spec = _gym_to_torchrl_spec_transform(
             self._env.spec.action_space,
             device=self.device,
@@ -1117,14 +1141,17 @@
             observation=self._get_observation_spec(),
             reward=self._get_reward_spec(),
             done=self._get_done_spec(),
             shape=(self.num_workers,),
         )
 
     def _get_observation_spec(self) -> TensorSpec:
+        # local import to avoid importing gym in the script
+        from torchrl.envs.libs.gym import _gym_to_torchrl_spec_transform
+
         # Gym specs produced by EnvPool don't contain batch_size, we add it to satisfy checks in EnvBase
         observation_spec = _gym_to_torchrl_spec_transform(
             self._env.spec.observation_space,
             device=self.device,
             categorical_action_encoding=True,
         )
         observation_spec = self._add_shape_to_spec(observation_spec)
@@ -1153,18 +1180,22 @@
         )
 
     def __repr__(self) -> str:
         return f"{self.__class__.__name__}(num_workers={self.num_workers}, device={self.device})"
 
     def _transform_reset_output(
         self,
-        envpool_output: Tuple[Union["treevalue.TreeValue", np.ndarray], Any],
+        envpool_output: Tuple[
+            Union["treevalue.TreeValue", np.ndarray], Any  # noqa: F821
+        ],
         reset_workers: Optional[torch.Tensor],
     ):
         """Process output of envpool env.reset."""
+        import treevalue
+
         observation, _ = envpool_output
         if reset_workers is not None:
             # Only specified workers were reset - need to set observation buffer values only for them
             if isinstance(observation, treevalue.TreeValue):
                 # If observation contain several fields, it will be returned as treevalue.TreeValue.
                 # Convert to treevalue.FastTreeValue to allow indexing
                 observation = treevalue.FastTreeValue(observation)
@@ -1193,33 +1224,41 @@
             obs,
             batch_size=self.batch_size,
             device=self.device,
         )
         return tensordict_out
 
     def _treevalue_or_numpy_to_tensor_or_dict(
-        self, x: Union["treevalue.TreeValue", np.ndarray]
+        self, x: Union["treevalue.TreeValue", np.ndarray]  # noqa: F821
     ) -> Union[torch.Tensor, Dict[str, torch.Tensor]]:
         """Converts observation returned by EnvPool.
 
         EnvPool step and reset return observation as a numpy array or a TreeValue of numpy arrays, which we convert
         to a tensor or a dictionary of tensors. Currently only supports depth 1 trees, but can easily be extended to
         arbitrary depth if necessary.
         """
+        import treevalue
+
         if isinstance(x, treevalue.TreeValue):
             ret = self._treevalue_to_dict(x)
-        else:
+        elif not isinstance(x, dict):
             ret = {"observation": torch.tensor(x)}
+        else:
+            ret = x
         return ret
 
-    def _treevalue_to_dict(self, tv: "treevalue.TreeValue") -> Dict[str, Any]:
+    def _treevalue_to_dict(
+        self, tv: "treevalue.TreeValue"  # noqa: F821
+    ) -> Dict[str, Any]:
         """Converts TreeValue to a dictionary.
 
         Currently only supports depth 1 trees, but can easily be extended to arbitrary depth if necessary.
         """
+        import treevalue
+
         return {k[0]: torch.tensor(v) for k, v in treevalue.flatten(tv)}
 
     def _set_seed(self, seed: Optional[int]):
         if seed is not None:
             print(
                 "MultiThreadedEnvWrapper._set_seed ignored, as setting seed in an existing envorinment is not\
                    supported by envpool. Please create a new environment, passing the seed to the constructor."
@@ -1249,15 +1288,14 @@
     def __init__(
         self,
         num_workers: int,
         env_name: str,
         create_env_kwargs: Optional[Dict[str, Any]] = None,
         **kwargs,
     ):
-
         self.env_name = env_name.replace("ALE/", "")  # Naming convention of EnvPool
         self.num_workers = num_workers
         self.batch_size = torch.Size([num_workers])
         self.create_env_kwargs = create_env_kwargs or {}
 
         kwargs["num_workers"] = num_workers
         kwargs["env_name"] = self.env_name
@@ -1266,14 +1304,16 @@
 
     def _build_env(
         self,
         env_name: str,
         num_workers: int,
         create_env_kwargs: Optional[Dict[str, Any]],
     ) -> Any:
+        import envpool
+
         create_env_kwargs = create_env_kwargs or {}
         env = envpool.make(
             task_id=env_name,
             env_type="gym",
             num_envs=num_workers,
             gym_reset_return_info=True,
             **create_env_kwargs,
```

## torchrl/envs/libs/brax.py

```diff
@@ -239,16 +239,15 @@
         return tensordict_out
 
     def _step_with_grad(self, tensordict: TensorDictBase):
 
         # convert tensors to ndarrays
         action = tensordict.get("action")
         state = tensordict.get("state")
-        qp_keys = list(state.get("qp").keys())
-        qp_values = list(state.get("qp").values())
+        qp_keys, qp_values = zip(*state.get("pipeline_state").items())
 
         # call env step with autograd function
         next_state_nograd, next_obs, next_reward, *next_qp_values = _BraxEnvStep.apply(
             self, state, action, *qp_values
         )
 
         # extract done values: we assume a shape identical to reward
@@ -257,15 +256,15 @@
 
         # merge with tensors with grad function
         next_state = next_state_nograd
         next_state["obs"] = next_obs
         next_state.set("reward", next_reward)
         next_state.set("done", next_done)
         next_done = next_done.bool()
-        next_state["qp"].update(dict(zip(qp_keys, next_qp_values)))
+        next_state.get("pipeline_state").update(dict(zip(qp_keys, next_qp_values)))
 
         # build result
         tensordict_out = TensorDict(
             source={
                 "observation": next_obs,
                 "reward": next_reward,
                 "done": next_done,
@@ -315,15 +314,16 @@
                 f"brax not found, unable to create {env_name}. "
                 f"Consider downloading and installing brax from"
                 f" {self.git_url}"
             ) from IMPORT_ERR
         from_pixels = kwargs.pop("from_pixels", False)
         pixels_only = kwargs.pop("pixels_only", True)
         requires_grad = kwargs.pop("requires_grad", False)
-        assert not kwargs
+        if kwargs:
+            raise ValueError("kwargs not supported.")
         self.wrapper_frame_skip = 1
         env = self.lib.envs.get_environment(env_name, **kwargs)
         return super()._build_env(
             env,
             pixels_only=pixels_only,
             from_pixels=from_pixels,
             requires_grad=requires_grad,
@@ -339,82 +339,110 @@
 
     def __repr__(self) -> str:
         return f"{self.__class__.__name__}(env={self.env_name}, batch_size={self.batch_size}, device={self.device})"
 
 
 class _BraxEnvStep(torch.autograd.Function):
     @staticmethod
-    def forward(ctx, env: BraxWrapper, state, action, *qp_values):
+    def forward(ctx, env: BraxWrapper, state_td, action_tensor, *qp_values):
 
         # convert tensors to ndarrays
-        state = _tensordict_to_object(state, env._state_example)
-        action = _tensor_to_ndarray(action)
+        state_obj = _tensordict_to_object(state_td, env._state_example)
+        action_nd = _tensor_to_ndarray(action_tensor)
 
         # flatten batch size
-        state = _tree_flatten(state, env.batch_size)
-        action = _tree_flatten(action, env.batch_size)
+        state = _tree_flatten(state_obj, env.batch_size)
+        action = _tree_flatten(action_nd, env.batch_size)
 
         # call vjp with jit and vmap
         next_state, vjp_fn = jax.vjp(env._vmap_jit_env_step, state, action)
 
         # reshape batch size
-        next_state = _tree_reshape(next_state, env.batch_size)
+        next_state_reshape = _tree_reshape(next_state, env.batch_size)
 
         # convert ndarrays to tensors
-        next_state = _object_to_tensordict(
-            next_state, device=env.device, batch_size=env.batch_size
+        next_state_tensor = _object_to_tensordict(
+            next_state_reshape, device=env.device, batch_size=env.batch_size
         )
 
         # save context
         ctx.vjp_fn = vjp_fn
-        ctx.next_state = next_state
+        ctx.next_state = next_state_tensor
         ctx.env = env
 
         return (
-            next_state,  # no gradient
-            next_state["obs"],
-            next_state["reward"],
-            *next_state["qp"].values(),
+            next_state_tensor,  # no gradient
+            next_state_tensor["obs"],
+            next_state_tensor["reward"],
+            *next_state_tensor["pipeline_state"].values(),
         )
 
     @staticmethod
     def backward(ctx, _, grad_next_obs, grad_next_reward, *grad_next_qp_values):
 
         # build gradient tensordict with zeros in fields with no grad
-        grad_next_state = TensorDict(
+        # if grad_next_reward is None:
+        #     raise RuntimeError("grad_next_reward")
+        #     grad_next_reward = torch.zeros((*ctx.env.batch_size, 1), device=ctx.env.device)
+        # if grad_next_obs is None:
+        #     raise RuntimeError("grad_next_obs")
+        # if any(val is None for val in grad_next_qp_values):
+        #     raise RuntimeError("grad_next_qp_values")
+
+        pipeline_state = dict(
+            zip(ctx.next_state["pipeline_state"].keys(), grad_next_qp_values)
+        )
+        none_keys = []
+
+        def _make_none(key, val):
+            if val is not None:
+                return val
+            none_keys.append(key)
+            return torch.zeros_like(ctx.next_state["pipeline_state"][key])
+
+        pipeline_state = {
+            key: _make_none(key, val) for key, val in pipeline_state.items()
+        }
+
+        grad_next_state_td = TensorDict(
             source={
-                "qp": dict(zip(ctx.next_state["qp"].keys(), grad_next_qp_values)),
+                "pipeline_state": pipeline_state,
                 "obs": grad_next_obs,
                 "reward": grad_next_reward,
                 "done": torch.zeros_like(ctx.next_state["done"]),
                 "metrics": {
                     k: torch.zeros_like(v) for k, v in ctx.next_state["metrics"].items()
                 },
                 "info": {
                     k: torch.zeros_like(v) for k, v in ctx.next_state["info"].items()
                 },
             },
             device=ctx.env.device,
             batch_size=ctx.env.batch_size,
-            _run_checks=False,
         )
-
         # convert tensors to ndarrays
-        grad_next_state = _tensordict_to_object(grad_next_state, ctx.env._state_example)
+        grad_next_state_obj = _tensordict_to_object(
+            grad_next_state_td, ctx.env._state_example
+        )
 
         # flatten batch size
-        grad_next_state = _tree_flatten(grad_next_state, ctx.env.batch_size)
+        grad_next_state_flat = _tree_flatten(grad_next_state_obj, ctx.env.batch_size)
 
         # call vjp to get gradients
-        grad_state, grad_action = ctx.vjp_fn(grad_next_state)
+        grad_state, grad_action = ctx.vjp_fn(grad_next_state_flat)
 
         # reshape batch size
         grad_state = _tree_reshape(grad_state, ctx.env.batch_size)
         grad_action = _tree_reshape(grad_action, ctx.env.batch_size)
 
         # convert ndarrays to tensors
         grad_state_qp = _object_to_tensordict(
-            grad_state.qp, device=ctx.env.device, batch_size=ctx.env.batch_size
+            grad_state.pipeline_state,
+            device=ctx.env.device,
+            batch_size=ctx.env.batch_size,
         )
         grad_action = _ndarray_to_tensor(grad_action)
-
+        grad_state_qp = {
+            key: val if key not in none_keys else None
+            for key, val in grad_state_qp.items()
+        }
         return (None, None, grad_action, *grad_state_qp.values())
```

## torchrl/envs/libs/dm_control.py

```diff
@@ -112,15 +112,15 @@
 
 
 class DMControlWrapper(GymLikeEnv):
     """DeepMind Control lab environment wrapper.
 
     Args:
         env (dm_control.suite env): environment instance
-        from_pixels (bool): if True, the observation
+        from_pixels (bool): if ``True``, the observation
 
     Examples:
         >>> env = dm_control.suite.load("cheetah", "run")
         >>> env = DMControlWrapper(env,
         ...    from_pixels=True, frame_skip=4)
         >>> td = env.rand_step()
         >>> print(td)
@@ -268,15 +268,15 @@
 class DMControlEnv(DMControlWrapper):
     """DeepMind Control lab environment wrapper.
 
     Args:
         env_name (str): name of the environment
         task_name (str): name of the task
         seed (int, optional): seed to use for the environment
-        from_pixels (bool, optional): if True, the observation will be returned
+        from_pixels (bool, optional): if ``True``, the observation will be returned
             as an image.
             Default is False.
 
     Examples:
         >>> env = DMControlEnv(env_name="cheetah", task_name="run",
         ...    from_pixels=True, frame_skip=4)
         >>> td = env.rand_step()
```

## torchrl/envs/libs/gym.py

```diff
@@ -1,83 +1,197 @@
 # Copyright (c) Meta Platforms, Inc. and affiliates.
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
+import importlib
 import warnings
+from copy import copy
 from types import ModuleType
 from typing import Dict, List
 from warnings import warn
 
 import torch
+
+try:
+    from torch.utils._contextlib import _DecoratorContextManager
+except ModuleNotFoundError:
+    from torchrl._utils import _DecoratorContextManager
+
+from torchrl._utils import implement_for
 from torchrl.data.tensor_specs import (
     BinaryDiscreteTensorSpec,
     BoundedTensorSpec,
     CompositeSpec,
     DiscreteTensorSpec,
     MultiDiscreteTensorSpec,
     MultiOneHotDiscreteTensorSpec,
     OneHotDiscreteTensorSpec,
     TensorSpec,
     UnboundedContinuousTensorSpec,
 )
+from torchrl.data.utils import numpy_to_torch_dtype_dict
 
-from ..._utils import implement_for
-from ...data.utils import numpy_to_torch_dtype_dict
-
-from ..gym_like import default_info_dict_reader, GymLikeEnv
-from ..utils import _classproperty
+from torchrl.envs.gym_like import default_info_dict_reader, GymLikeEnv
+from torchrl.envs.utils import _classproperty
 
+DEFAULT_GYM = None
 IMPORT_ERROR = None
-_has_gym = False
-try:
-    # rule of thumbs: gym precedes
-    import gym
+# check gym presence without importing it
+_has_gym = importlib.util.find_spec("gym") is not None
+if not _has_gym:
+    _has_gym = importlib.util.find_spec("gymnasium") is not None
 
-    _has_gym = True
-except ImportError as err:
-    IMPORT_ERROR = err
-    try:
-        import gymnasium as gym
+_has_mo = importlib.util.find_spec("mo_gymnasium") is not None
 
-        _has_gym = True
-    except ImportError as err:
-        IMPORT_ERROR = err
 
-if _has_gym:
-    try:
+class set_gym_backend(_DecoratorContextManager):
+    """Sets the gym-backend to a certain value.
+
+    Args:
+        backend (python module, string or callable returning a module): the
+            gym backend to use. Use a string or callable whenever you wish to
+            avoid importing gym at loading time.
+
+    Examples:
+        >>> import gym
+        >>> import gymnasium
+        >>> with set_gym_backend("gym"):
+        ...     assert gym_backend() == gym
+        >>> with set_gym_backend(lambda: gym):
+        ...     assert gym_backend() == gym
+        >>> with set_gym_backend(gym):
+        ...     assert gym_backend() == gym
+        >>> with set_gym_backend("gymnasium"):
+        ...     assert gym_backend() == gymnasium
+        >>> with set_gym_backend(lambda: gymnasium):
+        ...     assert gym_backend() == gymnasium
+        >>> with set_gym_backend(gymnasium):
+        ...     assert gym_backend() == gymnasium
+
+    This class can also be used as a function decorator.
+
+    Examples:
+        >>> @set_gym_backend("gym")
+        ... def fun():
+        ...     gym = gym_backend()
+        ...     print(gym)
+        >>> fun()
+        <module 'gym' from '/path/to/env/site-packages/gym/__init__.py'>
+        >>> @set_gym_backend("gymnasium")
+        ... def fun():
+        ...     gym = gym_backend()
+        ...     print(gym)
+        >>> fun()
+        <module 'gymnasium' from '/path/to/env/site-packages/gymnasium/__init__.py'>
+
+
+    """
+
+    def __init__(self, backend):
+        self.backend = backend
+
+    def _call(self):
+        global DEFAULT_GYM
+        DEFAULT_GYM = self.backend
+        # implement_for.reset()
+        setters = copy(implement_for._setters)
+        found_setter = False
+        for setter in setters:
+            check_module = (
+                callable(setter.module_name)
+                and setter.module_name.__name__ == self.backend.__name__
+            ) or setter.module_name == self.backend.__name__
+            check_version = setter.check_version(
+                self.backend.__version__, setter.from_version, setter.to_version
+            )
+            if check_module and check_version:
+                setter(setter.fn)
+                found_setter = True
+        if not found_setter:
+            raise ImportError(
+                f"could not set anything related to gym backend "
+                f"{self.backend.__name__} with version={self.backend.__version__}."
+            )
+
+    def __enter__(self):
+        self._setters = copy(implement_for._setters)
+        self._call()
+
+    def __exit__(self, exc_type, exc_val, exc_tb):
+        implement_for.reset(setters=self._setters)
+        delattr(self, "_setters")
+
+    def clone(self):
+        # override this method if your children class takes __init__ parameters
+        return self.__class__(self.backend)
+
+    @property
+    def backend(self):
+        if isinstance(self._backend, str):
+            return importlib.import_module(self._backend)
+        elif callable(self._backend):
+            return self._backend()
+        return self._backend
+
+    @backend.setter
+    def backend(self, value):
+        self._backend = value
+
+
+def gym_backend(submodule=None):
+    """Returns the gym backend, or a sumbodule of it.
+
+    Args:
+        submodule (str): the submodule to import. If ``None``, the backend
+            itself is returned.
+
+    Examples:
+        >>> import mo_gymnasium
+        >>> with set_gym_backend("gym"):
+        ...     wrappers = gym_backend('wrappers')
+        ...     print(wrappers)
+        >>> with set_gym_backend("gymnasium"):
+        ...     wrappers = gym_backend('wrappers')
+        ...     print(wrappers)
+    """
+    global IMPORT_ERROR
+    global DEFAULT_GYM
+    if DEFAULT_GYM is None:
         try:
-            from gym.wrappers.pixel_observation import PixelObservationWrapper
-        except ModuleNotFoundError:
-            from gymnasium.wrappers.pixel_observation import PixelObservationWrapper
+            # rule of thumbs: gym precedes
+            import gym
+        except ImportError as err:
+            IMPORT_ERROR = err
+            try:
+                import gymnasium as gym
+            except ImportError as err:
+                IMPORT_ERROR = err
+                gym = None
+        DEFAULT_GYM = gym
+    if submodule is not None:
+        if not submodule.startswith("."):
+            submodule = "." + submodule
+            submodule = importlib.import_module(submodule, package=DEFAULT_GYM.__name__)
+            return submodule
+    return DEFAULT_GYM
 
-        from torchrl.envs.libs.utils import (
-            GymPixelObservationWrapper as LegacyPixelObservationWrapper,
-        )
-    except ModuleNotFoundError:
-        warnings.warn(
-            f"gym {gym.__version__} does not provide the PixelObservationWrapper"
-            f"used by torchrl, which will be using a patched version. "
-            f"Consider updating gym to a newer version."
-        )
-        from torchrl.envs.libs.utils import (
-            GymPixelObservationWrapper as PixelObservationWrapper,
-        )
 
 __all__ = ["GymWrapper", "GymEnv"]
 
 
 def _gym_to_torchrl_spec_transform(
     spec, dtype=None, device="cpu", categorical_action_encoding=False
 ) -> TensorSpec:
     """Maps the gym specs to the TorchRL specs.
 
     By convention, 'state' keys of Dict specs will be renamed "observation" to match the
     default TorchRL keys.
 
     """
+    gym = gym_backend()
     if isinstance(spec, gym.spaces.tuple.Tuple):
         raise NotImplementedError("gym.spaces.tuple.Tuple mapping not yet implemented")
     if isinstance(spec, gym.spaces.discrete.Discrete):
         action_space_cls = (
             DiscreteTensorSpec
             if categorical_action_encoding
             else OneHotDiscreteTensorSpec
@@ -156,44 +270,61 @@
     envs = list(envs)
     envs = sorted(envs)
     return envs
 
 
 @implement_for("gym", None, "0.26.0")
 def _get_gym_envs():  # noqa: F811
+    gym = gym_backend()
     return gym.envs.registration.registry.env_specs.keys()
 
 
 @implement_for("gym", "0.26.0", None)
 def _get_gym_envs():  # noqa: F811
+    gym = gym_backend()
     return gym.envs.registration.registry.keys()
 
 
 @implement_for("gymnasium", "0.27.0", None)
 def _get_gym_envs():  # noqa: F811
+    gym = gym_backend()
     return gym.envs.registration.registry.keys()
 
 
 def _is_from_pixels(env):
+    gym = gym_backend()
     observation_spec = env.observation_space
+    try:
+        PixelObservationWrapper = gym_backend(
+            "wrappers.pixel_observation.PixelObservationWrapper"
+        )
+    except ModuleNotFoundError:
+
+        class PixelObservationWrapper:
+            pass
+
+    from torchrl.envs.libs.utils import (
+        GymPixelObservationWrapper as LegacyPixelObservationWrapper,
+    )
+
     if isinstance(observation_spec, (Dict,)):
         if "pixels" in set(observation_spec.keys()):
             return True
     if isinstance(observation_spec, (gym.spaces.dict.Dict,)):
         if "pixels" in set(observation_spec.spaces.keys()):
             return True
     elif (
         isinstance(observation_spec, gym.spaces.Box)
         and (observation_spec.low == 0).all()
         and (observation_spec.high == 255).all()
         and observation_spec.low.shape[-1] == 3
         and observation_spec.low.ndim == 3
     ):
         return True
-    elif isinstance(env, PixelObservationWrapper):
+    elif isinstance(env, (LegacyPixelObservationWrapper, PixelObservationWrapper)):
         return True
     return False
 
 
 class GymWrapper(GymLikeEnv):
     """OpenAI Gym environment wrapper.
 
@@ -205,95 +336,144 @@
         >>> print(env.available_envs)
 
     """
 
     git_url = "https://github.com/openai/gym"
     libname = "gym"
 
+    @staticmethod
+    def get_library_name(env):
+        # try gym
+        try:
+            import gym
+
+            if isinstance(env.action_space, gym.spaces.space.Space):
+                return gym
+        except ImportError:
+            pass
+        try:
+            import gymnasium
+
+            if isinstance(env.action_space, gymnasium.spaces.space.Space):
+                return gymnasium
+        except ImportError:
+            pass
+        raise RuntimeError(
+            f"Could not find the library of env {env}. Please file an issue on torchrl github repo."
+        )
+
     def __init__(self, env=None, categorical_action_encoding=False, **kwargs):
         if env is not None:
             kwargs["env"] = env
         self._seed_calls_reset = None
         self._categorical_action_encoding = categorical_action_encoding
-        super().__init__(**kwargs)
+        if "env" in kwargs:
+            with set_gym_backend(self.get_library_name(kwargs["env"])):
+                super().__init__(**kwargs)
+        else:
+            super().__init__(**kwargs)
 
     def _check_kwargs(self, kwargs: Dict):
         if "env" not in kwargs:
             raise TypeError("Could not find environment key 'env' in kwargs.")
         env = kwargs["env"]
         if not (hasattr(env, "action_space") and hasattr(env, "observation_space")):
             raise TypeError("env is not of type 'gym.Env'.")
 
     def _build_env(
         self,
         env,
         from_pixels: bool = False,
         pixels_only: bool = False,
-    ) -> "gym.core.Env":
+    ) -> "gym.core.Env":  # noqa: F821
         env_from_pixels = _is_from_pixels(env)
         from_pixels = from_pixels or env_from_pixels
         self.from_pixels = from_pixels
         self.pixels_only = pixels_only
         if from_pixels and not env_from_pixels:
-            if isinstance(env, PixelObservationWrapper):
-                raise TypeError(
-                    "PixelObservationWrapper cannot be used to wrap an environment"
-                    "that is already a PixelObservationWrapper instance."
+            try:
+                PixelObservationWrapper = gym_backend(
+                    "wrappers.pixel_observation.PixelObservationWrapper"
                 )
+                if isinstance(env, PixelObservationWrapper):
+                    raise TypeError(
+                        "PixelObservationWrapper cannot be used to wrap an environment"
+                        "that is already a PixelObservationWrapper instance."
+                    )
+            except ModuleNotFoundError:
+                pass
             env = self._build_gym_env(env, pixels_only)
         return env
 
-    @implement_for("gym", None, "0.26.0")
+    @implement_for("gym", None, "0.19.0")
     def _build_gym_env(self, env, pixels_only):  # noqa: F811
+        from .utils import GymPixelObservationWrapper as PixelObservationWrapper
+
         return PixelObservationWrapper(env, pixels_only=pixels_only)
 
+    @implement_for("gym", "0.19.0", "0.26.0")
+    def _build_gym_env(self, env, pixels_only):  # noqa: F811
+        pixel_observation = gym_backend("wrappers.pixel_observation")
+        return pixel_observation.PixelObservationWrapper(env, pixels_only=pixels_only)
+
     @implement_for("gym", "0.26.0", None)
     def _build_gym_env(self, env, pixels_only):  # noqa: F811
-        from gym.wrappers.compatibility import EnvCompatibility
+        compatibility = gym_backend("wrappers.compatibility")
+        pixel_observation = gym_backend("wrappers.pixel_observation")
 
         if env.render_mode:
-            return PixelObservationWrapper(env, pixels_only=pixels_only)
+            return pixel_observation.PixelObservationWrapper(
+                env, pixels_only=pixels_only
+            )
 
         warnings.warn(
             "Environments provided to GymWrapper that need to be wrapped in PixelObservationWrapper "
             "should be created with `gym.make(env_name, render_mode=mode)` where possible,"
             'where mode is either "rgb_array" or any other supported mode.'
         )
         # resetting as 0.26 comes with a very 'nice' OrderEnforcing wrapper
-        env = EnvCompatibility(env)
+        env = compatibility.EnvCompatibility(env)
         env.reset()
+        from torchrl.envs.libs.utils import (
+            GymPixelObservationWrapper as LegacyPixelObservationWrapper,
+        )
+
         return LegacyPixelObservationWrapper(env, pixels_only=pixels_only)
 
     @implement_for("gymnasium", "0.27.0", None)
     def _build_gym_env(self, env, pixels_only):  # noqa: F811
-        from gymnasium.wrappers.compatibility import EnvCompatibility
+        compatibility = gym_backend("wrappers.compatibility")
+        pixel_observation = gym_backend("wrappers.pixel_observation")
 
         if env.render_mode:
-            return PixelObservationWrapper(env, pixels_only=pixels_only)
+            return pixel_observation.PixelObservationWrapper(
+                env, pixels_only=pixels_only
+            )
 
         warnings.warn(
             "Environments provided to GymWrapper that need to be wrapped in PixelObservationWrapper "
             "should be created with `gym.make(env_name, render_mode=mode)` where possible,"
             'where mode is either "rgb_array" or any other supported mode.'
         )
         # resetting as 0.26 comes with a very 'nice' OrderEnforcing wrapper
-        env = EnvCompatibility(env)
+        env = compatibility.EnvCompatibility(env)
         env.reset()
+        from torchrl.envs.libs.utils import (
+            GymPixelObservationWrapper as LegacyPixelObservationWrapper,
+        )
+
         return LegacyPixelObservationWrapper(env, pixels_only=pixels_only)
 
     @_classproperty
     def available_envs(cls) -> List[str]:
         return _get_envs()
 
     @property
     def lib(self) -> ModuleType:
-        if _has_gym:
-            return gym
-        else:
-            raise ImportError("Gym not found, check installation") from IMPORT_ERROR
+        return gym_backend()
 
     def _set_seed(self, seed: int) -> int:  # noqa: F811
         if self._seed_calls_reset is None:
             # Determine basing on gym version whether `reset` is called when setting seed.
             self._set_seed_initial(seed)
         elif self._seed_calls_reset:
             self.reset(seed=seed)
@@ -329,15 +509,15 @@
             warnings.warn(
                 f"reset with seed kwarg returned an exception: {err}.\n"
                 f"Calling env.seed from now on."
             )
             self._seed_calls_reset = False
             self._env.seed(seed=seed)
 
-    def _make_specs(self, env: "gym.Env") -> None:
+    def _make_specs(self, env: "gym.Env") -> None:  # noqa: F821
         self.action_spec = _gym_to_torchrl_spec_transform(
             env.action_space,
             device=self.device,
             categorical_action_encoding=self._categorical_action_encoding,
         )
         observation_spec = _gym_to_torchrl_spec_transform(
             env.observation_space,
@@ -346,18 +526,25 @@
         )
         if not isinstance(observation_spec, CompositeSpec):
             if self.from_pixels:
                 observation_spec = CompositeSpec(pixels=observation_spec)
             else:
                 observation_spec = CompositeSpec(observation=observation_spec)
         self.observation_spec = observation_spec
-        self.reward_spec = UnboundedContinuousTensorSpec(
-            shape=[1],
-            device=self.device,
-        )
+        if hasattr(env, "reward_space") and env.reward_space is not None:
+            self.reward_spec = _gym_to_torchrl_spec_transform(
+                env.reward_space,
+                device=self.device,
+                categorical_action_encoding=self._categorical_action_encoding,
+            )
+        else:
+            self.reward_spec = UnboundedContinuousTensorSpec(
+                shape=[1],
+                device=self.device,
+            )
 
     def _init_env(self):
         self.reset()
 
     def __repr__(self) -> str:
         return (
             f"{self.__class__.__name__}(env={self._env}, batch_size={self.batch_size})"
@@ -392,49 +579,46 @@
         >>> env = GymEnv(env_name="Pendulum-v0", frame_skip=4)
         >>> td = env.rand_step()
         >>> print(td)
         >>> print(env.available_envs)
 
     """
 
-    def __init__(self, env_name, disable_env_checker=None, **kwargs):
+    def __init__(self, env_name, **kwargs):
         kwargs["env_name"] = env_name
-        self._set_gym_args(kwargs, disable_env_checker)
+        self._set_gym_args(kwargs)
         super().__init__(**kwargs)
 
     @implement_for("gym", None, "0.24.0")
-    def _set_gym_args(  # noqa: F811
-        self, kwargs, disable_env_checker: bool = None
-    ) -> None:
+    def _set_gym_args(self, kwargs) -> None:  # noqa: F811
+        disable_env_checker = kwargs.pop("disable_env_checker", None)
         if disable_env_checker is not None:
             raise RuntimeError(
                 "disable_env_checker should only be set if gym version is > 0.24"
             )
 
     @implement_for("gym", "0.24.0", None)
     def _set_gym_args(  # noqa: F811
-        self, kwargs, disable_env_checker: bool = None
+        self,
+        kwargs,
     ) -> None:
-        kwargs["disable_env_checker"] = (
-            disable_env_checker if disable_env_checker is not None else True
-        )
+        kwargs.setdefault("disable_env_checker", True)
 
     @implement_for("gymnasium", "0.27.0", None)
     def _set_gym_args(  # noqa: F811
-        self, kwargs, disable_env_checker: bool = None
+        self,
+        kwargs,
     ) -> None:
-        kwargs["disable_env_checker"] = (
-            disable_env_checker if disable_env_checker is not None else True
-        )
+        kwargs.setdefault("disable_env_checker", True)
 
     def _build_env(
         self,
         env_name: str,
         **kwargs,
-    ) -> "gym.core.Env":
+    ) -> "gym.core.Env":  # noqa: F821
         if not _has_gym:
             raise RuntimeError(
                 f"gym not found, unable to create {env_name}. "
                 f"Consider downloading and installing gym from"
                 f" {self.git_url}"
             )
         from_pixels = kwargs.get("from_pixels", False)
@@ -493,7 +677,54 @@
 
     def _check_kwargs(self, kwargs: Dict):
         if "env_name" not in kwargs:
             raise TypeError("Expected 'env_name' to be part of kwargs")
 
     def __repr__(self) -> str:
         return f"{self.__class__.__name__}(env={self.env_name}, batch_size={self.batch_size}, device={self.device})"
+
+
+class MOGymWrapper(GymWrapper):
+    """FARAMA MO-Gymnasium environment wrapper.
+
+    Examples:
+        >>> import mo_gymnasium as mo_gym
+        >>> env = MOGymWrapper(mo_gym.make('minecart-v0'), frame_skip=4)
+        >>> td = env.rand_step()
+        >>> print(td)
+        >>> print(env.available_envs)
+
+    """
+
+    git_url = "https://github.com/Farama-Foundation/MO-Gymnasium"
+    libname = "mo-gymnasium"
+
+    _make_specs = set_gym_backend("gymnasium")(GymEnv._make_specs)
+
+
+class MOGymEnv(GymEnv):
+    """FARAMA MO-Gymnasium environment wrapper.
+
+    Examples:
+        >>> env = MOGymEnv(env_name="minecart-v0", frame_skip=4)
+        >>> td = env.rand_step()
+        >>> print(td)
+        >>> print(env.available_envs)
+
+    """
+
+    git_url = "https://github.com/Farama-Foundation/MO-Gymnasium"
+    libname = "mo-gymnasium"
+
+    @property
+    def lib(self) -> ModuleType:
+        if _has_mo:
+            import mo_gymnasium as mo_gym
+
+            return mo_gym
+        else:
+            try:
+                import mo_gymnasium  # noqa: F401
+            except ImportError as err:
+                raise ImportError("MO-gymnasium not found, check installation") from err
+
+    _make_specs = set_gym_backend("gymnasium")(GymEnv._make_specs)
```

## torchrl/envs/libs/habitat.py

```diff
@@ -4,15 +4,15 @@
 # LICENSE file in the root directory of this source tree.
 import functools
 
 import torch
 
 from torchrl.data import DEVICE_TYPING
 from torchrl.envs import EnvBase
-from torchrl.envs.libs.gym import GymEnv
+from torchrl.envs.libs.gym import GymEnv, set_gym_backend
 from torchrl.envs.utils import classproperty
 
 IMPORT_ERR = None
 try:
     import habitat
     import habitat.gym  # noqa
 
@@ -49,22 +49,21 @@
 
     This class currently serves as placeholder and compatibility security.
     It behaves exactly like the GymEnv wrapper.
 
     """
 
     @_wrap_import_error
-    def __init__(self, env_name, disable_env_checker=None, **kwargs):
+    @set_gym_backend("gym")
+    def __init__(self, env_name, **kwargs):
         device_num = torch.device(kwargs.pop("device", 0)).index
         kwargs["override_options"] = [
             f"habitat.simulator.habitat_sim_v0.gpu_device_id={device_num}",
         ]
-        super().__init__(
-            env_name=env_name, disable_env_checker=disable_env_checker, **kwargs
-        )
+        super().__init__(env_name=env_name, **kwargs)
 
     @classproperty
     def available_envs(cls):
         yield from _get_available_envs()
 
     def _build_gym_env(self, env, pixels_only):
         if self.from_pixels:
```

## torchrl/envs/libs/jax_utils.py

```diff
@@ -14,14 +14,15 @@
 from torch.utils import dlpack as torch_dlpack
 from torchrl.data.tensor_specs import (
     CompositeSpec,
     TensorSpec,
     UnboundedContinuousTensorSpec,
     UnboundedDiscreteTensorSpec,
 )
+from torchrl.data.utils import numpy_to_torch_dtype_dict
 
 
 def _tree_reshape(x, batch_size: torch.Size):
     shape, n = batch_size, 1
     return jax.tree_util.tree_map(lambda x: x.reshape(shape + x.shape[n:]), x)
 
 
@@ -43,30 +44,35 @@
         value = value.view(_dtype_conversion[value.dtype])
     if isinstance(value, jnp.ndarray):
         dlpack_tensor = jax_dlpack.to_dlpack(value)
     elif isinstance(value, np.ndarray):
         dlpack_tensor = value.__dlpack__()
     else:
         raise NotImplementedError(f"unsupported data type {type(value)}")
-    return torch_dlpack.from_dlpack(dlpack_tensor)
+    out = torch_dlpack.from_dlpack(dlpack_tensor)
+    # dtype can be messed up by dlpack
+    return out.to(numpy_to_torch_dtype_dict[value.dtype])
 
 
 def _tensor_to_ndarray(value: torch.Tensor) -> jnp.ndarray:
     return jax_dlpack.from_dlpack(torch_dlpack.to_dlpack(value))
 
 
 def _get_object_fields(obj) -> dict:
+    """Converts an object (named tuple or dataclass or dict) to a dict."""
     if isinstance(obj, tuple) and hasattr(obj, "_fields"):  # named tuple
         return dict(zip(obj._fields, obj))
     elif dataclasses.is_dataclass(obj):
         return {
             field.name: getattr(obj, field.name) for field in dataclasses.fields(obj)
         }
     elif isinstance(obj, dict):
         return obj
+    elif obj is None:
+        return {}
     else:
         raise NotImplementedError(f"unsupported data type {type(obj)}")
 
 
 def _object_to_tensordict(obj, device, batch_size) -> TensorDictBase:
     """Converts a namedtuple or a dataclass to a TensorDict."""
     t = {}
@@ -74,27 +80,30 @@
     for name, value in _fields.items():
         if isinstance(value, (np.number, int, float)):
             t[name] = _ndarray_to_tensor(np.asarray([value])).to(device)
         elif isinstance(value, (jnp.ndarray, np.ndarray)):
             t[name] = _ndarray_to_tensor(value).to(device)
         else:
             t[name] = _object_to_tensordict(value, device, batch_size)
-    return make_tensordict(**t, device=device, batch_size=batch_size)
+    return make_tensordict(t, device=device, batch_size=batch_size)
 
 
 def _tensordict_to_object(tensordict: TensorDictBase, object_example):
     """Converts a TensorDict to a namedtuple or a dataclass."""
     t = {}
     _fields = _get_object_fields(object_example)
-    for name in tensordict.keys():
+    for name, value in tensordict.items():
         example = _fields[name]
-        value = tensordict[name]
         if isinstance(value, TensorDictBase):
             t[name] = _tensordict_to_object(value, example)
+        elif value is None:
+            t[name] = value
         else:
+            if value.dtype is torch.bool:
+                value = value.to(torch.uint8)
             value = jax_dlpack.from_dlpack(torch_dlpack.to_dlpack(value))
             t[name] = value.reshape(example.shape).view(example.dtype)
     return type(object_example)(**t)
 
 
 def _extract_spec(data: Union[torch.Tensor, TensorDictBase], key=None) -> TensorSpec:
     if isinstance(data, torch.Tensor):
```

## torchrl/envs/libs/jumanji.py

```diff
@@ -338,15 +338,16 @@
             raise RuntimeError(
                 f"jumanji not found, unable to create {env_name}. "
                 f"Consider installing jumanji. More info:"
                 f" {self.git_url}."
             ) from IMPORT_ERR
         from_pixels = kwargs.pop("from_pixels", False)
         pixels_only = kwargs.pop("pixels_only", True)
-        assert not kwargs
+        if kwargs:
+            raise ValueError(f"Extra kwargs are not supported by {type(self)}.")
         self.wrapper_frame_skip = 1
         env = self.lib.make(env_name, **kwargs)
         return super()._build_env(env, pixels_only=pixels_only, from_pixels=from_pixels)
 
     @property
     def env_name(self):
         return self._constructor_kwargs["env_name"]
```

## torchrl/envs/libs/utils.py

```diff
@@ -1,47 +1,44 @@
 # Copyright (c) Meta Platforms, Inc. and affiliates.
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
 
 # Copied from gym > 0.19 release
 
+# this file should only be accessed when gym is installed
+
 import collections
 import copy
 from collections.abc import MutableMapping
 
 import numpy as np
 
 IMPORT_ERROR = None
-_has_gym = False
 try:
     # rule of thumbs: gym precedes
     from gym import ObservationWrapper, spaces
-
-    _has_gym = True
 except ImportError as err:
     IMPORT_ERROR = err
     try:
         from gymnasium import ObservationWrapper, spaces
-
-        _has_gym = True
-    except ImportError as err:
-        IMPORT_ERROR = err
+    except ImportError as err2:
+        raise err from err2
 
 STATE_KEY = "observation"
 
 
 class GymPixelObservationWrapper(ObservationWrapper):
     """Augment observations by pixel values.
 
     Args:
         env: The environment to wrap.
         pixels_only: If :obj:`True` (default), the original observation returned
             by the wrapped environment will be discarded, and a dictionary
-            observation will only include pixels. If :obj:`False`, the
+            observation will only include pixels. If ``False``, the
             observation dictionary will contain both the original
             observations and the pixel observations.
         render_kwargs: Optional :obj:`dict` containing keyword arguments passed
             to the :obj:`self.render` method.
         pixel_keys: Optional custom string specifying the pixel
             observation's key in the :obj:`OrderedDict` of observations.
             Defaults to 'pixels'.
@@ -53,27 +50,28 @@
         ValueError: If :obj:`env`'s observation already contains any of the
             specified :obj:`pixel_keys`.
     """
 
     def __init__(
         self, env, pixels_only=True, render_kwargs=None, pixel_keys=("pixels",)
     ):
-        if not _has_gym:
-            raise IMPORT_ERROR
         env.reset()
         super().__init__(env)
 
         if render_kwargs is None:
             render_kwargs = {}
 
         for key in pixel_keys:
             render_kwargs.setdefault(key, {})
 
             render_mode = render_kwargs[key].pop("mode", "rgb_array")
-            assert render_mode == "rgb_array", render_mode
+            if render_mode != "rgb_array":
+                raise ValueError(
+                    f"Expected render_mode to be 'rgb_array', git {render_mode}"
+                )
             render_kwargs[key]["mode"] = "rgb_array"
 
         wrapped_observation_space = env.observation_space
 
         if isinstance(wrapped_observation_space, spaces.Box):
             self._observation_is_dict = False
             invalid_keys = {STATE_KEY}
```

## torchrl/envs/libs/vmas.py

```diff
@@ -1,26 +1,31 @@
-from typing import Dict, List, Optional
+from typing import Dict, List, Optional, Union
 
 import torch
 from tensordict.tensordict import TensorDict, TensorDictBase
 
-from torchrl.data import CompositeSpec, DEVICE_TYPING, UnboundedContinuousTensorSpec
+from torchrl.data import (
+    CompositeSpec,
+    DEVICE_TYPING,
+    DiscreteTensorSpec,
+    UnboundedContinuousTensorSpec,
+)
 from torchrl.envs.common import _EnvWrapper, EnvBase
 from torchrl.envs.libs.gym import _gym_to_torchrl_spec_transform
 from torchrl.envs.utils import _selective_unsqueeze
 
+IMPORT_ERR = None
 try:
     import vmas
 
     _has_vmas = True
 
 except ImportError as err:
-
     _has_vmas = False
-    IMPORT_ERR = str(err)
+    IMPORT_ERR = err
 
 __all__ = ["VmasWrapper", "VmasEnv"]
 
 
 def _get_envs() -> List:
     if not _has_vmas:
         return []
@@ -45,58 +50,57 @@
 
 class VmasWrapper(_EnvWrapper):
     """Vmas environment wrapper.
 
     Examples:
         >>>  env = VmasWrapper(
         ...      vmas.make_env(
-        ...          scenario_name="flocking",
+        ...          scenario="flocking",
         ...          num_envs=32,
         ...          continuous_actions=True,
         ...          max_steps=200,
         ...          device="cpu",
         ...          seed=None,
         ...          # Scenario kwargs
         ...          n_agents=5,
         ...      )
         ...  )
         >>>  print(env.rollout(10))
         TensorDict(
-             fields={
-                 action: Tensor(torch.Size([5, 32, 10, 2]), dtype=torch.float64),
-                 done: Tensor(torch.Size([5, 32, 10, 1]), dtype=torch.bool),
-                 info: TensorDict(
-                     fields={
-                         cohesion_rew: Tensor(torch.Size([5, 32, 10, 1]), dtype=torch.float32),
-                         collision_rew: Tensor(torch.Size([5, 32, 10, 1]), dtype=torch.float32),
-                         separation_rew: Tensor(torch.Size([5, 32, 10, 1]), dtype=torch.float32),
-                         velocity_rew: Tensor(torch.Size([5, 32, 10, 1]), dtype=torch.float32)},
-                     batch_size=torch.Size([5, 32, 10]),
-                     device=cpu,
-                     is_shared=False),
-                 next: TensorDict(
-                     fields={
-                         info: TensorDict(
-                             fields={
-                                 cohesion_rew: Tensor(torch.Size([5, 32, 10, 1]), dtype=torch.float32),
-                                 collision_rew: Tensor(torch.Size([5, 32, 10, 1]), dtype=torch.float32),
-                                 separation_rew: Tensor(torch.Size([5, 32, 10, 1]), dtype=torch.float32),
-                                 velocity_rew: Tensor(torch.Size([5, 32, 10, 1]), dtype=torch.float32)},
-                             batch_size=torch.Size([5, 32, 10]),
-                             device=cpu,
-                             is_shared=False),
-                         observation: Tensor(torch.Size([5, 32, 10, 18]), dtype=torch.float32)},
-                     batch_size=torch.Size([5, 32, 10]),
-                     device=cpu,
-                     is_shared=False),
-                 observation: Tensor(torch.Size([5, 32, 10, 18]), dtype=torch.float32),
-                 reward: Tensor(torch.Size([5, 32, 10, 1]), dtype=torch.float32)},
-             batch_size=torch.Size([5, 32, 10]),
-             device=cpu,
-             is_shared=False)
+            fields={
+                action: Tensor(shape=torch.Size([32, 10, 5, 2]), device=cpu, dtype=torch.float32, is_shared=False),
+                done: Tensor(shape=torch.Size([32, 10, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False),
+                info: TensorDict(
+                    fields={
+                        agent_collision_rew: Tensor(shape=torch.Size([32, 10, 5, 1]), device=cpu, dtype=torch.float32, is_shared=False),
+                        agent_distance_rew: Tensor(shape=torch.Size([32, 10, 5, 1]), device=cpu, dtype=torch.float32, is_shared=False)},
+                    batch_size=torch.Size([32, 10, 5]),
+                    device=cpu,
+                    is_shared=False),
+                next: TensorDict(
+                    fields={
+                        done: Tensor(shape=torch.Size([32, 10, 5, 1]), device=cpu, dtype=torch.bool, is_shared=False),
+                        info: TensorDict(
+                            fields={
+                                agent_collision_rew: Tensor(shape=torch.Size([32, 10, 5, 1]), device=cpu, dtype=torch.float32, is_shared=False),
+                                agent_distance_rew: Tensor(shape=torch.Size([32, 10, 5, 1]), device=cpu, dtype=torch.float32, is_shared=False)},
+                            batch_size=torch.Size([32, 10, 5]),
+                            device=cpu,
+                            is_shared=False),
+                        observation: Tensor(shape=torch.Size([32, 10, 5, 18]), device=cpu, dtype=torch.float32, is_shared=False),
+                        reward: Tensor(shape=torch.Size([32, 10, 5, 1]), device=cpu, dtype=torch.float32, is_shared=False)},
+                    batch_size=torch.Size([32, 10]),
+                    device=cpu,
+                    is_shared=False),
+                observation: Tensor(shape=torch.Size([32, 10, 5, 18]), device=cpu, dtype=torch.float32, is_shared=False),
+                reward: Tensor(shape=torch.Size([32, 10, 5, 1]), device=cpu, dtype=torch.float32, is_shared=False)},
+            batch_size=torch.Size([32, 10]),
+            device=cpu,
+            is_shared=False)
+
     """
 
     git_url = "https://github.com/proroklab/VectorizedMultiAgentSimulator"
     libname = "vmas"
     available_envs = _get_envs()
 
     def __init__(
@@ -136,60 +140,97 @@
                 raise TypeError(
                     "Batch size used in constructor does not match vmas batch size."
                 )
         else:
             raise TypeError(
                 "Batch size used in constructor is not compatible with vmas."
             )
-        self.batch_size = torch.Size([env.n_agents, *self.batch_size])
 
         return env
 
     def _make_specs(
         self, env: "vmas.simulator.environment.environment.Environment"
     ) -> None:
         # TODO heterogenous spaces
-        # For now the wrapper assumes all agent spaces to be homogenous, thus let's use agent0
-        agent0 = self.agents[0]
-        agent0_index = 0
 
-        self.input_spec = CompositeSpec(
-            action=(
+        # Agent specs
+        action_specs = []
+        observation_specs = []
+        reward_specs = []
+        info_specs = []
+        for agent_index, agent in enumerate(self.agents):
+            action_specs.append(
                 _gym_to_torchrl_spec_transform(
-                    self.action_space[agent0_index],
+                    self.action_space[agent_index],
                     categorical_action_encoding=True,
                     device=self.device,
                 )
-            )
-        ).expand(self.batch_size)
-
-        self.reward_spec = UnboundedContinuousTensorSpec(
-            shape=torch.Size((1,)),
-            device=self.device,
-        ).expand([*self.batch_size, 1])
-
-        self.observation_spec = CompositeSpec(
-            observation=(
+            )  # shape = (n_actions_per_agent,)
+            observation_specs.append(
                 _gym_to_torchrl_spec_transform(
-                    self.observation_space[agent0_index],
+                    self.observation_space[agent_index],
                     device=self.device,
                 )
-            ),
-            info=CompositeSpec(
-                {
-                    key: UnboundedContinuousTensorSpec(
-                        shape=_selective_unsqueeze(
-                            value, batch_size=torch.Size((self.num_envs,))
-                        ).shape[1:],
-                        device=self.device,
-                        dtype=torch.float32,
-                    )
-                    for key, value in self.scenario.info(agent0).items()
-                },
-            ).to(self.device),
+            )  # shape = (n_obs_per_agent,)
+            reward_specs.append(
+                UnboundedContinuousTensorSpec(
+                    shape=torch.Size((1,)),
+                    device=self.device,
+                )
+            )  # shape = (1,)
+            agent_info = self.scenario.info(agent)
+            if len(agent_info):
+                info_specs.append(
+                    CompositeSpec(
+                        {
+                            key: UnboundedContinuousTensorSpec(
+                                shape=_selective_unsqueeze(
+                                    value, batch_size=torch.Size((self.num_envs,))
+                                ).shape[1:],
+                                device=self.device,
+                                dtype=torch.float32,
+                            )
+                            for key, value in agent_info.items()
+                        },
+                    ).to(self.device)
+                )
+
+        # Create multi-agent specs
+        multi_agent_action_spec = torch.stack(
+            action_specs, dim=0
+        )  # UnboundedContinuousTensorSpec with shape = (n_agents, n_actions_per_agent)
+        multi_agent_observation_spec = torch.stack(
+            observation_specs, dim=0
+        )  # UnboundedContinuousTensorSpec with shape = (n_agents, n_obs_per_agent)
+        multi_agent_reward_spec = torch.stack(
+            reward_specs, dim=0
+        )  # UnboundedContinuousTensorSpec with shape = (n_agents, 1)
+
+        done_spec = DiscreteTensorSpec(
+            n=2,
+            shape=torch.Size((self.n_agents, 1)),
+            dtype=torch.bool,
+            device=self.device,
+        )  # shape = (n_agents, 1)
+
+        self.input_spec = CompositeSpec(action=multi_agent_action_spec).expand(
+            self.batch_size
+        )
+        if len(info_specs):
+            multi_agent_info_spec = torch.stack(info_specs, dim=0)
+            observation_spec = CompositeSpec(
+                observation=multi_agent_observation_spec, info=multi_agent_info_spec
+            )
+        else:
+            observation_spec = CompositeSpec(observation=multi_agent_observation_spec)
+
+        self.output_spec = CompositeSpec(
+            observation=observation_spec,
+            reward=multi_agent_reward_spec,
+            done=done_spec,
         ).expand(self.batch_size)
 
     def _check_kwargs(self, kwargs: Dict):
         if "env" not in kwargs:
             raise TypeError("Could not find environment key 'env' in kwargs.")
         env = kwargs["env"]
         if not isinstance(env, vmas.simulator.environment.Environment):
@@ -204,88 +245,82 @@
         self._env.seed(seed)
 
     def _reset(
         self, tensordict: Optional[TensorDictBase] = None, **kwargs
     ) -> TensorDictBase:
         if tensordict is not None and "_reset" in tensordict.keys():
             _reset = tensordict.get("_reset")
-            envs_to_reset = _reset.any(dim=0)
+            envs_to_reset = _reset.squeeze(-1).any(-1)
             for env_index, to_reset in enumerate(envs_to_reset):
                 if to_reset:
-                    self._env.reset_at(env_index)
-            done = _selective_unsqueeze(self._env.done(), batch_size=(self.num_envs,))
-            obs = []
-            infos = []
-            dones = []
-            for agent in self.agents:
-                obs.append(self.scenario.observation(agent))
-                infos.append(self.scenario.info(agent))
-                dones.append(done.clone())
-
+                    self._env.reset_at(env_index, return_observations=False)
         else:
-            obs, infos = self._env.reset(return_info=True)
-            dones = None
+            self._env.reset(return_observations=False)
+
+        obs, dones, infos = self._env.get_from_scenario(
+            get_observations=True,
+            get_infos=True,
+            get_rewards=False,
+            get_dones=True,
+        )
+        dones = self.read_done(dones)
 
         agent_tds = []
         for i in range(self.n_agents):
             agent_obs = self.read_obs(obs[i])
             agent_info = self.read_info(infos[i])
 
             agent_td = TensorDict(
                 source={
                     "observation": agent_obs,
                 },
                 batch_size=(self.num_envs,),
                 device=self.device,
             )
-
             if agent_info is not None:
                 agent_td.set("info", agent_info)
-            if dones is not None:
-                agent_td.set("done", dones[i])
             agent_tds.append(agent_td)
 
-        tensordict_out = torch.stack(agent_tds, dim=0)
-
+        tensordict_out = torch.stack(agent_tds, dim=1).to_tensordict()
+        tensordict_out.batch_size = self.batch_size
+        tensordict_out.set("done", dones)
         return tensordict_out
 
     def _step(
         self,
         tensordict: TensorDictBase,
     ) -> TensorDictBase:
-
         action = tensordict.get("action")
         action = self.read_action(action)
 
         obs, rews, dones, infos = self._env.step(action)
 
         dones = self.read_done(dones)
 
         agent_tds = []
         for i in range(self.n_agents):
             agent_obs = self.read_obs(obs[i])
             agent_rew = self.read_reward(rews[i])
-            agent_done = dones.clone()
             agent_info = self.read_info(infos[i])
 
             agent_td = TensorDict(
                 source={
                     "observation": agent_obs,
-                    "done": agent_done,
                     "reward": agent_rew,
                 },
                 batch_size=(self.num_envs,),
                 device=self.device,
             )
-
             if agent_info is not None:
                 agent_td.set("info", agent_info)
             agent_tds.append(agent_td)
 
-        tensordict_out = torch.stack(agent_tds, dim=0)
+        tensordict_out = torch.stack(agent_tds, dim=1).to_tensordict()
+        tensordict_out.batch_size = self.batch_size
+        tensordict_out.set("done", dones)
 
         return tensordict_out.select().set("next", tensordict_out)
 
     def read_obs(self, observations: torch.Tensor) -> torch.Tensor:
         observations = _selective_unsqueeze(
             observations, batch_size=torch.Size((self.num_envs,))
         )
@@ -305,45 +340,44 @@
             device=self.device,
         )
 
         return infos
 
     def read_done(self, done):
         done = _selective_unsqueeze(done, batch_size=torch.Size((self.num_envs,)))
-
+        done = done.unsqueeze(-1).expand(*self.batch_size, self.n_agents, 1)
         return done
 
     def read_reward(self, rewards):
         rewards = _selective_unsqueeze(rewards, batch_size=torch.Size((self.num_envs,)))
         return rewards
 
     def read_action(self, action):
-
         agent_actions = []
         for i in range(self.n_agents):
-            agent_actions.append(action[i, :, ...])
+            agent_actions.append(action[:, i, ...])
         return agent_actions
 
     def __repr__(self) -> str:
         return (
-            f"{self.__class__.__name__}(env={self._env}, num_envs={self.num_envs}, n_agents={self.n_agents},"
+            f"{self.__class__.__name__}(num_envs={self.num_envs}, n_agents={self.n_agents},"
             f" batch_size={self.batch_size}, device={self.device})"
         )
 
     def to(self, device: DEVICE_TYPING) -> EnvBase:
         self._env.to(device)
         return super().to(device)
 
 
 class VmasEnv(VmasWrapper):
     """Vmas environment wrapper.
 
     Examples:
         >>>  env = VmasEnv(
-        ...      scenario_name="flocking",
+        ...      scenario="flocking",
         ...      num_envs=32,
         ...      continuous_actions=True,
         ...      max_steps=200,
         ...      device="cpu",
         ...      seed=None,
         ...      # Scenario kwargs
         ...      n_agents=5,
@@ -382,62 +416,62 @@
             batch_size=torch.Size([5, 32, 10]),
             device=cpu,
             is_shared=False)
     """
 
     def __init__(
         self,
-        scenario_name: str,
+        scenario: Union[str, "vmas.simulator.scenario.BaseScenario"],
         num_envs: int,
         continuous_actions: bool = True,
         max_steps: Optional[int] = None,
         seed: Optional[int] = None,
         **kwargs,
     ):
         if not _has_vmas:
             raise ImportError(
                 f"vmas python package was not found. Please install this dependency. "
                 f"More info: {self.git_url}."
             ) from IMPORT_ERR
-        kwargs["scenario_name"] = scenario_name
+        kwargs["scenario"] = scenario
         kwargs["num_envs"] = num_envs
         kwargs["continuous_actions"] = continuous_actions
         kwargs["max_steps"] = max_steps
         kwargs["seed"] = seed
         super().__init__(**kwargs)
 
     def _check_kwargs(self, kwargs: Dict):
-        if "scenario_name" not in kwargs:
-            raise TypeError("Could not find environment key 'scenario_name' in kwargs.")
+        if "scenario" not in kwargs:
+            raise TypeError("Could not find environment key 'scenario' in kwargs.")
         if "num_envs" not in kwargs:
             raise TypeError("Could not find environment key 'num_envs' in kwargs.")
 
     def _build_env(
         self,
-        scenario_name: str,
+        scenario: Union[str, "vmas.simulator.scenario.BaseScenario"],
         num_envs: int,
         continuous_actions: bool,
         max_steps: Optional[int],
         seed: Optional[int],
         **scenario_kwargs,
     ) -> "vmas.simulator.environment.environment.Environment":
-        self.scenario_name = scenario_name
+        self.scenario_name = scenario
         from_pixels = scenario_kwargs.pop("from_pixels", False)
         pixels_only = scenario_kwargs.pop("pixels_only", False)
 
         return super()._build_env(
             env=vmas.make_env(
-                scenario_name=scenario_name,
+                scenario=scenario,
                 num_envs=num_envs,
                 device=self.device,
                 continuous_actions=continuous_actions,
                 max_steps=max_steps,
                 seed=seed,
                 wrapper=None,
                 **scenario_kwargs,
             ),
             pixels_only=pixels_only,
             from_pixels=from_pixels,
         )
 
     def __repr__(self):
-        return f"{super().__repr__()} (scenario_name={self.scenario_name})"
+        return f"{super().__repr__()} (scenario={self.scenario_name})"
```

## torchrl/envs/model_based/common.py

```diff
@@ -6,18 +6,18 @@
 import abc
 import warnings
 from typing import List, Optional, Union
 
 import numpy as np
 import torch
 from tensordict import TensorDict
+from tensordict.nn import TensorDictModule
 
 from torchrl.data.utils import DEVICE_TYPING
 from torchrl.envs.common import EnvBase
-from torchrl.modules.tensordict_module import SafeModule
 
 
 class ModelBasedEnvBase(EnvBase, metaclass=abc.ABCMeta):
     """Basic environnement for Model Based RL algorithms.
 
     Wrapper around the model of the MBRL algorithm.
     It is meant to give an env framework to a world model (including but not limited to observations, reward, done state and safety constraints models).
@@ -49,20 +49,20 @@
         ...         tensordict = tensordict.update(self.input_spec.rand())
         ...         tensordict = tensordict.update(self.observation_spec.rand())
         ...         return tensordict
         >>> # This environment is used as follows:
         >>> import torch.nn as nn
         >>> from torchrl.modules import MLP, WorldModelWrapper
         >>> world_model = WorldModelWrapper(
-        ...     SafeModule(
+        ...     TensorDictModule(
         ...         MLP(out_features=4, activation_class=nn.ReLU, activate_last_layer=True, depth=0),
         ...         in_keys=["hidden_observation", "action"],
         ...         out_keys=["hidden_observation"],
         ...     ),
-        ...     SafeModule(
+        ...     TensorDictModule(
         ...         nn.Linear(4, 1),
         ...         in_keys=["hidden_observation"],
         ...         out_keys=["reward"],
         ...     ),
         ... )
         >>> env = MyMBEnv(world_model)
         >>> tensordict = env.rollout(max_steps=10)
@@ -109,15 +109,15 @@
         rollout (Callable, ... -> TensorDict): executes a rollout in the environment with the given policy (or random
             steps if no policy is provided)
 
     """
 
     def __init__(
         self,
-        world_model: SafeModule,
+        world_model: TensorDictModule,
         params: Optional[List[torch.Tensor]] = None,
         buffers: Optional[List[torch.Tensor]] = None,
         device: DEVICE_TYPING = "cpu",
         dtype: Optional[Union[torch.dtype, np.dtype]] = None,
         batch_size: Optional[torch.Size] = None,
         run_type_checks: bool = False,
     ):
```

## torchrl/envs/model_based/dreamer.py

```diff
@@ -4,31 +4,31 @@
 # LICENSE file in the root directory of this source tree.
 
 from typing import Optional, Tuple, Union
 
 import numpy as np
 import torch
 from tensordict import TensorDict
+from tensordict.nn import TensorDictModule
 
 from torchrl.data.tensor_specs import CompositeSpec
 from torchrl.data.utils import DEVICE_TYPING
 from torchrl.envs import EnvBase
 from torchrl.envs.model_based import ModelBasedEnvBase
-from torchrl.modules.tensordict_module import SafeModule
 
 
 class DreamerEnv(ModelBasedEnvBase):
     """Dreamer simulation environment."""
 
     def __init__(
         self,
-        world_model: SafeModule,
+        world_model: TensorDictModule,
         prior_shape: Tuple[int, ...],
         belief_shape: Tuple[int, ...],
-        obs_decoder: SafeModule = None,
+        obs_decoder: TensorDictModule = None,
         device: DEVICE_TYPING = "cpu",
         dtype: Optional[Union[torch.dtype, np.dtype]] = None,
         batch_size: Optional[torch.Size] = None,
     ):
         super(DreamerEnv, self).__init__(
             world_model, device=device, dtype=dtype, batch_size=batch_size
         )
```

## torchrl/envs/transforms/__init__.py

```diff
@@ -22,20 +22,22 @@
     NoopResetEnv,
     ObservationNorm,
     ObservationTransform,
     PinMemoryTransform,
     RandomCropTensorDict,
     RenameTransform,
     Resize,
+    Reward2GoTransform,
     RewardClipping,
     RewardScaling,
     RewardSum,
     SelectTransform,
     SqueezeTransform,
     StepCounter,
+    TargetReturn,
     TensorDictPrimer,
     TimeMaxPool,
     ToTensorImage,
     Transform,
     TransformedEnv,
     UnsqueezeTransform,
     VecNorm,
```

## torchrl/envs/transforms/r3m.py

```diff
@@ -211,15 +211,15 @@
              "r3m_vec" is assumed.
         size (int, optional): Size of the image to feed to resnet.
             Defaults to 244.
         stack_images (bool, optional): if False, the images given in the :obj:`in_keys`
              argument will be treaded separetely and each will be given a single,
              separated entry in the output tensordict. Defaults to :obj:`True`.
         download (bool, torchvision Weights config or corresponding string):
-            if True, the weights will be downloaded using the torch.hub download
+            if ``True``, the weights will be downloaded using the torch.hub download
             API (i.e. weights will be cached for future use).
             These weights are the original weights from the R3M publication.
             If the torchvision weights are needed, there are two ways they can be
             obtained: :obj:`download=ResNet50_Weights.IMAGENET1K_V1` or :obj:`download="IMAGENET1K_V1"`
             where :obj:`ResNet50_Weights` can be imported via :obj:`from torchvision.models import resnet50, ResNet50_Weights`.
             Defaults to False.
         download_path (str, optional): path where to download the models.
```

## torchrl/envs/transforms/transforms.py

```diff
@@ -13,8860 +13,10412 @@
 000000c0: 7475 7265 5f5f 2069 6d70 6f72 7420 616e  ture__ import an
 000000d0: 6e6f 7461 7469 6f6e 730d 0a0d 0a69 6d70  notations....imp
 000000e0: 6f72 7420 636f 6c6c 6563 7469 6f6e 730d  ort collections.
 000000f0: 0a69 6d70 6f72 7420 6d75 6c74 6970 726f  .import multipro
 00000100: 6365 7373 696e 6720 6173 206d 700d 0a69  cessing as mp..i
 00000110: 6d70 6f72 7420 7761 726e 696e 6773 0d0a  mport warnings..
 00000120: 6672 6f6d 2063 6f70 7920 696d 706f 7274  from copy import
-00000130: 2063 6f70 790d 0a66 726f 6d20 7465 7874   copy..from text
-00000140: 7772 6170 2069 6d70 6f72 7420 696e 6465  wrap import inde
-00000150: 6e74 0d0a 6672 6f6d 2074 7970 696e 6720  nt..from typing 
-00000160: 696d 706f 7274 2041 6e79 2c20 4c69 7374  import Any, List
-00000170: 2c20 4f70 7469 6f6e 616c 2c20 4f72 6465  , Optional, Orde
-00000180: 7265 6444 6963 742c 2053 6571 7565 6e63  redDict, Sequenc
-00000190: 652c 2054 7570 6c65 2c20 556e 696f 6e0d  e, Tuple, Union.
-000001a0: 0a0d 0a69 6d70 6f72 7420 746f 7263 680d  ...import torch.
-000001b0: 0a66 726f 6d20 7465 6e73 6f72 6469 6374  .from tensordict
-000001c0: 2e6e 6e20 696d 706f 7274 2064 6973 7061  .nn import dispa
-000001d0: 7463 680d 0a66 726f 6d20 7465 6e73 6f72  tch..from tensor
-000001e0: 6469 6374 2e74 656e 736f 7264 6963 7420  dict.tensordict 
-000001f0: 696d 706f 7274 2054 656e 736f 7244 6963  import TensorDic
-00000200: 742c 2054 656e 736f 7244 6963 7442 6173  t, TensorDictBas
-00000210: 650d 0a66 726f 6d20 7465 6e73 6f72 6469  e..from tensordi
-00000220: 6374 2e75 7469 6c73 2069 6d70 6f72 7420  ct.utils import 
-00000230: 6578 7061 6e64 5f61 735f 7269 6768 740d  expand_as_right.
-00000240: 0a66 726f 6d20 746f 7263 6820 696d 706f  .from torch impo
-00000250: 7274 206e 6e2c 2054 656e 736f 720d 0a66  rt nn, Tensor..f
-00000260: 726f 6d20 746f 7263 6872 6c2e 6461 7461  rom torchrl.data
-00000270: 2e74 656e 736f 725f 7370 6563 7320 696d  .tensor_specs im
-00000280: 706f 7274 2028 0d0a 2020 2020 4269 6e61  port (..    Bina
-00000290: 7279 4469 7363 7265 7465 5465 6e73 6f72  ryDiscreteTensor
-000002a0: 5370 6563 2c0d 0a20 2020 2042 6f75 6e64  Spec,..    Bound
-000002b0: 6564 5465 6e73 6f72 5370 6563 2c0d 0a20  edTensorSpec,.. 
-000002c0: 2020 2043 6f6d 706f 7369 7465 5370 6563     CompositeSpec
-000002d0: 2c0d 0a20 2020 2043 6f6e 7469 6e75 6f75  ,..    Continuou
-000002e0: 7342 6f78 2c0d 0a20 2020 2044 4556 4943  sBox,..    DEVIC
-000002f0: 455f 5459 5049 4e47 2c0d 0a20 2020 2044  E_TYPING,..    D
-00000300: 6973 6372 6574 6554 656e 736f 7253 7065  iscreteTensorSpe
-00000310: 632c 0d0a 2020 2020 4f6e 6548 6f74 4469  c,..    OneHotDi
-00000320: 7363 7265 7465 5465 6e73 6f72 5370 6563  screteTensorSpec
-00000330: 2c0d 0a20 2020 2054 656e 736f 7253 7065  ,..    TensorSpe
-00000340: 632c 0d0a 2020 2020 556e 626f 756e 6465  c,..    Unbounde
-00000350: 6443 6f6e 7469 6e75 6f75 7354 656e 736f  dContinuousTenso
-00000360: 7253 7065 632c 0d0a 2020 2020 556e 626f  rSpec,..    Unbo
-00000370: 756e 6465 6444 6973 6372 6574 6554 656e  undedDiscreteTen
-00000380: 736f 7253 7065 632c 0d0a 290d 0a66 726f  sorSpec,..)..fro
-00000390: 6d20 746f 7263 6872 6c2e 656e 7673 2e63  m torchrl.envs.c
-000003a0: 6f6d 6d6f 6e20 696d 706f 7274 2045 6e76  ommon import Env
-000003b0: 4261 7365 2c20 6d61 6b65 5f74 656e 736f  Base, make_tenso
-000003c0: 7264 6963 740d 0a66 726f 6d20 746f 7263  rdict..from torc
-000003d0: 6872 6c2e 656e 7673 2e74 7261 6e73 666f  hrl.envs.transfo
-000003e0: 726d 7320 696d 706f 7274 2066 756e 6374  rms import funct
-000003f0: 696f 6e61 6c20 6173 2046 0d0a 6672 6f6d  ional as F..from
-00000400: 2074 6f72 6368 726c 2e65 6e76 732e 7472   torchrl.envs.tr
-00000410: 616e 7366 6f72 6d73 2e75 7469 6c73 2069  ansforms.utils i
-00000420: 6d70 6f72 7420 6368 6563 6b5f 6669 6e69  mport check_fini
-00000430: 7465 0d0a 6672 6f6d 2074 6f72 6368 726c  te..from torchrl
-00000440: 2e65 6e76 732e 7574 696c 7320 696d 706f  .envs.utils impo
-00000450: 7274 205f 736f 7274 5f6b 6579 732c 2073  rt _sort_keys, s
-00000460: 7465 705f 6d64 700d 0a0d 0a74 7279 3a0d  tep_mdp....try:.
-00000470: 0a20 2020 2066 726f 6d20 746f 7263 6876  .    from torchv
-00000480: 6973 696f 6e2e 7472 616e 7366 6f72 6d73  ision.transforms
-00000490: 2e66 756e 6374 696f 6e61 6c20 696d 706f  .functional impo
-000004a0: 7274 2063 656e 7465 725f 6372 6f70 0d0a  rt center_crop..
-000004b0: 0d0a 2020 2020 7472 793a 0d0a 2020 2020  ..    try:..    
-000004c0: 2020 2020 6672 6f6d 2074 6f72 6368 7669      from torchvi
-000004d0: 7369 6f6e 2e74 7261 6e73 666f 726d 732e  sion.transforms.
-000004e0: 6675 6e63 7469 6f6e 616c 2069 6d70 6f72  functional impor
-000004f0: 7420 496e 7465 7270 6f6c 6174 696f 6e4d  t InterpolationM
-00000500: 6f64 652c 2072 6573 697a 650d 0a0d 0a20  ode, resize.... 
-00000510: 2020 2020 2020 2064 6566 2069 6e74 6572         def inter
-00000520: 706f 6c61 7469 6f6e 5f66 6e28 696e 7465  polation_fn(inte
-00000530: 7270 6f6c 6174 696f 6e29 3a20 2023 206e  rpolation):  # n
-00000540: 6f71 613a 2044 3130 330d 0a20 2020 2020  oqa: D103..     
-00000550: 2020 2020 2020 2072 6574 7572 6e20 496e         return In
-00000560: 7465 7270 6f6c 6174 696f 6e4d 6f64 6528  terpolationMode(
-00000570: 696e 7465 7270 6f6c 6174 696f 6e29 0d0a  interpolation)..
-00000580: 0d0a 2020 2020 6578 6365 7074 2049 6d70  ..    except Imp
-00000590: 6f72 7445 7272 6f72 3a0d 0a0d 0a20 2020  ortError:....   
-000005a0: 2020 2020 2064 6566 2069 6e74 6572 706f       def interpo
-000005b0: 6c61 7469 6f6e 5f66 6e28 696e 7465 7270  lation_fn(interp
-000005c0: 6f6c 6174 696f 6e29 3a20 2023 206e 6f71  olation):  # noq
-000005d0: 613a 2044 3130 330d 0a20 2020 2020 2020  a: D103..       
-000005e0: 2020 2020 2072 6574 7572 6e20 696e 7465       return inte
-000005f0: 7270 6f6c 6174 696f 6e0d 0a0d 0a20 2020  rpolation....   
-00000600: 2020 2020 2066 726f 6d20 746f 7263 6876       from torchv
-00000610: 6973 696f 6e2e 7472 616e 7366 6f72 6d73  ision.transforms
-00000620: 2e66 756e 6374 696f 6e61 6c5f 7465 6e73  .functional_tens
-00000630: 6f72 2069 6d70 6f72 7420 7265 7369 7a65  or import resize
-00000640: 0d0a 0d0a 2020 2020 5f68 6173 5f74 7620  ....    _has_tv 
-00000650: 3d20 5472 7565 0d0a 6578 6365 7074 2049  = True..except I
-00000660: 6d70 6f72 7445 7272 6f72 3a0d 0a20 2020  mportError:..   
-00000670: 205f 6861 735f 7476 203d 2046 616c 7365   _has_tv = False
-00000680: 0d0a 0d0a 494d 4147 455f 4b45 5953 203d  ....IMAGE_KEYS =
-00000690: 205b 2270 6978 656c 7322 5d0d 0a5f 4d41   ["pixels"].._MA
-000006a0: 585f 4e4f 4f50 535f 5452 4941 4c53 203d  X_NOOPS_TRIALS =
-000006b0: 2031 300d 0a0d 0a46 4f52 5741 5244 5f4e   10....FORWARD_N
-000006c0: 4f54 5f49 4d50 4c45 4d45 4e54 4544 203d  OT_IMPLEMENTED =
-000006d0: 2022 636c 6173 7320 7b7d 2063 616e 6e6f   "class {} canno
-000006e0: 7420 6265 2065 7865 6375 7465 6420 7769  t be executed wi
-000006f0: 7468 6f75 7420 6120 7061 7265 6e74 2220  thout a parent" 
-00000700: 2265 6e76 6972 6f6e 6d65 6e74 2e22 0d0a  "environment."..
-00000710: 0d0a 0d0a 6465 6620 5f61 7070 6c79 5f74  ....def _apply_t
-00000720: 6f5f 636f 6d70 6f73 6974 6528 6675 6e63  o_composite(func
-00000730: 7469 6f6e 293a 0d0a 2020 2020 6465 6620  tion):..    def 
-00000740: 6e65 775f 6675 6e28 7365 6c66 2c20 6f62  new_fun(self, ob
-00000750: 7365 7276 6174 696f 6e5f 7370 6563 293a  servation_spec):
-00000760: 0d0a 2020 2020 2020 2020 6966 2069 7369  ..        if isi
-00000770: 6e73 7461 6e63 6528 6f62 7365 7276 6174  nstance(observat
-00000780: 696f 6e5f 7370 6563 2c20 436f 6d70 6f73  ion_spec, Compos
-00000790: 6974 6553 7065 6329 3a0d 0a20 2020 2020  iteSpec):..     
-000007a0: 2020 2020 2020 2064 203d 206f 6273 6572         d = obser
-000007b0: 7661 7469 6f6e 5f73 7065 632e 5f73 7065  vation_spec._spe
-000007c0: 6373 0d0a 2020 2020 2020 2020 2020 2020  cs..            
-000007d0: 666f 7220 696e 5f6b 6579 2c20 6f75 745f  for in_key, out_
-000007e0: 6b65 7920 696e 207a 6970 2873 656c 662e  key in zip(self.
-000007f0: 696e 5f6b 6579 732c 2073 656c 662e 6f75  in_keys, self.ou
-00000800: 745f 6b65 7973 293a 0d0a 2020 2020 2020  t_keys):..      
-00000810: 2020 2020 2020 2020 2020 6966 2069 6e5f            if in_
-00000820: 6b65 7920 696e 206f 6273 6572 7661 7469  key in observati
-00000830: 6f6e 5f73 7065 632e 6b65 7973 2854 7275  on_spec.keys(Tru
-00000840: 652c 2054 7275 6529 3a0d 0a20 2020 2020  e, True):..     
-00000850: 2020 2020 2020 2020 2020 2020 2020 2064                 d
-00000860: 5b6f 7574 5f6b 6579 5d20 3d20 6675 6e63  [out_key] = func
-00000870: 7469 6f6e 2873 656c 662c 206f 6273 6572  tion(self, obser
-00000880: 7661 7469 6f6e 5f73 7065 635b 696e 5f6b  vation_spec[in_k
-00000890: 6579 5d2e 636c 6f6e 6528 2929 0d0a 2020  ey].clone())..  
-000008a0: 2020 2020 2020 2020 2020 7265 7475 726e            return
-000008b0: 2043 6f6d 706f 7369 7465 5370 6563 280d   CompositeSpec(.
-000008c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000008d0: 2064 2c20 7368 6170 653d 6f62 7365 7276   d, shape=observ
-000008e0: 6174 696f 6e5f 7370 6563 2e73 6861 7065  ation_spec.shape
-000008f0: 2c20 6465 7669 6365 3d6f 6273 6572 7661  , device=observa
-00000900: 7469 6f6e 5f73 7065 632e 6465 7669 6365  tion_spec.device
-00000910: 0d0a 2020 2020 2020 2020 2020 2020 290d  ..            ).
-00000920: 0a20 2020 2020 2020 2065 6c73 653a 0d0a  .        else:..
-00000930: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-00000940: 726e 2066 756e 6374 696f 6e28 7365 6c66  rn function(self
-00000950: 2c20 6f62 7365 7276 6174 696f 6e5f 7370  , observation_sp
-00000960: 6563 290d 0a0d 0a20 2020 2072 6574 7572  ec)....    retur
-00000970: 6e20 6e65 775f 6675 6e0d 0a0d 0a0d 0a64  n new_fun......d
-00000980: 6566 205f 6170 706c 795f 746f 5f63 6f6d  ef _apply_to_com
-00000990: 706f 7369 7465 5f69 6e76 2866 756e 6374  posite_inv(funct
-000009a0: 696f 6e29 3a0d 0a20 2020 2023 2043 6861  ion):..    # Cha
-000009b0: 6e67 6573 2074 6865 2069 6e70 7574 5f73  nges the input_s
-000009c0: 7065 6320 666f 6c6c 6f77 696e 6720 6120  pec following a 
-000009d0: 7472 616e 7366 6f72 6d20 6675 6e63 7469  transform functi
-000009e0: 6f6e 2e0d 0a20 2020 2023 2054 6865 2075  on...    # The u
-000009f0: 7361 6765 2069 733a 2069 6620 616e 2065  sage is: if an e
-00000a00: 6e76 2065 7870 6563 7473 2061 2063 6572  nv expects a cer
-00000a10: 7461 696e 2069 6e70 7574 2028 652e 672e  tain input (e.g.
-00000a20: 2061 2064 6f75 626c 6520 7465 6e73 6f72   a double tensor
-00000a30: 290d 0a20 2020 2023 2062 7574 2074 6865  )..    # but the
-00000a40: 2069 6e70 7574 2068 6173 2074 6f20 6265   input has to be
-00000a50: 2074 7261 6e73 666f 726d 6564 2028 652e   transformed (e.
-00000a60: 672e 2069 7420 6973 2066 6c6f 6174 292c  g. it is float),
-00000a70: 2074 6869 7320 6675 6e63 7469 6f6e 2077   this function w
-00000a80: 696c 6c0d 0a20 2020 2023 206d 6f64 6966  ill..    # modif
-00000a90: 7920 7468 6520 7370 6563 2074 6f20 6765  y the spec to ge
-00000aa0: 7420 6120 7370 6563 2074 6861 7420 6672  t a spec that fr
-00000ab0: 6f6d 2074 6865 206f 7574 7369 6465 206d  om the outside m
-00000ac0: 6174 6368 6573 2077 6861 7420 6973 2067  atches what is g
-00000ad0: 6976 656e 0d0a 2020 2020 2320 2869 6520  iven..    # (ie 
-00000ae0: 6120 666c 6f61 7429 2e0d 0a20 2020 2023  a float)...    #
-00000af0: 204e 6f77 2073 696e 6365 2045 6e76 4261   Now since EnvBa
-00000b00: 7365 2e73 7465 7020 6967 6e6f 7265 7320  se.step ignores 
-00000b10: 6e65 7720 696e 7075 7473 2028 6965 2074  new inputs (ie t
-00000b20: 6865 2072 6f6f 7420 6c65 7665 6c20 6f66  he root level of
-00000b30: 2074 6865 0d0a 2020 2020 2320 7465 6e73   the..    # tens
-00000b40: 6f72 2069 7320 6e6f 7420 7570 6461 7465  or is not update
-00000b50: 6429 2061 6e20 6f75 745f 6b65 7920 7468  d) an out_key th
-00000b60: 6174 2064 6f65 7320 6e6f 7420 6d61 7463  at does not matc
-00000b70: 6820 7468 6520 696e 5f6b 6579 2068 6173  h the in_key has
-00000b80: 0d0a 2020 2020 2320 6e6f 2065 6666 6563  ..    # no effec
-00000b90: 7420 6f6e 2074 6865 2073 7065 632e 0d0a  t on the spec...
-00000ba0: 2020 2020 6465 6620 6e65 775f 6675 6e28      def new_fun(
-00000bb0: 7365 6c66 2c20 696e 7075 745f 7370 6563  self, input_spec
-00000bc0: 293a 0d0a 2020 2020 2020 2020 6966 2069  ):..        if i
-00000bd0: 7369 6e73 7461 6e63 6528 696e 7075 745f  sinstance(input_
-00000be0: 7370 6563 2c20 436f 6d70 6f73 6974 6553  spec, CompositeS
-00000bf0: 7065 6329 3a0d 0a20 2020 2020 2020 2020  pec):..         
-00000c00: 2020 2064 203d 2069 6e70 7574 5f73 7065     d = input_spe
-00000c10: 632e 5f73 7065 6373 0d0a 2020 2020 2020  c._specs..      
-00000c20: 2020 2020 2020 666f 7220 696e 5f6b 6579        for in_key
-00000c30: 2c20 6f75 745f 6b65 7920 696e 207a 6970  , out_key in zip
-00000c40: 2873 656c 662e 696e 5f6b 6579 735f 696e  (self.in_keys_in
-00000c50: 762c 2073 656c 662e 6f75 745f 6b65 7973  v, self.out_keys
-00000c60: 5f69 6e76 293a 0d0a 2020 2020 2020 2020  _inv):..        
-00000c70: 2020 2020 2020 2020 6966 2069 6e5f 6b65          if in_ke
-00000c80: 7920 696e 2069 6e70 7574 5f73 7065 632e  y in input_spec.
-00000c90: 6b65 7973 2854 7275 652c 2054 7275 6529  keys(True, True)
-00000ca0: 2061 6e64 2069 6e5f 6b65 7920 3d3d 206f   and in_key == o
-00000cb0: 7574 5f6b 6579 3a0d 0a20 2020 2020 2020  ut_key:..       
-00000cc0: 2020 2020 2020 2020 2020 2020 2064 5b6f               d[o
-00000cd0: 7574 5f6b 6579 5d20 3d20 6675 6e63 7469  ut_key] = functi
-00000ce0: 6f6e 2873 656c 662c 2069 6e70 7574 5f73  on(self, input_s
-00000cf0: 7065 635b 696e 5f6b 6579 5d2e 636c 6f6e  pec[in_key].clon
-00000d00: 6528 2929 0d0a 2020 2020 2020 2020 2020  e())..          
-00000d10: 2020 7265 7475 726e 2043 6f6d 706f 7369    return Composi
-00000d20: 7465 5370 6563 2864 2c20 7368 6170 653d  teSpec(d, shape=
-00000d30: 696e 7075 745f 7370 6563 2e73 6861 7065  input_spec.shape
-00000d40: 2c20 6465 7669 6365 3d69 6e70 7574 5f73  , device=input_s
-00000d50: 7065 632e 6465 7669 6365 290d 0a20 2020  pec.device)..   
-00000d60: 2020 2020 2065 6c73 653a 0d0a 2020 2020       else:..    
-00000d70: 2020 2020 2020 2020 7265 7475 726e 2066          return f
-00000d80: 756e 6374 696f 6e28 7365 6c66 2c20 696e  unction(self, in
-00000d90: 7075 745f 7370 6563 290d 0a0d 0a20 2020  put_spec)....   
-00000da0: 2072 6574 7572 6e20 6e65 775f 6675 6e0d   return new_fun.
-00000db0: 0a0d 0a0d 0a63 6c61 7373 2054 7261 6e73  .....class Trans
-00000dc0: 666f 726d 286e 6e2e 4d6f 6475 6c65 293a  form(nn.Module):
-00000dd0: 0d0a 2020 2020 2222 2245 6e76 6972 6f6e  ..    """Environ
-00000de0: 6d65 6e74 2074 7261 6e73 666f 726d 2070  ment transform p
-00000df0: 6172 656e 7420 636c 6173 732e 0d0a 0d0a  arent class.....
-00000e00: 2020 2020 496e 2070 7269 6e63 6970 6c65      In principle
-00000e10: 2c20 6120 7472 616e 7366 6f72 6d20 7265  , a transform re
-00000e20: 6365 6976 6573 2061 2074 656e 736f 7264  ceives a tensord
-00000e30: 6963 7420 6173 2069 6e70 7574 2061 6e64  ict as input and
-00000e40: 2072 6574 7572 6e73 2028 0d0a 2020 2020   returns (..    
-00000e50: 7468 6520 7361 6d65 206f 7220 616e 6f74  the same or anot
-00000e60: 6865 7229 2074 656e 736f 7264 6963 7420  her) tensordict 
-00000e70: 6173 206f 7574 7075 742c 2077 6865 7265  as output, where
-00000e80: 2061 2073 6572 6965 7320 6f66 2076 616c   a series of val
-00000e90: 7565 7320 6861 7665 0d0a 2020 2020 6265  ues have..    be
-00000ea0: 656e 206d 6f64 6966 6965 6420 6f72 2063  en modified or c
-00000eb0: 7265 6174 6564 2077 6974 6820 6120 6e65  reated with a ne
-00000ec0: 7720 6b65 792e 2057 6865 6e20 696e 7374  w key. When inst
-00000ed0: 616e 7469 6174 696e 6720 6120 6e65 770d  antiating a new.
-00000ee0: 0a20 2020 2074 7261 6e73 666f 726d 2c20  .    transform, 
-00000ef0: 7468 6520 6b65 7973 2074 6861 7420 6172  the keys that ar
-00000f00: 6520 746f 2062 6520 7265 6164 2066 726f  e to be read fro
-00000f10: 6d20 6172 6520 7061 7373 6564 2074 6f20  m are passed to 
-00000f20: 7468 650d 0a20 2020 2063 6f6e 7374 7275  the..    constru
-00000f30: 6374 6f72 2076 6961 2074 6865 203a 6f62  ctor via the :ob
-00000f40: 6a3a 606b 6579 7360 2061 7267 756d 656e  j:`keys` argumen
-00000f50: 742e 0d0a 0d0a 2020 2020 5472 616e 7366  t.....    Transf
-00000f60: 6f72 6d73 2061 7265 2074 6f20 6265 2063  orms are to be c
-00000f70: 6f6d 6269 6e65 6420 7769 7468 2074 6865  ombined with the
-00000f80: 6972 2074 6172 6765 7420 656e 7669 726f  ir target enviro
-00000f90: 6e6d 656e 7473 2077 6974 6820 7468 650d  nments with the.
-00000fa0: 0a20 2020 2054 7261 6e73 666f 726d 6564  .    Transformed
-00000fb0: 456e 7620 636c 6173 732c 2077 6869 6368  Env class, which
-00000fc0: 2074 616b 6573 2061 7320 6172 6775 6d65   takes as argume
-00000fd0: 6e74 7320 616e 203a 6f62 6a3a 6045 6e76  nts an :obj:`Env
-00000fe0: 4261 7365 6020 696e 7374 616e 6365 0d0a  Base` instance..
-00000ff0: 2020 2020 616e 6420 6120 7472 616e 7366      and a transf
-00001000: 6f72 6d2e 2049 6620 6d75 6c74 6970 6c65  orm. If multiple
-00001010: 2074 7261 6e73 666f 726d 7320 6172 6520   transforms are 
-00001020: 746f 2062 6520 7573 6564 2c20 7468 6579  to be used, they
-00001030: 2063 616e 2062 650d 0a20 2020 2063 6f6e   can be..    con
-00001040: 6361 7465 6e61 7465 6420 7573 696e 6720  catenated using 
-00001050: 7468 6520 3a6f 626a 3a60 436f 6d70 6f73  the :obj:`Compos
-00001060: 6560 2063 6c61 7373 2e0d 0a20 2020 2041  e` class...    A
-00001070: 2074 7261 6e73 666f 726d 2063 616e 2062   transform can b
-00001080: 6520 7374 6174 656c 6573 7320 6f72 2073  e stateless or s
-00001090: 7461 7465 6675 6c20 2865 2e67 2e20 4361  tateful (e.g. Ca
-000010a0: 7454 7261 6e73 666f 726d 292e 2042 6563  tTransform). Bec
-000010b0: 6175 7365 206f 660d 0a20 2020 2074 6869  ause of..    thi
-000010c0: 732c 2054 7261 6e73 666f 726d 7320 7375  s, Transforms su
-000010d0: 7070 6f72 7420 7468 6520 3a6f 626a 3a60  pport the :obj:`
-000010e0: 7265 7365 7460 206f 7065 7261 7469 6f6e  reset` operation
-000010f0: 2c20 7768 6963 6820 7368 6f75 6c64 2072  , which should r
-00001100: 6573 6574 2074 6865 0d0a 2020 2020 7472  eset the..    tr
-00001110: 616e 7366 6f72 6d20 746f 2069 7473 2069  ansform to its i
-00001120: 6e69 7469 616c 2073 7461 7465 2028 7375  nitial state (su
-00001130: 6368 2074 6861 7420 7375 6363 6573 7369  ch that successi
-00001140: 7665 2074 7261 6a65 6374 6f72 6965 7320  ve trajectories 
-00001150: 6172 6520 6b65 7074 0d0a 2020 2020 696e  are kept..    in
-00001160: 6465 7065 6e64 656e 7429 2e0d 0a0d 0a20  dependent)..... 
-00001170: 2020 204e 6f74 6162 6c79 2c20 3a6f 626a     Notably, :obj
-00001180: 3a60 5472 616e 7366 6f72 6d60 2073 7562  :`Transform` sub
-00001190: 636c 6173 7365 7320 7461 6b65 2063 6172  classes take car
-000011a0: 6520 6f66 2074 7261 6e73 666f 726d 696e  e of transformin
-000011b0: 6720 7468 6520 6166 6665 6374 6564 0d0a  g the affected..
-000011c0: 2020 2020 7370 6563 7320 6672 6f6d 2061      specs from a
-000011d0: 6e20 656e 7669 726f 6e6d 656e 743a 2077  n environment: w
-000011e0: 6865 6e20 7175 6572 7969 6e67 0d0a 2020  hen querying..  
-000011f0: 2020 6074 7261 6e73 666f 726d 6564 5f65    `transformed_e
-00001200: 6e76 2e6f 6273 6572 7661 7469 6f6e 5f73  nv.observation_s
-00001210: 7065 6360 2c20 7468 6520 7265 7375 6c74  pec`, the result
-00001220: 696e 6720 6f62 6a65 6374 7320 7769 6c6c  ing objects will
-00001230: 2064 6573 6372 6962 650d 0a20 2020 2074   describe..    t
-00001240: 6865 2073 7065 6373 206f 6620 7468 6520  he specs of the 
-00001250: 7472 616e 7366 6f72 6d65 645f 696e 2074  transformed_in t
-00001260: 656e 736f 7273 2e0d 0a0d 0a20 2020 2022  ensors.....    "
-00001270: 2222 0d0a 0d0a 2020 2020 696e 7665 7274  ""....    invert
-00001280: 6962 6c65 203d 2046 616c 7365 0d0a 0d0a  ible = False....
-00001290: 2020 2020 6465 6620 5f5f 696e 6974 5f5f      def __init__
-000012a0: 280d 0a20 2020 2020 2020 2073 656c 662c  (..        self,
-000012b0: 0d0a 2020 2020 2020 2020 696e 5f6b 6579  ..        in_key
-000012c0: 733a 2053 6571 7565 6e63 655b 7374 725d  s: Sequence[str]
-000012d0: 2c0d 0a20 2020 2020 2020 206f 7574 5f6b  ,..        out_k
-000012e0: 6579 733a 204f 7074 696f 6e61 6c5b 5365  eys: Optional[Se
-000012f0: 7175 656e 6365 5b73 7472 5d5d 203d 204e  quence[str]] = N
-00001300: 6f6e 652c 0d0a 2020 2020 2020 2020 696e  one,..        in
-00001310: 5f6b 6579 735f 696e 763a 204f 7074 696f  _keys_inv: Optio
-00001320: 6e61 6c5b 5365 7175 656e 6365 5b73 7472  nal[Sequence[str
-00001330: 5d5d 203d 204e 6f6e 652c 0d0a 2020 2020  ]] = None,..    
-00001340: 2020 2020 6f75 745f 6b65 7973 5f69 6e76      out_keys_inv
-00001350: 3a20 4f70 7469 6f6e 616c 5b53 6571 7565  : Optional[Seque
-00001360: 6e63 655b 7374 725d 5d20 3d20 4e6f 6e65  nce[str]] = None
-00001370: 2c0d 0a20 2020 2029 3a0d 0a20 2020 2020  ,..    ):..     
-00001380: 2020 2073 7570 6572 2829 2e5f 5f69 6e69     super().__ini
-00001390: 745f 5f28 290d 0a20 2020 2020 2020 2069  t__()..        i
-000013a0: 6620 6973 696e 7374 616e 6365 2869 6e5f  f isinstance(in_
-000013b0: 6b65 7973 2c20 7374 7229 3a0d 0a20 2020  keys, str):..   
-000013c0: 2020 2020 2020 2020 2069 6e5f 6b65 7973           in_keys
-000013d0: 203d 205b 696e 5f6b 6579 735d 0d0a 0d0a   = [in_keys]....
-000013e0: 2020 2020 2020 2020 7365 6c66 2e69 6e5f          self.in_
-000013f0: 6b65 7973 203d 2069 6e5f 6b65 7973 0d0a  keys = in_keys..
-00001400: 2020 2020 2020 2020 6966 206f 7574 5f6b          if out_k
-00001410: 6579 7320 6973 204e 6f6e 653a 0d0a 2020  eys is None:..  
-00001420: 2020 2020 2020 2020 2020 6f75 745f 6b65            out_ke
-00001430: 7973 203d 2063 6f70 7928 7365 6c66 2e69  ys = copy(self.i
-00001440: 6e5f 6b65 7973 290d 0a20 2020 2020 2020  n_keys)..       
-00001450: 2073 656c 662e 6f75 745f 6b65 7973 203d   self.out_keys =
-00001460: 206f 7574 5f6b 6579 730d 0a20 2020 2020   out_keys..     
-00001470: 2020 2069 6620 696e 5f6b 6579 735f 696e     if in_keys_in
-00001480: 7620 6973 204e 6f6e 653a 0d0a 2020 2020  v is None:..    
-00001490: 2020 2020 2020 2020 696e 5f6b 6579 735f          in_keys_
-000014a0: 696e 7620 3d20 5b5d 0d0a 2020 2020 2020  inv = []..      
-000014b0: 2020 7365 6c66 2e69 6e5f 6b65 7973 5f69    self.in_keys_i
-000014c0: 6e76 203d 2069 6e5f 6b65 7973 5f69 6e76  nv = in_keys_inv
-000014d0: 0d0a 2020 2020 2020 2020 6966 206f 7574  ..        if out
-000014e0: 5f6b 6579 735f 696e 7620 6973 204e 6f6e  _keys_inv is Non
-000014f0: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
-00001500: 6f75 745f 6b65 7973 5f69 6e76 203d 2063  out_keys_inv = c
-00001510: 6f70 7928 7365 6c66 2e69 6e5f 6b65 7973  opy(self.in_keys
-00001520: 5f69 6e76 290d 0a20 2020 2020 2020 2073  _inv)..        s
-00001530: 656c 662e 6f75 745f 6b65 7973 5f69 6e76  elf.out_keys_inv
-00001540: 203d 206f 7574 5f6b 6579 735f 696e 760d   = out_keys_inv.
-00001550: 0a20 2020 2020 2020 2073 656c 662e 5f5f  .        self.__
-00001560: 6469 6374 5f5f 5b22 5f63 6f6e 7461 696e  dict__["_contain
-00001570: 6572 225d 203d 204e 6f6e 650d 0a20 2020  er"] = None..   
-00001580: 2020 2020 2073 656c 662e 5f5f 6469 6374       self.__dict
-00001590: 5f5f 5b22 5f70 6172 656e 7422 5d20 3d20  __["_parent"] = 
-000015a0: 4e6f 6e65 0d0a 0d0a 2020 2020 6465 6620  None....    def 
-000015b0: 7265 7365 7428 7365 6c66 2c20 7465 6e73  reset(self, tens
-000015c0: 6f72 6469 6374 3a20 5465 6e73 6f72 4469  ordict: TensorDi
-000015d0: 6374 4261 7365 2920 2d3e 2054 656e 736f  ctBase) -> Tenso
-000015e0: 7244 6963 7442 6173 653a 0d0a 2020 2020  rDictBase:..    
-000015f0: 2020 2020 2222 2252 6573 6574 7320 6120      """Resets a 
-00001600: 7472 616e 666f 726d 2069 6620 6974 2069  tranform if it i
-00001610: 7320 7374 6174 6566 756c 2e22 2222 0d0a  s stateful."""..
-00001620: 2020 2020 2020 2020 7265 7475 726e 2074          return t
-00001630: 656e 736f 7264 6963 740d 0a0d 0a20 2020  ensordict....   
-00001640: 2064 6566 2069 6e69 7428 7365 6c66 2c20   def init(self, 
-00001650: 7465 6e73 6f72 6469 6374 2920 2d3e 204e  tensordict) -> N
-00001660: 6f6e 653a 0d0a 2020 2020 2020 2020 7061  one:..        pa
-00001670: 7373 0d0a 0d0a 2020 2020 6465 6620 5f61  ss....    def _a
-00001680: 7070 6c79 5f74 7261 6e73 666f 726d 2873  pply_transform(s
-00001690: 656c 662c 206f 6273 3a20 746f 7263 682e  elf, obs: torch.
-000016a0: 5465 6e73 6f72 2920 2d3e 204e 6f6e 653a  Tensor) -> None:
-000016b0: 0d0a 2020 2020 2020 2020 2222 2241 7070  ..        """App
-000016c0: 6c69 6573 2074 6865 2074 7261 6e73 666f  lies the transfo
-000016d0: 726d 2074 6f20 6120 7465 6e73 6f72 2e0d  rm to a tensor..
-000016e0: 0a0d 0a20 2020 2020 2020 2054 6869 7320  ...        This 
-000016f0: 6f70 6572 6174 696f 6e20 6361 6e20 6265  operation can be
-00001700: 2063 616c 6c65 6420 6d75 6c74 6970 6c65   called multiple
-00001710: 2074 696d 6573 2028 6966 206d 756c 7469   times (if multi
-00001720: 706c 6573 206b 6579 7320 6f66 2074 6865  ples keys of the
-00001730: 0d0a 2020 2020 2020 2020 7465 6e73 6f72  ..        tensor
-00001740: 6469 6374 206d 6174 6368 2074 6865 206b  dict match the k
-00001750: 6579 7320 6f66 2074 6865 2074 7261 6e73  eys of the trans
-00001760: 666f 726d 292e 0d0a 0d0a 2020 2020 2020  form).....      
-00001770: 2020 2222 220d 0a20 2020 2020 2020 2072    """..        r
-00001780: 6169 7365 204e 6f74 496d 706c 656d 656e  aise NotImplemen
-00001790: 7465 6445 7272 6f72 280d 0a20 2020 2020  tedError(..     
-000017a0: 2020 2020 2020 2066 227b 7365 6c66 2e5f         f"{self._
-000017b0: 5f63 6c61 7373 5f5f 2e5f 5f6e 616d 655f  _class__.__name_
-000017c0: 5f7d 5f61 7070 6c79 5f74 7261 6e73 666f  _}_apply_transfo
-000017d0: 726d 2069 7320 6e6f 7420 636f 6465 642e  rm is not coded.
-000017e0: 2049 6620 7468 6520 7472 616e 7366 6f72   If the transfor
-000017f0: 6d20 6973 2063 6f64 6564 2069 6e20 220d  m is coded in ".
-00001800: 0a20 2020 2020 2020 2020 2020 2022 7472  .            "tr
-00001810: 616e 7366 6f72 6d2e 5f63 616c 6c2c 206d  ansform._call, m
-00001820: 616b 6520 7375 7265 2074 6861 7420 7468  ake sure that th
-00001830: 6973 206d 6574 686f 6420 6973 2063 616c  is method is cal
-00001840: 6c65 6420 696e 7374 6561 6420 6f66 220d  led instead of".
-00001850: 0a20 2020 2020 2020 2020 2020 2022 7472  .            "tr
-00001860: 616e 7366 6f72 6d2e 666f 7277 6172 642c  ansform.forward,
-00001870: 2077 6869 6368 2069 7320 7265 7365 7276   which is reserv
-00001880: 6564 2066 6f72 2075 7361 6765 2069 6e73  ed for usage ins
-00001890: 6964 6520 6e6e 2e4d 6f64 756c 6573 220d  ide nn.Modules".
-000018a0: 0a20 2020 2020 2020 2020 2020 2022 6f72  .            "or
-000018b0: 2061 7070 656e 6465 6420 746f 2061 2072   appended to a r
-000018c0: 6570 6c61 7920 6275 6666 6572 2e22 0d0a  eplay buffer."..
-000018d0: 2020 2020 2020 2020 290d 0a0d 0a20 2020          )....   
-000018e0: 2064 6566 205f 6361 6c6c 2873 656c 662c   def _call(self,
-000018f0: 2074 656e 736f 7264 6963 743a 2054 656e   tensordict: Ten
-00001900: 736f 7244 6963 7442 6173 6529 202d 3e20  sorDictBase) -> 
-00001910: 5465 6e73 6f72 4469 6374 4261 7365 3a0d  TensorDictBase:.
-00001920: 0a20 2020 2020 2020 2022 2222 5265 6164  .        """Read
-00001930: 7320 7468 6520 696e 7075 7420 7465 6e73  s the input tens
-00001940: 6f72 6469 6374 2c20 616e 6420 666f 7220  ordict, and for 
-00001950: 7468 6520 7365 6c65 6374 6564 206b 6579  the selected key
-00001960: 732c 2061 7070 6c69 6573 2074 6865 2074  s, applies the t
-00001970: 7261 6e73 666f 726d 2e0d 0a0d 0a20 2020  ransform.....   
-00001980: 2020 2020 2046 6f72 2061 6e79 206f 7065       For any ope
-00001990: 7261 7469 6f6e 2074 6861 7420 7265 6c61  ration that rela
-000019a0: 7465 7320 6578 636c 7573 6976 656c 7920  tes exclusively 
-000019b0: 746f 2074 6865 2070 6172 656e 7420 656e  to the parent en
-000019c0: 7620 2865 2e67 2e20 4672 616d 6553 6b69  v (e.g. FrameSki
-000019d0: 7029 2c0d 0a20 2020 2020 2020 206d 6f64  p),..        mod
-000019e0: 6966 7920 7468 6520 5f73 7465 7020 6d65  ify the _step me
-000019f0: 7468 6f64 2069 6e73 7465 6164 2e20 3a6d  thod instead. :m
-00001a00: 6574 683a 607e 2e5f 6361 6c6c 6020 7368  eth:`~._call` sh
-00001a10: 6f75 6c64 206f 6e6c 7920 6265 206f 7665  ould only be ove
-00001a20: 7277 7269 7474 656e 0d0a 2020 2020 2020  rwritten..      
-00001a30: 2020 6966 2061 206d 6f64 6966 6963 6174    if a modificat
-00001a40: 696f 6e20 6f66 2074 6865 2069 6e70 7574  ion of the input
-00001a50: 2074 656e 736f 7264 6963 7420 6973 206e   tensordict is n
-00001a60: 6565 6465 642e 0d0a 0d0a 2020 2020 2020  eeded.....      
-00001a70: 2020 3a6d 6574 683a 607e 2e5f 6361 6c6c    :meth:`~._call
-00001a80: 6020 7769 6c6c 2062 6520 6361 6c6c 6564  ` will be called
-00001a90: 2062 7920 3a6d 6574 683a 6054 7261 6e73   by :meth:`Trans
-00001aa0: 666f 726d 6564 456e 762e 7374 6570 6020  formedEnv.step` 
-00001ab0: 616e 640d 0a20 2020 2020 2020 203a 6d65  and..        :me
-00001ac0: 7468 3a60 5472 616e 7366 6f72 6d65 6445  th:`TransformedE
-00001ad0: 6e76 2e72 6573 6574 602e 0d0a 0d0a 2020  nv.reset`.....  
-00001ae0: 2020 2020 2020 2222 220d 0a20 2020 2020        """..     
-00001af0: 2020 2066 6f72 2069 6e5f 6b65 792c 206f     for in_key, o
-00001b00: 7574 5f6b 6579 2069 6e20 7a69 7028 7365  ut_key in zip(se
-00001b10: 6c66 2e69 6e5f 6b65 7973 2c20 7365 6c66  lf.in_keys, self
-00001b20: 2e6f 7574 5f6b 6579 7329 3a0d 0a20 2020  .out_keys):..   
-00001b30: 2020 2020 2020 2020 2069 735f 7475 706c           is_tupl
-00001b40: 6520 3d20 6973 696e 7374 616e 6365 2869  e = isinstance(i
-00001b50: 6e5f 6b65 792c 2074 7570 6c65 290d 0a20  n_key, tuple).. 
-00001b60: 2020 2020 2020 2020 2020 2069 6620 696e             if in
-00001b70: 5f6b 6579 2069 6e20 7465 6e73 6f72 6469  _key in tensordi
-00001b80: 6374 2e6b 6579 7328 696e 636c 7564 655f  ct.keys(include_
-00001b90: 6e65 7374 6564 3d69 735f 7475 706c 6529  nested=is_tuple)
-00001ba0: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
-00001bb0: 2020 206f 6273 6572 7661 7469 6f6e 203d     observation =
-00001bc0: 2073 656c 662e 5f61 7070 6c79 5f74 7261   self._apply_tra
-00001bd0: 6e73 666f 726d 2874 656e 736f 7264 6963  nsform(tensordic
-00001be0: 742e 6765 7428 696e 5f6b 6579 2929 0d0a  t.get(in_key))..
-00001bf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001c00: 7465 6e73 6f72 6469 6374 2e73 6574 280d  tensordict.set(.
-00001c10: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00001c20: 2020 2020 206f 7574 5f6b 6579 2c0d 0a20       out_key,.. 
-00001c30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001c40: 2020 206f 6273 6572 7661 7469 6f6e 2c0d     observation,.
-00001c50: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00001c60: 2029 0d0a 2020 2020 2020 2020 7265 7475   )..        retu
-00001c70: 726e 2074 656e 736f 7264 6963 740d 0a0d  rn tensordict...
-00001c80: 0a20 2020 2040 6469 7370 6174 6368 2873  .    @dispatch(s
-00001c90: 6f75 7263 653d 2269 6e5f 6b65 7973 222c  ource="in_keys",
-00001ca0: 2064 6573 743d 226f 7574 5f6b 6579 7322   dest="out_keys"
-00001cb0: 290d 0a20 2020 2064 6566 2066 6f72 7761  )..    def forwa
-00001cc0: 7264 2873 656c 662c 2074 656e 736f 7264  rd(self, tensord
-00001cd0: 6963 743a 2054 656e 736f 7244 6963 7442  ict: TensorDictB
-00001ce0: 6173 6529 202d 3e20 5465 6e73 6f72 4469  ase) -> TensorDi
-00001cf0: 6374 4261 7365 3a0d 0a20 2020 2020 2020  ctBase:..       
-00001d00: 2022 2222 5265 6164 7320 7468 6520 696e   """Reads the in
-00001d10: 7075 7420 7465 6e73 6f72 6469 6374 2c20  put tensordict, 
-00001d20: 616e 6420 666f 7220 7468 6520 7365 6c65  and for the sele
-00001d30: 6374 6564 206b 6579 732c 2061 7070 6c69  cted keys, appli
-00001d40: 6573 2074 6865 2074 7261 6e73 666f 726d  es the transform
-00001d50: 2e22 2222 0d0a 2020 2020 2020 2020 666f  ."""..        fo
-00001d60: 7220 696e 5f6b 6579 2c20 6f75 745f 6b65  r in_key, out_ke
-00001d70: 7920 696e 207a 6970 2873 656c 662e 696e  y in zip(self.in
-00001d80: 5f6b 6579 732c 2073 656c 662e 6f75 745f  _keys, self.out_
-00001d90: 6b65 7973 293a 0d0a 2020 2020 2020 2020  keys):..        
-00001da0: 2020 2020 6966 2069 6e5f 6b65 7920 696e      if in_key in
-00001db0: 2074 656e 736f 7264 6963 742e 6b65 7973   tensordict.keys
-00001dc0: 2869 7369 6e73 7461 6e63 6528 696e 5f6b  (isinstance(in_k
-00001dd0: 6579 2c20 7475 706c 6529 293a 0d0a 2020  ey, tuple)):..  
-00001de0: 2020 2020 2020 2020 2020 2020 2020 6f62                ob
-00001df0: 7365 7276 6174 696f 6e20 3d20 7365 6c66  servation = self
-00001e00: 2e5f 6170 706c 795f 7472 616e 7366 6f72  ._apply_transfor
-00001e10: 6d28 7465 6e73 6f72 6469 6374 2e67 6574  m(tensordict.get
-00001e20: 2869 6e5f 6b65 7929 290d 0a20 2020 2020  (in_key))..     
-00001e30: 2020 2020 2020 2020 2020 2074 656e 736f             tenso
-00001e40: 7264 6963 742e 7365 7428 0d0a 2020 2020  rdict.set(..    
-00001e50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00001e60: 6f75 745f 6b65 792c 0d0a 2020 2020 2020  out_key,..      
-00001e70: 2020 2020 2020 2020 2020 2020 2020 6f62                ob
-00001e80: 7365 7276 6174 696f 6e2c 0d0a 2020 2020  servation,..    
-00001e90: 2020 2020 2020 2020 2020 2020 290d 0a20              ).. 
-00001ea0: 2020 2020 2020 2072 6574 7572 6e20 7465         return te
-00001eb0: 6e73 6f72 6469 6374 0d0a 0d0a 2020 2020  nsordict....    
-00001ec0: 6465 6620 5f73 7465 7028 7365 6c66 2c20  def _step(self, 
-00001ed0: 7465 6e73 6f72 6469 6374 3a20 5465 6e73  tensordict: Tens
-00001ee0: 6f72 4469 6374 4261 7365 2920 2d3e 2054  orDictBase) -> T
-00001ef0: 656e 736f 7244 6963 7442 6173 653a 0d0a  ensorDictBase:..
-00001f00: 2020 2020 2020 2020 2222 2254 6865 2070          """The p
-00001f10: 6172 656e 7420 6d65 7468 6f64 206f 6620  arent method of 
-00001f20: 6120 7472 616e 7366 6f72 6d20 6475 7269  a transform duri
-00001f30: 6e67 2074 6865 2060 6065 6e76 2e73 7465  ng the ``env.ste
-00001f40: 7060 6020 6578 6563 7574 696f 6e2e 0d0a  p`` execution...
-00001f50: 0d0a 2020 2020 2020 2020 5468 6973 206d  ..        This m
-00001f60: 6574 686f 6420 7368 6f75 6c64 2062 6520  ethod should be 
-00001f70: 6f76 6572 7772 6974 7465 6e20 7768 656e  overwritten when
-00001f80: 6576 6572 2074 6865 203a 6d65 7468 3a60  ever the :meth:`
-00001f90: 7e2e 5f73 7465 7060 206e 6565 6473 2074  ~._step` needs t
-00001fa0: 6f20 6265 0d0a 2020 2020 2020 2020 6164  o be..        ad
-00001fb0: 6170 7465 642e 2055 6e6c 696b 6520 3a6d  apted. Unlike :m
-00001fc0: 6574 683a 607e 2e5f 6361 6c6c 602c 2069  eth:`~._call`, i
-00001fd0: 7420 6973 2061 7373 756d 6564 2074 6861  t is assumed tha
-00001fe0: 7420 3a6d 6574 683a 607e 2e5f 7374 6570  t :meth:`~._step
-00001ff0: 600d 0a20 2020 2020 2020 2077 696c 6c20  `..        will 
-00002000: 6578 6563 7574 6520 736f 6d65 206f 7065  execute some ope
-00002010: 7261 7469 6f6e 2077 6974 6820 7468 6520  ration with the 
-00002020: 7061 7265 6e74 2065 6e76 206f 7220 7468  parent env or th
-00002030: 6174 2069 7420 7265 7175 6972 6573 0d0a  at it requires..
-00002040: 2020 2020 2020 2020 6163 6365 7373 2074          access t
-00002050: 6f20 7468 6520 636f 6e74 656e 7420 6f66  o the content of
-00002060: 2074 6865 2074 656e 736f 7264 6963 7420   the tensordict 
-00002070: 6174 2074 696d 6520 6060 7460 6020 616e  at time ``t`` an
-00002080: 6420 6e6f 7420 6f6e 6c79 0d0a 2020 2020  d not only..    
-00002090: 2020 2020 6060 742b 3160 6020 2874 6865      ``t+1`` (the
-000020a0: 2060 6022 6e65 7874 2260 6020 656e 7472   ``"next"`` entr
-000020b0: 7920 696e 2074 6865 2069 6e70 7574 2074  y in the input t
-000020c0: 656e 736f 7264 6963 7429 2e0d 0a0d 0a20  ensordict)..... 
-000020d0: 2020 2020 2020 203a 6d65 7468 3a60 7e2e         :meth:`~.
-000020e0: 5f73 7465 7060 2077 696c 6c20 6f6e 6c79  _step` will only
-000020f0: 2062 6520 6361 6c6c 6564 2062 7920 3a6d   be called by :m
-00002100: 6574 683a 6054 7261 6e73 666f 726d 6564  eth:`Transformed
-00002110: 456e 762e 7374 6570 6020 616e 640d 0a20  Env.step` and.. 
-00002120: 2020 2020 2020 206e 6f74 2062 7920 3a6d         not by :m
-00002130: 6574 683a 6054 7261 6e73 666f 726d 6564  eth:`Transformed
-00002140: 456e 762e 7265 7365 7460 2e0d 0a0d 0a20  Env.reset`..... 
-00002150: 2020 2020 2020 2022 2222 0d0a 2020 2020         """..    
-00002160: 2020 2020 6e65 7874 5f74 656e 736f 7264      next_tensord
-00002170: 6963 7420 3d20 7465 6e73 6f72 6469 6374  ict = tensordict
-00002180: 2e67 6574 2822 6e65 7874 2229 0d0a 2020  .get("next")..  
-00002190: 2020 2020 2020 6e65 7874 5f74 656e 736f        next_tenso
-000021a0: 7264 6963 7420 3d20 7365 6c66 2e5f 6361  rdict = self._ca
-000021b0: 6c6c 286e 6578 745f 7465 6e73 6f72 6469  ll(next_tensordi
-000021c0: 6374 290d 0a20 2020 2020 2020 2074 656e  ct)..        ten
-000021d0: 736f 7264 6963 742e 7365 7428 226e 6578  sordict.set("nex
-000021e0: 7422 2c20 6e65 7874 5f74 656e 736f 7264  t", next_tensord
-000021f0: 6963 7429 0d0a 2020 2020 2020 2020 7265  ict)..        re
-00002200: 7475 726e 2074 656e 736f 7264 6963 740d  turn tensordict.
-00002210: 0a0d 0a20 2020 2064 6566 205f 696e 765f  ...    def _inv_
-00002220: 6170 706c 795f 7472 616e 7366 6f72 6d28  apply_transform(
-00002230: 7365 6c66 2c20 6f62 733a 2074 6f72 6368  self, obs: torch
-00002240: 2e54 656e 736f 7229 202d 3e20 746f 7263  .Tensor) -> torc
-00002250: 682e 5465 6e73 6f72 3a0d 0a20 2020 2020  h.Tensor:..     
-00002260: 2020 2069 6620 7365 6c66 2e69 6e76 6572     if self.inver
-00002270: 7469 626c 653a 0d0a 2020 2020 2020 2020  tible:..        
-00002280: 2020 2020 7261 6973 6520 4e6f 7449 6d70      raise NotImp
-00002290: 6c65 6d65 6e74 6564 4572 726f 720d 0a20  lementedError.. 
-000022a0: 2020 2020 2020 2065 6c73 653a 0d0a 2020         else:..  
-000022b0: 2020 2020 2020 2020 2020 7265 7475 726e            return
-000022c0: 206f 6273 0d0a 0d0a 2020 2020 6465 6620   obs....    def 
-000022d0: 5f69 6e76 5f63 616c 6c28 7365 6c66 2c20  _inv_call(self, 
-000022e0: 7465 6e73 6f72 6469 6374 3a20 5465 6e73  tensordict: Tens
-000022f0: 6f72 4469 6374 4261 7365 2920 2d3e 2054  orDictBase) -> T
-00002300: 656e 736f 7244 6963 7442 6173 653a 0d0a  ensorDictBase:..
-00002310: 2020 2020 2020 2020 2320 2320 5765 2063          # # We c
-00002320: 7265 6174 6520 6120 7368 616c 6c6f 7720  reate a shallow 
-00002330: 636f 7079 206f 6620 7468 6520 7465 6e73  copy of the tens
-00002340: 6f72 6469 6374 2074 6f20 6176 6f69 6420  ordict to avoid 
-00002350: 7468 6174 2063 6861 6e67 6573 2061 7265  that changes are
-00002360: 0d0a 2020 2020 2020 2020 2320 2320 6578  ..        # # ex
-00002370: 706f 7365 6420 746f 2074 6865 2075 7365  posed to the use
-00002380: 723a 2077 6527 6420 6c69 6b65 2074 6861  r: we'd like tha
-00002390: 7420 7468 6520 696e 7075 7420 6b65 7973  t the input keys
-000023a0: 2072 656d 6169 6e20 756e 6368 616e 6765   remain unchange
-000023b0: 640d 0a20 2020 2020 2020 2023 2023 2069  d..        # # i
-000023c0: 6e20 7468 6520 6f72 6967 696e 6174 696e  n the originatin
-000023d0: 6720 7363 7269 7074 2069 6620 7468 6579  g script if they
-000023e0: 2772 6520 6265 696e 6720 7472 616e 7366  're being transf
-000023f0: 6f72 6d65 642e 0d0a 2020 2020 2020 2020  ormed...        
-00002400: 666f 7220 696e 5f6b 6579 2c20 6f75 745f  for in_key, out_
-00002410: 6b65 7920 696e 207a 6970 2873 656c 662e  key in zip(self.
-00002420: 696e 5f6b 6579 735f 696e 762c 2073 656c  in_keys_inv, sel
-00002430: 662e 6f75 745f 6b65 7973 5f69 6e76 293a  f.out_keys_inv):
-00002440: 0d0a 2020 2020 2020 2020 2020 2020 6966  ..            if
-00002450: 2069 6e5f 6b65 7920 696e 2074 656e 736f   in_key in tenso
-00002460: 7264 6963 742e 6b65 7973 2869 6e63 6c75  rdict.keys(inclu
-00002470: 6465 5f6e 6573 7465 643d 6973 696e 7374  de_nested=isinst
-00002480: 616e 6365 2869 6e5f 6b65 792c 2074 7570  ance(in_key, tup
-00002490: 6c65 2929 3a0d 0a20 2020 2020 2020 2020  le)):..         
-000024a0: 2020 2020 2020 2069 7465 6d20 3d20 7365         item = se
-000024b0: 6c66 2e5f 696e 765f 6170 706c 795f 7472  lf._inv_apply_tr
-000024c0: 616e 7366 6f72 6d28 7465 6e73 6f72 6469  ansform(tensordi
-000024d0: 6374 2e67 6574 2869 6e5f 6b65 7929 290d  ct.get(in_key)).
-000024e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000024f0: 2074 656e 736f 7264 6963 742e 7365 7428   tensordict.set(
-00002500: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00002510: 2020 2020 2020 6f75 745f 6b65 792c 0d0a        out_key,..
-00002520: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002530: 2020 2020 6974 656d 2c0d 0a20 2020 2020      item,..     
-00002540: 2020 2020 2020 2020 2020 2029 0d0a 2020             )..  
-00002550: 2020 2020 2020 7265 7475 726e 2074 656e        return ten
-00002560: 736f 7264 6963 740d 0a0d 0a20 2020 2040  sordict....    @
-00002570: 6469 7370 6174 6368 2873 6f75 7263 653d  dispatch(source=
-00002580: 2269 6e5f 6b65 7973 5f69 6e76 222c 2064  "in_keys_inv", d
-00002590: 6573 743d 226f 7574 5f6b 6579 735f 696e  est="out_keys_in
-000025a0: 7622 290d 0a20 2020 2064 6566 2069 6e76  v")..    def inv
-000025b0: 2873 656c 662c 2074 656e 736f 7264 6963  (self, tensordic
-000025c0: 743a 2054 656e 736f 7244 6963 7442 6173  t: TensorDictBas
-000025d0: 6529 202d 3e20 5465 6e73 6f72 4469 6374  e) -> TensorDict
-000025e0: 4261 7365 3a0d 0a20 2020 2020 2020 206f  Base:..        o
-000025f0: 7574 203d 2073 656c 662e 5f69 6e76 5f63  ut = self._inv_c
-00002600: 616c 6c28 7465 6e73 6f72 6469 6374 2e63  all(tensordict.c
-00002610: 6c6f 6e65 2846 616c 7365 2929 0d0a 2020  lone(False))..  
-00002620: 2020 2020 2020 7265 7475 726e 206f 7574        return out
-00002630: 0d0a 0d0a 2020 2020 6465 6620 7472 616e  ....    def tran
-00002640: 7366 6f72 6d5f 6f75 7470 7574 5f73 7065  sform_output_spe
-00002650: 6328 7365 6c66 2c20 6f75 7470 7574 5f73  c(self, output_s
-00002660: 7065 633a 2043 6f6d 706f 7369 7465 5370  pec: CompositeSp
-00002670: 6563 2920 2d3e 2043 6f6d 706f 7369 7465  ec) -> Composite
-00002680: 5370 6563 3a0d 0a20 2020 2020 2020 2022  Spec:..        "
-00002690: 2222 5472 616e 7366 6f72 6d73 2074 6865  ""Transforms the
-000026a0: 206f 7574 7075 7420 7370 6563 2073 7563   output spec suc
-000026b0: 6820 7468 6174 2074 6865 2072 6573 756c  h that the resul
-000026c0: 7469 6e67 2073 7065 6320 6d61 7463 6865  ting spec matche
-000026d0: 7320 7472 616e 7366 6f72 6d20 6d61 7070  s transform mapp
-000026e0: 696e 672e 0d0a 0d0a 2020 2020 2020 2020  ing.....        
-000026f0: 5468 6973 206d 6574 686f 6420 7368 6f75  This method shou
-00002700: 6c64 2067 656e 6572 616c 6c79 2062 6520  ld generally be 
-00002710: 6c65 6674 2075 6e74 6f75 6368 6564 2e20  left untouched. 
-00002720: 4368 616e 6765 7320 7368 6f75 6c64 2062  Changes should b
-00002730: 6520 696d 706c 656d 656e 7465 6420 7573  e implemented us
-00002740: 696e 670d 0a20 2020 2020 2020 203a 6d65  ing..        :me
-00002750: 7468 3a60 7e2e 7472 616e 7366 6f72 6d5f  th:`~.transform_
-00002760: 6f62 7365 7276 6174 696f 6e5f 7370 6563  observation_spec
-00002770: 602c 203a 6d65 7468 3a60 7e2e 7472 616e  `, :meth:`~.tran
-00002780: 7366 6f72 6d5f 7265 7761 7264 5f73 7065  sform_reward_spe
-00002790: 6360 2061 6e64 203a 6d65 7468 3a60 7e2e  c` and :meth:`~.
-000027a0: 7472 616e 7366 6f72 6d5f 646f 6e65 5f73  transform_done_s
-000027b0: 7065 6360 2e0d 0a20 2020 2020 2020 2041  pec`...        A
-000027c0: 7267 733a 0d0a 2020 2020 2020 2020 2020  rgs:..          
-000027d0: 2020 6f75 7470 7574 5f73 7065 6320 2854    output_spec (T
-000027e0: 656e 736f 7253 7065 6329 3a20 7370 6563  ensorSpec): spec
-000027f0: 2062 6566 6f72 6520 7468 6520 7472 616e   before the tran
-00002800: 7366 6f72 6d0d 0a0d 0a20 2020 2020 2020  sform....       
-00002810: 2052 6574 7572 6e73 3a0d 0a20 2020 2020   Returns:..     
-00002820: 2020 2020 2020 2065 7870 6563 7465 6420         expected 
-00002830: 7370 6563 2061 6674 6572 2074 6865 2074  spec after the t
-00002840: 7261 6e73 666f 726d 0d0a 0d0a 2020 2020  ransform....    
-00002850: 2020 2020 2222 220d 0a20 2020 2020 2020      """..       
-00002860: 206f 7574 7075 745f 7370 6563 203d 206f   output_spec = o
-00002870: 7574 7075 745f 7370 6563 2e63 6c6f 6e65  utput_spec.clone
-00002880: 2829 0d0a 2020 2020 2020 2020 6f75 7470  ()..        outp
-00002890: 7574 5f73 7065 635b 226f 6273 6572 7661  ut_spec["observa
-000028a0: 7469 6f6e 225d 203d 2073 656c 662e 7472  tion"] = self.tr
-000028b0: 616e 7366 6f72 6d5f 6f62 7365 7276 6174  ansform_observat
-000028c0: 696f 6e5f 7370 6563 280d 0a20 2020 2020  ion_spec(..     
-000028d0: 2020 2020 2020 206f 7574 7075 745f 7370         output_sp
-000028e0: 6563 5b22 6f62 7365 7276 6174 696f 6e22  ec["observation"
-000028f0: 5d0d 0a20 2020 2020 2020 2029 0d0a 2020  ]..        )..  
-00002900: 2020 2020 2020 6966 2022 7265 7761 7264        if "reward
-00002910: 2220 696e 206f 7574 7075 745f 7370 6563  " in output_spec
-00002920: 2e6b 6579 7328 293a 0d0a 2020 2020 2020  .keys():..      
-00002930: 2020 2020 2020 6f75 7470 7574 5f73 7065        output_spe
-00002940: 635b 2272 6577 6172 6422 5d20 3d20 7365  c["reward"] = se
-00002950: 6c66 2e74 7261 6e73 666f 726d 5f72 6577  lf.transform_rew
-00002960: 6172 645f 7370 6563 286f 7574 7075 745f  ard_spec(output_
-00002970: 7370 6563 5b22 7265 7761 7264 225d 290d  spec["reward"]).
-00002980: 0a20 2020 2020 2020 2069 6620 2264 6f6e  .        if "don
-00002990: 6522 2069 6e20 6f75 7470 7574 5f73 7065  e" in output_spe
-000029a0: 632e 6b65 7973 2829 3a0d 0a20 2020 2020  c.keys():..     
-000029b0: 2020 2020 2020 206f 7574 7075 745f 7370         output_sp
-000029c0: 6563 5b22 646f 6e65 225d 203d 2073 656c  ec["done"] = sel
-000029d0: 662e 7472 616e 7366 6f72 6d5f 646f 6e65  f.transform_done
-000029e0: 5f73 7065 6328 6f75 7470 7574 5f73 7065  _spec(output_spe
-000029f0: 635b 2264 6f6e 6522 5d29 0d0a 2020 2020  c["done"])..    
-00002a00: 2020 2020 7265 7475 726e 206f 7574 7075      return outpu
-00002a10: 745f 7370 6563 0d0a 0d0a 2020 2020 6465  t_spec....    de
-00002a20: 6620 7472 616e 7366 6f72 6d5f 696e 7075  f transform_inpu
-00002a30: 745f 7370 6563 2873 656c 662c 2069 6e70  t_spec(self, inp
-00002a40: 7574 5f73 7065 633a 2054 656e 736f 7253  ut_spec: TensorS
-00002a50: 7065 6329 202d 3e20 5465 6e73 6f72 5370  pec) -> TensorSp
-00002a60: 6563 3a0d 0a20 2020 2020 2020 2022 2222  ec:..        """
-00002a70: 5472 616e 7366 6f72 6d73 2074 6865 2069  Transforms the i
-00002a80: 6e70 7574 2073 7065 6320 7375 6368 2074  nput spec such t
-00002a90: 6861 7420 7468 6520 7265 7375 6c74 696e  hat the resultin
-00002aa0: 6720 7370 6563 206d 6174 6368 6573 2074  g spec matches t
-00002ab0: 7261 6e73 666f 726d 206d 6170 7069 6e67  ransform mapping
-00002ac0: 2e0d 0a0d 0a20 2020 2020 2020 2041 7267  .....        Arg
-00002ad0: 733a 0d0a 2020 2020 2020 2020 2020 2020  s:..            
-00002ae0: 696e 7075 745f 7370 6563 2028 5465 6e73  input_spec (Tens
-00002af0: 6f72 5370 6563 293a 2073 7065 6320 6265  orSpec): spec be
-00002b00: 666f 7265 2074 6865 2074 7261 6e73 666f  fore the transfo
-00002b10: 726d 0d0a 0d0a 2020 2020 2020 2020 5265  rm....        Re
-00002b20: 7475 726e 733a 0d0a 2020 2020 2020 2020  turns:..        
-00002b30: 2020 2020 6578 7065 6374 6564 2073 7065      expected spe
-00002b40: 6320 6166 7465 7220 7468 6520 7472 616e  c after the tran
-00002b50: 7366 6f72 6d0d 0a0d 0a20 2020 2020 2020  sform....       
-00002b60: 2022 2222 0d0a 2020 2020 2020 2020 7265   """..        re
-00002b70: 7475 726e 2069 6e70 7574 5f73 7065 630d  turn input_spec.
-00002b80: 0a0d 0a20 2020 2064 6566 2074 7261 6e73  ...    def trans
-00002b90: 666f 726d 5f6f 6273 6572 7661 7469 6f6e  form_observation
-00002ba0: 5f73 7065 6328 7365 6c66 2c20 6f62 7365  _spec(self, obse
-00002bb0: 7276 6174 696f 6e5f 7370 6563 3a20 5465  rvation_spec: Te
-00002bc0: 6e73 6f72 5370 6563 2920 2d3e 2054 656e  nsorSpec) -> Ten
-00002bd0: 736f 7253 7065 633a 0d0a 2020 2020 2020  sorSpec:..      
-00002be0: 2020 2222 2254 7261 6e73 666f 726d 7320    """Transforms 
-00002bf0: 7468 6520 6f62 7365 7276 6174 696f 6e20  the observation 
-00002c00: 7370 6563 2073 7563 6820 7468 6174 2074  spec such that t
-00002c10: 6865 2072 6573 756c 7469 6e67 2073 7065  he resulting spe
-00002c20: 6320 6d61 7463 6865 7320 7472 616e 7366  c matches transf
-00002c30: 6f72 6d20 6d61 7070 696e 672e 0d0a 0d0a  orm mapping.....
-00002c40: 2020 2020 2020 2020 4172 6773 3a0d 0a20          Args:.. 
-00002c50: 2020 2020 2020 2020 2020 206f 6273 6572             obser
-00002c60: 7661 7469 6f6e 5f73 7065 6320 2854 656e  vation_spec (Ten
-00002c70: 736f 7253 7065 6329 3a20 7370 6563 2062  sorSpec): spec b
-00002c80: 6566 6f72 6520 7468 6520 7472 616e 7366  efore the transf
-00002c90: 6f72 6d0d 0a0d 0a20 2020 2020 2020 2052  orm....        R
-00002ca0: 6574 7572 6e73 3a0d 0a20 2020 2020 2020  eturns:..       
-00002cb0: 2020 2020 2065 7870 6563 7465 6420 7370       expected sp
-00002cc0: 6563 2061 6674 6572 2074 6865 2074 7261  ec after the tra
-00002cd0: 6e73 666f 726d 0d0a 0d0a 2020 2020 2020  nsform....      
-00002ce0: 2020 2222 220d 0a20 2020 2020 2020 2072    """..        r
-00002cf0: 6574 7572 6e20 6f62 7365 7276 6174 696f  eturn observatio
-00002d00: 6e5f 7370 6563 0d0a 0d0a 2020 2020 6465  n_spec....    de
-00002d10: 6620 7472 616e 7366 6f72 6d5f 7265 7761  f transform_rewa
-00002d20: 7264 5f73 7065 6328 7365 6c66 2c20 7265  rd_spec(self, re
-00002d30: 7761 7264 5f73 7065 633a 2054 656e 736f  ward_spec: Tenso
-00002d40: 7253 7065 6329 202d 3e20 5465 6e73 6f72  rSpec) -> Tensor
-00002d50: 5370 6563 3a0d 0a20 2020 2020 2020 2022  Spec:..        "
-00002d60: 2222 5472 616e 7366 6f72 6d73 2074 6865  ""Transforms the
-00002d70: 2072 6577 6172 6420 7370 6563 2073 7563   reward spec suc
-00002d80: 6820 7468 6174 2074 6865 2072 6573 756c  h that the resul
-00002d90: 7469 6e67 2073 7065 6320 6d61 7463 6865  ting spec matche
-00002da0: 7320 7472 616e 7366 6f72 6d20 6d61 7070  s transform mapp
-00002db0: 696e 672e 0d0a 0d0a 2020 2020 2020 2020  ing.....        
-00002dc0: 4172 6773 3a0d 0a20 2020 2020 2020 2020  Args:..         
-00002dd0: 2020 2072 6577 6172 645f 7370 6563 2028     reward_spec (
-00002de0: 5465 6e73 6f72 5370 6563 293a 2073 7065  TensorSpec): spe
-00002df0: 6320 6265 666f 7265 2074 6865 2074 7261  c before the tra
-00002e00: 6e73 666f 726d 0d0a 0d0a 2020 2020 2020  nsform....      
-00002e10: 2020 5265 7475 726e 733a 0d0a 2020 2020    Returns:..    
-00002e20: 2020 2020 2020 2020 6578 7065 6374 6564          expected
-00002e30: 2073 7065 6320 6166 7465 7220 7468 6520   spec after the 
-00002e40: 7472 616e 7366 6f72 6d0d 0a0d 0a20 2020  transform....   
-00002e50: 2020 2020 2022 2222 0d0a 2020 2020 2020       """..      
-00002e60: 2020 7265 7475 726e 2072 6577 6172 645f    return reward_
-00002e70: 7370 6563 0d0a 0d0a 2020 2020 6465 6620  spec....    def 
-00002e80: 7472 616e 7366 6f72 6d5f 646f 6e65 5f73  transform_done_s
-00002e90: 7065 6328 7365 6c66 2c20 646f 6e65 5f73  pec(self, done_s
-00002ea0: 7065 633a 2054 656e 736f 7253 7065 6329  pec: TensorSpec)
-00002eb0: 202d 3e20 5465 6e73 6f72 5370 6563 3a0d   -> TensorSpec:.
-00002ec0: 0a20 2020 2020 2020 2022 2222 5472 616e  .        """Tran
-00002ed0: 7366 6f72 6d73 2074 6865 2064 6f6e 6520  sforms the done 
-00002ee0: 7370 6563 2073 7563 6820 7468 6174 2074  spec such that t
-00002ef0: 6865 2072 6573 756c 7469 6e67 2073 7065  he resulting spe
-00002f00: 6320 6d61 7463 6865 7320 7472 616e 7366  c matches transf
-00002f10: 6f72 6d20 6d61 7070 696e 672e 0d0a 0d0a  orm mapping.....
-00002f20: 2020 2020 2020 2020 4172 6773 3a0d 0a20          Args:.. 
-00002f30: 2020 2020 2020 2020 2020 2064 6f6e 655f             done_
-00002f40: 7370 6563 2028 5465 6e73 6f72 5370 6563  spec (TensorSpec
-00002f50: 293a 2073 7065 6320 6265 666f 7265 2074  ): spec before t
-00002f60: 6865 2074 7261 6e73 666f 726d 0d0a 0d0a  he transform....
-00002f70: 2020 2020 2020 2020 5265 7475 726e 733a          Returns:
-00002f80: 0d0a 2020 2020 2020 2020 2020 2020 6578  ..            ex
-00002f90: 7065 6374 6564 2073 7065 6320 6166 7465  pected spec afte
-00002fa0: 7220 7468 6520 7472 616e 7366 6f72 6d0d  r the transform.
-00002fb0: 0a0d 0a20 2020 2020 2020 2022 2222 0d0a  ...        """..
-00002fc0: 2020 2020 2020 2020 7265 7475 726e 2064          return d
-00002fd0: 6f6e 655f 7370 6563 0d0a 0d0a 2020 2020  one_spec....    
-00002fe0: 6465 6620 6475 6d70 2873 656c 662c 202a  def dump(self, *
-00002ff0: 2a6b 7761 7267 7329 202d 3e20 4e6f 6e65  *kwargs) -> None
-00003000: 3a0d 0a20 2020 2020 2020 2070 6173 730d  :..        pass.
-00003010: 0a0d 0a20 2020 2064 6566 205f 5f72 6570  ...    def __rep
-00003020: 725f 5f28 7365 6c66 2920 2d3e 2073 7472  r__(self) -> str
-00003030: 3a0d 0a20 2020 2020 2020 2072 6574 7572  :..        retur
-00003040: 6e20 6622 7b73 656c 662e 5f5f 636c 6173  n f"{self.__clas
-00003050: 735f 5f2e 5f5f 6e61 6d65 5f5f 7d28 6b65  s__.__name__}(ke
-00003060: 7973 3d7b 7365 6c66 2e69 6e5f 6b65 7973  ys={self.in_keys
-00003070: 7d29 220d 0a0d 0a20 2020 2064 6566 2073  })"....    def s
-00003080: 6574 5f63 6f6e 7461 696e 6572 2873 656c  et_container(sel
-00003090: 662c 2063 6f6e 7461 696e 6572 3a20 556e  f, container: Un
-000030a0: 696f 6e5b 5472 616e 7366 6f72 6d2c 2045  ion[Transform, E
-000030b0: 6e76 4261 7365 5d29 202d 3e20 4e6f 6e65  nvBase]) -> None
-000030c0: 3a0d 0a20 2020 2020 2020 2069 6620 7365  :..        if se
-000030d0: 6c66 2e70 6172 656e 7420 6973 206e 6f74  lf.parent is not
-000030e0: 204e 6f6e 653a 0d0a 2020 2020 2020 2020   None:..        
-000030f0: 2020 2020 7261 6973 6520 4174 7472 6962      raise Attrib
-00003100: 7574 6545 7272 6f72 280d 0a20 2020 2020  uteError(..     
-00003110: 2020 2020 2020 2020 2020 2066 2270 6172             f"par
-00003120: 656e 7420 6f66 2074 7261 6e73 666f 726d  ent of transform
-00003130: 207b 7479 7065 2873 656c 6629 7d20 616c   {type(self)} al
-00003140: 7265 6164 7920 7365 742e 2022 0d0a 2020  ready set. "..  
-00003150: 2020 2020 2020 2020 2020 2020 2020 2243                "C
-00003160: 616c 6c20 6074 7261 6e73 666f 726d 2e63  all `transform.c
-00003170: 6c6f 6e65 2829 6020 746f 2067 6574 2061  lone()` to get a
-00003180: 2073 696d 696c 6172 2074 7261 6e73 666f   similar transfo
-00003190: 726d 2077 6974 6820 6e6f 2070 6172 656e  rm with no paren
-000031a0: 7420 7365 742e 220d 0a20 2020 2020 2020  t set."..       
-000031b0: 2020 2020 2029 0d0a 2020 2020 2020 2020       )..        
-000031c0: 7365 6c66 2e5f 5f64 6963 745f 5f5b 225f  self.__dict__["_
-000031d0: 636f 6e74 6169 6e65 7222 5d20 3d20 636f  container"] = co
-000031e0: 6e74 6169 6e65 720d 0a0d 0a20 2020 2064  ntainer....    d
-000031f0: 6566 2072 6573 6574 5f70 6172 656e 7428  ef reset_parent(
-00003200: 7365 6c66 2920 2d3e 204e 6f6e 653a 0d0a  self) -> None:..
-00003210: 2020 2020 2020 2020 7365 6c66 2e5f 5f64          self.__d
-00003220: 6963 745f 5f5b 225f 636f 6e74 6169 6e65  ict__["_containe
-00003230: 7222 5d20 3d20 4e6f 6e65 0d0a 2020 2020  r"] = None..    
-00003240: 2020 2020 7365 6c66 2e5f 5f64 6963 745f      self.__dict_
-00003250: 5f5b 225f 7061 7265 6e74 225d 203d 204e  _["_parent"] = N
-00003260: 6f6e 650d 0a0d 0a20 2020 2064 6566 2063  one....    def c
-00003270: 6c6f 6e65 2873 656c 6629 3a0d 0a20 2020  lone(self):..   
-00003280: 2020 2020 2073 656c 665f 636f 7079 203d       self_copy =
-00003290: 2063 6f70 7928 7365 6c66 290d 0a20 2020   copy(self)..   
-000032a0: 2020 2020 2073 7461 7465 203d 2063 6f70       state = cop
-000032b0: 7928 7365 6c66 2e5f 5f64 6963 745f 5f29  y(self.__dict__)
-000032c0: 0d0a 2020 2020 2020 2020 7374 6174 655b  ..        state[
-000032d0: 225f 636f 6e74 6169 6e65 7222 5d20 3d20  "_container"] = 
-000032e0: 4e6f 6e65 0d0a 2020 2020 2020 2020 7374  None..        st
-000032f0: 6174 655b 225f 7061 7265 6e74 225d 203d  ate["_parent"] =
-00003300: 204e 6f6e 650d 0a20 2020 2020 2020 2073   None..        s
-00003310: 656c 665f 636f 7079 2e5f 5f64 6963 745f  elf_copy.__dict_
-00003320: 5f2e 7570 6461 7465 2873 7461 7465 290d  _.update(state).
-00003330: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00003340: 7365 6c66 5f63 6f70 790d 0a0d 0a20 2020  self_copy....   
-00003350: 2040 7072 6f70 6572 7479 0d0a 2020 2020   @property..    
-00003360: 6465 6620 7061 7265 6e74 2873 656c 6629  def parent(self)
-00003370: 202d 3e20 4f70 7469 6f6e 616c 5b45 6e76   -> Optional[Env
-00003380: 4261 7365 5d3a 0d0a 2020 2020 2020 2020  Base]:..        
-00003390: 6966 2073 656c 662e 5f5f 6469 6374 5f5f  if self.__dict__
-000033a0: 2e67 6574 2822 5f70 6172 656e 7422 2c20  .get("_parent", 
-000033b0: 4e6f 6e65 2920 6973 204e 6f6e 653a 0d0a  None) is None:..
-000033c0: 2020 2020 2020 2020 2020 2020 6966 2022              if "
-000033d0: 5f63 6f6e 7461 696e 6572 2220 6e6f 7420  _container" not 
-000033e0: 696e 2073 656c 662e 5f5f 6469 6374 5f5f  in self.__dict__
-000033f0: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
-00003400: 2020 2072 6169 7365 2041 7474 7269 6275     raise Attribu
-00003410: 7465 4572 726f 7228 2274 7261 6e73 666f  teError("transfo
-00003420: 726d 2070 6172 656e 7420 756e 696e 6974  rm parent uninit
-00003430: 6961 6c69 7a65 6422 290d 0a20 2020 2020  ialized")..     
-00003440: 2020 2020 2020 2063 6f6e 7461 696e 6572         container
-00003450: 203d 2073 656c 662e 5f5f 6469 6374 5f5f   = self.__dict__
-00003460: 5b22 5f63 6f6e 7461 696e 6572 225d 0d0a  ["_container"]..
-00003470: 2020 2020 2020 2020 2020 2020 6966 2063              if c
-00003480: 6f6e 7461 696e 6572 2069 7320 4e6f 6e65  ontainer is None
-00003490: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
-000034a0: 2020 2072 6574 7572 6e20 636f 6e74 6169     return contai
-000034b0: 6e65 720d 0a20 2020 2020 2020 2020 2020  ner..           
-000034c0: 206f 7574 203d 204e 6f6e 650d 0a20 2020   out = None..   
-000034d0: 2020 2020 2020 2020 2069 6620 6e6f 7420           if not 
-000034e0: 6973 696e 7374 616e 6365 2863 6f6e 7461  isinstance(conta
-000034f0: 696e 6572 2c20 456e 7642 6173 6529 3a0d  iner, EnvBase):.
-00003500: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00003510: 2023 2069 6620 6974 2773 206e 6f74 2061   # if it's not a
-00003520: 6e20 656e 762c 2069 7420 7368 6f75 6c64  n env, it should
-00003530: 2062 6520 6120 436f 6d70 6f73 6520 7472   be a Compose tr
-00003540: 616e 7366 6f72 6d0d 0a20 2020 2020 2020  ansform..       
-00003550: 2020 2020 2020 2020 2069 6620 6e6f 7420           if not 
-00003560: 6973 696e 7374 616e 6365 2863 6f6e 7461  isinstance(conta
-00003570: 696e 6572 2c20 436f 6d70 6f73 6529 3a0d  iner, Compose):.
-00003580: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00003590: 2020 2020 2072 6169 7365 2056 616c 7565       raise Value
-000035a0: 4572 726f 7228 0d0a 2020 2020 2020 2020  Error(..        
-000035b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000035c0: 2241 2074 7261 6e73 666f 726d 2070 6172  "A transform par
-000035d0: 656e 7420 6d75 7374 2062 6520 6569 7468  ent must be eith
-000035e0: 6572 2061 6e6f 7468 6572 2043 6f6d 706f  er another Compo
-000035f0: 7365 2074 7261 6e73 666f 726d 206f 7220  se transform or 
-00003600: 616e 2065 6e76 6972 6f6e 6d65 6e74 206f  an environment o
-00003610: 626a 6563 742e 220d 0a20 2020 2020 2020  bject."..       
-00003620: 2020 2020 2020 2020 2020 2020 2029 0d0a               )..
-00003630: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003640: 636f 6d70 6f73 6520 3d20 636f 6e74 6169  compose = contai
-00003650: 6e65 720d 0a20 2020 2020 2020 2020 2020  ner..           
-00003660: 2020 2020 2069 6620 636f 6d70 6f73 652e       if compose.
-00003670: 5f5f 6469 6374 5f5f 5b22 5f63 6f6e 7461  __dict__["_conta
-00003680: 696e 6572 225d 3a0d 0a20 2020 2020 2020  iner"]:..       
-00003690: 2020 2020 2020 2020 2020 2020 2023 2074               # t
-000036a0: 6865 2070 6172 656e 7420 6f66 2074 6865  he parent of the
-000036b0: 2063 6f6d 706f 7365 206d 7573 7420 6265   compose must be
-000036c0: 2061 2054 7261 6e73 666f 726d 6564 456e   a TransformedEn
-000036d0: 760d 0a20 2020 2020 2020 2020 2020 2020  v..             
-000036e0: 2020 2020 2020 2063 6f6d 706f 7365 5f70         compose_p
-000036f0: 6172 656e 7420 3d20 5472 616e 7366 6f72  arent = Transfor
-00003700: 6d65 6445 6e76 280d 0a20 2020 2020 2020  medEnv(..       
-00003710: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003720: 2063 6f6d 706f 7365 2e5f 5f64 6963 745f   compose.__dict_
-00003730: 5f5b 225f 636f 6e74 6169 6e65 7222 5d2e  _["_container"].
-00003740: 6261 7365 5f65 6e76 0d0a 2020 2020 2020  base_env..      
-00003750: 2020 2020 2020 2020 2020 2020 2020 290d                ).
-00003760: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00003770: 2020 2020 2069 6620 636f 6d70 6f73 655f       if compose_
-00003780: 7061 7265 6e74 2e74 7261 6e73 666f 726d  parent.transform
-00003790: 2069 7320 6e6f 7420 636f 6d70 6f73 653a   is not compose:
-000037a0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-000037b0: 2020 2020 2020 2020 2020 636f 6d70 5f70            comp_p
-000037c0: 6172 656e 745f 7472 616e 7320 3d20 636f  arent_trans = co
-000037d0: 6d70 6f73 655f 7061 7265 6e74 2e74 7261  mpose_parent.tra
-000037e0: 6e73 666f 726d 2e63 6c6f 6e65 2829 0d0a  nsform.clone()..
-000037f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003800: 2020 2020 656c 7365 3a0d 0a20 2020 2020      else:..     
-00003810: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003820: 2020 2063 6f6d 705f 7061 7265 6e74 5f74     comp_parent_t
-00003830: 7261 6e73 203d 204e 6f6e 650d 0a20 2020  rans = None..   
-00003840: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003850: 206f 7574 203d 2054 7261 6e73 666f 726d   out = Transform
-00003860: 6564 456e 7628 0d0a 2020 2020 2020 2020  edEnv(..        
-00003870: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003880: 636f 6d70 6f73 655f 7061 7265 6e74 2e62  compose_parent.b
-00003890: 6173 655f 656e 762c 0d0a 2020 2020 2020  ase_env,..      
-000038a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000038b0: 2020 7472 616e 7366 6f72 6d3d 636f 6d70    transform=comp
-000038c0: 5f70 6172 656e 745f 7472 616e 732c 0d0a  _parent_trans,..
-000038d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000038e0: 2020 2020 290d 0a20 2020 2020 2020 2020      )..         
-000038f0: 2020 2020 2020 2020 2020 2066 6f72 206f             for o
-00003900: 7269 675f 7472 616e 7320 696e 2063 6f6d  rig_trans in com
-00003910: 706f 7365 2e74 7261 6e73 666f 726d 733a  pose.transforms:
-00003920: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00003930: 2020 2020 2020 2020 2020 6966 206f 7269            if ori
-00003940: 675f 7472 616e 7320 6973 2073 656c 663a  g_trans is self:
-00003950: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00003960: 2020 2020 2020 2020 2020 2020 2020 6272                br
-00003970: 6561 6b0d 0a20 2020 2020 2020 2020 2020  eak..           
-00003980: 2020 2020 2020 2020 2020 2020 2074 7261               tra
-00003990: 6e73 666f 726d 203d 206f 7269 675f 7472  nsform = orig_tr
-000039a0: 616e 732e 636c 6f6e 6528 290d 0a20 2020  ans.clone()..   
-000039b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000039c0: 2020 2020 2074 7261 6e73 666f 726d 2e72       transform.r
-000039d0: 6573 6574 5f70 6172 656e 7428 290d 0a20  eset_parent().. 
-000039e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000039f0: 2020 2020 2020 206f 7574 2e61 7070 656e         out.appen
-00003a00: 645f 7472 616e 7366 6f72 6d28 7472 616e  d_transform(tran
-00003a10: 7366 6f72 6d29 0d0a 2020 2020 2020 2020  sform)..        
-00003a20: 2020 2020 656c 6966 2069 7369 6e73 7461      elif isinsta
-00003a30: 6e63 6528 636f 6e74 6169 6e65 722c 2054  nce(container, T
-00003a40: 7261 6e73 666f 726d 6564 456e 7629 3a0d  ransformedEnv):.
-00003a50: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00003a60: 206f 7574 203d 2054 7261 6e73 666f 726d   out = Transform
-00003a70: 6564 456e 7628 636f 6e74 6169 6e65 722e  edEnv(container.
-00003a80: 6261 7365 5f65 6e76 290d 0a20 2020 2020  base_env)..     
-00003a90: 2020 2020 2020 2065 6c73 653a 0d0a 2020         else:..  
-00003aa0: 2020 2020 2020 2020 2020 2020 2020 7261                ra
-00003ab0: 6973 6520 5661 6c75 6545 7272 6f72 2866  ise ValueError(f
-00003ac0: 2263 6f6e 7461 696e 6572 2069 7320 6f66  "container is of
-00003ad0: 2074 7970 6520 7b74 7970 6528 636f 6e74   type {type(cont
-00003ae0: 6169 6e65 7229 7d22 290d 0a20 2020 2020  ainer)}")..     
-00003af0: 2020 2020 2020 2073 656c 662e 5f5f 6469         self.__di
-00003b00: 6374 5f5f 5b22 5f70 6172 656e 7422 5d20  ct__["_parent"] 
-00003b10: 3d20 6f75 740d 0a20 2020 2020 2020 2072  = out..        r
-00003b20: 6574 7572 6e20 7365 6c66 2e5f 5f64 6963  eturn self.__dic
-00003b30: 745f 5f5b 225f 7061 7265 6e74 225d 0d0a  t__["_parent"]..
-00003b40: 0d0a 2020 2020 6465 6620 656d 7074 795f  ..    def empty_
-00003b50: 6361 6368 6528 7365 6c66 293a 0d0a 2020  cache(self):..  
-00003b60: 2020 2020 2020 7365 6c66 2e5f 5f64 6963        self.__dic
-00003b70: 745f 5f5b 225f 7061 7265 6e74 225d 203d  t__["_parent"] =
-00003b80: 204e 6f6e 650d 0a0d 0a0d 0a63 6c61 7373   None......class
-00003b90: 2054 7261 6e73 666f 726d 6564 456e 7628   TransformedEnv(
-00003ba0: 456e 7642 6173 6529 3a0d 0a20 2020 2022  EnvBase):..    "
-00003bb0: 2222 4120 7472 616e 7366 6f72 6d65 645f  ""A transformed_
-00003bc0: 696e 2065 6e76 6972 6f6e 6d65 6e74 2e0d  in environment..
-00003bd0: 0a0d 0a20 2020 2041 7267 733a 0d0a 2020  ...    Args:..  
-00003be0: 2020 2020 2020 656e 7620 2845 6e76 4261        env (EnvBa
-00003bf0: 7365 293a 206f 7269 6769 6e61 6c20 656e  se): original en
-00003c00: 7669 726f 6e6d 656e 7420 746f 2062 6520  vironment to be 
-00003c10: 7472 616e 7366 6f72 6d65 645f 696e 2e0d  transformed_in..
-00003c20: 0a20 2020 2020 2020 2074 7261 6e73 666f  .        transfo
-00003c30: 726d 2028 5472 616e 7366 6f72 6d2c 206f  rm (Transform, o
-00003c40: 7074 696f 6e61 6c29 3a20 7472 616e 7366  ptional): transf
-00003c50: 6f72 6d20 746f 2061 7070 6c79 2074 6f20  orm to apply to 
-00003c60: 7468 6520 7465 6e73 6f72 6469 6374 2072  the tensordict r
-00003c70: 6573 756c 7469 6e67 0d0a 2020 2020 2020  esulting..      
-00003c80: 2020 2020 2020 6672 6f6d 203a 6f62 6a3a        from :obj:
-00003c90: 6065 6e76 2e73 7465 7028 7464 2960 2e20  `env.step(td)`. 
-00003ca0: 4966 206e 6f6e 6520 6973 2070 726f 7669  If none is provi
-00003cb0: 6465 642c 2061 6e20 656d 7074 7920 436f  ded, an empty Co
-00003cc0: 6d70 6f73 650d 0a20 2020 2020 2020 2020  mpose..         
-00003cd0: 2020 2070 6c61 6365 686f 6c64 6572 2069     placeholder i
-00003ce0: 6e20 616e 2065 7661 6c20 6d6f 6465 2069  n an eval mode i
-00003cf0: 7320 7573 6564 2e0d 0a20 2020 2020 2020  s used...       
-00003d00: 2063 6163 6865 5f73 7065 6373 2028 626f   cache_specs (bo
-00003d10: 6f6c 2c20 6f70 7469 6f6e 616c 293a 2069  ol, optional): i
-00003d20: 6620 5472 7565 2c20 7468 6520 7370 6563  f True, the spec
-00003d30: 7320 7769 6c6c 2062 6520 6361 6368 6564  s will be cached
-00003d40: 206f 6e63 650d 0a20 2020 2020 2020 2020   once..         
-00003d50: 2020 2061 6e64 2066 6f72 2061 6c6c 2061     and for all a
-00003d60: 6674 6572 2074 6865 2066 6972 7374 2063  fter the first c
-00003d70: 616c 6c20 2869 2e65 2e20 7468 6520 7370  all (i.e. the sp
-00003d80: 6563 7320 7769 6c6c 2062 650d 0a20 2020  ecs will be..   
-00003d90: 2020 2020 2020 2020 2074 7261 6e73 666f           transfo
-00003da0: 726d 6564 5f69 6e20 6f6e 6c79 206f 6e63  rmed_in only onc
-00003db0: 6529 2e20 4966 2074 6865 2074 7261 6e73  e). If the trans
-00003dc0: 666f 726d 2063 6861 6e67 6573 2064 7572  form changes dur
-00003dd0: 696e 670d 0a20 2020 2020 2020 2020 2020  ing..           
-00003de0: 2074 7261 696e 696e 672c 2074 6865 206f   training, the o
-00003df0: 7269 6769 6e61 6c20 7370 6563 2074 7261  riginal spec tra
-00003e00: 6e73 666f 726d 206d 6179 206e 6f74 2062  nsform may not b
-00003e10: 6520 7661 6c69 6420 616e 796d 6f72 652c  e valid anymore,
-00003e20: 0d0a 2020 2020 2020 2020 2020 2020 696e  ..            in
-00003e30: 2077 6869 6368 2063 6173 6520 7468 6973   which case this
-00003e40: 2076 616c 7565 2073 686f 756c 6420 6265   value should be
-00003e50: 2073 6574 2020 746f 2060 4661 6c73 6560   set  to `False`
-00003e60: 2e20 4465 6661 756c 7420 6973 0d0a 2020  . Default is..  
-00003e70: 2020 2020 2020 2020 2020 6054 7275 6560            `True`
-00003e80: 2e0d 0a0d 0a20 2020 2045 7861 6d70 6c65  .....    Example
-00003e90: 733a 0d0a 2020 2020 2020 2020 3e3e 3e20  s:..        >>> 
-00003ea0: 656e 7620 3d20 4779 6d45 6e76 2822 5065  env = GymEnv("Pe
-00003eb0: 6e64 756c 756d 2d76 3022 290d 0a20 2020  ndulum-v0")..   
-00003ec0: 2020 2020 203e 3e3e 2074 7261 6e73 666f       >>> transfo
-00003ed0: 726d 203d 2052 6577 6172 6453 6361 6c69  rm = RewardScali
-00003ee0: 6e67 2830 2e30 2c20 312e 3029 0d0a 2020  ng(0.0, 1.0)..  
-00003ef0: 2020 2020 2020 3e3e 3e20 7472 616e 7366        >>> transf
-00003f00: 6f72 6d65 645f 656e 7620 3d20 5472 616e  ormed_env = Tran
-00003f10: 7366 6f72 6d65 6445 6e76 2865 6e76 2c20  sformedEnv(env, 
-00003f20: 7472 616e 7366 6f72 6d29 0d0a 0d0a 2020  transform)....  
-00003f30: 2020 2222 220d 0a0d 0a20 2020 2064 6566    """....    def
-00003f40: 205f 5f69 6e69 745f 5f28 0d0a 2020 2020   __init__(..    
-00003f50: 2020 2020 7365 6c66 2c0d 0a20 2020 2020      self,..     
-00003f60: 2020 2065 6e76 3a20 456e 7642 6173 652c     env: EnvBase,
-00003f70: 0d0a 2020 2020 2020 2020 7472 616e 7366  ..        transf
-00003f80: 6f72 6d3a 204f 7074 696f 6e61 6c5b 5472  orm: Optional[Tr
-00003f90: 616e 7366 6f72 6d5d 203d 204e 6f6e 652c  ansform] = None,
-00003fa0: 0d0a 2020 2020 2020 2020 6361 6368 655f  ..        cache_
-00003fb0: 7370 6563 733a 2062 6f6f 6c20 3d20 5472  specs: bool = Tr
-00003fc0: 7565 2c0d 0a20 2020 2020 2020 202a 2a6b  ue,..        **k
-00003fd0: 7761 7267 732c 0d0a 2020 2020 293a 0d0a  wargs,..    ):..
-00003fe0: 2020 2020 2020 2020 7365 6c66 2e5f 7472          self._tr
-00003ff0: 616e 7366 6f72 6d20 3d20 4e6f 6e65 0d0a  ansform = None..
-00004000: 2020 2020 2020 2020 6465 7669 6365 203d          device =
-00004010: 206b 7761 7267 732e 706f 7028 2264 6576   kwargs.pop("dev
-00004020: 6963 6522 2c20 4e6f 6e65 290d 0a20 2020  ice", None)..   
-00004030: 2020 2020 2069 6620 6465 7669 6365 2069       if device i
-00004040: 7320 6e6f 7420 4e6f 6e65 3a0d 0a20 2020  s not None:..   
-00004050: 2020 2020 2020 2020 2065 6e76 203d 2065           env = e
-00004060: 6e76 2e74 6f28 6465 7669 6365 290d 0a20  nv.to(device).. 
-00004070: 2020 2020 2020 2065 6c73 653a 0d0a 2020         else:..  
-00004080: 2020 2020 2020 2020 2020 6465 7669 6365            device
-00004090: 203d 2065 6e76 2e64 6576 6963 650d 0a20   = env.device.. 
-000040a0: 2020 2020 2020 2073 7570 6572 2829 2e5f         super()._
-000040b0: 5f69 6e69 745f 5f28 6465 7669 6365 3d4e  _init__(device=N
-000040c0: 6f6e 652c 202a 2a6b 7761 7267 7329 0d0a  one, **kwargs)..
-000040d0: 0d0a 2020 2020 2020 2020 6966 2069 7369  ..        if isi
-000040e0: 6e73 7461 6e63 6528 656e 762c 2054 7261  nstance(env, Tra
-000040f0: 6e73 666f 726d 6564 456e 7629 3a0d 0a20  nsformedEnv):.. 
-00004100: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-00004110: 5f73 6574 5f65 6e76 2865 6e76 2e62 6173  _set_env(env.bas
-00004120: 655f 656e 762c 2064 6576 6963 6529 0d0a  e_env, device)..
-00004130: 2020 2020 2020 2020 2020 2020 6966 2074              if t
-00004140: 7970 6528 7472 616e 7366 6f72 6d29 2069  ype(transform) i
-00004150: 7320 6e6f 7420 436f 6d70 6f73 653a 0d0a  s not Compose:..
-00004160: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004170: 2320 7765 2064 6f6e 2774 2075 7365 2069  # we don't use i
-00004180: 7369 6e73 7461 6e63 6520 6173 2073 6f6d  sinstance as som
-00004190: 6520 7472 616e 7366 6f72 6d73 206d 6179  e transforms may
-000041a0: 2062 6520 7375 6263 6c61 7373 6564 2066   be subclassed f
-000041b0: 726f 6d0d 0a20 2020 2020 2020 2020 2020  rom..           
-000041c0: 2020 2020 2023 2043 6f6d 706f 7365 2062       # Compose b
-000041d0: 7574 2077 6974 6820 6f74 6865 7220 6665  ut with other fe
-000041e0: 6174 7572 6573 2074 6861 7420 7765 2064  atures that we d
-000041f0: 6f6e 2774 2077 616e 7420 746f 206c 6f6f  on't want to loo
-00004200: 7365 2e0d 0a20 2020 2020 2020 2020 2020  se...           
-00004210: 2020 2020 2069 6620 7472 616e 7366 6f72       if transfor
-00004220: 6d20 6973 206e 6f74 204e 6f6e 653a 0d0a  m is not None:..
-00004230: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004240: 2020 2020 7472 616e 7366 6f72 6d20 3d20      transform = 
-00004250: 5b74 7261 6e73 666f 726d 5d0d 0a20 2020  [transform]..   
-00004260: 2020 2020 2020 2020 2020 2020 2065 6c73               els
-00004270: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
-00004280: 2020 2020 2020 2020 7472 616e 7366 6f72          transfor
-00004290: 6d20 3d20 5b5d 0d0a 2020 2020 2020 2020  m = []..        
-000042a0: 2020 2020 656c 7365 3a0d 0a20 2020 2020      else:..     
-000042b0: 2020 2020 2020 2020 2020 2066 6f72 2074             for t
-000042c0: 2069 6e20 7472 616e 7366 6f72 6d3a 0d0a   in transform:..
-000042d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000042e0: 2020 2020 742e 7265 7365 745f 7061 7265      t.reset_pare
-000042f0: 6e74 2829 0d0a 2020 2020 2020 2020 2020  nt()..          
-00004300: 2020 656e 765f 7472 616e 7366 6f72 6d20    env_transform 
-00004310: 3d20 656e 762e 7472 616e 7366 6f72 6d2e  = env.transform.
-00004320: 636c 6f6e 6528 290d 0a20 2020 2020 2020  clone()..       
-00004330: 2020 2020 2069 6620 7479 7065 2865 6e76       if type(env
-00004340: 5f74 7261 6e73 666f 726d 2920 6973 206e  _transform) is n
-00004350: 6f74 2043 6f6d 706f 7365 3a0d 0a20 2020  ot Compose:..   
-00004360: 2020 2020 2020 2020 2020 2020 2065 6e76               env
-00004370: 5f74 7261 6e73 666f 726d 203d 205b 656e  _transform = [en
-00004380: 765f 7472 616e 7366 6f72 6d5d 0d0a 2020  v_transform]..  
-00004390: 2020 2020 2020 2020 2020 656c 7365 3a0d            else:.
-000043a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000043b0: 2066 6f72 2074 2069 6e20 656e 765f 7472   for t in env_tr
-000043c0: 616e 7366 6f72 6d3a 0d0a 2020 2020 2020  ansform:..      
-000043d0: 2020 2020 2020 2020 2020 2020 2020 742e                t.
-000043e0: 7265 7365 745f 7061 7265 6e74 2829 0d0a  reset_parent()..
-000043f0: 2020 2020 2020 2020 2020 2020 7472 616e              tran
-00004400: 7366 6f72 6d20 3d20 436f 6d70 6f73 6528  sform = Compose(
-00004410: 2a65 6e76 5f74 7261 6e73 666f 726d 2c20  *env_transform, 
-00004420: 2a74 7261 6e73 666f 726d 292e 746f 2864  *transform).to(d
-00004430: 6576 6963 6529 0d0a 2020 2020 2020 2020  evice)..        
-00004440: 656c 7365 3a0d 0a20 2020 2020 2020 2020  else:..         
-00004450: 2020 2073 656c 662e 5f73 6574 5f65 6e76     self._set_env
-00004460: 2865 6e76 2c20 6465 7669 6365 290d 0a20  (env, device).. 
-00004470: 2020 2020 2020 2020 2020 2069 6620 7472             if tr
-00004480: 616e 7366 6f72 6d20 6973 204e 6f6e 653a  ansform is None:
-00004490: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-000044a0: 2020 7472 616e 7366 6f72 6d20 3d20 436f    transform = Co
-000044b0: 6d70 6f73 6528 290d 0a20 2020 2020 2020  mpose()..       
-000044c0: 2020 2020 2065 6c73 653a 0d0a 2020 2020       else:..    
-000044d0: 2020 2020 2020 2020 2020 2020 7472 616e              tran
-000044e0: 7366 6f72 6d20 3d20 7472 616e 7366 6f72  sform = transfor
-000044f0: 6d2e 746f 2864 6576 6963 6529 0d0a 2020  m.to(device)..  
-00004500: 2020 2020 2020 7365 6c66 2e74 7261 6e73        self.trans
-00004510: 666f 726d 203d 2074 7261 6e73 666f 726d  form = transform
-00004520: 0d0a 0d0a 2020 2020 2020 2020 7365 6c66  ....        self
-00004530: 2e5f 6c61 7374 5f6f 6273 203d 204e 6f6e  ._last_obs = Non
-00004540: 650d 0a20 2020 2020 2020 2073 656c 662e  e..        self.
-00004550: 6361 6368 655f 7370 6563 7320 3d20 6361  cache_specs = ca
-00004560: 6368 655f 7370 6563 730d 0a20 2020 2020  che_specs..     
-00004570: 2020 2073 656c 662e 5f5f 6469 6374 5f5f     self.__dict__
-00004580: 5b22 5f69 6e70 7574 5f73 7065 6322 5d20  ["_input_spec"] 
-00004590: 3d20 4e6f 6e65 0d0a 2020 2020 2020 2020  = None..        
-000045a0: 7365 6c66 2e5f 5f64 6963 745f 5f5b 225f  self.__dict__["_
-000045b0: 6f75 7470 7574 5f73 7065 6322 5d20 3d20  output_spec"] = 
-000045c0: 4e6f 6e65 0d0a 2020 2020 2020 2020 7365  None..        se
-000045d0: 6c66 2e62 6174 6368 5f73 697a 6520 3d20  lf.batch_size = 
-000045e0: 7365 6c66 2e62 6173 655f 656e 762e 6261  self.base_env.ba
-000045f0: 7463 685f 7369 7a65 0d0a 0d0a 2020 2020  tch_size....    
-00004600: 6465 6620 5f73 6574 5f65 6e76 2873 656c  def _set_env(sel
-00004610: 662c 2065 6e76 3a20 456e 7642 6173 652c  f, env: EnvBase,
-00004620: 2064 6576 6963 6529 202d 3e20 4e6f 6e65   device) -> None
-00004630: 3a0d 0a20 2020 2020 2020 2069 6620 6465  :..        if de
-00004640: 7669 6365 2021 3d20 656e 762e 6465 7669  vice != env.devi
-00004650: 6365 3a0d 0a20 2020 2020 2020 2020 2020  ce:..           
-00004660: 2065 6e76 203d 2065 6e76 2e74 6f28 6465   env = env.to(de
-00004670: 7669 6365 290d 0a20 2020 2020 2020 2073  vice)..        s
-00004680: 656c 662e 6261 7365 5f65 6e76 203d 2065  elf.base_env = e
-00004690: 6e76 0d0a 2020 2020 2020 2020 2320 7570  nv..        # up
-000046a0: 6461 7465 7320 6e65 6564 206e 6f74 2062  dates need not b
-000046b0: 6520 696e 706c 6163 652c 2061 7320 7472  e inplace, as tr
-000046c0: 616e 7366 6f72 6d73 206d 6179 206d 6f64  ansforms may mod
-000046d0: 6966 7920 7661 6c75 6573 206f 7574 2d70  ify values out-p
-000046e0: 6c61 6365 0d0a 2020 2020 2020 2020 7365  lace..        se
-000046f0: 6c66 2e62 6173 655f 656e 762e 5f69 6e70  lf.base_env._inp
-00004700: 6c61 6365 5f75 7064 6174 6520 3d20 4661  lace_update = Fa
-00004710: 6c73 650d 0a0d 0a20 2020 2040 7072 6f70  lse....    @prop
-00004720: 6572 7479 0d0a 2020 2020 6465 6620 7472  erty..    def tr
-00004730: 616e 7366 6f72 6d28 7365 6c66 2920 2d3e  ansform(self) ->
-00004740: 2054 7261 6e73 666f 726d 3a0d 0a20 2020   Transform:..   
-00004750: 2020 2020 2072 6574 7572 6e20 7365 6c66       return self
-00004760: 2e5f 7472 616e 7366 6f72 6d0d 0a0d 0a20  ._transform.... 
-00004770: 2020 2040 7472 616e 7366 6f72 6d2e 7365     @transform.se
-00004780: 7474 6572 0d0a 2020 2020 6465 6620 7472  tter..    def tr
-00004790: 616e 7366 6f72 6d28 7365 6c66 2c20 7472  ansform(self, tr
-000047a0: 616e 7366 6f72 6d3a 2054 7261 6e73 666f  ansform: Transfo
-000047b0: 726d 293a 0d0a 2020 2020 2020 2020 6966  rm):..        if
-000047c0: 206e 6f74 2069 7369 6e73 7461 6e63 6528   not isinstance(
-000047d0: 7472 616e 7366 6f72 6d2c 2054 7261 6e73  transform, Trans
-000047e0: 666f 726d 293a 0d0a 2020 2020 2020 2020  form):..        
-000047f0: 2020 2020 7261 6973 6520 5661 6c75 6545      raise ValueE
-00004800: 7272 6f72 280d 0a20 2020 2020 2020 2020  rror(..         
-00004810: 2020 2020 2020 2066 2222 2245 7870 6563         f"""Expec
-00004820: 7465 6420 6120 7472 616e 7366 6f72 6d20  ted a transform 
-00004830: 6f66 2074 7970 6520 746f 7263 6872 6c2e  of type torchrl.
-00004840: 656e 7673 2e74 7261 6e73 666f 726d 732e  envs.transforms.
-00004850: 5472 616e 7366 6f72 6d2c 0d0a 6275 7420  Transform,..but 
-00004860: 676f 7420 616e 206f 626a 6563 7420 6f66  got an object of
-00004870: 2074 7970 6520 7b74 7970 6528 7472 616e   type {type(tran
-00004880: 7366 6f72 6d29 7d2e 2222 220d 0a20 2020  sform)}."""..   
-00004890: 2020 2020 2020 2020 2029 0d0a 2020 2020           )..    
-000048a0: 2020 2020 7072 6576 5f74 7261 6e73 666f      prev_transfo
-000048b0: 726d 203d 2073 656c 662e 7472 616e 7366  rm = self.transf
-000048c0: 6f72 6d0d 0a20 2020 2020 2020 2069 6620  orm..        if 
-000048d0: 7072 6576 5f74 7261 6e73 666f 726d 2069  prev_transform i
-000048e0: 7320 6e6f 7420 4e6f 6e65 3a0d 0a20 2020  s not None:..   
-000048f0: 2020 2020 2020 2020 2070 7265 765f 7472           prev_tr
-00004900: 616e 7366 6f72 6d2e 656d 7074 795f 6361  ansform.empty_ca
-00004910: 6368 6528 290d 0a20 2020 2020 2020 2020  che()..         
-00004920: 2020 2070 7265 765f 7472 616e 7366 6f72     prev_transfor
-00004930: 6d2e 5f5f 6469 6374 5f5f 5b22 5f63 6f6e  m.__dict__["_con
-00004940: 7461 696e 6572 225d 203d 204e 6f6e 650d  tainer"] = None.
-00004950: 0a20 2020 2020 2020 2074 7261 6e73 666f  .        transfo
-00004960: 726d 2e73 6574 5f63 6f6e 7461 696e 6572  rm.set_container
-00004970: 2873 656c 6629 0d0a 2020 2020 2020 2020  (self)..        
-00004980: 7472 616e 7366 6f72 6d2e 6576 616c 2829  transform.eval()
-00004990: 0d0a 2020 2020 2020 2020 7365 6c66 2e5f  ..        self._
-000049a0: 7472 616e 7366 6f72 6d20 3d20 7472 616e  transform = tran
-000049b0: 7366 6f72 6d0d 0a0d 0a20 2020 2040 7072  sform....    @pr
-000049c0: 6f70 6572 7479 0d0a 2020 2020 6465 6620  operty..    def 
-000049d0: 6465 7669 6365 2873 656c 6629 202d 3e20  device(self) -> 
-000049e0: 626f 6f6c 3a0d 0a20 2020 2020 2020 2072  bool:..        r
-000049f0: 6574 7572 6e20 7365 6c66 2e62 6173 655f  eturn self.base_
-00004a00: 656e 762e 6465 7669 6365 0d0a 0d0a 2020  env.device....  
-00004a10: 2020 4064 6576 6963 652e 7365 7474 6572    @device.setter
-00004a20: 0d0a 2020 2020 6465 6620 6465 7669 6365  ..    def device
-00004a30: 2873 656c 662c 2076 616c 7565 293a 0d0a  (self, value):..
-00004a40: 2020 2020 2020 2020 7261 6973 6520 5275          raise Ru
-00004a50: 6e74 696d 6545 7272 6f72 2822 6465 7669  ntimeError("devi
-00004a60: 6365 2069 7320 6120 7265 6164 2d6f 6e6c  ce is a read-onl
-00004a70: 7920 7072 6f70 6572 7479 2229 0d0a 0d0a  y property")....
-00004a80: 2020 2020 4070 726f 7065 7274 790d 0a20      @property.. 
-00004a90: 2020 2064 6566 2062 6174 6368 5f6c 6f63     def batch_loc
-00004aa0: 6b65 6428 7365 6c66 2920 2d3e 2062 6f6f  ked(self) -> boo
-00004ab0: 6c3a 0d0a 2020 2020 2020 2020 7265 7475  l:..        retu
-00004ac0: 726e 2073 656c 662e 6261 7365 5f65 6e76  rn self.base_env
-00004ad0: 2e62 6174 6368 5f6c 6f63 6b65 640d 0a0d  .batch_locked...
-00004ae0: 0a20 2020 2040 6261 7463 685f 6c6f 636b  .    @batch_lock
-00004af0: 6564 2e73 6574 7465 720d 0a20 2020 2064  ed.setter..    d
-00004b00: 6566 2062 6174 6368 5f6c 6f63 6b65 6428  ef batch_locked(
-00004b10: 7365 6c66 2c20 7661 6c75 6529 3a0d 0a20  self, value):.. 
-00004b20: 2020 2020 2020 2072 6169 7365 2052 756e         raise Run
-00004b30: 7469 6d65 4572 726f 7228 2262 6174 6368  timeError("batch
-00004b40: 5f6c 6f63 6b65 6420 6973 2061 2072 6561  _locked is a rea
-00004b50: 642d 6f6e 6c79 2070 726f 7065 7274 7922  d-only property"
-00004b60: 290d 0a0d 0a20 2020 2040 7072 6f70 6572  )....    @proper
-00004b70: 7479 0d0a 2020 2020 6465 6620 7275 6e5f  ty..    def run_
-00004b80: 7479 7065 5f63 6865 636b 7328 7365 6c66  type_checks(self
-00004b90: 2920 2d3e 2062 6f6f 6c3a 0d0a 2020 2020  ) -> bool:..    
-00004ba0: 2020 2020 7265 7475 726e 2073 656c 662e      return self.
-00004bb0: 6261 7365 5f65 6e76 2e72 756e 5f74 7970  base_env.run_typ
-00004bc0: 655f 6368 6563 6b73 0d0a 0d0a 2020 2020  e_checks....    
-00004bd0: 4072 756e 5f74 7970 655f 6368 6563 6b73  @run_type_checks
-00004be0: 2e73 6574 7465 720d 0a20 2020 2064 6566  .setter..    def
-00004bf0: 2072 756e 5f74 7970 655f 6368 6563 6b73   run_type_checks
-00004c00: 2873 656c 662c 2076 616c 7565 293a 0d0a  (self, value):..
-00004c10: 2020 2020 2020 2020 7261 6973 6520 5275          raise Ru
-00004c20: 6e74 696d 6545 7272 6f72 280d 0a20 2020  ntimeError(..   
-00004c30: 2020 2020 2020 2020 2022 7275 6e5f 7479           "run_ty
-00004c40: 7065 5f63 6865 636b 7320 6973 2061 2072  pe_checks is a r
-00004c50: 6561 642d 6f6e 6c79 2070 726f 7065 7274  ead-only propert
-00004c60: 7920 666f 7220 5472 616e 7366 6f72 6d65  y for Transforme
-00004c70: 6445 6e76 7322 0d0a 2020 2020 2020 2020  dEnvs"..        
-00004c80: 290d 0a0d 0a20 2020 2040 7072 6f70 6572  )....    @proper
-00004c90: 7479 0d0a 2020 2020 6465 6620 5f69 6e70  ty..    def _inp
-00004ca0: 6c61 6365 5f75 7064 6174 6528 7365 6c66  lace_update(self
-00004cb0: 293a 0d0a 2020 2020 2020 2020 7265 7475  ):..        retu
+00000130: 2063 6f70 792c 2064 6565 7063 6f70 790d   copy, deepcopy.
+00000140: 0a66 726f 6d20 7465 7874 7772 6170 2069  .from textwrap i
+00000150: 6d70 6f72 7420 696e 6465 6e74 0d0a 6672  mport indent..fr
+00000160: 6f6d 2074 7970 696e 6720 696d 706f 7274  om typing import
+00000170: 2041 6e79 2c20 4c69 7374 2c20 4f70 7469   Any, List, Opti
+00000180: 6f6e 616c 2c20 4f72 6465 7265 6444 6963  onal, OrderedDic
+00000190: 742c 2053 6571 7565 6e63 652c 2054 7570  t, Sequence, Tup
+000001a0: 6c65 2c20 556e 696f 6e0d 0a0d 0a69 6d70  le, Union....imp
+000001b0: 6f72 7420 746f 7263 680d 0a66 726f 6d20  ort torch..from 
+000001c0: 7465 6e73 6f72 6469 6374 2e6e 6e20 696d  tensordict.nn im
+000001d0: 706f 7274 2064 6973 7061 7463 680d 0a66  port dispatch..f
+000001e0: 726f 6d20 7465 6e73 6f72 6469 6374 2e6e  rom tensordict.n
+000001f0: 6e2e 636f 6d6d 6f6e 2069 6d70 6f72 7420  n.common import 
+00000200: 5f73 6571 5f6f 665f 6e65 7374 6564 5f6b  _seq_of_nested_k
+00000210: 6579 5f63 6865 636b 0d0a 6672 6f6d 2074  ey_check..from t
+00000220: 656e 736f 7264 6963 742e 7465 6e73 6f72  ensordict.tensor
+00000230: 6469 6374 2069 6d70 6f72 7420 5465 6e73  dict import Tens
+00000240: 6f72 4469 6374 2c20 5465 6e73 6f72 4469  orDict, TensorDi
+00000250: 6374 4261 7365 0d0a 6672 6f6d 2074 656e  ctBase..from ten
+00000260: 736f 7264 6963 742e 7574 696c 7320 696d  sordict.utils im
+00000270: 706f 7274 2065 7870 616e 645f 6173 5f72  port expand_as_r
+00000280: 6967 6874 0d0a 6672 6f6d 2074 6f72 6368  ight..from torch
+00000290: 2069 6d70 6f72 7420 6e6e 2c20 5465 6e73   import nn, Tens
+000002a0: 6f72 0d0a 0d0a 6672 6f6d 2074 6f72 6368  or....from torch
+000002b0: 726c 2e64 6174 612e 7465 6e73 6f72 5f73  rl.data.tensor_s
+000002c0: 7065 6373 2069 6d70 6f72 7420 280d 0a20  pecs import (.. 
+000002d0: 2020 2042 696e 6172 7944 6973 6372 6574     BinaryDiscret
+000002e0: 6554 656e 736f 7253 7065 632c 0d0a 2020  eTensorSpec,..  
+000002f0: 2020 426f 756e 6465 6454 656e 736f 7253    BoundedTensorS
+00000300: 7065 632c 0d0a 2020 2020 436f 6d70 6f73  pec,..    Compos
+00000310: 6974 6553 7065 632c 0d0a 2020 2020 436f  iteSpec,..    Co
+00000320: 6e74 696e 756f 7573 426f 782c 0d0a 2020  ntinuousBox,..  
+00000330: 2020 4445 5649 4345 5f54 5950 494e 472c    DEVICE_TYPING,
+00000340: 0d0a 2020 2020 4469 7363 7265 7465 5465  ..    DiscreteTe
+00000350: 6e73 6f72 5370 6563 2c0d 0a20 2020 204f  nsorSpec,..    O
+00000360: 6e65 486f 7444 6973 6372 6574 6554 656e  neHotDiscreteTen
+00000370: 736f 7253 7065 632c 0d0a 2020 2020 5465  sorSpec,..    Te
+00000380: 6e73 6f72 5370 6563 2c0d 0a20 2020 2055  nsorSpec,..    U
+00000390: 6e62 6f75 6e64 6564 436f 6e74 696e 756f  nboundedContinuo
+000003a0: 7573 5465 6e73 6f72 5370 6563 2c0d 0a20  usTensorSpec,.. 
+000003b0: 2020 2055 6e62 6f75 6e64 6564 4469 7363     UnboundedDisc
+000003c0: 7265 7465 5465 6e73 6f72 5370 6563 2c0d  reteTensorSpec,.
+000003d0: 0a29 0d0a 6672 6f6d 2074 6f72 6368 726c  .)..from torchrl
+000003e0: 2e65 6e76 732e 636f 6d6d 6f6e 2069 6d70  .envs.common imp
+000003f0: 6f72 7420 456e 7642 6173 652c 206d 616b  ort EnvBase, mak
+00000400: 655f 7465 6e73 6f72 6469 6374 0d0a 6672  e_tensordict..fr
+00000410: 6f6d 2074 6f72 6368 726c 2e65 6e76 732e  om torchrl.envs.
+00000420: 7472 616e 7366 6f72 6d73 2069 6d70 6f72  transforms impor
+00000430: 7420 6675 6e63 7469 6f6e 616c 2061 7320  t functional as 
+00000440: 460d 0a66 726f 6d20 746f 7263 6872 6c2e  F..from torchrl.
+00000450: 656e 7673 2e74 7261 6e73 666f 726d 732e  envs.transforms.
+00000460: 7574 696c 7320 696d 706f 7274 2063 6865  utils import che
+00000470: 636b 5f66 696e 6974 650d 0a66 726f 6d20  ck_finite..from 
+00000480: 746f 7263 6872 6c2e 656e 7673 2e75 7469  torchrl.envs.uti
+00000490: 6c73 2069 6d70 6f72 7420 5f73 6f72 745f  ls import _sort_
+000004a0: 6b65 7973 2c20 7374 6570 5f6d 6470 0d0a  keys, step_mdp..
+000004b0: 6672 6f6d 2074 6f72 6368 726c 2e6f 626a  from torchrl.obj
+000004c0: 6563 7469 7665 732e 7661 6c75 652e 6675  ectives.value.fu
+000004d0: 6e63 7469 6f6e 616c 2069 6d70 6f72 7420  nctional import 
+000004e0: 7265 7761 7264 3267 6f0d 0a0d 0a74 7279  reward2go....try
+000004f0: 3a0d 0a20 2020 2066 726f 6d20 746f 7263  :..    from torc
+00000500: 6876 6973 696f 6e2e 7472 616e 7366 6f72  hvision.transfor
+00000510: 6d73 2e66 756e 6374 696f 6e61 6c20 696d  ms.functional im
+00000520: 706f 7274 2063 656e 7465 725f 6372 6f70  port center_crop
+00000530: 0d0a 0d0a 2020 2020 7472 793a 0d0a 2020  ....    try:..  
+00000540: 2020 2020 2020 6672 6f6d 2074 6f72 6368        from torch
+00000550: 7669 7369 6f6e 2e74 7261 6e73 666f 726d  vision.transform
+00000560: 732e 6675 6e63 7469 6f6e 616c 2069 6d70  s.functional imp
+00000570: 6f72 7420 496e 7465 7270 6f6c 6174 696f  ort Interpolatio
+00000580: 6e4d 6f64 652c 2072 6573 697a 650d 0a0d  nMode, resize...
+00000590: 0a20 2020 2020 2020 2064 6566 2069 6e74  .        def int
+000005a0: 6572 706f 6c61 7469 6f6e 5f66 6e28 696e  erpolation_fn(in
+000005b0: 7465 7270 6f6c 6174 696f 6e29 3a20 2023  terpolation):  #
+000005c0: 206e 6f71 613a 2044 3130 330d 0a20 2020   noqa: D103..   
+000005d0: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+000005e0: 496e 7465 7270 6f6c 6174 696f 6e4d 6f64  InterpolationMod
+000005f0: 6528 696e 7465 7270 6f6c 6174 696f 6e29  e(interpolation)
+00000600: 0d0a 0d0a 2020 2020 6578 6365 7074 2049  ....    except I
+00000610: 6d70 6f72 7445 7272 6f72 3a0d 0a0d 0a20  mportError:.... 
+00000620: 2020 2020 2020 2064 6566 2069 6e74 6572         def inter
+00000630: 706f 6c61 7469 6f6e 5f66 6e28 696e 7465  polation_fn(inte
+00000640: 7270 6f6c 6174 696f 6e29 3a20 2023 206e  rpolation):  # n
+00000650: 6f71 613a 2044 3130 330d 0a20 2020 2020  oqa: D103..     
+00000660: 2020 2020 2020 2072 6574 7572 6e20 696e         return in
+00000670: 7465 7270 6f6c 6174 696f 6e0d 0a0d 0a20  terpolation.... 
+00000680: 2020 2020 2020 2066 726f 6d20 746f 7263         from torc
+00000690: 6876 6973 696f 6e2e 7472 616e 7366 6f72  hvision.transfor
+000006a0: 6d73 2e66 756e 6374 696f 6e61 6c5f 7465  ms.functional_te
+000006b0: 6e73 6f72 2069 6d70 6f72 7420 7265 7369  nsor import resi
+000006c0: 7a65 0d0a 0d0a 2020 2020 5f68 6173 5f74  ze....    _has_t
+000006d0: 7620 3d20 5472 7565 0d0a 6578 6365 7074  v = True..except
+000006e0: 2049 6d70 6f72 7445 7272 6f72 3a0d 0a20   ImportError:.. 
+000006f0: 2020 205f 6861 735f 7476 203d 2046 616c     _has_tv = Fal
+00000700: 7365 0d0a 0d0a 494d 4147 455f 4b45 5953  se....IMAGE_KEYS
+00000710: 203d 205b 2270 6978 656c 7322 5d0d 0a5f   = ["pixels"].._
+00000720: 4d41 585f 4e4f 4f50 535f 5452 4941 4c53  MAX_NOOPS_TRIALS
+00000730: 203d 2031 300d 0a0d 0a46 4f52 5741 5244   = 10....FORWARD
+00000740: 5f4e 4f54 5f49 4d50 4c45 4d45 4e54 4544  _NOT_IMPLEMENTED
+00000750: 203d 2022 636c 6173 7320 7b7d 2063 616e   = "class {} can
+00000760: 6e6f 7420 6265 2065 7865 6375 7465 6420  not be executed 
+00000770: 7769 7468 6f75 7420 6120 7061 7265 6e74  without a parent
+00000780: 2220 2265 6e76 6972 6f6e 6d65 6e74 2e22  " "environment."
+00000790: 0d0a 0d0a 0d0a 6465 6620 5f61 7070 6c79  ......def _apply
+000007a0: 5f74 6f5f 636f 6d70 6f73 6974 6528 6675  _to_composite(fu
+000007b0: 6e63 7469 6f6e 293a 0d0a 2020 2020 6465  nction):..    de
+000007c0: 6620 6e65 775f 6675 6e28 7365 6c66 2c20  f new_fun(self, 
+000007d0: 6f62 7365 7276 6174 696f 6e5f 7370 6563  observation_spec
+000007e0: 293a 0d0a 2020 2020 2020 2020 6966 2069  ):..        if i
+000007f0: 7369 6e73 7461 6e63 6528 6f62 7365 7276  sinstance(observ
+00000800: 6174 696f 6e5f 7370 6563 2c20 436f 6d70  ation_spec, Comp
+00000810: 6f73 6974 6553 7065 6329 3a0d 0a20 2020  ositeSpec):..   
+00000820: 2020 2020 2020 2020 2064 203d 206f 6273           d = obs
+00000830: 6572 7661 7469 6f6e 5f73 7065 632e 5f73  ervation_spec._s
+00000840: 7065 6373 0d0a 2020 2020 2020 2020 2020  pecs..          
+00000850: 2020 666f 7220 696e 5f6b 6579 2c20 6f75    for in_key, ou
+00000860: 745f 6b65 7920 696e 207a 6970 2873 656c  t_key in zip(sel
+00000870: 662e 696e 5f6b 6579 732c 2073 656c 662e  f.in_keys, self.
+00000880: 6f75 745f 6b65 7973 293a 0d0a 2020 2020  out_keys):..    
+00000890: 2020 2020 2020 2020 2020 2020 6966 2069              if i
+000008a0: 6e5f 6b65 7920 696e 206f 6273 6572 7661  n_key in observa
+000008b0: 7469 6f6e 5f73 7065 632e 6b65 7973 2854  tion_spec.keys(T
+000008c0: 7275 652c 2054 7275 6529 3a0d 0a20 2020  rue, True):..   
+000008d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000008e0: 2064 5b6f 7574 5f6b 6579 5d20 3d20 6675   d[out_key] = fu
+000008f0: 6e63 7469 6f6e 2873 656c 662c 206f 6273  nction(self, obs
+00000900: 6572 7661 7469 6f6e 5f73 7065 635b 696e  ervation_spec[in
+00000910: 5f6b 6579 5d2e 636c 6f6e 6528 2929 0d0a  _key].clone())..
+00000920: 2020 2020 2020 2020 2020 2020 7265 7475              retu
+00000930: 726e 2043 6f6d 706f 7369 7465 5370 6563  rn CompositeSpec
+00000940: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
+00000950: 2020 2064 2c20 7368 6170 653d 6f62 7365     d, shape=obse
+00000960: 7276 6174 696f 6e5f 7370 6563 2e73 6861  rvation_spec.sha
+00000970: 7065 2c20 6465 7669 6365 3d6f 6273 6572  pe, device=obser
+00000980: 7661 7469 6f6e 5f73 7065 632e 6465 7669  vation_spec.devi
+00000990: 6365 0d0a 2020 2020 2020 2020 2020 2020  ce..            
+000009a0: 290d 0a20 2020 2020 2020 2065 6c73 653a  )..        else:
+000009b0: 0d0a 2020 2020 2020 2020 2020 2020 7265  ..            re
+000009c0: 7475 726e 2066 756e 6374 696f 6e28 7365  turn function(se
+000009d0: 6c66 2c20 6f62 7365 7276 6174 696f 6e5f  lf, observation_
+000009e0: 7370 6563 290d 0a0d 0a20 2020 2072 6574  spec)....    ret
+000009f0: 7572 6e20 6e65 775f 6675 6e0d 0a0d 0a0d  urn new_fun.....
+00000a00: 0a64 6566 205f 6170 706c 795f 746f 5f63  .def _apply_to_c
+00000a10: 6f6d 706f 7369 7465 5f69 6e76 2866 756e  omposite_inv(fun
+00000a20: 6374 696f 6e29 3a0d 0a20 2020 2023 2043  ction):..    # C
+00000a30: 6861 6e67 6573 2074 6865 2069 6e70 7574  hanges the input
+00000a40: 5f73 7065 6320 666f 6c6c 6f77 696e 6720  _spec following 
+00000a50: 6120 7472 616e 7366 6f72 6d20 6675 6e63  a transform func
+00000a60: 7469 6f6e 2e0d 0a20 2020 2023 2054 6865  tion...    # The
+00000a70: 2075 7361 6765 2069 733a 2069 6620 616e   usage is: if an
+00000a80: 2065 6e76 2065 7870 6563 7473 2061 2063   env expects a c
+00000a90: 6572 7461 696e 2069 6e70 7574 2028 652e  ertain input (e.
+00000aa0: 672e 2061 2064 6f75 626c 6520 7465 6e73  g. a double tens
+00000ab0: 6f72 290d 0a20 2020 2023 2062 7574 2074  or)..    # but t
+00000ac0: 6865 2069 6e70 7574 2068 6173 2074 6f20  he input has to 
+00000ad0: 6265 2074 7261 6e73 666f 726d 6564 2028  be transformed (
+00000ae0: 652e 672e 2069 7420 6973 2066 6c6f 6174  e.g. it is float
+00000af0: 292c 2074 6869 7320 6675 6e63 7469 6f6e  ), this function
+00000b00: 2077 696c 6c0d 0a20 2020 2023 206d 6f64   will..    # mod
+00000b10: 6966 7920 7468 6520 7370 6563 2074 6f20  ify the spec to 
+00000b20: 6765 7420 6120 7370 6563 2074 6861 7420  get a spec that 
+00000b30: 6672 6f6d 2074 6865 206f 7574 7369 6465  from the outside
+00000b40: 206d 6174 6368 6573 2077 6861 7420 6973   matches what is
+00000b50: 2067 6976 656e 0d0a 2020 2020 2320 2869   given..    # (i
+00000b60: 6520 6120 666c 6f61 7429 2e0d 0a20 2020  e a float)...   
+00000b70: 2023 204e 6f77 2073 696e 6365 2045 6e76   # Now since Env
+00000b80: 4261 7365 2e73 7465 7020 6967 6e6f 7265  Base.step ignore
+00000b90: 7320 6e65 7720 696e 7075 7473 2028 6965  s new inputs (ie
+00000ba0: 2074 6865 2072 6f6f 7420 6c65 7665 6c20   the root level 
+00000bb0: 6f66 2074 6865 0d0a 2020 2020 2320 7465  of the..    # te
+00000bc0: 6e73 6f72 2069 7320 6e6f 7420 7570 6461  nsor is not upda
+00000bd0: 7465 6429 2061 6e20 6f75 745f 6b65 7920  ted) an out_key 
+00000be0: 7468 6174 2064 6f65 7320 6e6f 7420 6d61  that does not ma
+00000bf0: 7463 6820 7468 6520 696e 5f6b 6579 2068  tch the in_key h
+00000c00: 6173 0d0a 2020 2020 2320 6e6f 2065 6666  as..    # no eff
+00000c10: 6563 7420 6f6e 2074 6865 2073 7065 632e  ect on the spec.
+00000c20: 0d0a 2020 2020 6465 6620 6e65 775f 6675  ..    def new_fu
+00000c30: 6e28 7365 6c66 2c20 696e 7075 745f 7370  n(self, input_sp
+00000c40: 6563 293a 0d0a 2020 2020 2020 2020 6966  ec):..        if
+00000c50: 2069 7369 6e73 7461 6e63 6528 696e 7075   isinstance(inpu
+00000c60: 745f 7370 6563 2c20 436f 6d70 6f73 6974  t_spec, Composit
+00000c70: 6553 7065 6329 3a0d 0a20 2020 2020 2020  eSpec):..       
+00000c80: 2020 2020 2064 203d 2069 6e70 7574 5f73       d = input_s
+00000c90: 7065 632e 5f73 7065 6373 0d0a 2020 2020  pec._specs..    
+00000ca0: 2020 2020 2020 2020 666f 7220 696e 5f6b          for in_k
+00000cb0: 6579 2c20 6f75 745f 6b65 7920 696e 207a  ey, out_key in z
+00000cc0: 6970 2873 656c 662e 696e 5f6b 6579 735f  ip(self.in_keys_
+00000cd0: 696e 762c 2073 656c 662e 6f75 745f 6b65  inv, self.out_ke
+00000ce0: 7973 5f69 6e76 293a 0d0a 2020 2020 2020  ys_inv):..      
+00000cf0: 2020 2020 2020 2020 2020 6966 2069 6e5f            if in_
+00000d00: 6b65 7920 696e 2069 6e70 7574 5f73 7065  key in input_spe
+00000d10: 632e 6b65 7973 2854 7275 652c 2054 7275  c.keys(True, Tru
+00000d20: 6529 2061 6e64 2069 6e5f 6b65 7920 3d3d  e) and in_key ==
+00000d30: 206f 7574 5f6b 6579 3a0d 0a20 2020 2020   out_key:..     
+00000d40: 2020 2020 2020 2020 2020 2020 2020 2064                 d
+00000d50: 5b6f 7574 5f6b 6579 5d20 3d20 6675 6e63  [out_key] = func
+00000d60: 7469 6f6e 2873 656c 662c 2069 6e70 7574  tion(self, input
+00000d70: 5f73 7065 635b 696e 5f6b 6579 5d2e 636c  _spec[in_key].cl
+00000d80: 6f6e 6528 2929 0d0a 2020 2020 2020 2020  one())..        
+00000d90: 2020 2020 7265 7475 726e 2043 6f6d 706f      return Compo
+00000da0: 7369 7465 5370 6563 2864 2c20 7368 6170  siteSpec(d, shap
+00000db0: 653d 696e 7075 745f 7370 6563 2e73 6861  e=input_spec.sha
+00000dc0: 7065 2c20 6465 7669 6365 3d69 6e70 7574  pe, device=input
+00000dd0: 5f73 7065 632e 6465 7669 6365 290d 0a20  _spec.device).. 
+00000de0: 2020 2020 2020 2065 6c73 653a 0d0a 2020         else:..  
+00000df0: 2020 2020 2020 2020 2020 7265 7475 726e            return
+00000e00: 2066 756e 6374 696f 6e28 7365 6c66 2c20   function(self, 
+00000e10: 696e 7075 745f 7370 6563 290d 0a0d 0a20  input_spec).... 
+00000e20: 2020 2072 6574 7572 6e20 6e65 775f 6675     return new_fu
+00000e30: 6e0d 0a0d 0a0d 0a63 6c61 7373 2054 7261  n......class Tra
+00000e40: 6e73 666f 726d 286e 6e2e 4d6f 6475 6c65  nsform(nn.Module
+00000e50: 293a 0d0a 2020 2020 2222 2245 6e76 6972  ):..    """Envir
+00000e60: 6f6e 6d65 6e74 2074 7261 6e73 666f 726d  onment transform
+00000e70: 2070 6172 656e 7420 636c 6173 732e 0d0a   parent class...
+00000e80: 0d0a 2020 2020 496e 2070 7269 6e63 6970  ..    In princip
+00000e90: 6c65 2c20 6120 7472 616e 7366 6f72 6d20  le, a transform 
+00000ea0: 7265 6365 6976 6573 2061 2074 656e 736f  receives a tenso
+00000eb0: 7264 6963 7420 6173 2069 6e70 7574 2061  rdict as input a
+00000ec0: 6e64 2072 6574 7572 6e73 2028 0d0a 2020  nd returns (..  
+00000ed0: 2020 7468 6520 7361 6d65 206f 7220 616e    the same or an
+00000ee0: 6f74 6865 7229 2074 656e 736f 7264 6963  other) tensordic
+00000ef0: 7420 6173 206f 7574 7075 742c 2077 6865  t as output, whe
+00000f00: 7265 2061 2073 6572 6965 7320 6f66 2076  re a series of v
+00000f10: 616c 7565 7320 6861 7665 0d0a 2020 2020  alues have..    
+00000f20: 6265 656e 206d 6f64 6966 6965 6420 6f72  been modified or
+00000f30: 2063 7265 6174 6564 2077 6974 6820 6120   created with a 
+00000f40: 6e65 7720 6b65 792e 2057 6865 6e20 696e  new key. When in
+00000f50: 7374 616e 7469 6174 696e 6720 6120 6e65  stantiating a ne
+00000f60: 770d 0a20 2020 2074 7261 6e73 666f 726d  w..    transform
+00000f70: 2c20 7468 6520 6b65 7973 2074 6861 7420  , the keys that 
+00000f80: 6172 6520 746f 2062 6520 7265 6164 2066  are to be read f
+00000f90: 726f 6d20 6172 6520 7061 7373 6564 2074  rom are passed t
+00000fa0: 6f20 7468 650d 0a20 2020 2063 6f6e 7374  o the..    const
+00000fb0: 7275 6374 6f72 2076 6961 2074 6865 203a  ructor via the :
+00000fc0: 6f62 6a3a 606b 6579 7360 2061 7267 756d  obj:`keys` argum
+00000fd0: 656e 742e 0d0a 0d0a 2020 2020 5472 616e  ent.....    Tran
+00000fe0: 7366 6f72 6d73 2061 7265 2074 6f20 6265  sforms are to be
+00000ff0: 2063 6f6d 6269 6e65 6420 7769 7468 2074   combined with t
+00001000: 6865 6972 2074 6172 6765 7420 656e 7669  heir target envi
+00001010: 726f 6e6d 656e 7473 2077 6974 6820 7468  ronments with th
+00001020: 650d 0a20 2020 2054 7261 6e73 666f 726d  e..    Transform
+00001030: 6564 456e 7620 636c 6173 732c 2077 6869  edEnv class, whi
+00001040: 6368 2074 616b 6573 2061 7320 6172 6775  ch takes as argu
+00001050: 6d65 6e74 7320 616e 203a 6f62 6a3a 6045  ments an :obj:`E
+00001060: 6e76 4261 7365 6020 696e 7374 616e 6365  nvBase` instance
+00001070: 0d0a 2020 2020 616e 6420 6120 7472 616e  ..    and a tran
+00001080: 7366 6f72 6d2e 2049 6620 6d75 6c74 6970  sform. If multip
+00001090: 6c65 2074 7261 6e73 666f 726d 7320 6172  le transforms ar
+000010a0: 6520 746f 2062 6520 7573 6564 2c20 7468  e to be used, th
+000010b0: 6579 2063 616e 2062 650d 0a20 2020 2063  ey can be..    c
+000010c0: 6f6e 6361 7465 6e61 7465 6420 7573 696e  oncatenated usin
+000010d0: 6720 7468 6520 3a6f 626a 3a60 436f 6d70  g the :obj:`Comp
+000010e0: 6f73 6560 2063 6c61 7373 2e0d 0a20 2020  ose` class...   
+000010f0: 2041 2074 7261 6e73 666f 726d 2063 616e   A transform can
+00001100: 2062 6520 7374 6174 656c 6573 7320 6f72   be stateless or
+00001110: 2073 7461 7465 6675 6c20 2865 2e67 2e20   stateful (e.g. 
+00001120: 4361 7454 7261 6e73 666f 726d 292e 2042  CatTransform). B
+00001130: 6563 6175 7365 206f 660d 0a20 2020 2074  ecause of..    t
+00001140: 6869 732c 2054 7261 6e73 666f 726d 7320  his, Transforms 
+00001150: 7375 7070 6f72 7420 7468 6520 3a6f 626a  support the :obj
+00001160: 3a60 7265 7365 7460 206f 7065 7261 7469  :`reset` operati
+00001170: 6f6e 2c20 7768 6963 6820 7368 6f75 6c64  on, which should
+00001180: 2072 6573 6574 2074 6865 0d0a 2020 2020   reset the..    
+00001190: 7472 616e 7366 6f72 6d20 746f 2069 7473  transform to its
+000011a0: 2069 6e69 7469 616c 2073 7461 7465 2028   initial state (
+000011b0: 7375 6368 2074 6861 7420 7375 6363 6573  such that succes
+000011c0: 7369 7665 2074 7261 6a65 6374 6f72 6965  sive trajectorie
+000011d0: 7320 6172 6520 6b65 7074 0d0a 2020 2020  s are kept..    
+000011e0: 696e 6465 7065 6e64 656e 7429 2e0d 0a0d  independent)....
+000011f0: 0a20 2020 204e 6f74 6162 6c79 2c20 3a6f  .    Notably, :o
+00001200: 626a 3a60 5472 616e 7366 6f72 6d60 2073  bj:`Transform` s
+00001210: 7562 636c 6173 7365 7320 7461 6b65 2063  ubclasses take c
+00001220: 6172 6520 6f66 2074 7261 6e73 666f 726d  are of transform
+00001230: 696e 6720 7468 6520 6166 6665 6374 6564  ing the affected
+00001240: 0d0a 2020 2020 7370 6563 7320 6672 6f6d  ..    specs from
+00001250: 2061 6e20 656e 7669 726f 6e6d 656e 743a   an environment:
+00001260: 2077 6865 6e20 7175 6572 7969 6e67 0d0a   when querying..
+00001270: 2020 2020 6074 7261 6e73 666f 726d 6564      `transformed
+00001280: 5f65 6e76 2e6f 6273 6572 7661 7469 6f6e  _env.observation
+00001290: 5f73 7065 6360 2c20 7468 6520 7265 7375  _spec`, the resu
+000012a0: 6c74 696e 6720 6f62 6a65 6374 7320 7769  lting objects wi
+000012b0: 6c6c 2064 6573 6372 6962 650d 0a20 2020  ll describe..   
+000012c0: 2074 6865 2073 7065 6373 206f 6620 7468   the specs of th
+000012d0: 6520 7472 616e 7366 6f72 6d65 645f 696e  e transformed_in
+000012e0: 2074 656e 736f 7273 2e0d 0a0d 0a20 2020   tensors.....   
+000012f0: 2022 2222 0d0a 0d0a 2020 2020 696e 7665   """....    inve
+00001300: 7274 6962 6c65 203d 2046 616c 7365 0d0a  rtible = False..
+00001310: 0d0a 2020 2020 6465 6620 5f5f 696e 6974  ..    def __init
+00001320: 5f5f 280d 0a20 2020 2020 2020 2073 656c  __(..        sel
+00001330: 662c 0d0a 2020 2020 2020 2020 696e 5f6b  f,..        in_k
+00001340: 6579 733a 2053 6571 7565 6e63 655b 7374  eys: Sequence[st
+00001350: 725d 2c0d 0a20 2020 2020 2020 206f 7574  r],..        out
+00001360: 5f6b 6579 733a 204f 7074 696f 6e61 6c5b  _keys: Optional[
+00001370: 5365 7175 656e 6365 5b73 7472 5d5d 203d  Sequence[str]] =
+00001380: 204e 6f6e 652c 0d0a 2020 2020 2020 2020   None,..        
+00001390: 696e 5f6b 6579 735f 696e 763a 204f 7074  in_keys_inv: Opt
+000013a0: 696f 6e61 6c5b 5365 7175 656e 6365 5b73  ional[Sequence[s
+000013b0: 7472 5d5d 203d 204e 6f6e 652c 0d0a 2020  tr]] = None,..  
+000013c0: 2020 2020 2020 6f75 745f 6b65 7973 5f69        out_keys_i
+000013d0: 6e76 3a20 4f70 7469 6f6e 616c 5b53 6571  nv: Optional[Seq
+000013e0: 7565 6e63 655b 7374 725d 5d20 3d20 4e6f  uence[str]] = No
+000013f0: 6e65 2c0d 0a20 2020 2029 3a0d 0a20 2020  ne,..    ):..   
+00001400: 2020 2020 2073 7570 6572 2829 2e5f 5f69       super().__i
+00001410: 6e69 745f 5f28 290d 0a20 2020 2020 2020  nit__()..       
+00001420: 2069 6620 6973 696e 7374 616e 6365 2869   if isinstance(i
+00001430: 6e5f 6b65 7973 2c20 7374 7229 3a0d 0a20  n_keys, str):.. 
+00001440: 2020 2020 2020 2020 2020 2069 6e5f 6b65             in_ke
+00001450: 7973 203d 205b 696e 5f6b 6579 735d 0d0a  ys = [in_keys]..
+00001460: 0d0a 2020 2020 2020 2020 7365 6c66 2e69  ..        self.i
+00001470: 6e5f 6b65 7973 203d 2069 6e5f 6b65 7973  n_keys = in_keys
+00001480: 0d0a 2020 2020 2020 2020 6966 206f 7574  ..        if out
+00001490: 5f6b 6579 7320 6973 204e 6f6e 653a 0d0a  _keys is None:..
+000014a0: 2020 2020 2020 2020 2020 2020 6f75 745f              out_
+000014b0: 6b65 7973 203d 2063 6f70 7928 7365 6c66  keys = copy(self
+000014c0: 2e69 6e5f 6b65 7973 290d 0a20 2020 2020  .in_keys)..     
+000014d0: 2020 2073 656c 662e 6f75 745f 6b65 7973     self.out_keys
+000014e0: 203d 206f 7574 5f6b 6579 730d 0a20 2020   = out_keys..   
+000014f0: 2020 2020 2069 6620 696e 5f6b 6579 735f       if in_keys_
+00001500: 696e 7620 6973 204e 6f6e 653a 0d0a 2020  inv is None:..  
+00001510: 2020 2020 2020 2020 2020 696e 5f6b 6579            in_key
+00001520: 735f 696e 7620 3d20 5b5d 0d0a 2020 2020  s_inv = []..    
+00001530: 2020 2020 7365 6c66 2e69 6e5f 6b65 7973      self.in_keys
+00001540: 5f69 6e76 203d 2069 6e5f 6b65 7973 5f69  _inv = in_keys_i
+00001550: 6e76 0d0a 2020 2020 2020 2020 6966 206f  nv..        if o
+00001560: 7574 5f6b 6579 735f 696e 7620 6973 204e  ut_keys_inv is N
+00001570: 6f6e 653a 0d0a 2020 2020 2020 2020 2020  one:..          
+00001580: 2020 6f75 745f 6b65 7973 5f69 6e76 203d    out_keys_inv =
+00001590: 2063 6f70 7928 7365 6c66 2e69 6e5f 6b65   copy(self.in_ke
+000015a0: 7973 5f69 6e76 290d 0a20 2020 2020 2020  ys_inv)..       
+000015b0: 2073 656c 662e 6f75 745f 6b65 7973 5f69   self.out_keys_i
+000015c0: 6e76 203d 206f 7574 5f6b 6579 735f 696e  nv = out_keys_in
+000015d0: 760d 0a20 2020 2020 2020 2073 656c 662e  v..        self.
+000015e0: 5f6d 6973 7369 6e67 5f74 6f6c 6572 616e  _missing_toleran
+000015f0: 6365 203d 2046 616c 7365 0d0a 2020 2020  ce = False..    
+00001600: 2020 2020 7365 6c66 2e5f 5f64 6963 745f      self.__dict_
+00001610: 5f5b 225f 636f 6e74 6169 6e65 7222 5d20  _["_container"] 
+00001620: 3d20 4e6f 6e65 0d0a 2020 2020 2020 2020  = None..        
+00001630: 7365 6c66 2e5f 5f64 6963 745f 5f5b 225f  self.__dict__["_
+00001640: 7061 7265 6e74 225d 203d 204e 6f6e 650d  parent"] = None.
+00001650: 0a0d 0a20 2020 2064 6566 2072 6573 6574  ...    def reset
+00001660: 2873 656c 662c 2074 656e 736f 7264 6963  (self, tensordic
+00001670: 743a 2054 656e 736f 7244 6963 7442 6173  t: TensorDictBas
+00001680: 6529 202d 3e20 5465 6e73 6f72 4469 6374  e) -> TensorDict
+00001690: 4261 7365 3a0d 0a20 2020 2020 2020 2022  Base:..        "
+000016a0: 2222 5265 7365 7473 2061 2074 7261 6e66  ""Resets a tranf
+000016b0: 6f72 6d20 6966 2069 7420 6973 2073 7461  orm if it is sta
+000016c0: 7465 6675 6c2e 2222 220d 0a20 2020 2020  teful."""..     
+000016d0: 2020 2072 6574 7572 6e20 7465 6e73 6f72     return tensor
+000016e0: 6469 6374 0d0a 0d0a 2020 2020 6465 6620  dict....    def 
+000016f0: 696e 6974 2873 656c 662c 2074 656e 736f  init(self, tenso
+00001700: 7264 6963 7429 202d 3e20 4e6f 6e65 3a0d  rdict) -> None:.
+00001710: 0a20 2020 2020 2020 2070 6173 730d 0a0d  .        pass...
+00001720: 0a20 2020 2064 6566 205f 6170 706c 795f  .    def _apply_
+00001730: 7472 616e 7366 6f72 6d28 7365 6c66 2c20  transform(self, 
+00001740: 6f62 733a 2074 6f72 6368 2e54 656e 736f  obs: torch.Tenso
+00001750: 7229 202d 3e20 4e6f 6e65 3a0d 0a20 2020  r) -> None:..   
+00001760: 2020 2020 2022 2222 4170 706c 6965 7320       """Applies 
+00001770: 7468 6520 7472 616e 7366 6f72 6d20 746f  the transform to
+00001780: 2061 2074 656e 736f 722e 0d0a 0d0a 2020   a tensor.....  
+00001790: 2020 2020 2020 5468 6973 206f 7065 7261        This opera
+000017a0: 7469 6f6e 2063 616e 2062 6520 6361 6c6c  tion can be call
+000017b0: 6564 206d 756c 7469 706c 6520 7469 6d65  ed multiple time
+000017c0: 7320 2869 6620 6d75 6c74 6970 6c65 7320  s (if multiples 
+000017d0: 6b65 7973 206f 6620 7468 650d 0a20 2020  keys of the..   
+000017e0: 2020 2020 2074 656e 736f 7264 6963 7420       tensordict 
+000017f0: 6d61 7463 6820 7468 6520 6b65 7973 206f  match the keys o
+00001800: 6620 7468 6520 7472 616e 7366 6f72 6d29  f the transform)
+00001810: 2e0d 0a0d 0a20 2020 2020 2020 2022 2222  .....        """
+00001820: 0d0a 2020 2020 2020 2020 7261 6973 6520  ..        raise 
+00001830: 4e6f 7449 6d70 6c65 6d65 6e74 6564 4572  NotImplementedEr
+00001840: 726f 7228 0d0a 2020 2020 2020 2020 2020  ror(..          
+00001850: 2020 6622 7b73 656c 662e 5f5f 636c 6173    f"{self.__clas
+00001860: 735f 5f2e 5f5f 6e61 6d65 5f5f 7d5f 6170  s__.__name__}_ap
+00001870: 706c 795f 7472 616e 7366 6f72 6d20 6973  ply_transform is
+00001880: 206e 6f74 2063 6f64 6564 2e20 4966 2074   not coded. If t
+00001890: 6865 2074 7261 6e73 666f 726d 2069 7320  he transform is 
+000018a0: 636f 6465 6420 696e 2022 0d0a 2020 2020  coded in "..    
+000018b0: 2020 2020 2020 2020 2274 7261 6e73 666f          "transfo
+000018c0: 726d 2e5f 6361 6c6c 2c20 6d61 6b65 2073  rm._call, make s
+000018d0: 7572 6520 7468 6174 2074 6869 7320 6d65  ure that this me
+000018e0: 7468 6f64 2069 7320 6361 6c6c 6564 2069  thod is called i
+000018f0: 6e73 7465 6164 206f 6622 0d0a 2020 2020  nstead of"..    
+00001900: 2020 2020 2020 2020 2274 7261 6e73 666f          "transfo
+00001910: 726d 2e66 6f72 7761 7264 2c20 7768 6963  rm.forward, whic
+00001920: 6820 6973 2072 6573 6572 7665 6420 666f  h is reserved fo
+00001930: 7220 7573 6167 6520 696e 7369 6465 206e  r usage inside n
+00001940: 6e2e 4d6f 6475 6c65 7322 0d0a 2020 2020  n.Modules"..    
+00001950: 2020 2020 2020 2020 226f 7220 6170 7065          "or appe
+00001960: 6e64 6564 2074 6f20 6120 7265 706c 6179  nded to a replay
+00001970: 2062 7566 6665 722e 220d 0a20 2020 2020   buffer."..     
+00001980: 2020 2029 0d0a 0d0a 2020 2020 6465 6620     )....    def 
+00001990: 5f63 616c 6c28 7365 6c66 2c20 7465 6e73  _call(self, tens
+000019a0: 6f72 6469 6374 3a20 5465 6e73 6f72 4469  ordict: TensorDi
+000019b0: 6374 4261 7365 2920 2d3e 2054 656e 736f  ctBase) -> Tenso
+000019c0: 7244 6963 7442 6173 653a 0d0a 2020 2020  rDictBase:..    
+000019d0: 2020 2020 2222 2252 6561 6473 2074 6865      """Reads the
+000019e0: 2069 6e70 7574 2074 656e 736f 7264 6963   input tensordic
+000019f0: 742c 2061 6e64 2066 6f72 2074 6865 2073  t, and for the s
+00001a00: 656c 6563 7465 6420 6b65 7973 2c20 6170  elected keys, ap
+00001a10: 706c 6965 7320 7468 6520 7472 616e 7366  plies the transf
+00001a20: 6f72 6d2e 0d0a 0d0a 2020 2020 2020 2020  orm.....        
+00001a30: 466f 7220 616e 7920 6f70 6572 6174 696f  For any operatio
+00001a40: 6e20 7468 6174 2072 656c 6174 6573 2065  n that relates e
+00001a50: 7863 6c75 7369 7665 6c79 2074 6f20 7468  xclusively to th
+00001a60: 6520 7061 7265 6e74 2065 6e76 2028 652e  e parent env (e.
+00001a70: 672e 2046 7261 6d65 536b 6970 292c 0d0a  g. FrameSkip),..
+00001a80: 2020 2020 2020 2020 6d6f 6469 6679 2074          modify t
+00001a90: 6865 205f 7374 6570 206d 6574 686f 6420  he _step method 
+00001aa0: 696e 7374 6561 642e 203a 6d65 7468 3a60  instead. :meth:`
+00001ab0: 7e2e 5f63 616c 6c60 2073 686f 756c 6420  ~._call` should 
+00001ac0: 6f6e 6c79 2062 6520 6f76 6572 7772 6974  only be overwrit
+00001ad0: 7465 6e0d 0a20 2020 2020 2020 2069 6620  ten..        if 
+00001ae0: 6120 6d6f 6469 6669 6361 7469 6f6e 206f  a modification o
+00001af0: 6620 7468 6520 696e 7075 7420 7465 6e73  f the input tens
+00001b00: 6f72 6469 6374 2069 7320 6e65 6564 6564  ordict is needed
+00001b10: 2e0d 0a0d 0a20 2020 2020 2020 203a 6d65  .....        :me
+00001b20: 7468 3a60 7e2e 5f63 616c 6c60 2077 696c  th:`~._call` wil
+00001b30: 6c20 6265 2063 616c 6c65 6420 6279 203a  l be called by :
+00001b40: 6d65 7468 3a60 5472 616e 7366 6f72 6d65  meth:`Transforme
+00001b50: 6445 6e76 2e73 7465 7060 2061 6e64 0d0a  dEnv.step` and..
+00001b60: 2020 2020 2020 2020 3a6d 6574 683a 6054          :meth:`T
+00001b70: 7261 6e73 666f 726d 6564 456e 762e 7265  ransformedEnv.re
+00001b80: 7365 7460 2e0d 0a0d 0a20 2020 2020 2020  set`.....       
+00001b90: 2022 2222 0d0a 2020 2020 2020 2020 666f   """..        fo
+00001ba0: 7220 696e 5f6b 6579 2c20 6f75 745f 6b65  r in_key, out_ke
+00001bb0: 7920 696e 207a 6970 2873 656c 662e 696e  y in zip(self.in
+00001bc0: 5f6b 6579 732c 2073 656c 662e 6f75 745f  _keys, self.out_
+00001bd0: 6b65 7973 293a 0d0a 2020 2020 2020 2020  keys):..        
+00001be0: 2020 2020 6966 2069 6e5f 6b65 7920 696e      if in_key in
+00001bf0: 2074 656e 736f 7264 6963 742e 6b65 7973   tensordict.keys
+00001c00: 2869 6e63 6c75 6465 5f6e 6573 7465 643d  (include_nested=
+00001c10: 5472 7565 293a 0d0a 2020 2020 2020 2020  True):..        
+00001c20: 2020 2020 2020 2020 6f62 7365 7276 6174          observat
+00001c30: 696f 6e20 3d20 7365 6c66 2e5f 6170 706c  ion = self._appl
+00001c40: 795f 7472 616e 7366 6f72 6d28 7465 6e73  y_transform(tens
+00001c50: 6f72 6469 6374 2e67 6574 2869 6e5f 6b65  ordict.get(in_ke
+00001c60: 7929 290d 0a20 2020 2020 2020 2020 2020  y))..           
+00001c70: 2020 2020 2074 656e 736f 7264 6963 742e       tensordict.
+00001c80: 7365 7428 0d0a 2020 2020 2020 2020 2020  set(..          
+00001c90: 2020 2020 2020 2020 2020 6f75 745f 6b65            out_ke
+00001ca0: 792c 0d0a 2020 2020 2020 2020 2020 2020  y,..            
+00001cb0: 2020 2020 2020 2020 6f62 7365 7276 6174          observat
+00001cc0: 696f 6e2c 0d0a 2020 2020 2020 2020 2020  ion,..          
+00001cd0: 2020 2020 2020 290d 0a20 2020 2020 2020        )..       
+00001ce0: 2020 2020 2065 6c69 6620 6e6f 7420 7365       elif not se
+00001cf0: 6c66 2e6d 6973 7369 6e67 5f74 6f6c 6572  lf.missing_toler
+00001d00: 616e 6365 3a0d 0a20 2020 2020 2020 2020  ance:..         
+00001d10: 2020 2020 2020 2072 6169 7365 204b 6579         raise Key
+00001d20: 4572 726f 7228 0d0a 2020 2020 2020 2020  Error(..        
+00001d30: 2020 2020 2020 2020 2020 2020 6622 7b73              f"{s
+00001d40: 656c 667d 3a20 277b 696e 5f6b 6579 7d27  elf}: '{in_key}'
+00001d50: 206e 6f74 2066 6f75 6e64 2069 6e20 7465   not found in te
+00001d60: 6e73 6f72 6469 6374 207b 7465 6e73 6f72  nsordict {tensor
+00001d70: 6469 6374 7d22 0d0a 2020 2020 2020 2020  dict}"..        
+00001d80: 2020 2020 2020 2020 290d 0a20 2020 2020          )..     
+00001d90: 2020 2072 6574 7572 6e20 7465 6e73 6f72     return tensor
+00001da0: 6469 6374 0d0a 0d0a 2020 2020 4064 6973  dict....    @dis
+00001db0: 7061 7463 6828 736f 7572 6365 3d22 696e  patch(source="in
+00001dc0: 5f6b 6579 7322 2c20 6465 7374 3d22 6f75  _keys", dest="ou
+00001dd0: 745f 6b65 7973 2229 0d0a 2020 2020 6465  t_keys")..    de
+00001de0: 6620 666f 7277 6172 6428 7365 6c66 2c20  f forward(self, 
+00001df0: 7465 6e73 6f72 6469 6374 3a20 5465 6e73  tensordict: Tens
+00001e00: 6f72 4469 6374 4261 7365 2920 2d3e 2054  orDictBase) -> T
+00001e10: 656e 736f 7244 6963 7442 6173 653a 0d0a  ensorDictBase:..
+00001e20: 2020 2020 2020 2020 2222 2252 6561 6473          """Reads
+00001e30: 2074 6865 2069 6e70 7574 2074 656e 736f   the input tenso
+00001e40: 7264 6963 742c 2061 6e64 2066 6f72 2074  rdict, and for t
+00001e50: 6865 2073 656c 6563 7465 6420 6b65 7973  he selected keys
+00001e60: 2c20 6170 706c 6965 7320 7468 6520 7472  , applies the tr
+00001e70: 616e 7366 6f72 6d2e 2222 220d 0a20 2020  ansform."""..   
+00001e80: 2020 2020 2066 6f72 2069 6e5f 6b65 792c       for in_key,
+00001e90: 206f 7574 5f6b 6579 2069 6e20 7a69 7028   out_key in zip(
+00001ea0: 7365 6c66 2e69 6e5f 6b65 7973 2c20 7365  self.in_keys, se
+00001eb0: 6c66 2e6f 7574 5f6b 6579 7329 3a0d 0a20  lf.out_keys):.. 
+00001ec0: 2020 2020 2020 2020 2020 2069 6620 696e             if in
+00001ed0: 5f6b 6579 2069 6e20 7465 6e73 6f72 6469  _key in tensordi
+00001ee0: 6374 2e6b 6579 7328 696e 636c 7564 655f  ct.keys(include_
+00001ef0: 6e65 7374 6564 3d54 7275 6529 3a0d 0a20  nested=True):.. 
+00001f00: 2020 2020 2020 2020 2020 2020 2020 206f                 o
+00001f10: 6273 6572 7661 7469 6f6e 203d 2073 656c  bservation = sel
+00001f20: 662e 5f61 7070 6c79 5f74 7261 6e73 666f  f._apply_transfo
+00001f30: 726d 2874 656e 736f 7264 6963 742e 6765  rm(tensordict.ge
+00001f40: 7428 696e 5f6b 6579 2929 0d0a 2020 2020  t(in_key))..    
+00001f50: 2020 2020 2020 2020 2020 2020 7465 6e73              tens
+00001f60: 6f72 6469 6374 2e73 6574 280d 0a20 2020  ordict.set(..   
+00001f70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00001f80: 206f 7574 5f6b 6579 2c0d 0a20 2020 2020   out_key,..     
+00001f90: 2020 2020 2020 2020 2020 2020 2020 206f                 o
+00001fa0: 6273 6572 7661 7469 6f6e 2c0d 0a20 2020  bservation,..   
+00001fb0: 2020 2020 2020 2020 2020 2020 2029 0d0a               )..
+00001fc0: 2020 2020 2020 2020 2020 2020 656c 6966              elif
+00001fd0: 206e 6f74 2073 656c 662e 6d69 7373 696e   not self.missin
+00001fe0: 675f 746f 6c65 7261 6e63 653a 0d0a 2020  g_tolerance:..  
+00001ff0: 2020 2020 2020 2020 2020 2020 2020 7261                ra
+00002000: 6973 6520 4b65 7945 7272 6f72 2866 2227  ise KeyError(f"'
+00002010: 7b69 6e5f 6b65 797d 2720 6e6f 7420 666f  {in_key}' not fo
+00002020: 756e 6420 696e 2074 656e 736f 7264 6963  und in tensordic
+00002030: 7420 7b74 656e 736f 7264 6963 747d 2229  t {tensordict}")
+00002040: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
+00002050: 2074 656e 736f 7264 6963 740d 0a0d 0a20   tensordict.... 
+00002060: 2020 2064 6566 205f 7374 6570 2873 656c     def _step(sel
+00002070: 662c 2074 656e 736f 7264 6963 743a 2054  f, tensordict: T
+00002080: 656e 736f 7244 6963 7442 6173 6529 202d  ensorDictBase) -
+00002090: 3e20 5465 6e73 6f72 4469 6374 4261 7365  > TensorDictBase
+000020a0: 3a0d 0a20 2020 2020 2020 2022 2222 5468  :..        """Th
+000020b0: 6520 7061 7265 6e74 206d 6574 686f 6420  e parent method 
+000020c0: 6f66 2061 2074 7261 6e73 666f 726d 2064  of a transform d
+000020d0: 7572 696e 6720 7468 6520 6060 656e 762e  uring the ``env.
+000020e0: 7374 6570 6060 2065 7865 6375 7469 6f6e  step`` execution
+000020f0: 2e0d 0a0d 0a20 2020 2020 2020 2054 6869  .....        Thi
+00002100: 7320 6d65 7468 6f64 2073 686f 756c 6420  s method should 
+00002110: 6265 206f 7665 7277 7269 7474 656e 2077  be overwritten w
+00002120: 6865 6e65 7665 7220 7468 6520 3a6d 6574  henever the :met
+00002130: 683a 607e 2e5f 7374 6570 6020 6e65 6564  h:`~._step` need
+00002140: 7320 746f 2062 650d 0a20 2020 2020 2020  s to be..       
+00002150: 2061 6461 7074 6564 2e20 556e 6c69 6b65   adapted. Unlike
+00002160: 203a 6d65 7468 3a60 7e2e 5f63 616c 6c60   :meth:`~._call`
+00002170: 2c20 6974 2069 7320 6173 7375 6d65 6420  , it is assumed 
+00002180: 7468 6174 203a 6d65 7468 3a60 7e2e 5f73  that :meth:`~._s
+00002190: 7465 7060 0d0a 2020 2020 2020 2020 7769  tep`..        wi
+000021a0: 6c6c 2065 7865 6375 7465 2073 6f6d 6520  ll execute some 
+000021b0: 6f70 6572 6174 696f 6e20 7769 7468 2074  operation with t
+000021c0: 6865 2070 6172 656e 7420 656e 7620 6f72  he parent env or
+000021d0: 2074 6861 7420 6974 2072 6571 7569 7265   that it require
+000021e0: 730d 0a20 2020 2020 2020 2061 6363 6573  s..        acces
+000021f0: 7320 746f 2074 6865 2063 6f6e 7465 6e74  s to the content
+00002200: 206f 6620 7468 6520 7465 6e73 6f72 6469   of the tensordi
+00002210: 6374 2061 7420 7469 6d65 2060 6074 6060  ct at time ``t``
+00002220: 2061 6e64 206e 6f74 206f 6e6c 790d 0a20   and not only.. 
+00002230: 2020 2020 2020 2060 6074 2b31 6060 2028         ``t+1`` (
+00002240: 7468 6520 6060 226e 6578 7422 6060 2065  the ``"next"`` e
+00002250: 6e74 7279 2069 6e20 7468 6520 696e 7075  ntry in the inpu
+00002260: 7420 7465 6e73 6f72 6469 6374 292e 0d0a  t tensordict)...
+00002270: 0d0a 2020 2020 2020 2020 3a6d 6574 683a  ..        :meth:
+00002280: 607e 2e5f 7374 6570 6020 7769 6c6c 206f  `~._step` will o
+00002290: 6e6c 7920 6265 2063 616c 6c65 6420 6279  nly be called by
+000022a0: 203a 6d65 7468 3a60 5472 616e 7366 6f72   :meth:`Transfor
+000022b0: 6d65 6445 6e76 2e73 7465 7060 2061 6e64  medEnv.step` and
+000022c0: 0d0a 2020 2020 2020 2020 6e6f 7420 6279  ..        not by
+000022d0: 203a 6d65 7468 3a60 5472 616e 7366 6f72   :meth:`Transfor
+000022e0: 6d65 6445 6e76 2e72 6573 6574 602e 0d0a  medEnv.reset`...
+000022f0: 0d0a 2020 2020 2020 2020 2222 220d 0a20  ..        """.. 
+00002300: 2020 2020 2020 206e 6578 745f 7465 6e73         next_tens
+00002310: 6f72 6469 6374 203d 2074 656e 736f 7264  ordict = tensord
+00002320: 6963 742e 6765 7428 226e 6578 7422 290d  ict.get("next").
+00002330: 0a20 2020 2020 2020 206e 6578 745f 7465  .        next_te
+00002340: 6e73 6f72 6469 6374 203d 2073 656c 662e  nsordict = self.
+00002350: 5f63 616c 6c28 6e65 7874 5f74 656e 736f  _call(next_tenso
+00002360: 7264 6963 7429 0d0a 2020 2020 2020 2020  rdict)..        
+00002370: 7465 6e73 6f72 6469 6374 2e73 6574 2822  tensordict.set("
+00002380: 6e65 7874 222c 206e 6578 745f 7465 6e73  next", next_tens
+00002390: 6f72 6469 6374 290d 0a20 2020 2020 2020  ordict)..       
+000023a0: 2072 6574 7572 6e20 7465 6e73 6f72 6469   return tensordi
+000023b0: 6374 0d0a 0d0a 2020 2020 6465 6620 5f69  ct....    def _i
+000023c0: 6e76 5f61 7070 6c79 5f74 7261 6e73 666f  nv_apply_transfo
+000023d0: 726d 2873 656c 662c 206f 6273 3a20 746f  rm(self, obs: to
+000023e0: 7263 682e 5465 6e73 6f72 2920 2d3e 2074  rch.Tensor) -> t
+000023f0: 6f72 6368 2e54 656e 736f 723a 0d0a 2020  orch.Tensor:..  
+00002400: 2020 2020 2020 6966 2073 656c 662e 696e        if self.in
+00002410: 7665 7274 6962 6c65 3a0d 0a20 2020 2020  vertible:..     
+00002420: 2020 2020 2020 2072 6169 7365 204e 6f74         raise Not
+00002430: 496d 706c 656d 656e 7465 6445 7272 6f72  ImplementedError
+00002440: 0d0a 2020 2020 2020 2020 656c 7365 3a0d  ..        else:.
+00002450: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
+00002460: 7572 6e20 6f62 730d 0a0d 0a20 2020 2064  urn obs....    d
+00002470: 6566 205f 696e 765f 6361 6c6c 2873 656c  ef _inv_call(sel
+00002480: 662c 2074 656e 736f 7264 6963 743a 2054  f, tensordict: T
+00002490: 656e 736f 7244 6963 7442 6173 6529 202d  ensorDictBase) -
+000024a0: 3e20 5465 6e73 6f72 4469 6374 4261 7365  > TensorDictBase
+000024b0: 3a0d 0a20 2020 2020 2020 2023 2023 2057  :..        # # W
+000024c0: 6520 6372 6561 7465 2061 2073 6861 6c6c  e create a shall
+000024d0: 6f77 2063 6f70 7920 6f66 2074 6865 2074  ow copy of the t
+000024e0: 656e 736f 7264 6963 7420 746f 2061 766f  ensordict to avo
+000024f0: 6964 2074 6861 7420 6368 616e 6765 7320  id that changes 
+00002500: 6172 650d 0a20 2020 2020 2020 2023 2023  are..        # #
+00002510: 2065 7870 6f73 6564 2074 6f20 7468 6520   exposed to the 
+00002520: 7573 6572 3a20 7765 2764 206c 696b 6520  user: we'd like 
+00002530: 7468 6174 2074 6865 2069 6e70 7574 206b  that the input k
+00002540: 6579 7320 7265 6d61 696e 2075 6e63 6861  eys remain uncha
+00002550: 6e67 6564 0d0a 2020 2020 2020 2020 2320  nged..        # 
+00002560: 2320 696e 2074 6865 206f 7269 6769 6e61  # in the origina
+00002570: 7469 6e67 2073 6372 6970 7420 6966 2074  ting script if t
+00002580: 6865 7927 7265 2062 6569 6e67 2074 7261  hey're being tra
+00002590: 6e73 666f 726d 6564 2e0d 0a20 2020 2020  nsformed...     
+000025a0: 2020 2066 6f72 2069 6e5f 6b65 792c 206f     for in_key, o
+000025b0: 7574 5f6b 6579 2069 6e20 7a69 7028 7365  ut_key in zip(se
+000025c0: 6c66 2e69 6e5f 6b65 7973 5f69 6e76 2c20  lf.in_keys_inv, 
+000025d0: 7365 6c66 2e6f 7574 5f6b 6579 735f 696e  self.out_keys_in
+000025e0: 7629 3a0d 0a20 2020 2020 2020 2020 2020  v):..           
+000025f0: 2069 6620 696e 5f6b 6579 2069 6e20 7465   if in_key in te
+00002600: 6e73 6f72 6469 6374 2e6b 6579 7328 696e  nsordict.keys(in
+00002610: 636c 7564 655f 6e65 7374 6564 3d54 7275  clude_nested=Tru
+00002620: 6529 3a0d 0a20 2020 2020 2020 2020 2020  e):..           
+00002630: 2020 2020 2069 7465 6d20 3d20 7365 6c66       item = self
+00002640: 2e5f 696e 765f 6170 706c 795f 7472 616e  ._inv_apply_tran
+00002650: 7366 6f72 6d28 7465 6e73 6f72 6469 6374  sform(tensordict
+00002660: 2e67 6574 2869 6e5f 6b65 7929 290d 0a20  .get(in_key)).. 
+00002670: 2020 2020 2020 2020 2020 2020 2020 2074                 t
+00002680: 656e 736f 7264 6963 742e 7365 7428 0d0a  ensordict.set(..
+00002690: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000026a0: 2020 2020 6f75 745f 6b65 792c 0d0a 2020      out_key,..  
+000026b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000026c0: 2020 6974 656d 2c0d 0a20 2020 2020 2020    item,..       
+000026d0: 2020 2020 2020 2020 2029 0d0a 2020 2020           )..    
+000026e0: 2020 2020 2020 2020 656c 6966 206e 6f74          elif not
+000026f0: 2073 656c 662e 6d69 7373 696e 675f 746f   self.missing_to
+00002700: 6c65 7261 6e63 653a 0d0a 2020 2020 2020  lerance:..      
+00002710: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
+00002720: 4b65 7945 7272 6f72 2866 2227 7b69 6e5f  KeyError(f"'{in_
+00002730: 6b65 797d 2720 6e6f 7420 666f 756e 6420  key}' not found 
+00002740: 696e 2074 656e 736f 7264 6963 7420 7b74  in tensordict {t
+00002750: 656e 736f 7264 6963 747d 2229 0d0a 0d0a  ensordict}")....
+00002760: 2020 2020 2020 2020 7265 7475 726e 2074          return t
+00002770: 656e 736f 7264 6963 740d 0a0d 0a20 2020  ensordict....   
+00002780: 2040 6469 7370 6174 6368 2873 6f75 7263   @dispatch(sourc
+00002790: 653d 2269 6e5f 6b65 7973 5f69 6e76 222c  e="in_keys_inv",
+000027a0: 2064 6573 743d 226f 7574 5f6b 6579 735f   dest="out_keys_
+000027b0: 696e 7622 290d 0a20 2020 2064 6566 2069  inv")..    def i
+000027c0: 6e76 2873 656c 662c 2074 656e 736f 7264  nv(self, tensord
+000027d0: 6963 743a 2054 656e 736f 7244 6963 7442  ict: TensorDictB
+000027e0: 6173 6529 202d 3e20 5465 6e73 6f72 4469  ase) -> TensorDi
+000027f0: 6374 4261 7365 3a0d 0a20 2020 2020 2020  ctBase:..       
+00002800: 206f 7574 203d 2073 656c 662e 5f69 6e76   out = self._inv
+00002810: 5f63 616c 6c28 7465 6e73 6f72 6469 6374  _call(tensordict
+00002820: 2e63 6c6f 6e65 2846 616c 7365 2929 0d0a  .clone(False))..
+00002830: 2020 2020 2020 2020 7265 7475 726e 206f          return o
+00002840: 7574 0d0a 0d0a 2020 2020 6465 6620 7472  ut....    def tr
+00002850: 616e 7366 6f72 6d5f 6f75 7470 7574 5f73  ansform_output_s
+00002860: 7065 6328 7365 6c66 2c20 6f75 7470 7574  pec(self, output
+00002870: 5f73 7065 633a 2043 6f6d 706f 7369 7465  _spec: Composite
+00002880: 5370 6563 2920 2d3e 2043 6f6d 706f 7369  Spec) -> Composi
+00002890: 7465 5370 6563 3a0d 0a20 2020 2020 2020  teSpec:..       
+000028a0: 2022 2222 5472 616e 7366 6f72 6d73 2074   """Transforms t
+000028b0: 6865 206f 7574 7075 7420 7370 6563 2073  he output spec s
+000028c0: 7563 6820 7468 6174 2074 6865 2072 6573  uch that the res
+000028d0: 756c 7469 6e67 2073 7065 6320 6d61 7463  ulting spec matc
+000028e0: 6865 7320 7472 616e 7366 6f72 6d20 6d61  hes transform ma
+000028f0: 7070 696e 672e 0d0a 0d0a 2020 2020 2020  pping.....      
+00002900: 2020 5468 6973 206d 6574 686f 6420 7368    This method sh
+00002910: 6f75 6c64 2067 656e 6572 616c 6c79 2062  ould generally b
+00002920: 6520 6c65 6674 2075 6e74 6f75 6368 6564  e left untouched
+00002930: 2e20 4368 616e 6765 7320 7368 6f75 6c64  . Changes should
+00002940: 2062 6520 696d 706c 656d 656e 7465 6420   be implemented 
+00002950: 7573 696e 670d 0a20 2020 2020 2020 203a  using..        :
+00002960: 6d65 7468 3a60 7e2e 7472 616e 7366 6f72  meth:`~.transfor
+00002970: 6d5f 6f62 7365 7276 6174 696f 6e5f 7370  m_observation_sp
+00002980: 6563 602c 203a 6d65 7468 3a60 7e2e 7472  ec`, :meth:`~.tr
+00002990: 616e 7366 6f72 6d5f 7265 7761 7264 5f73  ansform_reward_s
+000029a0: 7065 6360 2061 6e64 203a 6d65 7468 3a60  pec` and :meth:`
+000029b0: 7e2e 7472 616e 7366 6f72 6d5f 646f 6e65  ~.transform_done
+000029c0: 5f73 7065 6360 2e0d 0a20 2020 2020 2020  _spec`...       
+000029d0: 2041 7267 733a 0d0a 2020 2020 2020 2020   Args:..        
+000029e0: 2020 2020 6f75 7470 7574 5f73 7065 6320      output_spec 
+000029f0: 2854 656e 736f 7253 7065 6329 3a20 7370  (TensorSpec): sp
+00002a00: 6563 2062 6566 6f72 6520 7468 6520 7472  ec before the tr
+00002a10: 616e 7366 6f72 6d0d 0a0d 0a20 2020 2020  ansform....     
+00002a20: 2020 2052 6574 7572 6e73 3a0d 0a20 2020     Returns:..   
+00002a30: 2020 2020 2020 2020 2065 7870 6563 7465           expecte
+00002a40: 6420 7370 6563 2061 6674 6572 2074 6865  d spec after the
+00002a50: 2074 7261 6e73 666f 726d 0d0a 0d0a 2020   transform....  
+00002a60: 2020 2020 2020 2222 220d 0a20 2020 2020        """..     
+00002a70: 2020 206f 7574 7075 745f 7370 6563 203d     output_spec =
+00002a80: 206f 7574 7075 745f 7370 6563 2e63 6c6f   output_spec.clo
+00002a90: 6e65 2829 0d0a 2020 2020 2020 2020 6f75  ne()..        ou
+00002aa0: 7470 7574 5f73 7065 635b 226f 6273 6572  tput_spec["obser
+00002ab0: 7661 7469 6f6e 225d 203d 2073 656c 662e  vation"] = self.
+00002ac0: 7472 616e 7366 6f72 6d5f 6f62 7365 7276  transform_observ
+00002ad0: 6174 696f 6e5f 7370 6563 280d 0a20 2020  ation_spec(..   
+00002ae0: 2020 2020 2020 2020 206f 7574 7075 745f           output_
+00002af0: 7370 6563 5b22 6f62 7365 7276 6174 696f  spec["observatio
+00002b00: 6e22 5d0d 0a20 2020 2020 2020 2029 0d0a  n"]..        )..
+00002b10: 2020 2020 2020 2020 6966 2022 7265 7761          if "rewa
+00002b20: 7264 2220 696e 206f 7574 7075 745f 7370  rd" in output_sp
+00002b30: 6563 2e6b 6579 7328 293a 0d0a 2020 2020  ec.keys():..    
+00002b40: 2020 2020 2020 2020 6f75 7470 7574 5f73          output_s
+00002b50: 7065 635b 2272 6577 6172 6422 5d20 3d20  pec["reward"] = 
+00002b60: 7365 6c66 2e74 7261 6e73 666f 726d 5f72  self.transform_r
+00002b70: 6577 6172 645f 7370 6563 286f 7574 7075  eward_spec(outpu
+00002b80: 745f 7370 6563 5b22 7265 7761 7264 225d  t_spec["reward"]
+00002b90: 290d 0a20 2020 2020 2020 2069 6620 2264  )..        if "d
+00002ba0: 6f6e 6522 2069 6e20 6f75 7470 7574 5f73  one" in output_s
+00002bb0: 7065 632e 6b65 7973 2829 3a0d 0a20 2020  pec.keys():..   
+00002bc0: 2020 2020 2020 2020 206f 7574 7075 745f           output_
+00002bd0: 7370 6563 5b22 646f 6e65 225d 203d 2073  spec["done"] = s
+00002be0: 656c 662e 7472 616e 7366 6f72 6d5f 646f  elf.transform_do
+00002bf0: 6e65 5f73 7065 6328 6f75 7470 7574 5f73  ne_spec(output_s
+00002c00: 7065 635b 2264 6f6e 6522 5d29 0d0a 2020  pec["done"])..  
+00002c10: 2020 2020 2020 7265 7475 726e 206f 7574        return out
+00002c20: 7075 745f 7370 6563 0d0a 0d0a 2020 2020  put_spec....    
+00002c30: 6465 6620 7472 616e 7366 6f72 6d5f 696e  def transform_in
+00002c40: 7075 745f 7370 6563 2873 656c 662c 2069  put_spec(self, i
+00002c50: 6e70 7574 5f73 7065 633a 2054 656e 736f  nput_spec: Tenso
+00002c60: 7253 7065 6329 202d 3e20 5465 6e73 6f72  rSpec) -> Tensor
+00002c70: 5370 6563 3a0d 0a20 2020 2020 2020 2022  Spec:..        "
+00002c80: 2222 5472 616e 7366 6f72 6d73 2074 6865  ""Transforms the
+00002c90: 2069 6e70 7574 2073 7065 6320 7375 6368   input spec such
+00002ca0: 2074 6861 7420 7468 6520 7265 7375 6c74   that the result
+00002cb0: 696e 6720 7370 6563 206d 6174 6368 6573  ing spec matches
+00002cc0: 2074 7261 6e73 666f 726d 206d 6170 7069   transform mappi
+00002cd0: 6e67 2e0d 0a0d 0a20 2020 2020 2020 2041  ng.....        A
+00002ce0: 7267 733a 0d0a 2020 2020 2020 2020 2020  rgs:..          
+00002cf0: 2020 696e 7075 745f 7370 6563 2028 5465    input_spec (Te
+00002d00: 6e73 6f72 5370 6563 293a 2073 7065 6320  nsorSpec): spec 
+00002d10: 6265 666f 7265 2074 6865 2074 7261 6e73  before the trans
+00002d20: 666f 726d 0d0a 0d0a 2020 2020 2020 2020  form....        
+00002d30: 5265 7475 726e 733a 0d0a 2020 2020 2020  Returns:..      
+00002d40: 2020 2020 2020 6578 7065 6374 6564 2073        expected s
+00002d50: 7065 6320 6166 7465 7220 7468 6520 7472  pec after the tr
+00002d60: 616e 7366 6f72 6d0d 0a0d 0a20 2020 2020  ansform....     
+00002d70: 2020 2022 2222 0d0a 2020 2020 2020 2020     """..        
+00002d80: 7265 7475 726e 2069 6e70 7574 5f73 7065  return input_spe
+00002d90: 630d 0a0d 0a20 2020 2064 6566 2074 7261  c....    def tra
+00002da0: 6e73 666f 726d 5f6f 6273 6572 7661 7469  nsform_observati
+00002db0: 6f6e 5f73 7065 6328 7365 6c66 2c20 6f62  on_spec(self, ob
+00002dc0: 7365 7276 6174 696f 6e5f 7370 6563 3a20  servation_spec: 
+00002dd0: 5465 6e73 6f72 5370 6563 2920 2d3e 2054  TensorSpec) -> T
+00002de0: 656e 736f 7253 7065 633a 0d0a 2020 2020  ensorSpec:..    
+00002df0: 2020 2020 2222 2254 7261 6e73 666f 726d      """Transform
+00002e00: 7320 7468 6520 6f62 7365 7276 6174 696f  s the observatio
+00002e10: 6e20 7370 6563 2073 7563 6820 7468 6174  n spec such that
+00002e20: 2074 6865 2072 6573 756c 7469 6e67 2073   the resulting s
+00002e30: 7065 6320 6d61 7463 6865 7320 7472 616e  pec matches tran
+00002e40: 7366 6f72 6d20 6d61 7070 696e 672e 0d0a  sform mapping...
+00002e50: 0d0a 2020 2020 2020 2020 4172 6773 3a0d  ..        Args:.
+00002e60: 0a20 2020 2020 2020 2020 2020 206f 6273  .            obs
+00002e70: 6572 7661 7469 6f6e 5f73 7065 6320 2854  ervation_spec (T
+00002e80: 656e 736f 7253 7065 6329 3a20 7370 6563  ensorSpec): spec
+00002e90: 2062 6566 6f72 6520 7468 6520 7472 616e   before the tran
+00002ea0: 7366 6f72 6d0d 0a0d 0a20 2020 2020 2020  sform....       
+00002eb0: 2052 6574 7572 6e73 3a0d 0a20 2020 2020   Returns:..     
+00002ec0: 2020 2020 2020 2065 7870 6563 7465 6420         expected 
+00002ed0: 7370 6563 2061 6674 6572 2074 6865 2074  spec after the t
+00002ee0: 7261 6e73 666f 726d 0d0a 0d0a 2020 2020  ransform....    
+00002ef0: 2020 2020 2222 220d 0a20 2020 2020 2020      """..       
+00002f00: 2072 6574 7572 6e20 6f62 7365 7276 6174   return observat
+00002f10: 696f 6e5f 7370 6563 0d0a 0d0a 2020 2020  ion_spec....    
+00002f20: 6465 6620 7472 616e 7366 6f72 6d5f 7265  def transform_re
+00002f30: 7761 7264 5f73 7065 6328 7365 6c66 2c20  ward_spec(self, 
+00002f40: 7265 7761 7264 5f73 7065 633a 2054 656e  reward_spec: Ten
+00002f50: 736f 7253 7065 6329 202d 3e20 5465 6e73  sorSpec) -> Tens
+00002f60: 6f72 5370 6563 3a0d 0a20 2020 2020 2020  orSpec:..       
+00002f70: 2022 2222 5472 616e 7366 6f72 6d73 2074   """Transforms t
+00002f80: 6865 2072 6577 6172 6420 7370 6563 2073  he reward spec s
+00002f90: 7563 6820 7468 6174 2074 6865 2072 6573  uch that the res
+00002fa0: 756c 7469 6e67 2073 7065 6320 6d61 7463  ulting spec matc
+00002fb0: 6865 7320 7472 616e 7366 6f72 6d20 6d61  hes transform ma
+00002fc0: 7070 696e 672e 0d0a 0d0a 2020 2020 2020  pping.....      
+00002fd0: 2020 4172 6773 3a0d 0a20 2020 2020 2020    Args:..       
+00002fe0: 2020 2020 2072 6577 6172 645f 7370 6563       reward_spec
+00002ff0: 2028 5465 6e73 6f72 5370 6563 293a 2073   (TensorSpec): s
+00003000: 7065 6320 6265 666f 7265 2074 6865 2074  pec before the t
+00003010: 7261 6e73 666f 726d 0d0a 0d0a 2020 2020  ransform....    
+00003020: 2020 2020 5265 7475 726e 733a 0d0a 2020      Returns:..  
+00003030: 2020 2020 2020 2020 2020 6578 7065 6374            expect
+00003040: 6564 2073 7065 6320 6166 7465 7220 7468  ed spec after th
+00003050: 6520 7472 616e 7366 6f72 6d0d 0a0d 0a20  e transform.... 
+00003060: 2020 2020 2020 2022 2222 0d0a 2020 2020         """..    
+00003070: 2020 2020 7265 7475 726e 2072 6577 6172      return rewar
+00003080: 645f 7370 6563 0d0a 0d0a 2020 2020 6465  d_spec....    de
+00003090: 6620 7472 616e 7366 6f72 6d5f 646f 6e65  f transform_done
+000030a0: 5f73 7065 6328 7365 6c66 2c20 646f 6e65  _spec(self, done
+000030b0: 5f73 7065 633a 2054 656e 736f 7253 7065  _spec: TensorSpe
+000030c0: 6329 202d 3e20 5465 6e73 6f72 5370 6563  c) -> TensorSpec
+000030d0: 3a0d 0a20 2020 2020 2020 2022 2222 5472  :..        """Tr
+000030e0: 616e 7366 6f72 6d73 2074 6865 2064 6f6e  ansforms the don
+000030f0: 6520 7370 6563 2073 7563 6820 7468 6174  e spec such that
+00003100: 2074 6865 2072 6573 756c 7469 6e67 2073   the resulting s
+00003110: 7065 6320 6d61 7463 6865 7320 7472 616e  pec matches tran
+00003120: 7366 6f72 6d20 6d61 7070 696e 672e 0d0a  sform mapping...
+00003130: 0d0a 2020 2020 2020 2020 4172 6773 3a0d  ..        Args:.
+00003140: 0a20 2020 2020 2020 2020 2020 2064 6f6e  .            don
+00003150: 655f 7370 6563 2028 5465 6e73 6f72 5370  e_spec (TensorSp
+00003160: 6563 293a 2073 7065 6320 6265 666f 7265  ec): spec before
+00003170: 2074 6865 2074 7261 6e73 666f 726d 0d0a   the transform..
+00003180: 0d0a 2020 2020 2020 2020 5265 7475 726e  ..        Return
+00003190: 733a 0d0a 2020 2020 2020 2020 2020 2020  s:..            
+000031a0: 6578 7065 6374 6564 2073 7065 6320 6166  expected spec af
+000031b0: 7465 7220 7468 6520 7472 616e 7366 6f72  ter the transfor
+000031c0: 6d0d 0a0d 0a20 2020 2020 2020 2022 2222  m....        """
+000031d0: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
+000031e0: 2064 6f6e 655f 7370 6563 0d0a 0d0a 2020   done_spec....  
+000031f0: 2020 6465 6620 6475 6d70 2873 656c 662c    def dump(self,
+00003200: 202a 2a6b 7761 7267 7329 202d 3e20 4e6f   **kwargs) -> No
+00003210: 6e65 3a0d 0a20 2020 2020 2020 2070 6173  ne:..        pas
+00003220: 730d 0a0d 0a20 2020 2064 6566 205f 5f72  s....    def __r
+00003230: 6570 725f 5f28 7365 6c66 2920 2d3e 2073  epr__(self) -> s
+00003240: 7472 3a0d 0a20 2020 2020 2020 2072 6574  tr:..        ret
+00003250: 7572 6e20 6622 7b73 656c 662e 5f5f 636c  urn f"{self.__cl
+00003260: 6173 735f 5f2e 5f5f 6e61 6d65 5f5f 7d28  ass__.__name__}(
+00003270: 6b65 7973 3d7b 7365 6c66 2e69 6e5f 6b65  keys={self.in_ke
+00003280: 7973 7d29 220d 0a0d 0a20 2020 2064 6566  ys})"....    def
+00003290: 2073 6574 5f63 6f6e 7461 696e 6572 2873   set_container(s
+000032a0: 656c 662c 2063 6f6e 7461 696e 6572 3a20  elf, container: 
+000032b0: 556e 696f 6e5b 5472 616e 7366 6f72 6d2c  Union[Transform,
+000032c0: 2045 6e76 4261 7365 5d29 202d 3e20 4e6f   EnvBase]) -> No
+000032d0: 6e65 3a0d 0a20 2020 2020 2020 2069 6620  ne:..        if 
+000032e0: 7365 6c66 2e70 6172 656e 7420 6973 206e  self.parent is n
+000032f0: 6f74 204e 6f6e 653a 0d0a 2020 2020 2020  ot None:..      
+00003300: 2020 2020 2020 7261 6973 6520 4174 7472        raise Attr
+00003310: 6962 7574 6545 7272 6f72 280d 0a20 2020  ibuteError(..   
+00003320: 2020 2020 2020 2020 2020 2020 2066 2270               f"p
+00003330: 6172 656e 7420 6f66 2074 7261 6e73 666f  arent of transfo
+00003340: 726d 207b 7479 7065 2873 656c 6629 7d20  rm {type(self)} 
+00003350: 616c 7265 6164 7920 7365 742e 2022 0d0a  already set. "..
+00003360: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003370: 2243 616c 6c20 6074 7261 6e73 666f 726d  "Call `transform
+00003380: 2e63 6c6f 6e65 2829 6020 746f 2067 6574  .clone()` to get
+00003390: 2061 2073 696d 696c 6172 2074 7261 6e73   a similar trans
+000033a0: 666f 726d 2077 6974 6820 6e6f 2070 6172  form with no par
+000033b0: 656e 7420 7365 742e 220d 0a20 2020 2020  ent set."..     
+000033c0: 2020 2020 2020 2029 0d0a 2020 2020 2020         )..      
+000033d0: 2020 7365 6c66 2e5f 5f64 6963 745f 5f5b    self.__dict__[
+000033e0: 225f 636f 6e74 6169 6e65 7222 5d20 3d20  "_container"] = 
+000033f0: 636f 6e74 6169 6e65 720d 0a0d 0a20 2020  container....   
+00003400: 2064 6566 2072 6573 6574 5f70 6172 656e   def reset_paren
+00003410: 7428 7365 6c66 2920 2d3e 204e 6f6e 653a  t(self) -> None:
+00003420: 0d0a 2020 2020 2020 2020 7365 6c66 2e5f  ..        self._
+00003430: 5f64 6963 745f 5f5b 225f 636f 6e74 6169  _dict__["_contai
+00003440: 6e65 7222 5d20 3d20 4e6f 6e65 0d0a 2020  ner"] = None..  
+00003450: 2020 2020 2020 7365 6c66 2e5f 5f64 6963        self.__dic
+00003460: 745f 5f5b 225f 7061 7265 6e74 225d 203d  t__["_parent"] =
+00003470: 204e 6f6e 650d 0a0d 0a20 2020 2064 6566   None....    def
+00003480: 2063 6c6f 6e65 2873 656c 6629 3a0d 0a20   clone(self):.. 
+00003490: 2020 2020 2020 2073 656c 665f 636f 7079         self_copy
+000034a0: 203d 2063 6f70 7928 7365 6c66 290d 0a20   = copy(self).. 
+000034b0: 2020 2020 2020 2073 7461 7465 203d 2063         state = c
+000034c0: 6f70 7928 7365 6c66 2e5f 5f64 6963 745f  opy(self.__dict_
+000034d0: 5f29 0d0a 2020 2020 2020 2020 7374 6174  _)..        stat
+000034e0: 655b 225f 636f 6e74 6169 6e65 7222 5d20  e["_container"] 
+000034f0: 3d20 4e6f 6e65 0d0a 2020 2020 2020 2020  = None..        
+00003500: 7374 6174 655b 225f 7061 7265 6e74 225d  state["_parent"]
+00003510: 203d 204e 6f6e 650d 0a20 2020 2020 2020   = None..       
+00003520: 2073 656c 665f 636f 7079 2e5f 5f64 6963   self_copy.__dic
+00003530: 745f 5f2e 7570 6461 7465 2873 7461 7465  t__.update(state
+00003540: 290d 0a20 2020 2020 2020 2072 6574 7572  )..        retur
+00003550: 6e20 7365 6c66 5f63 6f70 790d 0a0d 0a20  n self_copy.... 
+00003560: 2020 2040 7072 6f70 6572 7479 0d0a 2020     @property..  
+00003570: 2020 6465 6620 7061 7265 6e74 2873 656c    def parent(sel
+00003580: 6629 202d 3e20 4f70 7469 6f6e 616c 5b45  f) -> Optional[E
+00003590: 6e76 4261 7365 5d3a 0d0a 2020 2020 2020  nvBase]:..      
+000035a0: 2020 6966 2073 656c 662e 5f5f 6469 6374    if self.__dict
+000035b0: 5f5f 2e67 6574 2822 5f70 6172 656e 7422  __.get("_parent"
+000035c0: 2c20 4e6f 6e65 2920 6973 204e 6f6e 653a  , None) is None:
+000035d0: 0d0a 2020 2020 2020 2020 2020 2020 6966  ..            if
+000035e0: 2022 5f63 6f6e 7461 696e 6572 2220 6e6f   "_container" no
+000035f0: 7420 696e 2073 656c 662e 5f5f 6469 6374  t in self.__dict
+00003600: 5f5f 3a0d 0a20 2020 2020 2020 2020 2020  __:..           
+00003610: 2020 2020 2072 6169 7365 2041 7474 7269       raise Attri
+00003620: 6275 7465 4572 726f 7228 2274 7261 6e73  buteError("trans
+00003630: 666f 726d 2070 6172 656e 7420 756e 696e  form parent unin
+00003640: 6974 6961 6c69 7a65 6422 290d 0a20 2020  itialized")..   
+00003650: 2020 2020 2020 2020 2063 6f6e 7461 696e           contain
+00003660: 6572 203d 2073 656c 662e 5f5f 6469 6374  er = self.__dict
+00003670: 5f5f 5b22 5f63 6f6e 7461 696e 6572 225d  __["_container"]
+00003680: 0d0a 2020 2020 2020 2020 2020 2020 6966  ..            if
+00003690: 2063 6f6e 7461 696e 6572 2069 7320 4e6f   container is No
+000036a0: 6e65 3a0d 0a20 2020 2020 2020 2020 2020  ne:..           
+000036b0: 2020 2020 2072 6574 7572 6e20 636f 6e74       return cont
+000036c0: 6169 6e65 720d 0a20 2020 2020 2020 2020  ainer..         
+000036d0: 2020 206f 7574 203d 204e 6f6e 650d 0a20     out = None.. 
+000036e0: 2020 2020 2020 2020 2020 2069 6620 6e6f             if no
+000036f0: 7420 6973 696e 7374 616e 6365 2863 6f6e  t isinstance(con
+00003700: 7461 696e 6572 2c20 456e 7642 6173 6529  tainer, EnvBase)
+00003710: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
+00003720: 2020 2023 2069 6620 6974 2773 206e 6f74     # if it's not
+00003730: 2061 6e20 656e 762c 2069 7420 7368 6f75   an env, it shou
+00003740: 6c64 2062 6520 6120 436f 6d70 6f73 6520  ld be a Compose 
+00003750: 7472 616e 7366 6f72 6d0d 0a20 2020 2020  transform..     
+00003760: 2020 2020 2020 2020 2020 2069 6620 6e6f             if no
+00003770: 7420 6973 696e 7374 616e 6365 2863 6f6e  t isinstance(con
+00003780: 7461 696e 6572 2c20 436f 6d70 6f73 6529  tainer, Compose)
+00003790: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
+000037a0: 2020 2020 2020 2072 6169 7365 2056 616c         raise Val
+000037b0: 7565 4572 726f 7228 0d0a 2020 2020 2020  ueError(..      
+000037c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000037d0: 2020 2241 2074 7261 6e73 666f 726d 2070    "A transform p
+000037e0: 6172 656e 7420 6d75 7374 2062 6520 6569  arent must be ei
+000037f0: 7468 6572 2061 6e6f 7468 6572 2043 6f6d  ther another Com
+00003800: 706f 7365 2074 7261 6e73 666f 726d 206f  pose transform o
+00003810: 7220 616e 2065 6e76 6972 6f6e 6d65 6e74  r an environment
+00003820: 206f 626a 6563 742e 220d 0a20 2020 2020   object."..     
+00003830: 2020 2020 2020 2020 2020 2020 2020 2029                 )
+00003840: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00003850: 2020 636f 6d70 6f73 6520 3d20 636f 6e74    compose = cont
+00003860: 6169 6e65 720d 0a20 2020 2020 2020 2020  ainer..         
+00003870: 2020 2020 2020 2069 6620 636f 6d70 6f73         if compos
+00003880: 652e 5f5f 6469 6374 5f5f 5b22 5f63 6f6e  e.__dict__["_con
+00003890: 7461 696e 6572 225d 3a0d 0a20 2020 2020  tainer"]:..     
+000038a0: 2020 2020 2020 2020 2020 2020 2020 2023                 #
+000038b0: 2074 6865 2070 6172 656e 7420 6f66 2074   the parent of t
+000038c0: 6865 2063 6f6d 706f 7365 206d 7573 7420  he compose must 
+000038d0: 6265 2061 2054 7261 6e73 666f 726d 6564  be a Transformed
+000038e0: 456e 760d 0a20 2020 2020 2020 2020 2020  Env..           
+000038f0: 2020 2020 2020 2020 2063 6f6d 706f 7365           compose
+00003900: 5f70 6172 656e 7420 3d20 5472 616e 7366  _parent = Transf
+00003910: 6f72 6d65 6445 6e76 280d 0a20 2020 2020  ormedEnv(..     
+00003920: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003930: 2020 2063 6f6d 706f 7365 2e5f 5f64 6963     compose.__dic
+00003940: 745f 5f5b 225f 636f 6e74 6169 6e65 7222  t__["_container"
+00003950: 5d2e 6261 7365 5f65 6e76 0d0a 2020 2020  ].base_env..    
+00003960: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003970: 290d 0a20 2020 2020 2020 2020 2020 2020  )..             
+00003980: 2020 2020 2020 2069 6620 636f 6d70 6f73         if compos
+00003990: 655f 7061 7265 6e74 2e74 7261 6e73 666f  e_parent.transfo
+000039a0: 726d 2069 7320 6e6f 7420 636f 6d70 6f73  rm is not compos
+000039b0: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
+000039c0: 2020 2020 2020 2020 2020 2020 636f 6d70              comp
+000039d0: 5f70 6172 656e 745f 7472 616e 7320 3d20  _parent_trans = 
+000039e0: 636f 6d70 6f73 655f 7061 7265 6e74 2e74  compose_parent.t
+000039f0: 7261 6e73 666f 726d 2e63 6c6f 6e65 2829  ransform.clone()
+00003a00: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00003a10: 2020 2020 2020 656c 7365 3a0d 0a20 2020        else:..   
+00003a20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003a30: 2020 2020 2063 6f6d 705f 7061 7265 6e74       comp_parent
+00003a40: 5f74 7261 6e73 203d 204e 6f6e 650d 0a20  _trans = None.. 
+00003a50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003a60: 2020 206f 7574 203d 2054 7261 6e73 666f     out = Transfo
+00003a70: 726d 6564 456e 7628 0d0a 2020 2020 2020  rmedEnv(..      
+00003a80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003a90: 2020 636f 6d70 6f73 655f 7061 7265 6e74    compose_parent
+00003aa0: 2e62 6173 655f 656e 762c 0d0a 2020 2020  .base_env,..    
+00003ab0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003ac0: 2020 2020 7472 616e 7366 6f72 6d3d 636f      transform=co
+00003ad0: 6d70 5f70 6172 656e 745f 7472 616e 732c  mp_parent_trans,
+00003ae0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00003af0: 2020 2020 2020 290d 0a20 2020 2020 2020        )..       
+00003b00: 2020 2020 2020 2020 2020 2020 2066 6f72               for
+00003b10: 206f 7269 675f 7472 616e 7320 696e 2063   orig_trans in c
+00003b20: 6f6d 706f 7365 2e74 7261 6e73 666f 726d  ompose.transform
+00003b30: 733a 0d0a 2020 2020 2020 2020 2020 2020  s:..            
+00003b40: 2020 2020 2020 2020 2020 2020 6966 206f              if o
+00003b50: 7269 675f 7472 616e 7320 6973 2073 656c  rig_trans is sel
+00003b60: 663a 0d0a 2020 2020 2020 2020 2020 2020  f:..            
+00003b70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003b80: 6272 6561 6b0d 0a20 2020 2020 2020 2020  break..         
+00003b90: 2020 2020 2020 2020 2020 2020 2020 2074                 t
+00003ba0: 7261 6e73 666f 726d 203d 206f 7269 675f  ransform = orig_
+00003bb0: 7472 616e 732e 636c 6f6e 6528 290d 0a20  trans.clone().. 
+00003bc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003bd0: 2020 2020 2020 2074 7261 6e73 666f 726d         transform
+00003be0: 2e72 6573 6574 5f70 6172 656e 7428 290d  .reset_parent().
+00003bf0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00003c00: 2020 2020 2020 2020 206f 7574 2e61 7070           out.app
+00003c10: 656e 645f 7472 616e 7366 6f72 6d28 7472  end_transform(tr
+00003c20: 616e 7366 6f72 6d29 0d0a 2020 2020 2020  ansform)..      
+00003c30: 2020 2020 2020 656c 6966 2069 7369 6e73        elif isins
+00003c40: 7461 6e63 6528 636f 6e74 6169 6e65 722c  tance(container,
+00003c50: 2054 7261 6e73 666f 726d 6564 456e 7629   TransformedEnv)
+00003c60: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
+00003c70: 2020 206f 7574 203d 2054 7261 6e73 666f     out = Transfo
+00003c80: 726d 6564 456e 7628 636f 6e74 6169 6e65  rmedEnv(containe
+00003c90: 722e 6261 7365 5f65 6e76 290d 0a20 2020  r.base_env)..   
+00003ca0: 2020 2020 2020 2020 2065 6c73 653a 0d0a           else:..
+00003cb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003cc0: 7261 6973 6520 5661 6c75 6545 7272 6f72  raise ValueError
+00003cd0: 2866 2263 6f6e 7461 696e 6572 2069 7320  (f"container is 
+00003ce0: 6f66 2074 7970 6520 7b74 7970 6528 636f  of type {type(co
+00003cf0: 6e74 6169 6e65 7229 7d22 290d 0a20 2020  ntainer)}")..   
+00003d00: 2020 2020 2020 2020 2073 656c 662e 5f5f           self.__
+00003d10: 6469 6374 5f5f 5b22 5f70 6172 656e 7422  dict__["_parent"
+00003d20: 5d20 3d20 6f75 740d 0a20 2020 2020 2020  ] = out..       
+00003d30: 2072 6574 7572 6e20 7365 6c66 2e5f 5f64   return self.__d
+00003d40: 6963 745f 5f5b 225f 7061 7265 6e74 225d  ict__["_parent"]
+00003d50: 0d0a 0d0a 2020 2020 6465 6620 656d 7074  ....    def empt
+00003d60: 795f 6361 6368 6528 7365 6c66 293a 0d0a  y_cache(self):..
+00003d70: 2020 2020 2020 2020 7365 6c66 2e5f 5f64          self.__d
+00003d80: 6963 745f 5f5b 225f 7061 7265 6e74 225d  ict__["_parent"]
+00003d90: 203d 204e 6f6e 650d 0a0d 0a20 2020 2064   = None....    d
+00003da0: 6566 2073 6574 5f6d 6973 7369 6e67 5f74  ef set_missing_t
+00003db0: 6f6c 6572 616e 6365 2873 656c 662c 206d  olerance(self, m
+00003dc0: 6f64 653d 4661 6c73 6529 3a0d 0a20 2020  ode=False):..   
+00003dd0: 2020 2020 2073 656c 662e 5f6d 6973 7369       self._missi
+00003de0: 6e67 5f74 6f6c 6572 616e 6365 203d 206d  ng_tolerance = m
+00003df0: 6f64 650d 0a0d 0a20 2020 2040 7072 6f70  ode....    @prop
+00003e00: 6572 7479 0d0a 2020 2020 6465 6620 6d69  erty..    def mi
+00003e10: 7373 696e 675f 746f 6c65 7261 6e63 6528  ssing_tolerance(
+00003e20: 7365 6c66 293a 0d0a 2020 2020 2020 2020  self):..        
+00003e30: 7265 7475 726e 2073 656c 662e 5f6d 6973  return self._mis
+00003e40: 7369 6e67 5f74 6f6c 6572 616e 6365 0d0a  sing_tolerance..
+00003e50: 0d0a 0d0a 636c 6173 7320 5472 616e 7366  ....class Transf
+00003e60: 6f72 6d65 6445 6e76 2845 6e76 4261 7365  ormedEnv(EnvBase
+00003e70: 293a 0d0a 2020 2020 2222 2241 2074 7261  ):..    """A tra
+00003e80: 6e73 666f 726d 6564 5f69 6e20 656e 7669  nsformed_in envi
+00003e90: 726f 6e6d 656e 742e 0d0a 0d0a 2020 2020  ronment.....    
+00003ea0: 4172 6773 3a0d 0a20 2020 2020 2020 2065  Args:..        e
+00003eb0: 6e76 2028 456e 7642 6173 6529 3a20 6f72  nv (EnvBase): or
+00003ec0: 6967 696e 616c 2065 6e76 6972 6f6e 6d65  iginal environme
+00003ed0: 6e74 2074 6f20 6265 2074 7261 6e73 666f  nt to be transfo
+00003ee0: 726d 6564 5f69 6e2e 0d0a 2020 2020 2020  rmed_in...      
+00003ef0: 2020 7472 616e 7366 6f72 6d20 2854 7261    transform (Tra
+00003f00: 6e73 666f 726d 2c20 6f70 7469 6f6e 616c  nsform, optional
+00003f10: 293a 2074 7261 6e73 666f 726d 2074 6f20  ): transform to 
+00003f20: 6170 706c 7920 746f 2074 6865 2074 656e  apply to the ten
+00003f30: 736f 7264 6963 7420 7265 7375 6c74 696e  sordict resultin
+00003f40: 670d 0a20 2020 2020 2020 2020 2020 2066  g..            f
+00003f50: 726f 6d20 3a6f 626a 3a60 656e 762e 7374  rom :obj:`env.st
+00003f60: 6570 2874 6429 602e 2049 6620 6e6f 6e65  ep(td)`. If none
+00003f70: 2069 7320 7072 6f76 6964 6564 2c20 616e   is provided, an
+00003f80: 2065 6d70 7479 2043 6f6d 706f 7365 0d0a   empty Compose..
+00003f90: 2020 2020 2020 2020 2020 2020 706c 6163              plac
+00003fa0: 6568 6f6c 6465 7220 696e 2061 6e20 6576  eholder in an ev
+00003fb0: 616c 206d 6f64 6520 6973 2075 7365 642e  al mode is used.
+00003fc0: 0d0a 2020 2020 2020 2020 6361 6368 655f  ..        cache_
+00003fd0: 7370 6563 7320 2862 6f6f 6c2c 206f 7074  specs (bool, opt
+00003fe0: 696f 6e61 6c29 3a20 6966 2060 6054 7275  ional): if ``Tru
+00003ff0: 6560 602c 2074 6865 2073 7065 6373 2077  e``, the specs w
+00004000: 696c 6c20 6265 2063 6163 6865 6420 6f6e  ill be cached on
+00004010: 6365 0d0a 2020 2020 2020 2020 2020 2020  ce..            
+00004020: 616e 6420 666f 7220 616c 6c20 6166 7465  and for all afte
+00004030: 7220 7468 6520 6669 7273 7420 6361 6c6c  r the first call
+00004040: 2028 692e 652e 2074 6865 2073 7065 6373   (i.e. the specs
+00004050: 2077 696c 6c20 6265 0d0a 2020 2020 2020   will be..      
+00004060: 2020 2020 2020 7472 616e 7366 6f72 6d65        transforme
+00004070: 645f 696e 206f 6e6c 7920 6f6e 6365 292e  d_in only once).
+00004080: 2049 6620 7468 6520 7472 616e 7366 6f72   If the transfor
+00004090: 6d20 6368 616e 6765 7320 6475 7269 6e67  m changes during
+000040a0: 0d0a 2020 2020 2020 2020 2020 2020 7472  ..            tr
+000040b0: 6169 6e69 6e67 2c20 7468 6520 6f72 6967  aining, the orig
+000040c0: 696e 616c 2073 7065 6320 7472 616e 7366  inal spec transf
+000040d0: 6f72 6d20 6d61 7920 6e6f 7420 6265 2076  orm may not be v
+000040e0: 616c 6964 2061 6e79 6d6f 7265 2c0d 0a20  alid anymore,.. 
+000040f0: 2020 2020 2020 2020 2020 2069 6e20 7768             in wh
+00004100: 6963 6820 6361 7365 2074 6869 7320 7661  ich case this va
+00004110: 6c75 6520 7368 6f75 6c64 2062 6520 7365  lue should be se
+00004120: 7420 2074 6f20 6046 616c 7365 602e 2044  t  to `False`. D
+00004130: 6566 6175 6c74 2069 730d 0a20 2020 2020  efault is..     
+00004140: 2020 2020 2020 2060 5472 7565 602e 0d0a         `True`...
+00004150: 0d0a 2020 2020 4578 616d 706c 6573 3a0d  ..    Examples:.
+00004160: 0a20 2020 2020 2020 203e 3e3e 2065 6e76  .        >>> env
+00004170: 203d 2047 796d 456e 7628 2250 656e 6475   = GymEnv("Pendu
+00004180: 6c75 6d2d 7630 2229 0d0a 2020 2020 2020  lum-v0")..      
+00004190: 2020 3e3e 3e20 7472 616e 7366 6f72 6d20    >>> transform 
+000041a0: 3d20 5265 7761 7264 5363 616c 696e 6728  = RewardScaling(
+000041b0: 302e 302c 2031 2e30 290d 0a20 2020 2020  0.0, 1.0)..     
+000041c0: 2020 203e 3e3e 2074 7261 6e73 666f 726d     >>> transform
+000041d0: 6564 5f65 6e76 203d 2054 7261 6e73 666f  ed_env = Transfo
+000041e0: 726d 6564 456e 7628 656e 762c 2074 7261  rmedEnv(env, tra
+000041f0: 6e73 666f 726d 290d 0a0d 0a20 2020 2022  nsform)....    "
+00004200: 2222 0d0a 0d0a 2020 2020 6465 6620 5f5f  ""....    def __
+00004210: 696e 6974 5f5f 280d 0a20 2020 2020 2020  init__(..       
+00004220: 2073 656c 662c 0d0a 2020 2020 2020 2020   self,..        
+00004230: 656e 763a 2045 6e76 4261 7365 2c0d 0a20  env: EnvBase,.. 
+00004240: 2020 2020 2020 2074 7261 6e73 666f 726d         transform
+00004250: 3a20 4f70 7469 6f6e 616c 5b54 7261 6e73  : Optional[Trans
+00004260: 666f 726d 5d20 3d20 4e6f 6e65 2c0d 0a20  form] = None,.. 
+00004270: 2020 2020 2020 2063 6163 6865 5f73 7065         cache_spe
+00004280: 6373 3a20 626f 6f6c 203d 2054 7275 652c  cs: bool = True,
+00004290: 0d0a 2020 2020 2020 2020 2a2a 6b77 6172  ..        **kwar
+000042a0: 6773 2c0d 0a20 2020 2029 3a0d 0a20 2020  gs,..    ):..   
+000042b0: 2020 2020 2073 656c 662e 5f74 7261 6e73       self._trans
+000042c0: 666f 726d 203d 204e 6f6e 650d 0a20 2020  form = None..   
+000042d0: 2020 2020 2064 6576 6963 6520 3d20 6b77       device = kw
+000042e0: 6172 6773 2e70 6f70 2822 6465 7669 6365  args.pop("device
+000042f0: 222c 204e 6f6e 6529 0d0a 2020 2020 2020  ", None)..      
+00004300: 2020 6966 2064 6576 6963 6520 6973 206e    if device is n
+00004310: 6f74 204e 6f6e 653a 0d0a 2020 2020 2020  ot None:..      
+00004320: 2020 2020 2020 656e 7620 3d20 656e 762e        env = env.
+00004330: 746f 2864 6576 6963 6529 0d0a 2020 2020  to(device)..    
+00004340: 2020 2020 656c 7365 3a0d 0a20 2020 2020      else:..     
+00004350: 2020 2020 2020 2064 6576 6963 6520 3d20         device = 
+00004360: 656e 762e 6465 7669 6365 0d0a 2020 2020  env.device..    
+00004370: 2020 2020 7375 7065 7228 292e 5f5f 696e      super().__in
+00004380: 6974 5f5f 2864 6576 6963 653d 4e6f 6e65  it__(device=None
+00004390: 2c20 2a2a 6b77 6172 6773 290d 0a0d 0a20  , **kwargs).... 
+000043a0: 2020 2020 2020 2069 6620 6973 696e 7374         if isinst
+000043b0: 616e 6365 2865 6e76 2c20 5472 616e 7366  ance(env, Transf
+000043c0: 6f72 6d65 6445 6e76 293a 0d0a 2020 2020  ormedEnv):..    
+000043d0: 2020 2020 2020 2020 7365 6c66 2e5f 7365          self._se
+000043e0: 745f 656e 7628 656e 762e 6261 7365 5f65  t_env(env.base_e
+000043f0: 6e76 2c20 6465 7669 6365 290d 0a20 2020  nv, device)..   
+00004400: 2020 2020 2020 2020 2069 6620 7479 7065           if type
+00004410: 2874 7261 6e73 666f 726d 2920 6973 206e  (transform) is n
+00004420: 6f74 2043 6f6d 706f 7365 3a0d 0a20 2020  ot Compose:..   
+00004430: 2020 2020 2020 2020 2020 2020 2023 2077               # w
+00004440: 6520 646f 6e27 7420 7573 6520 6973 696e  e don't use isin
+00004450: 7374 616e 6365 2061 7320 736f 6d65 2074  stance as some t
+00004460: 7261 6e73 666f 726d 7320 6d61 7920 6265  ransforms may be
+00004470: 2073 7562 636c 6173 7365 6420 6672 6f6d   subclassed from
+00004480: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00004490: 2020 2320 436f 6d70 6f73 6520 6275 7420    # Compose but 
+000044a0: 7769 7468 206f 7468 6572 2066 6561 7475  with other featu
+000044b0: 7265 7320 7468 6174 2077 6520 646f 6e27  res that we don'
+000044c0: 7420 7761 6e74 2074 6f20 6c6f 6f73 652e  t want to loose.
+000044d0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+000044e0: 2020 6966 2074 7261 6e73 666f 726d 2069    if transform i
+000044f0: 7320 6e6f 7420 4e6f 6e65 3a0d 0a20 2020  s not None:..   
+00004500: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004510: 2074 7261 6e73 666f 726d 203d 205b 7472   transform = [tr
+00004520: 616e 7366 6f72 6d5d 0d0a 2020 2020 2020  ansform]..      
+00004530: 2020 2020 2020 2020 2020 656c 7365 3a0d            else:.
+00004540: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00004550: 2020 2020 2074 7261 6e73 666f 726d 203d       transform =
+00004560: 205b 5d0d 0a20 2020 2020 2020 2020 2020   []..           
+00004570: 2065 6c73 653a 0d0a 2020 2020 2020 2020   else:..        
+00004580: 2020 2020 2020 2020 666f 7220 7420 696e          for t in
+00004590: 2074 7261 6e73 666f 726d 3a0d 0a20 2020   transform:..   
+000045a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000045b0: 2074 2e72 6573 6574 5f70 6172 656e 7428   t.reset_parent(
+000045c0: 290d 0a20 2020 2020 2020 2020 2020 2065  )..            e
+000045d0: 6e76 5f74 7261 6e73 666f 726d 203d 2065  nv_transform = e
+000045e0: 6e76 2e74 7261 6e73 666f 726d 2e63 6c6f  nv.transform.clo
+000045f0: 6e65 2829 0d0a 2020 2020 2020 2020 2020  ne()..          
+00004600: 2020 6966 2074 7970 6528 656e 765f 7472    if type(env_tr
+00004610: 616e 7366 6f72 6d29 2069 7320 6e6f 7420  ansform) is not 
+00004620: 436f 6d70 6f73 653a 0d0a 2020 2020 2020  Compose:..      
+00004630: 2020 2020 2020 2020 2020 656e 765f 7472            env_tr
+00004640: 616e 7366 6f72 6d20 3d20 5b65 6e76 5f74  ansform = [env_t
+00004650: 7261 6e73 666f 726d 5d0d 0a20 2020 2020  ransform]..     
+00004660: 2020 2020 2020 2065 6c73 653a 0d0a 2020         else:..  
+00004670: 2020 2020 2020 2020 2020 2020 2020 666f                fo
+00004680: 7220 7420 696e 2065 6e76 5f74 7261 6e73  r t in env_trans
+00004690: 666f 726d 3a0d 0a20 2020 2020 2020 2020  form:..         
+000046a0: 2020 2020 2020 2020 2020 2074 2e72 6573             t.res
+000046b0: 6574 5f70 6172 656e 7428 290d 0a20 2020  et_parent()..   
+000046c0: 2020 2020 2020 2020 2074 7261 6e73 666f           transfo
+000046d0: 726d 203d 2043 6f6d 706f 7365 282a 656e  rm = Compose(*en
+000046e0: 765f 7472 616e 7366 6f72 6d2c 202a 7472  v_transform, *tr
+000046f0: 616e 7366 6f72 6d29 2e74 6f28 6465 7669  ansform).to(devi
+00004700: 6365 290d 0a20 2020 2020 2020 2065 6c73  ce)..        els
+00004710: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
+00004720: 7365 6c66 2e5f 7365 745f 656e 7628 656e  self._set_env(en
+00004730: 762c 2064 6576 6963 6529 0d0a 2020 2020  v, device)..    
+00004740: 2020 2020 2020 2020 6966 2074 7261 6e73          if trans
+00004750: 666f 726d 2069 7320 4e6f 6e65 3a0d 0a20  form is None:.. 
+00004760: 2020 2020 2020 2020 2020 2020 2020 2074                 t
+00004770: 7261 6e73 666f 726d 203d 2043 6f6d 706f  ransform = Compo
+00004780: 7365 2829 0d0a 2020 2020 2020 2020 2020  se()..          
+00004790: 2020 656c 7365 3a0d 0a20 2020 2020 2020    else:..       
+000047a0: 2020 2020 2020 2020 2074 7261 6e73 666f           transfo
+000047b0: 726d 203d 2074 7261 6e73 666f 726d 2e74  rm = transform.t
+000047c0: 6f28 6465 7669 6365 290d 0a20 2020 2020  o(device)..     
+000047d0: 2020 2073 656c 662e 7472 616e 7366 6f72     self.transfor
+000047e0: 6d20 3d20 7472 616e 7366 6f72 6d0d 0a0d  m = transform...
+000047f0: 0a20 2020 2020 2020 2073 656c 662e 5f6c  .        self._l
+00004800: 6173 745f 6f62 7320 3d20 4e6f 6e65 0d0a  ast_obs = None..
+00004810: 2020 2020 2020 2020 7365 6c66 2e63 6163          self.cac
+00004820: 6865 5f73 7065 6373 203d 2063 6163 6865  he_specs = cache
+00004830: 5f73 7065 6373 0d0a 2020 2020 2020 2020  _specs..        
+00004840: 7365 6c66 2e5f 5f64 6963 745f 5f5b 225f  self.__dict__["_
+00004850: 696e 7075 745f 7370 6563 225d 203d 204e  input_spec"] = N
+00004860: 6f6e 650d 0a20 2020 2020 2020 2073 656c  one..        sel
+00004870: 662e 5f5f 6469 6374 5f5f 5b22 5f6f 7574  f.__dict__["_out
+00004880: 7075 745f 7370 6563 225d 203d 204e 6f6e  put_spec"] = Non
+00004890: 650d 0a20 2020 2020 2020 2073 656c 662e  e..        self.
+000048a0: 6261 7463 685f 7369 7a65 203d 2073 656c  batch_size = sel
+000048b0: 662e 6261 7365 5f65 6e76 2e62 6174 6368  f.base_env.batch
+000048c0: 5f73 697a 650d 0a0d 0a20 2020 2064 6566  _size....    def
+000048d0: 205f 7365 745f 656e 7628 7365 6c66 2c20   _set_env(self, 
+000048e0: 656e 763a 2045 6e76 4261 7365 2c20 6465  env: EnvBase, de
+000048f0: 7669 6365 2920 2d3e 204e 6f6e 653a 0d0a  vice) -> None:..
+00004900: 2020 2020 2020 2020 6966 2064 6576 6963          if devic
+00004910: 6520 213d 2065 6e76 2e64 6576 6963 653a  e != env.device:
+00004920: 0d0a 2020 2020 2020 2020 2020 2020 656e  ..            en
+00004930: 7620 3d20 656e 762e 746f 2864 6576 6963  v = env.to(devic
+00004940: 6529 0d0a 2020 2020 2020 2020 7365 6c66  e)..        self
+00004950: 2e62 6173 655f 656e 7620 3d20 656e 760d  .base_env = env.
+00004960: 0a20 2020 2020 2020 2023 2075 7064 6174  .        # updat
+00004970: 6573 206e 6565 6420 6e6f 7420 6265 2069  es need not be i
+00004980: 6e70 6c61 6365 2c20 6173 2074 7261 6e73  nplace, as trans
+00004990: 666f 726d 7320 6d61 7920 6d6f 6469 6679  forms may modify
+000049a0: 2076 616c 7565 7320 6f75 742d 706c 6163   values out-plac
+000049b0: 650d 0a20 2020 2020 2020 2073 656c 662e  e..        self.
+000049c0: 6261 7365 5f65 6e76 2e5f 696e 706c 6163  base_env._inplac
+000049d0: 655f 7570 6461 7465 203d 2046 616c 7365  e_update = False
+000049e0: 0d0a 0d0a 2020 2020 4070 726f 7065 7274  ....    @propert
+000049f0: 790d 0a20 2020 2064 6566 2074 7261 6e73  y..    def trans
+00004a00: 666f 726d 2873 656c 6629 202d 3e20 5472  form(self) -> Tr
+00004a10: 616e 7366 6f72 6d3a 0d0a 2020 2020 2020  ansform:..      
+00004a20: 2020 7265 7475 726e 2073 656c 662e 5f74    return self._t
+00004a30: 7261 6e73 666f 726d 0d0a 0d0a 2020 2020  ransform....    
+00004a40: 4074 7261 6e73 666f 726d 2e73 6574 7465  @transform.sette
+00004a50: 720d 0a20 2020 2064 6566 2074 7261 6e73  r..    def trans
+00004a60: 666f 726d 2873 656c 662c 2074 7261 6e73  form(self, trans
+00004a70: 666f 726d 3a20 5472 616e 7366 6f72 6d29  form: Transform)
+00004a80: 3a0d 0a20 2020 2020 2020 2069 6620 6e6f  :..        if no
+00004a90: 7420 6973 696e 7374 616e 6365 2874 7261  t isinstance(tra
+00004aa0: 6e73 666f 726d 2c20 5472 616e 7366 6f72  nsform, Transfor
+00004ab0: 6d29 3a0d 0a20 2020 2020 2020 2020 2020  m):..           
+00004ac0: 2072 6169 7365 2056 616c 7565 4572 726f   raise ValueErro
+00004ad0: 7228 0d0a 2020 2020 2020 2020 2020 2020  r(..            
+00004ae0: 2020 2020 6622 2222 4578 7065 6374 6564      f"""Expected
+00004af0: 2061 2074 7261 6e73 666f 726d 206f 6620   a transform of 
+00004b00: 7479 7065 2074 6f72 6368 726c 2e65 6e76  type torchrl.env
+00004b10: 732e 7472 616e 7366 6f72 6d73 2e54 7261  s.transforms.Tra
+00004b20: 6e73 666f 726d 2c0d 0a62 7574 2067 6f74  nsform,..but got
+00004b30: 2061 6e20 6f62 6a65 6374 206f 6620 7479   an object of ty
+00004b40: 7065 207b 7479 7065 2874 7261 6e73 666f  pe {type(transfo
+00004b50: 726d 297d 2e22 2222 0d0a 2020 2020 2020  rm)}."""..      
+00004b60: 2020 2020 2020 290d 0a20 2020 2020 2020        )..       
+00004b70: 2070 7265 765f 7472 616e 7366 6f72 6d20   prev_transform 
+00004b80: 3d20 7365 6c66 2e74 7261 6e73 666f 726d  = self.transform
+00004b90: 0d0a 2020 2020 2020 2020 6966 2070 7265  ..        if pre
+00004ba0: 765f 7472 616e 7366 6f72 6d20 6973 206e  v_transform is n
+00004bb0: 6f74 204e 6f6e 653a 0d0a 2020 2020 2020  ot None:..      
+00004bc0: 2020 2020 2020 7072 6576 5f74 7261 6e73        prev_trans
+00004bd0: 666f 726d 2e65 6d70 7479 5f63 6163 6865  form.empty_cache
+00004be0: 2829 0d0a 2020 2020 2020 2020 2020 2020  ()..            
+00004bf0: 7072 6576 5f74 7261 6e73 666f 726d 2e5f  prev_transform._
+00004c00: 5f64 6963 745f 5f5b 225f 636f 6e74 6169  _dict__["_contai
+00004c10: 6e65 7222 5d20 3d20 4e6f 6e65 0d0a 2020  ner"] = None..  
+00004c20: 2020 2020 2020 7472 616e 7366 6f72 6d2e        transform.
+00004c30: 7365 745f 636f 6e74 6169 6e65 7228 7365  set_container(se
+00004c40: 6c66 290d 0a20 2020 2020 2020 2074 7261  lf)..        tra
+00004c50: 6e73 666f 726d 2e65 7661 6c28 290d 0a20  nsform.eval().. 
+00004c60: 2020 2020 2020 2073 656c 662e 5f74 7261         self._tra
+00004c70: 6e73 666f 726d 203d 2074 7261 6e73 666f  nsform = transfo
+00004c80: 726d 0d0a 0d0a 2020 2020 4070 726f 7065  rm....    @prope
+00004c90: 7274 790d 0a20 2020 2064 6566 2064 6576  rty..    def dev
+00004ca0: 6963 6528 7365 6c66 2920 2d3e 2062 6f6f  ice(self) -> boo
+00004cb0: 6c3a 0d0a 2020 2020 2020 2020 7265 7475  l:..        retu
 00004cc0: 726e 2073 656c 662e 6261 7365 5f65 6e76  rn self.base_env
-00004cd0: 2e5f 696e 706c 6163 655f 7570 6461 7465  ._inplace_update
-00004ce0: 0d0a 0d0a 2020 2020 4070 726f 7065 7274  ....    @propert
-00004cf0: 790d 0a20 2020 2064 6566 206f 7574 7075  y..    def outpu
-00004d00: 745f 7370 6563 2873 656c 6629 202d 3e20  t_spec(self) -> 
-00004d10: 5465 6e73 6f72 5370 6563 3a0d 0a20 2020  TensorSpec:..   
-00004d20: 2020 2020 2022 2222 4f62 7365 7276 6174       """Observat
-00004d30: 696f 6e20 7370 6563 206f 6620 7468 6520  ion spec of the 
-00004d40: 7472 616e 7366 6f72 6d65 6420 656e 7669  transformed envi
-00004d50: 726f 6e6d 656e 742e 2222 220d 0a20 2020  ronment."""..   
-00004d60: 2020 2020 2069 6620 7365 6c66 2e5f 6f75       if self._ou
-00004d70: 7470 7574 5f73 7065 6320 6973 204e 6f6e  tput_spec is Non
-00004d80: 6520 6f72 206e 6f74 2073 656c 662e 6361  e or not self.ca
-00004d90: 6368 655f 7370 6563 733a 0d0a 2020 2020  che_specs:..    
-00004da0: 2020 2020 2020 2020 6f75 7470 7574 5f73          output_s
-00004db0: 7065 6320 3d20 7365 6c66 2e62 6173 655f  pec = self.base_
-00004dc0: 656e 762e 6f75 7470 7574 5f73 7065 632e  env.output_spec.
-00004dd0: 636c 6f6e 6528 290d 0a20 2020 2020 2020  clone()..       
-00004de0: 2020 2020 206f 7574 7075 745f 7370 6563       output_spec
-00004df0: 203d 2073 656c 662e 7472 616e 7366 6f72   = self.transfor
-00004e00: 6d2e 7472 616e 7366 6f72 6d5f 6f75 7470  m.transform_outp
-00004e10: 7574 5f73 7065 6328 6f75 7470 7574 5f73  ut_spec(output_s
-00004e20: 7065 6329 0d0a 2020 2020 2020 2020 2020  pec)..          
-00004e30: 2020 6966 2073 656c 662e 6361 6368 655f    if self.cache_
-00004e40: 7370 6563 733a 0d0a 2020 2020 2020 2020  specs:..        
-00004e50: 2020 2020 2020 2020 7365 6c66 2e5f 5f64          self.__d
-00004e60: 6963 745f 5f5b 225f 6f75 7470 7574 5f73  ict__["_output_s
-00004e70: 7065 6322 5d20 3d20 6f75 7470 7574 5f73  pec"] = output_s
-00004e80: 7065 630d 0a20 2020 2020 2020 2065 6c73  pec..        els
-00004e90: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
-00004ea0: 6f75 7470 7574 5f73 7065 6320 3d20 7365  output_spec = se
-00004eb0: 6c66 2e5f 6f75 7470 7574 5f73 7065 630d  lf._output_spec.
-00004ec0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00004ed0: 6f75 7470 7574 5f73 7065 630d 0a0d 0a20  output_spec.... 
-00004ee0: 2020 2040 7072 6f70 6572 7479 0d0a 2020     @property..  
-00004ef0: 2020 6465 6620 6163 7469 6f6e 5f73 7065    def action_spe
-00004f00: 6328 7365 6c66 2920 2d3e 2054 656e 736f  c(self) -> Tenso
-00004f10: 7253 7065 633a 0d0a 2020 2020 2020 2020  rSpec:..        
-00004f20: 2222 2241 6374 696f 6e20 7370 6563 206f  """Action spec o
-00004f30: 6620 7468 6520 7472 616e 7366 6f72 6d65  f the transforme
-00004f40: 6420 656e 7669 726f 6e6d 656e 742e 2222  d environment.""
-00004f50: 220d 0a20 2020 2020 2020 2072 6574 7572  "..        retur
-00004f60: 6e20 7365 6c66 2e69 6e70 7574 5f73 7065  n self.input_spe
-00004f70: 635b 2261 6374 696f 6e22 5d0d 0a0d 0a20  c["action"].... 
-00004f80: 2020 2040 7072 6f70 6572 7479 0d0a 2020     @property..  
-00004f90: 2020 6465 6620 696e 7075 745f 7370 6563    def input_spec
-00004fa0: 2873 656c 6629 202d 3e20 5465 6e73 6f72  (self) -> Tensor
-00004fb0: 5370 6563 3a0d 0a20 2020 2020 2020 2022  Spec:..        "
-00004fc0: 2222 4163 7469 6f6e 2073 7065 6320 6f66  ""Action spec of
-00004fd0: 2074 6865 2074 7261 6e73 666f 726d 6564   the transformed
-00004fe0: 2065 6e76 6972 6f6e 6d65 6e74 2e22 2222   environment."""
-00004ff0: 0d0a 2020 2020 2020 2020 6966 2073 656c  ..        if sel
-00005000: 662e 5f69 6e70 7574 5f73 7065 6320 6973  f._input_spec is
-00005010: 204e 6f6e 6520 6f72 206e 6f74 2073 656c   None or not sel
-00005020: 662e 6361 6368 655f 7370 6563 733a 0d0a  f.cache_specs:..
-00005030: 2020 2020 2020 2020 2020 2020 696e 7075              inpu
-00005040: 745f 7370 6563 203d 2073 656c 662e 7472  t_spec = self.tr
-00005050: 616e 7366 6f72 6d2e 7472 616e 7366 6f72  ansform.transfor
-00005060: 6d5f 696e 7075 745f 7370 6563 280d 0a20  m_input_spec(.. 
-00005070: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-00005080: 656c 662e 6261 7365 5f65 6e76 2e69 6e70  elf.base_env.inp
-00005090: 7574 5f73 7065 632e 636c 6f6e 6528 290d  ut_spec.clone().
-000050a0: 0a20 2020 2020 2020 2020 2020 2029 0d0a  .            )..
-000050b0: 2020 2020 2020 2020 2020 2020 6966 2073              if s
-000050c0: 656c 662e 6361 6368 655f 7370 6563 733a  elf.cache_specs:
-000050d0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-000050e0: 2020 7365 6c66 2e5f 5f64 6963 745f 5f5b    self.__dict__[
-000050f0: 225f 696e 7075 745f 7370 6563 225d 203d  "_input_spec"] =
-00005100: 2069 6e70 7574 5f73 7065 630d 0a20 2020   input_spec..   
-00005110: 2020 2020 2065 6c73 653a 0d0a 2020 2020       else:..    
-00005120: 2020 2020 2020 2020 696e 7075 745f 7370          input_sp
-00005130: 6563 203d 2073 656c 662e 5f69 6e70 7574  ec = self._input
-00005140: 5f73 7065 630d 0a20 2020 2020 2020 2072  _spec..        r
-00005150: 6574 7572 6e20 696e 7075 745f 7370 6563  eturn input_spec
-00005160: 0d0a 0d0a 2020 2020 4070 726f 7065 7274  ....    @propert
-00005170: 790d 0a20 2020 2064 6566 2072 6577 6172  y..    def rewar
-00005180: 645f 7370 6563 2873 656c 6629 202d 3e20  d_spec(self) -> 
-00005190: 5465 6e73 6f72 5370 6563 3a0d 0a20 2020  TensorSpec:..   
-000051a0: 2020 2020 2022 2222 5265 7761 7264 2073       """Reward s
-000051b0: 7065 6320 6f66 2074 6865 2074 7261 6e73  pec of the trans
-000051c0: 666f 726d 6564 2065 6e76 6972 6f6e 6d65  formed environme
-000051d0: 6e74 2e22 2222 0d0a 2020 2020 2020 2020  nt."""..        
-000051e0: 7265 7475 726e 2073 656c 662e 6f75 7470  return self.outp
-000051f0: 7574 5f73 7065 635b 2272 6577 6172 6422  ut_spec["reward"
-00005200: 5d0d 0a0d 0a20 2020 2040 7072 6f70 6572  ]....    @proper
-00005210: 7479 0d0a 2020 2020 6465 6620 6f62 7365  ty..    def obse
-00005220: 7276 6174 696f 6e5f 7370 6563 2873 656c  rvation_spec(sel
-00005230: 6629 202d 3e20 5465 6e73 6f72 5370 6563  f) -> TensorSpec
-00005240: 3a0d 0a20 2020 2020 2020 2022 2222 4f62  :..        """Ob
-00005250: 7365 7276 6174 696f 6e20 7370 6563 206f  servation spec o
-00005260: 6620 7468 6520 7472 616e 7366 6f72 6d65  f the transforme
-00005270: 6420 656e 7669 726f 6e6d 656e 742e 2222  d environment.""
-00005280: 220d 0a20 2020 2020 2020 2072 6574 7572  "..        retur
-00005290: 6e20 7365 6c66 2e6f 7574 7075 745f 7370  n self.output_sp
-000052a0: 6563 5b22 6f62 7365 7276 6174 696f 6e22  ec["observation"
-000052b0: 5d0d 0a0d 0a20 2020 2040 7072 6f70 6572  ]....    @proper
-000052c0: 7479 0d0a 2020 2020 6465 6620 646f 6e65  ty..    def done
-000052d0: 5f73 7065 6328 7365 6c66 2920 2d3e 2054  _spec(self) -> T
-000052e0: 656e 736f 7253 7065 633a 0d0a 2020 2020  ensorSpec:..    
-000052f0: 2020 2020 2222 2244 6f6e 6520 7370 6563      """Done spec
-00005300: 206f 6620 7468 6520 7472 616e 7366 6f72   of the transfor
-00005310: 6d65 6420 656e 7669 726f 6e6d 656e 742e  med environment.
-00005320: 2222 220d 0a20 2020 2020 2020 2072 6574  """..        ret
-00005330: 7572 6e20 7365 6c66 2e6f 7574 7075 745f  urn self.output_
-00005340: 7370 6563 5b22 646f 6e65 225d 0d0a 0d0a  spec["done"]....
-00005350: 2020 2020 6465 6620 5f73 7465 7028 7365      def _step(se
-00005360: 6c66 2c20 7465 6e73 6f72 6469 6374 3a20  lf, tensordict: 
-00005370: 5465 6e73 6f72 4469 6374 4261 7365 2920  TensorDictBase) 
-00005380: 2d3e 2054 656e 736f 7244 6963 7442 6173  -> TensorDictBas
-00005390: 653a 0d0a 2020 2020 2020 2020 7465 6e73  e:..        tens
-000053a0: 6f72 6469 6374 203d 2074 656e 736f 7264  ordict = tensord
-000053b0: 6963 742e 636c 6f6e 6528 4661 6c73 6529  ict.clone(False)
-000053c0: 0d0a 2020 2020 2020 2020 7465 6e73 6f72  ..        tensor
-000053d0: 6469 6374 5f69 6e20 3d20 7365 6c66 2e74  dict_in = self.t
-000053e0: 7261 6e73 666f 726d 2e69 6e76 2874 656e  ransform.inv(ten
-000053f0: 736f 7264 6963 7429 0d0a 2020 2020 2020  sordict)..      
-00005400: 2020 7465 6e73 6f72 6469 6374 5f6f 7574    tensordict_out
-00005410: 203d 2073 656c 662e 6261 7365 5f65 6e76   = self.base_env
-00005420: 2e5f 7374 6570 2874 656e 736f 7264 6963  ._step(tensordic
-00005430: 745f 696e 290d 0a20 2020 2020 2020 2023  t_in)..        #
-00005440: 2077 6520 7761 6e74 2074 6865 2069 6e70   we want the inp
-00005450: 7574 2065 6e74 7269 6573 2074 6f20 7265  ut entries to re
-00005460: 6d61 696e 2075 6e63 6861 6e67 6564 0d0a  main unchanged..
-00005470: 2020 2020 2020 2020 7465 6e73 6f72 6469          tensordi
-00005480: 6374 5f6f 7574 203d 2074 656e 736f 7264  ct_out = tensord
-00005490: 6963 742e 7570 6461 7465 2874 656e 736f  ict.update(tenso
-000054a0: 7264 6963 745f 6f75 7429 0d0a 2020 2020  rdict_out)..    
-000054b0: 2020 2020 7465 6e73 6f72 6469 6374 5f6f      tensordict_o
-000054c0: 7574 203d 2073 656c 662e 7472 616e 7366  ut = self.transf
-000054d0: 6f72 6d2e 5f73 7465 7028 7465 6e73 6f72  orm._step(tensor
-000054e0: 6469 6374 5f6f 7574 290d 0a20 2020 2020  dict_out)..     
-000054f0: 2020 2072 6574 7572 6e20 7465 6e73 6f72     return tensor
-00005500: 6469 6374 5f6f 7574 0d0a 0d0a 2020 2020  dict_out....    
-00005510: 6465 6620 7365 745f 7365 6564 280d 0a20  def set_seed(.. 
-00005520: 2020 2020 2020 2073 656c 662c 2073 6565         self, see
-00005530: 643a 204f 7074 696f 6e61 6c5b 696e 745d  d: Optional[int]
-00005540: 203d 204e 6f6e 652c 2073 7461 7469 635f   = None, static_
-00005550: 7365 6564 3a20 626f 6f6c 203d 2046 616c  seed: bool = Fal
-00005560: 7365 0d0a 2020 2020 2920 2d3e 204f 7074  se..    ) -> Opt
-00005570: 696f 6e61 6c5b 696e 745d 3a0d 0a20 2020  ional[int]:..   
-00005580: 2020 2020 2022 2222 5365 7420 7468 6520       """Set the 
-00005590: 7365 6564 7320 6f66 2074 6865 2065 6e76  seeds of the env
-000055a0: 6972 6f6e 6d65 6e74 2e22 2222 0d0a 2020  ironment."""..  
-000055b0: 2020 2020 2020 7265 7475 726e 2073 656c        return sel
-000055c0: 662e 6261 7365 5f65 6e76 2e73 6574 5f73  f.base_env.set_s
-000055d0: 6565 6428 7365 6564 2c20 7374 6174 6963  eed(seed, static
-000055e0: 5f73 6565 643d 7374 6174 6963 5f73 6565  _seed=static_see
-000055f0: 6429 0d0a 0d0a 2020 2020 6465 6620 5f73  d)....    def _s
-00005600: 6574 5f73 6565 6428 7365 6c66 2c20 7365  et_seed(self, se
-00005610: 6564 3a20 4f70 7469 6f6e 616c 5b69 6e74  ed: Optional[int
-00005620: 5d29 3a0d 0a20 2020 2020 2020 2022 2222  ]):..        """
-00005630: 5468 6973 206d 6574 686f 6420 6973 206e  This method is n
-00005640: 6f74 2075 7365 6420 696e 2074 7261 6e73  ot used in trans
-00005650: 666f 726d 6564 2065 6e76 732e 2222 220d  formed envs.""".
-00005660: 0a20 2020 2020 2020 2070 6173 730d 0a0d  .        pass...
-00005670: 0a20 2020 2064 6566 205f 7265 7365 7428  .    def _reset(
-00005680: 7365 6c66 2c20 7465 6e73 6f72 6469 6374  self, tensordict
-00005690: 3a20 4f70 7469 6f6e 616c 5b54 656e 736f  : Optional[Tenso
-000056a0: 7244 6963 7442 6173 655d 203d 204e 6f6e  rDictBase] = Non
-000056b0: 652c 202a 2a6b 7761 7267 7329 3a0d 0a20  e, **kwargs):.. 
-000056c0: 2020 2020 2020 2069 6620 7465 6e73 6f72         if tensor
-000056d0: 6469 6374 2069 7320 6e6f 7420 4e6f 6e65  dict is not None
-000056e0: 3a0d 0a20 2020 2020 2020 2020 2020 2074  :..            t
-000056f0: 656e 736f 7264 6963 7420 3d20 7465 6e73  ensordict = tens
-00005700: 6f72 6469 6374 2e63 6c6f 6e65 2872 6563  ordict.clone(rec
-00005710: 7572 7365 3d46 616c 7365 290d 0a20 2020  urse=False)..   
-00005720: 2020 2020 206f 7574 5f74 656e 736f 7264       out_tensord
-00005730: 6963 7420 3d20 7365 6c66 2e62 6173 655f  ict = self.base_
-00005740: 656e 762e 7265 7365 7428 7465 6e73 6f72  env.reset(tensor
-00005750: 6469 6374 3d74 656e 736f 7264 6963 742c  dict=tensordict,
-00005760: 202a 2a6b 7761 7267 7329 0d0a 2020 2020   **kwargs)..    
-00005770: 2020 2020 6f75 745f 7465 6e73 6f72 6469      out_tensordi
-00005780: 6374 203d 2073 656c 662e 7472 616e 7366  ct = self.transf
-00005790: 6f72 6d2e 7265 7365 7428 6f75 745f 7465  orm.reset(out_te
-000057a0: 6e73 6f72 6469 6374 290d 0a20 2020 2020  nsordict)..     
-000057b0: 2020 206f 7574 5f74 656e 736f 7264 6963     out_tensordic
-000057c0: 7420 3d20 7365 6c66 2e74 7261 6e73 666f  t = self.transfo
-000057d0: 726d 2e5f 6361 6c6c 286f 7574 5f74 656e  rm._call(out_ten
-000057e0: 736f 7264 6963 7429 0d0a 2020 2020 2020  sordict)..      
-000057f0: 2020 7265 7475 726e 206f 7574 5f74 656e    return out_ten
-00005800: 736f 7264 6963 740d 0a0d 0a20 2020 2064  sordict....    d
-00005810: 6566 2073 7461 7465 5f64 6963 7428 7365  ef state_dict(se
-00005820: 6c66 2c20 2a61 7267 732c 202a 2a6b 7761  lf, *args, **kwa
-00005830: 7267 7329 202d 3e20 4f72 6465 7265 6444  rgs) -> OrderedD
-00005840: 6963 743a 0d0a 2020 2020 2020 2020 7374  ict:..        st
-00005850: 6174 655f 6469 6374 203d 2073 656c 662e  ate_dict = self.
-00005860: 7472 616e 7366 6f72 6d2e 7374 6174 655f  transform.state_
-00005870: 6469 6374 282a 6172 6773 2c20 2a2a 6b77  dict(*args, **kw
-00005880: 6172 6773 290d 0a20 2020 2020 2020 2072  args)..        r
-00005890: 6574 7572 6e20 7374 6174 655f 6469 6374  eturn state_dict
-000058a0: 0d0a 0d0a 2020 2020 6465 6620 6c6f 6164  ....    def load
-000058b0: 5f73 7461 7465 5f64 6963 7428 7365 6c66  _state_dict(self
-000058c0: 2c20 7374 6174 655f 6469 6374 3a20 4f72  , state_dict: Or
-000058d0: 6465 7265 6444 6963 742c 202a 2a6b 7761  deredDict, **kwa
-000058e0: 7267 7329 202d 3e20 4e6f 6e65 3a0d 0a20  rgs) -> None:.. 
-000058f0: 2020 2020 2020 2073 656c 662e 7472 616e         self.tran
-00005900: 7366 6f72 6d2e 6c6f 6164 5f73 7461 7465  sform.load_state
-00005910: 5f64 6963 7428 7374 6174 655f 6469 6374  _dict(state_dict
-00005920: 2c20 2a2a 6b77 6172 6773 290d 0a0d 0a20  , **kwargs).... 
-00005930: 2020 2064 6566 2065 7661 6c28 7365 6c66     def eval(self
-00005940: 2920 2d3e 2054 7261 6e73 666f 726d 6564  ) -> Transformed
-00005950: 456e 763a 0d0a 2020 2020 2020 2020 6966  Env:..        if
-00005960: 2022 7472 616e 7366 6f72 6d22 2069 6e20   "transform" in 
-00005970: 7365 6c66 2e5f 5f64 6972 5f5f 2829 3a0d  self.__dir__():.
-00005980: 0a20 2020 2020 2020 2020 2020 2023 2077  .            # w
-00005990: 6865 6e20 6361 6c6c 696e 6720 5f5f 696e  hen calling __in
-000059a0: 6974 5f5f 2c20 6576 616c 2829 2069 7320  it__, eval() is 
-000059b0: 6361 6c6c 6564 2062 7574 2074 7261 6e73  called but trans
-000059c0: 666f 726d 7320 6172 6520 6e6f 7420 7365  forms are not se
-000059d0: 740d 0a20 2020 2020 2020 2020 2020 2023  t..            #
-000059e0: 2079 6574 2e0d 0a20 2020 2020 2020 2020   yet...         
-000059f0: 2020 2073 656c 662e 7472 616e 7366 6f72     self.transfor
-00005a00: 6d2e 6576 616c 2829 0d0a 2020 2020 2020  m.eval()..      
-00005a10: 2020 7265 7475 726e 2073 656c 660d 0a0d    return self...
-00005a20: 0a20 2020 2064 6566 2074 7261 696e 2873  .    def train(s
-00005a30: 656c 662c 206d 6f64 653a 2062 6f6f 6c20  elf, mode: bool 
-00005a40: 3d20 5472 7565 2920 2d3e 2054 7261 6e73  = True) -> Trans
-00005a50: 666f 726d 6564 456e 763a 0d0a 2020 2020  formedEnv:..    
-00005a60: 2020 2020 7365 6c66 2e74 7261 6e73 666f      self.transfo
-00005a70: 726d 2e74 7261 696e 286d 6f64 6529 0d0a  rm.train(mode)..
-00005a80: 2020 2020 2020 2020 7265 7475 726e 2073          return s
-00005a90: 656c 660d 0a0d 0a20 2020 2040 7072 6f70  elf....    @prop
-00005aa0: 6572 7479 0d0a 2020 2020 6465 6620 6973  erty..    def is
-00005ab0: 5f63 6c6f 7365 6428 7365 6c66 2920 2d3e  _closed(self) ->
-00005ac0: 2062 6f6f 6c3a 0d0a 2020 2020 2020 2020   bool:..        
-00005ad0: 7265 7475 726e 2073 656c 662e 6261 7365  return self.base
-00005ae0: 5f65 6e76 2e69 735f 636c 6f73 6564 0d0a  _env.is_closed..
-00005af0: 0d0a 2020 2020 4069 735f 636c 6f73 6564  ..    @is_closed
-00005b00: 2e73 6574 7465 720d 0a20 2020 2064 6566  .setter..    def
-00005b10: 2069 735f 636c 6f73 6564 2873 656c 662c   is_closed(self,
-00005b20: 2076 616c 7565 3a20 626f 6f6c 293a 0d0a   value: bool):..
-00005b30: 2020 2020 2020 2020 7365 6c66 2e62 6173          self.bas
-00005b40: 655f 656e 762e 6973 5f63 6c6f 7365 6420  e_env.is_closed 
-00005b50: 3d20 7661 6c75 650d 0a0d 0a20 2020 2064  = value....    d
-00005b60: 6566 2063 6c6f 7365 2873 656c 6629 3a0d  ef close(self):.
-00005b70: 0a20 2020 2020 2020 2073 656c 662e 6261  .        self.ba
-00005b80: 7365 5f65 6e76 2e63 6c6f 7365 2829 0d0a  se_env.close()..
-00005b90: 2020 2020 2020 2020 7365 6c66 2e69 735f          self.is_
-00005ba0: 636c 6f73 6564 203d 2054 7275 650d 0a0d  closed = True...
-00005bb0: 0a20 2020 2064 6566 2065 6d70 7479 5f63  .    def empty_c
-00005bc0: 6163 6865 2873 656c 6629 3a0d 0a20 2020  ache(self):..   
-00005bd0: 2020 2020 2073 656c 662e 5f5f 6469 6374       self.__dict
-00005be0: 5f5f 5b22 5f6f 7574 7075 745f 7370 6563  __["_output_spec
-00005bf0: 225d 203d 204e 6f6e 650d 0a20 2020 2020  "] = None..     
-00005c00: 2020 2073 656c 662e 5f5f 6469 6374 5f5f     self.__dict__
-00005c10: 5b22 5f69 6e70 7574 5f73 7065 6322 5d20  ["_input_spec"] 
-00005c20: 3d20 4e6f 6e65 0d0a 2020 2020 2020 2020  = None..        
-00005c30: 7365 6c66 2e5f 5f64 6963 745f 5f5b 225f  self.__dict__["_
-00005c40: 6361 6368 655f 696e 5f6b 6579 7322 5d20  cache_in_keys"] 
-00005c50: 3d20 4e6f 6e65 0d0a 0d0a 2020 2020 6465  = None....    de
-00005c60: 6620 6170 7065 6e64 5f74 7261 6e73 666f  f append_transfo
-00005c70: 726d 2873 656c 662c 2074 7261 6e73 666f  rm(self, transfo
-00005c80: 726d 3a20 5472 616e 7366 6f72 6d29 202d  rm: Transform) -
-00005c90: 3e20 4e6f 6e65 3a0d 0a20 2020 2020 2020  > None:..       
-00005ca0: 2073 656c 662e 5f65 7261 7365 5f6d 6574   self._erase_met
-00005cb0: 6164 6174 6128 290d 0a20 2020 2020 2020  adata()..       
-00005cc0: 2069 6620 6e6f 7420 6973 696e 7374 616e   if not isinstan
-00005cd0: 6365 2874 7261 6e73 666f 726d 2c20 5472  ce(transform, Tr
-00005ce0: 616e 7366 6f72 6d29 3a0d 0a20 2020 2020  ansform):..     
-00005cf0: 2020 2020 2020 2072 6169 7365 2056 616c         raise Val
-00005d00: 7565 4572 726f 7228 0d0a 2020 2020 2020  ueError(..      
-00005d10: 2020 2020 2020 2020 2020 2254 7261 6e73            "Trans
-00005d20: 666f 726d 6564 456e 762e 6170 7065 6e64  formedEnv.append
-00005d30: 5f74 7261 6e73 666f 726d 2065 7870 6563  _transform expec
-00005d40: 7465 6420 6120 7472 616e 7366 6f72 6d20  ted a transform 
-00005d50: 6275 7420 7265 6365 6976 6564 2061 6e20  but received an 
-00005d60: 6f62 6a65 6374 206f 6620 220d 0a20 2020  object of "..   
-00005d70: 2020 2020 2020 2020 2020 2020 2066 2274               f"t
-00005d80: 7970 6520 7b74 7970 6528 7472 616e 7366  ype {type(transf
-00005d90: 6f72 6d29 7d20 696e 7374 6561 642e 220d  orm)} instead.".
-00005da0: 0a20 2020 2020 2020 2020 2020 2029 0d0a  .            )..
-00005db0: 2020 2020 2020 2020 7472 616e 7366 6f72          transfor
-00005dc0: 6d20 3d20 7472 616e 7366 6f72 6d2e 746f  m = transform.to
-00005dd0: 2873 656c 662e 6465 7669 6365 290d 0a20  (self.device).. 
-00005de0: 2020 2020 2020 2069 6620 6e6f 7420 6973         if not is
-00005df0: 696e 7374 616e 6365 2873 656c 662e 7472  instance(self.tr
-00005e00: 616e 7366 6f72 6d2c 2043 6f6d 706f 7365  ansform, Compose
-00005e10: 293a 0d0a 2020 2020 2020 2020 2020 2020  ):..            
-00005e20: 7072 6576 5f74 7261 6e73 666f 726d 203d  prev_transform =
-00005e30: 2073 656c 662e 7472 616e 7366 6f72 6d0d   self.transform.
-00005e40: 0a20 2020 2020 2020 2020 2020 2070 7265  .            pre
-00005e50: 765f 7472 616e 7366 6f72 6d2e 7265 7365  v_transform.rese
-00005e60: 745f 7061 7265 6e74 2829 0d0a 2020 2020  t_parent()..    
-00005e70: 2020 2020 2020 2020 7365 6c66 2e74 7261          self.tra
-00005e80: 6e73 666f 726d 203d 2043 6f6d 706f 7365  nsform = Compose
-00005e90: 2829 0d0a 2020 2020 2020 2020 2020 2020  ()..            
-00005ea0: 7365 6c66 2e74 7261 6e73 666f 726d 2e61  self.transform.a
-00005eb0: 7070 656e 6428 7072 6576 5f74 7261 6e73  ppend(prev_trans
-00005ec0: 666f 726d 290d 0a0d 0a20 2020 2020 2020  form)....       
-00005ed0: 2073 656c 662e 7472 616e 7366 6f72 6d2e   self.transform.
-00005ee0: 6170 7065 6e64 2874 7261 6e73 666f 726d  append(transform
-00005ef0: 290d 0a0d 0a20 2020 2064 6566 2069 6e73  )....    def ins
-00005f00: 6572 745f 7472 616e 7366 6f72 6d28 7365  ert_transform(se
-00005f10: 6c66 2c20 696e 6465 783a 2069 6e74 2c20  lf, index: int, 
-00005f20: 7472 616e 7366 6f72 6d3a 2054 7261 6e73  transform: Trans
-00005f30: 666f 726d 2920 2d3e 204e 6f6e 653a 0d0a  form) -> None:..
-00005f40: 2020 2020 2020 2020 6966 206e 6f74 2069          if not i
-00005f50: 7369 6e73 7461 6e63 6528 7472 616e 7366  sinstance(transf
-00005f60: 6f72 6d2c 2054 7261 6e73 666f 726d 293a  orm, Transform):
-00005f70: 0d0a 2020 2020 2020 2020 2020 2020 7261  ..            ra
-00005f80: 6973 6520 5661 6c75 6545 7272 6f72 280d  ise ValueError(.
-00005f90: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00005fa0: 2022 5472 616e 7366 6f72 6d65 6445 6e76   "TransformedEnv
-00005fb0: 2e69 6e73 6572 745f 7472 616e 7366 6f72  .insert_transfor
-00005fc0: 6d20 6578 7065 6374 6564 2061 2074 7261  m expected a tra
-00005fd0: 6e73 666f 726d 2062 7574 2072 6563 6569  nsform but recei
-00005fe0: 7665 6420 616e 206f 626a 6563 7420 6f66  ved an object of
-00005ff0: 2022 0d0a 2020 2020 2020 2020 2020 2020   "..            
-00006000: 2020 2020 6622 7479 7065 207b 7479 7065      f"type {type
-00006010: 2874 7261 6e73 666f 726d 297d 2069 6e73  (transform)} ins
-00006020: 7465 6164 2e22 0d0a 2020 2020 2020 2020  tead."..        
-00006030: 2020 2020 290d 0a20 2020 2020 2020 2074      )..        t
-00006040: 7261 6e73 666f 726d 203d 2074 7261 6e73  ransform = trans
-00006050: 666f 726d 2e74 6f28 7365 6c66 2e64 6576  form.to(self.dev
-00006060: 6963 6529 0d0a 2020 2020 2020 2020 6966  ice)..        if
-00006070: 206e 6f74 2069 7369 6e73 7461 6e63 6528   not isinstance(
-00006080: 7365 6c66 2e74 7261 6e73 666f 726d 2c20  self.transform, 
-00006090: 436f 6d70 6f73 6529 3a0d 0a20 2020 2020  Compose):..     
-000060a0: 2020 2020 2020 2063 6f6d 706f 7365 203d         compose =
-000060b0: 2043 6f6d 706f 7365 2873 656c 662e 7472   Compose(self.tr
-000060c0: 616e 7366 6f72 6d2e 636c 6f6e 6528 2929  ansform.clone())
-000060d0: 0d0a 2020 2020 2020 2020 2020 2020 7365  ..            se
-000060e0: 6c66 2e74 7261 6e73 666f 726d 203d 2063  lf.transform = c
-000060f0: 6f6d 706f 7365 2020 2320 7061 7265 6e74  ompose  # parent
-00006100: 2073 6574 2061 7574 6f6d 6174 6963 616c   set automatical
-00006110: 6c79 0d0a 0d0a 2020 2020 2020 2020 7365  ly....        se
-00006120: 6c66 2e74 7261 6e73 666f 726d 2e69 6e73  lf.transform.ins
-00006130: 6572 7428 696e 6465 782c 2074 7261 6e73  ert(index, trans
-00006140: 666f 726d 290d 0a20 2020 2020 2020 2073  form)..        s
-00006150: 656c 662e 5f65 7261 7365 5f6d 6574 6164  elf._erase_metad
-00006160: 6174 6128 290d 0a0d 0a20 2020 2064 6566  ata()....    def
-00006170: 205f 5f67 6574 6174 7472 5f5f 2873 656c   __getattr__(sel
-00006180: 662c 2061 7474 723a 2073 7472 2920 2d3e  f, attr: str) ->
-00006190: 2041 6e79 3a0d 0a20 2020 2020 2020 2069   Any:..        i
-000061a0: 6620 6174 7472 2069 6e20 7365 6c66 2e5f  f attr in self._
-000061b0: 5f64 6972 5f5f 2829 3a0d 0a20 2020 2020  _dir__():..     
-000061c0: 2020 2020 2020 2072 6574 7572 6e20 7375         return su
-000061d0: 7065 7228 292e 5f5f 6765 7461 7474 725f  per().__getattr_
-000061e0: 5f28 0d0a 2020 2020 2020 2020 2020 2020  _(..            
-000061f0: 2020 2020 6174 7472 0d0a 2020 2020 2020      attr..      
-00006200: 2020 2020 2020 2920 2023 206d 616b 6520        )  # make 
-00006210: 7375 7265 2074 6861 7420 6170 7072 6f70  sure that approp
-00006220: 7269 6174 6520 6578 6365 7074 696f 6e73  riate exceptions
-00006230: 2061 7265 2072 6169 7365 640d 0a20 2020   are raised..   
-00006240: 2020 2020 2065 6c69 6620 6174 7472 2e73       elif attr.s
-00006250: 7461 7274 7377 6974 6828 225f 5f22 293a  tartswith("__"):
-00006260: 0d0a 2020 2020 2020 2020 2020 2020 7261  ..            ra
-00006270: 6973 6520 4174 7472 6962 7574 6545 7272  ise AttributeErr
-00006280: 6f72 280d 0a20 2020 2020 2020 2020 2020  or(..           
-00006290: 2020 2020 2022 7061 7373 696e 6720 6275       "passing bu
-000062a0: 696c 742d 696e 2070 7269 7661 7465 206d  ilt-in private m
-000062b0: 6574 686f 6473 2069 7320 220d 0a20 2020  ethods is "..   
-000062c0: 2020 2020 2020 2020 2020 2020 2066 226e               f"n
-000062d0: 6f74 2070 6572 6d69 7474 6564 2077 6974  ot permitted wit
-000062e0: 6820 7479 7065 207b 7479 7065 2873 656c  h type {type(sel
-000062f0: 6629 7d2e 2022 0d0a 2020 2020 2020 2020  f)}. "..        
-00006300: 2020 2020 2020 2020 6622 476f 7420 6174          f"Got at
-00006310: 7472 6962 7574 6520 7b61 7474 727d 2e22  tribute {attr}."
-00006320: 0d0a 2020 2020 2020 2020 2020 2020 290d  ..            ).
-00006330: 0a20 2020 2020 2020 2065 6c69 6620 2262  .        elif "b
-00006340: 6173 655f 656e 7622 2069 6e20 7365 6c66  ase_env" in self
-00006350: 2e5f 5f64 6972 5f5f 2829 3a0d 0a20 2020  .__dir__():..   
-00006360: 2020 2020 2020 2020 2062 6173 655f 656e           base_en
-00006370: 7620 3d20 7365 6c66 2e5f 5f67 6574 6174  v = self.__getat
-00006380: 7472 5f5f 2822 6261 7365 5f65 6e76 2229  tr__("base_env")
-00006390: 0d0a 2020 2020 2020 2020 2020 2020 7265  ..            re
-000063a0: 7475 726e 2067 6574 6174 7472 2862 6173  turn getattr(bas
-000063b0: 655f 656e 762c 2061 7474 7229 0d0a 0d0a  e_env, attr)....
-000063c0: 2020 2020 2020 2020 7261 6973 6520 4174          raise At
-000063d0: 7472 6962 7574 6545 7272 6f72 280d 0a20  tributeError(.. 
-000063e0: 2020 2020 2020 2020 2020 2066 2265 6e76             f"env
-000063f0: 206e 6f74 2073 6574 2069 6e20 7b73 656c   not set in {sel
-00006400: 662e 5f5f 636c 6173 735f 5f2e 5f5f 6e61  f.__class__.__na
-00006410: 6d65 5f5f 7d2c 2063 616e 6e6f 7420 6163  me__}, cannot ac
-00006420: 6365 7373 207b 6174 7472 7d22 0d0a 2020  cess {attr}"..  
-00006430: 2020 2020 2020 290d 0a0d 0a20 2020 2064        )....    d
-00006440: 6566 205f 5f72 6570 725f 5f28 7365 6c66  ef __repr__(self
-00006450: 2920 2d3e 2073 7472 3a0d 0a20 2020 2020  ) -> str:..     
-00006460: 2020 2065 6e76 5f73 7472 203d 2069 6e64     env_str = ind
-00006470: 656e 7428 6622 656e 763d 7b73 656c 662e  ent(f"env={self.
-00006480: 6261 7365 5f65 6e76 7d22 2c20 3420 2a20  base_env}", 4 * 
-00006490: 2220 2229 0d0a 2020 2020 2020 2020 745f  " ")..        t_
-000064a0: 7374 7220 3d20 696e 6465 6e74 2866 2274  str = indent(f"t
-000064b0: 7261 6e73 666f 726d 3d7b 7365 6c66 2e74  ransform={self.t
-000064c0: 7261 6e73 666f 726d 7d22 2c20 3420 2a20  ransform}", 4 * 
-000064d0: 2220 2229 0d0a 2020 2020 2020 2020 7265  " ")..        re
-000064e0: 7475 726e 2066 2254 7261 6e73 666f 726d  turn f"Transform
-000064f0: 6564 456e 7628 5c6e 7b65 6e76 5f73 7472  edEnv(\n{env_str
-00006500: 7d2c 5c6e 7b74 5f73 7472 7d29 220d 0a0d  },\n{t_str})"...
-00006510: 0a20 2020 2064 6566 205f 6572 6173 655f  .    def _erase_
-00006520: 6d65 7461 6461 7461 2873 656c 6629 3a0d  metadata(self):.
-00006530: 0a20 2020 2020 2020 2069 6620 7365 6c66  .        if self
-00006540: 2e63 6163 6865 5f73 7065 6373 3a0d 0a20  .cache_specs:.. 
-00006550: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-00006560: 5f5f 6469 6374 5f5f 5b22 5f69 6e70 7574  __dict__["_input
-00006570: 5f73 7065 6322 5d20 3d20 4e6f 6e65 0d0a  _spec"] = None..
-00006580: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-00006590: 2e5f 5f64 6963 745f 5f5b 225f 6f75 7470  .__dict__["_outp
-000065a0: 7574 5f73 7065 6322 5d20 3d20 4e6f 6e65  ut_spec"] = None
-000065b0: 0d0a 2020 2020 2020 2020 2020 2020 7365  ..            se
-000065c0: 6c66 2e5f 5f64 6963 745f 5f5b 225f 6361  lf.__dict__["_ca
-000065d0: 6368 655f 696e 5f6b 6579 7322 5d20 3d20  che_in_keys"] = 
-000065e0: 4e6f 6e65 0d0a 0d0a 2020 2020 6465 6620  None....    def 
-000065f0: 746f 2873 656c 662c 2064 6576 6963 653a  to(self, device:
-00006600: 2044 4556 4943 455f 5459 5049 4e47 2920   DEVICE_TYPING) 
-00006610: 2d3e 2054 7261 6e73 666f 726d 6564 456e  -> TransformedEn
-00006620: 763a 0d0a 2020 2020 2020 2020 7365 6c66  v:..        self
-00006630: 2e62 6173 655f 656e 762e 746f 2864 6576  .base_env.to(dev
-00006640: 6963 6529 0d0a 2020 2020 2020 2020 7365  ice)..        se
-00006650: 6c66 2e74 7261 6e73 666f 726d 2e74 6f28  lf.transform.to(
-00006660: 6465 7669 6365 290d 0a0d 0a20 2020 2020  device)....     
-00006670: 2020 2069 6620 7365 6c66 2e63 6163 6865     if self.cache
-00006680: 5f73 7065 6373 3a0d 0a20 2020 2020 2020  _specs:..       
-00006690: 2020 2020 2073 656c 662e 5f5f 6469 6374       self.__dict
-000066a0: 5f5f 5b22 5f69 6e70 7574 5f73 7065 6322  __["_input_spec"
-000066b0: 5d20 3d20 4e6f 6e65 0d0a 2020 2020 2020  ] = None..      
-000066c0: 2020 2020 2020 7365 6c66 2e5f 5f64 6963        self.__dic
-000066d0: 745f 5f5b 225f 6f75 7470 7574 5f73 7065  t__["_output_spe
-000066e0: 6322 5d20 3d20 4e6f 6e65 0d0a 2020 2020  c"] = None..    
-000066f0: 2020 2020 7265 7475 726e 2073 656c 660d      return self.
-00006700: 0a0d 0a20 2020 2064 6566 205f 5f73 6574  ...    def __set
-00006710: 6174 7472 5f5f 2873 656c 662c 206b 6579  attr__(self, key
-00006720: 2c20 7661 6c75 6529 3a0d 0a20 2020 2020  , value):..     
-00006730: 2020 2070 726f 706f 626a 203d 2067 6574     propobj = get
-00006740: 6174 7472 2873 656c 662e 5f5f 636c 6173  attr(self.__clas
-00006750: 735f 5f2c 206b 6579 2c20 4e6f 6e65 290d  s__, key, None).
-00006760: 0a0d 0a20 2020 2020 2020 2069 6620 6973  ...        if is
-00006770: 696e 7374 616e 6365 2870 726f 706f 626a  instance(propobj
-00006780: 2c20 7072 6f70 6572 7479 293a 0d0a 2020  , property):..  
-00006790: 2020 2020 2020 2020 2020 616e 6365 7374            ancest
-000067a0: 6f72 7320 3d20 6c69 7374 285f 5f63 6c61  ors = list(__cla
-000067b0: 7373 5f5f 2e5f 5f6d 726f 5f5f 295b 3a3a  ss__.__mro__)[::
-000067c0: 2d31 5d0d 0a20 2020 2020 2020 2020 2020  -1]..           
-000067d0: 2077 6869 6c65 2069 7369 6e73 7461 6e63   while isinstanc
-000067e0: 6528 7072 6f70 6f62 6a2c 2070 726f 7065  e(propobj, prope
-000067f0: 7274 7929 3a0d 0a20 2020 2020 2020 2020  rty):..         
-00006800: 2020 2020 2020 2069 6620 7072 6f70 6f62         if propob
-00006810: 6a2e 6673 6574 2069 7320 6e6f 7420 4e6f  j.fset is not No
-00006820: 6e65 3a0d 0a20 2020 2020 2020 2020 2020  ne:..           
-00006830: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
-00006840: 7072 6f70 6f62 6a2e 6673 6574 2873 656c  propobj.fset(sel
-00006850: 662c 2076 616c 7565 290d 0a20 2020 2020  f, value)..     
-00006860: 2020 2020 2020 2020 2020 2070 726f 706f             propo
-00006870: 626a 203d 2067 6574 6174 7472 2861 6e63  bj = getattr(anc
-00006880: 6573 746f 7273 2e70 6f70 2829 2c20 6b65  estors.pop(), ke
-00006890: 792c 204e 6f6e 6529 0d0a 2020 2020 2020  y, None)..      
-000068a0: 2020 2020 2020 656c 7365 3a0d 0a20 2020        else:..   
-000068b0: 2020 2020 2020 2020 2020 2020 2072 6169               rai
-000068c0: 7365 2041 7474 7269 6275 7465 4572 726f  se AttributeErro
-000068d0: 7228 6622 6361 6e27 7420 7365 7420 6174  r(f"can't set at
-000068e0: 7472 6962 7574 6520 7b6b 6579 7d22 290d  tribute {key}").
-000068f0: 0a20 2020 2020 2020 2065 6c73 653a 0d0a  .        else:..
-00006900: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-00006910: 726e 2073 7570 6572 2829 2e5f 5f73 6574  rn super().__set
-00006920: 6174 7472 5f5f 286b 6579 2c20 7661 6c75  attr__(key, valu
-00006930: 6529 0d0a 0d0a 2020 2020 6465 6620 5f5f  e)....    def __
-00006940: 6465 6c5f 5f28 7365 6c66 293a 0d0a 2020  del__(self):..  
-00006950: 2020 2020 2020 2320 7765 206d 6179 2064        # we may d
-00006960: 656c 6574 6520 6120 5472 616e 7366 6f72  elete a Transfor
-00006970: 6d65 6445 6e76 2074 6861 7420 636f 6e74  medEnv that cont
-00006980: 6169 6e73 2061 6e20 656e 7620 636f 6e74  ains an env cont
-00006990: 6169 6e65 6420 6279 2061 6e6f 7468 6572  ained by another
-000069a0: 0d0a 2020 2020 2020 2020 2320 7472 616e  ..        # tran
-000069b0: 7366 6f72 6d65 6420 656e 7620 616e 6420  sformed env and 
-000069c0: 7468 6174 2077 6520 646f 6e27 7420 7761  that we don't wa
-000069d0: 6e74 2074 6f20 636c 6f73 650d 0a20 2020  nt to close..   
-000069e0: 2020 2020 2070 6173 730d 0a0d 0a0d 0a63       pass......c
-000069f0: 6c61 7373 204f 6273 6572 7661 7469 6f6e  lass Observation
-00006a00: 5472 616e 7366 6f72 6d28 5472 616e 7366  Transform(Transf
-00006a10: 6f72 6d29 3a0d 0a20 2020 2022 2222 4162  orm):..    """Ab
-00006a20: 7374 7261 6374 2063 6c61 7373 2066 6f72  stract class for
-00006a30: 2074 7261 6e73 666f 726d 6174 696f 6e73   transformations
-00006a40: 206f 6620 7468 6520 6f62 7365 7276 6174   of the observat
-00006a50: 696f 6e73 2e22 2222 0d0a 0d0a 2020 2020  ions."""....    
-00006a60: 6465 6620 5f5f 696e 6974 5f5f 280d 0a20  def __init__(.. 
-00006a70: 2020 2020 2020 2073 656c 662c 0d0a 2020         self,..  
-00006a80: 2020 2020 2020 696e 5f6b 6579 733a 204f        in_keys: O
-00006a90: 7074 696f 6e61 6c5b 5365 7175 656e 6365  ptional[Sequence
-00006aa0: 5b73 7472 5d5d 203d 204e 6f6e 652c 0d0a  [str]] = None,..
-00006ab0: 2020 2020 2020 2020 6f75 745f 6b65 7973          out_keys
-00006ac0: 3a20 4f70 7469 6f6e 616c 5b53 6571 7565  : Optional[Seque
-00006ad0: 6e63 655b 7374 725d 5d20 3d20 4e6f 6e65  nce[str]] = None
-00006ae0: 2c0d 0a20 2020 2020 2020 2069 6e5f 6b65  ,..        in_ke
-00006af0: 7973 5f69 6e76 3a20 4f70 7469 6f6e 616c  ys_inv: Optional
-00006b00: 5b53 6571 7565 6e63 655b 7374 725d 5d20  [Sequence[str]] 
-00006b10: 3d20 4e6f 6e65 2c0d 0a20 2020 2020 2020  = None,..       
-00006b20: 206f 7574 5f6b 6579 735f 696e 763a 204f   out_keys_inv: O
-00006b30: 7074 696f 6e61 6c5b 5365 7175 656e 6365  ptional[Sequence
-00006b40: 5b73 7472 5d5d 203d 204e 6f6e 652c 0d0a  [str]] = None,..
-00006b50: 2020 2020 293a 0d0a 2020 2020 2020 2020      ):..        
-00006b60: 6966 2069 6e5f 6b65 7973 2069 7320 4e6f  if in_keys is No
-00006b70: 6e65 3a0d 0a20 2020 2020 2020 2020 2020  ne:..           
-00006b80: 2069 6e5f 6b65 7973 203d 205b 0d0a 2020   in_keys = [..  
-00006b90: 2020 2020 2020 2020 2020 2020 2020 226f                "o
-00006ba0: 6273 6572 7661 7469 6f6e 222c 0d0a 2020  bservation",..  
-00006bb0: 2020 2020 2020 2020 2020 2020 2020 2270                "p
-00006bc0: 6978 656c 7322 2c0d 0a20 2020 2020 2020  ixels",..       
-00006bd0: 2020 2020 205d 0d0a 2020 2020 2020 2020       ]..        
-00006be0: 7375 7065 7228 4f62 7365 7276 6174 696f  super(Observatio
-00006bf0: 6e54 7261 6e73 666f 726d 2c20 7365 6c66  nTransform, self
-00006c00: 292e 5f5f 696e 6974 5f5f 280d 0a20 2020  ).__init__(..   
-00006c10: 2020 2020 2020 2020 2069 6e5f 6b65 7973           in_keys
-00006c20: 3d69 6e5f 6b65 7973 2c0d 0a20 2020 2020  =in_keys,..     
-00006c30: 2020 2020 2020 206f 7574 5f6b 6579 733d         out_keys=
-00006c40: 6f75 745f 6b65 7973 2c0d 0a20 2020 2020  out_keys,..     
-00006c50: 2020 2020 2020 2069 6e5f 6b65 7973 5f69         in_keys_i
-00006c60: 6e76 3d69 6e5f 6b65 7973 5f69 6e76 2c0d  nv=in_keys_inv,.
-00006c70: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
-00006c80: 5f6b 6579 735f 696e 763d 6f75 745f 6b65  _keys_inv=out_ke
-00006c90: 7973 5f69 6e76 2c0d 0a20 2020 2020 2020  ys_inv,..       
-00006ca0: 2029 0d0a 0d0a 0d0a 636c 6173 7320 436f   )......class Co
-00006cb0: 6d70 6f73 6528 5472 616e 7366 6f72 6d29  mpose(Transform)
-00006cc0: 3a0d 0a20 2020 2022 2222 436f 6d70 6f73  :..    """Compos
-00006cd0: 6573 2061 2063 6861 696e 206f 6620 7472  es a chain of tr
-00006ce0: 616e 7366 6f72 6d73 2e0d 0a0d 0a20 2020  ansforms.....   
-00006cf0: 2045 7861 6d70 6c65 733a 0d0a 2020 2020   Examples:..    
-00006d00: 2020 2020 3e3e 3e20 656e 7620 3d20 4779      >>> env = Gy
-00006d10: 6d45 6e76 2822 5065 6e64 756c 756d 2d76  mEnv("Pendulum-v
-00006d20: 3022 290d 0a20 2020 2020 2020 203e 3e3e  0")..        >>>
-00006d30: 2074 7261 6e73 666f 726d 7320 3d20 5b52   transforms = [R
-00006d40: 6577 6172 6453 6361 6c69 6e67 2831 2e30  ewardScaling(1.0
-00006d50: 2c20 312e 3029 2c20 5265 7761 7264 436c  , 1.0), RewardCl
-00006d60: 6970 7069 6e67 282d 322e 302c 2032 2e30  ipping(-2.0, 2.0
-00006d70: 295d 0d0a 2020 2020 2020 2020 3e3e 3e20  )]..        >>> 
-00006d80: 7472 616e 7366 6f72 6d73 203d 2043 6f6d  transforms = Com
-00006d90: 706f 7365 282a 7472 616e 7366 6f72 6d73  pose(*transforms
-00006da0: 290d 0a20 2020 2020 2020 203e 3e3e 2074  )..        >>> t
-00006db0: 7261 6e73 666f 726d 6564 5f65 6e76 203d  ransformed_env =
-00006dc0: 2054 7261 6e73 666f 726d 6564 456e 7628   TransformedEnv(
-00006dd0: 656e 762c 2074 7261 6e73 666f 726d 7329  env, transforms)
-00006de0: 0d0a 0d0a 2020 2020 2222 220d 0a0d 0a20  ....    """.... 
-00006df0: 2020 2064 6566 205f 5f69 6e69 745f 5f28     def __init__(
-00006e00: 7365 6c66 2c20 2a74 7261 6e73 666f 726d  self, *transform
-00006e10: 733a 2054 7261 6e73 666f 726d 293a 0d0a  s: Transform):..
-00006e20: 2020 2020 2020 2020 7375 7065 7228 292e          super().
-00006e30: 5f5f 696e 6974 5f5f 2869 6e5f 6b65 7973  __init__(in_keys
-00006e40: 3d5b 5d29 0d0a 2020 2020 2020 2020 7365  =[])..        se
-00006e50: 6c66 2e74 7261 6e73 666f 726d 7320 3d20  lf.transforms = 
-00006e60: 6e6e 2e4d 6f64 756c 654c 6973 7428 7472  nn.ModuleList(tr
-00006e70: 616e 7366 6f72 6d73 290d 0a20 2020 2020  ansforms)..     
-00006e80: 2020 2066 6f72 2074 2069 6e20 7472 616e     for t in tran
-00006e90: 7366 6f72 6d73 3a0d 0a20 2020 2020 2020  sforms:..       
-00006ea0: 2020 2020 2074 2e73 6574 5f63 6f6e 7461       t.set_conta
-00006eb0: 696e 6572 2873 656c 6629 0d0a 0d0a 2020  iner(self)....  
-00006ec0: 2020 6465 6620 5f63 616c 6c28 7365 6c66    def _call(self
-00006ed0: 2c20 7465 6e73 6f72 6469 6374 3a20 5465  , tensordict: Te
-00006ee0: 6e73 6f72 4469 6374 4261 7365 2920 2d3e  nsorDictBase) ->
-00006ef0: 2054 656e 736f 7244 6963 7442 6173 653a   TensorDictBase:
-00006f00: 0d0a 2020 2020 2020 2020 666f 7220 7420  ..        for t 
-00006f10: 696e 2073 656c 662e 7472 616e 7366 6f72  in self.transfor
-00006f20: 6d73 3a0d 0a20 2020 2020 2020 2020 2020  ms:..           
-00006f30: 2074 656e 736f 7264 6963 7420 3d20 742e   tensordict = t.
-00006f40: 5f63 616c 6c28 7465 6e73 6f72 6469 6374  _call(tensordict
-00006f50: 290d 0a20 2020 2020 2020 2072 6574 7572  )..        retur
-00006f60: 6e20 7465 6e73 6f72 6469 6374 0d0a 0d0a  n tensordict....
-00006f70: 2020 2020 6465 6620 666f 7277 6172 6428      def forward(
-00006f80: 7365 6c66 2c20 7465 6e73 6f72 6469 6374  self, tensordict
-00006f90: 3a20 5465 6e73 6f72 4469 6374 4261 7365  : TensorDictBase
-00006fa0: 2920 2d3e 2054 656e 736f 7244 6963 7442  ) -> TensorDictB
-00006fb0: 6173 653a 0d0a 2020 2020 2020 2020 666f  ase:..        fo
-00006fc0: 7220 7420 696e 2073 656c 662e 7472 616e  r t in self.tran
-00006fd0: 7366 6f72 6d73 3a0d 0a20 2020 2020 2020  sforms:..       
-00006fe0: 2020 2020 2074 656e 736f 7264 6963 7420       tensordict 
-00006ff0: 3d20 7428 7465 6e73 6f72 6469 6374 290d  = t(tensordict).
-00007000: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00007010: 7465 6e73 6f72 6469 6374 0d0a 0d0a 2020  tensordict....  
-00007020: 2020 6465 6620 5f73 7465 7028 7365 6c66    def _step(self
-00007030: 2c20 7465 6e73 6f72 6469 6374 3a20 5465  , tensordict: Te
-00007040: 6e73 6f72 4469 6374 4261 7365 2920 2d3e  nsorDictBase) ->
-00007050: 2054 656e 736f 7244 6963 7442 6173 653a   TensorDictBase:
-00007060: 0d0a 2020 2020 2020 2020 666f 7220 7420  ..        for t 
-00007070: 696e 2073 656c 662e 7472 616e 7366 6f72  in self.transfor
-00007080: 6d73 3a0d 0a20 2020 2020 2020 2020 2020  ms:..           
-00007090: 2074 656e 736f 7264 6963 7420 3d20 742e   tensordict = t.
-000070a0: 5f73 7465 7028 7465 6e73 6f72 6469 6374  _step(tensordict
-000070b0: 290d 0a20 2020 2020 2020 2072 6574 7572  )..        retur
-000070c0: 6e20 7465 6e73 6f72 6469 6374 0d0a 0d0a  n tensordict....
-000070d0: 2020 2020 6465 6620 5f69 6e76 5f63 616c      def _inv_cal
-000070e0: 6c28 7365 6c66 2c20 7465 6e73 6f72 6469  l(self, tensordi
-000070f0: 6374 3a20 5465 6e73 6f72 4469 6374 4261  ct: TensorDictBa
-00007100: 7365 2920 2d3e 2054 656e 736f 7244 6963  se) -> TensorDic
-00007110: 7442 6173 653a 0d0a 2020 2020 2020 2020  tBase:..        
-00007120: 666f 7220 7420 696e 2072 6576 6572 7365  for t in reverse
-00007130: 6428 7365 6c66 2e74 7261 6e73 666f 726d  d(self.transform
-00007140: 7329 3a0d 0a20 2020 2020 2020 2020 2020  s):..           
-00007150: 2074 656e 736f 7264 6963 7420 3d20 742e   tensordict = t.
-00007160: 5f69 6e76 5f63 616c 6c28 7465 6e73 6f72  _inv_call(tensor
-00007170: 6469 6374 290d 0a20 2020 2020 2020 2072  dict)..        r
-00007180: 6574 7572 6e20 7465 6e73 6f72 6469 6374  eturn tensordict
-00007190: 0d0a 0d0a 2020 2020 6465 6620 7472 616e  ....    def tran
-000071a0: 7366 6f72 6d5f 696e 7075 745f 7370 6563  sform_input_spec
-000071b0: 2873 656c 662c 2069 6e70 7574 5f73 7065  (self, input_spe
-000071c0: 633a 2054 656e 736f 7253 7065 6329 202d  c: TensorSpec) -
-000071d0: 3e20 5465 6e73 6f72 5370 6563 3a0d 0a20  > TensorSpec:.. 
-000071e0: 2020 2020 2020 2066 6f72 2074 2069 6e20         for t in 
-000071f0: 7365 6c66 2e74 7261 6e73 666f 726d 735b  self.transforms[
-00007200: 3a3a 2d31 5d3a 0d0a 2020 2020 2020 2020  ::-1]:..        
-00007210: 2020 2020 696e 7075 745f 7370 6563 203d      input_spec =
-00007220: 2074 2e74 7261 6e73 666f 726d 5f69 6e70   t.transform_inp
-00007230: 7574 5f73 7065 6328 696e 7075 745f 7370  ut_spec(input_sp
-00007240: 6563 290d 0a20 2020 2020 2020 2072 6574  ec)..        ret
-00007250: 7572 6e20 696e 7075 745f 7370 6563 0d0a  urn input_spec..
-00007260: 0d0a 2020 2020 6465 6620 7472 616e 7366  ..    def transf
-00007270: 6f72 6d5f 6f62 7365 7276 6174 696f 6e5f  orm_observation_
-00007280: 7370 6563 2873 656c 662c 206f 6273 6572  spec(self, obser
-00007290: 7661 7469 6f6e 5f73 7065 633a 2054 656e  vation_spec: Ten
-000072a0: 736f 7253 7065 6329 202d 3e20 5465 6e73  sorSpec) -> Tens
-000072b0: 6f72 5370 6563 3a0d 0a20 2020 2020 2020  orSpec:..       
-000072c0: 2066 6f72 2074 2069 6e20 7365 6c66 2e74   for t in self.t
-000072d0: 7261 6e73 666f 726d 733a 0d0a 2020 2020  ransforms:..    
-000072e0: 2020 2020 2020 2020 6f62 7365 7276 6174          observat
-000072f0: 696f 6e5f 7370 6563 203d 2074 2e74 7261  ion_spec = t.tra
-00007300: 6e73 666f 726d 5f6f 6273 6572 7661 7469  nsform_observati
-00007310: 6f6e 5f73 7065 6328 6f62 7365 7276 6174  on_spec(observat
-00007320: 696f 6e5f 7370 6563 290d 0a20 2020 2020  ion_spec)..     
-00007330: 2020 2072 6574 7572 6e20 6f62 7365 7276     return observ
-00007340: 6174 696f 6e5f 7370 6563 0d0a 0d0a 2020  ation_spec....  
-00007350: 2020 6465 6620 7472 616e 7366 6f72 6d5f    def transform_
-00007360: 7265 7761 7264 5f73 7065 6328 7365 6c66  reward_spec(self
-00007370: 2c20 7265 7761 7264 5f73 7065 633a 2054  , reward_spec: T
-00007380: 656e 736f 7253 7065 6329 202d 3e20 5465  ensorSpec) -> Te
-00007390: 6e73 6f72 5370 6563 3a0d 0a20 2020 2020  nsorSpec:..     
-000073a0: 2020 2066 6f72 2074 2069 6e20 7365 6c66     for t in self
-000073b0: 2e74 7261 6e73 666f 726d 733a 0d0a 2020  .transforms:..  
-000073c0: 2020 2020 2020 2020 2020 7265 7761 7264            reward
-000073d0: 5f73 7065 6320 3d20 742e 7472 616e 7366  _spec = t.transf
-000073e0: 6f72 6d5f 7265 7761 7264 5f73 7065 6328  orm_reward_spec(
-000073f0: 7265 7761 7264 5f73 7065 6329 0d0a 2020  reward_spec)..  
-00007400: 2020 2020 2020 7265 7475 726e 2072 6577        return rew
-00007410: 6172 645f 7370 6563 0d0a 0d0a 2020 2020  ard_spec....    
-00007420: 6465 6620 5f5f 6765 7469 7465 6d5f 5f28  def __getitem__(
-00007430: 7365 6c66 2c20 6974 656d 3a20 556e 696f  self, item: Unio
-00007440: 6e5b 696e 742c 2073 6c69 6365 2c20 4c69  n[int, slice, Li
-00007450: 7374 5d29 202d 3e20 556e 696f 6e3a 0d0a  st]) -> Union:..
-00007460: 2020 2020 2020 2020 7472 616e 7366 6f72          transfor
-00007470: 6d20 3d20 7365 6c66 2e74 7261 6e73 666f  m = self.transfo
-00007480: 726d 730d 0a20 2020 2020 2020 2074 7261  rms..        tra
-00007490: 6e73 666f 726d 203d 2074 7261 6e73 666f  nsform = transfo
-000074a0: 726d 5b69 7465 6d5d 0d0a 2020 2020 2020  rm[item]..      
-000074b0: 2020 6966 206e 6f74 2069 7369 6e73 7461    if not isinsta
-000074c0: 6e63 6528 7472 616e 7366 6f72 6d2c 2054  nce(transform, T
-000074d0: 7261 6e73 666f 726d 293a 0d0a 2020 2020  ransform):..    
-000074e0: 2020 2020 2020 2020 6f75 7420 3d20 436f          out = Co
-000074f0: 6d70 6f73 6528 2a28 742e 636c 6f6e 6528  mpose(*(t.clone(
-00007500: 2920 666f 7220 7420 696e 2073 656c 662e  ) for t in self.
-00007510: 7472 616e 7366 6f72 6d73 5b69 7465 6d5d  transforms[item]
-00007520: 2929 0d0a 2020 2020 2020 2020 2020 2020  ))..            
-00007530: 6f75 742e 7365 745f 636f 6e74 6169 6e65  out.set_containe
-00007540: 7228 7365 6c66 2e70 6172 656e 7429 0d0a  r(self.parent)..
-00007550: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-00007560: 726e 206f 7574 0d0a 2020 2020 2020 2020  rn out..        
-00007570: 7265 7475 726e 2074 7261 6e73 666f 726d  return transform
-00007580: 0d0a 0d0a 2020 2020 6465 6620 6475 6d70  ....    def dump
-00007590: 2873 656c 662c 202a 2a6b 7761 7267 7329  (self, **kwargs)
-000075a0: 202d 3e20 4e6f 6e65 3a0d 0a20 2020 2020   -> None:..     
-000075b0: 2020 2066 6f72 2074 2069 6e20 7365 6c66     for t in self
-000075c0: 3a0d 0a20 2020 2020 2020 2020 2020 2074  :..            t
-000075d0: 2e64 756d 7028 2a2a 6b77 6172 6773 290d  .dump(**kwargs).
-000075e0: 0a0d 0a20 2020 2064 6566 2072 6573 6574  ...    def reset
-000075f0: 2873 656c 662c 2074 656e 736f 7264 6963  (self, tensordic
-00007600: 743a 2054 656e 736f 7244 6963 7442 6173  t: TensorDictBas
-00007610: 6529 202d 3e20 5465 6e73 6f72 4469 6374  e) -> TensorDict
-00007620: 4261 7365 3a0d 0a20 2020 2020 2020 2066  Base:..        f
-00007630: 6f72 2074 2069 6e20 7365 6c66 2e74 7261  or t in self.tra
-00007640: 6e73 666f 726d 733a 0d0a 2020 2020 2020  nsforms:..      
-00007650: 2020 2020 2020 7465 6e73 6f72 6469 6374        tensordict
-00007660: 203d 2074 2e72 6573 6574 2874 656e 736f   = t.reset(tenso
-00007670: 7264 6963 7429 0d0a 2020 2020 2020 2020  rdict)..        
-00007680: 7265 7475 726e 2074 656e 736f 7264 6963  return tensordic
-00007690: 740d 0a0d 0a20 2020 2064 6566 2069 6e69  t....    def ini
-000076a0: 7428 7365 6c66 2c20 7465 6e73 6f72 6469  t(self, tensordi
-000076b0: 6374 3a20 5465 6e73 6f72 4469 6374 4261  ct: TensorDictBa
-000076c0: 7365 2920 2d3e 204e 6f6e 653a 0d0a 2020  se) -> None:..  
-000076d0: 2020 2020 2020 666f 7220 7420 696e 2073        for t in s
-000076e0: 656c 662e 7472 616e 7366 6f72 6d73 3a0d  elf.transforms:.
-000076f0: 0a20 2020 2020 2020 2020 2020 2074 2e69  .            t.i
-00007700: 6e69 7428 7465 6e73 6f72 6469 6374 290d  nit(tensordict).
-00007710: 0a0d 0a20 2020 2064 6566 2061 7070 656e  ...    def appen
-00007720: 6428 7365 6c66 2c20 7472 616e 7366 6f72  d(self, transfor
-00007730: 6d29 3a0d 0a20 2020 2020 2020 2073 656c  m):..        sel
-00007740: 662e 656d 7074 795f 6361 6368 6528 290d  f.empty_cache().
-00007750: 0a20 2020 2020 2020 2069 6620 6e6f 7420  .        if not 
-00007760: 6973 696e 7374 616e 6365 2874 7261 6e73  isinstance(trans
-00007770: 666f 726d 2c20 5472 616e 7366 6f72 6d29  form, Transform)
-00007780: 3a0d 0a20 2020 2020 2020 2020 2020 2072  :..            r
-00007790: 6169 7365 2056 616c 7565 4572 726f 7228  aise ValueError(
-000077a0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-000077b0: 2020 2243 6f6d 706f 7365 2e61 7070 656e    "Compose.appen
-000077c0: 6420 6578 7065 6374 6564 2061 2074 7261  d expected a tra
-000077d0: 6e73 666f 726d 2062 7574 2072 6563 6569  nsform but recei
-000077e0: 7665 6420 616e 206f 626a 6563 7420 6f66  ved an object of
-000077f0: 2022 0d0a 2020 2020 2020 2020 2020 2020   "..            
-00007800: 2020 2020 6622 7479 7065 207b 7479 7065      f"type {type
-00007810: 2874 7261 6e73 666f 726d 297d 2069 6e73  (transform)} ins
-00007820: 7465 6164 2e22 0d0a 2020 2020 2020 2020  tead."..        
-00007830: 2020 2020 290d 0a20 2020 2020 2020 2074      )..        t
-00007840: 7261 6e73 666f 726d 2e65 7661 6c28 290d  ransform.eval().
-00007850: 0a20 2020 2020 2020 2073 656c 662e 7472  .        self.tr
-00007860: 616e 7366 6f72 6d73 2e61 7070 656e 6428  ansforms.append(
-00007870: 7472 616e 7366 6f72 6d29 0d0a 2020 2020  transform)..    
-00007880: 2020 2020 7472 616e 7366 6f72 6d2e 7365      transform.se
-00007890: 745f 636f 6e74 6169 6e65 7228 7365 6c66  t_container(self
-000078a0: 290d 0a0d 0a20 2020 2064 6566 2069 6e73  )....    def ins
-000078b0: 6572 7428 7365 6c66 2c20 696e 6465 783a  ert(self, index:
-000078c0: 2069 6e74 2c20 7472 616e 7366 6f72 6d3a   int, transform:
-000078d0: 2054 7261 6e73 666f 726d 2920 2d3e 204e   Transform) -> N
-000078e0: 6f6e 653a 0d0a 2020 2020 2020 2020 6966  one:..        if
-000078f0: 206e 6f74 2069 7369 6e73 7461 6e63 6528   not isinstance(
-00007900: 7472 616e 7366 6f72 6d2c 2054 7261 6e73  transform, Trans
-00007910: 666f 726d 293a 0d0a 2020 2020 2020 2020  form):..        
-00007920: 2020 2020 7261 6973 6520 5661 6c75 6545      raise ValueE
-00007930: 7272 6f72 280d 0a20 2020 2020 2020 2020  rror(..         
-00007940: 2020 2020 2020 2022 436f 6d70 6f73 652e         "Compose.
-00007950: 6170 7065 6e64 2065 7870 6563 7465 6420  append expected 
-00007960: 6120 7472 616e 7366 6f72 6d20 6275 7420  a transform but 
-00007970: 7265 6365 6976 6564 2061 6e20 6f62 6a65  received an obje
-00007980: 6374 206f 6620 220d 0a20 2020 2020 2020  ct of "..       
-00007990: 2020 2020 2020 2020 2066 2274 7970 6520           f"type 
-000079a0: 7b74 7970 6528 7472 616e 7366 6f72 6d29  {type(transform)
-000079b0: 7d20 696e 7374 6561 642e 220d 0a20 2020  } instead."..   
-000079c0: 2020 2020 2020 2020 2029 0d0a 0d0a 2020           )....  
-000079d0: 2020 2020 2020 6966 2061 6273 2869 6e64        if abs(ind
-000079e0: 6578 2920 3e20 6c65 6e28 7365 6c66 2e74  ex) > len(self.t
-000079f0: 7261 6e73 666f 726d 7329 3a0d 0a20 2020  ransforms):..   
-00007a00: 2020 2020 2020 2020 2072 6169 7365 2056           raise V
-00007a10: 616c 7565 4572 726f 7228 0d0a 2020 2020  alueError(..    
-00007a20: 2020 2020 2020 2020 2020 2020 6622 496e              f"In
-00007a30: 6465 7820 6578 7065 6374 6564 2074 6f20  dex expected to 
-00007a40: 6265 2062 6574 7765 656e 205b 2d7b 6c65  be between [-{le
-00007a50: 6e28 7365 6c66 2e74 7261 6e73 666f 726d  n(self.transform
-00007a60: 7329 7d2c 207b 6c65 6e28 7365 6c66 2e74  s)}, {len(self.t
-00007a70: 7261 6e73 666f 726d 7329 7d5d 2067 6f74  ransforms)}] got
-00007a80: 2069 6e64 6578 3d7b 696e 6465 787d 220d   index={index}".
-00007a90: 0a20 2020 2020 2020 2020 2020 2029 0d0a  .            )..
-00007aa0: 0d0a 2020 2020 2020 2020 2320 656d 7074  ..        # empt
-00007ab0: 7920 6361 6368 6520 6f66 2061 6c6c 2074  y cache of all t
-00007ac0: 7261 6e73 666f 726d 7320 746f 2072 6573  ransforms to res
-00007ad0: 6574 2070 6172 656e 7473 2061 6e64 2073  et parents and s
-00007ae0: 7065 6373 0d0a 2020 2020 2020 2020 7365  pecs..        se
-00007af0: 6c66 2e65 6d70 7479 5f63 6163 6865 2829  lf.empty_cache()
-00007b00: 0d0a 2020 2020 2020 2020 6966 2069 6e64  ..        if ind
-00007b10: 6578 203c 2030 3a0d 0a20 2020 2020 2020  ex < 0:..       
-00007b20: 2020 2020 2069 6e64 6578 203d 2069 6e64       index = ind
-00007b30: 6578 202b 206c 656e 2873 656c 662e 7472  ex + len(self.tr
-00007b40: 616e 7366 6f72 6d73 290d 0a20 2020 2020  ansforms)..     
-00007b50: 2020 2074 7261 6e73 666f 726d 2e65 7661     transform.eva
-00007b60: 6c28 290d 0a20 2020 2020 2020 2073 656c  l()..        sel
-00007b70: 662e 7472 616e 7366 6f72 6d73 2e69 6e73  f.transforms.ins
-00007b80: 6572 7428 696e 6465 782c 2074 7261 6e73  ert(index, trans
-00007b90: 666f 726d 290d 0a20 2020 2020 2020 2074  form)..        t
-00007ba0: 7261 6e73 666f 726d 2e73 6574 5f63 6f6e  ransform.set_con
-00007bb0: 7461 696e 6572 2873 656c 6629 0d0a 0d0a  tainer(self)....
-00007bc0: 2020 2020 6465 6620 746f 2873 656c 662c      def to(self,
-00007bd0: 2064 6573 743a 2055 6e69 6f6e 5b74 6f72   dest: Union[tor
-00007be0: 6368 2e64 7479 7065 2c20 4445 5649 4345  ch.dtype, DEVICE
-00007bf0: 5f54 5950 494e 475d 2920 2d3e 2043 6f6d  _TYPING]) -> Com
-00007c00: 706f 7365 3a0d 0a20 2020 2020 2020 2066  pose:..        f
-00007c10: 6f72 2074 2069 6e20 7365 6c66 2e74 7261  or t in self.tra
-00007c20: 6e73 666f 726d 733a 0d0a 2020 2020 2020  nsforms:..      
-00007c30: 2020 2020 2020 742e 746f 2864 6573 7429        t.to(dest)
-00007c40: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
-00007c50: 2073 7570 6572 2829 2e74 6f28 6465 7374   super().to(dest
-00007c60: 290d 0a0d 0a20 2020 2064 6566 205f 5f69  )....    def __i
-00007c70: 7465 725f 5f28 7365 6c66 293a 0d0a 2020  ter__(self):..  
-00007c80: 2020 2020 2020 7969 656c 6420 6672 6f6d        yield from
-00007c90: 2073 656c 662e 7472 616e 7366 6f72 6d73   self.transforms
-00007ca0: 0d0a 0d0a 2020 2020 6465 6620 5f5f 6c65  ....    def __le
-00007cb0: 6e5f 5f28 7365 6c66 293a 0d0a 2020 2020  n__(self):..    
-00007cc0: 2020 2020 7265 7475 726e 206c 656e 2873      return len(s
-00007cd0: 656c 662e 7472 616e 7366 6f72 6d73 290d  elf.transforms).
-00007ce0: 0a0d 0a20 2020 2064 6566 205f 5f72 6570  ...    def __rep
-00007cf0: 725f 5f28 7365 6c66 2920 2d3e 2073 7472  r__(self) -> str
-00007d00: 3a0d 0a20 2020 2020 2020 206c 6179 6572  :..        layer
-00007d10: 735f 7374 7220 3d20 222c 5c6e 222e 6a6f  s_str = ",\n".jo
-00007d20: 696e 280d 0a20 2020 2020 2020 2020 2020  in(..           
-00007d30: 205b 696e 6465 6e74 2873 7472 2874 7273   [indent(str(trs
-00007d40: 6629 2c20 3420 2a20 2220 2229 2066 6f72  f), 4 * " ") for
-00007d50: 2074 7273 6620 696e 2073 656c 662e 7472   trsf in self.tr
-00007d60: 616e 7366 6f72 6d73 5d0d 0a20 2020 2020  ansforms]..     
-00007d70: 2020 2029 0d0a 2020 2020 2020 2020 7265     )..        re
-00007d80: 7475 726e 2066 227b 7365 6c66 2e5f 5f63  turn f"{self.__c
-00007d90: 6c61 7373 5f5f 2e5f 5f6e 616d 655f 5f7d  lass__.__name__}
-00007da0: 285c 6e7b 696e 6465 6e74 286c 6179 6572  (\n{indent(layer
-00007db0: 735f 7374 722c 2034 202a 2027 2027 297d  s_str, 4 * ' ')}
-00007dc0: 2922 0d0a 0d0a 2020 2020 6465 6620 656d  )"....    def em
-00007dd0: 7074 795f 6361 6368 6528 7365 6c66 293a  pty_cache(self):
-00007de0: 0d0a 2020 2020 2020 2020 666f 7220 7420  ..        for t 
-00007df0: 696e 2073 656c 662e 7472 616e 7366 6f72  in self.transfor
-00007e00: 6d73 3a0d 0a20 2020 2020 2020 2020 2020  ms:..           
-00007e10: 2074 2e65 6d70 7479 5f63 6163 6865 2829   t.empty_cache()
-00007e20: 0d0a 2020 2020 2020 2020 7375 7065 7228  ..        super(
-00007e30: 292e 656d 7074 795f 6361 6368 6528 290d  ).empty_cache().
-00007e40: 0a0d 0a20 2020 2064 6566 2072 6573 6574  ...    def reset
-00007e50: 5f70 6172 656e 7428 7365 6c66 293a 0d0a  _parent(self):..
-00007e60: 2020 2020 2020 2020 666f 7220 7420 696e          for t in
-00007e70: 2073 656c 662e 7472 616e 7366 6f72 6d73   self.transforms
-00007e80: 3a0d 0a20 2020 2020 2020 2020 2020 2074  :..            t
-00007e90: 2e72 6573 6574 5f70 6172 656e 7428 290d  .reset_parent().
-00007ea0: 0a20 2020 2020 2020 2073 7570 6572 2829  .        super()
-00007eb0: 2e72 6573 6574 5f70 6172 656e 7428 290d  .reset_parent().
-00007ec0: 0a0d 0a20 2020 2064 6566 2063 6c6f 6e65  ...    def clone
-00007ed0: 2873 656c 6629 3a0d 0a20 2020 2020 2020  (self):..       
-00007ee0: 2074 7261 6e73 666f 726d 7320 3d20 5b5d   transforms = []
-00007ef0: 0d0a 2020 2020 2020 2020 666f 7220 7420  ..        for t 
-00007f00: 696e 2073 656c 662e 7472 616e 7366 6f72  in self.transfor
-00007f10: 6d73 3a0d 0a20 2020 2020 2020 2020 2020  ms:..           
-00007f20: 2074 7261 6e73 666f 726d 732e 6170 7065   transforms.appe
-00007f30: 6e64 2874 2e63 6c6f 6e65 2829 290d 0a20  nd(t.clone()).. 
-00007f40: 2020 2020 2020 2072 6574 7572 6e20 436f         return Co
-00007f50: 6d70 6f73 6528 2a74 7261 6e73 666f 726d  mpose(*transform
-00007f60: 7329 0d0a 0d0a 0d0a 636c 6173 7320 546f  s)......class To
-00007f70: 5465 6e73 6f72 496d 6167 6528 4f62 7365  TensorImage(Obse
-00007f80: 7276 6174 696f 6e54 7261 6e73 666f 726d  rvationTransform
-00007f90: 293a 0d0a 2020 2020 2222 2254 7261 6e73  ):..    """Trans
-00007fa0: 666f 726d 7320 6120 6e75 6d70 792d 6c69  forms a numpy-li
-00007fb0: 6b65 2069 6d61 6765 2028 3320 7820 5720  ke image (3 x W 
-00007fc0: 7820 4829 2074 6f20 6120 7079 746f 7263  x H) to a pytorc
-00007fd0: 6820 696d 6167 6520 2833 2078 2057 2078  h image (3 x W x
-00007fe0: 2048 292e 0d0a 0d0a 2020 2020 5472 616e   H).....    Tran
-00007ff0: 7366 6f72 6d73 2061 6e20 6f62 7365 7276  sforms an observ
-00008000: 6174 696f 6e20 696d 6167 6520 6672 6f6d  ation image from
-00008010: 2061 2028 2e2e 2e20 7820 5720 7820 4820   a (... x W x H 
-00008020: 7820 3329 2030 2e2e 3235 3520 7569 6e74  x 3) 0..255 uint
-00008030: 380d 0a20 2020 2074 656e 736f 7220 746f  8..    tensor to
-00008040: 2061 2073 696e 676c 652f 646f 7562 6c65   a single/double
-00008050: 2070 7265 6369 7369 6f6e 2066 6c6f 6174   precision float
-00008060: 696e 6720 706f 696e 7420 2833 2078 2057  ing point (3 x W
-00008070: 2078 2048 2920 7465 6e73 6f72 0d0a 2020   x H) tensor..  
-00008080: 2020 7769 7468 2076 616c 7565 7320 6265    with values be
-00008090: 7477 6565 6e20 3020 616e 6420 312e 0d0a  tween 0 and 1...
-000080a0: 0d0a 2020 2020 4172 6773 3a0d 0a20 2020  ..    Args:..   
-000080b0: 2020 2020 2075 6e73 7175 6565 7a65 2028       unsqueeze (
-000080c0: 626f 6f6c 293a 2069 6620 5472 7565 2c20  bool): if True, 
-000080d0: 7468 6520 6f62 7365 7276 6174 696f 6e20  the observation 
-000080e0: 7465 6e73 6f72 2069 7320 756e 7371 7565  tensor is unsque
-000080f0: 657a 6564 0d0a 2020 2020 2020 2020 2020  ezed..          
-00008100: 2020 616c 6f6e 6720 7468 6520 6669 7273    along the firs
-00008110: 7420 6469 6d65 6e73 696f 6e2e 2064 6566  t dimension. def
-00008120: 6175 6c74 3d46 616c 7365 2e0d 0a20 2020  ault=False...   
-00008130: 2020 2020 2064 7479 7065 2028 746f 7263       dtype (torc
-00008140: 682e 6474 7970 652c 206f 7074 696f 6e61  h.dtype, optiona
-00008150: 6c29 3a20 6474 7970 6520 746f 2075 7365  l): dtype to use
-00008160: 2066 6f72 2074 6865 2072 6573 756c 7469   for the resulti
-00008170: 6e67 0d0a 2020 2020 2020 2020 2020 2020  ng..            
-00008180: 6f62 7365 7276 6174 696f 6e73 2e0d 0a0d  observations....
-00008190: 0a20 2020 2045 7861 6d70 6c65 733a 0d0a  .    Examples:..
-000081a0: 2020 2020 2020 2020 3e3e 3e20 7472 616e          >>> tran
-000081b0: 7366 6f72 6d20 3d20 546f 5465 6e73 6f72  sform = ToTensor
-000081c0: 496d 6167 6528 696e 5f6b 6579 733d 5b22  Image(in_keys=["
-000081d0: 7069 7865 6c73 225d 290d 0a20 2020 2020  pixels"])..     
-000081e0: 2020 203e 3e3e 2072 6920 3d20 746f 7263     >>> ri = torc
-000081f0: 682e 7261 6e64 696e 7428 302c 2032 3535  h.randint(0, 255
-00008200: 2c20 2831 2c31 2c31 302c 3131 2c33 292c  , (1,1,10,11,3),
-00008210: 2064 7479 7065 3d74 6f72 6368 2e75 696e   dtype=torch.uin
-00008220: 7438 290d 0a20 2020 2020 2020 203e 3e3e  t8)..        >>>
-00008230: 2074 6420 3d20 5465 6e73 6f72 4469 6374   td = TensorDict
-00008240: 280d 0a20 2020 2020 2020 202e 2e2e 2020  (..        ...  
-00008250: 2020 207b 2270 6978 656c 7322 3a20 7269     {"pixels": ri
-00008260: 7d2c 0d0a 2020 2020 2020 2020 2e2e 2e20  },..        ... 
-00008270: 2020 2020 5b31 2c20 315d 290d 0a20 2020      [1, 1])..   
-00008280: 2020 2020 203e 3e3e 205f 203d 2074 7261       >>> _ = tra
-00008290: 6e73 666f 726d 2874 6429 0d0a 2020 2020  nsform(td)..    
-000082a0: 2020 2020 3e3e 3e20 6f62 7320 3d20 7464      >>> obs = td
-000082b0: 2e67 6574 2822 7069 7865 6c73 2229 0d0a  .get("pixels")..
-000082c0: 2020 2020 2020 2020 3e3e 3e20 7072 696e          >>> prin
-000082d0: 7428 6f62 732e 7368 6170 652c 206f 6273  t(obs.shape, obs
-000082e0: 2e64 7479 7065 290d 0a20 2020 2020 2020  .dtype)..       
-000082f0: 2074 6f72 6368 2e53 697a 6528 5b31 2c20   torch.Size([1, 
-00008300: 312c 2033 2c20 3130 2c20 3131 5d29 2074  1, 3, 10, 11]) t
-00008310: 6f72 6368 2e66 6c6f 6174 3332 0d0a 2020  orch.float32..  
-00008320: 2020 2222 220d 0a0d 0a20 2020 2064 6566    """....    def
-00008330: 205f 5f69 6e69 745f 5f28 0d0a 2020 2020   __init__(..    
-00008340: 2020 2020 7365 6c66 2c0d 0a20 2020 2020      self,..     
-00008350: 2020 2075 6e73 7175 6565 7a65 3a20 626f     unsqueeze: bo
-00008360: 6f6c 203d 2046 616c 7365 2c0d 0a20 2020  ol = False,..   
-00008370: 2020 2020 2064 7479 7065 3a20 4f70 7469       dtype: Opti
-00008380: 6f6e 616c 5b74 6f72 6368 2e64 6576 6963  onal[torch.devic
-00008390: 655d 203d 204e 6f6e 652c 0d0a 2020 2020  e] = None,..    
-000083a0: 2020 2020 696e 5f6b 6579 733a 204f 7074      in_keys: Opt
-000083b0: 696f 6e61 6c5b 5365 7175 656e 6365 5b73  ional[Sequence[s
-000083c0: 7472 5d5d 203d 204e 6f6e 652c 0d0a 2020  tr]] = None,..  
-000083d0: 2020 2020 2020 6f75 745f 6b65 7973 3a20        out_keys: 
-000083e0: 4f70 7469 6f6e 616c 5b53 6571 7565 6e63  Optional[Sequenc
-000083f0: 655b 7374 725d 5d20 3d20 4e6f 6e65 2c0d  e[str]] = None,.
-00008400: 0a20 2020 2029 3a0d 0a20 2020 2020 2020  .    ):..       
-00008410: 2069 6620 696e 5f6b 6579 7320 6973 204e   if in_keys is N
-00008420: 6f6e 653a 0d0a 2020 2020 2020 2020 2020  one:..          
-00008430: 2020 696e 5f6b 6579 7320 3d20 494d 4147    in_keys = IMAG
-00008440: 455f 4b45 5953 2020 2320 6465 6661 756c  E_KEYS  # defaul
-00008450: 740d 0a20 2020 2020 2020 2073 7570 6572  t..        super
-00008460: 2829 2e5f 5f69 6e69 745f 5f28 696e 5f6b  ().__init__(in_k
-00008470: 6579 733d 696e 5f6b 6579 732c 206f 7574  eys=in_keys, out
-00008480: 5f6b 6579 733d 6f75 745f 6b65 7973 290d  _keys=out_keys).
-00008490: 0a20 2020 2020 2020 2073 656c 662e 756e  .        self.un
-000084a0: 7371 7565 657a 6520 3d20 756e 7371 7565  squeeze = unsque
-000084b0: 657a 650d 0a20 2020 2020 2020 2073 656c  eze..        sel
-000084c0: 662e 6474 7970 6520 3d20 6474 7970 6520  f.dtype = dtype 
-000084d0: 6966 2064 7479 7065 2069 7320 6e6f 7420  if dtype is not 
-000084e0: 4e6f 6e65 2065 6c73 6520 746f 7263 682e  None else torch.
-000084f0: 6765 745f 6465 6661 756c 745f 6474 7970  get_default_dtyp
-00008500: 6528 290d 0a0d 0a20 2020 2064 6566 205f  e()....    def _
-00008510: 6170 706c 795f 7472 616e 7366 6f72 6d28  apply_transform(
-00008520: 7365 6c66 2c20 6f62 7365 7276 6174 696f  self, observatio
-00008530: 6e3a 2074 6f72 6368 2e46 6c6f 6174 5465  n: torch.FloatTe
-00008540: 6e73 6f72 2920 2d3e 2074 6f72 6368 2e54  nsor) -> torch.T
-00008550: 656e 736f 723a 0d0a 2020 2020 2020 2020  ensor:..        
-00008560: 6f62 7365 7276 6174 696f 6e20 3d20 6f62  observation = ob
-00008570: 7365 7276 6174 696f 6e2e 7065 726d 7574  servation.permut
-00008580: 6528 0d0a 2020 2020 2020 2020 2020 2020  e(..            
-00008590: 2a6c 6973 7428 7261 6e67 6528 6f62 7365  *list(range(obse
-000085a0: 7276 6174 696f 6e2e 6e64 696d 656e 7369  rvation.ndimensi
-000085b0: 6f6e 2829 202d 2033 2929 2c20 2d31 2c20  on() - 3)), -1, 
-000085c0: 2d33 2c20 2d32 0d0a 2020 2020 2020 2020  -3, -2..        
-000085d0: 290d 0a20 2020 2020 2020 206f 6273 6572  )..        obser
-000085e0: 7661 7469 6f6e 203d 206f 6273 6572 7661  vation = observa
-000085f0: 7469 6f6e 2e64 6976 2832 3535 292e 746f  tion.div(255).to
-00008600: 2873 656c 662e 6474 7970 6529 0d0a 2020  (self.dtype)..  
-00008610: 2020 2020 2020 6966 206f 6273 6572 7661        if observa
-00008620: 7469 6f6e 2e6e 6469 6d65 6e73 696f 6e28  tion.ndimension(
-00008630: 2920 3d3d 2033 2061 6e64 2073 656c 662e  ) == 3 and self.
-00008640: 756e 7371 7565 657a 653a 0d0a 2020 2020  unsqueeze:..    
-00008650: 2020 2020 2020 2020 6f62 7365 7276 6174          observat
-00008660: 696f 6e20 3d20 6f62 7365 7276 6174 696f  ion = observatio
-00008670: 6e2e 756e 7371 7565 657a 6528 3029 0d0a  n.unsqueeze(0)..
-00008680: 2020 2020 2020 2020 7265 7475 726e 206f          return o
-00008690: 6273 6572 7661 7469 6f6e 0d0a 0d0a 2020  bservation....  
-000086a0: 2020 405f 6170 706c 795f 746f 5f63 6f6d    @_apply_to_com
-000086b0: 706f 7369 7465 0d0a 2020 2020 6465 6620  posite..    def 
-000086c0: 7472 616e 7366 6f72 6d5f 6f62 7365 7276  transform_observ
-000086d0: 6174 696f 6e5f 7370 6563 2873 656c 662c  ation_spec(self,
-000086e0: 206f 6273 6572 7661 7469 6f6e 5f73 7065   observation_spe
-000086f0: 633a 2054 656e 736f 7253 7065 6329 202d  c: TensorSpec) -
-00008700: 3e20 5465 6e73 6f72 5370 6563 3a0d 0a20  > TensorSpec:.. 
-00008710: 2020 2020 2020 206f 6273 6572 7661 7469         observati
-00008720: 6f6e 5f73 7065 6320 3d20 7365 6c66 2e5f  on_spec = self._
-00008730: 7069 7865 6c5f 6f62 7365 7276 6174 696f  pixel_observatio
-00008740: 6e28 6f62 7365 7276 6174 696f 6e5f 7370  n(observation_sp
-00008750: 6563 290d 0a20 2020 2020 2020 206f 6273  ec)..        obs
-00008760: 6572 7661 7469 6f6e 5f73 7065 632e 7368  ervation_spec.sh
-00008770: 6170 6520 3d20 746f 7263 682e 5369 7a65  ape = torch.Size
-00008780: 280d 0a20 2020 2020 2020 2020 2020 205b  (..            [
-00008790: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-000087a0: 2020 2a6f 6273 6572 7661 7469 6f6e 5f73    *observation_s
-000087b0: 7065 632e 7368 6170 655b 3a2d 335d 2c0d  pec.shape[:-3],.
-000087c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000087d0: 206f 6273 6572 7661 7469 6f6e 5f73 7065   observation_spe
-000087e0: 632e 7368 6170 655b 2d31 5d2c 0d0a 2020  c.shape[-1],..  
-000087f0: 2020 2020 2020 2020 2020 2020 2020 6f62                ob
-00008800: 7365 7276 6174 696f 6e5f 7370 6563 2e73  servation_spec.s
-00008810: 6861 7065 5b2d 335d 2c0d 0a20 2020 2020  hape[-3],..     
-00008820: 2020 2020 2020 2020 2020 206f 6273 6572             obser
-00008830: 7661 7469 6f6e 5f73 7065 632e 7368 6170  vation_spec.shap
-00008840: 655b 2d32 5d2c 0d0a 2020 2020 2020 2020  e[-2],..        
-00008850: 2020 2020 5d0d 0a20 2020 2020 2020 2029      ]..        )
-00008860: 0d0a 2020 2020 2020 2020 6f62 7365 7276  ..        observ
-00008870: 6174 696f 6e5f 7370 6563 2e64 7479 7065  ation_spec.dtype
-00008880: 203d 2073 656c 662e 6474 7970 650d 0a20   = self.dtype.. 
-00008890: 2020 2020 2020 2072 6574 7572 6e20 6f62         return ob
-000088a0: 7365 7276 6174 696f 6e5f 7370 6563 0d0a  servation_spec..
-000088b0: 0d0a 2020 2020 6465 6620 5f70 6978 656c  ..    def _pixel
-000088c0: 5f6f 6273 6572 7661 7469 6f6e 2873 656c  _observation(sel
-000088d0: 662c 2073 7065 633a 2054 656e 736f 7253  f, spec: TensorS
-000088e0: 7065 6329 202d 3e20 4e6f 6e65 3a0d 0a20  pec) -> None:.. 
-000088f0: 2020 2020 2020 2069 6620 6973 696e 7374         if isinst
-00008900: 616e 6365 2873 7065 632e 7370 6163 652c  ance(spec.space,
-00008910: 2043 6f6e 7469 6e75 6f75 7342 6f78 293a   ContinuousBox):
-00008920: 0d0a 2020 2020 2020 2020 2020 2020 7370  ..            sp
-00008930: 6563 2e73 7061 6365 2e6d 6178 696d 756d  ec.space.maximum
-00008940: 203d 2073 656c 662e 5f61 7070 6c79 5f74   = self._apply_t
-00008950: 7261 6e73 666f 726d 2873 7065 632e 7370  ransform(spec.sp
-00008960: 6163 652e 6d61 7869 6d75 6d29 0d0a 2020  ace.maximum)..  
-00008970: 2020 2020 2020 2020 2020 7370 6563 2e73            spec.s
-00008980: 7061 6365 2e6d 696e 696d 756d 203d 2073  pace.minimum = s
-00008990: 656c 662e 5f61 7070 6c79 5f74 7261 6e73  elf._apply_trans
-000089a0: 666f 726d 2873 7065 632e 7370 6163 652e  form(spec.space.
-000089b0: 6d69 6e69 6d75 6d29 0d0a 2020 2020 2020  minimum)..      
-000089c0: 2020 7265 7475 726e 2073 7065 630d 0a0d    return spec...
-000089d0: 0a0d 0a63 6c61 7373 2052 6577 6172 6443  ...class RewardC
-000089e0: 6c69 7070 696e 6728 5472 616e 7366 6f72  lipping(Transfor
-000089f0: 6d29 3a0d 0a20 2020 2022 2222 436c 6970  m):..    """Clip
-00008a00: 7320 7468 6520 7265 7761 7264 2062 6574  s the reward bet
-00008a10: 7765 656e 2060 636c 616d 705f 6d69 6e60  ween `clamp_min`
-00008a20: 2061 6e64 2060 636c 616d 705f 6d61 7860   and `clamp_max`
-00008a30: 2e0d 0a0d 0a20 2020 2041 7267 733a 0d0a  .....    Args:..
-00008a40: 2020 2020 2020 2020 636c 6970 5f6d 696e          clip_min
-00008a50: 2028 7363 616c 6172 293a 206d 696e 696d   (scalar): minim
-00008a60: 756d 2076 616c 7565 206f 6620 7468 6520  um value of the 
-00008a70: 7265 7375 6c74 696e 6720 7265 7761 7264  resulting reward
-00008a80: 2e0d 0a20 2020 2020 2020 2063 6c69 705f  ...        clip_
-00008a90: 6d61 7820 2873 6361 6c61 7229 3a20 6d61  max (scalar): ma
-00008aa0: 7869 6d75 6d20 7661 6c75 6520 6f66 2074  ximum value of t
-00008ab0: 6865 2072 6573 756c 7469 6e67 2072 6577  he resulting rew
-00008ac0: 6172 642e 0d0a 0d0a 2020 2020 2222 220d  ard.....    """.
-00008ad0: 0a0d 0a20 2020 2064 6566 205f 5f69 6e69  ...    def __ini
-00008ae0: 745f 5f28 0d0a 2020 2020 2020 2020 7365  t__(..        se
-00008af0: 6c66 2c0d 0a20 2020 2020 2020 2063 6c61  lf,..        cla
-00008b00: 6d70 5f6d 696e 3a20 666c 6f61 7420 3d20  mp_min: float = 
-00008b10: 4e6f 6e65 2c0d 0a20 2020 2020 2020 2063  None,..        c
-00008b20: 6c61 6d70 5f6d 6178 3a20 666c 6f61 7420  lamp_max: float 
-00008b30: 3d20 4e6f 6e65 2c0d 0a20 2020 2020 2020  = None,..       
-00008b40: 2069 6e5f 6b65 7973 3a20 4f70 7469 6f6e   in_keys: Option
-00008b50: 616c 5b53 6571 7565 6e63 655b 7374 725d  al[Sequence[str]
-00008b60: 5d20 3d20 4e6f 6e65 2c0d 0a20 2020 2020  ] = None,..     
-00008b70: 2020 206f 7574 5f6b 6579 733a 204f 7074     out_keys: Opt
-00008b80: 696f 6e61 6c5b 5365 7175 656e 6365 5b73  ional[Sequence[s
-00008b90: 7472 5d5d 203d 204e 6f6e 652c 0d0a 2020  tr]] = None,..  
-00008ba0: 2020 293a 0d0a 2020 2020 2020 2020 6966    ):..        if
-00008bb0: 2069 6e5f 6b65 7973 2069 7320 4e6f 6e65   in_keys is None
-00008bc0: 3a0d 0a20 2020 2020 2020 2020 2020 2069  :..            i
-00008bd0: 6e5f 6b65 7973 203d 205b 2272 6577 6172  n_keys = ["rewar
-00008be0: 6422 5d0d 0a20 2020 2020 2020 2073 7570  d"]..        sup
-00008bf0: 6572 2829 2e5f 5f69 6e69 745f 5f28 696e  er().__init__(in
-00008c00: 5f6b 6579 733d 696e 5f6b 6579 732c 206f  _keys=in_keys, o
-00008c10: 7574 5f6b 6579 733d 6f75 745f 6b65 7973  ut_keys=out_keys
-00008c20: 290d 0a20 2020 2020 2020 2063 6c61 6d70  )..        clamp
-00008c30: 5f6d 696e 5f74 656e 736f 7220 3d20 280d  _min_tensor = (.
-00008c40: 0a20 2020 2020 2020 2020 2020 2063 6c61  .            cla
-00008c50: 6d70 5f6d 696e 2069 6620 6973 696e 7374  mp_min if isinst
-00008c60: 616e 6365 2863 6c61 6d70 5f6d 696e 2c20  ance(clamp_min, 
-00008c70: 5465 6e73 6f72 2920 656c 7365 2074 6f72  Tensor) else tor
-00008c80: 6368 2e74 656e 736f 7228 636c 616d 705f  ch.tensor(clamp_
-00008c90: 6d69 6e29 0d0a 2020 2020 2020 2020 290d  min)..        ).
-00008ca0: 0a20 2020 2020 2020 2063 6c61 6d70 5f6d  .        clamp_m
-00008cb0: 6178 5f74 656e 736f 7220 3d20 280d 0a20  ax_tensor = (.. 
-00008cc0: 2020 2020 2020 2020 2020 2063 6c61 6d70             clamp
-00008cd0: 5f6d 6178 2069 6620 6973 696e 7374 616e  _max if isinstan
-00008ce0: 6365 2863 6c61 6d70 5f6d 6178 2c20 5465  ce(clamp_max, Te
-00008cf0: 6e73 6f72 2920 656c 7365 2074 6f72 6368  nsor) else torch
-00008d00: 2e74 656e 736f 7228 636c 616d 705f 6d61  .tensor(clamp_ma
-00008d10: 7829 0d0a 2020 2020 2020 2020 290d 0a20  x)..        ).. 
-00008d20: 2020 2020 2020 2073 656c 662e 7265 6769         self.regi
-00008d30: 7374 6572 5f62 7566 6665 7228 2263 6c61  ster_buffer("cla
-00008d40: 6d70 5f6d 696e 222c 2063 6c61 6d70 5f6d  mp_min", clamp_m
-00008d50: 696e 5f74 656e 736f 7229 0d0a 2020 2020  in_tensor)..    
-00008d60: 2020 2020 7365 6c66 2e72 6567 6973 7465      self.registe
-00008d70: 725f 6275 6666 6572 2822 636c 616d 705f  r_buffer("clamp_
-00008d80: 6d61 7822 2c20 636c 616d 705f 6d61 785f  max", clamp_max_
-00008d90: 7465 6e73 6f72 290d 0a0d 0a20 2020 2064  tensor)....    d
-00008da0: 6566 205f 6170 706c 795f 7472 616e 7366  ef _apply_transf
-00008db0: 6f72 6d28 7365 6c66 2c20 7265 7761 7264  orm(self, reward
-00008dc0: 3a20 746f 7263 682e 5465 6e73 6f72 2920  : torch.Tensor) 
-00008dd0: 2d3e 2074 6f72 6368 2e54 656e 736f 723a  -> torch.Tensor:
-00008de0: 0d0a 2020 2020 2020 2020 6966 2073 656c  ..        if sel
-00008df0: 662e 636c 616d 705f 6d61 7820 6973 206e  f.clamp_max is n
-00008e00: 6f74 204e 6f6e 6520 616e 6420 7365 6c66  ot None and self
-00008e10: 2e63 6c61 6d70 5f6d 696e 2069 7320 6e6f  .clamp_min is no
-00008e20: 7420 4e6f 6e65 3a0d 0a20 2020 2020 2020  t None:..       
-00008e30: 2020 2020 2072 6577 6172 6420 3d20 7265       reward = re
-00008e40: 7761 7264 2e63 6c61 6d70 2873 656c 662e  ward.clamp(self.
-00008e50: 636c 616d 705f 6d69 6e2c 2073 656c 662e  clamp_min, self.
-00008e60: 636c 616d 705f 6d61 7829 0d0a 2020 2020  clamp_max)..    
-00008e70: 2020 2020 656c 6966 2073 656c 662e 636c      elif self.cl
-00008e80: 616d 705f 6d69 6e20 6973 206e 6f74 204e  amp_min is not N
-00008e90: 6f6e 653a 0d0a 2020 2020 2020 2020 2020  one:..          
-00008ea0: 2020 7265 7761 7264 203d 2072 6577 6172    reward = rewar
-00008eb0: 642e 636c 616d 705f 6d69 6e28 7365 6c66  d.clamp_min(self
-00008ec0: 2e63 6c61 6d70 5f6d 696e 290d 0a20 2020  .clamp_min)..   
-00008ed0: 2020 2020 2065 6c69 6620 7365 6c66 2e63       elif self.c
-00008ee0: 6c61 6d70 5f6d 6178 2069 7320 6e6f 7420  lamp_max is not 
-00008ef0: 4e6f 6e65 3a0d 0a20 2020 2020 2020 2020  None:..         
-00008f00: 2020 2072 6577 6172 6420 3d20 7265 7761     reward = rewa
-00008f10: 7264 2e63 6c61 6d70 5f6d 6178 2873 656c  rd.clamp_max(sel
-00008f20: 662e 636c 616d 705f 6d61 7829 0d0a 2020  f.clamp_max)..  
-00008f30: 2020 2020 2020 7265 7475 726e 2072 6577        return rew
-00008f40: 6172 640d 0a0d 0a20 2020 2064 6566 2074  ard....    def t
-00008f50: 7261 6e73 666f 726d 5f72 6577 6172 645f  ransform_reward_
-00008f60: 7370 6563 2873 656c 662c 2072 6577 6172  spec(self, rewar
-00008f70: 645f 7370 6563 3a20 5465 6e73 6f72 5370  d_spec: TensorSp
-00008f80: 6563 2920 2d3e 2054 656e 736f 7253 7065  ec) -> TensorSpe
-00008f90: 633a 0d0a 2020 2020 2020 2020 6966 2069  c:..        if i
-00008fa0: 7369 6e73 7461 6e63 6528 7265 7761 7264  sinstance(reward
-00008fb0: 5f73 7065 632c 2055 6e62 6f75 6e64 6564  _spec, Unbounded
-00008fc0: 436f 6e74 696e 756f 7573 5465 6e73 6f72  ContinuousTensor
-00008fd0: 5370 6563 293a 0d0a 2020 2020 2020 2020  Spec):..        
-00008fe0: 2020 2020 7265 7475 726e 2042 6f75 6e64      return Bound
-00008ff0: 6564 5465 6e73 6f72 5370 6563 280d 0a20  edTensorSpec(.. 
-00009000: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-00009010: 656c 662e 636c 616d 705f 6d69 6e2c 0d0a  elf.clamp_min,..
-00009020: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009030: 7365 6c66 2e63 6c61 6d70 5f6d 6178 2c0d  self.clamp_max,.
-00009040: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00009050: 2073 6861 7065 3d72 6577 6172 645f 7370   shape=reward_sp
-00009060: 6563 2e73 6861 7065 2c0d 0a20 2020 2020  ec.shape,..     
-00009070: 2020 2020 2020 2020 2020 2064 6576 6963             devic
-00009080: 653d 7265 7761 7264 5f73 7065 632e 6465  e=reward_spec.de
-00009090: 7669 6365 2c0d 0a20 2020 2020 2020 2020  vice,..         
-000090a0: 2020 2020 2020 2064 7479 7065 3d72 6577         dtype=rew
-000090b0: 6172 645f 7370 6563 2e64 7479 7065 2c0d  ard_spec.dtype,.
-000090c0: 0a20 2020 2020 2020 2020 2020 2029 0d0a  .            )..
-000090d0: 2020 2020 2020 2020 656c 7365 3a0d 0a20          else:.. 
-000090e0: 2020 2020 2020 2020 2020 2072 6169 7365             raise
-000090f0: 204e 6f74 496d 706c 656d 656e 7465 6445   NotImplementedE
-00009100: 7272 6f72 280d 0a20 2020 2020 2020 2020  rror(..         
-00009110: 2020 2020 2020 2066 227b 7365 6c66 2e5f         f"{self._
-00009120: 5f63 6c61 7373 5f5f 2e5f 5f6e 616d 655f  _class__.__name_
-00009130: 5f7d 2e74 7261 6e73 666f 726d 5f72 6577  _}.transform_rew
-00009140: 6172 645f 7370 6563 206e 6f74 2022 0d0a  ard_spec not "..
-00009150: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00009160: 6622 696d 706c 656d 656e 7465 6420 666f  f"implemented fo
-00009170: 7220 7465 6e73 6f72 2073 7065 6320 6f66  r tensor spec of
-00009180: 2074 7970 6522 0d0a 2020 2020 2020 2020   type"..        
-00009190: 2020 2020 2020 2020 6622 207b 7479 7065          f" {type
-000091a0: 2872 6577 6172 645f 7370 6563 292e 5f5f  (reward_spec).__
-000091b0: 6e61 6d65 5f5f 7d22 0d0a 2020 2020 2020  name__}"..      
-000091c0: 2020 2020 2020 290d 0a0d 0a20 2020 2064        )....    d
-000091d0: 6566 205f 5f72 6570 725f 5f28 7365 6c66  ef __repr__(self
-000091e0: 2920 2d3e 2073 7472 3a0d 0a20 2020 2020  ) -> str:..     
-000091f0: 2020 2072 6574 7572 6e20 280d 0a20 2020     return (..   
-00009200: 2020 2020 2020 2020 2066 227b 7365 6c66           f"{self
-00009210: 2e5f 5f63 6c61 7373 5f5f 2e5f 5f6e 616d  .__class__.__nam
-00009220: 655f 5f7d 2822 0d0a 2020 2020 2020 2020  e__}("..        
-00009230: 2020 2020 6622 636c 616d 705f 6d69 6e3d      f"clamp_min=
-00009240: 7b66 6c6f 6174 2873 656c 662e 636c 616d  {float(self.clam
-00009250: 705f 6d69 6e29 3a34 2e34 667d 2c20 636c  p_min):4.4f}, cl
-00009260: 616d 705f 6d61 7822 0d0a 2020 2020 2020  amp_max"..      
-00009270: 2020 2020 2020 6622 3d7b 666c 6f61 7428        f"={float(
-00009280: 7365 6c66 2e63 6c61 6d70 5f6d 6178 293a  self.clamp_max):
-00009290: 342e 3466 7d2c 206b 6579 733d 7b73 656c  4.4f}, keys={sel
-000092a0: 662e 696e 5f6b 6579 737d 2922 0d0a 2020  f.in_keys})"..  
-000092b0: 2020 2020 2020 290d 0a0d 0a0d 0a63 6c61        )......cla
-000092c0: 7373 2042 696e 6172 697a 6552 6577 6172  ss BinarizeRewar
-000092d0: 6428 5472 616e 7366 6f72 6d29 3a0d 0a20  d(Transform):.. 
-000092e0: 2020 2022 2222 4d61 7073 2074 6865 2072     """Maps the r
-000092f0: 6577 6172 6420 746f 2061 2062 696e 6172  eward to a binar
-00009300: 7920 7661 6c75 6520 2830 206f 7220 3129  y value (0 or 1)
-00009310: 2069 6620 7468 6520 7265 7761 7264 2069   if the reward i
-00009320: 7320 6e75 6c6c 206f 7220 6e6f 6e2d 6e75  s null or non-nu
-00009330: 6c6c 2c20 7265 7370 6563 7469 7665 6c79  ll, respectively
-00009340: 2e22 2222 0d0a 0d0a 2020 2020 6465 6620  ."""....    def 
-00009350: 5f5f 696e 6974 5f5f 280d 0a20 2020 2020  __init__(..     
-00009360: 2020 2073 656c 662c 0d0a 2020 2020 2020     self,..      
-00009370: 2020 696e 5f6b 6579 733a 204f 7074 696f    in_keys: Optio
-00009380: 6e61 6c5b 5365 7175 656e 6365 5b73 7472  nal[Sequence[str
-00009390: 5d5d 203d 204e 6f6e 652c 0d0a 2020 2020  ]] = None,..    
-000093a0: 2020 2020 6f75 745f 6b65 7973 3a20 4f70      out_keys: Op
-000093b0: 7469 6f6e 616c 5b53 6571 7565 6e63 655b  tional[Sequence[
-000093c0: 7374 725d 5d20 3d20 4e6f 6e65 2c0d 0a20  str]] = None,.. 
-000093d0: 2020 2029 3a0d 0a20 2020 2020 2020 2069     ):..        i
-000093e0: 6620 696e 5f6b 6579 7320 6973 204e 6f6e  f in_keys is Non
-000093f0: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
-00009400: 696e 5f6b 6579 7320 3d20 5b22 7265 7761  in_keys = ["rewa
-00009410: 7264 225d 0d0a 2020 2020 2020 2020 7375  rd"]..        su
-00009420: 7065 7228 292e 5f5f 696e 6974 5f5f 2869  per().__init__(i
-00009430: 6e5f 6b65 7973 3d69 6e5f 6b65 7973 2c20  n_keys=in_keys, 
-00009440: 6f75 745f 6b65 7973 3d6f 7574 5f6b 6579  out_keys=out_key
-00009450: 7329 0d0a 0d0a 2020 2020 6465 6620 5f61  s)....    def _a
-00009460: 7070 6c79 5f74 7261 6e73 666f 726d 2873  pply_transform(s
-00009470: 656c 662c 2072 6577 6172 643a 2074 6f72  elf, reward: tor
-00009480: 6368 2e54 656e 736f 7229 202d 3e20 746f  ch.Tensor) -> to
-00009490: 7263 682e 5465 6e73 6f72 3a0d 0a20 2020  rch.Tensor:..   
-000094a0: 2020 2020 2069 6620 6e6f 7420 7265 7761       if not rewa
-000094b0: 7264 2e73 6861 7065 206f 7220 7265 7761  rd.shape or rewa
-000094c0: 7264 2e73 6861 7065 5b2d 315d 2021 3d20  rd.shape[-1] != 
-000094d0: 313a 0d0a 2020 2020 2020 2020 2020 2020  1:..            
-000094e0: 7261 6973 6520 5275 6e74 696d 6545 7272  raise RuntimeErr
-000094f0: 6f72 280d 0a20 2020 2020 2020 2020 2020  or(..           
-00009500: 2020 2020 2066 2252 6577 6172 6420 7368       f"Reward sh
-00009510: 6170 6520 6c61 7374 2064 696d 656e 7369  ape last dimensi
-00009520: 6f6e 206d 7573 7420 6265 2073 696e 676c  on must be singl
-00009530: 6574 6f6e 2c20 676f 7420 7265 7761 7264  eton, got reward
-00009540: 206f 6620 7368 6170 6520 7b72 6577 6172   of shape {rewar
-00009550: 642e 7368 6170 657d 220d 0a20 2020 2020  d.shape}"..     
-00009560: 2020 2020 2020 2029 0d0a 2020 2020 2020         )..      
-00009570: 2020 7265 7475 726e 2028 7265 7761 7264    return (reward
-00009580: 203e 2030 2e30 292e 746f 2874 6f72 6368   > 0.0).to(torch
-00009590: 2e6c 6f6e 6729 0d0a 0d0a 2020 2020 6465  .long)....    de
-000095a0: 6620 7472 616e 7366 6f72 6d5f 7265 7761  f transform_rewa
-000095b0: 7264 5f73 7065 6328 7365 6c66 2c20 7265  rd_spec(self, re
-000095c0: 7761 7264 5f73 7065 633a 2054 656e 736f  ward_spec: Tenso
-000095d0: 7253 7065 6329 202d 3e20 5465 6e73 6f72  rSpec) -> Tensor
-000095e0: 5370 6563 3a0d 0a20 2020 2020 2020 2072  Spec:..        r
-000095f0: 6574 7572 6e20 4269 6e61 7279 4469 7363  eturn BinaryDisc
-00009600: 7265 7465 5465 6e73 6f72 5370 6563 280d  reteTensorSpec(.
-00009610: 0a20 2020 2020 2020 2020 2020 206e 3d31  .            n=1
-00009620: 2c20 6465 7669 6365 3d72 6577 6172 645f  , device=reward_
-00009630: 7370 6563 2e64 6576 6963 652c 2073 6861  spec.device, sha
-00009640: 7065 3d72 6577 6172 645f 7370 6563 2e73  pe=reward_spec.s
-00009650: 6861 7065 0d0a 2020 2020 2020 2020 290d  hape..        ).
-00009660: 0a0d 0a0d 0a63 6c61 7373 2052 6573 697a  .....class Resiz
-00009670: 6528 4f62 7365 7276 6174 696f 6e54 7261  e(ObservationTra
-00009680: 6e73 666f 726d 293a 0d0a 2020 2020 2222  nsform):..    ""
-00009690: 2252 6573 697a 6573 2061 6e20 7069 7865  "Resizes an pixe
-000096a0: 6c20 6f62 7365 7276 6174 696f 6e2e 0d0a  l observation...
-000096b0: 0d0a 2020 2020 4172 6773 3a0d 0a20 2020  ..    Args:..   
-000096c0: 2020 2020 2077 2028 696e 7429 3a20 7265       w (int): re
-000096d0: 7375 6c74 696e 6720 7769 6474 680d 0a20  sulting width.. 
-000096e0: 2020 2020 2020 2068 2028 696e 7429 3a20         h (int): 
-000096f0: 7265 7375 6c74 696e 6720 6865 6967 6874  resulting height
-00009700: 0d0a 2020 2020 2020 2020 696e 7465 7270  ..        interp
-00009710: 6f6c 6174 696f 6e20 2873 7472 293a 2069  olation (str): i
-00009720: 6e74 6572 706f 6c61 7469 6f6e 206d 6574  nterpolation met
-00009730: 686f 640d 0a20 2020 2022 2222 0d0a 0d0a  hod..    """....
-00009740: 2020 2020 6465 6620 5f5f 696e 6974 5f5f      def __init__
-00009750: 280d 0a20 2020 2020 2020 2073 656c 662c  (..        self,
-00009760: 0d0a 2020 2020 2020 2020 773a 2069 6e74  ..        w: int
-00009770: 2c0d 0a20 2020 2020 2020 2068 3a20 696e  ,..        h: in
-00009780: 742c 0d0a 2020 2020 2020 2020 696e 7465  t,..        inte
-00009790: 7270 6f6c 6174 696f 6e3a 2073 7472 203d  rpolation: str =
-000097a0: 2022 6269 6c69 6e65 6172 222c 0d0a 2020   "bilinear",..  
-000097b0: 2020 2020 2020 696e 5f6b 6579 733a 204f        in_keys: O
-000097c0: 7074 696f 6e61 6c5b 5365 7175 656e 6365  ptional[Sequence
-000097d0: 5b73 7472 5d5d 203d 204e 6f6e 652c 0d0a  [str]] = None,..
-000097e0: 2020 2020 2020 2020 6f75 745f 6b65 7973          out_keys
-000097f0: 3a20 4f70 7469 6f6e 616c 5b53 6571 7565  : Optional[Seque
-00009800: 6e63 655b 7374 725d 5d20 3d20 4e6f 6e65  nce[str]] = None
-00009810: 2c0d 0a20 2020 2029 3a0d 0a20 2020 2020  ,..    ):..     
-00009820: 2020 2069 6620 6e6f 7420 5f68 6173 5f74     if not _has_t
-00009830: 763a 0d0a 2020 2020 2020 2020 2020 2020  v:..            
-00009840: 7261 6973 6520 496d 706f 7274 4572 726f  raise ImportErro
-00009850: 7228 0d0a 2020 2020 2020 2020 2020 2020  r(..            
-00009860: 2020 2020 2254 6f72 6368 7669 7369 6f6e      "Torchvision
-00009870: 206e 6f74 2066 6f75 6e64 2e20 5468 6520   not found. The 
-00009880: 5265 7369 7a65 2074 7261 6e73 666f 726d  Resize transform
-00009890: 2072 656c 6965 7320 6f6e 2022 0d0a 2020   relies on "..  
-000098a0: 2020 2020 2020 2020 2020 2020 2020 2274                "t
-000098b0: 6f72 6368 7669 7369 6f6e 2069 6d70 6c65  orchvision imple
-000098c0: 6d65 6e74 6174 696f 6e2e 2022 0d0a 2020  mentation. "..  
-000098d0: 2020 2020 2020 2020 2020 2020 2020 2243                "C
-000098e0: 6f6e 7369 6465 7220 696e 7374 616c 6c69  onsider installi
-000098f0: 6e67 2074 6869 7320 6465 7065 6e64 656e  ng this dependen
-00009900: 6379 2e22 0d0a 2020 2020 2020 2020 2020  cy."..          
-00009910: 2020 290d 0a20 2020 2020 2020 2069 6620    )..        if 
-00009920: 696e 5f6b 6579 7320 6973 204e 6f6e 653a  in_keys is None:
-00009930: 0d0a 2020 2020 2020 2020 2020 2020 696e  ..            in
-00009940: 5f6b 6579 7320 3d20 494d 4147 455f 4b45  _keys = IMAGE_KE
-00009950: 5953 2020 2320 6465 6661 756c 740d 0a20  YS  # default.. 
-00009960: 2020 2020 2020 2073 7570 6572 2829 2e5f         super()._
-00009970: 5f69 6e69 745f 5f28 696e 5f6b 6579 733d  _init__(in_keys=
-00009980: 696e 5f6b 6579 732c 206f 7574 5f6b 6579  in_keys, out_key
-00009990: 733d 6f75 745f 6b65 7973 290d 0a20 2020  s=out_keys)..   
-000099a0: 2020 2020 2073 656c 662e 7720 3d20 696e       self.w = in
-000099b0: 7428 7729 0d0a 2020 2020 2020 2020 7365  t(w)..        se
-000099c0: 6c66 2e68 203d 2069 6e74 2868 290d 0a20  lf.h = int(h).. 
-000099d0: 2020 2020 2020 2073 656c 662e 696e 7465         self.inte
-000099e0: 7270 6f6c 6174 696f 6e20 3d20 696e 7465  rpolation = inte
-000099f0: 7270 6f6c 6174 696f 6e5f 666e 2869 6e74  rpolation_fn(int
-00009a00: 6572 706f 6c61 7469 6f6e 290d 0a0d 0a20  erpolation).... 
-00009a10: 2020 2064 6566 205f 6170 706c 795f 7472     def _apply_tr
-00009a20: 616e 7366 6f72 6d28 7365 6c66 2c20 6f62  ansform(self, ob
-00009a30: 7365 7276 6174 696f 6e3a 2074 6f72 6368  servation: torch
-00009a40: 2e54 656e 736f 7229 202d 3e20 746f 7263  .Tensor) -> torc
-00009a50: 682e 5465 6e73 6f72 3a0d 0a20 2020 2020  h.Tensor:..     
-00009a60: 2020 2023 2066 6c61 7474 656e 2069 6620     # flatten if 
-00009a70: 6e65 6365 7373 6172 790d 0a20 2020 2020  necessary..     
-00009a80: 2020 2069 6620 6f62 7365 7276 6174 696f     if observatio
-00009a90: 6e2e 7368 6170 655b 2d32 3a5d 203d 3d20  n.shape[-2:] == 
-00009aa0: 746f 7263 682e 5369 7a65 285b 7365 6c66  torch.Size([self
-00009ab0: 2e77 2c20 7365 6c66 2e68 5d29 3a0d 0a20  .w, self.h]):.. 
-00009ac0: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-00009ad0: 6e20 6f62 7365 7276 6174 696f 6e0d 0a20  n observation.. 
-00009ae0: 2020 2020 2020 206e 6469 6d20 3d20 6f62         ndim = ob
-00009af0: 7365 7276 6174 696f 6e2e 6e64 696d 656e  servation.ndimen
-00009b00: 7369 6f6e 2829 0d0a 2020 2020 2020 2020  sion()..        
-00009b10: 6966 206e 6469 6d20 3e20 343a 0d0a 2020  if ndim > 4:..  
-00009b20: 2020 2020 2020 2020 2020 7369 7a65 7320            sizes 
-00009b30: 3d20 6f62 7365 7276 6174 696f 6e2e 7368  = observation.sh
-00009b40: 6170 655b 3a2d 335d 0d0a 2020 2020 2020  ape[:-3]..      
-00009b50: 2020 2020 2020 6f62 7365 7276 6174 696f        observatio
-00009b60: 6e20 3d20 746f 7263 682e 666c 6174 7465  n = torch.flatte
-00009b70: 6e28 6f62 7365 7276 6174 696f 6e2c 2030  n(observation, 0
-00009b80: 2c20 6e64 696d 202d 2034 290d 0a20 2020  , ndim - 4)..   
-00009b90: 2020 2020 206f 6273 6572 7661 7469 6f6e       observation
-00009ba0: 203d 2072 6573 697a 6528 0d0a 2020 2020   = resize(..    
-00009bb0: 2020 2020 2020 2020 6f62 7365 7276 6174          observat
-00009bc0: 696f 6e2c 205b 7365 6c66 2e77 2c20 7365  ion, [self.w, se
-00009bd0: 6c66 2e68 5d2c 2069 6e74 6572 706f 6c61  lf.h], interpola
-00009be0: 7469 6f6e 3d73 656c 662e 696e 7465 7270  tion=self.interp
-00009bf0: 6f6c 6174 696f 6e0d 0a20 2020 2020 2020  olation..       
-00009c00: 2029 0d0a 2020 2020 2020 2020 6966 206e   )..        if n
-00009c10: 6469 6d20 3e20 343a 0d0a 2020 2020 2020  dim > 4:..      
-00009c20: 2020 2020 2020 6f62 7365 7276 6174 696f        observatio
-00009c30: 6e20 3d20 6f62 7365 7276 6174 696f 6e2e  n = observation.
-00009c40: 756e 666c 6174 7465 6e28 302c 2073 697a  unflatten(0, siz
-00009c50: 6573 290d 0a0d 0a20 2020 2020 2020 2072  es)....        r
-00009c60: 6574 7572 6e20 6f62 7365 7276 6174 696f  eturn observatio
-00009c70: 6e0d 0a0d 0a20 2020 2040 5f61 7070 6c79  n....    @_apply
-00009c80: 5f74 6f5f 636f 6d70 6f73 6974 650d 0a20  _to_composite.. 
-00009c90: 2020 2064 6566 2074 7261 6e73 666f 726d     def transform
-00009ca0: 5f6f 6273 6572 7661 7469 6f6e 5f73 7065  _observation_spe
-00009cb0: 6328 7365 6c66 2c20 6f62 7365 7276 6174  c(self, observat
-00009cc0: 696f 6e5f 7370 6563 3a20 5465 6e73 6f72  ion_spec: Tensor
-00009cd0: 5370 6563 2920 2d3e 2054 656e 736f 7253  Spec) -> TensorS
-00009ce0: 7065 633a 0d0a 2020 2020 2020 2020 7370  pec:..        sp
-00009cf0: 6163 6520 3d20 6f62 7365 7276 6174 696f  ace = observatio
-00009d00: 6e5f 7370 6563 2e73 7061 6365 0d0a 2020  n_spec.space..  
-00009d10: 2020 2020 2020 6966 2069 7369 6e73 7461        if isinsta
-00009d20: 6e63 6528 7370 6163 652c 2043 6f6e 7469  nce(space, Conti
-00009d30: 6e75 6f75 7342 6f78 293a 0d0a 2020 2020  nuousBox):..    
-00009d40: 2020 2020 2020 2020 7370 6163 652e 6d69          space.mi
-00009d50: 6e69 6d75 6d20 3d20 7365 6c66 2e5f 6170  nimum = self._ap
-00009d60: 706c 795f 7472 616e 7366 6f72 6d28 7370  ply_transform(sp
-00009d70: 6163 652e 6d69 6e69 6d75 6d29 0d0a 2020  ace.minimum)..  
-00009d80: 2020 2020 2020 2020 2020 7370 6163 652e            space.
-00009d90: 6d61 7869 6d75 6d20 3d20 7365 6c66 2e5f  maximum = self._
-00009da0: 6170 706c 795f 7472 616e 7366 6f72 6d28  apply_transform(
-00009db0: 7370 6163 652e 6d61 7869 6d75 6d29 0d0a  space.maximum)..
-00009dc0: 2020 2020 2020 2020 2020 2020 6f62 7365              obse
-00009dd0: 7276 6174 696f 6e5f 7370 6563 2e73 6861  rvation_spec.sha
-00009de0: 7065 203d 2073 7061 6365 2e6d 696e 696d  pe = space.minim
-00009df0: 756d 2e73 6861 7065 0d0a 2020 2020 2020  um.shape..      
-00009e00: 2020 656c 7365 3a0d 0a20 2020 2020 2020    else:..       
-00009e10: 2020 2020 206f 6273 6572 7661 7469 6f6e       observation
-00009e20: 5f73 7065 632e 7368 6170 6520 3d20 7365  _spec.shape = se
-00009e30: 6c66 2e5f 6170 706c 795f 7472 616e 7366  lf._apply_transf
-00009e40: 6f72 6d28 0d0a 2020 2020 2020 2020 2020  orm(..          
-00009e50: 2020 2020 2020 746f 7263 682e 7a65 726f        torch.zero
-00009e60: 7328 6f62 7365 7276 6174 696f 6e5f 7370  s(observation_sp
-00009e70: 6563 2e73 6861 7065 290d 0a20 2020 2020  ec.shape)..     
-00009e80: 2020 2020 2020 2029 2e73 6861 7065 0d0a         ).shape..
-00009e90: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
-00009ea0: 206f 6273 6572 7661 7469 6f6e 5f73 7065   observation_spe
-00009eb0: 630d 0a0d 0a20 2020 2064 6566 205f 5f72  c....    def __r
-00009ec0: 6570 725f 5f28 7365 6c66 2920 2d3e 2073  epr__(self) -> s
-00009ed0: 7472 3a0d 0a20 2020 2020 2020 2072 6574  tr:..        ret
-00009ee0: 7572 6e20 280d 0a20 2020 2020 2020 2020  urn (..         
-00009ef0: 2020 2066 227b 7365 6c66 2e5f 5f63 6c61     f"{self.__cla
-00009f00: 7373 5f5f 2e5f 5f6e 616d 655f 5f7d 2822  ss__.__name__}("
-00009f10: 0d0a 2020 2020 2020 2020 2020 2020 6622  ..            f"
-00009f20: 773d 7b69 6e74 2873 656c 662e 7729 7d2c  w={int(self.w)},
-00009f30: 2068 3d7b 696e 7428 7365 6c66 2e68 297d   h={int(self.h)}
-00009f40: 2c20 220d 0a20 2020 2020 2020 2020 2020  , "..           
-00009f50: 2066 2269 6e74 6572 706f 6c61 7469 6f6e   f"interpolation
-00009f60: 3d7b 7365 6c66 2e69 6e74 6572 706f 6c61  ={self.interpola
-00009f70: 7469 6f6e 7d2c 206b 6579 733d 7b73 656c  tion}, keys={sel
-00009f80: 662e 696e 5f6b 6579 737d 2922 0d0a 2020  f.in_keys})"..  
-00009f90: 2020 2020 2020 290d 0a0d 0a0d 0a63 6c61        )......cla
-00009fa0: 7373 2043 656e 7465 7243 726f 7028 4f62  ss CenterCrop(Ob
-00009fb0: 7365 7276 6174 696f 6e54 7261 6e73 666f  servationTransfo
-00009fc0: 726d 293a 0d0a 2020 2020 2222 2243 726f  rm):..    """Cro
-00009fd0: 7073 2074 6865 2063 656e 7465 7220 6f66  ps the center of
-00009fe0: 2061 6e20 696d 6167 652e 0d0a 0d0a 2020   an image.....  
-00009ff0: 2020 4172 6773 3a0d 0a20 2020 2020 2020    Args:..       
-0000a000: 2077 2028 696e 7429 3a20 7265 7375 6c74   w (int): result
-0000a010: 696e 6720 7769 6474 680d 0a20 2020 2020  ing width..     
-0000a020: 2020 2068 2028 696e 742c 206f 7074 696f     h (int, optio
-0000a030: 6e61 6c29 3a20 7265 7375 6c74 696e 6720  nal): resulting 
-0000a040: 6865 6967 6874 2e20 4966 204e 6f6e 652c  height. If None,
-0000a050: 2074 6865 6e20 7720 6973 2075 7365 6420   then w is used 
-0000a060: 2873 7175 6172 6520 6372 6f70 292e 0d0a  (square crop)...
-0000a070: 2020 2020 2020 2020 696e 5f6b 6579 7320          in_keys 
-0000a080: 2873 6571 7565 6e63 6520 6f66 2073 7472  (sequence of str
-0000a090: 2c20 6f70 7469 6f6e 616c 293a 2074 6865  , optional): the
-0000a0a0: 2065 6e74 7269 6573 2074 6f20 6372 6f70   entries to crop
-0000a0b0: 2e20 4966 206e 6f6e 6520 6973 2070 726f  . If none is pro
-0000a0c0: 7669 6465 642c 0d0a 2020 2020 2020 2020  vided,..        
-0000a0d0: 2020 2020 3a6f 626a 3a60 5b22 7069 7865      :obj:`["pixe
-0000a0e0: 6c73 225d 6020 6973 2061 7373 756d 6564  ls"]` is assumed
-0000a0f0: 2e0d 0a20 2020 2020 2020 206f 7574 5f6b  ...        out_k
-0000a100: 6579 7320 2873 6571 7565 6e63 6520 6f66  eys (sequence of
-0000a110: 2073 7472 2c20 6f70 7469 6f6e 616c 293a   str, optional):
-0000a120: 2074 6865 2063 726f 7070 6564 2069 6d61   the cropped ima
-0000a130: 6765 7320 6b65 7973 2e20 4966 206e 6f6e  ges keys. If non
-0000a140: 6520 6973 0d0a 2020 2020 2020 2020 2020  e is..          
-0000a150: 2020 7072 6f76 6964 6564 2c20 3a6f 626a    provided, :obj
-0000a160: 3a60 696e 5f6b 6579 7360 2069 7320 6173  :`in_keys` is as
-0000a170: 7375 6d65 642e 0d0a 0d0a 2020 2020 2222  sumed.....    ""
-0000a180: 220d 0a0d 0a20 2020 2064 6566 205f 5f69  "....    def __i
-0000a190: 6e69 745f 5f28 0d0a 2020 2020 2020 2020  nit__(..        
-0000a1a0: 7365 6c66 2c0d 0a20 2020 2020 2020 2077  self,..        w
-0000a1b0: 3a20 696e 742c 0d0a 2020 2020 2020 2020  : int,..        
-0000a1c0: 683a 2069 6e74 203d 204e 6f6e 652c 0d0a  h: int = None,..
-0000a1d0: 2020 2020 2020 2020 696e 5f6b 6579 733a          in_keys:
-0000a1e0: 204f 7074 696f 6e61 6c5b 5365 7175 656e   Optional[Sequen
-0000a1f0: 6365 5b73 7472 5d5d 203d 204e 6f6e 652c  ce[str]] = None,
-0000a200: 0d0a 2020 2020 2020 2020 6f75 745f 6b65  ..        out_ke
-0000a210: 7973 3a20 4f70 7469 6f6e 616c 5b53 6571  ys: Optional[Seq
-0000a220: 7565 6e63 655b 7374 725d 5d20 3d20 4e6f  uence[str]] = No
-0000a230: 6e65 2c0d 0a20 2020 2029 3a0d 0a20 2020  ne,..    ):..   
-0000a240: 2020 2020 2069 6620 696e 5f6b 6579 7320       if in_keys 
-0000a250: 6973 204e 6f6e 653a 0d0a 2020 2020 2020  is None:..      
-0000a260: 2020 2020 2020 696e 5f6b 6579 7320 3d20        in_keys = 
-0000a270: 494d 4147 455f 4b45 5953 2020 2320 6465  IMAGE_KEYS  # de
-0000a280: 6661 756c 740d 0a20 2020 2020 2020 2073  fault..        s
-0000a290: 7570 6572 2829 2e5f 5f69 6e69 745f 5f28  uper().__init__(
-0000a2a0: 696e 5f6b 6579 733d 696e 5f6b 6579 732c  in_keys=in_keys,
-0000a2b0: 206f 7574 5f6b 6579 733d 6f75 745f 6b65   out_keys=out_ke
-0000a2c0: 7973 290d 0a20 2020 2020 2020 2073 656c  ys)..        sel
-0000a2d0: 662e 7720 3d20 770d 0a20 2020 2020 2020  f.w = w..       
-0000a2e0: 2073 656c 662e 6820 3d20 6820 6966 2068   self.h = h if h
-0000a2f0: 2065 6c73 6520 770d 0a0d 0a20 2020 2064   else w....    d
-0000a300: 6566 205f 6170 706c 795f 7472 616e 7366  ef _apply_transf
-0000a310: 6f72 6d28 7365 6c66 2c20 6f62 7365 7276  orm(self, observ
-0000a320: 6174 696f 6e3a 2074 6f72 6368 2e54 656e  ation: torch.Ten
-0000a330: 736f 7229 202d 3e20 746f 7263 682e 5465  sor) -> torch.Te
-0000a340: 6e73 6f72 3a0d 0a20 2020 2020 2020 206f  nsor:..        o
-0000a350: 6273 6572 7661 7469 6f6e 203d 2063 656e  bservation = cen
-0000a360: 7465 725f 6372 6f70 286f 6273 6572 7661  ter_crop(observa
-0000a370: 7469 6f6e 2c20 5b73 656c 662e 772c 2073  tion, [self.w, s
-0000a380: 656c 662e 685d 290d 0a20 2020 2020 2020  elf.h])..       
-0000a390: 2072 6574 7572 6e20 6f62 7365 7276 6174   return observat
-0000a3a0: 696f 6e0d 0a0d 0a20 2020 2040 5f61 7070  ion....    @_app
-0000a3b0: 6c79 5f74 6f5f 636f 6d70 6f73 6974 650d  ly_to_composite.
-0000a3c0: 0a20 2020 2064 6566 2074 7261 6e73 666f  .    def transfo
-0000a3d0: 726d 5f6f 6273 6572 7661 7469 6f6e 5f73  rm_observation_s
-0000a3e0: 7065 6328 7365 6c66 2c20 6f62 7365 7276  pec(self, observ
-0000a3f0: 6174 696f 6e5f 7370 6563 3a20 5465 6e73  ation_spec: Tens
-0000a400: 6f72 5370 6563 2920 2d3e 2054 656e 736f  orSpec) -> Tenso
-0000a410: 7253 7065 633a 0d0a 2020 2020 2020 2020  rSpec:..        
-0000a420: 7370 6163 6520 3d20 6f62 7365 7276 6174  space = observat
-0000a430: 696f 6e5f 7370 6563 2e73 7061 6365 0d0a  ion_spec.space..
-0000a440: 2020 2020 2020 2020 6966 2069 7369 6e73          if isins
-0000a450: 7461 6e63 6528 7370 6163 652c 2043 6f6e  tance(space, Con
-0000a460: 7469 6e75 6f75 7342 6f78 293a 0d0a 2020  tinuousBox):..  
-0000a470: 2020 2020 2020 2020 2020 7370 6163 652e            space.
-0000a480: 6d69 6e69 6d75 6d20 3d20 7365 6c66 2e5f  minimum = self._
-0000a490: 6170 706c 795f 7472 616e 7366 6f72 6d28  apply_transform(
-0000a4a0: 7370 6163 652e 6d69 6e69 6d75 6d29 0d0a  space.minimum)..
-0000a4b0: 2020 2020 2020 2020 2020 2020 7370 6163              spac
-0000a4c0: 652e 6d61 7869 6d75 6d20 3d20 7365 6c66  e.maximum = self
-0000a4d0: 2e5f 6170 706c 795f 7472 616e 7366 6f72  ._apply_transfor
-0000a4e0: 6d28 7370 6163 652e 6d61 7869 6d75 6d29  m(space.maximum)
-0000a4f0: 0d0a 2020 2020 2020 2020 2020 2020 6f62  ..            ob
-0000a500: 7365 7276 6174 696f 6e5f 7370 6563 2e73  servation_spec.s
-0000a510: 6861 7065 203d 2073 7061 6365 2e6d 696e  hape = space.min
-0000a520: 696d 756d 2e73 6861 7065 0d0a 2020 2020  imum.shape..    
-0000a530: 2020 2020 656c 7365 3a0d 0a20 2020 2020      else:..     
-0000a540: 2020 2020 2020 206f 6273 6572 7661 7469         observati
-0000a550: 6f6e 5f73 7065 632e 7368 6170 6520 3d20  on_spec.shape = 
-0000a560: 7365 6c66 2e5f 6170 706c 795f 7472 616e  self._apply_tran
-0000a570: 7366 6f72 6d28 0d0a 2020 2020 2020 2020  sform(..        
-0000a580: 2020 2020 2020 2020 746f 7263 682e 7a65          torch.ze
-0000a590: 726f 7328 6f62 7365 7276 6174 696f 6e5f  ros(observation_
-0000a5a0: 7370 6563 2e73 6861 7065 290d 0a20 2020  spec.shape)..   
-0000a5b0: 2020 2020 2020 2020 2029 2e73 6861 7065           ).shape
-0000a5c0: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
-0000a5d0: 206f 6273 6572 7661 7469 6f6e 5f73 7065   observation_spe
-0000a5e0: 630d 0a0d 0a20 2020 2064 6566 205f 5f72  c....    def __r
-0000a5f0: 6570 725f 5f28 7365 6c66 2920 2d3e 2073  epr__(self) -> s
-0000a600: 7472 3a0d 0a20 2020 2020 2020 2072 6574  tr:..        ret
-0000a610: 7572 6e20 280d 0a20 2020 2020 2020 2020  urn (..         
-0000a620: 2020 2066 227b 7365 6c66 2e5f 5f63 6c61     f"{self.__cla
-0000a630: 7373 5f5f 2e5f 5f6e 616d 655f 5f7d 2822  ss__.__name__}("
-0000a640: 0d0a 2020 2020 2020 2020 2020 2020 6622  ..            f"
-0000a650: 773d 7b66 6c6f 6174 2873 656c 662e 7729  w={float(self.w)
-0000a660: 3a34 2e34 667d 2c20 683d 7b66 6c6f 6174  :4.4f}, h={float
-0000a670: 2873 656c 662e 6829 3a34 2e34 667d 2c20  (self.h):4.4f}, 
-0000a680: 220d 0a20 2020 2020 2020 2029 0d0a 0d0a  "..        )....
-0000a690: 0d0a 636c 6173 7320 466c 6174 7465 6e4f  ..class FlattenO
-0000a6a0: 6273 6572 7661 7469 6f6e 284f 6273 6572  bservation(Obser
-0000a6b0: 7661 7469 6f6e 5472 616e 7366 6f72 6d29  vationTransform)
-0000a6c0: 3a0d 0a20 2020 2022 2222 466c 6174 7465  :..    """Flatte
-0000a6d0: 6e20 6164 6a61 6365 6e74 2064 696d 656e  n adjacent dimen
-0000a6e0: 7369 6f6e 7320 6f66 2061 2074 656e 736f  sions of a tenso
-0000a6f0: 722e 0d0a 0d0a 2020 2020 4172 6773 3a0d  r.....    Args:.
-0000a700: 0a20 2020 2020 2020 2066 6972 7374 5f64  .        first_d
-0000a710: 696d 2028 696e 7429 3a20 6669 7273 7420  im (int): first 
-0000a720: 6469 6d65 6e73 696f 6e20 6f66 2074 6865  dimension of the
-0000a730: 2064 696d 656e 7369 6f6e 7320 746f 2066   dimensions to f
-0000a740: 6c61 7474 656e 2e0d 0a20 2020 2020 2020  latten...       
-0000a750: 206c 6173 745f 6469 6d20 2869 6e74 293a   last_dim (int):
-0000a760: 206c 6173 7420 6469 6d65 6e73 696f 6e20   last dimension 
-0000a770: 6f66 2074 6865 2064 696d 656e 7369 6f6e  of the dimension
-0000a780: 7320 746f 2066 6c61 7474 656e 2e0d 0a20  s to flatten... 
-0000a790: 2020 2020 2020 2069 6e5f 6b65 7973 2028         in_keys (
-0000a7a0: 7365 7175 656e 6365 206f 6620 7374 722c  sequence of str,
-0000a7b0: 206f 7074 696f 6e61 6c29 3a20 7468 6520   optional): the 
-0000a7c0: 656e 7472 6965 7320 746f 2066 6c61 7474  entries to flatt
-0000a7d0: 656e 2e20 4966 206e 6f6e 6520 6973 2070  en. If none is p
-0000a7e0: 726f 7669 6465 642c 0d0a 2020 2020 2020  rovided,..      
-0000a7f0: 2020 2020 2020 3a6f 626a 3a60 5b22 7069        :obj:`["pi
-0000a800: 7865 6c73 225d 6020 6973 2061 7373 756d  xels"]` is assum
-0000a810: 6564 2e0d 0a20 2020 2020 2020 206f 7574  ed...        out
-0000a820: 5f6b 6579 7320 2873 6571 7565 6e63 6520  _keys (sequence 
-0000a830: 6f66 2073 7472 2c20 6f70 7469 6f6e 616c  of str, optional
-0000a840: 293a 2074 6865 2066 6c61 7474 656e 206f  ): the flatten o
-0000a850: 6273 6572 7661 7469 6f6e 206b 6579 732e  bservation keys.
-0000a860: 2049 6620 6e6f 6e65 2069 730d 0a20 2020   If none is..   
-0000a870: 2020 2020 2020 2020 2070 726f 7669 6465           provide
-0000a880: 642c 203a 6f62 6a3a 6069 6e5f 6b65 7973  d, :obj:`in_keys
-0000a890: 6020 6973 2061 7373 756d 6564 2e0d 0a20  ` is assumed... 
-0000a8a0: 2020 2020 2020 2061 6c6c 6f77 5f70 6f73         allow_pos
-0000a8b0: 6974 6976 655f 6469 6d20 2862 6f6f 6c2c  itive_dim (bool,
-0000a8c0: 206f 7074 696f 6e61 6c29 3a20 6966 2054   optional): if T
-0000a8d0: 7275 652c 2070 6f73 6974 6976 6520 6469  rue, positive di
-0000a8e0: 6d65 6e73 696f 6e73 2061 7265 2061 6363  mensions are acc
-0000a8f0: 6570 7465 642e 0d0a 2020 2020 2020 2020  epted...        
-0000a900: 2020 2020 3a6f 626a 3a60 466c 6174 7465      :obj:`Flatte
-0000a910: 6e4f 6273 6572 7661 7469 6f6e 6020 7769  nObservation` wi
-0000a920: 6c6c 206d 6170 2074 6865 7365 2074 6f20  ll map these to 
-0000a930: 7468 6520 6e5e 7468 2066 6561 7475 7265  the n^th feature
-0000a940: 2064 696d 656e 7369 6f6e 0d0a 2020 2020   dimension..    
-0000a950: 2020 2020 2020 2020 2869 6520 6e5e 7468          (ie n^th
-0000a960: 2064 696d 656e 7369 6f6e 2061 6674 6572   dimension after
-0000a970: 2062 6174 6368 2073 697a 6520 6f66 2070   batch size of p
-0000a980: 6172 656e 7420 656e 7629 206f 6620 7468  arent env) of th
-0000a990: 6520 696e 7075 7420 7465 6e73 6f72 2e0d  e input tensor..
-0000a9a0: 0a20 2020 2020 2020 2020 2020 2044 6566  .            Def
-0000a9b0: 6175 6c74 7320 746f 2046 616c 7365 2c20  aults to False, 
-0000a9c0: 6965 2e20 6e6f 6e2d 6e65 6761 7469 7665  ie. non-negative
-0000a9d0: 2064 696d 656e 7369 6f6e 7320 6172 6520   dimensions are 
-0000a9e0: 6e6f 7420 7065 726d 6974 7465 642e 0d0a  not permitted...
-0000a9f0: 2020 2020 2222 220d 0a0d 0a20 2020 2064      """....    d
-0000aa00: 6566 205f 5f69 6e69 745f 5f28 0d0a 2020  ef __init__(..  
-0000aa10: 2020 2020 2020 7365 6c66 2c0d 0a20 2020        self,..   
-0000aa20: 2020 2020 2066 6972 7374 5f64 696d 3a20       first_dim: 
-0000aa30: 696e 742c 0d0a 2020 2020 2020 2020 6c61  int,..        la
-0000aa40: 7374 5f64 696d 3a20 696e 742c 0d0a 2020  st_dim: int,..  
-0000aa50: 2020 2020 2020 696e 5f6b 6579 733a 204f        in_keys: O
-0000aa60: 7074 696f 6e61 6c5b 5365 7175 656e 6365  ptional[Sequence
-0000aa70: 5b73 7472 5d5d 203d 204e 6f6e 652c 0d0a  [str]] = None,..
-0000aa80: 2020 2020 2020 2020 6f75 745f 6b65 7973          out_keys
-0000aa90: 3a20 4f70 7469 6f6e 616c 5b53 6571 7565  : Optional[Seque
-0000aaa0: 6e63 655b 7374 725d 5d20 3d20 4e6f 6e65  nce[str]] = None
-0000aab0: 2c0d 0a20 2020 2020 2020 2061 6c6c 6f77  ,..        allow
-0000aac0: 5f70 6f73 6974 6976 655f 6469 6d3a 2062  _positive_dim: b
-0000aad0: 6f6f 6c20 3d20 4661 6c73 652c 0d0a 2020  ool = False,..  
-0000aae0: 2020 293a 0d0a 2020 2020 2020 2020 6966    ):..        if
-0000aaf0: 2069 6e5f 6b65 7973 2069 7320 4e6f 6e65   in_keys is None
-0000ab00: 3a0d 0a20 2020 2020 2020 2020 2020 2069  :..            i
-0000ab10: 6e5f 6b65 7973 203d 2049 4d41 4745 5f4b  n_keys = IMAGE_K
-0000ab20: 4559 5320 2023 2064 6566 6175 6c74 0d0a  EYS  # default..
-0000ab30: 2020 2020 2020 2020 7375 7065 7228 292e          super().
-0000ab40: 5f5f 696e 6974 5f5f 2869 6e5f 6b65 7973  __init__(in_keys
-0000ab50: 3d69 6e5f 6b65 7973 2c20 6f75 745f 6b65  =in_keys, out_ke
-0000ab60: 7973 3d6f 7574 5f6b 6579 7329 0d0a 2020  ys=out_keys)..  
-0000ab70: 2020 2020 2020 6966 206e 6f74 2061 6c6c        if not all
-0000ab80: 6f77 5f70 6f73 6974 6976 655f 6469 6d20  ow_positive_dim 
-0000ab90: 616e 6420 6669 7273 745f 6469 6d20 3e3d  and first_dim >=
-0000aba0: 2030 3a0d 0a20 2020 2020 2020 2020 2020   0:..           
-0000abb0: 2072 6169 7365 2056 616c 7565 4572 726f   raise ValueErro
-0000abc0: 7228 0d0a 2020 2020 2020 2020 2020 2020  r(..            
-0000abd0: 2020 2020 2266 6972 7374 5f64 696d 2073      "first_dim s
-0000abe0: 686f 756c 6420 6265 2073 6d61 6c6c 6572  hould be smaller
-0000abf0: 2074 6861 6e20 3020 746f 2061 6363 6f6d   than 0 to accom
-0000ac00: 6f64 6174 6520 666f 7220 220d 0a20 2020  odate for "..   
-0000ac10: 2020 2020 2020 2020 2020 2020 2022 656e               "en
-0000ac20: 7673 206f 6620 6469 6666 6572 656e 7420  vs of different 
-0000ac30: 6261 7463 685f 7369 7a65 732e 220d 0a20  batch_sizes.".. 
-0000ac40: 2020 2020 2020 2020 2020 2029 0d0a 2020             )..  
-0000ac50: 2020 2020 2020 6966 206e 6f74 2061 6c6c        if not all
-0000ac60: 6f77 5f70 6f73 6974 6976 655f 6469 6d20  ow_positive_dim 
-0000ac70: 616e 6420 6c61 7374 5f64 696d 203e 3d20  and last_dim >= 
-0000ac80: 303a 0d0a 2020 2020 2020 2020 2020 2020  0:..            
-0000ac90: 7261 6973 6520 5661 6c75 6545 7272 6f72  raise ValueError
-0000aca0: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
-0000acb0: 2020 2022 6c61 7374 5f64 696d 2073 686f     "last_dim sho
-0000acc0: 756c 6420 6265 2073 6d61 6c6c 6572 2074  uld be smaller t
-0000acd0: 6861 6e20 3020 746f 2061 6363 6f6d 6f64  han 0 to accomod
-0000ace0: 6174 6520 666f 7220 220d 0a20 2020 2020  ate for "..     
-0000acf0: 2020 2020 2020 2020 2020 2022 656e 7673             "envs
-0000ad00: 206f 6620 6469 6666 6572 656e 7420 6261   of different ba
-0000ad10: 7463 685f 7369 7a65 732e 220d 0a20 2020  tch_sizes."..   
-0000ad20: 2020 2020 2020 2020 2029 0d0a 2020 2020           )..    
-0000ad30: 2020 2020 7365 6c66 2e5f 6669 7273 745f      self._first_
-0000ad40: 6469 6d20 3d20 6669 7273 745f 6469 6d0d  dim = first_dim.
-0000ad50: 0a20 2020 2020 2020 2073 656c 662e 5f6c  .        self._l
-0000ad60: 6173 745f 6469 6d20 3d20 6c61 7374 5f64  ast_dim = last_d
-0000ad70: 696d 0d0a 0d0a 2020 2020 4070 726f 7065  im....    @prope
-0000ad80: 7274 790d 0a20 2020 2064 6566 2066 6972  rty..    def fir
-0000ad90: 7374 5f64 696d 2873 656c 6629 3a0d 0a20  st_dim(self):.. 
-0000ada0: 2020 2020 2020 2069 6620 7365 6c66 2e5f         if self._
-0000adb0: 6669 7273 745f 6469 6d20 3e3d 2030 2061  first_dim >= 0 a
-0000adc0: 6e64 2073 656c 662e 7061 7265 6e74 2069  nd self.parent i
-0000add0: 7320 6e6f 7420 4e6f 6e65 3a0d 0a20 2020  s not None:..   
-0000ade0: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
-0000adf0: 6c65 6e28 7365 6c66 2e70 6172 656e 742e  len(self.parent.
-0000ae00: 6261 7463 685f 7369 7a65 2920 2b20 7365  batch_size) + se
-0000ae10: 6c66 2e5f 6669 7273 745f 6469 6d0d 0a20  lf._first_dim.. 
-0000ae20: 2020 2020 2020 2072 6574 7572 6e20 7365         return se
-0000ae30: 6c66 2e5f 6669 7273 745f 6469 6d0d 0a0d  lf._first_dim...
-0000ae40: 0a20 2020 2040 7072 6f70 6572 7479 0d0a  .    @property..
-0000ae50: 2020 2020 6465 6620 6c61 7374 5f64 696d      def last_dim
-0000ae60: 2873 656c 6629 3a0d 0a20 2020 2020 2020  (self):..       
-0000ae70: 2069 6620 7365 6c66 2e5f 6c61 7374 5f64   if self._last_d
-0000ae80: 696d 203e 3d20 3020 616e 6420 7365 6c66  im >= 0 and self
-0000ae90: 2e70 6172 656e 7420 6973 206e 6f74 204e  .parent is not N
-0000aea0: 6f6e 653a 0d0a 2020 2020 2020 2020 2020  one:..          
-0000aeb0: 2020 7265 7475 726e 206c 656e 2873 656c    return len(sel
-0000aec0: 662e 7061 7265 6e74 2e62 6174 6368 5f73  f.parent.batch_s
-0000aed0: 697a 6529 202b 2073 656c 662e 5f6c 6173  ize) + self._las
-0000aee0: 745f 6469 6d0d 0a20 2020 2020 2020 2072  t_dim..        r
-0000aef0: 6574 7572 6e20 7365 6c66 2e5f 6c61 7374  eturn self._last
-0000af00: 5f64 696d 0d0a 0d0a 2020 2020 6465 6620  _dim....    def 
-0000af10: 5f61 7070 6c79 5f74 7261 6e73 666f 726d  _apply_transform
-0000af20: 2873 656c 662c 206f 6273 6572 7661 7469  (self, observati
-0000af30: 6f6e 3a20 746f 7263 682e 5465 6e73 6f72  on: torch.Tensor
-0000af40: 2920 2d3e 2074 6f72 6368 2e54 656e 736f  ) -> torch.Tenso
-0000af50: 723a 0d0a 2020 2020 2020 2020 6f62 7365  r:..        obse
-0000af60: 7276 6174 696f 6e20 3d20 746f 7263 682e  rvation = torch.
-0000af70: 666c 6174 7465 6e28 6f62 7365 7276 6174  flatten(observat
-0000af80: 696f 6e2c 2073 656c 662e 6669 7273 745f  ion, self.first_
-0000af90: 6469 6d2c 2073 656c 662e 6c61 7374 5f64  dim, self.last_d
-0000afa0: 696d 290d 0a20 2020 2020 2020 2072 6574  im)..        ret
-0000afb0: 7572 6e20 6f62 7365 7276 6174 696f 6e0d  urn observation.
-0000afc0: 0a0d 0a20 2020 2066 6f72 7761 7264 203d  ...    forward =
-0000afd0: 204f 6273 6572 7661 7469 6f6e 5472 616e   ObservationTran
-0000afe0: 7366 6f72 6d2e 5f63 616c 6c0d 0a0d 0a20  sform._call.... 
-0000aff0: 2020 2040 5f61 7070 6c79 5f74 6f5f 636f     @_apply_to_co
-0000b000: 6d70 6f73 6974 650d 0a20 2020 2064 6566  mposite..    def
-0000b010: 2074 7261 6e73 666f 726d 5f6f 6273 6572   transform_obser
-0000b020: 7661 7469 6f6e 5f73 7065 6328 7365 6c66  vation_spec(self
-0000b030: 2c20 6f62 7365 7276 6174 696f 6e5f 7370  , observation_sp
-0000b040: 6563 3a20 5465 6e73 6f72 5370 6563 2920  ec: TensorSpec) 
-0000b050: 2d3e 2054 656e 736f 7253 7065 633a 0d0a  -> TensorSpec:..
-0000b060: 2020 2020 2020 2020 7370 6163 6520 3d20          space = 
-0000b070: 6f62 7365 7276 6174 696f 6e5f 7370 6563  observation_spec
-0000b080: 2e73 7061 6365 0d0a 0d0a 2020 2020 2020  .space....      
-0000b090: 2020 6966 2069 7369 6e73 7461 6e63 6528    if isinstance(
-0000b0a0: 7370 6163 652c 2043 6f6e 7469 6e75 6f75  space, Continuou
-0000b0b0: 7342 6f78 293a 0d0a 2020 2020 2020 2020  sBox):..        
-0000b0c0: 2020 2020 7370 6163 652e 6d69 6e69 6d75      space.minimu
-0000b0d0: 6d20 3d20 7365 6c66 2e5f 6170 706c 795f  m = self._apply_
-0000b0e0: 7472 616e 7366 6f72 6d28 7370 6163 652e  transform(space.
-0000b0f0: 6d69 6e69 6d75 6d29 0d0a 2020 2020 2020  minimum)..      
-0000b100: 2020 2020 2020 7370 6163 652e 6d61 7869        space.maxi
-0000b110: 6d75 6d20 3d20 7365 6c66 2e5f 6170 706c  mum = self._appl
-0000b120: 795f 7472 616e 7366 6f72 6d28 7370 6163  y_transform(spac
-0000b130: 652e 6d61 7869 6d75 6d29 0d0a 2020 2020  e.maximum)..    
-0000b140: 2020 2020 2020 2020 6f62 7365 7276 6174          observat
-0000b150: 696f 6e5f 7370 6563 2e73 6861 7065 203d  ion_spec.shape =
-0000b160: 2073 7061 6365 2e6d 696e 696d 756d 2e73   space.minimum.s
-0000b170: 6861 7065 0d0a 2020 2020 2020 2020 656c  hape..        el
-0000b180: 7365 3a0d 0a20 2020 2020 2020 2020 2020  se:..           
-0000b190: 206f 6273 6572 7661 7469 6f6e 5f73 7065   observation_spe
-0000b1a0: 632e 7368 6170 6520 3d20 7365 6c66 2e5f  c.shape = self._
-0000b1b0: 6170 706c 795f 7472 616e 7366 6f72 6d28  apply_transform(
-0000b1c0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-0000b1d0: 2020 746f 7263 682e 7a65 726f 7328 6f62    torch.zeros(ob
-0000b1e0: 7365 7276 6174 696f 6e5f 7370 6563 2e73  servation_spec.s
-0000b1f0: 6861 7065 290d 0a20 2020 2020 2020 2020  hape)..         
-0000b200: 2020 2029 2e73 6861 7065 0d0a 2020 2020     ).shape..    
-0000b210: 2020 2020 7265 7475 726e 206f 6273 6572      return obser
-0000b220: 7661 7469 6f6e 5f73 7065 630d 0a0d 0a20  vation_spec.... 
-0000b230: 2020 2064 6566 205f 5f72 6570 725f 5f28     def __repr__(
-0000b240: 7365 6c66 2920 2d3e 2073 7472 3a0d 0a20  self) -> str:.. 
-0000b250: 2020 2020 2020 2072 6574 7572 6e20 280d         return (.
-0000b260: 0a20 2020 2020 2020 2020 2020 2066 227b  .            f"{
-0000b270: 7365 6c66 2e5f 5f63 6c61 7373 5f5f 2e5f  self.__class__._
-0000b280: 5f6e 616d 655f 5f7d 2822 0d0a 2020 2020  _name__}("..    
-0000b290: 2020 2020 2020 2020 6622 6669 7273 745f          f"first_
-0000b2a0: 6469 6d3d 7b69 6e74 2873 656c 662e 6669  dim={int(self.fi
-0000b2b0: 7273 745f 6469 6d29 7d2c 206c 6173 745f  rst_dim)}, last_
-0000b2c0: 6469 6d3d 7b69 6e74 2873 656c 662e 6c61  dim={int(self.la
-0000b2d0: 7374 5f64 696d 297d 2c20 696e 5f6b 6579  st_dim)}, in_key
-0000b2e0: 733d 7b73 656c 662e 696e 5f6b 6579 737d  s={self.in_keys}
-0000b2f0: 2c20 6f75 745f 6b65 7973 3d7b 7365 6c66  , out_keys={self
-0000b300: 2e6f 7574 5f6b 6579 737d 2922 0d0a 2020  .out_keys})"..  
-0000b310: 2020 2020 2020 290d 0a0d 0a0d 0a63 6c61        )......cla
-0000b320: 7373 2055 6e73 7175 6565 7a65 5472 616e  ss UnsqueezeTran
-0000b330: 7366 6f72 6d28 5472 616e 7366 6f72 6d29  sform(Transform)
-0000b340: 3a0d 0a20 2020 2022 2222 496e 7365 7274  :..    """Insert
-0000b350: 7320 6120 6469 6d65 6e73 696f 6e20 6f66  s a dimension of
-0000b360: 2073 697a 6520 6f6e 6520 6174 2074 6865   size one at the
-0000b370: 2073 7065 6369 6669 6564 2070 6f73 6974   specified posit
-0000b380: 696f 6e2e 0d0a 0d0a 2020 2020 4172 6773  ion.....    Args
-0000b390: 3a0d 0a20 2020 2020 2020 2075 6e73 7175  :..        unsqu
-0000b3a0: 6565 7a65 5f64 696d 2028 696e 7429 3a20  eeze_dim (int): 
-0000b3b0: 6469 6d65 6e73 696f 6e20 746f 2075 6e73  dimension to uns
-0000b3c0: 7175 6565 7a65 2e20 4d75 7374 2062 6520  queeze. Must be 
-0000b3d0: 6e65 6761 7469 7665 2028 6f72 2061 6c6c  negative (or all
-0000b3e0: 6f77 5f70 6f73 6974 6976 655f 6469 6d0d  ow_positive_dim.
-0000b3f0: 0a20 2020 2020 2020 2020 2020 206d 7573  .            mus
-0000b400: 7420 6265 2074 7572 6e65 6420 6f6e 292e  t be turned on).
-0000b410: 0d0a 2020 2020 2020 2020 616c 6c6f 775f  ..        allow_
-0000b420: 706f 7369 7469 7665 5f64 696d 2028 626f  positive_dim (bo
-0000b430: 6f6c 2c20 6f70 7469 6f6e 616c 293a 2069  ol, optional): i
-0000b440: 6620 5472 7565 2c20 706f 7369 7469 7665  f True, positive
-0000b450: 2064 696d 656e 7369 6f6e 7320 6172 6520   dimensions are 
-0000b460: 6163 6365 7074 6564 2e0d 0a20 2020 2020  accepted...     
-0000b470: 2020 2020 2020 203a 6f62 6a3a 6055 6e73         :obj:`Uns
-0000b480: 7175 6565 7a65 5472 616e 7366 6f72 6d60  queezeTransform`
-0000b490: 2077 696c 6c20 6d61 7020 7468 6573 6520   will map these 
-0000b4a0: 746f 2074 6865 206e 5e74 6820 6665 6174  to the n^th feat
-0000b4b0: 7572 6520 6469 6d65 6e73 696f 6e0d 0a20  ure dimension.. 
-0000b4c0: 2020 2020 2020 2020 2020 2028 6965 206e             (ie n
-0000b4d0: 5e74 6820 6469 6d65 6e73 696f 6e20 6166  ^th dimension af
-0000b4e0: 7465 7220 6261 7463 6820 7369 7a65 206f  ter batch size o
-0000b4f0: 6620 7061 7265 6e74 2065 6e76 2920 6f66  f parent env) of
-0000b500: 2074 6865 2069 6e70 7574 2074 656e 736f   the input tenso
-0000b510: 722c 0d0a 2020 2020 2020 2020 2020 2020  r,..            
-0000b520: 696e 6465 7065 6e64 656e 746c 7920 6672  independently fr
-0000b530: 6f6d 2074 6865 2074 656e 736f 7264 6963  om the tensordic
-0000b540: 7420 6261 7463 6820 7369 7a65 2028 6965  t batch size (ie
-0000b550: 2070 6f73 6974 6976 6520 6469 6d73 206d   positive dims m
-0000b560: 6179 2062 650d 0a20 2020 2020 2020 2020  ay be..         
-0000b570: 2020 2064 616e 6765 726f 7573 2069 6e20     dangerous in 
-0000b580: 636f 6e74 6578 7473 2077 6865 7265 2074  contexts where t
-0000b590: 656e 736f 7264 6963 7420 6f66 2064 6966  ensordict of dif
-0000b5a0: 6665 7265 6e74 2062 6174 6368 2064 696d  ferent batch dim
-0000b5b0: 656e 7369 6f6e 0d0a 2020 2020 2020 2020  ension..        
-0000b5c0: 2020 2020 6172 6520 7061 7373 6564 292e      are passed).
-0000b5d0: 0d0a 2020 2020 2020 2020 2020 2020 4465  ..            De
-0000b5e0: 6661 756c 7473 2074 6f20 4661 6c73 652c  faults to False,
-0000b5f0: 2069 652e 206e 6f6e 2d6e 6567 6174 6976   ie. non-negativ
-0000b600: 6520 6469 6d65 6e73 696f 6e73 2061 7265  e dimensions are
-0000b610: 206e 6f74 2070 6572 6d69 7474 6564 2e0d   not permitted..
-0000b620: 0a20 2020 2022 2222 0d0a 0d0a 2020 2020  .    """....    
-0000b630: 696e 7665 7274 6962 6c65 203d 2054 7275  invertible = Tru
-0000b640: 650d 0a0d 0a20 2020 2040 636c 6173 736d  e....    @classm
-0000b650: 6574 686f 640d 0a20 2020 2064 6566 205f  ethod..    def _
-0000b660: 5f6e 6577 5f5f 2863 6c73 2c20 2a61 7267  _new__(cls, *arg
-0000b670: 732c 202a 2a6b 7761 7267 7329 3a0d 0a20  s, **kwargs):.. 
-0000b680: 2020 2020 2020 2063 6c73 2e5f 756e 7371         cls._unsq
-0000b690: 7565 657a 655f 6469 6d20 3d20 4e6f 6e65  ueeze_dim = None
-0000b6a0: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
-0000b6b0: 2073 7570 6572 2829 2e5f 5f6e 6577 5f5f   super().__new__
-0000b6c0: 2863 6c73 290d 0a0d 0a20 2020 2064 6566  (cls)....    def
-0000b6d0: 205f 5f69 6e69 745f 5f28 0d0a 2020 2020   __init__(..    
-0000b6e0: 2020 2020 7365 6c66 2c0d 0a20 2020 2020      self,..     
-0000b6f0: 2020 2075 6e73 7175 6565 7a65 5f64 696d     unsqueeze_dim
-0000b700: 3a20 696e 742c 0d0a 2020 2020 2020 2020  : int,..        
-0000b710: 616c 6c6f 775f 706f 7369 7469 7665 5f64  allow_positive_d
-0000b720: 696d 3a20 626f 6f6c 203d 2046 616c 7365  im: bool = False
-0000b730: 2c0d 0a20 2020 2020 2020 2069 6e5f 6b65  ,..        in_ke
-0000b740: 7973 3a20 4f70 7469 6f6e 616c 5b53 6571  ys: Optional[Seq
-0000b750: 7565 6e63 655b 7374 725d 5d20 3d20 4e6f  uence[str]] = No
-0000b760: 6e65 2c0d 0a20 2020 2020 2020 206f 7574  ne,..        out
-0000b770: 5f6b 6579 733a 204f 7074 696f 6e61 6c5b  _keys: Optional[
-0000b780: 5365 7175 656e 6365 5b73 7472 5d5d 203d  Sequence[str]] =
-0000b790: 204e 6f6e 652c 0d0a 2020 2020 2020 2020   None,..        
-0000b7a0: 696e 5f6b 6579 735f 696e 763a 204f 7074  in_keys_inv: Opt
-0000b7b0: 696f 6e61 6c5b 5365 7175 656e 6365 5b73  ional[Sequence[s
-0000b7c0: 7472 5d5d 203d 204e 6f6e 652c 0d0a 2020  tr]] = None,..  
-0000b7d0: 2020 2020 2020 6f75 745f 6b65 7973 5f69        out_keys_i
-0000b7e0: 6e76 3a20 4f70 7469 6f6e 616c 5b53 6571  nv: Optional[Seq
-0000b7f0: 7565 6e63 655b 7374 725d 5d20 3d20 4e6f  uence[str]] = No
-0000b800: 6e65 2c0d 0a20 2020 2029 3a0d 0a20 2020  ne,..    ):..   
-0000b810: 2020 2020 2069 6620 696e 5f6b 6579 7320       if in_keys 
-0000b820: 6973 204e 6f6e 653a 0d0a 2020 2020 2020  is None:..      
-0000b830: 2020 2020 2020 696e 5f6b 6579 7320 3d20        in_keys = 
-0000b840: 494d 4147 455f 4b45 5953 2020 2320 6465  IMAGE_KEYS  # de
-0000b850: 6661 756c 740d 0a20 2020 2020 2020 2073  fault..        s
-0000b860: 7570 6572 2829 2e5f 5f69 6e69 745f 5f28  uper().__init__(
-0000b870: 0d0a 2020 2020 2020 2020 2020 2020 696e  ..            in
-0000b880: 5f6b 6579 733d 696e 5f6b 6579 732c 0d0a  _keys=in_keys,..
-0000b890: 2020 2020 2020 2020 2020 2020 6f75 745f              out_
-0000b8a0: 6b65 7973 3d6f 7574 5f6b 6579 732c 0d0a  keys=out_keys,..
-0000b8b0: 2020 2020 2020 2020 2020 2020 696e 5f6b              in_k
-0000b8c0: 6579 735f 696e 763d 696e 5f6b 6579 735f  eys_inv=in_keys_
-0000b8d0: 696e 762c 0d0a 2020 2020 2020 2020 2020  inv,..          
-0000b8e0: 2020 6f75 745f 6b65 7973 5f69 6e76 3d6f    out_keys_inv=o
-0000b8f0: 7574 5f6b 6579 735f 696e 762c 0d0a 2020  ut_keys_inv,..  
-0000b900: 2020 2020 2020 290d 0a20 2020 2020 2020        )..       
-0000b910: 2073 656c 662e 616c 6c6f 775f 706f 7369   self.allow_posi
-0000b920: 7469 7665 5f64 696d 203d 2061 6c6c 6f77  tive_dim = allow
-0000b930: 5f70 6f73 6974 6976 655f 6469 6d0d 0a20  _positive_dim.. 
-0000b940: 2020 2020 2020 2069 6620 756e 7371 7565         if unsque
-0000b950: 657a 655f 6469 6d20 3e3d 2030 2061 6e64  eze_dim >= 0 and
-0000b960: 206e 6f74 2061 6c6c 6f77 5f70 6f73 6974   not allow_posit
-0000b970: 6976 655f 6469 6d3a 0d0a 2020 2020 2020  ive_dim:..      
-0000b980: 2020 2020 2020 7261 6973 6520 5275 6e74        raise Runt
-0000b990: 696d 6545 7272 6f72 280d 0a20 2020 2020  imeError(..     
-0000b9a0: 2020 2020 2020 2020 2020 2022 756e 7371             "unsq
-0000b9b0: 7565 657a 655f 6469 6d20 7368 6f75 6c64  ueeze_dim should
-0000b9c0: 2062 6520 736d 616c 6c65 7220 7468 616e   be smaller than
-0000b9d0: 2030 2074 6f20 6163 636f 6d6f 6461 7465   0 to accomodate
-0000b9e0: 2066 6f72 2022 0d0a 2020 2020 2020 2020   for "..        
-0000b9f0: 2020 2020 2020 2020 2265 6e76 7320 6f66          "envs of
-0000ba00: 2064 6966 6665 7265 6e74 2062 6174 6368   different batch
-0000ba10: 5f73 697a 6573 2e20 5475 726e 2061 6c6c  _sizes. Turn all
-0000ba20: 6f77 5f70 6f73 6974 6976 655f 6469 6d20  ow_positive_dim 
-0000ba30: 746f 2061 6363 6f6d 6f64 6174 6520 220d  to accomodate ".
-0000ba40: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000ba50: 2022 666f 7220 706f 7369 7469 7665 2075   "for positive u
-0000ba60: 6e73 7175 6565 7a65 5f64 696d 2e22 0d0a  nsqueeze_dim."..
-0000ba70: 2020 2020 2020 2020 2020 2020 290d 0a20              ).. 
-0000ba80: 2020 2020 2020 2073 656c 662e 5f75 6e73         self._uns
-0000ba90: 7175 6565 7a65 5f64 696d 203d 2075 6e73  queeze_dim = uns
-0000baa0: 7175 6565 7a65 5f64 696d 0d0a 0d0a 2020  queeze_dim....  
-0000bab0: 2020 4070 726f 7065 7274 790d 0a20 2020    @property..   
-0000bac0: 2064 6566 2075 6e73 7175 6565 7a65 5f64   def unsqueeze_d
-0000bad0: 696d 2873 656c 6629 3a0d 0a20 2020 2020  im(self):..     
-0000bae0: 2020 2069 6620 7365 6c66 2e5f 756e 7371     if self._unsq
-0000baf0: 7565 657a 655f 6469 6d20 3e3d 2030 2061  ueeze_dim >= 0 a
-0000bb00: 6e64 2073 656c 662e 7061 7265 6e74 2069  nd self.parent i
-0000bb10: 7320 6e6f 7420 4e6f 6e65 3a0d 0a20 2020  s not None:..   
-0000bb20: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
-0000bb30: 6c65 6e28 7365 6c66 2e70 6172 656e 742e  len(self.parent.
-0000bb40: 6261 7463 685f 7369 7a65 2920 2b20 7365  batch_size) + se
-0000bb50: 6c66 2e5f 756e 7371 7565 657a 655f 6469  lf._unsqueeze_di
-0000bb60: 6d0d 0a20 2020 2020 2020 2072 6574 7572  m..        retur
-0000bb70: 6e20 7365 6c66 2e5f 756e 7371 7565 657a  n self._unsqueez
-0000bb80: 655f 6469 6d0d 0a0d 0a20 2020 2064 6566  e_dim....    def
-0000bb90: 205f 6170 706c 795f 7472 616e 7366 6f72   _apply_transfor
-0000bba0: 6d28 7365 6c66 2c20 6f62 7365 7276 6174  m(self, observat
-0000bbb0: 696f 6e3a 2074 6f72 6368 2e54 656e 736f  ion: torch.Tenso
-0000bbc0: 7229 202d 3e20 746f 7263 682e 5465 6e73  r) -> torch.Tens
-0000bbd0: 6f72 3a0d 0a20 2020 2020 2020 206f 6273  or:..        obs
-0000bbe0: 6572 7661 7469 6f6e 203d 206f 6273 6572  ervation = obser
-0000bbf0: 7661 7469 6f6e 2e75 6e73 7175 6565 7a65  vation.unsqueeze
-0000bc00: 2873 656c 662e 756e 7371 7565 657a 655f  (self.unsqueeze_
-0000bc10: 6469 6d29 0d0a 2020 2020 2020 2020 7265  dim)..        re
-0000bc20: 7475 726e 206f 6273 6572 7661 7469 6f6e  turn observation
-0000bc30: 0d0a 0d0a 2020 2020 6465 6620 5f69 6e76  ....    def _inv
-0000bc40: 5f61 7070 6c79 5f74 7261 6e73 666f 726d  _apply_transform
-0000bc50: 2873 656c 662c 206f 6273 6572 7661 7469  (self, observati
-0000bc60: 6f6e 3a20 746f 7263 682e 5465 6e73 6f72  on: torch.Tensor
-0000bc70: 2920 2d3e 2074 6f72 6368 2e54 656e 736f  ) -> torch.Tenso
-0000bc80: 723a 0d0a 2020 2020 2020 2020 6f62 7365  r:..        obse
-0000bc90: 7276 6174 696f 6e20 3d20 6f62 7365 7276  rvation = observ
-0000bca0: 6174 696f 6e2e 7371 7565 657a 6528 7365  ation.squeeze(se
-0000bcb0: 6c66 2e75 6e73 7175 6565 7a65 5f64 696d  lf.unsqueeze_dim
-0000bcc0: 290d 0a20 2020 2020 2020 2072 6574 7572  )..        retur
-0000bcd0: 6e20 6f62 7365 7276 6174 696f 6e0d 0a0d  n observation...
-0000bce0: 0a20 2020 2064 6566 205f 7472 616e 7366  .    def _transf
-0000bcf0: 6f72 6d5f 7370 6563 2873 656c 662c 2073  orm_spec(self, s
-0000bd00: 7065 633a 2054 656e 736f 7253 7065 6329  pec: TensorSpec)
-0000bd10: 202d 3e20 4e6f 6e65 3a0d 0a20 2020 2020   -> None:..     
-0000bd20: 2020 2073 7061 6365 203d 2073 7065 632e     space = spec.
-0000bd30: 7370 6163 650d 0a20 2020 2020 2020 2069  space..        i
-0000bd40: 6620 6973 696e 7374 616e 6365 2873 7061  f isinstance(spa
-0000bd50: 6365 2c20 436f 6e74 696e 756f 7573 426f  ce, ContinuousBo
-0000bd60: 7829 3a0d 0a20 2020 2020 2020 2020 2020  x):..           
-0000bd70: 2073 7061 6365 2e6d 696e 696d 756d 203d   space.minimum =
-0000bd80: 2073 656c 662e 5f61 7070 6c79 5f74 7261   self._apply_tra
-0000bd90: 6e73 666f 726d 2873 7061 6365 2e6d 696e  nsform(space.min
-0000bda0: 696d 756d 290d 0a20 2020 2020 2020 2020  imum)..         
-0000bdb0: 2020 2073 7061 6365 2e6d 6178 696d 756d     space.maximum
-0000bdc0: 203d 2073 656c 662e 5f61 7070 6c79 5f74   = self._apply_t
-0000bdd0: 7261 6e73 666f 726d 2873 7061 6365 2e6d  ransform(space.m
-0000bde0: 6178 696d 756d 290d 0a20 2020 2020 2020  aximum)..       
-0000bdf0: 2020 2020 2073 7065 632e 7368 6170 6520       spec.shape 
-0000be00: 3d20 7370 6163 652e 6d69 6e69 6d75 6d2e  = space.minimum.
-0000be10: 7368 6170 650d 0a20 2020 2020 2020 2065  shape..        e
-0000be20: 6c73 653a 0d0a 2020 2020 2020 2020 2020  lse:..          
-0000be30: 2020 7370 6563 2e73 6861 7065 203d 2073    spec.shape = s
-0000be40: 656c 662e 5f61 7070 6c79 5f74 7261 6e73  elf._apply_trans
-0000be50: 666f 726d 2874 6f72 6368 2e7a 6572 6f73  form(torch.zeros
-0000be60: 2873 7065 632e 7368 6170 6529 292e 7368  (spec.shape)).sh
-0000be70: 6170 650d 0a20 2020 2020 2020 2072 6574  ape..        ret
-0000be80: 7572 6e20 7370 6563 0d0a 0d0a 2020 2020  urn spec....    
-0000be90: 6465 6620 5f69 6e76 5f74 7261 6e73 666f  def _inv_transfo
-0000bea0: 726d 5f73 7065 6328 7365 6c66 2c20 7370  rm_spec(self, sp
-0000beb0: 6563 3a20 5465 6e73 6f72 5370 6563 2920  ec: TensorSpec) 
-0000bec0: 2d3e 204e 6f6e 653a 0d0a 2020 2020 2020  -> None:..      
-0000bed0: 2020 7370 6163 6520 3d20 7370 6563 2e73    space = spec.s
-0000bee0: 7061 6365 0d0a 2020 2020 2020 2020 6966  pace..        if
-0000bef0: 2069 7369 6e73 7461 6e63 6528 7370 6163   isinstance(spac
-0000bf00: 652c 2043 6f6e 7469 6e75 6f75 7342 6f78  e, ContinuousBox
-0000bf10: 293a 0d0a 2020 2020 2020 2020 2020 2020  ):..            
-0000bf20: 7370 6163 652e 6d69 6e69 6d75 6d20 3d20  space.minimum = 
-0000bf30: 7365 6c66 2e5f 696e 765f 6170 706c 795f  self._inv_apply_
-0000bf40: 7472 616e 7366 6f72 6d28 7370 6163 652e  transform(space.
-0000bf50: 6d69 6e69 6d75 6d29 0d0a 2020 2020 2020  minimum)..      
-0000bf60: 2020 2020 2020 7370 6163 652e 6d61 7869        space.maxi
-0000bf70: 6d75 6d20 3d20 7365 6c66 2e5f 696e 765f  mum = self._inv_
-0000bf80: 6170 706c 795f 7472 616e 7366 6f72 6d28  apply_transform(
-0000bf90: 7370 6163 652e 6d61 7869 6d75 6d29 0d0a  space.maximum)..
-0000bfa0: 2020 2020 2020 2020 2020 2020 7370 6563              spec
-0000bfb0: 2e73 6861 7065 203d 2073 7061 6365 2e6d  .shape = space.m
-0000bfc0: 696e 696d 756d 2e73 6861 7065 0d0a 2020  inimum.shape..  
-0000bfd0: 2020 2020 2020 656c 7365 3a0d 0a20 2020        else:..   
-0000bfe0: 2020 2020 2020 2020 2073 7065 632e 7368           spec.sh
-0000bff0: 6170 6520 3d20 7365 6c66 2e5f 696e 765f  ape = self._inv_
-0000c000: 6170 706c 795f 7472 616e 7366 6f72 6d28  apply_transform(
-0000c010: 746f 7263 682e 7a65 726f 7328 7370 6563  torch.zeros(spec
-0000c020: 2e73 6861 7065 2929 2e73 6861 7065 0d0a  .shape)).shape..
-0000c030: 2020 2020 2020 2020 7265 7475 726e 2073          return s
-0000c040: 7065 630d 0a0d 0a20 2020 2040 5f61 7070  pec....    @_app
-0000c050: 6c79 5f74 6f5f 636f 6d70 6f73 6974 655f  ly_to_composite_
-0000c060: 696e 760d 0a20 2020 2064 6566 2074 7261  inv..    def tra
-0000c070: 6e73 666f 726d 5f69 6e70 7574 5f73 7065  nsform_input_spe
-0000c080: 6328 7365 6c66 2c20 696e 7075 745f 7370  c(self, input_sp
-0000c090: 6563 3a20 5465 6e73 6f72 5370 6563 2920  ec: TensorSpec) 
-0000c0a0: 2d3e 2054 656e 736f 7253 7065 633a 0d0a  -> TensorSpec:..
-0000c0b0: 2020 2020 2020 2020 7265 7475 726e 2073          return s
-0000c0c0: 656c 662e 5f69 6e76 5f74 7261 6e73 666f  elf._inv_transfo
-0000c0d0: 726d 5f73 7065 6328 696e 7075 745f 7370  rm_spec(input_sp
-0000c0e0: 6563 290d 0a0d 0a20 2020 2064 6566 2074  ec)....    def t
-0000c0f0: 7261 6e73 666f 726d 5f72 6577 6172 645f  ransform_reward_
-0000c100: 7370 6563 2873 656c 662c 2072 6577 6172  spec(self, rewar
-0000c110: 645f 7370 6563 3a20 5465 6e73 6f72 5370  d_spec: TensorSp
-0000c120: 6563 2920 2d3e 2054 656e 736f 7253 7065  ec) -> TensorSpe
-0000c130: 633a 0d0a 2020 2020 2020 2020 6966 2022  c:..        if "
-0000c140: 7265 7761 7264 2220 696e 2073 656c 662e  reward" in self.
-0000c150: 696e 5f6b 6579 733a 0d0a 2020 2020 2020  in_keys:..      
-0000c160: 2020 2020 2020 7265 7761 7264 5f73 7065        reward_spe
-0000c170: 6320 3d20 7365 6c66 2e5f 7472 616e 7366  c = self._transf
-0000c180: 6f72 6d5f 7370 6563 2872 6577 6172 645f  orm_spec(reward_
-0000c190: 7370 6563 290d 0a20 2020 2020 2020 2072  spec)..        r
-0000c1a0: 6574 7572 6e20 7265 7761 7264 5f73 7065  eturn reward_spe
-0000c1b0: 630d 0a0d 0a20 2020 2040 5f61 7070 6c79  c....    @_apply
-0000c1c0: 5f74 6f5f 636f 6d70 6f73 6974 650d 0a20  _to_composite.. 
-0000c1d0: 2020 2064 6566 2074 7261 6e73 666f 726d     def transform
-0000c1e0: 5f6f 6273 6572 7661 7469 6f6e 5f73 7065  _observation_spe
-0000c1f0: 6328 7365 6c66 2c20 6f62 7365 7276 6174  c(self, observat
-0000c200: 696f 6e5f 7370 6563 3a20 5465 6e73 6f72  ion_spec: Tensor
-0000c210: 5370 6563 2920 2d3e 2054 656e 736f 7253  Spec) -> TensorS
-0000c220: 7065 633a 0d0a 2020 2020 2020 2020 7265  pec:..        re
-0000c230: 7475 726e 2073 656c 662e 5f74 7261 6e73  turn self._trans
-0000c240: 666f 726d 5f73 7065 6328 6f62 7365 7276  form_spec(observ
-0000c250: 6174 696f 6e5f 7370 6563 290d 0a0d 0a20  ation_spec).... 
-0000c260: 2020 2064 6566 205f 5f72 6570 725f 5f28     def __repr__(
-0000c270: 7365 6c66 2920 2d3e 2073 7472 3a0d 0a20  self) -> str:.. 
-0000c280: 2020 2020 2020 2073 203d 2028 0d0a 2020         s = (..  
-0000c290: 2020 2020 2020 2020 2020 6622 7b73 656c            f"{sel
-0000c2a0: 662e 5f5f 636c 6173 735f 5f2e 5f5f 6e61  f.__class__.__na
-0000c2b0: 6d65 5f5f 7d28 756e 7371 7565 657a 655f  me__}(unsqueeze_
-0000c2c0: 6469 6d3d 7b73 656c 662e 756e 7371 7565  dim={self.unsque
-0000c2d0: 657a 655f 6469 6d7d 2c20 696e 5f6b 6579  eze_dim}, in_key
-0000c2e0: 733d 7b73 656c 662e 696e 5f6b 6579 737d  s={self.in_keys}
-0000c2f0: 2c20 6f75 745f 6b65 7973 3d7b 7365 6c66  , out_keys={self
-0000c300: 2e6f 7574 5f6b 6579 737d 2c22 0d0a 2020  .out_keys},"..  
-0000c310: 2020 2020 2020 2020 2020 6622 2069 6e5f            f" in_
-0000c320: 6b65 7973 5f69 6e76 3d7b 7365 6c66 2e69  keys_inv={self.i
-0000c330: 6e5f 6b65 7973 5f69 6e76 7d2c 206f 7574  n_keys_inv}, out
-0000c340: 5f6b 6579 735f 696e 763d 7b73 656c 662e  _keys_inv={self.
-0000c350: 6f75 745f 6b65 7973 5f69 6e76 7d29 220d  out_keys_inv})".
-0000c360: 0a20 2020 2020 2020 2029 0d0a 2020 2020  .        )..    
-0000c370: 2020 2020 7265 7475 726e 2073 0d0a 0d0a      return s....
-0000c380: 0d0a 636c 6173 7320 5371 7565 657a 6554  ..class SqueezeT
-0000c390: 7261 6e73 666f 726d 2855 6e73 7175 6565  ransform(Unsquee
-0000c3a0: 7a65 5472 616e 7366 6f72 6d29 3a0d 0a20  zeTransform):.. 
-0000c3b0: 2020 2022 2222 5265 6d6f 7665 7320 6120     """Removes a 
-0000c3c0: 6469 6d65 6e73 696f 6e20 6f66 2073 697a  dimension of siz
-0000c3d0: 6520 6f6e 6520 6174 2074 6865 2073 7065  e one at the spe
-0000c3e0: 6369 6669 6564 2070 6f73 6974 696f 6e2e  cified position.
-0000c3f0: 0d0a 0d0a 2020 2020 4172 6773 3a0d 0a20  ....    Args:.. 
-0000c400: 2020 2020 2020 2073 7175 6565 7a65 5f64         squeeze_d
-0000c410: 696d 2028 696e 7429 3a20 6469 6d65 6e73  im (int): dimens
-0000c420: 696f 6e20 746f 2073 7175 6565 7a65 2e0d  ion to squeeze..
-0000c430: 0a20 2020 2022 2222 0d0a 0d0a 2020 2020  .    """....    
-0000c440: 696e 7665 7274 6962 6c65 203d 2054 7275  invertible = Tru
-0000c450: 650d 0a0d 0a20 2020 2064 6566 205f 5f69  e....    def __i
-0000c460: 6e69 745f 5f28 0d0a 2020 2020 2020 2020  nit__(..        
-0000c470: 7365 6c66 2c0d 0a20 2020 2020 2020 2073  self,..        s
-0000c480: 7175 6565 7a65 5f64 696d 3a20 696e 742c  queeze_dim: int,
-0000c490: 0d0a 2020 2020 2020 2020 2a61 7267 732c  ..        *args,
-0000c4a0: 0d0a 2020 2020 2020 2020 696e 5f6b 6579  ..        in_key
-0000c4b0: 733a 204f 7074 696f 6e61 6c5b 5365 7175  s: Optional[Sequ
-0000c4c0: 656e 6365 5b73 7472 5d5d 203d 204e 6f6e  ence[str]] = Non
-0000c4d0: 652c 0d0a 2020 2020 2020 2020 6f75 745f  e,..        out_
-0000c4e0: 6b65 7973 3a20 4f70 7469 6f6e 616c 5b53  keys: Optional[S
-0000c4f0: 6571 7565 6e63 655b 7374 725d 5d20 3d20  equence[str]] = 
-0000c500: 4e6f 6e65 2c0d 0a20 2020 2020 2020 2069  None,..        i
-0000c510: 6e5f 6b65 7973 5f69 6e76 3a20 4f70 7469  n_keys_inv: Opti
-0000c520: 6f6e 616c 5b53 6571 7565 6e63 655b 7374  onal[Sequence[st
-0000c530: 725d 5d20 3d20 4e6f 6e65 2c0d 0a20 2020  r]] = None,..   
-0000c540: 2020 2020 206f 7574 5f6b 6579 735f 696e       out_keys_in
-0000c550: 763a 204f 7074 696f 6e61 6c5b 5365 7175  v: Optional[Sequ
-0000c560: 656e 6365 5b73 7472 5d5d 203d 204e 6f6e  ence[str]] = Non
-0000c570: 652c 0d0a 2020 2020 2020 2020 2a2a 6b77  e,..        **kw
-0000c580: 6172 6773 2c0d 0a20 2020 2029 3a0d 0a20  args,..    ):.. 
-0000c590: 2020 2020 2020 2073 7570 6572 2829 2e5f         super()._
-0000c5a0: 5f69 6e69 745f 5f28 0d0a 2020 2020 2020  _init__(..      
-0000c5b0: 2020 2020 2020 7371 7565 657a 655f 6469        squeeze_di
-0000c5c0: 6d2c 0d0a 2020 2020 2020 2020 2020 2020  m,..            
-0000c5d0: 2a61 7267 732c 0d0a 2020 2020 2020 2020  *args,..        
-0000c5e0: 2020 2020 696e 5f6b 6579 733d 696e 5f6b      in_keys=in_k
-0000c5f0: 6579 732c 0d0a 2020 2020 2020 2020 2020  eys,..          
-0000c600: 2020 6f75 745f 6b65 7973 3d6f 7574 5f6b    out_keys=out_k
-0000c610: 6579 732c 0d0a 2020 2020 2020 2020 2020  eys,..          
-0000c620: 2020 696e 5f6b 6579 735f 696e 763d 696e    in_keys_inv=in
-0000c630: 5f6b 6579 735f 696e 762c 0d0a 2020 2020  _keys_inv,..    
-0000c640: 2020 2020 2020 2020 6f75 745f 6b65 7973          out_keys
-0000c650: 5f69 6e76 3d6f 7574 5f6b 6579 735f 696e  _inv=out_keys_in
-0000c660: 762c 0d0a 2020 2020 2020 2020 2020 2020  v,..            
-0000c670: 2a2a 6b77 6172 6773 2c0d 0a20 2020 2020  **kwargs,..     
-0000c680: 2020 2029 0d0a 0d0a 2020 2020 4070 726f     )....    @pro
-0000c690: 7065 7274 790d 0a20 2020 2064 6566 2073  perty..    def s
-0000c6a0: 7175 6565 7a65 5f64 696d 2873 656c 6629  queeze_dim(self)
-0000c6b0: 3a0d 0a20 2020 2020 2020 2072 6574 7572  :..        retur
-0000c6c0: 6e20 7375 7065 7228 292e 756e 7371 7565  n super().unsque
-0000c6d0: 657a 655f 6469 6d0d 0a0d 0a20 2020 205f  eze_dim....    _
-0000c6e0: 6170 706c 795f 7472 616e 7366 6f72 6d20  apply_transform 
-0000c6f0: 3d20 556e 7371 7565 657a 6554 7261 6e73  = UnsqueezeTrans
-0000c700: 666f 726d 2e5f 696e 765f 6170 706c 795f  form._inv_apply_
-0000c710: 7472 616e 7366 6f72 6d0d 0a20 2020 205f  transform..    _
-0000c720: 696e 765f 6170 706c 795f 7472 616e 7366  inv_apply_transf
-0000c730: 6f72 6d20 3d20 556e 7371 7565 657a 6554  orm = UnsqueezeT
-0000c740: 7261 6e73 666f 726d 2e5f 6170 706c 795f  ransform._apply_
-0000c750: 7472 616e 7366 6f72 6d0d 0a0d 0a0d 0a63  transform......c
-0000c760: 6c61 7373 2047 7261 7953 6361 6c65 284f  lass GrayScale(O
-0000c770: 6273 6572 7661 7469 6f6e 5472 616e 7366  bservationTransf
-0000c780: 6f72 6d29 3a0d 0a20 2020 2022 2222 5475  orm):..    """Tu
-0000c790: 726e 7320 6120 7069 7865 6c20 6f62 7365  rns a pixel obse
-0000c7a0: 7276 6174 696f 6e20 746f 2067 7261 7973  rvation to grays
-0000c7b0: 6361 6c65 2e22 2222 0d0a 0d0a 2020 2020  cale."""....    
-0000c7c0: 6465 6620 5f5f 696e 6974 5f5f 280d 0a20  def __init__(.. 
-0000c7d0: 2020 2020 2020 2073 656c 662c 0d0a 2020         self,..  
-0000c7e0: 2020 2020 2020 696e 5f6b 6579 733a 204f        in_keys: O
-0000c7f0: 7074 696f 6e61 6c5b 5365 7175 656e 6365  ptional[Sequence
-0000c800: 5b73 7472 5d5d 203d 204e 6f6e 652c 0d0a  [str]] = None,..
-0000c810: 2020 2020 2020 2020 6f75 745f 6b65 7973          out_keys
-0000c820: 3a20 4f70 7469 6f6e 616c 5b53 6571 7565  : Optional[Seque
-0000c830: 6e63 655b 7374 725d 5d20 3d20 4e6f 6e65  nce[str]] = None
-0000c840: 2c0d 0a20 2020 2029 3a0d 0a20 2020 2020  ,..    ):..     
-0000c850: 2020 2069 6620 696e 5f6b 6579 7320 6973     if in_keys is
-0000c860: 204e 6f6e 653a 0d0a 2020 2020 2020 2020   None:..        
-0000c870: 2020 2020 696e 5f6b 6579 7320 3d20 494d      in_keys = IM
-0000c880: 4147 455f 4b45 5953 0d0a 2020 2020 2020  AGE_KEYS..      
-0000c890: 2020 7375 7065 7228 4772 6179 5363 616c    super(GrayScal
-0000c8a0: 652c 2073 656c 6629 2e5f 5f69 6e69 745f  e, self).__init_
-0000c8b0: 5f28 696e 5f6b 6579 733d 696e 5f6b 6579  _(in_keys=in_key
-0000c8c0: 732c 206f 7574 5f6b 6579 733d 6f75 745f  s, out_keys=out_
-0000c8d0: 6b65 7973 290d 0a0d 0a20 2020 2064 6566  keys)....    def
-0000c8e0: 205f 6170 706c 795f 7472 616e 7366 6f72   _apply_transfor
-0000c8f0: 6d28 7365 6c66 2c20 6f62 7365 7276 6174  m(self, observat
-0000c900: 696f 6e3a 2074 6f72 6368 2e54 656e 736f  ion: torch.Tenso
-0000c910: 7229 202d 3e20 746f 7263 682e 5465 6e73  r) -> torch.Tens
-0000c920: 6f72 3a0d 0a20 2020 2020 2020 206f 6273  or:..        obs
-0000c930: 6572 7661 7469 6f6e 203d 2046 2e72 6762  ervation = F.rgb
-0000c940: 5f74 6f5f 6772 6179 7363 616c 6528 6f62  _to_grayscale(ob
-0000c950: 7365 7276 6174 696f 6e29 0d0a 2020 2020  servation)..    
-0000c960: 2020 2020 7265 7475 726e 206f 6273 6572      return obser
-0000c970: 7661 7469 6f6e 0d0a 0d0a 2020 2020 405f  vation....    @_
-0000c980: 6170 706c 795f 746f 5f63 6f6d 706f 7369  apply_to_composi
-0000c990: 7465 0d0a 2020 2020 6465 6620 7472 616e  te..    def tran
-0000c9a0: 7366 6f72 6d5f 6f62 7365 7276 6174 696f  sform_observatio
-0000c9b0: 6e5f 7370 6563 2873 656c 662c 206f 6273  n_spec(self, obs
-0000c9c0: 6572 7661 7469 6f6e 5f73 7065 633a 2054  ervation_spec: T
-0000c9d0: 656e 736f 7253 7065 6329 202d 3e20 5465  ensorSpec) -> Te
-0000c9e0: 6e73 6f72 5370 6563 3a0d 0a20 2020 2020  nsorSpec:..     
-0000c9f0: 2020 2073 7061 6365 203d 206f 6273 6572     space = obser
-0000ca00: 7661 7469 6f6e 5f73 7065 632e 7370 6163  vation_spec.spac
-0000ca10: 650d 0a20 2020 2020 2020 2069 6620 6973  e..        if is
-0000ca20: 696e 7374 616e 6365 2873 7061 6365 2c20  instance(space, 
-0000ca30: 436f 6e74 696e 756f 7573 426f 7829 3a0d  ContinuousBox):.
-0000ca40: 0a20 2020 2020 2020 2020 2020 2073 7061  .            spa
-0000ca50: 6365 2e6d 696e 696d 756d 203d 2073 656c  ce.minimum = sel
-0000ca60: 662e 5f61 7070 6c79 5f74 7261 6e73 666f  f._apply_transfo
-0000ca70: 726d 2873 7061 6365 2e6d 696e 696d 756d  rm(space.minimum
-0000ca80: 290d 0a20 2020 2020 2020 2020 2020 2073  )..            s
-0000ca90: 7061 6365 2e6d 6178 696d 756d 203d 2073  pace.maximum = s
-0000caa0: 656c 662e 5f61 7070 6c79 5f74 7261 6e73  elf._apply_trans
-0000cab0: 666f 726d 2873 7061 6365 2e6d 6178 696d  form(space.maxim
-0000cac0: 756d 290d 0a20 2020 2020 2020 2020 2020  um)..           
-0000cad0: 206f 6273 6572 7661 7469 6f6e 5f73 7065   observation_spe
-0000cae0: 632e 7368 6170 6520 3d20 7370 6163 652e  c.shape = space.
-0000caf0: 6d69 6e69 6d75 6d2e 7368 6170 650d 0a20  minimum.shape.. 
-0000cb00: 2020 2020 2020 2065 6c73 653a 0d0a 2020         else:..  
-0000cb10: 2020 2020 2020 2020 2020 6f62 7365 7276            observ
-0000cb20: 6174 696f 6e5f 7370 6563 2e73 6861 7065  ation_spec.shape
-0000cb30: 203d 2073 656c 662e 5f61 7070 6c79 5f74   = self._apply_t
-0000cb40: 7261 6e73 666f 726d 280d 0a20 2020 2020  ransform(..     
-0000cb50: 2020 2020 2020 2020 2020 2074 6f72 6368             torch
-0000cb60: 2e7a 6572 6f73 286f 6273 6572 7661 7469  .zeros(observati
-0000cb70: 6f6e 5f73 7065 632e 7368 6170 6529 0d0a  on_spec.shape)..
-0000cb80: 2020 2020 2020 2020 2020 2020 292e 7368              ).sh
-0000cb90: 6170 650d 0a20 2020 2020 2020 2072 6574  ape..        ret
-0000cba0: 7572 6e20 6f62 7365 7276 6174 696f 6e5f  urn observation_
-0000cbb0: 7370 6563 0d0a 0d0a 0d0a 636c 6173 7320  spec......class 
-0000cbc0: 4f62 7365 7276 6174 696f 6e4e 6f72 6d28  ObservationNorm(
-0000cbd0: 4f62 7365 7276 6174 696f 6e54 7261 6e73  ObservationTrans
-0000cbe0: 666f 726d 293a 0d0a 2020 2020 2222 224f  form):..    """O
-0000cbf0: 6273 6572 7661 7469 6f6e 2061 6666 696e  bservation affin
-0000cc00: 6520 7472 616e 7366 6f72 6d61 7469 6f6e  e transformation
-0000cc10: 206c 6179 6572 2e0d 0a0d 0a20 2020 204e   layer.....    N
-0000cc20: 6f72 6d61 6c69 7a65 7320 616e 206f 6273  ormalizes an obs
-0000cc30: 6572 7661 7469 6f6e 2061 6363 6f72 6469  ervation accordi
-0000cc40: 6e67 2074 6f0d 0a0d 0a20 2020 202e 2e20  ng to....    .. 
-0000cc50: 6d61 7468 3a3a 0d0a 2020 2020 2020 2020  math::..        
-0000cc60: 6f62 7320 3d20 6f62 7320 2a20 7363 616c  obs = obs * scal
-0000cc70: 6520 2b20 6c6f 630d 0a0d 0a20 2020 2041  e + loc....    A
-0000cc80: 7267 733a 0d0a 2020 2020 2020 2020 6c6f  rgs:..        lo
-0000cc90: 6320 286e 756d 6265 7220 6f72 2074 656e  c (number or ten
-0000cca0: 736f 7229 3a20 6c6f 6361 7469 6f6e 206f  sor): location o
-0000ccb0: 6620 7468 6520 6166 6669 6e65 2074 7261  f the affine tra
-0000ccc0: 6e73 666f 726d 0d0a 2020 2020 2020 2020  nsform..        
-0000ccd0: 7363 616c 6520 286e 756d 6265 7220 6f72  scale (number or
-0000cce0: 2074 656e 736f 7229 3a20 7363 616c 6520   tensor): scale 
-0000ccf0: 6f66 2074 6865 2061 6666 696e 6520 7472  of the affine tr
-0000cd00: 616e 7366 6f72 6d0d 0a20 2020 2020 2020  ansform..       
-0000cd10: 2069 6e5f 6b65 7973 2028 6c69 7374 206f   in_keys (list o
-0000cd20: 6620 696e 742c 206f 7074 696f 6e61 6c29  f int, optional)
-0000cd30: 3a20 656e 7472 6965 7320 746f 2062 6520  : entries to be 
-0000cd40: 6e6f 726d 616c 697a 6564 2e20 4465 6661  normalized. Defa
-0000cd50: 756c 7473 2074 6f20 5b22 6f62 7365 7276  ults to ["observ
-0000cd60: 6174 696f 6e22 2c20 2270 6978 656c 7322  ation", "pixels"
-0000cd70: 5d2e 0d0a 2020 2020 2020 2020 2020 2020  ]...            
-0000cd80: 416c 6c20 656e 7472 6965 7320 7769 6c6c  All entries will
-0000cd90: 2062 6520 6e6f 726d 616c 697a 6564 2077   be normalized w
-0000cda0: 6974 6820 7468 6520 7361 6d65 2076 616c  ith the same val
-0000cdb0: 7565 733a 2069 6620 6120 6469 6666 6572  ues: if a differ
-0000cdc0: 656e 7420 6265 6861 7669 6f75 7220 6973  ent behaviour is
-0000cdd0: 2064 6573 6972 6564 0d0a 2020 2020 2020   desired..      
-0000cde0: 2020 2020 2020 2865 2e67 2e20 6120 6469        (e.g. a di
-0000cdf0: 6666 6572 656e 7420 6e6f 726d 616c 697a  fferent normaliz
-0000ce00: 6174 696f 6e20 666f 7220 7069 7865 6c73  ation for pixels
-0000ce10: 2061 6e64 2073 7461 7465 7329 2064 6966   and states) dif
-0000ce20: 6665 7265 6e74 203a 6f62 6a3a 604f 6273  ferent :obj:`Obs
-0000ce30: 6572 7661 7469 6f6e 4e6f 726d 600d 0a20  ervationNorm`.. 
-0000ce40: 2020 2020 2020 2020 2020 206f 626a 6563             objec
-0000ce50: 7473 2073 686f 756c 6420 6265 2075 7365  ts should be use
-0000ce60: 642e 0d0a 2020 2020 2020 2020 6f75 745f  d...        out_
-0000ce70: 6b65 7973 2028 6c69 7374 206f 6620 696e  keys (list of in
-0000ce80: 742c 206f 7074 696f 6e61 6c29 3a20 6f75  t, optional): ou
-0000ce90: 7470 7574 2065 6e74 7269 6573 2e20 4465  tput entries. De
-0000cea0: 6661 756c 7473 2074 6f20 7468 6520 7661  faults to the va
-0000ceb0: 6c75 6520 6f66 2060 696e 5f6b 6579 7360  lue of `in_keys`
-0000cec0: 2e0d 0a20 2020 2020 2020 2069 6e5f 6b65  ...        in_ke
-0000ced0: 7973 5f69 6e76 2028 6c69 7374 206f 6620  ys_inv (list of 
-0000cee0: 696e 742c 206f 7074 696f 6e61 6c29 3a20  int, optional): 
-0000cef0: 4f62 7365 7276 6174 696f 6e4e 6f72 6d20  ObservationNorm 
-0000cf00: 616c 736f 2073 7570 706f 7274 7320 696e  also supports in
-0000cf10: 7665 7273 6520 7472 616e 7366 6f72 6d73  verse transforms
-0000cf20: 2e20 5468 6973 2077 696c 6c0d 0a20 2020  . This will..   
-0000cf30: 2020 2020 2020 2020 206f 6e6c 7920 6f63           only oc
-0000cf40: 6375 7220 6966 2061 206c 6973 7420 6f66  cur if a list of
-0000cf50: 206b 6579 7320 6973 2070 726f 7669 6465   keys is provide
-0000cf60: 6420 746f 203a 6f62 6a3a 6069 6e5f 6b65  d to :obj:`in_ke
-0000cf70: 7973 5f69 6e76 602e 2049 6620 6e6f 6e65  ys_inv`. If none
-0000cf80: 2069 7320 7072 6f76 6964 6564 2c0d 0a20   is provided,.. 
-0000cf90: 2020 2020 2020 2020 2020 206f 6e6c 7920             only 
-0000cfa0: 7468 6520 666f 7277 6172 6420 7472 616e  the forward tran
-0000cfb0: 7366 6f72 6d20 7769 6c6c 2062 6520 6361  sform will be ca
-0000cfc0: 6c6c 6564 2e0d 0a20 2020 2020 2020 206f  lled...        o
-0000cfd0: 7574 5f6b 6579 735f 696e 7620 286c 6973  ut_keys_inv (lis
-0000cfe0: 7420 6f66 2069 6e74 2c20 6f70 7469 6f6e  t of int, option
-0000cff0: 616c 293a 206f 7574 7075 7420 656e 7472  al): output entr
-0000d000: 6965 7320 666f 7220 7468 6520 696e 7665  ies for the inve
-0000d010: 7273 6520 7472 616e 7366 6f72 6d2e 0d0a  rse transform...
-0000d020: 2020 2020 2020 2020 2020 2020 4465 6661              Defa
-0000d030: 756c 7473 2074 6f20 7468 6520 7661 6c75  ults to the valu
-0000d040: 6520 6f66 2060 696e 5f6b 6579 735f 696e  e of `in_keys_in
-0000d050: 7660 2e0d 0a20 2020 2020 2020 2073 7461  v`...        sta
-0000d060: 6e64 6172 645f 6e6f 726d 616c 2028 626f  ndard_normal (bo
-0000d070: 6f6c 2c20 6f70 7469 6f6e 616c 293a 2069  ol, optional): i
-0000d080: 6620 5472 7565 2c20 7468 6520 7472 616e  f True, the tran
-0000d090: 7366 6f72 6d20 7769 6c6c 2062 650d 0a0d  sform will be...
-0000d0a0: 0a20 2020 2020 2020 2020 2020 202e 2e20  .            .. 
-0000d0b0: 6d61 7468 3a3a 0d0a 2020 2020 2020 2020  math::..        
-0000d0c0: 2020 2020 2020 2020 6f62 7320 3d20 286f          obs = (o
-0000d0d0: 6273 2d6c 6f63 292f 7363 616c 650d 0a0d  bs-loc)/scale...
-0000d0e0: 0a20 2020 2020 2020 2020 2020 2061 7320  .            as 
-0000d0f0: 6974 2069 7320 646f 6e65 2066 6f72 2073  it is done for s
-0000d100: 7461 6e64 6172 6469 7a61 7469 6f6e 2e20  tandardization. 
-0000d110: 4465 6661 756c 7420 6973 2060 4661 6c73  Default is `Fals
-0000d120: 6560 2e0d 0a0d 0a20 2020 2045 7861 6d70  e`.....    Examp
-0000d130: 6c65 733a 0d0a 2020 2020 2020 2020 3e3e  les:..        >>
-0000d140: 3e20 746f 7263 682e 7365 745f 6465 6661  > torch.set_defa
-0000d150: 756c 745f 7465 6e73 6f72 5f74 7970 6528  ult_tensor_type(
-0000d160: 746f 7263 682e 446f 7562 6c65 5465 6e73  torch.DoubleTens
-0000d170: 6f72 290d 0a20 2020 2020 2020 203e 3e3e  or)..        >>>
-0000d180: 2072 203d 2074 6f72 6368 2e72 616e 646e   r = torch.randn
-0000d190: 2831 3030 2c20 3329 2a74 6f72 6368 2e72  (100, 3)*torch.r
-0000d1a0: 616e 646e 2833 2920 2b20 746f 7263 682e  andn(3) + torch.
-0000d1b0: 7261 6e64 6e28 3329 0d0a 2020 2020 2020  randn(3)..      
-0000d1c0: 2020 3e3e 3e20 7464 203d 2054 656e 736f    >>> td = Tenso
-0000d1d0: 7244 6963 7428 7b27 6f62 7327 3a20 727d  rDict({'obs': r}
-0000d1e0: 2c20 5b31 3030 5d29 0d0a 2020 2020 2020  , [100])..      
-0000d1f0: 2020 3e3e 3e20 7472 616e 7366 6f72 6d20    >>> transform 
-0000d200: 3d20 4f62 7365 7276 6174 696f 6e4e 6f72  = ObservationNor
-0000d210: 6d28 0d0a 2020 2020 2020 2020 2e2e 2e20  m(..        ... 
-0000d220: 2020 2020 6c6f 6320 3d20 7464 2e67 6574      loc = td.get
-0000d230: 2827 6f62 7327 292e 6d65 616e 2830 292c  ('obs').mean(0),
-0000d240: 0d0a 2020 2020 2020 2020 2e2e 2e20 2020  ..        ...   
-0000d250: 2020 7363 616c 6520 3d20 7464 2e67 6574    scale = td.get
-0000d260: 2827 6f62 7327 292e 7374 6428 3029 2c0d  ('obs').std(0),.
-0000d270: 0a20 2020 2020 2020 202e 2e2e 2020 2020  .        ...    
-0000d280: 2069 6e5f 6b65 7973 3d5b 226f 6273 225d   in_keys=["obs"]
-0000d290: 2c0d 0a20 2020 2020 2020 202e 2e2e 2020  ,..        ...  
-0000d2a0: 2020 2073 7461 6e64 6172 645f 6e6f 726d     standard_norm
-0000d2b0: 616c 3d54 7275 6529 0d0a 2020 2020 2020  al=True)..      
-0000d2c0: 2020 3e3e 3e20 5f20 3d20 7472 616e 7366    >>> _ = transf
-0000d2d0: 6f72 6d28 7464 290d 0a20 2020 2020 2020  orm(td)..       
-0000d2e0: 203e 3e3e 2070 7269 6e74 2874 6f72 6368   >>> print(torch
-0000d2f0: 2e69 7363 6c6f 7365 2874 642e 6765 7428  .isclose(td.get(
-0000d300: 276f 6273 2729 2e6d 6561 6e28 3029 2c0d  'obs').mean(0),.
-0000d310: 0a20 2020 2020 2020 202e 2e2e 2020 2020  .        ...    
-0000d320: 2074 6f72 6368 2e7a 6572 6f73 2833 2929   torch.zeros(3))
-0000d330: 2e61 6c6c 2829 290d 0a20 2020 2020 2020  .all())..       
-0000d340: 2074 656e 736f 7228 5472 7565 290d 0a20   tensor(True).. 
-0000d350: 2020 2020 2020 203e 3e3e 2070 7269 6e74         >>> print
-0000d360: 2874 6f72 6368 2e69 7363 6c6f 7365 2874  (torch.isclose(t
-0000d370: 642e 6765 7428 276e 6578 745f 6f62 7327  d.get('next_obs'
-0000d380: 292e 7374 6428 3029 2c0d 0a20 2020 2020  ).std(0),..     
-0000d390: 2020 202e 2e2e 2020 2020 2074 6f72 6368     ...     torch
-0000d3a0: 2e6f 6e65 7328 3329 292e 616c 6c28 2929  .ones(3)).all())
-0000d3b0: 0d0a 2020 2020 2020 2020 7465 6e73 6f72  ..        tensor
-0000d3c0: 2854 7275 6529 0d0a 0d0a 2020 2020 5468  (True)....    Th
-0000d3d0: 6520 6e6f 726d 616c 697a 6174 696f 6e20  e normalization 
-0000d3e0: 7374 6174 7320 6361 6e20 6265 2061 7574  stats can be aut
-0000d3f0: 6f6d 6174 6963 616c 6c79 2063 6f6d 7075  omatically compu
-0000d400: 7465 643a 0d0a 2020 2020 4578 616d 706c  ted:..    Exampl
-0000d410: 6573 3a0d 0a20 2020 2020 2020 203e 3e3e  es:..        >>>
-0000d420: 2066 726f 6d20 746f 7263 6872 6c2e 656e   from torchrl.en
-0000d430: 7673 2e6c 6962 732e 6779 6d20 696d 706f  vs.libs.gym impo
-0000d440: 7274 2047 796d 456e 760d 0a20 2020 2020  rt GymEnv..     
-0000d450: 2020 203e 3e3e 2074 6f72 6368 2e6d 616e     >>> torch.man
-0000d460: 7561 6c5f 7365 6564 2830 290d 0a20 2020  ual_seed(0)..   
-0000d470: 2020 2020 203e 3e3e 2065 6e76 203d 2047       >>> env = G
-0000d480: 796d 456e 7628 2250 656e 6475 6c75 6d2d  ymEnv("Pendulum-
-0000d490: 7631 2229 0d0a 2020 2020 2020 2020 3e3e  v1")..        >>
-0000d4a0: 3e20 656e 7620 3d20 5472 616e 7366 6f72  > env = Transfor
-0000d4b0: 6d65 6445 6e76 2865 6e76 2c20 4f62 7365  medEnv(env, Obse
-0000d4c0: 7276 6174 696f 6e4e 6f72 6d28 696e 5f6b  rvationNorm(in_k
-0000d4d0: 6579 733d 5b22 6f62 7365 7276 6174 696f  eys=["observatio
-0000d4e0: 6e22 5d29 290d 0a20 2020 2020 2020 203e  n"]))..        >
-0000d4f0: 3e3e 2065 6e76 2e73 6574 5f73 6565 6428  >> env.set_seed(
-0000d500: 3029 0d0a 2020 2020 2020 2020 3e3e 3e20  0)..        >>> 
-0000d510: 656e 762e 7472 616e 7366 6f72 6d2e 696e  env.transform.in
-0000d520: 6974 5f73 7461 7473 2831 3030 290d 0a20  it_stats(100).. 
-0000d530: 2020 2020 2020 203e 3e3e 2070 7269 6e74         >>> print
-0000d540: 2865 6e76 2e74 7261 6e73 666f 726d 2e6c  (env.transform.l
-0000d550: 6f63 2c20 656e 762e 7472 616e 7366 6f72  oc, env.transfor
-0000d560: 6d2e 7363 616c 6529 0d0a 2020 2020 2020  m.scale)..      
-0000d570: 2020 7465 6e73 6f72 285b 2d31 2e33 3735    tensor([-1.375
-0000d580: 3265 2b30 312c 202d 362e 3530 3837 652d  2e+01, -6.5087e-
-0000d590: 3033 2c20 2032 2e39 3239 3465 2d30 335d  03,  2.9294e-03]
-0000d5a0: 2c20 6474 7970 653d 746f 7263 682e 666c  , dtype=torch.fl
-0000d5b0: 6f61 7433 3229 2074 656e 736f 7228 5b31  oat32) tensor([1
-0000d5c0: 342e 3936 3336 2c20 2032 2e35 3630 382c  4.9636,  2.5608,
-0000d5d0: 2020 302e 3634 3038 5d2c 2064 7479 7065    0.6408], dtype
-0000d5e0: 3d74 6f72 6368 2e66 6c6f 6174 3332 290d  =torch.float32).
-0000d5f0: 0a0d 0a20 2020 2022 2222 0d0a 0d0a 2020  ...    """....  
-0000d600: 2020 5f45 5252 5f49 4e49 545f 4d53 4720    _ERR_INIT_MSG 
-0000d610: 3d20 2243 616e 6e6f 7420 6861 7665 2061  = "Cannot have a
-0000d620: 6e20 6d69 7865 6420 696e 6974 6961 6c69  n mixed initiali
-0000d630: 7a65 6420 616e 6420 756e 696e 6974 6961  zed and uninitia
-0000d640: 6c69 7a65 6420 6c6f 6320 616e 6420 7363  lized loc and sc
-0000d650: 616c 6522 0d0a 0d0a 2020 2020 6465 6620  ale"....    def 
-0000d660: 5f5f 696e 6974 5f5f 280d 0a20 2020 2020  __init__(..     
-0000d670: 2020 2073 656c 662c 0d0a 2020 2020 2020     self,..      
-0000d680: 2020 6c6f 633a 204f 7074 696f 6e61 6c5b    loc: Optional[
-0000d690: 666c 6f61 742c 2074 6f72 6368 2e54 656e  float, torch.Ten
-0000d6a0: 736f 725d 203d 204e 6f6e 652c 0d0a 2020  sor] = None,..  
-0000d6b0: 2020 2020 2020 7363 616c 653a 204f 7074        scale: Opt
-0000d6c0: 696f 6e61 6c5b 666c 6f61 742c 2074 6f72  ional[float, tor
-0000d6d0: 6368 2e54 656e 736f 725d 203d 204e 6f6e  ch.Tensor] = Non
-0000d6e0: 652c 0d0a 2020 2020 2020 2020 696e 5f6b  e,..        in_k
-0000d6f0: 6579 733a 204f 7074 696f 6e61 6c5b 5365  eys: Optional[Se
-0000d700: 7175 656e 6365 5b73 7472 5d5d 203d 204e  quence[str]] = N
-0000d710: 6f6e 652c 0d0a 2020 2020 2020 2020 6f75  one,..        ou
-0000d720: 745f 6b65 7973 3a20 4f70 7469 6f6e 616c  t_keys: Optional
-0000d730: 5b53 6571 7565 6e63 655b 7374 725d 5d20  [Sequence[str]] 
-0000d740: 3d20 4e6f 6e65 2c0d 0a20 2020 2020 2020  = None,..       
-0000d750: 2069 6e5f 6b65 7973 5f69 6e76 3a20 4f70   in_keys_inv: Op
-0000d760: 7469 6f6e 616c 5b53 6571 7565 6e63 655b  tional[Sequence[
-0000d770: 7374 725d 5d20 3d20 4e6f 6e65 2c0d 0a20  str]] = None,.. 
-0000d780: 2020 2020 2020 206f 7574 5f6b 6579 735f         out_keys_
-0000d790: 696e 763a 204f 7074 696f 6e61 6c5b 5365  inv: Optional[Se
-0000d7a0: 7175 656e 6365 5b73 7472 5d5d 203d 204e  quence[str]] = N
-0000d7b0: 6f6e 652c 0d0a 2020 2020 2020 2020 7374  one,..        st
-0000d7c0: 616e 6461 7264 5f6e 6f72 6d61 6c3a 2062  andard_normal: b
-0000d7d0: 6f6f 6c20 3d20 4661 6c73 652c 0d0a 2020  ool = False,..  
-0000d7e0: 2020 293a 0d0a 2020 2020 2020 2020 6966    ):..        if
-0000d7f0: 2069 6e5f 6b65 7973 2069 7320 4e6f 6e65   in_keys is None
-0000d800: 3a0d 0a20 2020 2020 2020 2020 2020 2069  :..            i
-0000d810: 6e5f 6b65 7973 203d 205b 0d0a 2020 2020  n_keys = [..    
-0000d820: 2020 2020 2020 2020 2020 2020 226f 6273              "obs
-0000d830: 6572 7661 7469 6f6e 222c 0d0a 2020 2020  ervation",..    
-0000d840: 2020 2020 2020 2020 2020 2020 2270 6978              "pix
-0000d850: 656c 7322 2c0d 0a20 2020 2020 2020 2020  els",..         
-0000d860: 2020 205d 0d0a 2020 2020 2020 2020 7375     ]..        su
-0000d870: 7065 7228 292e 5f5f 696e 6974 5f5f 280d  per().__init__(.
-0000d880: 0a20 2020 2020 2020 2020 2020 2069 6e5f  .            in_
-0000d890: 6b65 7973 3d69 6e5f 6b65 7973 2c0d 0a20  keys=in_keys,.. 
-0000d8a0: 2020 2020 2020 2020 2020 206f 7574 5f6b             out_k
-0000d8b0: 6579 733d 6f75 745f 6b65 7973 2c0d 0a20  eys=out_keys,.. 
-0000d8c0: 2020 2020 2020 2020 2020 2069 6e5f 6b65             in_ke
-0000d8d0: 7973 5f69 6e76 3d69 6e5f 6b65 7973 5f69  ys_inv=in_keys_i
-0000d8e0: 6e76 2c0d 0a20 2020 2020 2020 2020 2020  nv,..           
-0000d8f0: 206f 7574 5f6b 6579 735f 696e 763d 6f75   out_keys_inv=ou
-0000d900: 745f 6b65 7973 5f69 6e76 2c0d 0a20 2020  t_keys_inv,..   
-0000d910: 2020 2020 2029 0d0a 2020 2020 2020 2020       )..        
-0000d920: 6966 206e 6f74 2069 7369 6e73 7461 6e63  if not isinstanc
-0000d930: 6528 7374 616e 6461 7264 5f6e 6f72 6d61  e(standard_norma
-0000d940: 6c2c 2074 6f72 6368 2e54 656e 736f 7229  l, torch.Tensor)
-0000d950: 3a0d 0a20 2020 2020 2020 2020 2020 2073  :..            s
-0000d960: 7461 6e64 6172 645f 6e6f 726d 616c 203d  tandard_normal =
-0000d970: 2074 6f72 6368 2e74 656e 736f 7228 7374   torch.tensor(st
-0000d980: 616e 6461 7264 5f6e 6f72 6d61 6c29 0d0a  andard_normal)..
-0000d990: 2020 2020 2020 2020 7365 6c66 2e72 6567          self.reg
-0000d9a0: 6973 7465 725f 6275 6666 6572 2822 7374  ister_buffer("st
-0000d9b0: 616e 6461 7264 5f6e 6f72 6d61 6c22 2c20  andard_normal", 
-0000d9c0: 7374 616e 6461 7264 5f6e 6f72 6d61 6c29  standard_normal)
-0000d9d0: 0d0a 2020 2020 2020 2020 7365 6c66 2e65  ..        self.e
-0000d9e0: 7073 203d 2031 652d 360d 0a0d 0a20 2020  ps = 1e-6....   
-0000d9f0: 2020 2020 2069 6620 6c6f 6320 6973 206e       if loc is n
-0000da00: 6f74 204e 6f6e 6520 616e 6420 6e6f 7420  ot None and not 
-0000da10: 6973 696e 7374 616e 6365 286c 6f63 2c20  isinstance(loc, 
-0000da20: 746f 7263 682e 5465 6e73 6f72 293a 0d0a  torch.Tensor):..
-0000da30: 2020 2020 2020 2020 2020 2020 6c6f 6320              loc 
-0000da40: 3d20 746f 7263 682e 7465 6e73 6f72 286c  = torch.tensor(l
-0000da50: 6f63 2c20 6474 7970 653d 746f 7263 682e  oc, dtype=torch.
-0000da60: 6765 745f 6465 6661 756c 745f 6474 7970  get_default_dtyp
-0000da70: 6528 2929 0d0a 2020 2020 2020 2020 656c  e())..        el
-0000da80: 6966 206c 6f63 2069 7320 4e6f 6e65 3a0d  if loc is None:.
-0000da90: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
-0000daa0: 7363 616c 6520 6973 206e 6f74 204e 6f6e  scale is not Non
-0000dab0: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
-0000dac0: 2020 2020 7261 6973 6520 5661 6c75 6545      raise ValueE
-0000dad0: 7272 6f72 2873 656c 662e 5f45 5252 5f49  rror(self._ERR_I
-0000dae0: 4e49 545f 4d53 4729 0d0a 2020 2020 2020  NIT_MSG)..      
-0000daf0: 2020 2020 2020 6c6f 6320 3d20 6e6e 2e55        loc = nn.U
-0000db00: 6e69 6e69 7469 616c 697a 6564 4275 6666  ninitializedBuff
-0000db10: 6572 2829 0d0a 0d0a 2020 2020 2020 2020  er()....        
-0000db20: 6966 2073 6361 6c65 2069 7320 6e6f 7420  if scale is not 
-0000db30: 4e6f 6e65 2061 6e64 206e 6f74 2069 7369  None and not isi
-0000db40: 6e73 7461 6e63 6528 7363 616c 652c 2074  nstance(scale, t
-0000db50: 6f72 6368 2e54 656e 736f 7229 3a0d 0a20  orch.Tensor):.. 
-0000db60: 2020 2020 2020 2020 2020 2073 6361 6c65             scale
-0000db70: 203d 2074 6f72 6368 2e74 656e 736f 7228   = torch.tensor(
-0000db80: 7363 616c 652c 2064 7479 7065 3d74 6f72  scale, dtype=tor
-0000db90: 6368 2e67 6574 5f64 6566 6175 6c74 5f64  ch.get_default_d
-0000dba0: 7479 7065 2829 290d 0a20 2020 2020 2020  type())..       
-0000dbb0: 2020 2020 2073 6361 6c65 203d 2073 6361       scale = sca
-0000dbc0: 6c65 2e63 6c61 6d70 5f6d 696e 2873 656c  le.clamp_min(sel
-0000dbd0: 662e 6570 7329 0d0a 2020 2020 2020 2020  f.eps)..        
-0000dbe0: 656c 6966 2073 6361 6c65 2069 7320 4e6f  elif scale is No
-0000dbf0: 6e65 3a0d 0a20 2020 2020 2020 2020 2020  ne:..           
-0000dc00: 2023 2063 6865 636b 2074 6861 7420 6c6f   # check that lo
-0000dc10: 6320 6973 204e 6f6e 6520 746f 6f0d 0a20  c is None too.. 
-0000dc20: 2020 2020 2020 2020 2020 2069 6620 6e6f             if no
-0000dc30: 7420 6973 696e 7374 616e 6365 286c 6f63  t isinstance(loc
-0000dc40: 2c20 6e6e 2e55 6e69 6e69 7469 616c 697a  , nn.Uninitializ
-0000dc50: 6564 4275 6666 6572 293a 0d0a 2020 2020  edBuffer):..    
-0000dc60: 2020 2020 2020 2020 2020 2020 7261 6973              rais
-0000dc70: 6520 5661 6c75 6545 7272 6f72 2873 656c  e ValueError(sel
-0000dc80: 662e 5f45 5252 5f49 4e49 545f 4d53 4729  f._ERR_INIT_MSG)
-0000dc90: 0d0a 2020 2020 2020 2020 2020 2020 7363  ..            sc
-0000dca0: 616c 6520 3d20 6e6e 2e55 6e69 6e69 7469  ale = nn.Uniniti
-0000dcb0: 616c 697a 6564 4275 6666 6572 2829 0d0a  alizedBuffer()..
-0000dcc0: 0d0a 2020 2020 2020 2020 2320 7365 6c66  ..        # self
-0000dcd0: 2e6f 6273 6572 7661 7469 6f6e 5f73 7065  .observation_spe
-0000dce0: 635f 6b65 7920 3d20 6f62 7365 7276 6174  c_key = observat
-0000dcf0: 696f 6e5f 7370 6563 5f6b 6579 0d0a 2020  ion_spec_key..  
-0000dd00: 2020 2020 2020 7365 6c66 2e72 6567 6973        self.regis
-0000dd10: 7465 725f 6275 6666 6572 2822 6c6f 6322  ter_buffer("loc"
-0000dd20: 2c20 6c6f 6329 0d0a 2020 2020 2020 2020  , loc)..        
-0000dd30: 7365 6c66 2e72 6567 6973 7465 725f 6275  self.register_bu
-0000dd40: 6666 6572 2822 7363 616c 6522 2c20 7363  ffer("scale", sc
-0000dd50: 616c 6529 0d0a 0d0a 2020 2020 4070 726f  ale)....    @pro
-0000dd60: 7065 7274 790d 0a20 2020 2064 6566 2069  perty..    def i
-0000dd70: 6e69 7469 616c 697a 6564 2873 656c 6629  nitialized(self)
-0000dd80: 3a0d 0a20 2020 2020 2020 2072 6574 7572  :..        retur
-0000dd90: 6e20 6e6f 7420 6973 696e 7374 616e 6365  n not isinstance
-0000dda0: 2873 656c 662e 6c6f 632c 206e 6e2e 556e  (self.loc, nn.Un
-0000ddb0: 696e 6974 6961 6c69 7a65 6442 7566 6665  initializedBuffe
-0000ddc0: 7229 0d0a 0d0a 2020 2020 6465 6620 696e  r)....    def in
-0000ddd0: 6974 5f73 7461 7473 280d 0a20 2020 2020  it_stats(..     
-0000dde0: 2020 2073 656c 662c 0d0a 2020 2020 2020     self,..      
-0000ddf0: 2020 6e75 6d5f 6974 6572 3a20 696e 742c    num_iter: int,
-0000de00: 0d0a 2020 2020 2020 2020 7265 6475 6365  ..        reduce
-0000de10: 5f64 696d 3a20 556e 696f 6e5b 696e 742c  _dim: Union[int,
-0000de20: 2054 7570 6c65 5b69 6e74 5d5d 203d 2030   Tuple[int]] = 0
-0000de30: 2c0d 0a20 2020 2020 2020 2063 6174 5f64  ,..        cat_d
-0000de40: 696d 3a20 4f70 7469 6f6e 616c 5b69 6e74  im: Optional[int
-0000de50: 5d20 3d20 4e6f 6e65 2c0d 0a20 2020 2020  ] = None,..     
-0000de60: 2020 206b 6579 3a20 4f70 7469 6f6e 616c     key: Optional
-0000de70: 5b73 7472 5d20 3d20 4e6f 6e65 2c0d 0a20  [str] = None,.. 
-0000de80: 2020 2020 2020 206b 6565 705f 6469 6d73         keep_dims
-0000de90: 3a20 4f70 7469 6f6e 616c 5b54 7570 6c65  : Optional[Tuple
-0000dea0: 5b69 6e74 5d5d 203d 204e 6f6e 652c 0d0a  [int]] = None,..
-0000deb0: 2020 2020 2920 2d3e 204e 6f6e 653a 0d0a      ) -> None:..
-0000dec0: 2020 2020 2020 2020 2222 2249 6e69 7469          """Initi
-0000ded0: 616c 697a 6573 2074 6865 206c 6f63 2061  alizes the loc a
-0000dee0: 6e64 2073 6361 6c65 2073 7461 7473 206f  nd scale stats o
-0000def0: 6620 7468 6520 7061 7265 6e74 2065 6e76  f the parent env
-0000df00: 6972 6f6e 6d65 6e74 2e0d 0a0d 0a20 2020  ironment.....   
-0000df10: 2020 2020 204e 6f72 6d61 6c69 7a61 7469       Normalizati
-0000df20: 6f6e 2063 6f6e 7374 616e 7420 7368 6f75  on constant shou
-0000df30: 6c64 2069 6465 616c 6c79 206d 616b 6520  ld ideally make 
-0000df40: 7468 6520 6f62 7365 7276 6174 696f 6e20  the observation 
-0000df50: 7374 6174 6973 7469 6373 2061 7070 726f  statistics appro
-0000df60: 6163 680d 0a20 2020 2020 2020 2074 686f  ach..        tho
-0000df70: 7365 206f 6620 6120 7374 616e 6461 7264  se of a standard
-0000df80: 2047 6175 7373 6961 6e20 6469 7374 7269   Gaussian distri
-0000df90: 6275 7469 6f6e 2e20 5468 6973 206d 6574  bution. This met
-0000dfa0: 686f 6420 636f 6d70 7574 6573 2061 206c  hod computes a l
-0000dfb0: 6f63 6174 696f 6e0d 0a20 2020 2020 2020  ocation..       
-0000dfc0: 2061 6e64 2073 6361 6c65 2074 656e 736f   and scale tenso
-0000dfd0: 7220 7468 6174 2077 696c 6c20 656d 7069  r that will empi
-0000dfe0: 7269 6361 6c6c 7920 636f 6d70 7574 6520  rically compute 
-0000dff0: 7468 6520 6d65 616e 2061 6e64 2073 7461  the mean and sta
-0000e000: 6e64 6172 640d 0a20 2020 2020 2020 2064  ndard..        d
-0000e010: 6576 6961 7469 6f6e 206f 6620 6120 4761  eviation of a Ga
-0000e020: 7573 7369 616e 2064 6973 7472 6962 7574  ussian distribut
-0000e030: 696f 6e20 6669 7474 6564 206f 6e20 6461  ion fitted on da
-0000e040: 7461 2067 656e 6572 6174 6564 2072 616e  ta generated ran
-0000e050: 646f 6d6c 7920 7769 7468 0d0a 2020 2020  domly with..    
-0000e060: 2020 2020 7468 6520 7061 7265 6e74 2065      the parent e
-0000e070: 6e76 6972 6f6e 6d65 6e74 2066 6f72 2061  nvironment for a
-0000e080: 2067 6976 656e 206e 756d 6265 7220 6f66   given number of
-0000e090: 2073 7465 7073 2e0d 0a0d 0a20 2020 2020   steps.....     
-0000e0a0: 2020 2041 7267 733a 0d0a 2020 2020 2020     Args:..      
-0000e0b0: 2020 2020 2020 6e75 6d5f 6974 6572 2028        num_iter (
-0000e0c0: 696e 7429 3a20 6e75 6d62 6572 206f 6620  int): number of 
-0000e0d0: 7261 6e64 6f6d 2069 7465 7261 7469 6f6e  random iteration
-0000e0e0: 7320 746f 2072 756e 2069 6e20 7468 6520  s to run in the 
-0000e0f0: 656e 7669 726f 6e6d 656e 742e 0d0a 2020  environment...  
-0000e100: 2020 2020 2020 2020 2020 7265 6475 6365            reduce
-0000e110: 5f64 696d 2028 696e 7420 6f72 2074 7570  _dim (int or tup
-0000e120: 6c65 206f 6620 696e 742c 206f 7074 696f  le of int, optio
-0000e130: 6e61 6c29 3a20 6469 6d65 6e73 696f 6e20  nal): dimension 
-0000e140: 746f 2063 6f6d 7075 7465 2074 6865 206d  to compute the m
-0000e150: 6561 6e20 616e 6420 7374 6420 6f76 6572  ean and std over
-0000e160: 2e0d 0a20 2020 2020 2020 2020 2020 2020  ...             
-0000e170: 2020 2044 6566 6175 6c74 7320 746f 2030     Defaults to 0
-0000e180: 2e0d 0a20 2020 2020 2020 2020 2020 2063  ...            c
-0000e190: 6174 5f64 696d 2028 696e 742c 206f 7074  at_dim (int, opt
-0000e1a0: 696f 6e61 6c29 3a20 6469 6d65 6e73 696f  ional): dimensio
-0000e1b0: 6e20 616c 6f6e 6720 7768 6963 6820 7468  n along which th
-0000e1c0: 6520 6261 7463 6865 7320 636f 6c6c 6563  e batches collec
-0000e1d0: 7465 6420 7769 6c6c 2062 6520 636f 6e63  ted will be conc
-0000e1e0: 6174 656e 6174 6564 2e0d 0a20 2020 2020  atenated...     
-0000e1f0: 2020 2020 2020 2020 2020 2049 7420 6d75             It mu
-0000e200: 7374 2062 6520 7061 7274 2065 7175 616c  st be part equal
-0000e210: 2074 6f20 7265 6475 6365 5f64 696d 2028   to reduce_dim (
-0000e220: 6966 2069 6e74 6567 6572 2920 6f72 2070  if integer) or p
-0000e230: 6172 7420 6f66 2074 6865 2072 6564 7563  art of the reduc
-0000e240: 655f 6469 6d20 7475 706c 652e 0d0a 2020  e_dim tuple...  
-0000e250: 2020 2020 2020 2020 2020 2020 2020 4465                De
-0000e260: 6661 756c 7473 2074 6f20 7468 6520 7361  faults to the sa
-0000e270: 6d65 2076 616c 7565 2061 7320 7265 6475  me value as redu
-0000e280: 6365 5f64 696d 2e0d 0a20 2020 2020 2020  ce_dim...       
-0000e290: 2020 2020 206b 6579 2028 7374 722c 206f       key (str, o
-0000e2a0: 7074 696f 6e61 6c29 3a20 6966 2070 726f  ptional): if pro
-0000e2b0: 7669 6465 642c 2074 6865 2073 756d 6d61  vided, the summa
-0000e2c0: 7279 2073 7461 7469 7374 6963 7320 7769  ry statistics wi
-0000e2d0: 6c6c 2062 650d 0a20 2020 2020 2020 2020  ll be..         
-0000e2e0: 2020 2020 2020 2072 6574 7269 6576 6564         retrieved
-0000e2f0: 2066 726f 6d20 7468 6174 206b 6579 2069   from that key i
-0000e300: 6e20 7468 6520 7265 7375 6c74 696e 6720  n the resulting 
-0000e310: 7465 6e73 6f72 6469 6374 732e 0d0a 2020  tensordicts...  
-0000e320: 2020 2020 2020 2020 2020 2020 2020 4f74                Ot
-0000e330: 6865 7277 6973 652c 2074 6865 2066 6972  herwise, the fir
-0000e340: 7374 206b 6579 2069 6e20 3a6f 626a 3a60  st key in :obj:`
-0000e350: 4f62 7365 7276 6174 696f 6e4e 6f72 6d2e  ObservationNorm.
-0000e360: 696e 5f6b 6579 7360 2077 696c 6c20 6265  in_keys` will be
-0000e370: 2075 7365 642e 0d0a 2020 2020 2020 2020   used...        
-0000e380: 2020 2020 6b65 6570 5f64 696d 7320 2874      keep_dims (t
-0000e390: 7570 6c65 206f 6620 696e 742c 206f 7074  uple of int, opt
-0000e3a0: 696f 6e61 6c29 3a20 7468 6520 6469 6d65  ional): the dime
-0000e3b0: 6e73 696f 6e73 2074 6f20 6b65 6570 2069  nsions to keep i
-0000e3c0: 6e20 7468 6520 6c6f 6320 616e 6420 7363  n the loc and sc
-0000e3d0: 616c 652e 0d0a 2020 2020 2020 2020 2020  ale...          
-0000e3e0: 2020 2020 2020 466f 7220 696e 7374 616e        For instan
-0000e3f0: 6365 2c20 6f6e 6520 6d61 7920 7761 6e74  ce, one may want
-0000e400: 2074 6865 206c 6f63 6174 696f 6e20 616e   the location an
-0000e410: 6420 7363 616c 6520 746f 2068 6176 6520  d scale to have 
-0000e420: 7368 6170 6520 5b43 2c20 312c 2031 5d0d  shape [C, 1, 1].
-0000e430: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000e440: 2077 6865 6e20 6e6f 726d 616c 697a 696e   when normalizin
-0000e450: 6720 6120 3344 2074 656e 736f 7220 6f76  g a 3D tensor ov
-0000e460: 6572 2074 6865 206c 6173 7420 7477 6f20  er the last two 
-0000e470: 6469 6d65 6e73 696f 6e73 2c20 6275 7420  dimensions, but 
-0000e480: 6e6f 7420 7468 650d 0a20 2020 2020 2020  not the..       
-0000e490: 2020 2020 2020 2020 2074 6869 7264 2e20           third. 
-0000e4a0: 4465 6661 756c 7473 2074 6f20 4e6f 6e65  Defaults to None
-0000e4b0: 2e0d 0a0d 0a20 2020 2020 2020 2022 2222  .....        """
-0000e4c0: 0d0a 2020 2020 2020 2020 6966 2063 6174  ..        if cat
-0000e4d0: 5f64 696d 2069 7320 4e6f 6e65 3a0d 0a20  _dim is None:.. 
-0000e4e0: 2020 2020 2020 2020 2020 2063 6174 5f64             cat_d
-0000e4f0: 696d 203d 2072 6564 7563 655f 6469 6d0d  im = reduce_dim.
-0000e500: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
-0000e510: 6e6f 7420 6973 696e 7374 616e 6365 2863  not isinstance(c
-0000e520: 6174 5f64 696d 2c20 696e 7429 3a0d 0a20  at_dim, int):.. 
-0000e530: 2020 2020 2020 2020 2020 2020 2020 2072                 r
-0000e540: 6169 7365 2056 616c 7565 4572 726f 7228  aise ValueError(
-0000e550: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-0000e560: 2020 2020 2020 2263 6174 5f64 696d 206d        "cat_dim m
-0000e570: 7573 7420 6265 2073 7065 6369 6669 6564  ust be specified
-0000e580: 2069 6620 7265 6475 6365 5f64 696d 2069   if reduce_dim i
-0000e590: 7320 6e6f 7420 616e 2069 6e74 6567 6572  s not an integer
-0000e5a0: 2e22 0d0a 2020 2020 2020 2020 2020 2020  ."..            
-0000e5b0: 2020 2020 290d 0a20 2020 2020 2020 2069      )..        i
-0000e5c0: 6620 2869 7369 6e73 7461 6e63 6528 7265  f (isinstance(re
-0000e5d0: 6475 6365 5f64 696d 2c20 7475 706c 6529  duce_dim, tuple)
-0000e5e0: 2061 6e64 2063 6174 5f64 696d 206e 6f74   and cat_dim not
-0000e5f0: 2069 6e20 7265 6475 6365 5f64 696d 2920   in reduce_dim) 
-0000e600: 6f72 2028 0d0a 2020 2020 2020 2020 2020  or (..          
-0000e610: 2020 6973 696e 7374 616e 6365 2872 6564    isinstance(red
-0000e620: 7563 655f 6469 6d2c 2069 6e74 2920 616e  uce_dim, int) an
-0000e630: 6420 6361 745f 6469 6d20 213d 2072 6564  d cat_dim != red
-0000e640: 7563 655f 6469 6d0d 0a20 2020 2020 2020  uce_dim..       
-0000e650: 2029 3a0d 0a20 2020 2020 2020 2020 2020   ):..           
-0000e660: 2072 6169 7365 2056 616c 7565 4572 726f   raise ValueErro
-0000e670: 7228 2263 6174 5f64 696d 206d 7573 7420  r("cat_dim must 
-0000e680: 6265 2070 6172 7420 6f66 206f 7220 6571  be part of or eq
-0000e690: 7561 6c20 746f 2072 6564 7563 655f 6469  ual to reduce_di
-0000e6a0: 6d2e 2229 0d0a 2020 2020 2020 2020 6966  m.")..        if
-0000e6b0: 2073 656c 662e 696e 6974 6961 6c69 7a65   self.initialize
-0000e6c0: 643a 0d0a 2020 2020 2020 2020 2020 2020  d:..            
-0000e6d0: 7261 6973 6520 5275 6e74 696d 6545 7272  raise RuntimeErr
-0000e6e0: 6f72 280d 0a20 2020 2020 2020 2020 2020  or(..           
-0000e6f0: 2020 2020 2066 224c 6f63 2f53 6361 6c65       f"Loc/Scale
-0000e700: 2061 7265 2061 6c72 6561 6479 2069 6e69   are already ini
-0000e710: 7469 616c 697a 6564 3a20 287b 7365 6c66  tialized: ({self
-0000e720: 2e6c 6f63 7d2c 207b 7365 6c66 2e73 6361  .loc}, {self.sca
-0000e730: 6c65 7d29 220d 0a20 2020 2020 2020 2020  le})"..         
-0000e740: 2020 2029 0d0a 0d0a 2020 2020 2020 2020     )....        
-0000e750: 6966 206c 656e 2873 656c 662e 696e 5f6b  if len(self.in_k
-0000e760: 6579 7329 203e 2031 2061 6e64 206b 6579  eys) > 1 and key
-0000e770: 2069 7320 4e6f 6e65 3a0d 0a20 2020 2020   is None:..     
-0000e780: 2020 2020 2020 2072 6169 7365 2052 756e         raise Run
-0000e790: 7469 6d65 4572 726f 7228 0d0a 2020 2020  timeError(..    
-0000e7a0: 2020 2020 2020 2020 2020 2020 2254 7261              "Tra
-0000e7b0: 6e73 666f 726d 2068 6173 206d 756c 7469  nsform has multi
-0000e7c0: 706c 6520 696e 5f6b 6579 7320 6275 7420  ple in_keys but 
-0000e7d0: 6e6f 2073 7065 6369 6669 6320 6b65 7920  no specific key 
-0000e7e0: 7761 7320 7061 7373 6564 2061 7320 616e  was passed as an
-0000e7f0: 2061 7267 756d 656e 7422 0d0a 2020 2020   argument"..    
-0000e800: 2020 2020 2020 2020 290d 0a20 2020 2020          )..     
-0000e810: 2020 206b 6579 203d 2073 656c 662e 696e     key = self.in
-0000e820: 5f6b 6579 735b 305d 2069 6620 6b65 7920  _keys[0] if key 
-0000e830: 6973 204e 6f6e 6520 656c 7365 206b 6579  is None else key
-0000e840: 0d0a 0d0a 2020 2020 2020 2020 6465 6620  ....        def 
-0000e850: 7261 6973 655f 696e 6974 6961 6c69 7a61  raise_initializa
-0000e860: 7469 6f6e 5f65 7863 6570 7469 6f6e 286d  tion_exception(m
-0000e870: 6f64 756c 6529 3a0d 0a20 2020 2020 2020  odule):..       
-0000e880: 2020 2020 2069 6620 6973 696e 7374 616e       if isinstan
-0000e890: 6365 286d 6f64 756c 652c 204f 6273 6572  ce(module, Obser
-0000e8a0: 7661 7469 6f6e 4e6f 726d 2920 616e 6420  vationNorm) and 
-0000e8b0: 6e6f 7420 6d6f 6475 6c65 2e69 6e69 7469  not module.initi
-0000e8c0: 616c 697a 6564 3a0d 0a20 2020 2020 2020  alized:..       
-0000e8d0: 2020 2020 2020 2020 2072 6169 7365 2052           raise R
-0000e8e0: 756e 7469 6d65 4572 726f 7228 0d0a 2020  untimeError(..  
-0000e8f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e900: 2020 224f 6273 6572 7661 7469 6f6e 4e6f    "ObservationNo
-0000e910: 726d 7320 6e65 6564 2074 6f20 6265 2069  rms need to be i
-0000e920: 6e69 7469 616c 697a 6564 2069 6e20 7468  nitialized in th
-0000e930: 6520 7269 6768 7420 6f72 6465 722e 220d  e right order.".
-0000e940: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000e950: 2020 2020 2022 5472 7969 6e67 2074 6f20       "Trying to 
-0000e960: 696e 6974 6961 6c69 7a65 2061 6e20 4f62  initialize an Ob
-0000e970: 7365 7276 6174 696f 6e4e 6f72 6d20 220d  servationNorm ".
-0000e980: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000e990: 2020 2020 2022 7768 696c 6520 6120 7061       "while a pa
-0000e9a0: 7265 6e74 204f 6273 6572 7661 7469 6f6e  rent Observation
-0000e9b0: 4e6f 726d 2074 7261 6e73 666f 726d 2069  Norm transform i
-0000e9c0: 7320 7374 696c 6c20 756e 696e 6974 6961  s still uninitia
-0000e9d0: 6c69 7a65 6422 0d0a 2020 2020 2020 2020  lized"..        
-0000e9e0: 2020 2020 2020 2020 290d 0a0d 0a20 2020          )....   
-0000e9f0: 2020 2020 2070 6172 656e 7420 3d20 7365       parent = se
-0000ea00: 6c66 2e70 6172 656e 740d 0a20 2020 2020  lf.parent..     
-0000ea10: 2020 2069 6620 7061 7265 6e74 2069 7320     if parent is 
-0000ea20: 4e6f 6e65 3a0d 0a20 2020 2020 2020 2020  None:..         
-0000ea30: 2020 2072 6169 7365 2052 756e 7469 6d65     raise Runtime
-0000ea40: 4572 726f 7228 0d0a 2020 2020 2020 2020  Error(..        
-0000ea50: 2020 2020 2020 2020 2243 616e 6e6f 7420          "Cannot 
-0000ea60: 696e 6974 6961 6c69 7a65 2074 6865 2074  initialize the t
-0000ea70: 7261 6e73 666f 726d 2069 6620 7061 7265  ransform if pare
-0000ea80: 6e74 2065 6e76 2069 7320 6e6f 7420 6465  nt env is not de
-0000ea90: 6669 6e65 642e 220d 0a20 2020 2020 2020  fined."..       
-0000eaa0: 2020 2020 2029 0d0a 2020 2020 2020 2020       )..        
-0000eab0: 7061 7265 6e74 2e61 7070 6c79 2872 6169  parent.apply(rai
-0000eac0: 7365 5f69 6e69 7469 616c 697a 6174 696f  se_initializatio
-0000ead0: 6e5f 6578 6365 7074 696f 6e29 0d0a 0d0a  n_exception)....
-0000eae0: 2020 2020 2020 2020 636f 6c6c 6563 7465          collecte
-0000eaf0: 645f 6672 616d 6573 203d 2030 0d0a 2020  d_frames = 0..  
-0000eb00: 2020 2020 2020 6461 7461 203d 205b 5d0d        data = [].
-0000eb10: 0a20 2020 2020 2020 2077 6869 6c65 2063  .        while c
-0000eb20: 6f6c 6c65 6374 6564 5f66 7261 6d65 7320  ollected_frames 
-0000eb30: 3c20 6e75 6d5f 6974 6572 3a0d 0a20 2020  < num_iter:..   
-0000eb40: 2020 2020 2020 2020 2074 656e 736f 7264           tensord
-0000eb50: 6963 7420 3d20 7061 7265 6e74 2e72 6f6c  ict = parent.rol
-0000eb60: 6c6f 7574 286d 6178 5f73 7465 7073 3d6e  lout(max_steps=n
-0000eb70: 756d 5f69 7465 7229 0d0a 2020 2020 2020  um_iter)..      
-0000eb80: 2020 2020 2020 636f 6c6c 6563 7465 645f        collected_
-0000eb90: 6672 616d 6573 202b 3d20 7465 6e73 6f72  frames += tensor
-0000eba0: 6469 6374 2e6e 756d 656c 2829 0d0a 2020  dict.numel()..  
-0000ebb0: 2020 2020 2020 2020 2020 6461 7461 2e61            data.a
-0000ebc0: 7070 656e 6428 7465 6e73 6f72 6469 6374  ppend(tensordict
-0000ebd0: 2e67 6574 286b 6579 2929 0d0a 0d0a 2020  .get(key))....  
-0000ebe0: 2020 2020 2020 6461 7461 203d 2074 6f72        data = tor
-0000ebf0: 6368 2e63 6174 2864 6174 612c 2063 6174  ch.cat(data, cat
-0000ec00: 5f64 696d 290d 0a20 2020 2020 2020 2069  _dim)..        i
-0000ec10: 6620 6973 696e 7374 616e 6365 2872 6564  f isinstance(red
-0000ec20: 7563 655f 6469 6d2c 2069 6e74 293a 0d0a  uce_dim, int):..
-0000ec30: 2020 2020 2020 2020 2020 2020 7265 6475              redu
-0000ec40: 6365 5f64 696d 203d 205b 7265 6475 6365  ce_dim = [reduce
-0000ec50: 5f64 696d 5d0d 0a20 2020 2020 2020 2069  _dim]..        i
-0000ec60: 6620 6b65 6570 5f64 696d 7320 6973 206e  f keep_dims is n
-0000ec70: 6f74 204e 6f6e 653a 0d0a 2020 2020 2020  ot None:..      
-0000ec80: 2020 2020 2020 6966 206e 6f74 2061 6c6c        if not all
-0000ec90: 286b 2069 6e20 7265 6475 6365 5f64 696d  (k in reduce_dim
-0000eca0: 2066 6f72 206b 2069 6e20 6b65 6570 5f64   for k in keep_d
-0000ecb0: 696d 7329 3a0d 0a20 2020 2020 2020 2020  ims):..         
-0000ecc0: 2020 2020 2020 2072 6169 7365 2056 616c         raise Val
-0000ecd0: 7565 4572 726f 7228 226b 6565 705f 6469  ueError("keep_di
-0000ece0: 6d20 656c 656d 656e 7473 206d 7573 7420  m elements must 
-0000ecf0: 6265 2070 6172 7420 6f66 2072 6564 7563  be part of reduc
-0000ed00: 655f 6469 6d20 6c69 7374 2e22 290d 0a20  e_dim list.").. 
-0000ed10: 2020 2020 2020 2065 6c73 653a 0d0a 2020         else:..  
-0000ed20: 2020 2020 2020 2020 2020 6b65 6570 5f64            keep_d
-0000ed30: 696d 7320 3d20 5b5d 0d0a 2020 2020 2020  ims = []..      
-0000ed40: 2020 6c6f 6320 3d20 6461 7461 2e6d 6561    loc = data.mea
-0000ed50: 6e28 7265 6475 6365 5f64 696d 2c20 6b65  n(reduce_dim, ke
-0000ed60: 6570 6469 6d3d 5472 7565 290d 0a20 2020  epdim=True)..   
-0000ed70: 2020 2020 2073 6361 6c65 203d 2064 6174       scale = dat
-0000ed80: 612e 7374 6428 7265 6475 6365 5f64 696d  a.std(reduce_dim
-0000ed90: 2c20 6b65 6570 6469 6d3d 5472 7565 290d  , keepdim=True).
-0000eda0: 0a20 2020 2020 2020 2066 6f72 2072 2069  .        for r i
-0000edb0: 6e20 736f 7274 6564 2872 6564 7563 655f  n sorted(reduce_
-0000edc0: 6469 6d2c 2072 6576 6572 7365 3d54 7275  dim, reverse=Tru
-0000edd0: 6529 3a0d 0a20 2020 2020 2020 2020 2020  e):..           
-0000ede0: 2069 6620 7220 6e6f 7420 696e 206b 6565   if r not in kee
-0000edf0: 705f 6469 6d73 3a0d 0a20 2020 2020 2020  p_dims:..       
-0000ee00: 2020 2020 2020 2020 206c 6f63 203d 206c           loc = l
-0000ee10: 6f63 2e73 7175 6565 7a65 2872 290d 0a20  oc.squeeze(r).. 
-0000ee20: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-0000ee30: 6361 6c65 203d 2073 6361 6c65 2e73 7175  cale = scale.squ
-0000ee40: 6565 7a65 2872 290d 0a0d 0a20 2020 2020  eeze(r)....     
-0000ee50: 2020 2069 6620 6e6f 7420 7365 6c66 2e73     if not self.s
-0000ee60: 7461 6e64 6172 645f 6e6f 726d 616c 3a0d  tandard_normal:.
-0000ee70: 0a20 2020 2020 2020 2020 2020 2073 6361  .            sca
-0000ee80: 6c65 203d 2031 202f 2073 6361 6c65 2e63  le = 1 / scale.c
-0000ee90: 6c61 6d70 5f6d 696e 2873 656c 662e 6570  lamp_min(self.ep
-0000eea0: 7329 0d0a 2020 2020 2020 2020 2020 2020  s)..            
-0000eeb0: 6c6f 6320 3d20 2d6c 6f63 202a 2073 6361  loc = -loc * sca
-0000eec0: 6c65 0d0a 0d0a 2020 2020 2020 2020 6966  le....        if
-0000eed0: 206e 6f74 2074 6f72 6368 2e69 7366 696e   not torch.isfin
-0000eee0: 6974 6528 6c6f 6329 2e61 6c6c 2829 3a0d  ite(loc).all():.
-0000eef0: 0a20 2020 2020 2020 2020 2020 2072 6169  .            rai
-0000ef00: 7365 2052 756e 7469 6d65 4572 726f 7228  se RuntimeError(
-0000ef10: 224e 6f6e 2d66 696e 6974 6520 7661 6c75  "Non-finite valu
-0000ef20: 6573 2066 6f75 6e64 2069 6e20 6c6f 6322  es found in loc"
-0000ef30: 290d 0a20 2020 2020 2020 2069 6620 6e6f  )..        if no
-0000ef40: 7420 746f 7263 682e 6973 6669 6e69 7465  t torch.isfinite
-0000ef50: 2873 6361 6c65 292e 616c 6c28 293a 0d0a  (scale).all():..
-0000ef60: 2020 2020 2020 2020 2020 2020 7261 6973              rais
-0000ef70: 6520 5275 6e74 696d 6545 7272 6f72 2822  e RuntimeError("
-0000ef80: 4e6f 6e2d 6669 6e69 7465 2076 616c 7565  Non-finite value
-0000ef90: 7320 666f 756e 6420 696e 2073 6361 6c65  s found in scale
-0000efa0: 2229 0d0a 2020 2020 2020 2020 7365 6c66  ")..        self
-0000efb0: 2e6c 6f63 2e6d 6174 6572 6961 6c69 7a65  .loc.materialize
-0000efc0: 2873 6861 7065 3d6c 6f63 2e73 6861 7065  (shape=loc.shape
-0000efd0: 2c20 6474 7970 653d 6c6f 632e 6474 7970  , dtype=loc.dtyp
-0000efe0: 6529 0d0a 2020 2020 2020 2020 7365 6c66  e)..        self
-0000eff0: 2e6c 6f63 2e63 6f70 795f 286c 6f63 290d  .loc.copy_(loc).
-0000f000: 0a20 2020 2020 2020 2073 656c 662e 7363  .        self.sc
-0000f010: 616c 652e 6d61 7465 7269 616c 697a 6528  ale.materialize(
-0000f020: 7368 6170 653d 7363 616c 652e 7368 6170  shape=scale.shap
-0000f030: 652c 2064 7479 7065 3d73 6361 6c65 2e64  e, dtype=scale.d
-0000f040: 7479 7065 290d 0a20 2020 2020 2020 2073  type)..        s
-0000f050: 656c 662e 7363 616c 652e 636f 7079 5f28  elf.scale.copy_(
-0000f060: 7363 616c 652e 636c 616d 705f 6d69 6e28  scale.clamp_min(
-0000f070: 7365 6c66 2e65 7073 2929 0d0a 0d0a 2020  self.eps))....  
-0000f080: 2020 6465 6620 5f61 7070 6c79 5f74 7261    def _apply_tra
-0000f090: 6e73 666f 726d 2873 656c 662c 206f 6273  nsform(self, obs
-0000f0a0: 3a20 746f 7263 682e 5465 6e73 6f72 2920  : torch.Tensor) 
-0000f0b0: 2d3e 2074 6f72 6368 2e54 656e 736f 723a  -> torch.Tensor:
-0000f0c0: 0d0a 2020 2020 2020 2020 6966 206e 6f74  ..        if not
-0000f0d0: 2073 656c 662e 696e 6974 6961 6c69 7a65   self.initialize
-0000f0e0: 643a 0d0a 2020 2020 2020 2020 2020 2020  d:..            
-0000f0f0: 7261 6973 6520 5275 6e74 696d 6545 7272  raise RuntimeErr
-0000f100: 6f72 280d 0a20 2020 2020 2020 2020 2020  or(..           
-0000f110: 2020 2020 2022 4c6f 632f 5363 616c 6520       "Loc/Scale 
-0000f120: 6861 7665 206e 6f74 2062 6565 6e20 696e  have not been in
-0000f130: 6974 6961 6c69 7a65 642e 2045 6974 6865  itialized. Eithe
-0000f140: 7220 7061 7373 2069 6e20 7661 6c75 6573  r pass in values
-0000f150: 2069 6e20 7468 6520 636f 6e73 7472 7563   in the construc
-0000f160: 746f 7220 220d 0a20 2020 2020 2020 2020  tor "..         
-0000f170: 2020 2020 2020 2022 6f72 2063 616c 6c20         "or call 
-0000f180: 7468 6520 696e 6974 5f73 7461 7473 206d  the init_stats m
-0000f190: 6574 686f 6422 0d0a 2020 2020 2020 2020  ethod"..        
-0000f1a0: 2020 2020 290d 0a20 2020 2020 2020 2069      )..        i
-0000f1b0: 6620 7365 6c66 2e73 7461 6e64 6172 645f  f self.standard_
-0000f1c0: 6e6f 726d 616c 3a0d 0a20 2020 2020 2020  normal:..       
-0000f1d0: 2020 2020 206c 6f63 203d 2073 656c 662e       loc = self.
-0000f1e0: 6c6f 630d 0a20 2020 2020 2020 2020 2020  loc..           
-0000f1f0: 2073 6361 6c65 203d 2073 656c 662e 7363   scale = self.sc
-0000f200: 616c 650d 0a20 2020 2020 2020 2020 2020  ale..           
-0000f210: 2072 6574 7572 6e20 286f 6273 202d 206c   return (obs - l
-0000f220: 6f63 2920 2f20 7363 616c 650d 0a20 2020  oc) / scale..   
-0000f230: 2020 2020 2065 6c73 653a 0d0a 2020 2020       else:..    
-0000f240: 2020 2020 2020 2020 7363 616c 6520 3d20          scale = 
-0000f250: 7365 6c66 2e73 6361 6c65 0d0a 2020 2020  self.scale..    
-0000f260: 2020 2020 2020 2020 6c6f 6320 3d20 7365          loc = se
-0000f270: 6c66 2e6c 6f63 0d0a 2020 2020 2020 2020  lf.loc..        
-0000f280: 2020 2020 7265 7475 726e 206f 6273 202a      return obs *
-0000f290: 2073 6361 6c65 202b 206c 6f63 0d0a 0d0a   scale + loc....
-0000f2a0: 2020 2020 6465 6620 5f69 6e76 5f61 7070      def _inv_app
-0000f2b0: 6c79 5f74 7261 6e73 666f 726d 2873 656c  ly_transform(sel
-0000f2c0: 662c 206f 6273 3a20 746f 7263 682e 5465  f, obs: torch.Te
-0000f2d0: 6e73 6f72 2920 2d3e 2074 6f72 6368 2e54  nsor) -> torch.T
-0000f2e0: 656e 736f 723a 0d0a 2020 2020 2020 2020  ensor:..        
-0000f2f0: 6966 2073 656c 662e 6c6f 6320 6973 204e  if self.loc is N
-0000f300: 6f6e 6520 6f72 2073 656c 662e 7363 616c  one or self.scal
-0000f310: 6520 6973 204e 6f6e 653a 0d0a 2020 2020  e is None:..    
-0000f320: 2020 2020 2020 2020 7261 6973 6520 5275          raise Ru
-0000f330: 6e74 696d 6545 7272 6f72 280d 0a20 2020  ntimeError(..   
-0000f340: 2020 2020 2020 2020 2020 2020 2022 4c6f               "Lo
-0000f350: 632f 5363 616c 6520 6861 7665 206e 6f74  c/Scale have not
-0000f360: 2062 6565 6e20 696e 6974 6961 6c69 7a65   been initialize
-0000f370: 642e 2045 6974 6865 7220 7061 7373 2069  d. Either pass i
-0000f380: 6e20 7661 6c75 6573 2069 6e20 7468 6520  n values in the 
-0000f390: 636f 6e73 7472 7563 746f 7220 220d 0a20  constructor ".. 
-0000f3a0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
-0000f3b0: 6f72 2063 616c 6c20 7468 6520 696e 6974  or call the init
-0000f3c0: 5f73 7461 7473 206d 6574 686f 6422 0d0a  _stats method"..
-0000f3d0: 2020 2020 2020 2020 2020 2020 290d 0a20              ).. 
-0000f3e0: 2020 2020 2020 2069 6620 6e6f 7420 7365         if not se
-0000f3f0: 6c66 2e73 7461 6e64 6172 645f 6e6f 726d  lf.standard_norm
-0000f400: 616c 3a0d 0a20 2020 2020 2020 2020 2020  al:..           
-0000f410: 206c 6f63 203d 2073 656c 662e 6c6f 630d   loc = self.loc.
-0000f420: 0a20 2020 2020 2020 2020 2020 2073 6361  .            sca
-0000f430: 6c65 203d 2073 656c 662e 7363 616c 650d  le = self.scale.
-0000f440: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
-0000f450: 7572 6e20 286f 6273 202d 206c 6f63 2920  urn (obs - loc) 
-0000f460: 2f20 7363 616c 650d 0a20 2020 2020 2020  / scale..       
-0000f470: 2065 6c73 653a 0d0a 2020 2020 2020 2020   else:..        
-0000f480: 2020 2020 7363 616c 6520 3d20 7365 6c66      scale = self
-0000f490: 2e73 6361 6c65 0d0a 2020 2020 2020 2020  .scale..        
-0000f4a0: 2020 2020 6c6f 6320 3d20 7365 6c66 2e6c      loc = self.l
-0000f4b0: 6f63 0d0a 2020 2020 2020 2020 2020 2020  oc..            
-0000f4c0: 7265 7475 726e 206f 6273 202a 2073 6361  return obs * sca
-0000f4d0: 6c65 202b 206c 6f63 0d0a 0d0a 2020 2020  le + loc....    
-0000f4e0: 405f 6170 706c 795f 746f 5f63 6f6d 706f  @_apply_to_compo
-0000f4f0: 7369 7465 0d0a 2020 2020 6465 6620 7472  site..    def tr
-0000f500: 616e 7366 6f72 6d5f 6f62 7365 7276 6174  ansform_observat
-0000f510: 696f 6e5f 7370 6563 2873 656c 662c 206f  ion_spec(self, o
-0000f520: 6273 6572 7661 7469 6f6e 5f73 7065 633a  bservation_spec:
-0000f530: 2054 656e 736f 7253 7065 6329 202d 3e20   TensorSpec) -> 
-0000f540: 5465 6e73 6f72 5370 6563 3a0d 0a20 2020  TensorSpec:..   
-0000f550: 2020 2020 2073 7061 6365 203d 206f 6273       space = obs
-0000f560: 6572 7661 7469 6f6e 5f73 7065 632e 7370  ervation_spec.sp
-0000f570: 6163 650d 0a20 2020 2020 2020 2069 6620  ace..        if 
-0000f580: 6973 696e 7374 616e 6365 2873 7061 6365  isinstance(space
-0000f590: 2c20 436f 6e74 696e 756f 7573 426f 7829  , ContinuousBox)
-0000f5a0: 3a0d 0a20 2020 2020 2020 2020 2020 2073  :..            s
-0000f5b0: 7061 6365 2e6d 696e 696d 756d 203d 2073  pace.minimum = s
-0000f5c0: 656c 662e 5f61 7070 6c79 5f74 7261 6e73  elf._apply_trans
-0000f5d0: 666f 726d 2873 7061 6365 2e6d 696e 696d  form(space.minim
-0000f5e0: 756d 290d 0a20 2020 2020 2020 2020 2020  um)..           
-0000f5f0: 2073 7061 6365 2e6d 6178 696d 756d 203d   space.maximum =
-0000f600: 2073 656c 662e 5f61 7070 6c79 5f74 7261   self._apply_tra
-0000f610: 6e73 666f 726d 2873 7061 6365 2e6d 6178  nsform(space.max
-0000f620: 696d 756d 290d 0a20 2020 2020 2020 2072  imum)..        r
-0000f630: 6574 7572 6e20 6f62 7365 7276 6174 696f  eturn observatio
-0000f640: 6e5f 7370 6563 0d0a 0d0a 2020 2020 405f  n_spec....    @_
-0000f650: 6170 706c 795f 746f 5f63 6f6d 706f 7369  apply_to_composi
-0000f660: 7465 5f69 6e76 0d0a 2020 2020 6465 6620  te_inv..    def 
-0000f670: 7472 616e 7366 6f72 6d5f 696e 7075 745f  transform_input_
-0000f680: 7370 6563 2873 656c 662c 2069 6e70 7574  spec(self, input
-0000f690: 5f73 7065 633a 2054 656e 736f 7253 7065  _spec: TensorSpe
-0000f6a0: 6329 202d 3e20 5465 6e73 6f72 5370 6563  c) -> TensorSpec
-0000f6b0: 3a0d 0a20 2020 2020 2020 2073 7061 6365  :..        space
-0000f6c0: 203d 2069 6e70 7574 5f73 7065 632e 7370   = input_spec.sp
-0000f6d0: 6163 650d 0a20 2020 2020 2020 2069 6620  ace..        if 
-0000f6e0: 6973 696e 7374 616e 6365 2873 7061 6365  isinstance(space
-0000f6f0: 2c20 436f 6e74 696e 756f 7573 426f 7829  , ContinuousBox)
-0000f700: 3a0d 0a20 2020 2020 2020 2020 2020 2073  :..            s
-0000f710: 7061 6365 2e6d 696e 696d 756d 203d 2073  pace.minimum = s
-0000f720: 656c 662e 5f61 7070 6c79 5f74 7261 6e73  elf._apply_trans
-0000f730: 666f 726d 2873 7061 6365 2e6d 696e 696d  form(space.minim
-0000f740: 756d 290d 0a20 2020 2020 2020 2020 2020  um)..           
-0000f750: 2073 7061 6365 2e6d 6178 696d 756d 203d   space.maximum =
-0000f760: 2073 656c 662e 5f61 7070 6c79 5f74 7261   self._apply_tra
-0000f770: 6e73 666f 726d 2873 7061 6365 2e6d 6178  nsform(space.max
-0000f780: 696d 756d 290d 0a20 2020 2020 2020 2072  imum)..        r
-0000f790: 6574 7572 6e20 696e 7075 745f 7370 6563  eturn input_spec
-0000f7a0: 0d0a 0d0a 2020 2020 6465 6620 5f5f 7265  ....    def __re
-0000f7b0: 7072 5f5f 2873 656c 6629 202d 3e20 7374  pr__(self) -> st
-0000f7c0: 723a 0d0a 2020 2020 2020 2020 6966 2073  r:..        if s
-0000f7d0: 656c 662e 696e 6974 6961 6c69 7a65 6420  elf.initialized 
-0000f7e0: 616e 6420 2873 656c 662e 6c6f 632e 6e75  and (self.loc.nu
-0000f7f0: 6d65 6c28 2920 3d3d 2031 2061 6e64 2073  mel() == 1 and s
-0000f800: 656c 662e 7363 616c 652e 6e75 6d65 6c28  elf.scale.numel(
-0000f810: 2920 3d3d 2031 293a 0d0a 2020 2020 2020  ) == 1):..      
-0000f820: 2020 2020 2020 7265 7475 726e 2028 0d0a        return (..
-0000f830: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000f840: 6622 7b73 656c 662e 5f5f 636c 6173 735f  f"{self.__class_
-0000f850: 5f2e 5f5f 6e61 6d65 5f5f 7d28 220d 0a20  _.__name__}(".. 
-0000f860: 2020 2020 2020 2020 2020 2020 2020 2066                 f
-0000f870: 226c 6f63 3d7b 666c 6f61 7428 7365 6c66  "loc={float(self
-0000f880: 2e6c 6f63 293a 342e 3466 7d2c 2073 6361  .loc):4.4f}, sca
-0000f890: 6c65 220d 0a20 2020 2020 2020 2020 2020  le"..           
-0000f8a0: 2020 2020 2066 223d 7b66 6c6f 6174 2873       f"={float(s
-0000f8b0: 656c 662e 7363 616c 6529 3a34 2e34 667d  elf.scale):4.4f}
-0000f8c0: 2c20 6b65 7973 3d7b 7365 6c66 2e69 6e5f  , keys={self.in_
-0000f8d0: 6b65 7973 7d29 220d 0a20 2020 2020 2020  keys})"..       
-0000f8e0: 2020 2020 2029 0d0a 2020 2020 2020 2020       )..        
-0000f8f0: 656c 7365 3a0d 0a20 2020 2020 2020 2020  else:..         
-0000f900: 2020 2072 6574 7572 6e20 7375 7065 7228     return super(
-0000f910: 292e 5f5f 7265 7072 5f5f 2829 0d0a 0d0a  ).__repr__()....
-0000f920: 0d0a 636c 6173 7320 4361 7446 7261 6d65  ..class CatFrame
-0000f930: 7328 4f62 7365 7276 6174 696f 6e54 7261  s(ObservationTra
-0000f940: 6e73 666f 726d 293a 0d0a 2020 2020 2222  nsform):..    ""
-0000f950: 2243 6f6e 6361 7465 6e61 7465 7320 7375  "Concatenates su
-0000f960: 6363 6573 7369 7665 206f 6273 6572 7661  ccessive observa
-0000f970: 7469 6f6e 2066 7261 6d65 7320 696e 746f  tion frames into
-0000f980: 2061 2073 696e 676c 6520 7465 6e73 6f72   a single tensor
-0000f990: 2e0d 0a0d 0a20 2020 2054 6869 7320 6361  .....    This ca
-0000f9a0: 6e2c 2066 6f72 2069 6e73 7461 6e63 652c  n, for instance,
-0000f9b0: 2061 6363 6f75 6e74 2066 6f72 206d 6f76   account for mov
-0000f9c0: 656d 656e 742f 7665 6c6f 6369 7479 206f  ement/velocity o
-0000f9d0: 6620 7468 6520 6f62 7365 7276 6564 0d0a  f the observed..
-0000f9e0: 2020 2020 6665 6174 7572 652e 2050 726f      feature. Pro
-0000f9f0: 706f 7365 6420 696e 2022 506c 6179 696e  posed in "Playin
-0000fa00: 6720 4174 6172 6920 7769 7468 2044 6565  g Atari with Dee
-0000fa10: 7020 5265 696e 666f 7263 656d 656e 7420  p Reinforcement 
-0000fa20: 4c65 6172 6e69 6e67 2220 280d 0a20 2020  Learning" (..   
-0000fa30: 2068 7474 7073 3a2f 2f61 7278 6976 2e6f   https://arxiv.o
-0000fa40: 7267 2f70 6466 2f31 3331 322e 3536 3032  rg/pdf/1312.5602
-0000fa50: 2e70 6466 292e 0d0a 0d0a 2020 2020 4361  .pdf).....    Ca
-0000fa60: 7446 7261 6d65 7320 6973 2061 2073 7461  tFrames is a sta
-0000fa70: 7465 6675 6c20 636c 6173 7320 616e 6420  teful class and 
-0000fa80: 6974 2063 616e 2062 6520 7265 7365 7420  it can be reset 
-0000fa90: 746f 2069 7473 206e 6174 6976 6520 7374  to its native st
-0000faa0: 6174 6520 6279 0d0a 2020 2020 6361 6c6c  ate by..    call
-0000fab0: 696e 6720 7468 6520 6072 6573 6574 2829  ing the `reset()
-0000fac0: 6020 6d65 7468 6f64 2e0d 0a0d 0a20 2020  ` method.....   
-0000fad0: 2041 7267 733a 0d0a 2020 2020 2020 2020   Args:..        
-0000fae0: 4e20 2869 6e74 293a 206e 756d 6265 7220  N (int): number 
-0000faf0: 6f66 206f 6273 6572 7661 7469 6f6e 2074  of observation t
-0000fb00: 6f20 636f 6e63 6174 656e 6174 652e 0d0a  o concatenate...
-0000fb10: 2020 2020 2020 2020 6469 6d20 2869 6e74          dim (int
-0000fb20: 293a 2064 696d 656e 7369 6f6e 2061 6c6f  ): dimension alo
-0000fb30: 6e67 2077 6869 6368 2063 6f6e 6361 7465  ng which concate
-0000fb40: 6e61 7465 2074 6865 0d0a 2020 2020 2020  nate the..      
-0000fb50: 2020 2020 2020 6f62 7365 7276 6174 696f        observatio
-0000fb60: 6e73 2e20 5368 6f75 6c64 2062 6520 6e65  ns. Should be ne
-0000fb70: 6761 7469 7665 2c20 746f 2065 6e73 7572  gative, to ensur
-0000fb80: 6520 7468 6174 2069 7420 6973 2063 6f6d  e that it is com
-0000fb90: 7061 7469 626c 650d 0a20 2020 2020 2020  patible..       
-0000fba0: 2020 2020 2077 6974 6820 656e 7669 726f       with enviro
-0000fbb0: 6e6d 656e 7473 206f 6620 6469 6666 6572  nments of differ
-0000fbc0: 656e 7420 6261 7463 685f 7369 7a65 2e0d  ent batch_size..
-0000fbd0: 0a20 2020 2020 2020 2069 6e5f 6b65 7973  .        in_keys
-0000fbe0: 2028 6c69 7374 206f 6620 696e 742c 206f   (list of int, o
-0000fbf0: 7074 696f 6e61 6c29 3a20 6b65 7973 2070  ptional): keys p
-0000fc00: 6f69 6e74 696e 6720 746f 2074 6865 2066  ointing to the f
-0000fc10: 7261 6d65 7320 7468 6174 2068 6176 650d  rames that have.
-0000fc20: 0a20 2020 2020 2020 2020 2020 2074 6f20  .            to 
-0000fc30: 6265 2063 6f6e 6361 7465 6e61 7465 642e  be concatenated.
-0000fc40: 2044 6566 6175 6c74 7320 746f 205b 2270   Defaults to ["p
-0000fc50: 6978 656c 7322 5d2e 0d0a 2020 2020 2020  ixels"]...      
-0000fc60: 2020 6f75 745f 6b65 7973 2028 6c69 7374    out_keys (list
-0000fc70: 206f 6620 696e 742c 206f 7074 696f 6e61   of int, optiona
-0000fc80: 6c29 3a20 6b65 7973 2070 6f69 6e74 696e  l): keys pointin
-0000fc90: 6720 746f 2077 6865 7265 2074 6865 206f  g to where the o
-0000fca0: 7574 7075 740d 0a20 2020 2020 2020 2020  utput..         
-0000fcb0: 2020 2068 6173 2074 6f20 6265 2077 7269     has to be wri
-0000fcc0: 7474 656e 2e20 4465 6661 756c 7473 2074  tten. Defaults t
-0000fcd0: 6f20 7468 6520 7661 6c75 6520 6f66 2060  o the value of `
-0000fce0: 696e 5f6b 6579 7360 2e0d 0a0d 0a20 2020  in_keys`.....   
-0000fcf0: 2022 2222 0d0a 0d0a 2020 2020 696e 706c   """....    inpl
-0000fd00: 6163 6520 3d20 4661 6c73 650d 0a20 2020  ace = False..   
-0000fd10: 205f 4341 545f 4449 4d5f 4552 5220 3d20   _CAT_DIM_ERR = 
-0000fd20: 280d 0a20 2020 2020 2020 2022 6469 6d20  (..        "dim 
-0000fd30: 6d75 7374 2062 6520 3e20 3020 746f 2061  must be > 0 to a
-0000fd40: 6363 6f6d 6f64 6174 6520 666f 7220 7465  ccomodate for te
-0000fd50: 6e73 6f72 6469 6374 206f 6620 220d 0a20  nsordict of ".. 
-0000fd60: 2020 2020 2020 2022 6469 6666 6572 656e         "differen
-0000fd70: 7420 6261 7463 682d 7369 7a65 7320 2873  t batch-sizes (s
-0000fd80: 696e 6365 206e 6567 6174 6976 6520 6469  ince negative di
-0000fd90: 6d73 2061 7265 2062 6174 6368 2069 6e76  ms are batch inv
-0000fda0: 6172 6961 6e74 292e 220d 0a20 2020 2029  ariant)."..    )
-0000fdb0: 0d0a 0d0a 2020 2020 6465 6620 5f5f 696e  ....    def __in
-0000fdc0: 6974 5f5f 280d 0a20 2020 2020 2020 2073  it__(..        s
-0000fdd0: 656c 662c 0d0a 2020 2020 2020 2020 4e3a  elf,..        N:
-0000fde0: 2069 6e74 2c0d 0a20 2020 2020 2020 2064   int,..        d
-0000fdf0: 696d 3a20 696e 742c 0d0a 2020 2020 2020  im: int,..      
-0000fe00: 2020 696e 5f6b 6579 733a 204f 7074 696f    in_keys: Optio
-0000fe10: 6e61 6c5b 5365 7175 656e 6365 5b73 7472  nal[Sequence[str
-0000fe20: 5d5d 203d 204e 6f6e 652c 0d0a 2020 2020  ]] = None,..    
-0000fe30: 2020 2020 6f75 745f 6b65 7973 3a20 4f70      out_keys: Op
-0000fe40: 7469 6f6e 616c 5b53 6571 7565 6e63 655b  tional[Sequence[
-0000fe50: 7374 725d 5d20 3d20 4e6f 6e65 2c0d 0a20  str]] = None,.. 
-0000fe60: 2020 2029 3a0d 0a20 2020 2020 2020 2069     ):..        i
-0000fe70: 6620 696e 5f6b 6579 7320 6973 204e 6f6e  f in_keys is Non
-0000fe80: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
-0000fe90: 696e 5f6b 6579 7320 3d20 494d 4147 455f  in_keys = IMAGE_
-0000fea0: 4b45 5953 0d0a 2020 2020 2020 2020 7375  KEYS..        su
-0000feb0: 7065 7228 292e 5f5f 696e 6974 5f5f 2869  per().__init__(i
-0000fec0: 6e5f 6b65 7973 3d69 6e5f 6b65 7973 2c20  n_keys=in_keys, 
-0000fed0: 6f75 745f 6b65 7973 3d6f 7574 5f6b 6579  out_keys=out_key
-0000fee0: 7329 0d0a 2020 2020 2020 2020 7365 6c66  s)..        self
-0000fef0: 2e4e 203d 204e 0d0a 2020 2020 2020 2020  .N = N..        
-0000ff00: 6966 2064 696d 203e 2030 3a0d 0a20 2020  if dim > 0:..   
-0000ff10: 2020 2020 2020 2020 2072 6169 7365 2056           raise V
-0000ff20: 616c 7565 4572 726f 7228 7365 6c66 2e5f  alueError(self._
-0000ff30: 4341 545f 4449 4d5f 4552 5229 0d0a 2020  CAT_DIM_ERR)..  
-0000ff40: 2020 2020 2020 7365 6c66 2e64 696d 203d        self.dim =
-0000ff50: 2064 696d 0d0a 2020 2020 2020 2020 666f   dim..        fo
-0000ff60: 7220 696e 5f6b 6579 2069 6e20 7365 6c66  r in_key in self
-0000ff70: 2e69 6e5f 6b65 7973 3a0d 0a20 2020 2020  .in_keys:..     
-0000ff80: 2020 2020 2020 2062 7566 6665 725f 6e61         buffer_na
-0000ff90: 6d65 203d 2066 225f 6361 745f 6275 6666  me = f"_cat_buff
-0000ffa0: 6572 735f 7b69 6e5f 6b65 797d 220d 0a20  ers_{in_key}".. 
-0000ffb0: 2020 2020 2020 2020 2020 2073 6574 6174             setat
-0000ffc0: 7472 280d 0a20 2020 2020 2020 2020 2020  tr(..           
-0000ffd0: 2020 2020 2073 656c 662c 0d0a 2020 2020       self,..    
-0000ffe0: 2020 2020 2020 2020 2020 2020 6275 6666              buff
-0000fff0: 6572 5f6e 616d 652c 0d0a 2020 2020 2020  er_name,..      
-00010000: 2020 2020 2020 2020 2020 746f 7263 682e            torch.
-00010010: 6e6e 2e70 6172 616d 6574 6572 2e55 6e69  nn.parameter.Uni
-00010020: 6e69 7469 616c 697a 6564 4275 6666 6572  nitializedBuffer
-00010030: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
-00010040: 2020 2020 2020 2064 6576 6963 653d 746f         device=to
-00010050: 7263 682e 6465 7669 6365 2822 6370 7522  rch.device("cpu"
-00010060: 292c 2064 7479 7065 3d74 6f72 6368 2e67  ), dtype=torch.g
-00010070: 6574 5f64 6566 6175 6c74 5f64 7479 7065  et_default_dtype
-00010080: 2829 0d0a 2020 2020 2020 2020 2020 2020  ()..            
-00010090: 2020 2020 292c 0d0a 2020 2020 2020 2020      ),..        
-000100a0: 2020 2020 290d 0a20 2020 2020 2020 2023      )..        #
-000100b0: 206b 6565 7073 2074 7261 636b 206f 6620   keeps track of 
-000100c0: 6361 6c6c 7320 746f 205f 7265 7365 7420  calls to _reset 
-000100d0: 7369 6e63 6520 6974 2773 206f 6e6c 7920  since it's only 
-000100e0: 5f63 616c 6c20 7468 6174 2077 696c 6c20  _call that will 
-000100f0: 706f 7075 6c61 7465 2074 6865 2062 7566  populate the buf
-00010100: 6665 720d 0a20 2020 2020 2020 2073 656c  fer..        sel
-00010110: 662e 5f6a 7573 745f 7265 7365 7420 3d20  f._just_reset = 
-00010120: 4661 6c73 650d 0a0d 0a20 2020 2064 6566  False....    def
-00010130: 2072 6573 6574 2873 656c 662c 2074 656e   reset(self, ten
-00010140: 736f 7264 6963 743a 2054 656e 736f 7244  sordict: TensorD
-00010150: 6963 7442 6173 6529 202d 3e20 5465 6e73  ictBase) -> Tens
-00010160: 6f72 4469 6374 4261 7365 3a0d 0a20 2020  orDictBase:..   
-00010170: 2020 2020 2022 2222 5265 7365 7473 205f       """Resets _
-00010180: 6275 6666 6572 732e 2222 220d 0a20 2020  buffers."""..   
-00010190: 2020 2020 205f 7265 7365 7420 3d20 7465       _reset = te
-000101a0: 6e73 6f72 6469 6374 2e67 6574 280d 0a20  nsordict.get(.. 
-000101b0: 2020 2020 2020 2020 2020 2022 5f72 6573             "_res
-000101c0: 6574 222c 0d0a 2020 2020 2020 2020 2020  et",..          
-000101d0: 2020 4e6f 6e65 2c0d 0a20 2020 2020 2020    None,..       
-000101e0: 2029 0d0a 2020 2020 2020 2020 6966 205f   )..        if _
-000101f0: 7265 7365 7420 6973 204e 6f6e 653a 0d0a  reset is None:..
-00010200: 2020 2020 2020 2020 2020 2020 5f72 6573              _res
-00010210: 6574 203d 2074 6f72 6368 2e6f 6e65 7328  et = torch.ones(
-00010220: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00010230: 2020 7465 6e73 6f72 6469 6374 2e62 6174    tensordict.bat
-00010240: 6368 5f73 697a 652c 0d0a 2020 2020 2020  ch_size,..      
-00010250: 2020 2020 2020 2020 2020 6474 7970 653d            dtype=
-00010260: 746f 7263 682e 626f 6f6c 2c0d 0a20 2020  torch.bool,..   
-00010270: 2020 2020 2020 2020 2020 2020 2064 6576               dev
-00010280: 6963 653d 7465 6e73 6f72 6469 6374 2e64  ice=tensordict.d
-00010290: 6576 6963 650d 0a20 2020 2020 2020 2020  evice..         
-000102a0: 2020 2020 2020 2069 6620 7465 6e73 6f72         if tensor
-000102b0: 6469 6374 2e64 6576 6963 6520 6973 206e  dict.device is n
-000102c0: 6f74 204e 6f6e 650d 0a20 2020 2020 2020  ot None..       
-000102d0: 2020 2020 2020 2020 2065 6c73 6520 746f           else to
-000102e0: 7263 682e 6465 7669 6365 2822 6370 7522  rch.device("cpu"
-000102f0: 292c 0d0a 2020 2020 2020 2020 2020 2020  ),..            
-00010300: 290d 0a20 2020 2020 2020 2066 6f72 2069  )..        for i
-00010310: 6e5f 6b65 7920 696e 2073 656c 662e 696e  n_key in self.in
-00010320: 5f6b 6579 733a 0d0a 2020 2020 2020 2020  _keys:..        
-00010330: 2020 2020 6275 6666 6572 5f6e 616d 6520      buffer_name 
-00010340: 3d20 6622 5f63 6174 5f62 7566 6665 7273  = f"_cat_buffers
-00010350: 5f7b 696e 5f6b 6579 7d22 0d0a 2020 2020  _{in_key}"..    
-00010360: 2020 2020 2020 2020 6275 6666 6572 203d          buffer =
-00010370: 2067 6574 6174 7472 2873 656c 662c 2062   getattr(self, b
-00010380: 7566 6665 725f 6e61 6d65 290d 0a20 2020  uffer_name)..   
-00010390: 2020 2020 2020 2020 2069 6620 6973 696e           if isin
-000103a0: 7374 616e 6365 2862 7566 6665 722c 2074  stance(buffer, t
-000103b0: 6f72 6368 2e6e 6e2e 7061 7261 6d65 7465  orch.nn.paramete
-000103c0: 722e 556e 696e 6974 6961 6c69 7a65 6442  r.UninitializedB
-000103d0: 7566 6665 7229 3a0d 0a20 2020 2020 2020  uffer):..       
-000103e0: 2020 2020 2020 2020 2063 6f6e 7469 6e75           continu
-000103f0: 650d 0a20 2020 2020 2020 2020 2020 2062  e..            b
-00010400: 7566 6665 725b 5f72 6573 6574 5d20 3d20  uffer[_reset] = 
-00010410: 300d 0a0d 0a20 2020 2020 2020 2073 656c  0....        sel
-00010420: 662e 5f6a 7573 745f 7265 7365 7420 3d20  f._just_reset = 
-00010430: 5472 7565 0d0a 2020 2020 2020 2020 7265  True..        re
-00010440: 7475 726e 2074 656e 736f 7264 6963 740d  turn tensordict.
-00010450: 0a0d 0a20 2020 2064 6566 205f 6d61 6b65  ...    def _make
-00010460: 5f6d 6973 7369 6e67 5f62 7566 6665 7228  _missing_buffer(
-00010470: 7365 6c66 2c20 6461 7461 2c20 6275 6666  self, data, buff
-00010480: 6572 5f6e 616d 6529 3a0d 0a20 2020 2020  er_name):..     
-00010490: 2020 2073 6861 7065 203d 206c 6973 7428     shape = list(
-000104a0: 6461 7461 2e73 6861 7065 290d 0a20 2020  data.shape)..   
-000104b0: 2020 2020 2064 203d 2073 6861 7065 5b73       d = shape[s
-000104c0: 656c 662e 6469 6d5d 0d0a 2020 2020 2020  elf.dim]..      
-000104d0: 2020 7368 6170 655b 7365 6c66 2e64 696d    shape[self.dim
-000104e0: 5d20 3d20 6420 2a20 7365 6c66 2e4e 0d0a  ] = d * self.N..
-000104f0: 2020 2020 2020 2020 7368 6170 6520 3d20          shape = 
-00010500: 746f 7263 682e 5369 7a65 2873 6861 7065  torch.Size(shape
-00010510: 290d 0a20 2020 2020 2020 2067 6574 6174  )..        getat
-00010520: 7472 2873 656c 662c 2062 7566 6665 725f  tr(self, buffer_
-00010530: 6e61 6d65 292e 6d61 7465 7269 616c 697a  name).materializ
-00010540: 6528 7368 6170 6529 0d0a 2020 2020 2020  e(shape)..      
-00010550: 2020 6275 6666 6572 203d 2067 6574 6174    buffer = getat
-00010560: 7472 2873 656c 662c 2062 7566 6665 725f  tr(self, buffer_
-00010570: 6e61 6d65 292e 746f 2864 6174 612e 6474  name).to(data.dt
-00010580: 7970 6529 2e74 6f28 6461 7461 2e64 6576  ype).to(data.dev
-00010590: 6963 6529 2e7a 6572 6f5f 2829 0d0a 2020  ice).zero_()..  
-000105a0: 2020 2020 2020 7365 7461 7474 7228 7365        setattr(se
-000105b0: 6c66 2c20 6275 6666 6572 5f6e 616d 652c  lf, buffer_name,
-000105c0: 2062 7566 6665 7229 0d0a 2020 2020 2020   buffer)..      
-000105d0: 2020 7265 7475 726e 2062 7566 6665 720d    return buffer.
-000105e0: 0a0d 0a20 2020 2064 6566 205f 6361 6c6c  ...    def _call
-000105f0: 2873 656c 662c 2074 656e 736f 7264 6963  (self, tensordic
-00010600: 743a 2054 656e 736f 7244 6963 7442 6173  t: TensorDictBas
-00010610: 6529 202d 3e20 5465 6e73 6f72 4469 6374  e) -> TensorDict
-00010620: 4261 7365 3a0d 0a20 2020 2020 2020 2022  Base:..        "
-00010630: 2222 5570 6461 7465 2074 6865 2065 7069  ""Update the epi
-00010640: 736f 6465 2074 656e 736f 7264 6963 7420  sode tensordict 
-00010650: 7769 7468 206d 6178 2070 6f6f 6c65 6420  with max pooled 
-00010660: 6b65 7973 2e22 2222 0d0a 2020 2020 2020  keys."""..      
-00010670: 2020 5f72 6573 6574 203d 2074 656e 736f    _reset = tenso
-00010680: 7264 6963 742e 6765 7428 225f 7265 7365  rdict.get("_rese
-00010690: 7422 2c20 4e6f 6e65 290d 0a0d 0a20 2020  t", None)....   
-000106a0: 2020 2020 2066 6f72 2069 6e5f 6b65 792c       for in_key,
-000106b0: 206f 7574 5f6b 6579 2069 6e20 7a69 7028   out_key in zip(
-000106c0: 7365 6c66 2e69 6e5f 6b65 7973 2c20 7365  self.in_keys, se
-000106d0: 6c66 2e6f 7574 5f6b 6579 7329 3a0d 0a20  lf.out_keys):.. 
-000106e0: 2020 2020 2020 2020 2020 2023 204c 617a             # Laz
-000106f0: 7920 696e 6974 206f 6620 6275 6666 6572  y init of buffer
-00010700: 730d 0a20 2020 2020 2020 2020 2020 2062  s..            b
-00010710: 7566 6665 725f 6e61 6d65 203d 2066 225f  uffer_name = f"_
-00010720: 6361 745f 6275 6666 6572 735f 7b69 6e5f  cat_buffers_{in_
-00010730: 6b65 797d 220d 0a20 2020 2020 2020 2020  key}"..         
-00010740: 2020 2064 6174 6120 3d20 7465 6e73 6f72     data = tensor
-00010750: 6469 6374 5b69 6e5f 6b65 795d 0d0a 2020  dict[in_key]..  
-00010760: 2020 2020 2020 2020 2020 6420 3d20 6461            d = da
-00010770: 7461 2e73 697a 6528 7365 6c66 2e64 696d  ta.size(self.dim
-00010780: 290d 0a20 2020 2020 2020 2020 2020 2062  )..            b
-00010790: 7566 6665 7220 3d20 6765 7461 7474 7228  uffer = getattr(
-000107a0: 7365 6c66 2c20 6275 6666 6572 5f6e 616d  self, buffer_nam
-000107b0: 6529 0d0a 2020 2020 2020 2020 2020 2020  e)..            
-000107c0: 6966 2069 7369 6e73 7461 6e63 6528 6275  if isinstance(bu
-000107d0: 6666 6572 2c20 746f 7263 682e 6e6e 2e70  ffer, torch.nn.p
-000107e0: 6172 616d 6574 6572 2e55 6e69 6e69 7469  arameter.Uniniti
-000107f0: 616c 697a 6564 4275 6666 6572 293a 0d0a  alizedBuffer):..
-00010800: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010810: 6275 6666 6572 203d 2073 656c 662e 5f6d  buffer = self._m
-00010820: 616b 655f 6d69 7373 696e 675f 6275 6666  ake_missing_buff
-00010830: 6572 2864 6174 612c 2062 7566 6665 725f  er(data, buffer_
-00010840: 6e61 6d65 290d 0a20 2020 2020 2020 2020  name)..         
-00010850: 2020 2023 2073 6869 6674 206f 6273 2031     # shift obs 1
-00010860: 2070 6f73 6974 696f 6e20 746f 2074 6865   position to the
-00010870: 2072 6967 6874 0d0a 2020 2020 2020 2020   right..        
-00010880: 2020 2020 6966 2073 656c 662e 5f6a 7573      if self._jus
-00010890: 745f 7265 7365 7420 6f72 2028 5f72 6573  t_reset or (_res
-000108a0: 6574 2069 7320 6e6f 7420 4e6f 6e65 2061  et is not None a
-000108b0: 6e64 205f 7265 7365 742e 616e 7928 2929  nd _reset.any())
-000108c0: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
-000108d0: 2020 2064 6174 615f 696e 203d 2062 7566     data_in = buf
-000108e0: 6665 725b 5f72 6573 6574 5d0d 0a20 2020  fer[_reset]..   
-000108f0: 2020 2020 2020 2020 2020 2020 2073 6861               sha
-00010900: 7065 203d 205b 3120 666f 7220 5f20 696e  pe = [1 for _ in
-00010910: 2064 6174 615f 696e 2e73 6861 7065 5d0d   data_in.shape].
-00010920: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00010930: 2073 6861 7065 5b73 656c 662e 6469 6d5d   shape[self.dim]
-00010940: 203d 2073 656c 662e 4e0d 0a20 2020 2020   = self.N..     
-00010950: 2020 2020 2020 2020 2020 2062 7566 6665             buffe
-00010960: 725b 5f72 6573 6574 5d20 3d20 6275 6666  r[_reset] = buff
-00010970: 6572 5b5f 7265 7365 745d 2e63 6f70 795f  er[_reset].copy_
-00010980: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
-00010990: 2020 2020 2020 2064 6174 615b 5f72 6573         data[_res
-000109a0: 6574 5d2e 7265 7065 6174 2873 6861 7065  et].repeat(shape
-000109b0: 292e 636c 6f6e 6528 290d 0a20 2020 2020  ).clone()..     
-000109c0: 2020 2020 2020 2020 2020 2029 0d0a 2020             )..  
-000109d0: 2020 2020 2020 2020 2020 6275 6666 6572            buffer
-000109e0: 2e63 6f70 795f 2874 6f72 6368 2e72 6f6c  .copy_(torch.rol
-000109f0: 6c28 6275 6666 6572 2c20 7368 6966 7473  l(buffer, shifts
-00010a00: 3d2d 642c 2064 696d 733d 7365 6c66 2e64  =-d, dims=self.d
-00010a10: 696d 2929 0d0a 2020 2020 2020 2020 2020  im))..          
-00010a20: 2020 2320 6164 6420 6e65 7720 6f62 730d    # add new obs.
-00010a30: 0a20 2020 2020 2020 2020 2020 2069 6478  .            idx
-00010a40: 203d 2073 656c 662e 6469 6d0d 0a20 2020   = self.dim..   
-00010a50: 2020 2020 2020 2020 2069 6620 6964 7820           if idx 
-00010a60: 3c20 303a 0d0a 2020 2020 2020 2020 2020  < 0:..          
-00010a70: 2020 2020 2020 6964 7820 3d20 6275 6666        idx = buff
-00010a80: 6572 2e6e 6469 6d65 6e73 696f 6e28 2920  er.ndimension() 
-00010a90: 2b20 6964 780d 0a20 2020 2020 2020 2020  + idx..         
-00010aa0: 2020 2065 6c73 653a 0d0a 2020 2020 2020     else:..      
-00010ab0: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
-00010ac0: 5661 6c75 6545 7272 6f72 2873 656c 662e  ValueError(self.
-00010ad0: 5f43 4154 5f44 494d 5f45 5252 290d 0a20  _CAT_DIM_ERR).. 
-00010ae0: 2020 2020 2020 2020 2020 2069 6478 203d             idx =
-00010af0: 205b 736c 6963 6528 4e6f 6e65 2c20 4e6f   [slice(None, No
-00010b00: 6e65 2920 666f 7220 5f20 696e 2072 616e  ne) for _ in ran
-00010b10: 6765 2869 6478 295d 202b 205b 736c 6963  ge(idx)] + [slic
-00010b20: 6528 2d64 2c20 4e6f 6e65 295d 0d0a 2020  e(-d, None)]..  
-00010b30: 2020 2020 2020 2020 2020 6275 6666 6572            buffer
-00010b40: 5b69 6478 5d2e 636f 7079 5f28 6461 7461  [idx].copy_(data
-00010b50: 290d 0a20 2020 2020 2020 2020 2020 2023  )..            #
-00010b60: 2061 6464 2074 6f20 7465 6e73 6f72 6469   add to tensordi
-00010b70: 6374 0d0a 2020 2020 2020 2020 2020 2020  ct..            
-00010b80: 7465 6e73 6f72 6469 6374 2e73 6574 286f  tensordict.set(o
-00010b90: 7574 5f6b 6579 2c20 6275 6666 6572 2e63  ut_key, buffer.c
-00010ba0: 6c6f 6e65 2829 290d 0a20 2020 2020 2020  lone())..       
-00010bb0: 2073 656c 662e 5f6a 7573 745f 7265 7365   self._just_rese
-00010bc0: 7420 3d20 4661 6c73 650d 0a20 2020 2020  t = False..     
-00010bd0: 2020 2072 6574 7572 6e20 7465 6e73 6f72     return tensor
-00010be0: 6469 6374 0d0a 0d0a 2020 2020 405f 6170  dict....    @_ap
-00010bf0: 706c 795f 746f 5f63 6f6d 706f 7369 7465  ply_to_composite
-00010c00: 0d0a 2020 2020 6465 6620 7472 616e 7366  ..    def transf
-00010c10: 6f72 6d5f 6f62 7365 7276 6174 696f 6e5f  orm_observation_
-00010c20: 7370 6563 2873 656c 662c 206f 6273 6572  spec(self, obser
-00010c30: 7661 7469 6f6e 5f73 7065 633a 2054 656e  vation_spec: Ten
-00010c40: 736f 7253 7065 6329 202d 3e20 5465 6e73  sorSpec) -> Tens
-00010c50: 6f72 5370 6563 3a0d 0a20 2020 2020 2020  orSpec:..       
-00010c60: 2073 7061 6365 203d 206f 6273 6572 7661   space = observa
-00010c70: 7469 6f6e 5f73 7065 632e 7370 6163 650d  tion_spec.space.
-00010c80: 0a20 2020 2020 2020 2069 6620 6973 696e  .        if isin
-00010c90: 7374 616e 6365 2873 7061 6365 2c20 436f  stance(space, Co
-00010ca0: 6e74 696e 756f 7573 426f 7829 3a0d 0a20  ntinuousBox):.. 
-00010cb0: 2020 2020 2020 2020 2020 2073 7061 6365             space
-00010cc0: 2e6d 696e 696d 756d 203d 2074 6f72 6368  .minimum = torch
-00010cd0: 2e63 6174 285b 7370 6163 652e 6d69 6e69  .cat([space.mini
-00010ce0: 6d75 6d5d 202a 2073 656c 662e 4e2c 2073  mum] * self.N, s
-00010cf0: 656c 662e 6469 6d29 0d0a 2020 2020 2020  elf.dim)..      
-00010d00: 2020 2020 2020 7370 6163 652e 6d61 7869        space.maxi
-00010d10: 6d75 6d20 3d20 746f 7263 682e 6361 7428  mum = torch.cat(
-00010d20: 5b73 7061 6365 2e6d 6178 696d 756d 5d20  [space.maximum] 
-00010d30: 2a20 7365 6c66 2e4e 2c20 7365 6c66 2e64  * self.N, self.d
-00010d40: 696d 290d 0a20 2020 2020 2020 2020 2020  im)..           
-00010d50: 206f 6273 6572 7661 7469 6f6e 5f73 7065   observation_spe
-00010d60: 632e 7368 6170 6520 3d20 7370 6163 652e  c.shape = space.
-00010d70: 6d69 6e69 6d75 6d2e 7368 6170 650d 0a20  minimum.shape.. 
-00010d80: 2020 2020 2020 2065 6c73 653a 0d0a 2020         else:..  
-00010d90: 2020 2020 2020 2020 2020 7368 6170 6520            shape 
-00010da0: 3d20 6c69 7374 286f 6273 6572 7661 7469  = list(observati
-00010db0: 6f6e 5f73 7065 632e 7368 6170 6529 0d0a  on_spec.shape)..
-00010dc0: 2020 2020 2020 2020 2020 2020 7368 6170              shap
-00010dd0: 655b 7365 6c66 2e64 696d 5d20 3d20 7365  e[self.dim] = se
-00010de0: 6c66 2e4e 202a 2073 6861 7065 5b73 656c  lf.N * shape[sel
-00010df0: 662e 6469 6d5d 0d0a 2020 2020 2020 2020  f.dim]..        
-00010e00: 2020 2020 6f62 7365 7276 6174 696f 6e5f      observation_
-00010e10: 7370 6563 2e73 6861 7065 203d 2074 6f72  spec.shape = tor
-00010e20: 6368 2e53 697a 6528 7368 6170 6529 0d0a  ch.Size(shape)..
-00010e30: 2020 2020 2020 2020 7265 7475 726e 206f          return o
-00010e40: 6273 6572 7661 7469 6f6e 5f73 7065 630d  bservation_spec.
-00010e50: 0a0d 0a20 2020 2064 6566 2066 6f72 7761  ...    def forwa
-00010e60: 7264 2873 656c 662c 2074 656e 736f 7264  rd(self, tensord
-00010e70: 6963 743a 2054 656e 736f 7244 6963 7442  ict: TensorDictB
-00010e80: 6173 6529 202d 3e20 5465 6e73 6f72 4469  ase) -> TensorDi
-00010e90: 6374 4261 7365 3a0d 0a20 2020 2020 2020  ctBase:..       
-00010ea0: 2072 6169 7365 204e 6f74 496d 706c 656d   raise NotImplem
-00010eb0: 656e 7465 6445 7272 6f72 280d 0a20 2020  entedError(..   
-00010ec0: 2020 2020 2020 2020 2022 4361 7446 7261           "CatFra
-00010ed0: 6d65 7320 6361 6e6e 6f74 2062 6520 6361  mes cannot be ca
-00010ee0: 6c6c 6564 2069 6e64 6570 656e 6465 6e74  lled independent
-00010ef0: 6c79 2c20 6f6e 6c79 2069 7473 2073 7465  ly, only its ste
-00010f00: 7020 616e 6420 7265 7365 7420 6d65 7468  p and reset meth
-00010f10: 6f64 7320 220d 0a20 2020 2020 2020 2020  ods "..         
-00010f20: 2020 2022 6172 6520 6675 6e63 7469 6f6e     "are function
-00010f30: 616c 2e20 5468 6520 7265 6173 6f6e 2066  al. The reason f
-00010f40: 6f72 2074 6869 7320 6973 2074 6861 7420  or this is that 
-00010f50: 6974 2069 7320 6861 7264 2074 6f20 636f  it is hard to co
-00010f60: 6e73 6964 6572 2075 7369 6e67 2022 0d0a  nsider using "..
-00010f70: 2020 2020 2020 2020 2020 2020 2243 6174              "Cat
-00010f80: 4672 616d 6573 2077 6974 6820 6e6f 6e2d  Frames with non-
-00010f90: 7365 7175 656e 7469 616c 2064 6174 612c  sequential data,
-00010fa0: 2073 7563 6820 6173 2074 686f 7365 2063   such as those c
-00010fb0: 6f6c 6c65 6374 6564 2062 7920 6120 7265  ollected by a re
-00010fc0: 706c 6179 2062 7566 6665 7220 220d 0a20  play buffer ".. 
-00010fd0: 2020 2020 2020 2020 2020 2022 6f72 2061             "or a
-00010fe0: 2064 6174 6173 6574 2e20 4966 2079 6f75   dataset. If you
-00010ff0: 206e 6565 6420 4361 7446 7261 6d65 7320   need CatFrames 
-00011000: 746f 2077 6f72 6b20 6f6e 2061 2062 6174  to work on a bat
-00011010: 6368 206f 6620 7365 7175 656e 7469 616c  ch of sequential
-00011020: 2064 6174 6120 220d 0a20 2020 2020 2020   data "..       
-00011030: 2020 2020 2022 2869 6520 6173 204c 5354       "(ie as LST
-00011040: 4d20 776f 756c 6420 776f 726b 206f 7665  M would work ove
-00011050: 7220 6120 7768 6f6c 6520 7365 7175 656e  r a whole sequen
-00011060: 6365 206f 6620 6461 7461 292c 2066 696c  ce of data), fil
-00011070: 6520 616e 2069 7373 7565 206f 6e20 220d  e an issue on ".
-00011080: 0a20 2020 2020 2020 2020 2020 2022 546f  .            "To
-00011090: 7263 6852 4c20 7265 7175 6573 7469 6e67  rchRL requesting
-000110a0: 2074 6861 7420 6665 6174 7572 652e 220d   that feature.".
-000110b0: 0a20 2020 2020 2020 2029 0d0a 0d0a 2020  .        )....  
-000110c0: 2020 6465 6620 5f5f 7265 7072 5f5f 2873    def __repr__(s
-000110d0: 656c 6629 202d 3e20 7374 723a 0d0a 2020  elf) -> str:..  
-000110e0: 2020 2020 2020 7265 7475 726e 2028 0d0a        return (..
-000110f0: 2020 2020 2020 2020 2020 2020 6622 7b73              f"{s
-00011100: 656c 662e 5f5f 636c 6173 735f 5f2e 5f5f  elf.__class__.__
-00011110: 6e61 6d65 5f5f 7d28 4e3d 7b73 656c 662e  name__}(N={self.
-00011120: 4e7d 2c20 6469 6d22 0d0a 2020 2020 2020  N}, dim"..      
-00011130: 2020 2020 2020 6622 3d7b 7365 6c66 2e64        f"={self.d
-00011140: 696d 7d2c 206b 6579 733d 7b73 656c 662e  im}, keys={self.
-00011150: 696e 5f6b 6579 737d 2922 0d0a 2020 2020  in_keys})"..    
-00011160: 2020 2020 290d 0a0d 0a0d 0a63 6c61 7373      )......class
-00011170: 2052 6577 6172 6453 6361 6c69 6e67 2854   RewardScaling(T
-00011180: 7261 6e73 666f 726d 293a 0d0a 2020 2020  ransform):..    
-00011190: 2222 2241 6666 696e 6520 7472 616e 7366  """Affine transf
-000111a0: 6f72 6d20 6f66 2074 6865 2072 6577 6172  orm of the rewar
-000111b0: 642e 0d0a 0d0a 2020 2020 2054 6865 2072  d.....     The r
-000111c0: 6577 6172 6420 6973 2074 7261 6e73 666f  eward is transfo
-000111d0: 726d 6564 2061 6363 6f72 6469 6e67 2074  rmed according t
-000111e0: 6f3a 0d0a 0d0a 2020 2020 2e2e 206d 6174  o:....    .. mat
-000111f0: 683a 3a0d 0a20 2020 2020 2020 2072 6577  h::..        rew
-00011200: 6172 6420 3d20 7265 7761 7264 202a 2073  ard = reward * s
-00011210: 6361 6c65 202b 206c 6f63 0d0a 0d0a 2020  cale + loc....  
-00011220: 2020 4172 6773 3a0d 0a20 2020 2020 2020    Args:..       
-00011230: 206c 6f63 2028 6e75 6d62 6572 206f 7220   loc (number or 
-00011240: 746f 7263 682e 5465 6e73 6f72 293a 206c  torch.Tensor): l
-00011250: 6f63 6174 696f 6e20 6f66 2074 6865 2061  ocation of the a
-00011260: 6666 696e 6520 7472 616e 7366 6f72 6d0d  ffine transform.
-00011270: 0a20 2020 2020 2020 2073 6361 6c65 2028  .        scale (
-00011280: 6e75 6d62 6572 206f 7220 746f 7263 682e  number or torch.
-00011290: 5465 6e73 6f72 293a 2073 6361 6c65 206f  Tensor): scale o
-000112a0: 6620 7468 6520 6166 6669 6e65 2074 7261  f the affine tra
-000112b0: 6e73 666f 726d 0d0a 2020 2020 2020 2020  nsform..        
-000112c0: 7374 616e 6461 7264 5f6e 6f72 6d61 6c20  standard_normal 
-000112d0: 2862 6f6f 6c2c 206f 7074 696f 6e61 6c29  (bool, optional)
-000112e0: 3a20 6966 2054 7275 652c 2074 6865 2074  : if True, the t
-000112f0: 7261 6e73 666f 726d 2077 696c 6c20 6265  ransform will be
-00011300: 0d0a 0d0a 2020 2020 2020 2020 2020 2020  ....            
-00011310: 2e2e 206d 6174 683a 3a0d 0a20 2020 2020  .. math::..     
-00011320: 2020 2020 2020 2020 2020 2072 6577 6172             rewar
-00011330: 6420 3d20 2872 6577 6172 642d 6c6f 6329  d = (reward-loc)
-00011340: 2f73 6361 6c65 0d0a 0d0a 2020 2020 2020  /scale....      
-00011350: 2020 2020 2020 6173 2069 7420 6973 2064        as it is d
-00011360: 6f6e 6520 666f 7220 7374 616e 6461 7264  one for standard
-00011370: 697a 6174 696f 6e2e 2044 6566 6175 6c74  ization. Default
-00011380: 2069 7320 6046 616c 7365 602e 0d0a 2020   is `False`...  
-00011390: 2020 2222 220d 0a0d 0a20 2020 2064 6566    """....    def
-000113a0: 205f 5f69 6e69 745f 5f28 0d0a 2020 2020   __init__(..    
-000113b0: 2020 2020 7365 6c66 2c0d 0a20 2020 2020      self,..     
-000113c0: 2020 206c 6f63 3a20 556e 696f 6e5b 666c     loc: Union[fl
-000113d0: 6f61 742c 2074 6f72 6368 2e54 656e 736f  oat, torch.Tenso
-000113e0: 725d 2c0d 0a20 2020 2020 2020 2073 6361  r],..        sca
-000113f0: 6c65 3a20 556e 696f 6e5b 666c 6f61 742c  le: Union[float,
-00011400: 2074 6f72 6368 2e54 656e 736f 725d 2c0d   torch.Tensor],.
-00011410: 0a20 2020 2020 2020 2069 6e5f 6b65 7973  .        in_keys
-00011420: 3a20 4f70 7469 6f6e 616c 5b53 6571 7565  : Optional[Seque
-00011430: 6e63 655b 7374 725d 5d20 3d20 4e6f 6e65  nce[str]] = None
-00011440: 2c0d 0a20 2020 2020 2020 2073 7461 6e64  ,..        stand
-00011450: 6172 645f 6e6f 726d 616c 3a20 626f 6f6c  ard_normal: bool
-00011460: 203d 2046 616c 7365 2c0d 0a20 2020 2029   = False,..    )
-00011470: 3a0d 0a20 2020 2020 2020 2069 6620 696e  :..        if in
-00011480: 5f6b 6579 7320 6973 204e 6f6e 653a 0d0a  _keys is None:..
-00011490: 2020 2020 2020 2020 2020 2020 696e 5f6b              in_k
-000114a0: 6579 7320 3d20 5b22 7265 7761 7264 225d  eys = ["reward"]
-000114b0: 0d0a 2020 2020 2020 2020 7375 7065 7228  ..        super(
-000114c0: 292e 5f5f 696e 6974 5f5f 2869 6e5f 6b65  ).__init__(in_ke
-000114d0: 7973 3d69 6e5f 6b65 7973 290d 0a20 2020  ys=in_keys)..   
-000114e0: 2020 2020 2069 6620 6e6f 7420 6973 696e       if not isin
-000114f0: 7374 616e 6365 2873 7461 6e64 6172 645f  stance(standard_
-00011500: 6e6f 726d 616c 2c20 746f 7263 682e 5465  normal, torch.Te
-00011510: 6e73 6f72 293a 0d0a 2020 2020 2020 2020  nsor):..        
-00011520: 2020 2020 7374 616e 6461 7264 5f6e 6f72      standard_nor
-00011530: 6d61 6c20 3d20 746f 7263 682e 7465 6e73  mal = torch.tens
-00011540: 6f72 2873 7461 6e64 6172 645f 6e6f 726d  or(standard_norm
-00011550: 616c 290d 0a20 2020 2020 2020 2073 656c  al)..        sel
-00011560: 662e 7265 6769 7374 6572 5f62 7566 6665  f.register_buffe
-00011570: 7228 2273 7461 6e64 6172 645f 6e6f 726d  r("standard_norm
-00011580: 616c 222c 2073 7461 6e64 6172 645f 6e6f  al", standard_no
-00011590: 726d 616c 290d 0a0d 0a20 2020 2020 2020  rmal)....       
-000115a0: 2069 6620 6e6f 7420 6973 696e 7374 616e   if not isinstan
-000115b0: 6365 286c 6f63 2c20 746f 7263 682e 5465  ce(loc, torch.Te
-000115c0: 6e73 6f72 293a 0d0a 2020 2020 2020 2020  nsor):..        
-000115d0: 2020 2020 6c6f 6320 3d20 746f 7263 682e      loc = torch.
-000115e0: 7465 6e73 6f72 286c 6f63 290d 0a20 2020  tensor(loc)..   
-000115f0: 2020 2020 2069 6620 6e6f 7420 6973 696e       if not isin
-00011600: 7374 616e 6365 2873 6361 6c65 2c20 746f  stance(scale, to
-00011610: 7263 682e 5465 6e73 6f72 293a 0d0a 2020  rch.Tensor):..  
-00011620: 2020 2020 2020 2020 2020 7363 616c 6520            scale 
-00011630: 3d20 746f 7263 682e 7465 6e73 6f72 2873  = torch.tensor(s
-00011640: 6361 6c65 290d 0a0d 0a20 2020 2020 2020  cale)....       
-00011650: 2073 656c 662e 7265 6769 7374 6572 5f62   self.register_b
-00011660: 7566 6665 7228 226c 6f63 222c 206c 6f63  uffer("loc", loc
-00011670: 290d 0a20 2020 2020 2020 2073 656c 662e  )..        self.
-00011680: 7265 6769 7374 6572 5f62 7566 6665 7228  register_buffer(
-00011690: 2273 6361 6c65 222c 2073 6361 6c65 2e63  "scale", scale.c
-000116a0: 6c61 6d70 5f6d 696e 2831 652d 3629 290d  lamp_min(1e-6)).
-000116b0: 0a0d 0a20 2020 2064 6566 205f 6170 706c  ...    def _appl
-000116c0: 795f 7472 616e 7366 6f72 6d28 7365 6c66  y_transform(self
-000116d0: 2c20 7265 7761 7264 3a20 746f 7263 682e  , reward: torch.
-000116e0: 5465 6e73 6f72 2920 2d3e 2074 6f72 6368  Tensor) -> torch
-000116f0: 2e54 656e 736f 723a 0d0a 2020 2020 2020  .Tensor:..      
-00011700: 2020 6966 2073 656c 662e 7374 616e 6461    if self.standa
-00011710: 7264 5f6e 6f72 6d61 6c3a 0d0a 2020 2020  rd_normal:..    
-00011720: 2020 2020 2020 2020 6c6f 6320 3d20 7365          loc = se
-00011730: 6c66 2e6c 6f63 0d0a 2020 2020 2020 2020  lf.loc..        
-00011740: 2020 2020 7363 616c 6520 3d20 7365 6c66      scale = self
-00011750: 2e73 6361 6c65 0d0a 2020 2020 2020 2020  .scale..        
-00011760: 2020 2020 7265 7761 7264 203d 2028 7265      reward = (re
-00011770: 7761 7264 202d 206c 6f63 2920 2f20 7363  ward - loc) / sc
-00011780: 616c 650d 0a20 2020 2020 2020 2020 2020  ale..           
-00011790: 2072 6574 7572 6e20 7265 7761 7264 0d0a   return reward..
-000117a0: 2020 2020 2020 2020 656c 7365 3a0d 0a20          else:.. 
-000117b0: 2020 2020 2020 2020 2020 2073 6361 6c65             scale
-000117c0: 203d 2073 656c 662e 7363 616c 650d 0a20   = self.scale.. 
-000117d0: 2020 2020 2020 2020 2020 206c 6f63 203d             loc =
-000117e0: 2073 656c 662e 6c6f 630d 0a20 2020 2020   self.loc..     
-000117f0: 2020 2020 2020 2072 6577 6172 6420 3d20         reward = 
-00011800: 7265 7761 7264 202a 2073 6361 6c65 202b  reward * scale +
-00011810: 206c 6f63 0d0a 2020 2020 2020 2020 2020   loc..          
-00011820: 2020 7265 7475 726e 2072 6577 6172 640d    return reward.
-00011830: 0a0d 0a20 2020 2064 6566 2074 7261 6e73  ...    def trans
-00011840: 666f 726d 5f72 6577 6172 645f 7370 6563  form_reward_spec
-00011850: 2873 656c 662c 2072 6577 6172 645f 7370  (self, reward_sp
-00011860: 6563 3a20 5465 6e73 6f72 5370 6563 2920  ec: TensorSpec) 
-00011870: 2d3e 2054 656e 736f 7253 7065 633a 0d0a  -> TensorSpec:..
-00011880: 2020 2020 2020 2020 6966 2069 7369 6e73          if isins
-00011890: 7461 6e63 6528 7265 7761 7264 5f73 7065  tance(reward_spe
-000118a0: 632c 2055 6e62 6f75 6e64 6564 436f 6e74  c, UnboundedCont
-000118b0: 696e 756f 7573 5465 6e73 6f72 5370 6563  inuousTensorSpec
-000118c0: 293a 0d0a 2020 2020 2020 2020 2020 2020  ):..            
-000118d0: 7265 7475 726e 2072 6577 6172 645f 7370  return reward_sp
-000118e0: 6563 0d0a 2020 2020 2020 2020 656c 7365  ec..        else
-000118f0: 3a0d 0a20 2020 2020 2020 2020 2020 2072  :..            r
-00011900: 6169 7365 204e 6f74 496d 706c 656d 656e  aise NotImplemen
-00011910: 7465 6445 7272 6f72 280d 0a20 2020 2020  tedError(..     
-00011920: 2020 2020 2020 2020 2020 2066 227b 7365             f"{se
-00011930: 6c66 2e5f 5f63 6c61 7373 5f5f 2e5f 5f6e  lf.__class__.__n
-00011940: 616d 655f 5f7d 2e74 7261 6e73 666f 726d  ame__}.transform
-00011950: 5f72 6577 6172 645f 7370 6563 206e 6f74  _reward_spec not
-00011960: 2022 0d0a 2020 2020 2020 2020 2020 2020   "..            
-00011970: 2020 2020 6622 696d 706c 656d 656e 7465      f"implemente
-00011980: 6420 666f 7220 7465 6e73 6f72 2073 7065  d for tensor spe
-00011990: 6320 6f66 2074 7970 6522 0d0a 2020 2020  c of type"..    
-000119a0: 2020 2020 2020 2020 2020 2020 6622 207b              f" {
-000119b0: 7479 7065 2872 6577 6172 645f 7370 6563  type(reward_spec
-000119c0: 292e 5f5f 6e61 6d65 5f5f 7d22 0d0a 2020  ).__name__}"..  
-000119d0: 2020 2020 2020 2020 2020 290d 0a0d 0a20            ).... 
-000119e0: 2020 2064 6566 205f 5f72 6570 725f 5f28     def __repr__(
-000119f0: 7365 6c66 2920 2d3e 2073 7472 3a0d 0a20  self) -> str:.. 
-00011a00: 2020 2020 2020 2072 6574 7572 6e20 280d         return (.
-00011a10: 0a20 2020 2020 2020 2020 2020 2066 227b  .            f"{
-00011a20: 7365 6c66 2e5f 5f63 6c61 7373 5f5f 2e5f  self.__class__._
-00011a30: 5f6e 616d 655f 5f7d 2822 0d0a 2020 2020  _name__}("..    
-00011a40: 2020 2020 2020 2020 6622 6c6f 633d 7b73          f"loc={s
-00011a50: 656c 662e 6c6f 632e 6974 656d 2829 3a34  elf.loc.item():4
-00011a60: 2e34 667d 2c20 7363 616c 653d 7b73 656c  .4f}, scale={sel
-00011a70: 662e 7363 616c 652e 6974 656d 2829 3a34  f.scale.item():4
-00011a80: 2e34 667d 2c20 220d 0a20 2020 2020 2020  .4f}, "..       
-00011a90: 2020 2020 2066 226b 6579 733d 7b73 656c       f"keys={sel
-00011aa0: 662e 696e 5f6b 6579 737d 2922 0d0a 2020  f.in_keys})"..  
-00011ab0: 2020 2020 2020 290d 0a0d 0a0d 0a63 6c61        )......cla
-00011ac0: 7373 2046 696e 6974 6554 656e 736f 7244  ss FiniteTensorD
-00011ad0: 6963 7443 6865 636b 2854 7261 6e73 666f  ictCheck(Transfo
-00011ae0: 726d 293a 0d0a 2020 2020 2222 2254 6869  rm):..    """Thi
-00011af0: 7320 7472 616e 7366 6f72 6d20 7769 6c6c  s transform will
-00011b00: 2063 6865 636b 2074 6861 7420 616c 6c20   check that all 
-00011b10: 7468 6520 6974 656d 7320 6f66 2074 6865  the items of the
-00011b20: 2074 656e 736f 7264 6963 7420 6172 6520   tensordict are 
-00011b30: 6669 6e69 7465 2c20 616e 6420 7261 6973  finite, and rais
-00011b40: 6520 616e 2065 7863 6570 7469 6f6e 2069  e an exception i
-00011b50: 6620 7468 6579 2061 7265 206e 6f74 2e22  f they are not."
-00011b60: 2222 0d0a 0d0a 2020 2020 6465 6620 5f5f  ""....    def __
-00011b70: 696e 6974 5f5f 2873 656c 6629 3a0d 0a20  init__(self):.. 
-00011b80: 2020 2020 2020 2073 7570 6572 2829 2e5f         super()._
-00011b90: 5f69 6e69 745f 5f28 696e 5f6b 6579 733d  _init__(in_keys=
-00011ba0: 5b5d 290d 0a0d 0a20 2020 2064 6566 205f  [])....    def _
-00011bb0: 6361 6c6c 2873 656c 662c 2074 656e 736f  call(self, tenso
-00011bc0: 7264 6963 743a 2054 656e 736f 7244 6963  rdict: TensorDic
-00011bd0: 7442 6173 6529 202d 3e20 5465 6e73 6f72  tBase) -> Tensor
-00011be0: 4469 6374 4261 7365 3a0d 0a20 2020 2020  DictBase:..     
-00011bf0: 2020 2074 656e 736f 7264 6963 742e 6170     tensordict.ap
-00011c00: 706c 7928 6368 6563 6b5f 6669 6e69 7465  ply(check_finite
-00011c10: 290d 0a20 2020 2020 2020 2072 6574 7572  )..        retur
-00011c20: 6e20 7465 6e73 6f72 6469 6374 0d0a 0d0a  n tensordict....
-00011c30: 2020 2020 666f 7277 6172 6420 3d20 5f63      forward = _c
-00011c40: 616c 6c0d 0a0d 0a0d 0a63 6c61 7373 2044  all......class D
-00011c50: 6f75 626c 6554 6f46 6c6f 6174 2854 7261  oubleToFloat(Tra
-00011c60: 6e73 666f 726d 293a 0d0a 2020 2020 2222  nsform):..    ""
-00011c70: 224d 6170 7320 6163 7469 6f6e 7320 666c  "Maps actions fl
-00011c80: 6f61 7420 746f 2064 6f75 626c 6520 6265  oat to double be
-00011c90: 666f 7265 2074 6865 7920 6172 6520 6361  fore they are ca
-00011ca0: 6c6c 6564 206f 6e20 7468 6520 656e 7669  lled on the envi
-00011cb0: 726f 6e6d 656e 742e 0d0a 0d0a 2020 2020  ronment.....    
-00011cc0: 4172 6773 3a0d 0a20 2020 2020 2020 2069  Args:..        i
-00011cd0: 6e5f 6b65 7973 2028 6c69 7374 206f 6620  n_keys (list of 
-00011ce0: 7374 722c 206f 7074 696f 6e61 6c29 3a20  str, optional): 
-00011cf0: 6c69 7374 206f 6620 646f 7562 6c65 206b  list of double k
-00011d00: 6579 7320 746f 2062 6520 636f 6e76 6572  eys to be conver
-00011d10: 7465 6420 746f 0d0a 2020 2020 2020 2020  ted to..        
-00011d20: 2020 2020 666c 6f61 7420 6265 666f 7265      float before
-00011d30: 2062 6569 6e67 2065 7870 6f73 6564 2074   being exposed t
-00011d40: 6f20 6578 7465 726e 616c 206f 626a 6563  o external objec
-00011d50: 7473 2061 6e64 2066 756e 6374 696f 6e73  ts and functions
-00011d60: 2e0d 0a20 2020 2020 2020 2069 6e5f 6b65  ...        in_ke
-00011d70: 7973 5f69 6e76 2028 6c69 7374 206f 6620  ys_inv (list of 
-00011d80: 7374 722c 206f 7074 696f 6e61 6c29 3a20  str, optional): 
-00011d90: 6c69 7374 206f 6620 666c 6f61 7420 6b65  list of float ke
-00011da0: 7973 2074 6f20 6265 2063 6f6e 7665 7274  ys to be convert
-00011db0: 6564 2074 6f0d 0a20 2020 2020 2020 2020  ed to..         
-00011dc0: 2020 2064 6f75 626c 6520 6265 666f 7265     double before
-00011dd0: 2062 6569 6e67 2070 6173 7365 6420 746f   being passed to
-00011de0: 2074 6865 2063 6f6e 7461 696e 6564 2062   the contained b
-00011df0: 6173 655f 656e 7620 6f72 2073 746f 7261  ase_env or stora
-00011e00: 6765 2e0d 0a0d 0a20 2020 2045 7861 6d70  ge.....    Examp
-00011e10: 6c65 733a 0d0a 2020 2020 2020 2020 3e3e  les:..        >>
-00011e20: 3e20 7464 203d 2054 656e 736f 7244 6963  > td = TensorDic
-00011e30: 7428 0d0a 2020 2020 2020 2020 2e2e 2e20  t(..        ... 
-00011e40: 2020 2020 7b27 6f62 7327 3a20 746f 7263      {'obs': torc
-00011e50: 682e 6f6e 6573 2831 2c20 6474 7970 653d  h.ones(1, dtype=
-00011e60: 746f 7263 682e 646f 7562 6c65 297d 2c20  torch.double)}, 
-00011e70: 5b5d 290d 0a20 2020 2020 2020 203e 3e3e  [])..        >>>
-00011e80: 2074 7261 6e73 666f 726d 203d 2044 6f75   transform = Dou
-00011e90: 626c 6554 6f46 6c6f 6174 2869 6e5f 6b65  bleToFloat(in_ke
-00011ea0: 7973 3d5b 226f 6273 225d 290d 0a20 2020  ys=["obs"])..   
-00011eb0: 2020 2020 203e 3e3e 205f 203d 2074 7261       >>> _ = tra
-00011ec0: 6e73 666f 726d 2874 6429 0d0a 2020 2020  nsform(td)..    
-00011ed0: 2020 2020 3e3e 3e20 7072 696e 7428 7464      >>> print(td
-00011ee0: 2e67 6574 2822 6f62 7322 292e 6474 7970  .get("obs").dtyp
-00011ef0: 6529 0d0a 2020 2020 2020 2020 746f 7263  e)..        torc
-00011f00: 682e 666c 6f61 7433 320d 0a0d 0a20 2020  h.float32....   
-00011f10: 2022 2222 0d0a 0d0a 2020 2020 696e 7665   """....    inve
-00011f20: 7274 6962 6c65 203d 2054 7275 650d 0a0d  rtible = True...
-00011f30: 0a20 2020 2064 6566 205f 5f69 6e69 745f  .    def __init_
-00011f40: 5f28 0d0a 2020 2020 2020 2020 7365 6c66  _(..        self
-00011f50: 2c0d 0a20 2020 2020 2020 2069 6e5f 6b65  ,..        in_ke
-00011f60: 7973 3a20 4f70 7469 6f6e 616c 5b53 6571  ys: Optional[Seq
-00011f70: 7565 6e63 655b 7374 725d 5d20 3d20 4e6f  uence[str]] = No
-00011f80: 6e65 2c0d 0a20 2020 2020 2020 2069 6e5f  ne,..        in_
-00011f90: 6b65 7973 5f69 6e76 3a20 4f70 7469 6f6e  keys_inv: Option
-00011fa0: 616c 5b53 6571 7565 6e63 655b 7374 725d  al[Sequence[str]
-00011fb0: 5d20 3d20 4e6f 6e65 2c0d 0a20 2020 2029  ] = None,..    )
-00011fc0: 3a0d 0a20 2020 2020 2020 2073 7570 6572  :..        super
-00011fd0: 2829 2e5f 5f69 6e69 745f 5f28 696e 5f6b  ().__init__(in_k
-00011fe0: 6579 733d 696e 5f6b 6579 732c 2069 6e5f  eys=in_keys, in_
-00011ff0: 6b65 7973 5f69 6e76 3d69 6e5f 6b65 7973  keys_inv=in_keys
-00012000: 5f69 6e76 290d 0a0d 0a20 2020 2064 6566  _inv)....    def
-00012010: 205f 6170 706c 795f 7472 616e 7366 6f72   _apply_transfor
-00012020: 6d28 7365 6c66 2c20 6f62 733a 2074 6f72  m(self, obs: tor
-00012030: 6368 2e54 656e 736f 7229 202d 3e20 746f  ch.Tensor) -> to
-00012040: 7263 682e 5465 6e73 6f72 3a0d 0a20 2020  rch.Tensor:..   
-00012050: 2020 2020 2072 6574 7572 6e20 6f62 732e       return obs.
-00012060: 746f 2874 6f72 6368 2e66 6c6f 6174 290d  to(torch.float).
-00012070: 0a0d 0a20 2020 2064 6566 205f 696e 765f  ...    def _inv_
-00012080: 6170 706c 795f 7472 616e 7366 6f72 6d28  apply_transform(
-00012090: 7365 6c66 2c20 6f62 733a 2074 6f72 6368  self, obs: torch
-000120a0: 2e54 656e 736f 7229 202d 3e20 746f 7263  .Tensor) -> torc
-000120b0: 682e 5465 6e73 6f72 3a0d 0a20 2020 2020  h.Tensor:..     
-000120c0: 2020 2072 6574 7572 6e20 6f62 732e 746f     return obs.to
-000120d0: 2874 6f72 6368 2e64 6f75 626c 6529 0d0a  (torch.double)..
-000120e0: 0d0a 2020 2020 6465 6620 5f74 7261 6e73  ..    def _trans
-000120f0: 666f 726d 5f73 7065 6328 7365 6c66 2c20  form_spec(self, 
-00012100: 7370 6563 3a20 5465 6e73 6f72 5370 6563  spec: TensorSpec
-00012110: 2920 2d3e 204e 6f6e 653a 0d0a 2020 2020  ) -> None:..    
-00012120: 2020 2020 6966 2069 7369 6e73 7461 6e63      if isinstanc
-00012130: 6528 7370 6563 2c20 436f 6d70 6f73 6974  e(spec, Composit
-00012140: 6553 7065 6329 3a0d 0a20 2020 2020 2020  eSpec):..       
-00012150: 2020 2020 2066 6f72 206b 6579 2069 6e20       for key in 
-00012160: 7370 6563 3a0d 0a20 2020 2020 2020 2020  spec:..         
-00012170: 2020 2020 2020 2073 656c 662e 5f74 7261         self._tra
-00012180: 6e73 666f 726d 5f73 7065 6328 7370 6563  nsform_spec(spec
-00012190: 5b6b 6579 5d29 0d0a 2020 2020 2020 2020  [key])..        
-000121a0: 656c 7365 3a0d 0a20 2020 2020 2020 2020  else:..         
-000121b0: 2020 2073 7065 632e 6474 7970 6520 3d20     spec.dtype = 
-000121c0: 746f 7263 682e 666c 6f61 740d 0a20 2020  torch.float..   
-000121d0: 2020 2020 2020 2020 2073 7061 6365 203d           space =
-000121e0: 2073 7065 632e 7370 6163 650d 0a20 2020   spec.space..   
-000121f0: 2020 2020 2020 2020 2069 6620 6973 696e           if isin
-00012200: 7374 616e 6365 2873 7061 6365 2c20 436f  stance(space, Co
-00012210: 6e74 696e 756f 7573 426f 7829 3a0d 0a20  ntinuousBox):.. 
-00012220: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-00012230: 7061 6365 2e6d 696e 696d 756d 203d 2073  pace.minimum = s
-00012240: 7061 6365 2e6d 696e 696d 756d 2e74 6f28  pace.minimum.to(
-00012250: 746f 7263 682e 666c 6f61 7429 0d0a 2020  torch.float)..  
-00012260: 2020 2020 2020 2020 2020 2020 2020 7370                sp
-00012270: 6163 652e 6d61 7869 6d75 6d20 3d20 7370  ace.maximum = sp
-00012280: 6163 652e 6d61 7869 6d75 6d2e 746f 2874  ace.maximum.to(t
-00012290: 6f72 6368 2e66 6c6f 6174 290d 0a0d 0a20  orch.float).... 
-000122a0: 2020 2064 6566 2074 7261 6e73 666f 726d     def transform
-000122b0: 5f69 6e70 7574 5f73 7065 6328 7365 6c66  _input_spec(self
-000122c0: 2c20 696e 7075 745f 7370 6563 3a20 5465  , input_spec: Te
-000122d0: 6e73 6f72 5370 6563 2920 2d3e 2054 656e  nsorSpec) -> Ten
-000122e0: 736f 7253 7065 633a 0d0a 2020 2020 2020  sorSpec:..      
-000122f0: 2020 666f 7220 6b65 7920 696e 2073 656c    for key in sel
-00012300: 662e 696e 5f6b 6579 735f 696e 763a 0d0a  f.in_keys_inv:..
-00012310: 2020 2020 2020 2020 2020 2020 6966 2069              if i
-00012320: 6e70 7574 5f73 7065 635b 6b65 795d 2e64  nput_spec[key].d
-00012330: 7479 7065 2069 7320 6e6f 7420 746f 7263  type is not torc
-00012340: 682e 646f 7562 6c65 3a0d 0a20 2020 2020  h.double:..     
-00012350: 2020 2020 2020 2020 2020 2072 6169 7365             raise
-00012360: 2054 7970 6545 7272 6f72 280d 0a20 2020   TypeError(..   
-00012370: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012380: 2066 2269 6e70 7574 5f73 7065 635b 7b6b   f"input_spec[{k
-00012390: 6579 7d5d 2e64 7479 7065 2069 7320 6e6f  ey}].dtype is no
-000123a0: 7420 646f 7562 6c65 3a20 7b69 6e70 7574  t double: {input
-000123b0: 5f73 7065 635b 6b65 795d 2e64 7479 7065  _spec[key].dtype
-000123c0: 7d22 0d0a 2020 2020 2020 2020 2020 2020  }"..            
-000123d0: 2020 2020 290d 0a20 2020 2020 2020 2020      )..         
-000123e0: 2020 2073 656c 662e 5f74 7261 6e73 666f     self._transfo
-000123f0: 726d 5f73 7065 6328 696e 7075 745f 7370  rm_spec(input_sp
-00012400: 6563 5b6b 6579 5d29 0d0a 2020 2020 2020  ec[key])..      
-00012410: 2020 7265 7475 726e 2069 6e70 7574 5f73    return input_s
-00012420: 7065 630d 0a0d 0a20 2020 2064 6566 2074  pec....    def t
-00012430: 7261 6e73 666f 726d 5f72 6577 6172 645f  ransform_reward_
-00012440: 7370 6563 2873 656c 662c 2072 6577 6172  spec(self, rewar
-00012450: 645f 7370 6563 3a20 5465 6e73 6f72 5370  d_spec: TensorSp
-00012460: 6563 2920 2d3e 2054 656e 736f 7253 7065  ec) -> TensorSpe
-00012470: 633a 0d0a 2020 2020 2020 2020 6966 2022  c:..        if "
-00012480: 7265 7761 7264 2220 696e 2073 656c 662e  reward" in self.
-00012490: 696e 5f6b 6579 733a 0d0a 2020 2020 2020  in_keys:..      
-000124a0: 2020 2020 2020 6966 2072 6577 6172 645f        if reward_
-000124b0: 7370 6563 2e64 7479 7065 2069 7320 6e6f  spec.dtype is no
-000124c0: 7420 746f 7263 682e 646f 7562 6c65 3a0d  t torch.double:.
-000124d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000124e0: 2072 6169 7365 2054 7970 6545 7272 6f72   raise TypeError
-000124f0: 2822 7265 7761 7264 5f73 7065 632e 6474  ("reward_spec.dt
-00012500: 7970 6520 6973 206e 6f74 2064 6f75 626c  ype is not doubl
-00012510: 6522 290d 0a0d 0a20 2020 2020 2020 2020  e")....         
-00012520: 2020 2073 656c 662e 5f74 7261 6e73 666f     self._transfo
-00012530: 726d 5f73 7065 6328 7265 7761 7264 5f73  rm_spec(reward_s
-00012540: 7065 6329 0d0a 2020 2020 2020 2020 7265  pec)..        re
-00012550: 7475 726e 2072 6577 6172 645f 7370 6563  turn reward_spec
-00012560: 0d0a 0d0a 2020 2020 405f 6170 706c 795f  ....    @_apply_
-00012570: 746f 5f63 6f6d 706f 7369 7465 0d0a 2020  to_composite..  
-00012580: 2020 6465 6620 7472 616e 7366 6f72 6d5f    def transform_
-00012590: 6f62 7365 7276 6174 696f 6e5f 7370 6563  observation_spec
-000125a0: 2873 656c 662c 206f 6273 6572 7661 7469  (self, observati
-000125b0: 6f6e 5f73 7065 633a 2054 656e 736f 7253  on_spec: TensorS
-000125c0: 7065 6329 202d 3e20 5465 6e73 6f72 5370  pec) -> TensorSp
-000125d0: 6563 3a0d 0a20 2020 2020 2020 2073 656c  ec:..        sel
-000125e0: 662e 5f74 7261 6e73 666f 726d 5f73 7065  f._transform_spe
-000125f0: 6328 6f62 7365 7276 6174 696f 6e5f 7370  c(observation_sp
-00012600: 6563 290d 0a20 2020 2020 2020 2072 6574  ec)..        ret
-00012610: 7572 6e20 6f62 7365 7276 6174 696f 6e5f  urn observation_
-00012620: 7370 6563 0d0a 0d0a 2020 2020 6465 6620  spec....    def 
-00012630: 5f5f 7265 7072 5f5f 2873 656c 6629 202d  __repr__(self) -
-00012640: 3e20 7374 723a 0d0a 2020 2020 2020 2020  > str:..        
-00012650: 7320 3d20 280d 0a20 2020 2020 2020 2020  s = (..         
-00012660: 2020 2066 227b 7365 6c66 2e5f 5f63 6c61     f"{self.__cla
-00012670: 7373 5f5f 2e5f 5f6e 616d 655f 5f7d 2869  ss__.__name__}(i
-00012680: 6e5f 6b65 7973 3d7b 7365 6c66 2e69 6e5f  n_keys={self.in_
-00012690: 6b65 7973 7d2c 206f 7574 5f6b 6579 733d  keys}, out_keys=
-000126a0: 7b73 656c 662e 6f75 745f 6b65 7973 7d2c  {self.out_keys},
-000126b0: 2022 0d0a 2020 2020 2020 2020 2020 2020   "..            
-000126c0: 6622 696e 5f6b 6579 735f 696e 763d 7b73  f"in_keys_inv={s
-000126d0: 656c 662e 696e 5f6b 6579 735f 696e 767d  elf.in_keys_inv}
-000126e0: 2c20 6f75 745f 6b65 7973 5f69 6e76 3d7b  , out_keys_inv={
-000126f0: 7365 6c66 2e6f 7574 5f6b 6579 735f 696e  self.out_keys_in
-00012700: 767d 2922 0d0a 2020 2020 2020 2020 290d  v})"..        ).
-00012710: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00012720: 730d 0a0d 0a0d 0a63 6c61 7373 2043 6174  s......class Cat
-00012730: 5465 6e73 6f72 7328 5472 616e 7366 6f72  Tensors(Transfor
-00012740: 6d29 3a0d 0a20 2020 2022 2222 436f 6e63  m):..    """Conc
-00012750: 6174 656e 6174 6573 2073 6576 6572 616c  atenates several
-00012760: 206b 6579 7320 696e 2061 2073 696e 676c   keys in a singl
-00012770: 6520 7465 6e73 6f72 2e0d 0a0d 0a20 2020  e tensor.....   
-00012780: 2054 6869 7320 6973 2065 7370 6563 6961   This is especia
-00012790: 6c6c 7920 7573 6566 756c 2069 6620 6d75  lly useful if mu
-000127a0: 6c74 6970 6c65 206b 6579 7320 6465 7363  ltiple keys desc
-000127b0: 7269 6265 2061 2073 696e 676c 6520 7374  ribe a single st
-000127c0: 6174 6520 2865 2e67 2e0d 0a20 2020 2022  ate (e.g...    "
-000127d0: 6f62 7365 7276 6174 696f 6e5f 706f 7369  observation_posi
-000127e0: 7469 6f6e 2220 616e 640d 0a20 2020 2022  tion" and..    "
-000127f0: 6f62 7365 7276 6174 696f 6e5f 7665 6c6f  observation_velo
-00012800: 6369 7479 2229 0d0a 0d0a 2020 2020 4172  city")....    Ar
-00012810: 6773 3a0d 0a20 2020 2020 2020 2069 6e5f  gs:..        in_
-00012820: 6b65 7973 2028 5365 7175 656e 6365 206f  keys (Sequence o
-00012830: 6620 7374 7229 3a20 6b65 7973 2074 6f20  f str): keys to 
-00012840: 6265 2063 6f6e 6361 7465 6e61 7465 642e  be concatenated.
-00012850: 2049 6620 604e 6f6e 6560 2028 6f72 206e   If `None` (or n
-00012860: 6f74 2070 726f 7669 6465 6429 0d0a 2020  ot provided)..  
-00012870: 2020 2020 2020 2020 2020 7468 6520 6b65            the ke
-00012880: 7973 2077 696c 6c20 6265 2072 6574 7269  ys will be retri
-00012890: 6576 6564 2066 726f 6d20 7468 6520 7061  eved from the pa
-000128a0: 7265 6e74 2065 6e76 6972 6f6e 6d65 6e74  rent environment
-000128b0: 2074 6865 2066 6972 7374 2074 696d 650d   the first time.
-000128c0: 0a20 2020 2020 2020 2020 2020 2074 6865  .            the
-000128d0: 2074 7261 6e73 666f 726d 2069 7320 7573   transform is us
-000128e0: 6564 2e20 5468 6973 2062 6568 6176 696f  ed. This behavio
-000128f0: 7572 2077 696c 6c20 6f6e 6c79 2077 6f72  ur will only wor
-00012900: 6b20 6966 2061 2070 6172 656e 7420 6973  k if a parent is
-00012910: 2073 6574 2e0d 0a20 2020 2020 2020 206f   set...        o
-00012920: 7574 5f6b 6579 3a20 6b65 7920 6f66 2074  ut_key: key of t
-00012930: 6865 2072 6573 756c 7469 6e67 2074 656e  he resulting ten
-00012940: 736f 722e 0d0a 2020 2020 2020 2020 6469  sor...        di
-00012950: 6d20 2869 6e74 2c20 6f70 7469 6f6e 616c  m (int, optional
-00012960: 293a 2064 696d 656e 7369 6f6e 2061 6c6f  ): dimension alo
-00012970: 6e67 2077 6869 6368 2074 6865 2063 6f6e  ng which the con
-00012980: 6361 7465 6e61 7469 6f6e 2077 696c 6c20  catenation will 
-00012990: 6f63 6375 722e 0d0a 2020 2020 2020 2020  occur...        
-000129a0: 2020 2020 4465 6661 756c 7420 6973 202d      Default is -
-000129b0: 312e 0d0a 2020 2020 2020 2020 6465 6c5f  1...        del_
-000129c0: 6b65 7973 2028 626f 6f6c 2c20 6f70 7469  keys (bool, opti
-000129d0: 6f6e 616c 293a 2069 6620 5472 7565 2c20  onal): if True, 
-000129e0: 7468 6520 696e 7075 7420 7661 6c75 6573  the input values
-000129f0: 2077 696c 6c20 6265 2064 656c 6574 6564   will be deleted
-00012a00: 2061 6674 6572 0d0a 2020 2020 2020 2020   after..        
-00012a10: 2020 2020 636f 6e63 6174 656e 6174 696f      concatenatio
-00012a20: 6e2e 2044 6566 6175 6c74 2069 7320 5472  n. Default is Tr
-00012a30: 7565 2e0d 0a20 2020 2020 2020 2075 6e73  ue...        uns
-00012a40: 7175 6565 7a65 5f69 665f 6f6f 7220 2862  queeze_if_oor (b
-00012a50: 6f6f 6c2c 206f 7074 696f 6e61 6c29 3a20  ool, optional): 
-00012a60: 6966 2054 7275 652c 2043 6174 5465 6e73  if True, CatTens
-00012a70: 6f72 2077 696c 6c20 6368 6563 6b20 7468  or will check th
-00012a80: 6174 0d0a 2020 2020 2020 2020 2020 2020  at..            
-00012a90: 7468 6520 6469 6d65 6e73 696f 6e20 696e  the dimension in
-00012aa0: 6469 6361 7465 6420 6578 6973 7420 666f  dicated exist fo
-00012ab0: 7220 7468 6520 7465 6e73 6f72 7320 746f  r the tensors to
-00012ac0: 2063 6f6e 6361 7465 6e61 7465 2e20 4966   concatenate. If
-00012ad0: 206e 6f74 2c0d 0a20 2020 2020 2020 2020   not,..         
-00012ae0: 2020 2074 6865 2074 656e 736f 7273 2077     the tensors w
-00012af0: 696c 6c20 6265 2075 6e73 7175 6565 7a65  ill be unsqueeze
-00012b00: 6420 616c 6f6e 6720 7468 6174 2064 696d  d along that dim
-00012b10: 656e 7369 6f6e 2e0d 0a20 2020 2020 2020  ension...       
-00012b20: 2020 2020 2044 6566 6175 6c74 2069 7320       Default is 
-00012b30: 4661 6c73 652e 0d0a 0d0a 2020 2020 4578  False.....    Ex
-00012b40: 616d 706c 6573 3a0d 0a20 2020 2020 2020  amples:..       
-00012b50: 203e 3e3e 2074 7261 6e73 666f 726d 203d   >>> transform =
-00012b60: 2043 6174 5465 6e73 6f72 7328 696e 5f6b   CatTensors(in_k
-00012b70: 6579 733d 5b22 6b65 7931 222c 2022 6b65  eys=["key1", "ke
-00012b80: 7932 225d 290d 0a20 2020 2020 2020 203e  y2"])..        >
-00012b90: 3e3e 2074 6420 3d20 5465 6e73 6f72 4469  >> td = TensorDi
-00012ba0: 6374 287b 226b 6579 3122 3a20 746f 7263  ct({"key1": torc
-00012bb0: 682e 7a65 726f 7328 312c 2031 292c 0d0a  h.zeros(1, 1),..
-00012bc0: 2020 2020 2020 2020 2e2e 2e20 2020 2020          ...     
-00012bd0: 226b 6579 3222 3a20 746f 7263 682e 6f6e  "key2": torch.on
-00012be0: 6573 2831 2c20 3129 7d2c 205b 315d 290d  es(1, 1)}, [1]).
-00012bf0: 0a20 2020 2020 2020 203e 3e3e 205f 203d  .        >>> _ =
-00012c00: 2074 7261 6e73 666f 726d 2874 6429 0d0a   transform(td)..
-00012c10: 2020 2020 2020 2020 3e3e 3e20 7072 696e          >>> prin
-00012c20: 7428 7464 2e67 6574 2822 6f62 7365 7276  t(td.get("observ
-00012c30: 6174 696f 6e5f 7665 6374 6f72 2229 290d  ation_vector")).
-00012c40: 0a20 2020 2020 2020 2074 656e 736f 7228  .        tensor(
-00012c50: 5b5b 302e 2c20 312e 5d5d 290d 0a20 2020  [[0., 1.]])..   
-00012c60: 2020 2020 203e 3e3e 2074 7261 6e73 666f       >>> transfo
-00012c70: 726d 203d 2043 6174 5465 6e73 6f72 7328  rm = CatTensors(
-00012c80: 696e 5f6b 6579 733d 5b22 6b65 7931 222c  in_keys=["key1",
-00012c90: 2022 6b65 7932 225d 2c20 6469 6d3d 2d32   "key2"], dim=-2
-00012ca0: 2c20 756e 7371 7565 657a 655f 6966 5f6f  , unsqueeze_if_o
-00012cb0: 6f72 3d54 7275 6529 0d0a 2020 2020 2020  or=True)..      
-00012cc0: 2020 3e3e 3e20 7464 203d 2054 656e 736f    >>> td = Tenso
-00012cd0: 7244 6963 7428 7b22 6b65 7931 223a 2074  rDict({"key1": t
-00012ce0: 6f72 6368 2e7a 6572 6f73 2831 292c 0d0a  orch.zeros(1),..
-00012cf0: 2020 2020 2020 2020 2e2e 2e20 2020 2020          ...     
-00012d00: 226b 6579 3222 3a20 746f 7263 682e 6f6e  "key2": torch.on
-00012d10: 6573 2831 297d 2c20 5b5d 290d 0a20 2020  es(1)}, [])..   
-00012d20: 2020 2020 203e 3e3e 205f 203d 2074 7261       >>> _ = tra
-00012d30: 6e73 666f 726d 2874 6429 0d0a 2020 2020  nsform(td)..    
-00012d40: 2020 2020 3e3e 3e20 7072 696e 7428 7464      >>> print(td
-00012d50: 2e67 6574 2822 6f62 7365 7276 6174 696f  .get("observatio
-00012d60: 6e5f 7665 6374 6f72 2229 2e73 6861 7065  n_vector").shape
-00012d70: 290d 0a20 2020 2020 2020 2074 6f72 6368  )..        torch
-00012d80: 2e53 697a 6528 5b32 2c20 315d 290d 0a0d  .Size([2, 1])...
-00012d90: 0a20 2020 2022 2222 0d0a 0d0a 2020 2020  .    """....    
-00012da0: 696e 7665 7274 6962 6c65 203d 2046 616c  invertible = Fal
-00012db0: 7365 0d0a 0d0a 2020 2020 6465 6620 5f5f  se....    def __
-00012dc0: 696e 6974 5f5f 280d 0a20 2020 2020 2020  init__(..       
-00012dd0: 2073 656c 662c 0d0a 2020 2020 2020 2020   self,..        
-00012de0: 696e 5f6b 6579 733a 204f 7074 696f 6e61  in_keys: Optiona
-00012df0: 6c5b 5365 7175 656e 6365 5b73 7472 5d5d  l[Sequence[str]]
-00012e00: 203d 204e 6f6e 652c 0d0a 2020 2020 2020   = None,..      
-00012e10: 2020 6f75 745f 6b65 793a 2073 7472 203d    out_key: str =
-00012e20: 2022 6f62 7365 7276 6174 696f 6e5f 7665   "observation_ve
-00012e30: 6374 6f72 222c 0d0a 2020 2020 2020 2020  ctor",..        
-00012e40: 6469 6d3a 2069 6e74 203d 202d 312c 0d0a  dim: int = -1,..
-00012e50: 2020 2020 2020 2020 6465 6c5f 6b65 7973          del_keys
-00012e60: 3a20 626f 6f6c 203d 2054 7275 652c 0d0a  : bool = True,..
-00012e70: 2020 2020 2020 2020 756e 7371 7565 657a          unsqueez
-00012e80: 655f 6966 5f6f 6f72 3a20 626f 6f6c 203d  e_if_oor: bool =
-00012e90: 2046 616c 7365 2c0d 0a20 2020 2029 3a0d   False,..    ):.
-00012ea0: 0a20 2020 2020 2020 2073 656c 662e 5f69  .        self._i
-00012eb0: 6e69 7469 616c 697a 6564 203d 2069 6e5f  nitialized = in_
-00012ec0: 6b65 7973 2069 7320 6e6f 7420 4e6f 6e65  keys is not None
-00012ed0: 0d0a 2020 2020 2020 2020 6966 206e 6f74  ..        if not
-00012ee0: 2073 656c 662e 5f69 6e69 7469 616c 697a   self._initializ
-00012ef0: 6564 3a0d 0a20 2020 2020 2020 2020 2020  ed:..           
-00012f00: 2069 6620 6469 6d20 213d 202d 313a 0d0a   if dim != -1:..
-00012f10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012f20: 7261 6973 6520 5661 6c75 6545 7272 6f72  raise ValueError
-00012f30: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
-00012f40: 2020 2020 2020 2022 4c61 7a79 2063 616c         "Lazy cal
-00012f50: 6c20 746f 2043 6174 5465 6e73 6f72 7320  l to CatTensors 
-00012f60: 6973 206f 6e6c 7920 7375 7070 6f72 7465  is only supporte
-00012f70: 6420 7768 656e 2060 6469 6d3d 2d31 602e  d when `dim=-1`.
-00012f80: 220d 0a20 2020 2020 2020 2020 2020 2020  "..             
-00012f90: 2020 2029 0d0a 2020 2020 2020 2020 656c     )..        el
-00012fa0: 7365 3a0d 0a20 2020 2020 2020 2020 2020  se:..           
-00012fb0: 2069 6e5f 6b65 7973 203d 2073 6f72 7465   in_keys = sorte
-00012fc0: 6428 696e 5f6b 6579 732c 206b 6579 3d5f  d(in_keys, key=_
-00012fd0: 736f 7274 5f6b 6579 7329 0d0a 2020 2020  sort_keys)..    
-00012fe0: 2020 2020 6966 2074 7970 6528 6f75 745f      if type(out_
-00012ff0: 6b65 7929 2021 3d20 7374 723a 0d0a 2020  key) != str:..  
-00013000: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
-00013010: 4578 6365 7074 696f 6e28 2243 6174 5465  Exception("CatTe
-00013020: 6e73 6f72 7320 7265 7175 6972 6573 206f  nsors requires o
-00013030: 7574 5f6b 6579 2074 6f20 6265 206f 6620  ut_key to be of 
-00013040: 7479 7065 2073 7472 696e 6722 290d 0a20  type string").. 
-00013050: 2020 2020 2020 2023 2073 7570 6572 2829         # super()
-00013060: 2e5f 5f69 6e69 745f 5f28 696e 5f6b 6579  .__init__(in_key
-00013070: 733d 696e 5f6b 6579 7329 0d0a 2020 2020  s=in_keys)..    
-00013080: 2020 2020 7375 7065 7228 4361 7454 656e      super(CatTen
-00013090: 736f 7273 2c20 7365 6c66 292e 5f5f 696e  sors, self).__in
-000130a0: 6974 5f5f 2869 6e5f 6b65 7973 3d69 6e5f  it__(in_keys=in_
-000130b0: 6b65 7973 2c20 6f75 745f 6b65 7973 3d5b  keys, out_keys=[
-000130c0: 6f75 745f 6b65 795d 290d 0a20 2020 2020  out_key])..     
-000130d0: 2020 2073 656c 662e 6469 6d20 3d20 6469     self.dim = di
-000130e0: 6d0d 0a20 2020 2020 2020 2073 656c 662e  m..        self.
-000130f0: 5f64 656c 5f6b 6579 7320 3d20 6465 6c5f  _del_keys = del_
-00013100: 6b65 7973 0d0a 2020 2020 2020 2020 7365  keys..        se
-00013110: 6c66 2e5f 6b65 7973 5f74 6f5f 6578 636c  lf._keys_to_excl
-00013120: 7564 6520 3d20 4e6f 6e65 0d0a 2020 2020  ude = None..    
-00013130: 2020 2020 7365 6c66 2e75 6e73 7175 6565      self.unsquee
-00013140: 7a65 5f69 665f 6f6f 7220 3d20 756e 7371  ze_if_oor = unsq
-00013150: 7565 657a 655f 6966 5f6f 6f72 0d0a 0d0a  ueeze_if_oor....
-00013160: 2020 2020 4070 726f 7065 7274 790d 0a20      @property.. 
-00013170: 2020 2064 6566 206b 6579 735f 746f 5f65     def keys_to_e
-00013180: 7863 6c75 6465 2873 656c 6629 3a0d 0a20  xclude(self):.. 
-00013190: 2020 2020 2020 2069 6620 7365 6c66 2e5f         if self._
-000131a0: 6b65 7973 5f74 6f5f 6578 636c 7564 6520  keys_to_exclude 
-000131b0: 6973 204e 6f6e 653a 0d0a 2020 2020 2020  is None:..      
-000131c0: 2020 2020 2020 7365 6c66 2e5f 6b65 7973        self._keys
-000131d0: 5f74 6f5f 6578 636c 7564 6520 3d20 5b0d  _to_exclude = [.
-000131e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000131f0: 206b 6579 2066 6f72 206b 6579 2069 6e20   key for key in 
-00013200: 7365 6c66 2e69 6e5f 6b65 7973 2069 6620  self.in_keys if 
-00013210: 6b65 7920 213d 2073 656c 662e 6f75 745f  key != self.out_
-00013220: 6b65 7973 5b30 5d0d 0a20 2020 2020 2020  keys[0]..       
-00013230: 2020 2020 205d 0d0a 2020 2020 2020 2020       ]..        
-00013240: 7265 7475 726e 2073 656c 662e 5f6b 6579  return self._key
-00013250: 735f 746f 5f65 7863 6c75 6465 0d0a 0d0a  s_to_exclude....
-00013260: 2020 2020 6465 6620 5f66 696e 645f 696e      def _find_in
-00013270: 5f6b 6579 7328 7365 6c66 293a 0d0a 2020  _keys(self):..  
-00013280: 2020 2020 2020 7061 7265 6e74 203d 2073        parent = s
-00013290: 656c 662e 7061 7265 6e74 0d0a 2020 2020  elf.parent..    
-000132a0: 2020 2020 6f62 735f 7370 6563 203d 2070      obs_spec = p
-000132b0: 6172 656e 742e 6f62 7365 7276 6174 696f  arent.observatio
-000132c0: 6e5f 7370 6563 0d0a 2020 2020 2020 2020  n_spec..        
-000132d0: 696e 5f6b 6579 7320 3d20 5b5d 0d0a 2020  in_keys = []..  
-000132e0: 2020 2020 2020 666f 7220 6b65 792c 2076        for key, v
-000132f0: 616c 7565 2069 6e20 6f62 735f 7370 6563  alue in obs_spec
-00013300: 2e69 7465 6d73 2829 3a0d 0a20 2020 2020  .items():..     
-00013310: 2020 2020 2020 2069 6620 6c65 6e28 7661         if len(va
-00013320: 6c75 652e 7368 6170 6529 203d 3d20 313a  lue.shape) == 1:
-00013330: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00013340: 2020 696e 5f6b 6579 732e 6170 7065 6e64    in_keys.append
-00013350: 286b 6579 290d 0a20 2020 2020 2020 2072  (key)..        r
-00013360: 6574 7572 6e20 736f 7274 6564 2869 6e5f  eturn sorted(in_
-00013370: 6b65 7973 2c20 6b65 793d 5f73 6f72 745f  keys, key=_sort_
-00013380: 6b65 7973 290d 0a0d 0a20 2020 2064 6566  keys)....    def
-00013390: 205f 6361 6c6c 2873 656c 662c 2074 656e   _call(self, ten
-000133a0: 736f 7264 6963 743a 2054 656e 736f 7244  sordict: TensorD
-000133b0: 6963 7442 6173 6529 202d 3e20 5465 6e73  ictBase) -> Tens
-000133c0: 6f72 4469 6374 4261 7365 3a0d 0a20 2020  orDictBase:..   
-000133d0: 2020 2020 2069 6620 6e6f 7420 7365 6c66       if not self
-000133e0: 2e5f 696e 6974 6961 6c69 7a65 643a 0d0a  ._initialized:..
-000133f0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-00013400: 2e69 6e5f 6b65 7973 203d 2073 656c 662e  .in_keys = self.
-00013410: 5f66 696e 645f 696e 5f6b 6579 7328 290d  _find_in_keys().
-00013420: 0a20 2020 2020 2020 2020 2020 2073 656c  .            sel
-00013430: 662e 5f69 6e69 7469 616c 697a 6564 203d  f._initialized =
-00013440: 2054 7275 650d 0a0d 0a20 2020 2020 2020   True....       
-00013450: 2069 6620 616c 6c28 6b65 7920 696e 2074   if all(key in t
-00013460: 656e 736f 7264 6963 742e 6b65 7973 2869  ensordict.keys(i
-00013470: 6e63 6c75 6465 5f6e 6573 7465 643d 5472  nclude_nested=Tr
-00013480: 7565 2920 666f 7220 6b65 7920 696e 2073  ue) for key in s
-00013490: 656c 662e 696e 5f6b 6579 7329 3a0d 0a20  elf.in_keys):.. 
-000134a0: 2020 2020 2020 2020 2020 2076 616c 7565             value
-000134b0: 7320 3d20 5b74 656e 736f 7264 6963 742e  s = [tensordict.
-000134c0: 6765 7428 6b65 7929 2066 6f72 206b 6579  get(key) for key
-000134d0: 2069 6e20 7365 6c66 2e69 6e5f 6b65 7973   in self.in_keys
-000134e0: 5d0d 0a20 2020 2020 2020 2020 2020 2069  ]..            i
-000134f0: 6620 7365 6c66 2e75 6e73 7175 6565 7a65  f self.unsqueeze
-00013500: 5f69 665f 6f6f 723a 0d0a 2020 2020 2020  _if_oor:..      
-00013510: 2020 2020 2020 2020 2020 706f 735f 6964            pos_id
-00013520: 7820 3d20 7365 6c66 2e64 696d 203e 2030  x = self.dim > 0
-00013530: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00013540: 2020 6162 735f 6964 7820 3d20 7365 6c66    abs_idx = self
-00013550: 2e64 696d 2069 6620 706f 735f 6964 7820  .dim if pos_idx 
-00013560: 656c 7365 202d 7365 6c66 2e64 696d 202d  else -self.dim -
-00013570: 2031 0d0a 2020 2020 2020 2020 2020 2020   1..            
-00013580: 2020 2020 7661 6c75 6573 203d 205b 0d0a      values = [..
-00013590: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000135a0: 2020 2020 760d 0a20 2020 2020 2020 2020      v..         
-000135b0: 2020 2020 2020 2020 2020 2069 6620 6162             if ab
-000135c0: 735f 6964 7820 3c20 762e 6e64 696d 656e  s_idx < v.ndimen
-000135d0: 7369 6f6e 2829 0d0a 2020 2020 2020 2020  sion()..        
-000135e0: 2020 2020 2020 2020 2020 2020 656c 7365              else
-000135f0: 2076 2e75 6e73 7175 6565 7a65 2830 290d   v.unsqueeze(0).
-00013600: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00013610: 2020 2020 2069 6620 6e6f 7420 706f 735f       if not pos_
-00013620: 6964 780d 0a20 2020 2020 2020 2020 2020  idx..           
-00013630: 2020 2020 2020 2020 2065 6c73 6520 762e           else v.
-00013640: 756e 7371 7565 657a 6528 2d31 290d 0a20  unsqueeze(-1).. 
-00013650: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013660: 2020 2066 6f72 2076 2069 6e20 7661 6c75     for v in valu
-00013670: 6573 0d0a 2020 2020 2020 2020 2020 2020  es..            
-00013680: 2020 2020 5d0d 0a0d 0a20 2020 2020 2020      ]....       
-00013690: 2020 2020 206f 7574 5f74 656e 736f 7220       out_tensor 
-000136a0: 3d20 746f 7263 682e 6361 7428 7661 6c75  = torch.cat(valu
-000136b0: 6573 2c20 6469 6d3d 7365 6c66 2e64 696d  es, dim=self.dim
-000136c0: 290d 0a20 2020 2020 2020 2020 2020 2074  )..            t
-000136d0: 656e 736f 7264 6963 742e 7365 7428 7365  ensordict.set(se
-000136e0: 6c66 2e6f 7574 5f6b 6579 735b 305d 2c20  lf.out_keys[0], 
-000136f0: 6f75 745f 7465 6e73 6f72 290d 0a20 2020  out_tensor)..   
-00013700: 2020 2020 2020 2020 2069 6620 7365 6c66           if self
-00013710: 2e5f 6465 6c5f 6b65 7973 3a0d 0a20 2020  ._del_keys:..   
-00013720: 2020 2020 2020 2020 2020 2020 2074 656e               ten
-00013730: 736f 7264 6963 742e 6578 636c 7564 6528  sordict.exclude(
-00013740: 2a73 656c 662e 6b65 7973 5f74 6f5f 6578  *self.keys_to_ex
-00013750: 636c 7564 652c 2069 6e70 6c61 6365 3d54  clude, inplace=T
-00013760: 7275 6529 0d0a 2020 2020 2020 2020 656c  rue)..        el
-00013770: 7365 3a0d 0a20 2020 2020 2020 2020 2020  se:..           
-00013780: 2072 6169 7365 2045 7863 6570 7469 6f6e   raise Exception
-00013790: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
-000137a0: 2020 2066 2243 6174 5465 6e73 6f72 2066     f"CatTensor f
-000137b0: 6169 6c65 642c 2061 7320 6974 2065 7870  ailed, as it exp
-000137c0: 6563 7465 6420 696e 7075 7420 6b65 7973  ected input keys
-000137d0: 203d 220d 0a20 2020 2020 2020 2020 2020   ="..           
-000137e0: 2020 2020 2066 2220 7b73 6f72 7465 6428       f" {sorted(
-000137f0: 7365 6c66 2e69 6e5f 6b65 7973 2c20 6b65  self.in_keys, ke
-00013800: 793d 5f73 6f72 745f 6b65 7973 297d 2062  y=_sort_keys)} b
-00013810: 7574 2067 6f74 2061 2054 656e 736f 7244  ut got a TensorD
-00013820: 6963 7420 7769 7468 206b 6579 7322 0d0a  ict with keys"..
-00013830: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013840: 6622 207b 736f 7274 6564 2874 656e 736f  f" {sorted(tenso
-00013850: 7264 6963 742e 6b65 7973 2869 6e63 6c75  rdict.keys(inclu
-00013860: 6465 5f6e 6573 7465 643d 5472 7565 292c  de_nested=True),
-00013870: 206b 6579 3d5f 736f 7274 5f6b 6579 7329   key=_sort_keys)
-00013880: 7d22 0d0a 2020 2020 2020 2020 2020 2020  }"..            
-00013890: 290d 0a20 2020 2020 2020 2072 6574 7572  )..        retur
-000138a0: 6e20 7465 6e73 6f72 6469 6374 0d0a 0d0a  n tensordict....
-000138b0: 2020 2020 666f 7277 6172 6420 3d20 5f63      forward = _c
-000138c0: 616c 6c0d 0a0d 0a20 2020 2064 6566 2074  all....    def t
-000138d0: 7261 6e73 666f 726d 5f6f 6273 6572 7661  ransform_observa
-000138e0: 7469 6f6e 5f73 7065 6328 7365 6c66 2c20  tion_spec(self, 
-000138f0: 6f62 7365 7276 6174 696f 6e5f 7370 6563  observation_spec
-00013900: 3a20 5465 6e73 6f72 5370 6563 2920 2d3e  : TensorSpec) ->
-00013910: 2054 656e 736f 7253 7065 633a 0d0a 2020   TensorSpec:..  
-00013920: 2020 2020 2020 2320 6368 6563 6b20 7468        # check th
-00013930: 6174 2061 6c6c 206b 6579 7320 6172 6520  at all keys are 
-00013940: 696e 206f 6273 6572 7661 7469 6f6e 5f73  in observation_s
-00013950: 7065 630d 0a20 2020 2020 2020 2069 6620  pec..        if 
-00013960: 6c65 6e28 7365 6c66 2e69 6e5f 6b65 7973  len(self.in_keys
-00013970: 2920 3e20 3120 616e 6420 6e6f 7420 6973  ) > 1 and not is
-00013980: 696e 7374 616e 6365 286f 6273 6572 7661  instance(observa
-00013990: 7469 6f6e 5f73 7065 632c 2043 6f6d 706f  tion_spec, Compo
-000139a0: 7369 7465 5370 6563 293a 0d0a 2020 2020  siteSpec):..    
-000139b0: 2020 2020 2020 2020 7261 6973 6520 5661          raise Va
-000139c0: 6c75 6545 7272 6f72 280d 0a20 2020 2020  lueError(..     
-000139d0: 2020 2020 2020 2020 2020 2022 4361 7454             "CatT
-000139e0: 656e 736f 7220 6361 6e6e 6f74 2069 6e66  ensor cannot inf
-000139f0: 6572 2074 6865 206f 7574 7075 7420 6f62  er the output ob
-00013a00: 7365 7276 6174 696f 6e20 7370 6563 2061  servation spec a
-00013a10: 7320 7468 6572 6520 6172 6520 6d75 6c74  s there are mult
-00013a20: 6970 6c65 2069 6e70 7574 206b 6579 7320  iple input keys 
-00013a30: 6275 7420 220d 0a20 2020 2020 2020 2020  but "..         
-00013a40: 2020 2020 2020 2022 6f6e 6c79 206f 6e65         "only one
-00013a50: 206f 6273 6572 7661 7469 6f6e 5f73 7065   observation_spe
-00013a60: 632e 220d 0a20 2020 2020 2020 2020 2020  c."..           
-00013a70: 2029 0d0a 0d0a 2020 2020 2020 2020 6966   )....        if
-00013a80: 2069 7369 6e73 7461 6e63 6528 6f62 7365   isinstance(obse
-00013a90: 7276 6174 696f 6e5f 7370 6563 2c20 436f  rvation_spec, Co
-00013aa0: 6d70 6f73 6974 6553 7065 6329 2061 6e64  mpositeSpec) and
-00013ab0: 206c 656e 280d 0a20 2020 2020 2020 2020   len(..         
-00013ac0: 2020 205b 6b65 7920 666f 7220 6b65 7920     [key for key 
-00013ad0: 696e 2073 656c 662e 696e 5f6b 6579 7320  in self.in_keys 
-00013ae0: 6966 206b 6579 206e 6f74 2069 6e20 6f62  if key not in ob
-00013af0: 7365 7276 6174 696f 6e5f 7370 6563 5d0d  servation_spec].
-00013b00: 0a20 2020 2020 2020 2029 3a0d 0a20 2020  .        ):..   
-00013b10: 2020 2020 2020 2020 2072 6169 7365 2056           raise V
-00013b20: 616c 7565 4572 726f 7228 0d0a 2020 2020  alueError(..    
-00013b30: 2020 2020 2020 2020 2020 2020 2243 6174              "Cat
-00013b40: 5465 6e73 6f72 2067 6f74 2061 206c 6973  Tensor got a lis
-00013b50: 7420 6f66 206b 6579 7320 7468 6174 2064  t of keys that d
-00013b60: 6f65 7320 6e6f 7420 6d61 7463 6820 7468  oes not match th
-00013b70: 6520 6b65 7973 2069 6e20 6f62 7365 7276  e keys in observ
-00013b80: 6174 696f 6e5f 7370 6563 2e20 220d 0a20  ation_spec. ".. 
-00013b90: 2020 2020 2020 2020 2020 2020 2020 2022                 "
-00013ba0: 4d61 6b65 2073 7572 6520 7468 6520 656e  Make sure the en
-00013bb0: 7669 726f 6e6d 656e 7420 6861 7320 616e  vironment has an
-00013bc0: 206f 6273 6572 7661 7469 6f6e 5f73 7065   observation_spe
-00013bd0: 6320 6174 7472 6962 7574 6520 7468 6174  c attribute that
-00013be0: 2069 6e63 6c75 6465 7320 616c 6c20 7468   includes all th
-00013bf0: 6520 7370 6563 7320 6e65 6564 6564 2066  e specs needed f
-00013c00: 6f72 2043 6174 5465 6e73 6f72 2e22 0d0a  or CatTensor."..
-00013c10: 2020 2020 2020 2020 2020 2020 290d 0a0d              )...
-00013c20: 0a20 2020 2020 2020 2069 6620 6e6f 7420  .        if not 
-00013c30: 6973 696e 7374 616e 6365 286f 6273 6572  isinstance(obser
-00013c40: 7661 7469 6f6e 5f73 7065 632c 2043 6f6d  vation_spec, Com
-00013c50: 706f 7369 7465 5370 6563 293a 0d0a 2020  positeSpec):..  
-00013c60: 2020 2020 2020 2020 2020 2320 6279 2064            # by d
-00013c70: 6566 2c20 7468 6572 6520 6d75 7374 2062  ef, there must b
-00013c80: 6520 6f6e 6c79 206f 6e65 206b 6579 0d0a  e only one key..
-00013c90: 2020 2020 2020 2020 2020 2020 7265 7475              retu
-00013ca0: 726e 206f 6273 6572 7661 7469 6f6e 5f73  rn observation_s
-00013cb0: 7065 630d 0a0d 0a20 2020 2020 2020 206b  pec....        k
-00013cc0: 6579 7320 3d20 5b6b 6579 2066 6f72 206b  eys = [key for k
-00013cd0: 6579 2069 6e20 6f62 7365 7276 6174 696f  ey in observatio
-00013ce0: 6e5f 7370 6563 2e6b 6579 7328 5472 7565  n_spec.keys(True
-00013cf0: 2c20 5472 7565 2920 6966 206b 6579 2069  , True) if key i
-00013d00: 6e20 7365 6c66 2e69 6e5f 6b65 7973 5d0d  n self.in_keys].
-00013d10: 0a0d 0a20 2020 2020 2020 2073 756d 5f73  ...        sum_s
-00013d20: 6861 7065 203d 2073 756d 280d 0a20 2020  hape = sum(..   
-00013d30: 2020 2020 2020 2020 205b 0d0a 2020 2020           [..    
-00013d40: 2020 2020 2020 2020 2020 2020 6f62 7365              obse
-00013d50: 7276 6174 696f 6e5f 7370 6563 5b6b 6579  rvation_spec[key
-00013d60: 5d2e 7368 6170 655b 7365 6c66 2e64 696d  ].shape[self.dim
-00013d70: 5d0d 0a20 2020 2020 2020 2020 2020 2020  ]..             
-00013d80: 2020 2069 6620 6f62 7365 7276 6174 696f     if observatio
-00013d90: 6e5f 7370 6563 5b6b 6579 5d2e 7368 6170  n_spec[key].shap
-00013da0: 650d 0a20 2020 2020 2020 2020 2020 2020  e..             
-00013db0: 2020 2065 6c73 6520 310d 0a20 2020 2020     else 1..     
-00013dc0: 2020 2020 2020 2020 2020 2066 6f72 206b             for k
-00013dd0: 6579 2069 6e20 6b65 7973 0d0a 2020 2020  ey in keys..    
-00013de0: 2020 2020 2020 2020 5d0d 0a20 2020 2020          ]..     
-00013df0: 2020 2029 0d0a 2020 2020 2020 2020 7370     )..        sp
-00013e00: 6563 3020 3d20 6f62 7365 7276 6174 696f  ec0 = observatio
-00013e10: 6e5f 7370 6563 5b6b 6579 735b 305d 5d0d  n_spec[keys[0]].
-00013e20: 0a20 2020 2020 2020 206f 7574 5f6b 6579  .        out_key
-00013e30: 203d 2073 656c 662e 6f75 745f 6b65 7973   = self.out_keys
-00013e40: 5b30 5d0d 0a20 2020 2020 2020 2073 6861  [0]..        sha
-00013e50: 7065 203d 206c 6973 7428 7370 6563 302e  pe = list(spec0.
-00013e60: 7368 6170 6529 0d0a 2020 2020 2020 2020  shape)..        
-00013e70: 6465 7669 6365 203d 2073 7065 6330 2e64  device = spec0.d
-00013e80: 6576 6963 650d 0a20 2020 2020 2020 2073  evice..        s
-00013e90: 6861 7065 5b73 656c 662e 6469 6d5d 203d  hape[self.dim] =
-00013ea0: 2073 756d 5f73 6861 7065 0d0a 2020 2020   sum_shape..    
-00013eb0: 2020 2020 7368 6170 6520 3d20 746f 7263      shape = torc
-00013ec0: 682e 5369 7a65 2873 6861 7065 290d 0a20  h.Size(shape).. 
-00013ed0: 2020 2020 2020 206f 6273 6572 7661 7469         observati
-00013ee0: 6f6e 5f73 7065 635b 6f75 745f 6b65 795d  on_spec[out_key]
-00013ef0: 203d 2055 6e62 6f75 6e64 6564 436f 6e74   = UnboundedCont
-00013f00: 696e 756f 7573 5465 6e73 6f72 5370 6563  inuousTensorSpec
-00013f10: 280d 0a20 2020 2020 2020 2020 2020 2073  (..            s
-00013f20: 6861 7065 3d73 6861 7065 2c0d 0a20 2020  hape=shape,..   
-00013f30: 2020 2020 2020 2020 2064 7479 7065 3d73           dtype=s
-00013f40: 7065 6330 2e64 7479 7065 2c0d 0a20 2020  pec0.dtype,..   
-00013f50: 2020 2020 2020 2020 2064 6576 6963 653d           device=
-00013f60: 6465 7669 6365 2c0d 0a20 2020 2020 2020  device,..       
-00013f70: 2029 0d0a 2020 2020 2020 2020 6966 2073   )..        if s
-00013f80: 656c 662e 5f64 656c 5f6b 6579 733a 0d0a  elf._del_keys:..
-00013f90: 2020 2020 2020 2020 2020 2020 666f 7220              for 
-00013fa0: 6b65 7920 696e 2073 656c 662e 6b65 7973  key in self.keys
-00013fb0: 5f74 6f5f 6578 636c 7564 653a 0d0a 2020  _to_exclude:..  
-00013fc0: 2020 2020 2020 2020 2020 2020 2020 6465                de
-00013fd0: 6c20 6f62 7365 7276 6174 696f 6e5f 7370  l observation_sp
-00013fe0: 6563 5b6b 6579 5d0d 0a20 2020 2020 2020  ec[key]..       
-00013ff0: 2072 6574 7572 6e20 6f62 7365 7276 6174   return observat
-00014000: 696f 6e5f 7370 6563 0d0a 0d0a 2020 2020  ion_spec....    
-00014010: 6465 6620 5f5f 7265 7072 5f5f 2873 656c  def __repr__(sel
-00014020: 6629 202d 3e20 7374 723a 0d0a 2020 2020  f) -> str:..    
-00014030: 2020 2020 7265 7475 726e 2028 0d0a 2020      return (..  
-00014040: 2020 2020 2020 2020 2020 6622 7b73 656c            f"{sel
-00014050: 662e 5f5f 636c 6173 735f 5f2e 5f5f 6e61  f.__class__.__na
-00014060: 6d65 5f5f 7d28 696e 5f6b 6579 733d 7b73  me__}(in_keys={s
-00014070: 656c 662e 696e 5f6b 6579 737d 2c20 6f75  elf.in_keys}, ou
-00014080: 745f 6b65 7922 0d0a 2020 2020 2020 2020  t_key"..        
-00014090: 2020 2020 6622 3d7b 7365 6c66 2e6f 7574      f"={self.out
-000140a0: 5f6b 6579 735b 305d 7d29 220d 0a20 2020  _keys[0]})"..   
-000140b0: 2020 2020 2029 0d0a 0d0a 0d0a 636c 6173       )......clas
-000140c0: 7320 4469 7363 7265 7465 4163 7469 6f6e  s DiscreteAction
-000140d0: 5072 6f6a 6563 7469 6f6e 2854 7261 6e73  Projection(Trans
-000140e0: 666f 726d 293a 0d0a 2020 2020 2222 2250  form):..    """P
-000140f0: 726f 6a65 6374 7320 6469 7363 7265 7465  rojects discrete
-00014100: 2061 6374 696f 6e73 2066 726f 6d20 6120   actions from a 
-00014110: 6869 6768 2064 696d 656e 7369 6f6e 616c  high dimensional
-00014120: 2073 7061 6365 2074 6f20 6120 6c6f 7720   space to a low 
-00014130: 6469 6d65 6e73 696f 6e61 6c20 7370 6163  dimensional spac
-00014140: 652e 0d0a 0d0a 2020 2020 4769 7665 6e20  e.....    Given 
-00014150: 6120 6469 7363 7265 7465 2061 6374 696f  a discrete actio
-00014160: 6e20 2866 726f 6d20 3120 746f 204e 2920  n (from 1 to N) 
-00014170: 656e 636f 6465 6420 6173 2061 206f 6e65  encoded as a one
-00014180: 2d68 6f74 2076 6563 746f 7220 616e 6420  -hot vector and 
-00014190: 610d 0a20 2020 206d 6178 696d 756d 2061  a..    maximum a
-000141a0: 6374 696f 6e20 696e 6465 7820 6e75 6d5f  ction index num_
-000141b0: 6163 7469 6f6e 7320 2877 6974 6820 6e75  actions (with nu
-000141c0: 6d5f 6163 7469 6f6e 7320 3c20 4e29 2c20  m_actions < N), 
-000141d0: 7472 616e 7366 6f72 6d73 2074 6865 2061  transforms the a
-000141e0: 6374 696f 6e20 7375 6368 2074 6861 740d  ction such that.
-000141f0: 0a20 2020 2061 6374 696f 6e5f 6f75 7420  .    action_out 
-00014200: 6973 2061 7420 6d6f 7374 206e 756d 5f61  is at most num_a
-00014210: 6374 696f 6e73 2e0d 0a0d 0a20 2020 2049  ctions.....    I
-00014220: 6620 7468 6520 696e 7075 7420 6163 7469  f the input acti
-00014230: 6f6e 2069 7320 3e20 6e75 6d5f 6163 7469  on is > num_acti
-00014240: 6f6e 732c 2069 7420 6973 2062 6569 6e67  ons, it is being
-00014250: 2072 6570 6c61 6365 6420 6279 2061 2072   replaced by a r
-00014260: 616e 646f 6d20 7661 6c75 650d 0a20 2020  andom value..   
-00014270: 2062 6574 7765 656e 2030 2061 6e64 206e   between 0 and n
-00014280: 756d 5f61 6374 696f 6e73 2d31 2e20 4f74  um_actions-1. Ot
-00014290: 6865 7277 6973 6520 7468 6520 7361 6d65  herwise the same
-000142a0: 2061 6374 696f 6e20 6973 206b 6570 742e   action is kept.
-000142b0: 0d0a 2020 2020 5468 6973 2069 7320 696e  ..    This is in
-000142c0: 7465 6e64 6564 2074 6f20 6265 2075 7365  tended to be use
-000142d0: 6420 7769 7468 2070 6f6c 6963 6965 7320  d with policies 
-000142e0: 6170 706c 6965 6420 6f76 6572 206d 756c  applied over mul
-000142f0: 7469 706c 6520 6469 7363 7265 7465 0d0a  tiple discrete..
-00014300: 2020 2020 636f 6e74 726f 6c20 656e 7669      control envi
-00014310: 726f 6e6d 656e 7473 2077 6974 6820 6469  ronments with di
-00014320: 6666 6572 656e 7420 6163 7469 6f6e 2073  fferent action s
-00014330: 7061 6365 2e0d 0a0d 0a20 2020 2041 2063  pace.....    A c
-00014340: 616c 6c20 746f 2044 6973 6372 6574 6541  all to DiscreteA
-00014350: 6374 696f 6e50 726f 6a65 6374 696f 6e2e  ctionProjection.
-00014360: 666f 7277 6172 6420 2865 6720 6672 6f6d  forward (eg from
-00014370: 2061 2072 6570 6c61 7920 6275 6666 6572   a replay buffer
-00014380: 206f 7220 696e 2061 0d0a 2020 2020 7365   or in a..    se
-00014390: 7175 656e 6365 206f 6620 6e6e 2e4d 6f64  quence of nn.Mod
-000143a0: 756c 6573 2920 7769 6c6c 2063 616c 6c20  ules) will call 
-000143b0: 7468 6520 7472 616e 7366 6f72 6d20 6e75  the transform nu
-000143c0: 6d5f 6163 7469 6f6e 735f 6566 6665 6374  m_actions_effect
-000143d0: 6976 6520 2d3e 206d 6178 5f61 6374 696f  ive -> max_actio
-000143e0: 6e73 0d0a 2020 2020 6f6e 2074 6865 203a  ns..    on the :
-000143f0: 6f62 6a3a 6022 696e 5f6b 6579 7322 602c  obj:`"in_keys"`,
-00014400: 2077 6865 7265 6173 2061 2063 616c 6c20   whereas a call 
-00014410: 746f 205f 6361 6c6c 2077 696c 6c20 6265  to _call will be
-00014420: 2069 676e 6f72 6564 2e20 496e 6465 6564   ignored. Indeed
-00014430: 2c0d 0a20 2020 2074 7261 6e73 666f 726d  ,..    transform
-00014440: 6564 2065 6e76 7320 6172 6520 696e 7374  ed envs are inst
-00014450: 7275 6374 6564 2074 6f20 7570 6461 7465  ructed to update
-00014460: 2074 6865 2069 6e70 7574 206b 6579 7320   the input keys 
-00014470: 6f6e 6c79 2066 6f72 2074 6865 2069 6e6e  only for the inn
-00014480: 6572 0d0a 2020 2020 6261 7365 5f65 6e76  er..    base_env
-00014490: 2c20 6275 7420 7468 6520 6f72 6967 696e  , but the origin
-000144a0: 616c 2069 6e70 7574 206b 6579 7320 7769  al input keys wi
-000144b0: 6c6c 2072 656d 6169 6e20 756e 6368 616e  ll remain unchan
-000144c0: 6765 642e 0d0a 0d0a 2020 2020 4172 6773  ged.....    Args
-000144d0: 3a0d 0a20 2020 2020 2020 206e 756d 5f61  :..        num_a
-000144e0: 6374 696f 6e73 5f65 6666 6563 7469 7665  ctions_effective
-000144f0: 2028 696e 7429 3a20 6d61 7820 6e75 6d62   (int): max numb
-00014500: 6572 206f 6620 6163 7469 6f6e 2063 6f6e  er of action con
-00014510: 7369 6465 7265 642e 0d0a 2020 2020 2020  sidered...      
-00014520: 2020 6d61 785f 6163 7469 6f6e 7320 2869    max_actions (i
-00014530: 6e74 293a 206d 6178 696d 756d 206e 756d  nt): maximum num
-00014540: 6265 7220 6f66 2061 6374 696f 6e73 2074  ber of actions t
-00014550: 6861 7420 7468 6973 206d 6f64 756c 6520  hat this module 
-00014560: 6361 6e20 7265 6164 2e0d 0a20 2020 2020  can read...     
-00014570: 2020 2061 6374 696f 6e5f 6b65 7920 2873     action_key (s
-00014580: 7472 2c20 6f70 7469 6f6e 616c 293a 206b  tr, optional): k
-00014590: 6579 206e 616d 6520 6f66 2074 6865 2061  ey name of the a
-000145a0: 6374 696f 6e2e 2044 6566 6175 6c74 7320  ction. Defaults 
-000145b0: 746f 2022 6163 7469 6f6e 222e 0d0a 2020  to "action"...  
-000145c0: 2020 2020 2020 696e 636c 7564 655f 666f        include_fo
-000145d0: 7277 6172 6420 2862 6f6f 6c2c 206f 7074  rward (bool, opt
-000145e0: 696f 6e61 6c29 3a20 6966 2054 7275 652c  ional): if True,
-000145f0: 2061 2063 616c 6c20 746f 2066 6f72 7761   a call to forwa
-00014600: 7264 2077 696c 6c20 616c 736f 0d0a 2020  rd will also..  
-00014610: 2020 2020 2020 2020 2020 6d61 7020 7468            map th
-00014620: 6520 6163 7469 6f6e 2066 726f 6d20 6f6e  e action from on
-00014630: 6520 646f 6d61 696e 2074 6f20 7468 6520  e domain to the 
-00014640: 6f74 6865 7220 7768 656e 2074 6865 206d  other when the m
-00014650: 6f64 756c 6520 6973 2063 616c 6c65 640d  odule is called.
-00014660: 0a20 2020 2020 2020 2020 2020 2062 7920  .            by 
-00014670: 6120 7265 706c 6179 2062 7566 6665 7220  a replay buffer 
-00014680: 6f72 2061 6e20 6e6e 2e4d 6f64 756c 6520  or an nn.Module 
-00014690: 6368 6169 6e2e 2044 6566 6175 6c74 7320  chain. Defaults 
-000146a0: 746f 2054 7275 652e 0d0a 0d0a 2020 2020  to True.....    
-000146b0: 4578 616d 706c 6573 3a0d 0a20 2020 2020  Examples:..     
-000146c0: 2020 203e 3e3e 2074 6f72 6368 2e6d 616e     >>> torch.man
-000146d0: 7561 6c5f 7365 6564 2830 290d 0a20 2020  ual_seed(0)..   
-000146e0: 2020 2020 203e 3e3e 204e 203d 2033 0d0a       >>> N = 3..
-000146f0: 2020 2020 2020 2020 3e3e 3e20 4d20 3d20          >>> M = 
-00014700: 320d 0a20 2020 2020 2020 203e 3e3e 2061  2..        >>> a
-00014710: 6374 696f 6e20 3d20 746f 7263 682e 7a65  ction = torch.ze
-00014720: 726f 7328 4e2c 2064 7479 7065 3d74 6f72  ros(N, dtype=tor
-00014730: 6368 2e6c 6f6e 6729 0d0a 2020 2020 2020  ch.long)..      
-00014740: 2020 3e3e 3e20 6163 7469 6f6e 5b2d 315d    >>> action[-1]
-00014750: 203d 2031 0d0a 2020 2020 2020 2020 3e3e   = 1..        >>
-00014760: 3e20 7464 203d 2054 656e 736f 7244 6963  > td = TensorDic
-00014770: 7428 7b22 6163 7469 6f6e 223a 2061 6374  t({"action": act
-00014780: 696f 6e7d 2c20 5b5d 290d 0a20 2020 2020  ion}, [])..     
-00014790: 2020 203e 3e3e 2074 7261 6e73 666f 726d     >>> transform
-000147a0: 203d 2044 6973 6372 6574 6541 6374 696f   = DiscreteActio
-000147b0: 6e50 726f 6a65 6374 696f 6e28 6e75 6d5f  nProjection(num_
-000147c0: 6163 7469 6f6e 735f 6566 6665 6374 6976  actions_effectiv
-000147d0: 653d 4d2c 206d 6178 5f61 6374 696f 6e73  e=M, max_actions
-000147e0: 3d4e 290d 0a20 2020 2020 2020 203e 3e3e  =N)..        >>>
-000147f0: 205f 203d 2074 7261 6e73 666f 726d 2e69   _ = transform.i
-00014800: 6e76 2874 6429 0d0a 2020 2020 2020 2020  nv(td)..        
-00014810: 3e3e 3e20 7072 696e 7428 7464 2e67 6574  >>> print(td.get
-00014820: 2822 6163 7469 6f6e 2229 290d 0a20 2020  ("action"))..   
-00014830: 2020 2020 2074 656e 736f 7228 5b31 5d29       tensor([1])
-00014840: 0d0a 2020 2020 2222 220d 0a0d 0a20 2020  ..    """....   
-00014850: 2064 6566 205f 5f69 6e69 745f 5f28 0d0a   def __init__(..
-00014860: 2020 2020 2020 2020 7365 6c66 2c0d 0a20          self,.. 
-00014870: 2020 2020 2020 206e 756d 5f61 6374 696f         num_actio
-00014880: 6e73 5f65 6666 6563 7469 7665 3a20 696e  ns_effective: in
-00014890: 742c 0d0a 2020 2020 2020 2020 6d61 785f  t,..        max_
-000148a0: 6163 7469 6f6e 733a 2069 6e74 2c0d 0a20  actions: int,.. 
-000148b0: 2020 2020 2020 2061 6374 696f 6e5f 6b65         action_ke
-000148c0: 793a 2073 7472 203d 2022 6163 7469 6f6e  y: str = "action
-000148d0: 222c 0d0a 2020 2020 2020 2020 696e 636c  ",..        incl
-000148e0: 7564 655f 666f 7277 6172 643a 2062 6f6f  ude_forward: boo
-000148f0: 6c20 3d20 5472 7565 2c0d 0a20 2020 2029  l = True,..    )
-00014900: 3a0d 0a20 2020 2020 2020 2069 6e5f 6b65  :..        in_ke
-00014910: 7973 5f69 6e76 203d 205b 6163 7469 6f6e  ys_inv = [action
-00014920: 5f6b 6579 5d0d 0a20 2020 2020 2020 2069  _key]..        i
-00014930: 6620 696e 636c 7564 655f 666f 7277 6172  f include_forwar
-00014940: 643a 0d0a 2020 2020 2020 2020 2020 2020  d:..            
-00014950: 696e 5f6b 6579 7320 3d20 696e 5f6b 6579  in_keys = in_key
-00014960: 735f 696e 760d 0a20 2020 2020 2020 2065  s_inv..        e
-00014970: 6c73 653a 0d0a 2020 2020 2020 2020 2020  lse:..          
-00014980: 2020 696e 5f6b 6579 7320 3d20 5b5d 0d0a    in_keys = []..
-00014990: 2020 2020 2020 2020 7375 7065 7228 292e          super().
-000149a0: 5f5f 696e 6974 5f5f 280d 0a20 2020 2020  __init__(..     
-000149b0: 2020 2020 2020 2069 6e5f 6b65 7973 3d69         in_keys=i
-000149c0: 6e5f 6b65 7973 2c0d 0a20 2020 2020 2020  n_keys,..       
-000149d0: 2020 2020 206f 7574 5f6b 6579 733d 696e       out_keys=in
-000149e0: 5f6b 6579 732c 0d0a 2020 2020 2020 2020  _keys,..        
-000149f0: 2020 2020 696e 5f6b 6579 735f 696e 763d      in_keys_inv=
-00014a00: 696e 5f6b 6579 735f 696e 762c 0d0a 2020  in_keys_inv,..  
-00014a10: 2020 2020 2020 2020 2020 6f75 745f 6b65            out_ke
-00014a20: 7973 5f69 6e76 3d69 6e5f 6b65 7973 5f69  ys_inv=in_keys_i
-00014a30: 6e76 2c0d 0a20 2020 2020 2020 2029 0d0a  nv,..        )..
-00014a40: 2020 2020 2020 2020 7365 6c66 2e6e 756d          self.num
-00014a50: 5f61 6374 696f 6e73 5f65 6666 6563 7469  _actions_effecti
-00014a60: 7665 203d 206e 756d 5f61 6374 696f 6e73  ve = num_actions
-00014a70: 5f65 6666 6563 7469 7665 0d0a 2020 2020  _effective..    
-00014a80: 2020 2020 7365 6c66 2e6d 6178 5f61 6374      self.max_act
-00014a90: 696f 6e73 203d 206d 6178 5f61 6374 696f  ions = max_actio
-00014aa0: 6e73 0d0a 2020 2020 2020 2020 6966 206d  ns..        if m
-00014ab0: 6178 5f61 6374 696f 6e73 203c 206e 756d  ax_actions < num
-00014ac0: 5f61 6374 696f 6e73 5f65 6666 6563 7469  _actions_effecti
-00014ad0: 7665 3a0d 0a20 2020 2020 2020 2020 2020  ve:..           
-00014ae0: 2072 6169 7365 2052 756e 7469 6d65 4572   raise RuntimeEr
-00014af0: 726f 7228 0d0a 2020 2020 2020 2020 2020  ror(..          
-00014b00: 2020 2020 2020 2254 6865 2060 6d61 785f        "The `max_
-00014b10: 6163 7469 6f6e 7360 2069 6e74 206d 7573  actions` int mus
-00014b20: 7420 6265 2067 7265 6174 6572 206f 7220  t be greater or 
-00014b30: 6571 7561 6c20 746f 2060 6e75 6d5f 6163  equal to `num_ac
-00014b40: 7469 6f6e 735f 6566 6665 6374 6976 6560  tions_effective`
-00014b50: 2e22 0d0a 2020 2020 2020 2020 2020 2020  ."..            
-00014b60: 290d 0a0d 0a20 2020 2064 6566 205f 6361  )....    def _ca
-00014b70: 6c6c 2873 656c 662c 2074 656e 736f 7264  ll(self, tensord
-00014b80: 6963 743a 2054 656e 736f 7244 6963 7442  ict: TensorDictB
-00014b90: 6173 6529 202d 3e20 5465 6e73 6f72 4469  ase) -> TensorDi
-00014ba0: 6374 4261 7365 3a0d 0a20 2020 2020 2020  ctBase:..       
-00014bb0: 2023 2057 6520 646f 6e27 7420 646f 2061   # We don't do a
-00014bc0: 6e79 7468 696e 6720 6865 7265 2062 6563  nything here bec
-00014bd0: 6175 7365 2074 6865 2061 6374 696f 6e20  ause the action 
-00014be0: 6973 206d 6f64 6966 6965 6420 6279 2074  is modified by t
-00014bf0: 6865 2069 6e76 0d0a 2020 2020 2020 2020  he inv..        
-00014c00: 2320 6d65 7468 6f64 2062 7574 2077 6520  # method but we 
-00014c10: 646f 6e27 7420 6e65 6564 2074 6f20 6d61  don't need to ma
-00014c20: 7020 6974 2062 6163 6b20 6173 2069 7420  p it back as it 
-00014c30: 776f 6e27 7420 6265 2075 7064 6174 6564  won't be updated
-00014c40: 2069 6e20 7468 6520 6f72 6967 696e 616c   in the original
-00014c50: 0d0a 2020 2020 2020 2020 2320 7465 6e73  ..        # tens
-00014c60: 6f72 6469 6374 0d0a 2020 2020 2020 2020  ordict..        
-00014c70: 7265 7475 726e 2074 656e 736f 7264 6963  return tensordic
-00014c80: 740d 0a0d 0a20 2020 2064 6566 205f 6170  t....    def _ap
-00014c90: 706c 795f 7472 616e 7366 6f72 6d28 7365  ply_transform(se
-00014ca0: 6c66 2c20 6163 7469 6f6e 3a20 746f 7263  lf, action: torc
-00014cb0: 682e 5465 6e73 6f72 2920 2d3e 204e 6f6e  h.Tensor) -> Non
-00014cc0: 653a 0d0a 2020 2020 2020 2020 2320 5765  e:..        # We
-00014cd0: 2073 7469 6c6c 206e 6565 6420 746f 2063   still need to c
-00014ce0: 6f64 6520 7468 6520 666f 7277 6172 6420  ode the forward 
-00014cf0: 7472 616e 7366 6f72 6d20 666f 7220 7265  transform for re
-00014d00: 706c 6179 2062 7566 6665 7273 2061 6e64  play buffers and
-00014d10: 206d 6f64 656c 730d 0a20 2020 2020 2020   models..       
-00014d20: 2061 6374 696f 6e20 3d20 6163 7469 6f6e   action = action
-00014d30: 2e61 7267 6d61 7828 2d31 2920 2023 2062  .argmax(-1)  # b
-00014d40: 6f6f 6c20 746f 2069 6e74 0d0a 2020 2020  ool to int..    
-00014d50: 2020 2020 6163 7469 6f6e 203d 206e 6e2e      action = nn.
-00014d60: 6675 6e63 7469 6f6e 616c 2e6f 6e65 5f68  functional.one_h
-00014d70: 6f74 2861 6374 696f 6e2c 2073 656c 662e  ot(action, self.
-00014d80: 6d61 785f 6163 7469 6f6e 7329 0d0a 2020  max_actions)..  
-00014d90: 2020 2020 2020 7265 7475 726e 2061 6374        return act
-00014da0: 696f 6e0d 0a0d 0a20 2020 2064 6566 205f  ion....    def _
-00014db0: 696e 765f 6170 706c 795f 7472 616e 7366  inv_apply_transf
-00014dc0: 6f72 6d28 7365 6c66 2c20 6163 7469 6f6e  orm(self, action
-00014dd0: 3a20 746f 7263 682e 5465 6e73 6f72 2920  : torch.Tensor) 
-00014de0: 2d3e 2074 6f72 6368 2e54 656e 736f 723a  -> torch.Tensor:
-00014df0: 0d0a 2020 2020 2020 2020 6966 2061 6374  ..        if act
-00014e00: 696f 6e2e 7368 6170 655b 2d31 5d20 213d  ion.shape[-1] !=
-00014e10: 2073 656c 662e 6d61 785f 6163 7469 6f6e   self.max_action
-00014e20: 733a 0d0a 2020 2020 2020 2020 2020 2020  s:..            
-00014e30: 7261 6973 6520 5275 6e74 696d 6545 7272  raise RuntimeErr
-00014e40: 6f72 280d 0a20 2020 2020 2020 2020 2020  or(..           
-00014e50: 2020 2020 2066 2261 6374 696f 6e2e 7368       f"action.sh
-00014e60: 6170 655b 2d31 5d3d 7b61 6374 696f 6e2e  ape[-1]={action.
-00014e70: 7368 6170 655b 2d31 5d7d 206d 7573 7420  shape[-1]} must 
-00014e80: 6d61 7463 6820 7365 6c66 2e6d 6178 5f61  match self.max_a
-00014e90: 6374 696f 6e73 3d7b 7365 6c66 2e6d 6178  ctions={self.max
-00014ea0: 5f61 6374 696f 6e73 7d2e 220d 0a20 2020  _actions}."..   
-00014eb0: 2020 2020 2020 2020 2029 0d0a 2020 2020           )..    
-00014ec0: 2020 2020 6163 7469 6f6e 203d 2061 6374      action = act
-00014ed0: 696f 6e2e 6172 676d 6178 282d 3129 2020  ion.argmax(-1)  
-00014ee0: 2320 626f 6f6c 2074 6f20 696e 740d 0a20  # bool to int.. 
-00014ef0: 2020 2020 2020 2069 6478 203d 2061 6374         idx = act
-00014f00: 696f 6e20 3e3d 2073 656c 662e 6e75 6d5f  ion >= self.num_
-00014f10: 6163 7469 6f6e 735f 6566 6665 6374 6976  actions_effectiv
-00014f20: 650d 0a20 2020 2020 2020 2069 6620 6964  e..        if id
-00014f30: 782e 616e 7928 293a 0d0a 2020 2020 2020  x.any():..      
-00014f40: 2020 2020 2020 6163 7469 6f6e 5b69 6478        action[idx
-00014f50: 5d20 3d20 746f 7263 682e 7261 6e64 696e  ] = torch.randin
-00014f60: 7428 7365 6c66 2e6e 756d 5f61 6374 696f  t(self.num_actio
-00014f70: 6e73 5f65 6666 6563 7469 7665 2c20 2869  ns_effective, (i
-00014f80: 6478 2e73 756d 2829 2c29 290d 0a20 2020  dx.sum(),))..   
-00014f90: 2020 2020 2061 6374 696f 6e20 3d20 6e6e       action = nn
-00014fa0: 2e66 756e 6374 696f 6e61 6c2e 6f6e 655f  .functional.one_
-00014fb0: 686f 7428 6163 7469 6f6e 2c20 7365 6c66  hot(action, self
-00014fc0: 2e6e 756d 5f61 6374 696f 6e73 5f65 6666  .num_actions_eff
-00014fd0: 6563 7469 7665 290d 0a20 2020 2020 2020  ective)..       
-00014fe0: 2072 6574 7572 6e20 6163 7469 6f6e 0d0a   return action..
-00014ff0: 0d0a 2020 2020 6465 6620 7472 616e 7366  ..    def transf
-00015000: 6f72 6d5f 696e 7075 745f 7370 6563 2873  orm_input_spec(s
-00015010: 656c 662c 2069 6e70 7574 5f73 7065 633a  elf, input_spec:
-00015020: 2043 6f6d 706f 7369 7465 5370 6563 293a   CompositeSpec):
-00015030: 0d0a 2020 2020 2020 2020 696e 7075 745f  ..        input_
-00015040: 7370 6563 203d 2069 6e70 7574 5f73 7065  spec = input_spe
-00015050: 632e 636c 6f6e 6528 290d 0a20 2020 2020  c.clone()..     
-00015060: 2020 2069 6e70 7574 5f73 7065 635b 2261     input_spec["a
-00015070: 6374 696f 6e22 5d20 3d20 4f6e 6548 6f74  ction"] = OneHot
-00015080: 4469 7363 7265 7465 5465 6e73 6f72 5370  DiscreteTensorSp
-00015090: 6563 280d 0a20 2020 2020 2020 2020 2020  ec(..           
-000150a0: 2073 656c 662e 6d61 785f 6163 7469 6f6e   self.max_action
-000150b0: 732c 0d0a 2020 2020 2020 2020 2020 2020  s,..            
-000150c0: 7368 6170 653d 282a 696e 7075 745f 7370  shape=(*input_sp
-000150d0: 6563 5b22 6163 7469 6f6e 225d 2e73 6861  ec["action"].sha
-000150e0: 7065 5b3a 2d31 5d2c 2073 656c 662e 6d61  pe[:-1], self.ma
-000150f0: 785f 6163 7469 6f6e 7329 2c0d 0a20 2020  x_actions),..   
-00015100: 2020 2020 2020 2020 2064 6576 6963 653d           device=
-00015110: 696e 7075 745f 7370 6563 2e64 6576 6963  input_spec.devic
-00015120: 652c 0d0a 2020 2020 2020 2020 2020 2020  e,..            
-00015130: 6474 7970 653d 696e 7075 745f 7370 6563  dtype=input_spec
-00015140: 5b22 6163 7469 6f6e 225d 2e64 7479 7065  ["action"].dtype
-00015150: 2c0d 0a20 2020 2020 2020 2029 0d0a 2020  ,..        )..  
-00015160: 2020 2020 2020 7265 7475 726e 2069 6e70        return inp
-00015170: 7574 5f73 7065 630d 0a0d 0a20 2020 2064  ut_spec....    d
-00015180: 6566 205f 5f72 6570 725f 5f28 7365 6c66  ef __repr__(self
-00015190: 2920 2d3e 2073 7472 3a0d 0a20 2020 2020  ) -> str:..     
-000151a0: 2020 2072 6574 7572 6e20 280d 0a20 2020     return (..   
-000151b0: 2020 2020 2020 2020 2066 227b 7365 6c66           f"{self
-000151c0: 2e5f 5f63 6c61 7373 5f5f 2e5f 5f6e 616d  .__class__.__nam
-000151d0: 655f 5f7d 286e 756d 5f61 6374 696f 6e73  e__}(num_actions
-000151e0: 5f65 6666 6563 7469 7665 3d7b 7365 6c66  _effective={self
-000151f0: 2e6e 756d 5f61 6374 696f 6e73 5f65 6666  .num_actions_eff
-00015200: 6563 7469 7665 7d2c 206d 6178 5f61 6374  ective}, max_act
-00015210: 696f 6e73 3d7b 7365 6c66 2e6d 6178 5f61  ions={self.max_a
-00015220: 6374 696f 6e73 7d2c 2022 0d0a 2020 2020  ctions}, "..    
-00015230: 2020 2020 2020 2020 6622 696e 5f6b 6579          f"in_key
-00015240: 735f 696e 763d 7b73 656c 662e 696e 5f6b  s_inv={self.in_k
-00015250: 6579 735f 696e 767d 2922 0d0a 2020 2020  eys_inv})"..    
-00015260: 2020 2020 290d 0a0d 0a0d 0a63 6c61 7373      )......class
-00015270: 2046 7261 6d65 536b 6970 5472 616e 7366   FrameSkipTransf
-00015280: 6f72 6d28 5472 616e 7366 6f72 6d29 3a0d  orm(Transform):.
-00015290: 0a20 2020 2022 2222 4120 6672 616d 652d  .    """A frame-
-000152a0: 736b 6970 2074 7261 6e73 666f 726d 2e0d  skip transform..
-000152b0: 0a0d 0a20 2020 2054 6869 7320 7472 616e  ...    This tran
-000152c0: 7366 6f72 6d20 6170 706c 6965 7320 7468  sform applies th
-000152d0: 6520 7361 6d65 2061 6374 696f 6e20 7265  e same action re
-000152e0: 7065 6174 6564 6c79 2069 6e20 7468 6520  peatedly in the 
-000152f0: 7061 7265 6e74 2065 6e76 6972 6f6e 6d65  parent environme
-00015300: 6e74 2c0d 0a20 2020 2077 6869 6368 2069  nt,..    which i
-00015310: 6d70 726f 7665 7320 7374 6162 696c 6974  mproves stabilit
-00015320: 7920 6f6e 2063 6572 7461 696e 2074 7261  y on certain tra
-00015330: 696e 696e 6720 616c 676f 7269 7468 6d73  ining algorithms
-00015340: 2e0d 0a0d 0a20 2020 2041 7267 733a 0d0a  .....    Args:..
-00015350: 2020 2020 2020 2020 6672 616d 655f 736b          frame_sk
-00015360: 6970 2028 696e 742c 206f 7074 696f 6e61  ip (int, optiona
-00015370: 6c29 3a20 6120 706f 7369 7469 7665 2069  l): a positive i
-00015380: 6e74 6567 6572 2072 6570 7265 7365 6e74  nteger represent
-00015390: 696e 6720 7468 6520 6e75 6d62 6572 0d0a  ing the number..
-000153a0: 2020 2020 2020 2020 2020 2020 6f66 2066              of f
-000153b0: 7261 6d65 7320 6475 7269 6e67 2077 6869  rames during whi
-000153c0: 6368 2074 6865 2073 616d 6520 6163 7469  ch the same acti
-000153d0: 6f6e 206d 7573 7420 6265 2061 7070 6c69  on must be appli
-000153e0: 6564 2e0d 0a0d 0a20 2020 2022 2222 0d0a  ed.....    """..
-000153f0: 0d0a 2020 2020 6465 6620 5f5f 696e 6974  ..    def __init
-00015400: 5f5f 2873 656c 662c 2066 7261 6d65 5f73  __(self, frame_s
-00015410: 6b69 703a 2069 6e74 203d 2031 293a 0d0a  kip: int = 1):..
-00015420: 2020 2020 2020 2020 7375 7065 7228 292e          super().
-00015430: 5f5f 696e 6974 5f5f 285b 5d29 0d0a 2020  __init__([])..  
-00015440: 2020 2020 2020 6966 2066 7261 6d65 5f73        if frame_s
-00015450: 6b69 7020 3c20 313a 0d0a 2020 2020 2020  kip < 1:..      
-00015460: 2020 2020 2020 7261 6973 6520 5661 6c75        raise Valu
-00015470: 6545 7272 6f72 2822 6672 616d 655f 736b  eError("frame_sk
-00015480: 6970 2073 686f 756c 6420 6861 7665 2061  ip should have a
-00015490: 2076 616c 7565 2067 7265 6174 6572 206f   value greater o
-000154a0: 7220 6571 7561 6c20 746f 206f 6e65 2e22  r equal to one."
-000154b0: 290d 0a20 2020 2020 2020 2073 656c 662e  )..        self.
-000154c0: 6672 616d 655f 736b 6970 203d 2066 7261  frame_skip = fra
-000154d0: 6d65 5f73 6b69 700d 0a0d 0a20 2020 2064  me_skip....    d
-000154e0: 6566 205f 7374 6570 2873 656c 662c 2074  ef _step(self, t
-000154f0: 656e 736f 7264 6963 743a 2054 656e 736f  ensordict: Tenso
-00015500: 7244 6963 7442 6173 6529 202d 3e20 5465  rDictBase) -> Te
-00015510: 6e73 6f72 4469 6374 4261 7365 3a0d 0a20  nsorDictBase:.. 
-00015520: 2020 2020 2020 2070 6172 656e 7420 3d20         parent = 
-00015530: 7365 6c66 2e70 6172 656e 740d 0a20 2020  self.parent..   
-00015540: 2020 2020 2069 6620 7061 7265 6e74 2069       if parent i
-00015550: 7320 4e6f 6e65 3a0d 0a20 2020 2020 2020  s None:..       
-00015560: 2020 2020 2072 6169 7365 2052 756e 7469       raise Runti
-00015570: 6d65 4572 726f 7228 2270 6172 656e 7420  meError("parent 
-00015580: 6e6f 7420 666f 756e 6420 666f 7220 4672  not found for Fr
-00015590: 616d 6553 6b69 7054 7261 6e73 666f 726d  ameSkipTransform
-000155a0: 2229 0d0a 2020 2020 2020 2020 7265 7761  ")..        rewa
-000155b0: 7264 203d 2074 656e 736f 7264 6963 742e  rd = tensordict.
-000155c0: 6765 7428 2822 6e65 7874 222c 2022 7265  get(("next", "re
-000155d0: 7761 7264 2229 290d 0a20 2020 2020 2020  ward"))..       
-000155e0: 2066 6f72 205f 2069 6e20 7261 6e67 6528   for _ in range(
-000155f0: 7365 6c66 2e66 7261 6d65 5f73 6b69 7020  self.frame_skip 
-00015600: 2d20 3129 3a0d 0a20 2020 2020 2020 2020  - 1):..         
-00015610: 2020 2074 656e 736f 7264 6963 7420 3d20     tensordict = 
-00015620: 7061 7265 6e74 2e5f 7374 6570 2874 656e  parent._step(ten
-00015630: 736f 7264 6963 7429 0d0a 2020 2020 2020  sordict)..      
-00015640: 2020 2020 2020 7265 7761 7264 203d 2072        reward = r
-00015650: 6577 6172 6420 2b20 7465 6e73 6f72 6469  eward + tensordi
-00015660: 6374 2e67 6574 2828 226e 6578 7422 2c20  ct.get(("next", 
-00015670: 2272 6577 6172 6422 2929 0d0a 2020 2020  "reward"))..    
-00015680: 2020 2020 7265 7475 726e 2074 656e 736f      return tenso
-00015690: 7264 6963 742e 7365 7428 2822 6e65 7874  rdict.set(("next
-000156a0: 222c 2022 7265 7761 7264 2229 2c20 7265  ", "reward"), re
-000156b0: 7761 7264 290d 0a0d 0a20 2020 2064 6566  ward)....    def
-000156c0: 2066 6f72 7761 7264 2873 656c 662c 2074   forward(self, t
-000156d0: 656e 736f 7264 6963 7429 3a0d 0a20 2020  ensordict):..   
-000156e0: 2020 2020 2072 6169 7365 2052 756e 7469       raise Runti
-000156f0: 6d65 4572 726f 7228 0d0a 2020 2020 2020  meError(..      
-00015700: 2020 2020 2020 2246 7261 6d65 536b 6970        "FrameSkip
-00015710: 5472 616e 7366 6f72 6d20 6361 6e20 6f6e  Transform can on
-00015720: 6c79 2062 6520 7573 6564 2077 6865 6e20  ly be used when 
-00015730: 6170 7065 6e64 6564 2074 6f20 6120 7472  appended to a tr
-00015740: 616e 7366 6f72 6d65 6420 656e 762e 220d  ansformed env.".
-00015750: 0a20 2020 2020 2020 2029 0d0a 0d0a 0d0a  .        )......
-00015760: 636c 6173 7320 4e6f 6f70 5265 7365 7445  class NoopResetE
-00015770: 6e76 2854 7261 6e73 666f 726d 293a 0d0a  nv(Transform):..
-00015780: 2020 2020 2222 2252 756e 7320 6120 7365      """Runs a se
-00015790: 7269 6573 206f 6620 7261 6e64 6f6d 2061  ries of random a
-000157a0: 6374 696f 6e73 2077 6865 6e20 616e 2065  ctions when an e
-000157b0: 6e76 6972 6f6e 6d65 6e74 2069 7320 7265  nvironment is re
-000157c0: 7365 742e 0d0a 0d0a 2020 2020 4172 6773  set.....    Args
-000157d0: 3a0d 0a20 2020 2020 2020 2065 6e76 2028  :..        env (
-000157e0: 456e 7642 6173 6529 3a20 656e 7620 6f6e  EnvBase): env on
-000157f0: 2077 6869 6368 2074 6865 2072 616e 646f   which the rando
-00015800: 6d20 6163 7469 6f6e 7320 6861 7665 2074  m actions have t
-00015810: 6f20 6265 0d0a 2020 2020 2020 2020 2020  o be..          
-00015820: 2020 7065 7266 6f72 6d65 642e 2043 616e    performed. Can
-00015830: 2062 6520 7468 6520 7361 6d65 2065 6e76   be the same env
-00015840: 2061 7320 7468 6520 6f6e 6520 7072 6f76   as the one prov
-00015850: 6964 6564 2074 6f20 7468 650d 0a20 2020  ided to the..   
-00015860: 2020 2020 2020 2020 2054 7261 6e73 666f           Transfo
-00015870: 726d 6564 456e 7620 636c 6173 730d 0a20  rmedEnv class.. 
-00015880: 2020 2020 2020 206e 6f6f 7073 2028 696e         noops (in
-00015890: 742c 206f 7074 696f 6e61 6c29 3a20 6e75  t, optional): nu
-000158a0: 6d62 6572 206f 6620 6163 7469 6f6e 7320  mber of actions 
-000158b0: 7065 7266 6f72 6d65 6420 6166 7465 7220  performed after 
-000158c0: 7265 7365 742e 0d0a 2020 2020 2020 2020  reset...        
-000158d0: 2020 2020 4465 6661 756c 7420 6973 2060      Default is `
-000158e0: 3330 602e 0d0a 2020 2020 2020 2020 7261  30`...        ra
-000158f0: 6e64 6f6d 2028 626f 6f6c 2c20 6f70 7469  ndom (bool, opti
-00015900: 6f6e 616c 293a 2069 6620 4661 6c73 652c  onal): if False,
-00015910: 2074 6865 206e 756d 6265 7220 6f66 2072   the number of r
-00015920: 616e 646f 6d20 6f70 7320 7769 6c6c 0d0a  andom ops will..
-00015930: 2020 2020 2020 2020 2020 2020 616c 7761              alwa
-00015940: 7973 2062 6520 6571 7561 6c20 746f 2074  ys be equal to t
-00015950: 6865 206e 6f6f 7073 2076 616c 7565 2e20  he noops value. 
-00015960: 4966 2054 7275 652c 2074 6865 206e 756d  If True, the num
-00015970: 6265 7220 6f66 0d0a 2020 2020 2020 2020  ber of..        
-00015980: 2020 2020 7261 6e64 6f6d 2061 6374 696f      random actio
-00015990: 6e73 2077 696c 6c20 6265 2072 616e 646f  ns will be rando
-000159a0: 6d6c 7920 7365 6c65 6374 6564 2062 6574  mly selected bet
-000159b0: 7765 656e 2030 2061 6e64 206e 6f6f 7073  ween 0 and noops
-000159c0: 2e0d 0a20 2020 2020 2020 2020 2020 2044  ...            D
-000159d0: 6566 6175 6c74 2069 7320 6054 7275 6560  efault is `True`
-000159e0: 2e0d 0a0d 0a20 2020 2022 2222 0d0a 0d0a  .....    """....
-000159f0: 2020 2020 6465 6620 5f5f 696e 6974 5f5f      def __init__
-00015a00: 2873 656c 662c 206e 6f6f 7073 3a20 696e  (self, noops: in
-00015a10: 7420 3d20 3330 2c20 7261 6e64 6f6d 3a20  t = 30, random: 
-00015a20: 626f 6f6c 203d 2054 7275 6529 3a0d 0a20  bool = True):.. 
-00015a30: 2020 2020 2020 2022 2222 5361 6d70 6c65         """Sample
-00015a40: 2069 6e69 7469 616c 2073 7461 7465 7320   initial states 
-00015a50: 6279 2074 616b 696e 6720 7261 6e64 6f6d  by taking random
-00015a60: 206e 756d 6265 7220 6f66 206e 6f2d 6f70   number of no-op
-00015a70: 7320 6f6e 2072 6573 6574 2e0d 0a0d 0a20  s on reset..... 
-00015a80: 2020 2020 2020 204e 6f2d 6f70 2069 7320         No-op is 
-00015a90: 6173 7375 6d65 6420 746f 2062 6520 6163  assumed to be ac
-00015aa0: 7469 6f6e 2030 2e0d 0a20 2020 2020 2020  tion 0...       
-00015ab0: 2022 2222 0d0a 2020 2020 2020 2020 7375   """..        su
-00015ac0: 7065 7228 292e 5f5f 696e 6974 5f5f 285b  per().__init__([
-00015ad0: 5d29 0d0a 2020 2020 2020 2020 7365 6c66  ])..        self
-00015ae0: 2e6e 6f6f 7073 203d 206e 6f6f 7073 0d0a  .noops = noops..
-00015af0: 2020 2020 2020 2020 7365 6c66 2e72 616e          self.ran
-00015b00: 646f 6d20 3d20 7261 6e64 6f6d 0d0a 0d0a  dom = random....
-00015b10: 2020 2020 4070 726f 7065 7274 790d 0a20      @property.. 
-00015b20: 2020 2064 6566 2062 6173 655f 656e 7628     def base_env(
-00015b30: 7365 6c66 293a 0d0a 2020 2020 2020 2020  self):..        
-00015b40: 7265 7475 726e 2073 656c 662e 7061 7265  return self.pare
-00015b50: 6e74 0d0a 0d0a 2020 2020 6465 6620 7265  nt....    def re
-00015b60: 7365 7428 7365 6c66 2c20 7465 6e73 6f72  set(self, tensor
-00015b70: 6469 6374 3a20 5465 6e73 6f72 4469 6374  dict: TensorDict
-00015b80: 4261 7365 2920 2d3e 2054 656e 736f 7244  Base) -> TensorD
-00015b90: 6963 7442 6173 653a 0d0a 2020 2020 2020  ictBase:..      
-00015ba0: 2020 2222 2244 6f20 6e6f 2d6f 7020 6163    """Do no-op ac
-00015bb0: 7469 6f6e 2066 6f72 2061 206e 756d 6265  tion for a numbe
-00015bc0: 7220 6f66 2073 7465 7073 2069 6e20 5b31  r of steps in [1
-00015bd0: 2c20 6e6f 6f70 5f6d 6178 5d2e 2222 220d  , noop_max].""".
-00015be0: 0a20 2020 2020 2020 2074 645f 7265 7365  .        td_rese
-00015bf0: 7420 3d20 7465 6e73 6f72 6469 6374 2e63  t = tensordict.c
-00015c00: 6c6f 6e65 2846 616c 7365 290d 0a20 2020  lone(False)..   
-00015c10: 2020 2020 2074 656e 736f 7264 6963 7420       tensordict 
-00015c20: 3d20 7465 6e73 6f72 6469 6374 2e63 6c6f  = tensordict.clo
-00015c30: 6e65 2846 616c 7365 290d 0a20 2020 2020  ne(False)..     
-00015c40: 2020 2023 2063 6865 636b 2074 6861 7420     # check that 
-00015c50: 7468 6572 6520 6973 2061 2073 696e 676c  there is a singl
-00015c60: 6520 646f 6e65 2073 7461 7465 202d 2d20  e done state -- 
-00015c70: 6265 6861 7669 6f75 7220 6973 2075 6e64  behaviour is und
-00015c80: 6566 696e 6564 2066 6f72 206d 756c 7469  efined for multi
-00015c90: 706c 6520 646f 6e65 730d 0a20 2020 2020  ple dones..     
-00015ca0: 2020 2070 6172 656e 7420 3d20 7365 6c66     parent = self
-00015cb0: 2e70 6172 656e 740d 0a20 2020 2020 2020  .parent..       
-00015cc0: 2069 6620 7061 7265 6e74 2069 7320 4e6f   if parent is No
-00015cd0: 6e65 3a0d 0a20 2020 2020 2020 2020 2020  ne:..           
-00015ce0: 2072 6169 7365 2052 756e 7469 6d65 4572   raise RuntimeEr
-00015cf0: 726f 7228 0d0a 2020 2020 2020 2020 2020  ror(..          
-00015d00: 2020 2020 2020 224e 6f6f 7052 6573 6574        "NoopReset
-00015d10: 456e 762e 7061 7265 6e74 206e 6f74 2066  Env.parent not f
-00015d20: 6f75 6e64 2e20 4d61 6b65 2073 7572 6520  ound. Make sure 
-00015d30: 7468 6174 2074 6865 2070 6172 656e 7420  that the parent 
-00015d40: 6973 2073 6574 2e22 0d0a 2020 2020 2020  is set."..      
-00015d50: 2020 2020 2020 290d 0a20 2020 2020 2020        )..       
-00015d60: 2069 6620 7465 6e73 6f72 6469 6374 2e67   if tensordict.g
-00015d70: 6574 2822 646f 6e65 2229 2e6e 756d 656c  et("done").numel
-00015d80: 2829 203e 2031 3a0d 0a20 2020 2020 2020  () > 1:..       
-00015d90: 2020 2020 2072 6169 7365 2056 616c 7565       raise Value
-00015da0: 4572 726f 7228 0d0a 2020 2020 2020 2020  Error(..        
-00015db0: 2020 2020 2020 2020 2274 6865 7265 2069          "there i
-00015dc0: 7320 6d6f 7265 2074 6861 6e20 6f6e 6520  s more than one 
-00015dd0: 646f 6e65 2073 7461 7465 2069 6e20 7468  done state in th
-00015de0: 6520 7061 7265 6e74 2065 6e76 6972 6f6e  e parent environ
-00015df0: 6d65 6e74 2e20 220d 0a20 2020 2020 2020  ment. "..       
-00015e00: 2020 2020 2020 2020 2022 4e6f 6f70 5265           "NoopRe
-00015e10: 7365 7445 6e76 2069 7320 6465 7369 676e  setEnv is design
-00015e20: 6564 2074 6f20 776f 726b 206f 6e20 7369  ed to work on si
-00015e30: 6e67 6c65 2065 6e76 2069 6e73 7461 6e63  ngle env instanc
-00015e40: 6573 2c20 6173 2070 6172 7469 616c 2072  es, as partial r
-00015e50: 6573 6574 2022 0d0a 2020 2020 2020 2020  eset "..        
-00015e60: 2020 2020 2020 2020 2269 7320 6375 7272          "is curr
-00015e70: 656e 746c 7920 6e6f 7420 7375 7070 6f72  ently not suppor
-00015e80: 7465 642e 2049 6620 796f 7520 6665 656c  ted. If you feel
-00015e90: 206c 696b 6520 7468 6973 2069 7320 6120   like this is a 
-00015ea0: 6d69 7373 696e 6720 6665 6174 7572 652c  missing feature,
-00015eb0: 2073 7562 6d69 7420 220d 0a20 2020 2020   submit "..     
-00015ec0: 2020 2020 2020 2020 2020 2022 616e 2069             "an i
-00015ed0: 7373 7565 206f 6e20 546f 7263 6852 4c20  ssue on TorchRL 
-00015ee0: 6769 7468 7562 2072 6570 6f2e 2022 0d0a  github repo. "..
-00015ef0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015f00: 2249 6e20 6361 7365 2079 6f75 2061 7265  "In case you are
-00015f10: 2074 7279 696e 6720 746f 2075 7365 204e   trying to use N
-00015f20: 6f6f 7052 6573 6574 456e 7620 6f76 6572  oopResetEnv over
-00015f30: 2061 2062 6174 6368 206f 6620 656e 7669   a batch of envi
-00015f40: 726f 6e6d 656e 7473 2c20 6b6e 6f77 2022  ronments, know "
-00015f50: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00015f60: 2020 2274 6861 7420 796f 7520 6361 6e20    "that you can 
-00015f70: 6861 7665 2061 2074 7261 6e73 666f 726d  have a transform
-00015f80: 6564 2062 6174 6368 206f 6620 7472 616e  ed batch of tran
-00015f90: 7366 6f72 6d65 6420 656e 7673 2c20 7375  sformed envs, su
-00015fa0: 6368 2061 733a 2022 0d0a 2020 2020 2020  ch as: "..      
-00015fb0: 2020 2020 2020 2020 2020 2260 5472 616e            "`Tran
-00015fc0: 7366 6f72 6d65 6445 6e76 2850 6172 616c  sformedEnv(Paral
-00015fd0: 6c65 6c45 6e76 2833 2c20 6c61 6d62 6461  lelEnv(3, lambda
-00015fe0: 3a20 5472 616e 7366 6f72 6d65 6445 6e76  : TransformedEnv
-00015ff0: 284d 7945 6e76 2829 2c20 4e6f 6f70 5265  (MyEnv(), NoopRe
-00016000: 7365 7445 6e76 2833 2929 292c 204f 7468  setEnv(3))), Oth
-00016010: 6572 5472 616e 7366 6f72 6d28 2929 602e  erTransform())`.
-00016020: 220d 0a20 2020 2020 2020 2020 2020 2029  "..            )
-00016030: 0d0a 2020 2020 2020 2020 6e6f 6f70 7320  ..        noops 
-00016040: 3d20 280d 0a20 2020 2020 2020 2020 2020  = (..           
-00016050: 2073 656c 662e 6e6f 6f70 7320 6966 206e   self.noops if n
-00016060: 6f74 2073 656c 662e 7261 6e64 6f6d 2065  ot self.random e
-00016070: 6c73 6520 746f 7263 682e 7261 6e64 696e  lse torch.randin
-00016080: 7428 7365 6c66 2e6e 6f6f 7073 2c20 2831  t(self.noops, (1
-00016090: 2c29 292e 6974 656d 2829 0d0a 2020 2020  ,)).item()..    
-000160a0: 2020 2020 290d 0a20 2020 2020 2020 2074      )..        t
-000160b0: 7269 616c 203d 2030 0d0a 0d0a 2020 2020  rial = 0....    
-000160c0: 2020 2020 7768 696c 6520 5472 7565 3a0d      while True:.
-000160d0: 0a20 2020 2020 2020 2020 2020 2069 203d  .            i =
-000160e0: 2030 0d0a 2020 2020 2020 2020 2020 2020   0..            
-000160f0: 7768 696c 6520 6920 3c20 6e6f 6f70 733a  while i < noops:
-00016100: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00016110: 2020 6920 2b3d 2031 0d0a 2020 2020 2020    i += 1..      
-00016120: 2020 2020 2020 2020 2020 7465 6e73 6f72            tensor
-00016130: 6469 6374 203d 2070 6172 656e 742e 7261  dict = parent.ra
-00016140: 6e64 5f73 7465 7028 7465 6e73 6f72 6469  nd_step(tensordi
-00016150: 6374 290d 0a20 2020 2020 2020 2020 2020  ct)..           
-00016160: 2020 2020 2074 656e 736f 7264 6963 7420       tensordict 
-00016170: 3d20 7374 6570 5f6d 6470 2874 656e 736f  = step_mdp(tenso
-00016180: 7264 6963 742c 2065 7863 6c75 6465 5f64  rdict, exclude_d
-00016190: 6f6e 653d 4661 6c73 6529 0d0a 2020 2020  one=False)..    
-000161a0: 2020 2020 2020 2020 2020 2020 6966 2074              if t
-000161b0: 656e 736f 7264 6963 742e 6765 7428 2264  ensordict.get("d
-000161c0: 6f6e 6522 293a 0d0a 2020 2020 2020 2020  one"):..        
-000161d0: 2020 2020 2020 2020 2020 2020 7465 6e73              tens
-000161e0: 6f72 6469 6374 203d 2070 6172 656e 742e  ordict = parent.
-000161f0: 7265 7365 7428 7464 5f72 6573 6574 2e63  reset(td_reset.c
-00016200: 6c6f 6e65 2846 616c 7365 2929 0d0a 2020  lone(False))..  
-00016210: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016220: 2020 6272 6561 6b0d 0a20 2020 2020 2020    break..       
-00016230: 2020 2020 2065 6c73 653a 0d0a 2020 2020       else:..    
-00016240: 2020 2020 2020 2020 2020 2020 6272 6561              brea
-00016250: 6b0d 0a0d 0a20 2020 2020 2020 2020 2020  k....           
-00016260: 2074 7269 616c 202b 3d20 310d 0a20 2020   trial += 1..   
-00016270: 2020 2020 2020 2020 2069 6620 7472 6961           if tria
-00016280: 6c20 3e20 5f4d 4158 5f4e 4f4f 5053 5f54  l > _MAX_NOOPS_T
-00016290: 5249 414c 533a 0d0a 2020 2020 2020 2020  RIALS:..        
-000162a0: 2020 2020 2020 2020 7465 6e73 6f72 6469          tensordi
-000162b0: 6374 203d 2070 6172 656e 742e 7261 6e64  ct = parent.rand
-000162c0: 5f73 7465 7028 7465 6e73 6f72 6469 6374  _step(tensordict
-000162d0: 290d 0a20 2020 2020 2020 2020 2020 2020  )..             
-000162e0: 2020 2069 6620 7465 6e73 6f72 6469 6374     if tensordict
-000162f0: 2e67 6574 2828 226e 6578 7422 2c20 2264  .get(("next", "d
-00016300: 6f6e 6522 2929 3a0d 0a20 2020 2020 2020  one")):..       
-00016310: 2020 2020 2020 2020 2020 2020 2072 6169               rai
-00016320: 7365 2052 756e 7469 6d65 4572 726f 7228  se RuntimeError(
-00016330: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00016340: 2020 2020 2020 2020 2020 6622 7061 7265            f"pare
-00016350: 6e74 2069 7320 7374 696c 6c20 646f 6e65  nt is still done
-00016360: 2061 6674 6572 2061 2073 696e 676c 6520   after a single 
-00016370: 7261 6e64 6f6d 2073 7465 7020 2869 3d7b  random step (i={
-00016380: 697d 292e 220d 0a20 2020 2020 2020 2020  i})."..         
-00016390: 2020 2020 2020 2020 2020 2029 0d0a 2020             )..  
-000163a0: 2020 2020 2020 2020 2020 2020 2020 6272                br
-000163b0: 6561 6b0d 0a0d 0a20 2020 2020 2020 2069  eak....        i
-000163c0: 6620 7465 6e73 6f72 6469 6374 2e67 6574  f tensordict.get
-000163d0: 2822 646f 6e65 2229 3a0d 0a20 2020 2020  ("done"):..     
-000163e0: 2020 2020 2020 2072 6169 7365 2052 756e         raise Run
-000163f0: 7469 6d65 4572 726f 7228 224e 6f6f 7052  timeError("NoopR
-00016400: 6573 6574 456e 7620 636f 6e63 6c75 6465  esetEnv conclude
-00016410: 6420 7769 7468 2064 6f6e 6520 656e 7669  d with done envi
-00016420: 726f 6e6d 656e 7422 290d 0a20 2020 2020  ronment")..     
-00016430: 2020 2072 6574 7572 6e20 7465 6e73 6f72     return tensor
-00016440: 6469 6374 0d0a 0d0a 2020 2020 6465 6620  dict....    def 
-00016450: 5f5f 7265 7072 5f5f 2873 656c 6629 202d  __repr__(self) -
-00016460: 3e20 7374 723a 0d0a 2020 2020 2020 2020  > str:..        
-00016470: 7261 6e64 6f6d 203d 2073 656c 662e 7261  random = self.ra
-00016480: 6e64 6f6d 0d0a 2020 2020 2020 2020 6e6f  ndom..        no
-00016490: 6f70 7320 3d20 7365 6c66 2e6e 6f6f 7073  ops = self.noops
-000164a0: 0d0a 2020 2020 2020 2020 636c 6173 735f  ..        class_
-000164b0: 6e61 6d65 203d 2073 656c 662e 5f5f 636c  name = self.__cl
-000164c0: 6173 735f 5f2e 5f5f 6e61 6d65 5f5f 0d0a  ass__.__name__..
-000164d0: 2020 2020 2020 2020 7265 7475 726e 2066          return f
-000164e0: 227b 636c 6173 735f 6e61 6d65 7d28 6e6f  "{class_name}(no
-000164f0: 6f70 733d 7b6e 6f6f 7073 7d2c 2072 616e  ops={noops}, ran
-00016500: 646f 6d3d 7b72 616e 646f 6d7d 2922 0d0a  dom={random})"..
-00016510: 0d0a 0d0a 636c 6173 7320 5465 6e73 6f72  ....class Tensor
-00016520: 4469 6374 5072 696d 6572 2854 7261 6e73  DictPrimer(Trans
-00016530: 666f 726d 293a 0d0a 2020 2020 2222 2241  form):..    """A
-00016540: 2070 7269 6d65 7220 666f 7220 5465 6e73   primer for Tens
-00016550: 6f72 4469 6374 2069 6e69 7469 616c 697a  orDict initializ
-00016560: 6174 696f 6e20 6174 2072 6573 6574 2074  ation at reset t
-00016570: 696d 652e 0d0a 0d0a 2020 2020 5468 6973  ime.....    This
-00016580: 2074 7261 6e73 666f 726d 2077 696c 6c20   transform will 
-00016590: 706f 7075 6c61 7465 2074 6865 2074 656e  populate the ten
-000165a0: 736f 7264 6963 7420 6174 2072 6573 6574  sordict at reset
-000165b0: 2077 6974 6820 7661 6c75 6573 2064 7261   with values dra
-000165c0: 776e 2066 726f 6d0d 0a20 2020 2074 6865  wn from..    the
-000165d0: 2072 656c 6174 6976 6520 7465 6e73 6f72   relative tensor
-000165e0: 7370 6563 7320 7072 6f76 6964 6564 2061  specs provided a
-000165f0: 7420 696e 6974 6961 6c69 7a61 7469 6f6e  t initialization
-00016600: 2e0d 0a20 2020 2049 6620 7468 6520 7472  ...    If the tr
-00016610: 616e 7366 6f72 6d20 6973 2075 7365 6420  ansform is used 
-00016620: 6f75 7420 6f66 2074 6865 2065 6e76 2063  out of the env c
-00016630: 6f6e 7465 7874 2028 652e 672e 2061 7320  ontext (e.g. as 
-00016640: 616e 206e 6e2e 4d6f 6475 6c65 206f 720d  an nn.Module or.
-00016650: 0a20 2020 2061 7070 656e 6465 6420 746f  .    appended to
-00016660: 2061 2072 6570 6c61 7920 6275 6666 6572   a replay buffer
-00016670: 292c 2061 2063 616c 6c20 746f 2060 666f  ), a call to `fo
-00016680: 7277 6172 6460 2077 696c 6c20 616c 736f  rward` will also
-00016690: 2070 6f70 756c 6174 6520 7468 650d 0a20   populate the.. 
-000166a0: 2020 2074 656e 736f 7264 6963 7420 7769     tensordict wi
-000166b0: 7468 2074 6865 2064 6573 6972 6564 2066  th the desired f
-000166c0: 6561 7475 7265 732e 0d0a 0d0a 2020 2020  eatures.....    
-000166d0: 4172 6773 3a0d 0a20 2020 2020 2020 2070  Args:..        p
-000166e0: 7269 6d65 7273 2028 6469 6374 2c20 6f70  rimers (dict, op
-000166f0: 7469 6f6e 616c 293a 2061 2064 6963 7469  tional): a dicti
-00016700: 6f6e 6172 7920 636f 6e74 6169 6e69 6e67  onary containing
-00016710: 206b 6579 2d73 7065 6320 7061 6972 7320   key-spec pairs 
-00016720: 7768 6963 6820 7769 6c6c 0d0a 2020 2020  which will..    
-00016730: 2020 2020 2020 2020 6265 2075 7365 6420          be used 
-00016740: 746f 2070 6f70 756c 6174 6520 7468 6520  to populate the 
-00016750: 696e 7075 7420 7465 6e73 6f72 6469 6374  input tensordict
-00016760: 2e0d 0a20 2020 2020 2020 2072 616e 646f  ...        rando
-00016770: 6d20 2862 6f6f 6c2c 206f 7074 696f 6e61  m (bool, optiona
-00016780: 6c29 3a20 6966 2054 7275 652c 2074 6865  l): if True, the
-00016790: 2076 616c 7565 7320 7769 6c6c 2062 6520   values will be 
-000167a0: 6472 6177 6e20 7261 6e64 6f6d 6c79 2066  drawn randomly f
-000167b0: 726f 6d0d 0a20 2020 2020 2020 2020 2020  rom..           
-000167c0: 2074 6865 2054 656e 736f 7253 7065 6320   the TensorSpec 
-000167d0: 646f 6d61 696e 2028 6f72 2061 2075 6e69  domain (or a uni
-000167e0: 7420 4761 7573 7369 616e 2069 6620 756e  t Gaussian if un
-000167f0: 626f 756e 6465 6429 2e20 4f74 6865 7277  bounded). Otherw
-00016800: 6973 6520 6120 6669 7865 6420 7661 6c75  ise a fixed valu
-00016810: 6520 7769 6c6c 2062 6520 6173 7375 6d65  e will be assume
-00016820: 642e 0d0a 2020 2020 2020 2020 2020 2020  d...            
-00016830: 4465 6661 756c 7473 2074 6f20 6046 616c  Defaults to `Fal
-00016840: 7365 602e 0d0a 2020 2020 2020 2020 6465  se`...        de
-00016850: 6661 756c 745f 7661 6c75 6520 2866 6c6f  fault_value (flo
-00016860: 6174 2c20 6f70 7469 6f6e 616c 293a 2069  at, optional): i
-00016870: 6620 6e6f 6e2d 7261 6e64 6f6d 2066 696c  f non-random fil
-00016880: 6c69 6e67 2069 7320 6368 6f73 656e 2c20  ling is chosen, 
-00016890: 7468 6973 0d0a 2020 2020 2020 2020 2020  this..          
-000168a0: 2020 7661 6c75 6520 7769 6c6c 2062 6520    value will be 
-000168b0: 7573 6564 2074 6f20 706f 7075 6c61 7465  used to populate
-000168c0: 2074 6865 2074 656e 736f 7273 2e20 4465   the tensors. De
-000168d0: 6661 756c 7473 2074 6f20 6030 2e30 602e  faults to `0.0`.
-000168e0: 0d0a 2020 2020 2020 2020 2a2a 6b77 6172  ..        **kwar
-000168f0: 6773 3a20 6561 6368 206b 6579 776f 7264  gs: each keyword
-00016900: 2061 7267 756d 656e 7420 636f 7272 6573   argument corres
-00016910: 706f 6e64 7320 746f 2061 206b 6579 2069  ponds to a key i
-00016920: 6e20 7468 6520 7465 6e73 6f72 6469 6374  n the tensordict
-00016930: 2e0d 0a20 2020 2020 2020 2020 2020 2054  ...            T
-00016940: 6865 2063 6f72 7265 7370 6f6e 6469 6e67  he corresponding
-00016950: 2076 616c 7565 2068 6173 2074 6f20 6265   value has to be
-00016960: 2061 2054 656e 736f 7253 7065 6320 696e   a TensorSpec in
-00016970: 7374 616e 6365 2069 6e64 6963 6174 696e  stance indicatin
-00016980: 670d 0a20 2020 2020 2020 2020 2020 2077  g..            w
-00016990: 6861 7420 7468 6520 7661 6c75 6520 6d75  hat the value mu
-000169a0: 7374 2062 652e 0d0a 0d0a 2020 2020 5768  st be.....    Wh
-000169b0: 656e 2075 7365 6420 696e 2061 2054 7261  en used in a Tra
-000169c0: 6e73 666f 6d65 6445 6e76 2c20 7468 6520  nsfomedEnv, the 
-000169d0: 7370 6563 2073 6861 7065 7320 6d75 7374  spec shapes must
-000169e0: 206d 6174 6368 2074 6865 2065 6e76 7320   match the envs 
-000169f0: 7368 6170 6520 6966 0d0a 2020 2020 7468  shape if..    th
-00016a00: 6520 7061 7265 6e74 2065 6e76 2069 7320  e parent env is 
-00016a10: 6261 7463 682d 6c6f 636b 6564 2028 3a6f  batch-locked (:o
-00016a20: 626a 3a60 656e 762e 6261 7463 685f 6c6f  bj:`env.batch_lo
-00016a30: 636b 6564 3d54 7275 6560 292e 0d0a 2020  cked=True`)...  
-00016a40: 2020 4966 2074 6865 2065 6e76 2069 7320    If the env is 
-00016a50: 6e6f 7420 6261 7463 682d 6c6f 636b 6564  not batch-locked
-00016a60: 2028 652e 672e 206d 6f64 656c 2d62 6173   (e.g. model-bas
-00016a70: 6564 2065 6e76 7329 2c20 6974 2069 7320  ed envs), it is 
-00016a80: 6173 7375 6d65 6420 7468 6174 2074 6865  assumed that the
-00016a90: 2062 6174 6368 2069 730d 0a20 2020 2067   batch is..    g
-00016aa0: 6976 656e 2062 7920 7468 6520 696e 7075  iven by the inpu
-00016ab0: 7420 7465 6e73 6f72 6469 6374 2069 6e73  t tensordict ins
-00016ac0: 7465 6164 2e0d 0a0d 0a20 2020 2045 7861  tead.....    Exa
-00016ad0: 6d70 6c65 733a 0d0a 2020 2020 2020 2020  mples:..        
-00016ae0: 3e3e 3e20 6672 6f6d 2074 6f72 6368 726c  >>> from torchrl
-00016af0: 2e65 6e76 732e 6c69 6273 2e67 796d 2069  .envs.libs.gym i
-00016b00: 6d70 6f72 7420 4779 6d45 6e76 0d0a 2020  mport GymEnv..  
-00016b10: 2020 2020 2020 3e3e 3e20 6261 7365 5f65        >>> base_e
-00016b20: 6e76 203d 2053 6572 6961 6c45 6e76 2832  nv = SerialEnv(2
-00016b30: 2c20 4779 6d45 6e76 2822 5065 6e64 756c  , GymEnv("Pendul
-00016b40: 756d 2d76 3122 2929 0d0a 2020 2020 2020  um-v1"))..      
-00016b50: 2020 3e3e 3e20 656e 7620 3d20 5472 616e    >>> env = Tran
-00016b60: 7366 6f72 6d65 6445 6e76 2862 6173 655f  sformedEnv(base_
-00016b70: 656e 7629 0d0a 2020 2020 2020 2020 3e3e  env)..        >>
-00016b80: 3e20 2320 7468 6520 656e 7620 6973 2062  > # the env is b
-00016b90: 6174 6368 2d6c 6f63 6b65 642c 2073 6f20  atch-locked, so 
-00016ba0: 7468 6520 6c65 6164 696e 6720 6469 6d73  the leading dims
-00016bb0: 206f 6620 7468 6520 7370 6563 206d 7573   of the spec mus
-00016bc0: 7420 6d61 7463 6820 7468 6f73 6520 6f66  t match those of
-00016bd0: 2074 6865 2065 6e76 0d0a 2020 2020 2020   the env..      
-00016be0: 2020 3e3e 3e20 656e 762e 6170 7065 6e64    >>> env.append
-00016bf0: 5f74 7261 6e73 666f 726d 2854 656e 736f  _transform(Tenso
-00016c00: 7244 6963 7450 7269 6d65 7228 6d79 6b65  rDictPrimer(myke
-00016c10: 793d 556e 626f 756e 6465 6443 6f6e 7469  y=UnboundedConti
-00016c20: 6e75 6f75 7354 656e 736f 7253 7065 6328  nuousTensorSpec(
-00016c30: 5b32 2c20 335d 2929 290d 0a20 2020 2020  [2, 3])))..     
-00016c40: 2020 203e 3e3e 2070 7269 6e74 2865 6e76     >>> print(env
-00016c50: 2e72 6573 6574 2829 290d 0a20 2020 2020  .reset())..     
-00016c60: 2020 2054 656e 736f 7244 6963 7428 0d0a     TensorDict(..
-00016c70: 2020 2020 2020 2020 2020 2020 6669 656c              fiel
-00016c80: 6473 3d7b 0d0a 2020 2020 2020 2020 2020  ds={..          
-00016c90: 2020 2020 2020 646f 6e65 3a20 5465 6e73        done: Tens
-00016ca0: 6f72 2874 6f72 6368 2e53 697a 6528 5b31  or(torch.Size([1
-00016cb0: 5d29 2c20 6474 7970 653d 746f 7263 682e  ]), dtype=torch.
-00016cc0: 626f 6f6c 292c 0d0a 2020 2020 2020 2020  bool),..        
-00016cd0: 2020 2020 2020 2020 6d79 6b65 793a 2054          mykey: T
-00016ce0: 656e 736f 7228 746f 7263 682e 5369 7a65  ensor(torch.Size
-00016cf0: 285b 335d 292c 2064 7479 7065 3d74 6f72  ([3]), dtype=tor
-00016d00: 6368 2e66 6c6f 6174 3332 292c 0d0a 2020  ch.float32),..  
-00016d10: 2020 2020 2020 2020 2020 2020 2020 6f62                ob
-00016d20: 7365 7276 6174 696f 6e3a 2054 656e 736f  servation: Tenso
-00016d30: 7228 746f 7263 682e 5369 7a65 285b 335d  r(torch.Size([3]
-00016d40: 292c 2064 7479 7065 3d74 6f72 6368 2e66  ), dtype=torch.f
-00016d50: 6c6f 6174 3332 297d 2c0d 0a20 2020 2020  loat32)},..     
-00016d60: 2020 2020 2020 2062 6174 6368 5f73 697a         batch_siz
-00016d70: 653d 746f 7263 682e 5369 7a65 285b 5d29  e=torch.Size([])
-00016d80: 2c0d 0a20 2020 2020 2020 2020 2020 2064  ,..            d
-00016d90: 6576 6963 653d 6370 752c 0d0a 2020 2020  evice=cpu,..    
-00016da0: 2020 2020 2020 2020 6973 5f73 6861 7265          is_share
-00016db0: 643d 4661 6c73 6529 0d0a 2020 2020 2222  d=False)..    ""
-00016dc0: 220d 0a0d 0a20 2020 2064 6566 205f 5f69  "....    def __i
-00016dd0: 6e69 745f 5f28 7365 6c66 2c20 7072 696d  nit__(self, prim
-00016de0: 6572 733a 2064 6963 7420 3d20 4e6f 6e65  ers: dict = None
-00016df0: 2c20 7261 6e64 6f6d 3d46 616c 7365 2c20  , random=False, 
-00016e00: 6465 6661 756c 745f 7661 6c75 653d 302e  default_value=0.
-00016e10: 302c 202a 2a6b 7761 7267 7329 3a0d 0a20  0, **kwargs):.. 
-00016e20: 2020 2020 2020 2073 656c 662e 6465 7669         self.devi
-00016e30: 6365 203d 206b 7761 7267 732e 706f 7028  ce = kwargs.pop(
-00016e40: 2264 6576 6963 6522 2c20 4e6f 6e65 290d  "device", None).
-00016e50: 0a20 2020 2020 2020 2069 6620 7072 696d  .        if prim
-00016e60: 6572 7320 6973 206e 6f74 204e 6f6e 653a  ers is not None:
-00016e70: 0d0a 2020 2020 2020 2020 2020 2020 6966  ..            if
-00016e80: 206b 7761 7267 733a 0d0a 2020 2020 2020   kwargs:..      
-00016e90: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
-00016ea0: 5275 6e74 696d 6545 7272 6f72 280d 0a20  RuntimeError(.. 
-00016eb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00016ec0: 2020 2022 7072 6f76 6964 696e 6720 7468     "providing th
-00016ed0: 6520 7072 696d 6572 7320 6173 2061 2064  e primers as a d
-00016ee0: 6963 7469 6f6e 6172 7920 6973 2069 6e63  ictionary is inc
-00016ef0: 6f6d 7061 7469 626c 6520 7769 7468 2065  ompatible with e
-00016f00: 7874 7261 206b 6579 7320 7072 6f76 6964  xtra keys provid
-00016f10: 6564 2022 0d0a 2020 2020 2020 2020 2020  ed "..          
-00016f20: 2020 2020 2020 2020 2020 2261 7320 6b77            "as kw
-00016f30: 6172 6773 2e22 0d0a 2020 2020 2020 2020  args."..        
-00016f40: 2020 2020 2020 2020 290d 0a20 2020 2020          )..     
-00016f50: 2020 2020 2020 206b 7761 7267 7320 3d20         kwargs = 
-00016f60: 7072 696d 6572 730d 0a20 2020 2020 2020  primers..       
-00016f70: 2073 656c 662e 7072 696d 6572 7320 3d20   self.primers = 
-00016f80: 6b77 6172 6773 0d0a 2020 2020 2020 2020  kwargs..        
-00016f90: 7365 6c66 2e72 616e 646f 6d20 3d20 7261  self.random = ra
-00016fa0: 6e64 6f6d 0d0a 2020 2020 2020 2020 7365  ndom..        se
-00016fb0: 6c66 2e64 6566 6175 6c74 5f76 616c 7565  lf.default_value
-00016fc0: 203d 2064 6566 6175 6c74 5f76 616c 7565   = default_value
-00016fd0: 0d0a 0d0a 2020 2020 2020 2020 2320 7361  ....        # sa
-00016fe0: 6e69 7479 2063 6865 636b 0d0a 2020 2020  nity check..    
-00016ff0: 2020 2020 666f 7220 7370 6563 2069 6e20      for spec in 
-00017000: 7365 6c66 2e70 7269 6d65 7273 2e76 616c  self.primers.val
-00017010: 7565 7328 293a 0d0a 2020 2020 2020 2020  ues():..        
-00017020: 2020 2020 6966 206e 6f74 2069 7369 6e73      if not isins
-00017030: 7461 6e63 6528 7370 6563 2c20 5465 6e73  tance(spec, Tens
-00017040: 6f72 5370 6563 293a 0d0a 2020 2020 2020  orSpec):..      
-00017050: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
-00017060: 5661 6c75 6545 7272 6f72 280d 0a20 2020  ValueError(..   
-00017070: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017080: 2022 5468 6520 7661 6c75 6573 206f 6620   "The values of 
-00017090: 7468 6520 7072 696d 6572 7320 6d75 7374  the primers must
-000170a0: 2062 6520 6120 7375 6274 7970 6520 6f66   be a subtype of
-000170b0: 2074 6865 2054 656e 736f 7253 7065 6320   the TensorSpec 
-000170c0: 636c 6173 732e 2022 0d0a 2020 2020 2020  class. "..      
-000170d0: 2020 2020 2020 2020 2020 2020 2020 6622                f"
-000170e0: 476f 7420 7b74 7970 6528 7370 6563 297d  Got {type(spec)}
-000170f0: 2069 6e73 7465 6164 2e22 0d0a 2020 2020   instead."..    
-00017100: 2020 2020 2020 2020 2020 2020 290d 0a20              ).. 
-00017110: 2020 2020 2020 2073 7570 6572 2829 2e5f         super()._
-00017120: 5f69 6e69 745f 5f28 5b5d 290d 0a0d 0a20  _init__([]).... 
-00017130: 2020 2040 7072 6f70 6572 7479 0d0a 2020     @property..  
-00017140: 2020 6465 6620 6465 7669 6365 2873 656c    def device(sel
-00017150: 6629 3a0d 0a20 2020 2020 2020 2064 6576  f):..        dev
-00017160: 6963 6520 3d20 7365 6c66 2e5f 6465 7669  ice = self._devi
-00017170: 6365 0d0a 2020 2020 2020 2020 6966 2064  ce..        if d
-00017180: 6576 6963 6520 6973 204e 6f6e 6520 616e  evice is None an
-00017190: 6420 7365 6c66 2e70 6172 656e 7420 6973  d self.parent is
-000171a0: 206e 6f74 204e 6f6e 653a 0d0a 2020 2020   not None:..    
-000171b0: 2020 2020 2020 2020 6465 7669 6365 203d          device =
-000171c0: 2073 656c 662e 7061 7265 6e74 2e64 6576   self.parent.dev
-000171d0: 6963 650d 0a20 2020 2020 2020 2020 2020  ice..           
-000171e0: 2073 656c 662e 5f64 6576 6963 6520 3d20   self._device = 
-000171f0: 6465 7669 6365 0d0a 2020 2020 2020 2020  device..        
-00017200: 7265 7475 726e 2064 6576 6963 650d 0a0d  return device...
-00017210: 0a20 2020 2040 6465 7669 6365 2e73 6574  .    @device.set
-00017220: 7465 720d 0a20 2020 2064 6566 2064 6576  ter..    def dev
-00017230: 6963 6528 7365 6c66 2c20 7661 6c75 6529  ice(self, value)
-00017240: 3a0d 0a20 2020 2020 2020 2069 6620 7661  :..        if va
-00017250: 6c75 6520 6973 204e 6f6e 653a 0d0a 2020  lue is None:..  
-00017260: 2020 2020 2020 2020 2020 7365 6c66 2e5f            self._
-00017270: 6465 7669 6365 203d 204e 6f6e 650d 0a20  device = None.. 
-00017280: 2020 2020 2020 2020 2020 2072 6574 7572             retur
-00017290: 6e0d 0a20 2020 2020 2020 2073 656c 662e  n..        self.
-000172a0: 5f64 6576 6963 6520 3d20 746f 7263 682e  _device = torch.
-000172b0: 6465 7669 6365 2876 616c 7565 290d 0a0d  device(value)...
-000172c0: 0a20 2020 2064 6566 2074 6f28 7365 6c66  .    def to(self
-000172d0: 2c20 6474 7970 655f 6f72 5f64 6576 6963  , dtype_or_devic
-000172e0: 6529 3a0d 0a20 2020 2020 2020 2069 6620  e):..        if 
-000172f0: 6e6f 7420 6973 696e 7374 616e 6365 2864  not isinstance(d
-00017300: 7479 7065 5f6f 725f 6465 7669 6365 2c20  type_or_device, 
-00017310: 746f 7263 682e 6474 7970 6529 3a0d 0a20  torch.dtype):.. 
-00017320: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-00017330: 6465 7669 6365 203d 2064 7479 7065 5f6f  device = dtype_o
-00017340: 725f 6465 7669 6365 0d0a 2020 2020 2020  r_device..      
-00017350: 2020 7265 7475 726e 2073 7570 6572 2829    return super()
-00017360: 2e74 6f28 6474 7970 655f 6f72 5f64 6576  .to(dtype_or_dev
-00017370: 6963 6529 0d0a 0d0a 2020 2020 6465 6620  ice)....    def 
-00017380: 7472 616e 7366 6f72 6d5f 6f62 7365 7276  transform_observ
-00017390: 6174 696f 6e5f 7370 6563 280d 0a20 2020  ation_spec(..   
-000173a0: 2020 2020 2073 656c 662c 206f 6273 6572       self, obser
-000173b0: 7661 7469 6f6e 5f73 7065 633a 2043 6f6d  vation_spec: Com
-000173c0: 706f 7369 7465 5370 6563 0d0a 2020 2020  positeSpec..    
-000173d0: 2920 2d3e 2043 6f6d 706f 7369 7465 5370  ) -> CompositeSp
-000173e0: 6563 3a0d 0a20 2020 2020 2020 2069 6620  ec:..        if 
-000173f0: 6e6f 7420 6973 696e 7374 616e 6365 286f  not isinstance(o
-00017400: 6273 6572 7661 7469 6f6e 5f73 7065 632c  bservation_spec,
-00017410: 2043 6f6d 706f 7369 7465 5370 6563 293a   CompositeSpec):
-00017420: 0d0a 2020 2020 2020 2020 2020 2020 7261  ..            ra
-00017430: 6973 6520 5661 6c75 6545 7272 6f72 280d  ise ValueError(.
-00017440: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00017450: 2066 226f 6273 6572 7661 7469 6f6e 5f73   f"observation_s
-00017460: 7065 6320 7761 7320 6578 7065 6374 6564  pec was expected
-00017470: 2074 6f20 6265 206f 6620 7479 7065 2043   to be of type C
-00017480: 6f6d 706f 7369 7465 5370 6563 2e20 476f  ompositeSpec. Go
-00017490: 7420 7b74 7970 6528 6f62 7365 7276 6174  t {type(observat
-000174a0: 696f 6e5f 7370 6563 297d 2069 6e73 7465  ion_spec)} inste
-000174b0: 6164 2e22 0d0a 2020 2020 2020 2020 2020  ad."..          
-000174c0: 2020 290d 0a20 2020 2020 2020 2066 6f72    )..        for
-000174d0: 206b 6579 2c20 7370 6563 2069 6e20 7365   key, spec in se
-000174e0: 6c66 2e70 7269 6d65 7273 2e69 7465 6d73  lf.primers.items
-000174f0: 2829 3a0d 0a20 2020 2020 2020 2020 2020  ():..           
-00017500: 2069 6620 7370 6563 2e73 6861 7065 5b3a   if spec.shape[:
-00017510: 206c 656e 286f 6273 6572 7661 7469 6f6e   len(observation
-00017520: 5f73 7065 632e 7368 6170 6529 5d20 213d  _spec.shape)] !=
-00017530: 206f 6273 6572 7661 7469 6f6e 5f73 7065   observation_spe
-00017540: 632e 7368 6170 653a 0d0a 2020 2020 2020  c.shape:..      
-00017550: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
-00017560: 5275 6e74 696d 6545 7272 6f72 280d 0a20  RuntimeError(.. 
-00017570: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017580: 2020 2066 2254 6865 206c 6561 6469 6e67     f"The leading
-00017590: 2073 6861 7065 206f 6620 7468 6520 7072   shape of the pr
-000175a0: 696d 6572 2073 7065 6373 2028 7b73 656c  imer specs ({sel
-000175b0: 662e 5f5f 636c 6173 735f 5f7d 2920 7368  f.__class__}) sh
-000175c0: 6f75 6c64 206d 6174 6368 2074 6865 206f  ould match the o
-000175d0: 6e65 206f 6620 7468 6520 7061 7265 6e74  ne of the parent
-000175e0: 2065 6e76 2e20 220d 0a20 2020 2020 2020   env. "..       
-000175f0: 2020 2020 2020 2020 2020 2020 2066 2247               f"G
-00017600: 6f74 206f 6273 6572 7661 7469 6f6e 5f73  ot observation_s
-00017610: 7065 632e 7368 6170 653d 7b6f 6273 6572  pec.shape={obser
-00017620: 7661 7469 6f6e 5f73 7065 632e 7368 6170  vation_spec.shap
-00017630: 657d 2062 7574 2074 6865 2027 7b6b 6579  e} but the '{key
-00017640: 7d27 2065 6e74 7279 2773 2073 6861 7065  }' entry's shape
-00017650: 2069 7320 7b73 7065 632e 7368 6170 657d   is {spec.shape}
-00017660: 2e22 0d0a 2020 2020 2020 2020 2020 2020  ."..            
-00017670: 2020 2020 290d 0a20 2020 2020 2020 2020      )..         
-00017680: 2020 2074 7279 3a0d 0a20 2020 2020 2020     try:..       
-00017690: 2020 2020 2020 2020 2064 6576 6963 6520           device 
-000176a0: 3d20 6f62 7365 7276 6174 696f 6e5f 7370  = observation_sp
-000176b0: 6563 2e64 6576 6963 650d 0a20 2020 2020  ec.device..     
-000176c0: 2020 2020 2020 2065 7863 6570 7420 5275         except Ru
-000176d0: 6e74 696d 6545 7272 6f72 3a0d 0a20 2020  ntimeError:..   
-000176e0: 2020 2020 2020 2020 2020 2020 2064 6576               dev
-000176f0: 6963 6520 3d20 7365 6c66 2e64 6576 6963  ice = self.devic
-00017700: 650d 0a20 2020 2020 2020 2020 2020 206f  e..            o
-00017710: 6273 6572 7661 7469 6f6e 5f73 7065 635b  bservation_spec[
-00017720: 6b65 795d 203d 2073 7065 632e 746f 2864  key] = spec.to(d
-00017730: 6576 6963 6529 0d0a 2020 2020 2020 2020  evice)..        
-00017740: 7265 7475 726e 206f 6273 6572 7661 7469  return observati
-00017750: 6f6e 5f73 7065 630d 0a0d 0a20 2020 2040  on_spec....    @
-00017760: 7072 6f70 6572 7479 0d0a 2020 2020 6465  property..    de
-00017770: 6620 5f62 6174 6368 5f73 697a 6528 7365  f _batch_size(se
-00017780: 6c66 293a 0d0a 2020 2020 2020 2020 7265  lf):..        re
-00017790: 7475 726e 2073 656c 662e 7061 7265 6e74  turn self.parent
-000177a0: 2e62 6174 6368 5f73 697a 650d 0a0d 0a20  .batch_size.... 
-000177b0: 2020 2064 6566 2066 6f72 7761 7264 2873     def forward(s
-000177c0: 656c 662c 2074 656e 736f 7264 6963 743a  elf, tensordict:
-000177d0: 2054 656e 736f 7244 6963 7442 6173 6529   TensorDictBase)
-000177e0: 202d 3e20 5465 6e73 6f72 4469 6374 4261   -> TensorDictBa
-000177f0: 7365 3a0d 0a20 2020 2020 2020 2066 6f72  se:..        for
-00017800: 206b 6579 2c20 7370 6563 2069 6e20 7365   key, spec in se
-00017810: 6c66 2e70 7269 6d65 7273 2e69 7465 6d73  lf.primers.items
-00017820: 2829 3a0d 0a20 2020 2020 2020 2020 2020  ():..           
-00017830: 2069 6620 7370 6563 2e73 6861 7065 5b3a   if spec.shape[:
-00017840: 206c 656e 2874 656e 736f 7264 6963 742e   len(tensordict.
-00017850: 7368 6170 6529 5d20 213d 2074 656e 736f  shape)] != tenso
-00017860: 7264 6963 742e 7368 6170 653a 0d0a 2020  rdict.shape:..  
-00017870: 2020 2020 2020 2020 2020 2020 2020 7261                ra
-00017880: 6973 6520 5275 6e74 696d 6545 7272 6f72  ise RuntimeError
-00017890: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
-000178a0: 2020 2020 2020 2022 5468 6520 6c65 6164         "The lead
-000178b0: 696e 6720 7368 6170 6520 6f66 2074 6865  ing shape of the
-000178c0: 2073 7065 6320 6d75 7374 206d 6174 6368   spec must match
-000178d0: 2074 6865 2074 656e 736f 7264 6963 7427   the tensordict'
-000178e0: 732c 2022 0d0a 2020 2020 2020 2020 2020  s, "..          
-000178f0: 2020 2020 2020 2020 2020 2262 7574 2069            "but i
-00017900: 7420 646f 6573 206e 6f74 3a20 676f 7420  t does not: got 
-00017910: 220d 0a20 2020 2020 2020 2020 2020 2020  "..             
-00017920: 2020 2020 2020 2066 2274 656e 736f 7264         f"tensord
-00017930: 6963 742e 7368 6170 653d 7b74 656e 736f  ict.shape={tenso
-00017940: 7264 6963 742e 7368 6170 657d 2077 6865  rdict.shape} whe
-00017950: 7265 6173 207b 6b65 797d 2073 7065 6327  reas {key} spec'
-00017960: 7320 7368 6170 6520 6973 2022 0d0a 2020  s shape is "..  
-00017970: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017980: 2020 6622 7b73 7065 632e 7368 6170 657d    f"{spec.shape}
-00017990: 2e22 0d0a 2020 2020 2020 2020 2020 2020  ."..            
-000179a0: 2020 2020 290d 0a20 2020 2020 2020 2020      )..         
-000179b0: 2020 2069 6620 7365 6c66 2e72 616e 646f     if self.rando
-000179c0: 6d3a 0d0a 2020 2020 2020 2020 2020 2020  m:..            
-000179d0: 2020 2020 7661 6c75 6520 3d20 7370 6563      value = spec
-000179e0: 2e72 616e 6428 290d 0a20 2020 2020 2020  .rand()..       
-000179f0: 2020 2020 2065 6c73 653a 0d0a 2020 2020       else:..    
-00017a00: 2020 2020 2020 2020 2020 2020 7661 6c75              valu
-00017a10: 6520 3d20 746f 7263 682e 6675 6c6c 5f6c  e = torch.full_l
-00017a20: 696b 6528 0d0a 2020 2020 2020 2020 2020  ike(..          
-00017a30: 2020 2020 2020 2020 2020 7370 6563 2e7a            spec.z
-00017a40: 6572 6f28 292c 0d0a 2020 2020 2020 2020  ero(),..        
-00017a50: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-00017a60: 2e64 6566 6175 6c74 5f76 616c 7565 2c0d  .default_value,.
-00017a70: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00017a80: 2029 0d0a 2020 2020 2020 2020 2020 2020   )..            
-00017a90: 7465 6e73 6f72 6469 6374 2e73 6574 286b  tensordict.set(k
-00017aa0: 6579 2c20 7661 6c75 6529 0d0a 2020 2020  ey, value)..    
-00017ab0: 2020 2020 7265 7475 726e 2074 656e 736f      return tenso
-00017ac0: 7264 6963 740d 0a0d 0a20 2020 2064 6566  rdict....    def
-00017ad0: 205f 7374 6570 2873 656c 662c 2074 656e   _step(self, ten
-00017ae0: 736f 7264 6963 743a 2054 656e 736f 7244  sordict: TensorD
-00017af0: 6963 7442 6173 6529 202d 3e20 5465 6e73  ictBase) -> Tens
-00017b00: 6f72 4469 6374 4261 7365 3a0d 0a20 2020  orDictBase:..   
-00017b10: 2020 2020 2066 6f72 206b 6579 2069 6e20       for key in 
-00017b20: 7365 6c66 2e70 7269 6d65 7273 2e6b 6579  self.primers.key
-00017b30: 7328 293a 0d0a 2020 2020 2020 2020 2020  s():..          
-00017b40: 2020 6966 2069 7369 6e73 7461 6e63 6528    if isinstance(
-00017b50: 6b65 792c 2073 7472 293a 0d0a 2020 2020  key, str):..    
-00017b60: 2020 2020 2020 2020 2020 2020 6b65 7920              key 
-00017b70: 3d20 286b 6579 2c29 0d0a 2020 2020 2020  = (key,)..      
-00017b80: 2020 2020 2020 7465 6e73 6f72 6469 6374        tensordict
-00017b90: 5b28 226e 6578 7422 2c20 2a6b 6579 295d  [("next", *key)]
-00017ba0: 203d 2074 656e 736f 7264 6963 745b 6b65   = tensordict[ke
-00017bb0: 795d 0d0a 2020 2020 2020 2020 7265 7475  y]..        retu
-00017bc0: 726e 2074 656e 736f 7264 6963 740d 0a0d  rn tensordict...
-00017bd0: 0a20 2020 2064 6566 2072 6573 6574 2873  .    def reset(s
-00017be0: 656c 662c 2074 656e 736f 7264 6963 743a  elf, tensordict:
-00017bf0: 2054 656e 736f 7244 6963 7442 6173 6529   TensorDictBase)
-00017c00: 202d 3e20 5465 6e73 6f72 4469 6374 4261   -> TensorDictBa
-00017c10: 7365 3a0d 0a20 2020 2020 2020 2022 2222  se:..        """
-00017c20: 5365 7473 2074 6865 2064 6566 6175 6c74  Sets the default
-00017c30: 2076 616c 7565 7320 696e 2074 6865 2069   values in the i
-00017c40: 6e70 7574 2074 656e 736f 7264 6963 742e  nput tensordict.
-00017c50: 0d0a 0d0a 2020 2020 2020 2020 4966 2074  ....        If t
-00017c60: 6865 2070 6172 656e 7420 6973 2062 6174  he parent is bat
-00017c70: 6368 2d6c 6f63 6b65 642c 2077 6520 6173  ch-locked, we as
-00017c80: 7375 6d65 2074 6861 7420 7468 6520 7370  sume that the sp
-00017c90: 6563 7320 6861 7665 2074 6865 2061 7070  ecs have the app
-00017ca0: 726f 7072 6961 7465 206c 6561 6469 6e67  ropriate leading
-00017cb0: 0d0a 2020 2020 2020 2020 7368 6170 652e  ..        shape.
-00017cc0: 2057 6520 616c 6c6f 7720 666f 7220 6578   We allow for ex
-00017cd0: 6563 7574 696f 6e20 7768 656e 2074 6865  ecution when the
-00017ce0: 2070 6172 656e 7420 6973 206d 6973 7369   parent is missi
-00017cf0: 6e67 2c20 696e 2077 6869 6368 2063 6173  ng, in which cas
-00017d00: 6520 7468 650d 0a20 2020 2020 2020 2073  e the..        s
-00017d10: 7065 6320 7368 6170 6520 6973 2061 7373  pec shape is ass
-00017d20: 756d 6564 2074 6f20 6d61 7463 6820 7468  umed to match th
-00017d30: 6520 7465 6e73 6f72 6469 6374 2773 2e0d  e tensordict's..
-00017d40: 0a0d 0a20 2020 2020 2020 2022 2222 0d0a  ...        """..
-00017d50: 2020 2020 2020 2020 7368 6170 6520 3d20          shape = 
-00017d60: 280d 0a20 2020 2020 2020 2020 2020 2028  (..            (
-00017d70: 290d 0a20 2020 2020 2020 2020 2020 2069  )..            i
-00017d80: 6620 286e 6f74 2073 656c 662e 7061 7265  f (not self.pare
-00017d90: 6e74 206f 7220 7365 6c66 2e70 6172 656e  nt or self.paren
-00017da0: 742e 6261 7463 685f 6c6f 636b 6564 290d  t.batch_locked).
-00017db0: 0a20 2020 2020 2020 2020 2020 2065 6c73  .            els
-00017dc0: 6520 7465 6e73 6f72 6469 6374 2e62 6174  e tensordict.bat
-00017dd0: 6368 5f73 697a 650d 0a20 2020 2020 2020  ch_size..       
-00017de0: 2029 0d0a 2020 2020 2020 2020 666f 7220   )..        for 
-00017df0: 6b65 792c 2073 7065 6320 696e 2073 656c  key, spec in sel
-00017e00: 662e 7072 696d 6572 732e 6974 656d 7328  f.primers.items(
-00017e10: 293a 0d0a 2020 2020 2020 2020 2020 2020  ):..            
-00017e20: 6966 2073 656c 662e 7261 6e64 6f6d 3a0d  if self.random:.
-00017e30: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00017e40: 2076 616c 7565 203d 2073 7065 632e 7261   value = spec.ra
-00017e50: 6e64 2873 6861 7065 290d 0a20 2020 2020  nd(shape)..     
-00017e60: 2020 2020 2020 2065 6c73 653a 0d0a 2020         else:..  
-00017e70: 2020 2020 2020 2020 2020 2020 2020 7661                va
-00017e80: 6c75 6520 3d20 746f 7263 682e 6675 6c6c  lue = torch.full
-00017e90: 5f6c 696b 6528 0d0a 2020 2020 2020 2020  _like(..        
-00017ea0: 2020 2020 2020 2020 2020 2020 7370 6563              spec
-00017eb0: 2e7a 6572 6f28 7368 6170 6529 2c0d 0a20  .zero(shape),.. 
-00017ec0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017ed0: 2020 2073 656c 662e 6465 6661 756c 745f     self.default_
-00017ee0: 7661 6c75 652c 0d0a 2020 2020 2020 2020  value,..        
-00017ef0: 2020 2020 2020 2020 290d 0a20 2020 2020          )..     
-00017f00: 2020 2020 2020 2074 656e 736f 7264 6963         tensordic
-00017f10: 742e 7365 7428 6b65 792c 2076 616c 7565  t.set(key, value
-00017f20: 290d 0a20 2020 2020 2020 2072 6574 7572  )..        retur
-00017f30: 6e20 7465 6e73 6f72 6469 6374 0d0a 0d0a  n tensordict....
-00017f40: 2020 2020 6465 6620 5f5f 7265 7072 5f5f      def __repr__
-00017f50: 2873 656c 6629 202d 3e20 7374 723a 0d0a  (self) -> str:..
-00017f60: 2020 2020 2020 2020 636c 6173 735f 6e61          class_na
-00017f70: 6d65 203d 2073 656c 662e 5f5f 636c 6173  me = self.__clas
-00017f80: 735f 5f2e 5f5f 6e61 6d65 5f5f 0d0a 2020  s__.__name__..  
-00017f90: 2020 2020 2020 7265 7475 726e 2066 227b        return f"{
-00017fa0: 636c 6173 735f 6e61 6d65 7d28 7072 696d  class_name}(prim
-00017fb0: 6572 733d 7b73 656c 662e 7072 696d 6572  ers={self.primer
-00017fc0: 737d 2c20 6465 6661 756c 745f 7661 6c75  s}, default_valu
-00017fd0: 653d 7b73 656c 662e 6465 6661 756c 745f  e={self.default_
-00017fe0: 7661 6c75 657d 2c20 7261 6e64 6f6d 3d7b  value}, random={
-00017ff0: 7365 6c66 2e72 616e 646f 6d7d 2922 0d0a  self.random})"..
-00018000: 0d0a 0d0a 636c 6173 7320 5069 6e4d 656d  ....class PinMem
-00018010: 6f72 7954 7261 6e73 666f 726d 2854 7261  oryTransform(Tra
-00018020: 6e73 666f 726d 293a 0d0a 2020 2020 2222  nsform):..    ""
-00018030: 2243 616c 6c73 2070 696e 5f6d 656d 6f72  "Calls pin_memor
-00018040: 7920 6f6e 2074 6865 2074 656e 736f 7264  y on the tensord
-00018050: 6963 7420 746f 2066 6163 696c 6974 6174  ict to facilitat
-00018060: 6520 7772 6974 696e 6720 6f6e 2043 5544  e writing on CUD
-00018070: 4120 6465 7669 6365 732e 2222 220d 0a0d  A devices."""...
-00018080: 0a20 2020 2064 6566 205f 5f69 6e69 745f  .    def __init_
-00018090: 5f28 7365 6c66 293a 0d0a 2020 2020 2020  _(self):..      
-000180a0: 2020 7375 7065 7228 292e 5f5f 696e 6974    super().__init
-000180b0: 5f5f 285b 5d29 0d0a 0d0a 2020 2020 6465  __([])....    de
-000180c0: 6620 5f63 616c 6c28 7365 6c66 2c20 7465  f _call(self, te
-000180d0: 6e73 6f72 6469 6374 3a20 5465 6e73 6f72  nsordict: Tensor
-000180e0: 4469 6374 4261 7365 2920 2d3e 2054 656e  DictBase) -> Ten
-000180f0: 736f 7244 6963 7442 6173 653a 0d0a 2020  sorDictBase:..  
-00018100: 2020 2020 2020 7265 7475 726e 2074 656e        return ten
-00018110: 736f 7264 6963 742e 7069 6e5f 6d65 6d6f  sordict.pin_memo
-00018120: 7279 2829 0d0a 0d0a 2020 2020 666f 7277  ry()....    forw
-00018130: 6172 6420 3d20 5f63 616c 6c0d 0a0d 0a0d  ard = _call.....
-00018140: 0a64 6566 205f 7375 6d5f 6c65 6674 2876  .def _sum_left(v
-00018150: 616c 2c20 6465 7374 293a 0d0a 2020 2020  al, dest):..    
-00018160: 7768 696c 6520 7661 6c2e 6e64 696d 656e  while val.ndimen
-00018170: 7369 6f6e 2829 203e 2064 6573 742e 6e64  sion() > dest.nd
-00018180: 696d 656e 7369 6f6e 2829 3a0d 0a20 2020  imension():..   
-00018190: 2020 2020 2076 616c 203d 2076 616c 2e73       val = val.s
-000181a0: 756d 2830 290d 0a20 2020 2072 6574 7572  um(0)..    retur
-000181b0: 6e20 7661 6c0d 0a0d 0a0d 0a63 6c61 7373  n val......class
-000181c0: 2067 5344 454e 6f69 7365 2854 656e 736f   gSDENoise(Tenso
-000181d0: 7244 6963 7450 7269 6d65 7229 3a0d 0a20  rDictPrimer):.. 
-000181e0: 2020 2022 2222 4120 6753 4445 206e 6f69     """A gSDE noi
-000181f0: 7365 2069 6e69 7469 616c 697a 6572 2e0d  se initializer..
-00018200: 0a0d 0a20 2020 2053 6565 2074 6865 203a  ...    See the :
-00018210: 6675 6e63 3a60 7e74 6f72 6368 726c 2e6d  func:`~torchrl.m
-00018220: 6f64 756c 6573 2e6d 6f64 656c 732e 6578  odules.models.ex
-00018230: 706c 6f72 6174 696f 6e2e 6753 4445 4d6f  ploration.gSDEMo
-00018240: 6475 6c65 2720 666f 7220 6d6f 7265 2069  dule' for more i
-00018250: 6e66 6f2e 0d0a 2020 2020 2222 220d 0a0d  nfo...    """...
-00018260: 0a20 2020 2064 6566 205f 5f69 6e69 745f  .    def __init_
-00018270: 5f28 0d0a 2020 2020 2020 2020 7365 6c66  _(..        self
-00018280: 2c0d 0a20 2020 2020 2020 2073 7461 7465  ,..        state
-00018290: 5f64 696d 3d4e 6f6e 652c 0d0a 2020 2020  _dim=None,..    
-000182a0: 2020 2020 6163 7469 6f6e 5f64 696d 3d4e      action_dim=N
-000182b0: 6f6e 652c 0d0a 2020 2020 2020 2020 7368  one,..        sh
-000182c0: 6170 653d 4e6f 6e65 2c0d 0a20 2020 2029  ape=None,..    )
-000182d0: 202d 3e20 4e6f 6e65 3a0d 0a20 2020 2020   -> None:..     
-000182e0: 2020 2073 656c 662e 7374 6174 655f 6469     self.state_di
-000182f0: 6d20 3d20 7374 6174 655f 6469 6d0d 0a20  m = state_dim.. 
-00018300: 2020 2020 2020 2073 656c 662e 6163 7469         self.acti
-00018310: 6f6e 5f64 696d 203d 2061 6374 696f 6e5f  on_dim = action_
-00018320: 6469 6d0d 0a20 2020 2020 2020 2069 6620  dim..        if 
-00018330: 7368 6170 6520 6973 204e 6f6e 653a 0d0a  shape is None:..
-00018340: 2020 2020 2020 2020 2020 2020 7368 6170              shap
-00018350: 6520 3d20 2829 0d0a 2020 2020 2020 2020  e = ()..        
-00018360: 7461 696c 5f64 696d 203d 2028 0d0a 2020  tail_dim = (..  
-00018370: 2020 2020 2020 2020 2020 2831 2c29 2069            (1,) i
-00018380: 6620 7374 6174 655f 6469 6d20 6973 204e  f state_dim is N
-00018390: 6f6e 6520 6f72 2061 6374 696f 6e5f 6469  one or action_di
-000183a0: 6d20 6973 204e 6f6e 6520 656c 7365 2028  m is None else (
-000183b0: 6163 7469 6f6e 5f64 696d 2c20 7374 6174  action_dim, stat
-000183c0: 655f 6469 6d29 0d0a 2020 2020 2020 2020  e_dim)..        
-000183d0: 290d 0a20 2020 2020 2020 2072 616e 646f  )..        rando
-000183e0: 6d20 3d20 7374 6174 655f 6469 6d20 6973  m = state_dim is
-000183f0: 206e 6f74 204e 6f6e 6520 616e 6420 6163   not None and ac
-00018400: 7469 6f6e 5f64 696d 2069 7320 6e6f 7420  tion_dim is not 
-00018410: 4e6f 6e65 0d0a 2020 2020 2020 2020 7368  None..        sh
-00018420: 6170 6520 3d20 7475 706c 6528 7368 6170  ape = tuple(shap
-00018430: 6529 202b 2074 6169 6c5f 6469 6d0d 0a20  e) + tail_dim.. 
-00018440: 2020 2020 2020 2070 7269 6d65 7273 203d         primers =
-00018450: 207b 225f 6570 735f 6753 4445 223a 2055   {"_eps_gSDE": U
-00018460: 6e62 6f75 6e64 6564 436f 6e74 696e 756f  nboundedContinuo
-00018470: 7573 5465 6e73 6f72 5370 6563 2873 6861  usTensorSpec(sha
-00018480: 7065 3d73 6861 7065 297d 0d0a 2020 2020  pe=shape)}..    
-00018490: 2020 2020 7375 7065 7228 292e 5f5f 696e      super().__in
-000184a0: 6974 5f5f 2870 7269 6d65 7273 3d70 7269  it__(primers=pri
-000184b0: 6d65 7273 2c20 7261 6e64 6f6d 3d72 616e  mers, random=ran
-000184c0: 646f 6d29 0d0a 0d0a 0d0a 636c 6173 7320  dom)......class 
-000184d0: 5665 634e 6f72 6d28 5472 616e 7366 6f72  VecNorm(Transfor
-000184e0: 6d29 3a0d 0a20 2020 2022 2222 4d6f 7669  m):..    """Movi
-000184f0: 6e67 2061 7665 7261 6765 206e 6f72 6d61  ng average norma
-00018500: 6c69 7a61 7469 6f6e 206c 6179 6572 2066  lization layer f
-00018510: 6f72 2074 6f72 6368 726c 2065 6e76 6972  or torchrl envir
-00018520: 6f6e 6d65 6e74 732e 0d0a 0d0a 2020 2020  onments.....    
-00018530: 5665 634e 6f72 6d20 6b65 6570 7320 7472  VecNorm keeps tr
-00018540: 6163 6b20 6f66 2074 6865 2073 756d 6d61  ack of the summa
-00018550: 7279 2073 7461 7469 7374 6963 7320 6f66  ry statistics of
-00018560: 2061 2064 6174 6173 6574 2074 6f20 7374   a dataset to st
-00018570: 616e 6461 7264 697a 650d 0a20 2020 2069  andardize..    i
-00018580: 7420 6f6e 2d74 6865 2d66 6c79 2e20 4966  t on-the-fly. If
-00018590: 2074 6865 2074 7261 6e73 666f 726d 2069   the transform i
-000185a0: 7320 696e 2027 6576 616c 2720 6d6f 6465  s in 'eval' mode
-000185b0: 2c20 7468 6520 7275 6e6e 696e 670d 0a20  , the running.. 
-000185c0: 2020 2073 7461 7469 7374 6963 7320 6172     statistics ar
-000185d0: 6520 6e6f 7420 7570 6461 7465 642e 0d0a  e not updated...
-000185e0: 0d0a 2020 2020 4966 206d 756c 7469 706c  ..    If multipl
-000185f0: 6520 7072 6f63 6573 7365 7320 6172 6520  e processes are 
-00018600: 7275 6e6e 696e 6720 6120 7369 6d69 6c61  running a simila
-00018610: 7220 656e 7669 726f 6e6d 656e 742c 206f  r environment, o
-00018620: 6e65 2063 616e 2070 6173 7320 610d 0a20  ne can pass a.. 
-00018630: 2020 2054 656e 736f 7244 6963 7442 6173     TensorDictBas
-00018640: 6520 696e 7374 616e 6365 2074 6861 7420  e instance that 
-00018650: 6973 2070 6c61 6365 6420 696e 2073 6861  is placed in sha
-00018660: 7265 6420 6d65 6d6f 7279 3a20 6966 2073  red memory: if s
-00018670: 6f2c 2065 7665 7279 2074 696d 650d 0a20  o, every time.. 
-00018680: 2020 2074 6865 206e 6f72 6d61 6c69 7a61     the normaliza
-00018690: 7469 6f6e 206c 6179 6572 2069 7320 7175  tion layer is qu
-000186a0: 6572 6965 6420 6974 2077 696c 6c20 7570  eried it will up
-000186b0: 6461 7465 2074 6865 2076 616c 7565 7320  date the values 
-000186c0: 666f 7220 616c 6c0d 0a20 2020 2070 726f  for all..    pro
-000186d0: 6365 7373 6573 2074 6861 7420 7368 6172  cesses that shar
-000186e0: 6520 7468 6520 7361 6d65 2072 6566 6572  e the same refer
-000186f0: 656e 6365 2e0d 0a0d 0a20 2020 2054 6f20  ence.....    To 
-00018700: 7573 6520 5665 634e 6f72 6d20 6174 2069  use VecNorm at i
-00018710: 6e66 6572 656e 6365 2074 696d 6520 616e  nference time an
-00018720: 6420 6176 6f69 6420 7570 6461 7469 6e67  d avoid updating
-00018730: 2074 6865 2076 616c 7565 7320 7769 7468   the values with
-00018740: 2074 6865 206e 6577 0d0a 2020 2020 6f62   the new..    ob
-00018750: 7365 7276 6174 696f 6e73 2c20 6f6e 6520  servations, one 
-00018760: 7368 6f75 6c64 2073 7562 7374 6974 7574  should substitut
-00018770: 6520 7468 6973 206c 6179 6572 2062 7920  e this layer by 
-00018780: 6076 6563 6e6f 726d 2e74 6f5f 6f62 7365  `vecnorm.to_obse
-00018790: 7276 6174 696f 6e5f 6e6f 726d 2829 602e  rvation_norm()`.
-000187a0: 0d0a 0d0a 2020 2020 4172 6773 3a0d 0a20  ....    Args:.. 
-000187b0: 2020 2020 2020 2069 6e5f 6b65 7973 2028         in_keys (
-000187c0: 6974 6572 6162 6c65 206f 6620 7374 722c  iterable of str,
-000187d0: 206f 7074 696f 6e61 6c29 3a20 6b65 7973   optional): keys
-000187e0: 2074 6f20 6265 2075 7064 6174 6564 2e0d   to be updated..
-000187f0: 0a20 2020 2020 2020 2020 2020 2064 6566  .            def
-00018800: 6175 6c74 3a20 5b22 6f62 7365 7276 6174  ault: ["observat
-00018810: 696f 6e22 2c20 2272 6577 6172 6422 5d0d  ion", "reward"].
-00018820: 0a20 2020 2020 2020 2073 6861 7265 645f  .        shared_
-00018830: 7464 2028 5465 6e73 6f72 4469 6374 4261  td (TensorDictBa
-00018840: 7365 2c20 6f70 7469 6f6e 616c 293a 2041  se, optional): A
-00018850: 2073 6861 7265 6420 7465 6e73 6f72 6469   shared tensordi
-00018860: 6374 2063 6f6e 7461 696e 696e 6720 7468  ct containing th
-00018870: 650d 0a20 2020 2020 2020 2020 2020 206b  e..            k
-00018880: 6579 7320 6f66 2074 6865 2074 7261 6e73  eys of the trans
-00018890: 666f 726d 2e0d 0a20 2020 2020 2020 2064  form...        d
-000188a0: 6563 6179 2028 6e75 6d62 6572 2c20 6f70  ecay (number, op
-000188b0: 7469 6f6e 616c 293a 2064 6563 6179 2072  tional): decay r
-000188c0: 6174 6520 6f66 2074 6865 206d 6f76 696e  ate of the movin
-000188d0: 6720 6176 6572 6167 652e 0d0a 2020 2020  g average...    
-000188e0: 2020 2020 2020 2020 6465 6661 756c 743a          default:
-000188f0: 2030 2e39 390d 0a20 2020 2020 2020 2065   0.99..        e
-00018900: 7073 2028 6e75 6d62 6572 2c20 6f70 7469  ps (number, opti
-00018910: 6f6e 616c 293a 206c 6f77 6572 2062 6f75  onal): lower bou
-00018920: 6e64 206f 6620 7468 6520 7275 6e6e 696e  nd of the runnin
-00018930: 6720 7374 616e 6461 7264 0d0a 2020 2020  g standard..    
-00018940: 2020 2020 2020 2020 6465 7669 6174 696f          deviatio
-00018950: 6e20 2866 6f72 206e 756d 6572 6963 616c  n (for numerical
-00018960: 2075 6e64 6572 666c 6f77 292e 2044 6566   underflow). Def
-00018970: 6175 6c74 2069 7320 3165 2d34 2e0d 0a0d  ault is 1e-4....
-00018980: 0a20 2020 2045 7861 6d70 6c65 733a 0d0a  .    Examples:..
-00018990: 2020 2020 2020 2020 3e3e 3e20 6672 6f6d          >>> from
-000189a0: 2074 6f72 6368 726c 2e65 6e76 732e 6c69   torchrl.envs.li
-000189b0: 6273 2e67 796d 2069 6d70 6f72 7420 4779  bs.gym import Gy
-000189c0: 6d45 6e76 0d0a 2020 2020 2020 2020 3e3e  mEnv..        >>
-000189d0: 3e20 7420 3d20 5665 634e 6f72 6d28 6465  > t = VecNorm(de
-000189e0: 6361 793d 302e 3929 0d0a 2020 2020 2020  cay=0.9)..      
-000189f0: 2020 3e3e 3e20 656e 7620 3d20 4779 6d45    >>> env = GymE
-00018a00: 6e76 2822 5065 6e64 756c 756d 2d76 3022  nv("Pendulum-v0"
-00018a10: 290d 0a20 2020 2020 2020 203e 3e3e 2065  )..        >>> e
-00018a20: 6e76 203d 2054 7261 6e73 666f 726d 6564  nv = Transformed
-00018a30: 456e 7628 656e 762c 2074 290d 0a20 2020  Env(env, t)..   
-00018a40: 2020 2020 203e 3e3e 2074 6473 203d 205b       >>> tds = [
-00018a50: 5d0d 0a20 2020 2020 2020 203e 3e3e 2066  ]..        >>> f
-00018a60: 6f72 205f 2069 6e20 7261 6e67 6528 3130  or _ in range(10
-00018a70: 3030 293a 0d0a 2020 2020 2020 2020 2e2e  00):..        ..
-00018a80: 2e20 2020 2020 7464 203d 2065 6e76 2e72  .     td = env.r
-00018a90: 616e 645f 7374 6570 2829 0d0a 2020 2020  and_step()..    
-00018aa0: 2020 2020 2e2e 2e20 2020 2020 6966 2074      ...     if t
-00018ab0: 642e 6765 7428 2264 6f6e 6522 293a 0d0a  d.get("done"):..
-00018ac0: 2020 2020 2020 2020 2e2e 2e20 2020 2020          ...     
-00018ad0: 2020 2020 5f20 3d20 656e 762e 7265 7365      _ = env.rese
-00018ae0: 7428 290d 0a20 2020 2020 2020 202e 2e2e  t()..        ...
-00018af0: 2020 2020 2074 6473 202b 3d20 5b74 645d       tds += [td]
-00018b00: 0d0a 2020 2020 2020 2020 3e3e 3e20 7464  ..        >>> td
-00018b10: 7320 3d20 746f 7263 682e 7374 6163 6b28  s = torch.stack(
-00018b20: 7464 732c 2030 290d 0a20 2020 2020 2020  tds, 0)..       
-00018b30: 203e 3e3e 2070 7269 6e74 2828 6162 7328   >>> print((abs(
-00018b40: 7464 732e 6765 7428 2822 6e65 7874 222c  tds.get(("next",
-00018b50: 2022 6f62 7365 7276 6174 696f 6e22 2929   "observation"))
-00018b60: 2e6d 6561 6e28 3029 293c 302e 3229 2e61  .mean(0))<0.2).a
-00018b70: 6c6c 2829 290d 0a20 2020 2020 2020 2074  ll())..        t
-00018b80: 656e 736f 7228 5472 7565 290d 0a20 2020  ensor(True)..   
-00018b90: 2020 2020 203e 3e3e 2070 7269 6e74 2828       >>> print((
-00018ba0: 6162 7328 7464 732e 6765 7428 2822 6e65  abs(tds.get(("ne
-00018bb0: 7874 222c 2022 6f62 7365 7276 6174 696f  xt", "observatio
-00018bc0: 6e22 2929 2e73 7464 2830 292d 3129 3c30  n")).std(0)-1)<0
-00018bd0: 2e32 292e 616c 6c28 2929 0d0a 2020 2020  .2).all())..    
-00018be0: 2020 2020 7465 6e73 6f72 2854 7275 6529      tensor(True)
-00018bf0: 0d0a 0d0a 2020 2020 2222 220d 0a0d 0a20  ....    """.... 
-00018c00: 2020 2064 6566 205f 5f69 6e69 745f 5f28     def __init__(
-00018c10: 0d0a 2020 2020 2020 2020 7365 6c66 2c0d  ..        self,.
-00018c20: 0a20 2020 2020 2020 2069 6e5f 6b65 7973  .        in_keys
-00018c30: 3a20 4f70 7469 6f6e 616c 5b53 6571 7565  : Optional[Seque
-00018c40: 6e63 655b 7374 725d 5d20 3d20 4e6f 6e65  nce[str]] = None
-00018c50: 2c0d 0a20 2020 2020 2020 2073 6861 7265  ,..        share
-00018c60: 645f 7464 3a20 4f70 7469 6f6e 616c 5b54  d_td: Optional[T
-00018c70: 656e 736f 7244 6963 7442 6173 655d 203d  ensorDictBase] =
-00018c80: 204e 6f6e 652c 0d0a 2020 2020 2020 2020   None,..        
-00018c90: 6c6f 636b 3a20 6d70 2e4c 6f63 6b20 3d20  lock: mp.Lock = 
-00018ca0: 4e6f 6e65 2c0d 0a20 2020 2020 2020 2064  None,..        d
-00018cb0: 6563 6179 3a20 666c 6f61 7420 3d20 302e  ecay: float = 0.
-00018cc0: 3939 3939 2c0d 0a20 2020 2020 2020 2065  9999,..        e
-00018cd0: 7073 3a20 666c 6f61 7420 3d20 3165 2d34  ps: float = 1e-4
-00018ce0: 2c0d 0a20 2020 2029 202d 3e20 4e6f 6e65  ,..    ) -> None
-00018cf0: 3a0d 0a20 2020 2020 2020 2069 6620 6c6f  :..        if lo
-00018d00: 636b 2069 7320 4e6f 6e65 3a0d 0a20 2020  ck is None:..   
-00018d10: 2020 2020 2020 2020 206c 6f63 6b20 3d20           lock = 
-00018d20: 6d70 2e4c 6f63 6b28 290d 0a20 2020 2020  mp.Lock()..     
-00018d30: 2020 2069 6620 696e 5f6b 6579 7320 6973     if in_keys is
-00018d40: 204e 6f6e 653a 0d0a 2020 2020 2020 2020   None:..        
-00018d50: 2020 2020 696e 5f6b 6579 7320 3d20 5b22      in_keys = ["
-00018d60: 6f62 7365 7276 6174 696f 6e22 2c20 2272  observation", "r
-00018d70: 6577 6172 6422 5d0d 0a20 2020 2020 2020  eward"]..       
-00018d80: 2073 7570 6572 2829 2e5f 5f69 6e69 745f   super().__init_
-00018d90: 5f28 696e 5f6b 6579 7329 0d0a 2020 2020  _(in_keys)..    
-00018da0: 2020 2020 7365 6c66 2e5f 7464 203d 2073      self._td = s
-00018db0: 6861 7265 645f 7464 0d0a 2020 2020 2020  hared_td..      
-00018dc0: 2020 6966 2073 6861 7265 645f 7464 2069    if shared_td i
-00018dd0: 7320 6e6f 7420 4e6f 6e65 2061 6e64 206e  s not None and n
-00018de0: 6f74 2028 0d0a 2020 2020 2020 2020 2020  ot (..          
-00018df0: 2020 7368 6172 6564 5f74 642e 6973 5f73    shared_td.is_s
-00018e00: 6861 7265 6428 2920 6f72 2073 6861 7265  hared() or share
-00018e10: 645f 7464 2e69 735f 6d65 6d6d 6170 2829  d_td.is_memmap()
-00018e20: 0d0a 2020 2020 2020 2020 293a 0d0a 2020  ..        ):..  
-00018e30: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
-00018e40: 5275 6e74 696d 6545 7272 6f72 280d 0a20  RuntimeError(.. 
-00018e50: 2020 2020 2020 2020 2020 2020 2020 2022                 "
-00018e60: 7368 6172 6564 5f74 6420 6d75 7374 2062  shared_td must b
-00018e70: 6520 6569 7468 6572 2069 6e20 7368 6172  e either in shar
-00018e80: 6564 206d 656d 6f72 7920 6f72 2061 206d  ed memory or a m
-00018e90: 656d 6d61 7020 2220 2274 656e 736f 7264  emmap " "tensord
-00018ea0: 6963 742e 220d 0a20 2020 2020 2020 2020  ict."..         
-00018eb0: 2020 2029 0d0a 2020 2020 2020 2020 6966     )..        if
-00018ec0: 2073 6861 7265 645f 7464 2069 7320 6e6f   shared_td is no
-00018ed0: 7420 4e6f 6e65 3a0d 0a20 2020 2020 2020  t None:..       
-00018ee0: 2020 2020 2066 6f72 206b 6579 2069 6e20       for key in 
-00018ef0: 696e 5f6b 6579 733a 0d0a 2020 2020 2020  in_keys:..      
-00018f00: 2020 2020 2020 2020 2020 6966 2028 0d0a            if (..
-00018f10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018f20: 2020 2020 286b 6579 202b 2022 5f73 756d      (key + "_sum
-00018f30: 2220 6e6f 7420 696e 2073 6861 7265 645f  " not in shared_
-00018f40: 7464 2e6b 6579 7328 2929 0d0a 2020 2020  td.keys())..    
-00018f50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018f60: 6f72 2028 6b65 7920 2b20 225f 7373 7122  or (key + "_ssq"
-00018f70: 206e 6f74 2069 6e20 7368 6172 6564 5f74   not in shared_t
-00018f80: 642e 6b65 7973 2829 290d 0a20 2020 2020  d.keys())..     
-00018f90: 2020 2020 2020 2020 2020 2020 2020 206f                 o
-00018fa0: 7220 286b 6579 202b 2022 5f63 6f75 6e74  r (key + "_count
-00018fb0: 2220 6e6f 7420 696e 2073 6861 7265 645f  " not in shared_
-00018fc0: 7464 2e6b 6579 7328 2929 0d0a 2020 2020  td.keys())..    
-00018fd0: 2020 2020 2020 2020 2020 2020 293a 0d0a              ):..
-00018fe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018ff0: 2020 2020 7261 6973 6520 4b65 7945 7272      raise KeyErr
-00019000: 6f72 280d 0a20 2020 2020 2020 2020 2020  or(..           
-00019010: 2020 2020 2020 2020 2020 2020 2066 226b               f"k
-00019020: 6579 207b 6b65 797d 206e 6f74 2070 7265  ey {key} not pre
-00019030: 7365 6e74 2069 6e20 7468 6520 7368 6172  sent in the shar
-00019040: 6564 2074 656e 736f 7264 6963 7420 220d  ed tensordict ".
-00019050: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00019060: 2020 2020 2020 2020 2066 2277 6974 6820           f"with 
-00019070: 6b65 7973 207b 7368 6172 6564 5f74 642e  keys {shared_td.
-00019080: 6b65 7973 2829 7d22 0d0a 2020 2020 2020  keys()}"..      
-00019090: 2020 2020 2020 2020 2020 2020 2020 290d                ).
-000190a0: 0a0d 0a20 2020 2020 2020 2073 656c 662e  ...        self.
-000190b0: 6c6f 636b 203d 206c 6f63 6b0d 0a20 2020  lock = lock..   
-000190c0: 2020 2020 2073 656c 662e 6465 6361 7920       self.decay 
-000190d0: 3d20 6465 6361 790d 0a20 2020 2020 2020  = decay..       
-000190e0: 2073 656c 662e 6570 7320 3d20 6570 730d   self.eps = eps.
-000190f0: 0a0d 0a20 2020 2064 6566 205f 6361 6c6c  ...    def _call
-00019100: 2873 656c 662c 2074 656e 736f 7264 6963  (self, tensordic
-00019110: 743a 2054 656e 736f 7244 6963 7442 6173  t: TensorDictBas
-00019120: 6529 202d 3e20 5465 6e73 6f72 4469 6374  e) -> TensorDict
-00019130: 4261 7365 3a0d 0a20 2020 2020 2020 2069  Base:..        i
-00019140: 6620 7365 6c66 2e6c 6f63 6b20 6973 206e  f self.lock is n
-00019150: 6f74 204e 6f6e 653a 0d0a 2020 2020 2020  ot None:..      
-00019160: 2020 2020 2020 7365 6c66 2e6c 6f63 6b2e        self.lock.
-00019170: 6163 7175 6972 6528 290d 0a0d 0a20 2020  acquire()....   
-00019180: 2020 2020 2066 6f72 206b 6579 2069 6e20       for key in 
-00019190: 7365 6c66 2e69 6e5f 6b65 7973 3a0d 0a20  self.in_keys:.. 
-000191a0: 2020 2020 2020 2020 2020 2069 6620 6b65             if ke
-000191b0: 7920 6e6f 7420 696e 2074 656e 736f 7264  y not in tensord
-000191c0: 6963 742e 6b65 7973 2869 6e63 6c75 6465  ict.keys(include
-000191d0: 5f6e 6573 7465 643d 5472 7565 293a 0d0a  _nested=True):..
-000191e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000191f0: 636f 6e74 696e 7565 0d0a 2020 2020 2020  continue..      
-00019200: 2020 2020 2020 7365 6c66 2e5f 696e 6974        self._init
-00019210: 2874 656e 736f 7264 6963 742c 206b 6579  (tensordict, key
-00019220: 290d 0a20 2020 2020 2020 2020 2020 2023  )..            #
-00019230: 2075 7064 6174 6520 616e 6420 7374 616e   update and stan
-00019240: 6461 7264 697a 650d 0a20 2020 2020 2020  dardize..       
-00019250: 2020 2020 206e 6577 5f76 616c 203d 2073       new_val = s
-00019260: 656c 662e 5f75 7064 6174 6528 0d0a 2020  elf._update(..  
-00019270: 2020 2020 2020 2020 2020 2020 2020 6b65                ke
-00019280: 792c 2074 656e 736f 7264 6963 742e 6765  y, tensordict.ge
-00019290: 7428 6b65 7929 2c20 4e3d 6d61 7828 312c  t(key), N=max(1,
-000192a0: 2074 656e 736f 7264 6963 742e 6e75 6d65   tensordict.nume
-000192b0: 6c28 2929 0d0a 2020 2020 2020 2020 2020  l())..          
-000192c0: 2020 290d 0a0d 0a20 2020 2020 2020 2020    )....         
-000192d0: 2020 2074 656e 736f 7264 6963 742e 7365     tensordict.se
-000192e0: 7428 6b65 792c 206e 6577 5f76 616c 290d  t(key, new_val).
-000192f0: 0a0d 0a20 2020 2020 2020 2069 6620 7365  ...        if se
-00019300: 6c66 2e6c 6f63 6b20 6973 206e 6f74 204e  lf.lock is not N
-00019310: 6f6e 653a 0d0a 2020 2020 2020 2020 2020  one:..          
-00019320: 2020 7365 6c66 2e6c 6f63 6b2e 7265 6c65    self.lock.rele
-00019330: 6173 6528 290d 0a0d 0a20 2020 2020 2020  ase()....       
-00019340: 2072 6574 7572 6e20 7465 6e73 6f72 6469   return tensordi
-00019350: 6374 0d0a 0d0a 2020 2020 666f 7277 6172  ct....    forwar
-00019360: 6420 3d20 5f63 616c 6c0d 0a0d 0a20 2020  d = _call....   
-00019370: 2064 6566 205f 696e 6974 2873 656c 662c   def _init(self,
-00019380: 2074 656e 736f 7264 6963 743a 2054 656e   tensordict: Ten
-00019390: 736f 7244 6963 7442 6173 652c 206b 6579  sorDictBase, key
-000193a0: 3a20 7374 7229 202d 3e20 4e6f 6e65 3a0d  : str) -> None:.
-000193b0: 0a20 2020 2020 2020 2069 6620 7365 6c66  .        if self
-000193c0: 2e5f 7464 2069 7320 4e6f 6e65 206f 7220  ._td is None or 
-000193d0: 6b65 7920 2b20 225f 7375 6d22 206e 6f74  key + "_sum" not
-000193e0: 2069 6e20 7365 6c66 2e5f 7464 2e6b 6579   in self._td.key
-000193f0: 7328 293a 0d0a 2020 2020 2020 2020 2020  s():..          
-00019400: 2020 7464 5f76 6965 7720 3d20 7465 6e73    td_view = tens
-00019410: 6f72 6469 6374 2e76 6965 7728 2d31 290d  ordict.view(-1).
-00019420: 0a20 2020 2020 2020 2020 2020 2074 645f  .            td_
-00019430: 7365 6c65 6374 203d 2074 645f 7669 6577  select = td_view
-00019440: 5b30 5d0d 0a20 2020 2020 2020 2020 2020  [0]..           
-00019450: 2064 203d 207b 6b65 7920 2b20 225f 7375   d = {key + "_su
-00019460: 6d22 3a20 746f 7263 682e 7a65 726f 735f  m": torch.zeros_
-00019470: 6c69 6b65 2874 645f 7365 6c65 6374 2e67  like(td_select.g
-00019480: 6574 286b 6579 2929 7d0d 0a20 2020 2020  et(key))}..     
-00019490: 2020 2020 2020 2064 2e75 7064 6174 6528         d.update(
-000194a0: 7b6b 6579 202b 2022 5f73 7371 223a 2074  {key + "_ssq": t
-000194b0: 6f72 6368 2e7a 6572 6f73 5f6c 696b 6528  orch.zeros_like(
-000194c0: 7464 5f73 656c 6563 742e 6765 7428 6b65  td_select.get(ke
-000194d0: 7929 297d 290d 0a20 2020 2020 2020 2020  y))})..         
-000194e0: 2020 2064 2e75 7064 6174 6528 0d0a 2020     d.update(..  
-000194f0: 2020 2020 2020 2020 2020 2020 2020 7b0d                {.
-00019500: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00019510: 2020 2020 206b 6579 0d0a 2020 2020 2020       key..      
-00019520: 2020 2020 2020 2020 2020 2020 2020 2b20                + 
-00019530: 225f 636f 756e 7422 3a20 746f 7263 682e  "_count": torch.
-00019540: 7a65 726f 7328 0d0a 2020 2020 2020 2020  zeros(..        
-00019550: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00019560: 312c 2064 6576 6963 653d 7464 5f73 656c  1, device=td_sel
-00019570: 6563 742e 6765 7428 6b65 7929 2e64 6576  ect.get(key).dev
-00019580: 6963 652c 2064 7479 7065 3d74 6f72 6368  ice, dtype=torch
-00019590: 2e66 6c6f 6174 0d0a 2020 2020 2020 2020  .float..        
-000195a0: 2020 2020 2020 2020 2020 2020 290d 0a20              ).. 
-000195b0: 2020 2020 2020 2020 2020 2020 2020 207d                 }
-000195c0: 0d0a 2020 2020 2020 2020 2020 2020 290d  ..            ).
-000195d0: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
-000195e0: 7365 6c66 2e5f 7464 2069 7320 4e6f 6e65  self._td is None
-000195f0: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
-00019600: 2020 2073 656c 662e 5f74 6420 3d20 5465     self._td = Te
-00019610: 6e73 6f72 4469 6374 2864 2c20 6261 7463  nsorDict(d, batc
-00019620: 685f 7369 7a65 3d5b 5d29 0d0a 2020 2020  h_size=[])..    
-00019630: 2020 2020 2020 2020 656c 7365 3a0d 0a20          else:.. 
-00019640: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-00019650: 656c 662e 5f74 642e 7570 6461 7465 2864  elf._td.update(d
-00019660: 290d 0a20 2020 2020 2020 2065 6c73 653a  )..        else:
-00019670: 0d0a 2020 2020 2020 2020 2020 2020 7061  ..            pa
-00019680: 7373 0d0a 0d0a 2020 2020 6465 6620 5f75  ss....    def _u
-00019690: 7064 6174 6528 7365 6c66 2c20 6b65 792c  pdate(self, key,
-000196a0: 2076 616c 7565 2c20 4e29 202d 3e20 746f   value, N) -> to
-000196b0: 7263 682e 5465 6e73 6f72 3a0d 0a20 2020  rch.Tensor:..   
-000196c0: 2020 2020 205f 7375 6d20 3d20 7365 6c66       _sum = self
-000196d0: 2e5f 7464 2e67 6574 286b 6579 202b 2022  ._td.get(key + "
-000196e0: 5f73 756d 2229 0d0a 2020 2020 2020 2020  _sum")..        
-000196f0: 5f73 7371 203d 2073 656c 662e 5f74 642e  _ssq = self._td.
-00019700: 6765 7428 6b65 7920 2b20 225f 7373 7122  get(key + "_ssq"
-00019710: 290d 0a20 2020 2020 2020 205f 636f 756e  )..        _coun
-00019720: 7420 3d20 7365 6c66 2e5f 7464 2e67 6574  t = self._td.get
-00019730: 286b 6579 202b 2022 5f63 6f75 6e74 2229  (key + "_count")
-00019740: 0d0a 0d0a 2020 2020 2020 2020 5f73 756d  ....        _sum
-00019750: 203d 2073 656c 662e 5f74 642e 6765 7428   = self._td.get(
-00019760: 6b65 7920 2b20 225f 7375 6d22 290d 0a20  key + "_sum").. 
-00019770: 2020 2020 2020 2076 616c 7565 5f73 756d         value_sum
-00019780: 203d 205f 7375 6d5f 6c65 6674 2876 616c   = _sum_left(val
-00019790: 7565 2c20 5f73 756d 290d 0a20 2020 2020  ue, _sum)..     
-000197a0: 2020 205f 7375 6d20 2a3d 2073 656c 662e     _sum *= self.
-000197b0: 6465 6361 790d 0a20 2020 2020 2020 205f  decay..        _
-000197c0: 7375 6d20 2b3d 2076 616c 7565 5f73 756d  sum += value_sum
-000197d0: 0d0a 2020 2020 2020 2020 7365 6c66 2e5f  ..        self._
-000197e0: 7464 2e73 6574 5f28 0d0a 2020 2020 2020  td.set_(..      
-000197f0: 2020 2020 2020 6b65 7920 2b20 225f 7375        key + "_su
-00019800: 6d22 2c0d 0a20 2020 2020 2020 2020 2020  m",..           
-00019810: 205f 7375 6d2c 0d0a 2020 2020 2020 2020   _sum,..        
-00019820: 290d 0a0d 0a20 2020 2020 2020 205f 7373  )....        _ss
-00019830: 7120 3d20 7365 6c66 2e5f 7464 2e67 6574  q = self._td.get
-00019840: 286b 6579 202b 2022 5f73 7371 2229 0d0a  (key + "_ssq")..
-00019850: 2020 2020 2020 2020 7661 6c75 655f 7373          value_ss
-00019860: 7120 3d20 5f73 756d 5f6c 6566 7428 7661  q = _sum_left(va
-00019870: 6c75 652e 706f 7728 3229 2c20 5f73 7371  lue.pow(2), _ssq
-00019880: 290d 0a20 2020 2020 2020 205f 7373 7120  )..        _ssq 
-00019890: 2a3d 2073 656c 662e 6465 6361 790d 0a20  *= self.decay.. 
-000198a0: 2020 2020 2020 205f 7373 7120 2b3d 2076         _ssq += v
-000198b0: 616c 7565 5f73 7371 0d0a 2020 2020 2020  alue_ssq..      
-000198c0: 2020 7365 6c66 2e5f 7464 2e73 6574 5f28    self._td.set_(
-000198d0: 0d0a 2020 2020 2020 2020 2020 2020 6b65  ..            ke
-000198e0: 7920 2b20 225f 7373 7122 2c0d 0a20 2020  y + "_ssq",..   
-000198f0: 2020 2020 2020 2020 205f 7373 712c 0d0a           _ssq,..
-00019900: 2020 2020 2020 2020 290d 0a0d 0a20 2020          )....   
-00019910: 2020 2020 205f 636f 756e 7420 3d20 7365       _count = se
-00019920: 6c66 2e5f 7464 2e67 6574 286b 6579 202b  lf._td.get(key +
-00019930: 2022 5f63 6f75 6e74 2229 0d0a 2020 2020   "_count")..    
-00019940: 2020 2020 5f63 6f75 6e74 202a 3d20 7365      _count *= se
-00019950: 6c66 2e64 6563 6179 0d0a 2020 2020 2020  lf.decay..      
-00019960: 2020 5f63 6f75 6e74 202b 3d20 4e0d 0a20    _count += N.. 
-00019970: 2020 2020 2020 2073 656c 662e 5f74 642e         self._td.
-00019980: 7365 745f 280d 0a20 2020 2020 2020 2020  set_(..         
-00019990: 2020 206b 6579 202b 2022 5f63 6f75 6e74     key + "_count
-000199a0: 222c 0d0a 2020 2020 2020 2020 2020 2020  ",..            
-000199b0: 5f63 6f75 6e74 2c0d 0a20 2020 2020 2020  _count,..       
-000199c0: 2029 0d0a 0d0a 2020 2020 2020 2020 6d65   )....        me
-000199d0: 616e 203d 205f 7375 6d20 2f20 5f63 6f75  an = _sum / _cou
-000199e0: 6e74 0d0a 2020 2020 2020 2020 7374 6420  nt..        std 
-000199f0: 3d20 285f 7373 7120 2f20 5f63 6f75 6e74  = (_ssq / _count
-00019a00: 202d 206d 6561 6e2e 706f 7728 3229 292e   - mean.pow(2)).
-00019a10: 636c 616d 705f 6d69 6e28 7365 6c66 2e65  clamp_min(self.e
-00019a20: 7073 292e 7371 7274 2829 0d0a 2020 2020  ps).sqrt()..    
-00019a30: 2020 2020 7265 7475 726e 2028 7661 6c75      return (valu
-00019a40: 6520 2d20 6d65 616e 2920 2f20 7374 642e  e - mean) / std.
-00019a50: 636c 616d 705f 6d69 6e28 7365 6c66 2e65  clamp_min(self.e
-00019a60: 7073 290d 0a0d 0a20 2020 2064 6566 2074  ps)....    def t
-00019a70: 6f5f 6f62 7365 7276 6174 696f 6e5f 6e6f  o_observation_no
-00019a80: 726d 2873 656c 6629 202d 3e20 556e 696f  rm(self) -> Unio
-00019a90: 6e5b 436f 6d70 6f73 652c 204f 6273 6572  n[Compose, Obser
-00019aa0: 7661 7469 6f6e 4e6f 726d 5d3a 0d0a 2020  vationNorm]:..  
-00019ab0: 2020 2020 2020 2222 2243 6f6e 7665 7274        """Convert
-00019ac0: 7320 5665 634e 6f72 6d20 696e 746f 2061  s VecNorm into a
-00019ad0: 6e20 4f62 7365 7276 6174 696f 6e4e 6f72  n ObservationNor
-00019ae0: 6d20 636c 6173 7320 7468 6174 2063 616e  m class that can
-00019af0: 2062 6520 7573 6564 2061 7420 696e 6665   be used at infe
-00019b00: 7265 6e63 6520 7469 6d65 2e22 2222 0d0a  rence time."""..
-00019b10: 2020 2020 2020 2020 6f75 7420 3d20 5b5d          out = []
-00019b20: 0d0a 2020 2020 2020 2020 666f 7220 6b65  ..        for ke
-00019b30: 7920 696e 2073 656c 662e 696e 5f6b 6579  y in self.in_key
-00019b40: 733a 0d0a 2020 2020 2020 2020 2020 2020  s:..            
-00019b50: 5f73 756d 203d 2073 656c 662e 5f74 642e  _sum = self._td.
-00019b60: 6765 7428 6b65 7920 2b20 225f 7375 6d22  get(key + "_sum"
-00019b70: 290d 0a20 2020 2020 2020 2020 2020 205f  )..            _
-00019b80: 7373 7120 3d20 7365 6c66 2e5f 7464 2e67  ssq = self._td.g
-00019b90: 6574 286b 6579 202b 2022 5f73 7371 2229  et(key + "_ssq")
-00019ba0: 0d0a 2020 2020 2020 2020 2020 2020 5f63  ..            _c
-00019bb0: 6f75 6e74 203d 2073 656c 662e 5f74 642e  ount = self._td.
-00019bc0: 6765 7428 6b65 7920 2b20 225f 636f 756e  get(key + "_coun
-00019bd0: 7422 290d 0a20 2020 2020 2020 2020 2020  t")..           
-00019be0: 206d 6561 6e20 3d20 5f73 756d 202f 205f   mean = _sum / _
-00019bf0: 636f 756e 740d 0a20 2020 2020 2020 2020  count..         
-00019c00: 2020 2073 7464 203d 2028 5f73 7371 202f     std = (_ssq /
-00019c10: 205f 636f 756e 7420 2d20 6d65 616e 2e70   _count - mean.p
-00019c20: 6f77 2832 2929 2e63 6c61 6d70 5f6d 696e  ow(2)).clamp_min
-00019c30: 2873 656c 662e 6570 7329 2e73 7172 7428  (self.eps).sqrt(
-00019c40: 290d 0a0d 0a20 2020 2020 2020 2020 2020  )....           
-00019c50: 205f 6f75 7420 3d20 4f62 7365 7276 6174   _out = Observat
-00019c60: 696f 6e4e 6f72 6d28 0d0a 2020 2020 2020  ionNorm(..      
-00019c70: 2020 2020 2020 2020 2020 6c6f 633d 6d65            loc=me
-00019c80: 616e 2c0d 0a20 2020 2020 2020 2020 2020  an,..           
-00019c90: 2020 2020 2073 6361 6c65 3d73 7464 2c0d       scale=std,.
-00019ca0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00019cb0: 2073 7461 6e64 6172 645f 6e6f 726d 616c   standard_normal
-00019cc0: 3d54 7275 652c 0d0a 2020 2020 2020 2020  =True,..        
-00019cd0: 2020 2020 2020 2020 696e 5f6b 6579 733d          in_keys=
-00019ce0: 7365 6c66 2e69 6e5f 6b65 7973 2c0d 0a20  self.in_keys,.. 
-00019cf0: 2020 2020 2020 2020 2020 2029 0d0a 2020             )..  
-00019d00: 2020 2020 2020 2020 2020 6966 206c 656e            if len
-00019d10: 2873 656c 662e 696e 5f6b 6579 7329 203d  (self.in_keys) =
-00019d20: 3d20 313a 0d0a 2020 2020 2020 2020 2020  = 1:..          
-00019d30: 2020 2020 2020 7265 7475 726e 205f 6f75        return _ou
-00019d40: 740d 0a20 2020 2020 2020 2020 2020 2065  t..            e
-00019d50: 6c73 653a 0d0a 2020 2020 2020 2020 2020  lse:..          
-00019d60: 2020 2020 2020 6f75 7420 2b3d 204f 6273        out += Obs
-00019d70: 6572 7661 7469 6f6e 4e6f 726d 0d0a 2020  ervationNorm..  
-00019d80: 2020 2020 2020 7265 7475 726e 2043 6f6d        return Com
-00019d90: 706f 7365 282a 6f75 7429 0d0a 0d0a 2020  pose(*out)....  
-00019da0: 2020 4073 7461 7469 636d 6574 686f 640d    @staticmethod.
-00019db0: 0a20 2020 2064 6566 2062 7569 6c64 5f74  .    def build_t
-00019dc0: 645f 666f 725f 7368 6172 6564 5f76 6563  d_for_shared_vec
-00019dd0: 6e6f 726d 280d 0a20 2020 2020 2020 2065  norm(..        e
-00019de0: 6e76 3a20 456e 7642 6173 652c 0d0a 2020  nv: EnvBase,..  
-00019df0: 2020 2020 2020 6b65 7973 3a20 4f70 7469        keys: Opti
-00019e00: 6f6e 616c 5b53 6571 7565 6e63 655b 7374  onal[Sequence[st
-00019e10: 725d 5d20 3d20 4e6f 6e65 2c0d 0a20 2020  r]] = None,..   
-00019e20: 2020 2020 206d 656d 6d61 703a 2062 6f6f       memmap: boo
-00019e30: 6c20 3d20 4661 6c73 652c 0d0a 2020 2020  l = False,..    
-00019e40: 2920 2d3e 2054 656e 736f 7244 6963 7442  ) -> TensorDictB
-00019e50: 6173 653a 0d0a 2020 2020 2020 2020 2222  ase:..        ""
-00019e60: 2243 7265 6174 6573 2061 2073 6861 7265  "Creates a share
-00019e70: 6420 7465 6e73 6f72 6469 6374 2066 6f72  d tensordict for
-00019e80: 206e 6f72 6d61 6c69 7a61 7469 6f6e 2061   normalization a
-00019e90: 6372 6f73 7320 7072 6f63 6573 7365 732e  cross processes.
-00019ea0: 0d0a 0d0a 2020 2020 2020 2020 4172 6773  ....        Args
-00019eb0: 3a0d 0a20 2020 2020 2020 2020 2020 2065  :..            e
-00019ec0: 6e76 2028 456e 7642 6173 6529 3a20 6578  nv (EnvBase): ex
-00019ed0: 616d 706c 6520 656e 7669 726f 6e6d 656e  ample environmen
-00019ee0: 7420 746f 2062 6520 7573 6564 2074 6f20  t to be used to 
-00019ef0: 6372 6561 7465 2074 6865 0d0a 2020 2020  create the..    
-00019f00: 2020 2020 2020 2020 2020 2020 7465 6e73              tens
-00019f10: 6f72 6469 6374 0d0a 2020 2020 2020 2020  ordict..        
-00019f20: 2020 2020 6b65 7973 2028 6974 6572 6162      keys (iterab
-00019f30: 6c65 206f 6620 7374 722c 206f 7074 696f  le of str, optio
-00019f40: 6e61 6c29 3a20 6b65 7973 2074 6861 740d  nal): keys that.
-00019f50: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00019f60: 2068 6176 6520 746f 2062 6520 6e6f 726d   have to be norm
-00019f70: 616c 697a 6564 2e20 4465 6661 756c 7420  alized. Default 
-00019f80: 6973 2060 5b22 6e65 7874 222c 2022 7265  is `["next", "re
-00019f90: 7761 7264 225d 600d 0a20 2020 2020 2020  ward"]`..       
-00019fa0: 2020 2020 206d 656d 6d61 7020 2862 6f6f       memmap (boo
-00019fb0: 6c29 3a20 6966 2054 7275 652c 2074 6865  l): if True, the
-00019fc0: 2072 6573 756c 7469 6e67 2074 656e 736f   resulting tenso
-00019fd0: 7264 6963 7420 7769 6c6c 2062 6520 6361  rdict will be ca
-00019fe0: 7374 2069 6e74 6f0d 0a20 2020 2020 2020  st into..       
-00019ff0: 2020 2020 2020 2020 206d 656d 6d6f 7279           memmory
-0001a000: 206d 6170 2028 7573 696e 6720 606d 656d   map (using `mem
-0001a010: 6d61 705f 2829 6029 2e20 4f74 6865 7277  map_()`). Otherw
-0001a020: 6973 652c 2074 6865 2074 656e 736f 7264  ise, the tensord
-0001a030: 6963 740d 0a20 2020 2020 2020 2020 2020  ict..           
-0001a040: 2020 2020 2077 696c 6c20 6265 2070 6c61       will be pla
-0001a050: 6365 6420 696e 2073 6861 7265 6420 6d65  ced in shared me
-0001a060: 6d6f 7279 2e0d 0a0d 0a20 2020 2020 2020  mory.....       
-0001a070: 2052 6574 7572 6e73 3a0d 0a20 2020 2020   Returns:..     
-0001a080: 2020 2020 2020 2041 206d 656d 6f72 7920         A memory 
-0001a090: 696e 2073 6861 7265 6420 6d65 6d6f 7279  in shared memory
-0001a0a0: 2074 6f20 6265 2073 656e 7420 746f 2065   to be sent to e
-0001a0b0: 6163 6820 7072 6f63 6573 732e 0d0a 0d0a  ach process.....
-0001a0c0: 2020 2020 2020 2020 4578 616d 706c 6573          Examples
-0001a0d0: 3a0d 0a20 2020 2020 2020 2020 2020 203e  :..            >
-0001a0e0: 3e3e 2066 726f 6d20 746f 7263 6820 696d  >> from torch im
-0001a0f0: 706f 7274 206d 756c 7469 7072 6f63 6573  port multiproces
-0001a100: 7369 6e67 2061 7320 6d70 0d0a 2020 2020  sing as mp..    
-0001a110: 2020 2020 2020 2020 3e3e 3e20 7175 6575          >>> queu
-0001a120: 6520 3d20 6d70 2e51 7565 7565 2829 0d0a  e = mp.Queue()..
-0001a130: 2020 2020 2020 2020 2020 2020 3e3e 3e20              >>> 
-0001a140: 656e 7620 3d20 6d61 6b65 5f65 6e76 2829  env = make_env()
-0001a150: 0d0a 2020 2020 2020 2020 2020 2020 3e3e  ..            >>
-0001a160: 3e20 7464 5f73 6861 7265 6420 3d20 5665  > td_shared = Ve
-0001a170: 634e 6f72 6d2e 6275 696c 645f 7464 5f66  cNorm.build_td_f
-0001a180: 6f72 5f73 6861 7265 645f 7665 636e 6f72  or_shared_vecnor
-0001a190: 6d28 656e 762c 0d0a 2020 2020 2020 2020  m(env,..        
-0001a1a0: 2020 2020 2e2e 2e20 2020 2020 5b22 6e65      ...     ["ne
-0001a1b0: 7874 222c 2022 7265 7761 7264 225d 290d  xt", "reward"]).
-0001a1c0: 0a20 2020 2020 2020 2020 2020 203e 3e3e  .            >>>
-0001a1d0: 2061 7373 6572 7420 7464 5f73 6861 7265   assert td_share
-0001a1e0: 642e 6973 5f73 6861 7265 6428 290d 0a20  d.is_shared().. 
-0001a1f0: 2020 2020 2020 2020 2020 203e 3e3e 2071             >>> q
-0001a200: 7565 7565 2e70 7574 2874 645f 7368 6172  ueue.put(td_shar
-0001a210: 6564 290d 0a20 2020 2020 2020 2020 2020  ed)..           
-0001a220: 203e 3e3e 2023 206f 6e20 776f 726b 6572   >>> # on worker
-0001a230: 730d 0a20 2020 2020 2020 2020 2020 203e  s..            >
-0001a240: 3e3e 2076 203d 2056 6563 4e6f 726d 2873  >> v = VecNorm(s
-0001a250: 6861 7265 645f 7464 3d71 7565 7565 2e67  hared_td=queue.g
-0001a260: 6574 2829 290d 0a20 2020 2020 2020 2020  et())..         
-0001a270: 2020 203e 3e3e 2065 6e76 203d 2054 7261     >>> env = Tra
-0001a280: 6e73 666f 726d 6564 456e 7628 6d61 6b65  nsformedEnv(make
-0001a290: 5f65 6e76 2829 2c20 7629 0d0a 0d0a 2020  _env(), v)....  
-0001a2a0: 2020 2020 2020 2222 220d 0a20 2020 2020        """..     
-0001a2b0: 2020 2072 6169 7365 204e 6f74 496d 706c     raise NotImpl
-0001a2c0: 656d 656e 7465 6445 7272 6f72 2822 7468  ementedError("th
-0001a2d0: 6973 2066 6561 7475 7265 2069 7320 6375  is feature is cu
-0001a2e0: 7272 656e 746c 7920 7075 7420 6f6e 2068  rrently put on h
-0001a2f0: 6f6c 642e 2229 0d0a 2020 2020 2020 2020  old.")..        
-0001a300: 7365 7020 3d20 222e 2d7c 2d2e 220d 0a20  sep = ".-|-.".. 
-0001a310: 2020 2020 2020 2069 6620 6b65 7973 2069         if keys i
-0001a320: 7320 4e6f 6e65 3a0d 0a20 2020 2020 2020  s None:..       
-0001a330: 2020 2020 206b 6579 7320 3d20 5b22 6e65       keys = ["ne
-0001a340: 7874 222c 2022 7265 7761 7264 225d 0d0a  xt", "reward"]..
-0001a350: 2020 2020 2020 2020 7464 203d 206d 616b          td = mak
-0001a360: 655f 7465 6e73 6f72 6469 6374 2865 6e76  e_tensordict(env
-0001a370: 290d 0a20 2020 2020 2020 206b 6579 7320  )..        keys 
-0001a380: 3d20 7b6b 6579 2066 6f72 206b 6579 2069  = {key for key i
-0001a390: 6e20 7464 2e6b 6579 7328 2920 6966 206b  n td.keys() if k
-0001a3a0: 6579 2069 6e20 6b65 7973 7d0d 0a20 2020  ey in keys}..   
-0001a3b0: 2020 2020 2074 645f 7365 6c65 6374 203d       td_select =
-0001a3c0: 2074 642e 7365 6c65 6374 282a 6b65 7973   td.select(*keys
-0001a3d0: 290d 0a20 2020 2020 2020 2074 645f 7365  )..        td_se
-0001a3e0: 6c65 6374 203d 2074 645f 7365 6c65 6374  lect = td_select
-0001a3f0: 2e66 6c61 7474 656e 5f6b 6579 7328 7365  .flatten_keys(se
-0001a400: 7029 0d0a 2020 2020 2020 2020 6966 2074  p)..        if t
-0001a410: 642e 6261 7463 685f 6469 6d73 3a0d 0a20  d.batch_dims:.. 
-0001a420: 2020 2020 2020 2020 2020 2072 6169 7365             raise
-0001a430: 2052 756e 7469 6d65 4572 726f 7228 0d0a   RuntimeError(..
-0001a440: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a450: 6622 5665 634e 6f72 6d20 7368 6f75 6c64  f"VecNorm should
-0001a460: 2062 6520 7573 6564 2077 6974 6820 6e6f   be used with no
-0001a470: 6e2d 6261 7463 6865 6420 656e 7669 726f  n-batched enviro
-0001a480: 6e6d 656e 7473 2e20 220d 0a20 2020 2020  nments. "..     
-0001a490: 2020 2020 2020 2020 2020 2066 2247 6f74             f"Got
-0001a4a0: 2062 6174 6368 5f73 697a 653d 7b74 642e   batch_size={td.
-0001a4b0: 6261 7463 685f 7369 7a65 7d22 0d0a 2020  batch_size}"..  
-0001a4c0: 2020 2020 2020 2020 2020 290d 0a20 2020            )..   
-0001a4d0: 2020 2020 206b 6579 7320 3d20 6c69 7374       keys = list
-0001a4e0: 2874 645f 7365 6c65 6374 2e6b 6579 7328  (td_select.keys(
-0001a4f0: 2929 0d0a 2020 2020 2020 2020 666f 7220  ))..        for 
-0001a500: 6b65 7920 696e 206b 6579 733a 0d0a 2020  key in keys:..  
-0001a510: 2020 2020 2020 2020 2020 7464 5f73 656c            td_sel
-0001a520: 6563 742e 7365 7428 6b65 7920 2b20 225f  ect.set(key + "_
-0001a530: 7373 7122 2c20 7464 5f73 656c 6563 742e  ssq", td_select.
-0001a540: 6765 7428 6b65 7929 2e63 6c6f 6e65 2829  get(key).clone()
-0001a550: 290d 0a20 2020 2020 2020 2020 2020 2074  )..            t
-0001a560: 645f 7365 6c65 6374 2e73 6574 280d 0a20  d_select.set(.. 
-0001a570: 2020 2020 2020 2020 2020 2020 2020 206b                 k
-0001a580: 6579 202b 2022 5f63 6f75 6e74 222c 0d0a  ey + "_count",..
-0001a590: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a5a0: 746f 7263 682e 7a65 726f 7328 0d0a 2020  torch.zeros(..  
-0001a5b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001a5c0: 2020 2a74 642e 6261 7463 685f 7369 7a65    *td.batch_size
-0001a5d0: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
-0001a5e0: 2020 2020 2020 2031 2c0d 0a20 2020 2020         1,..     
-0001a5f0: 2020 2020 2020 2020 2020 2020 2020 2064                 d
-0001a600: 6576 6963 653d 7464 5f73 656c 6563 742e  evice=td_select.
-0001a610: 6465 7669 6365 2c0d 0a20 2020 2020 2020  device,..       
-0001a620: 2020 2020 2020 2020 2020 2020 2064 7479               dty
-0001a630: 7065 3d74 6f72 6368 2e66 6c6f 6174 2c0d  pe=torch.float,.
-0001a640: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001a650: 2029 2c0d 0a20 2020 2020 2020 2020 2020   ),..           
-0001a660: 2029 0d0a 2020 2020 2020 2020 2020 2020   )..            
-0001a670: 7464 5f73 656c 6563 742e 7265 6e61 6d65  td_select.rename
-0001a680: 5f6b 6579 5f28 6b65 792c 206b 6579 202b  _key_(key, key +
-0001a690: 2022 5f73 756d 2229 0d0a 2020 2020 2020   "_sum")..      
-0001a6a0: 2020 7464 5f73 656c 6563 742e 6578 636c    td_select.excl
-0001a6b0: 7564 6528 2a6b 6579 7329 2e7a 6572 6f5f  ude(*keys).zero_
-0001a6c0: 2829 0d0a 2020 2020 2020 2020 7464 5f73  ()..        td_s
-0001a6d0: 656c 6563 7420 3d20 7464 5f73 656c 6563  elect = td_selec
-0001a6e0: 742e 756e 666c 6174 7465 6e5f 6b65 7973  t.unflatten_keys
-0001a6f0: 2873 6570 290d 0a20 2020 2020 2020 2069  (sep)..        i
-0001a700: 6620 6d65 6d6d 6170 3a0d 0a20 2020 2020  f memmap:..     
-0001a710: 2020 2020 2020 2072 6574 7572 6e20 7464         return td
-0001a720: 5f73 656c 6563 742e 6d65 6d6d 6170 5f28  _select.memmap_(
-0001a730: 290d 0a20 2020 2020 2020 2072 6574 7572  )..        retur
-0001a740: 6e20 7464 5f73 656c 6563 742e 7368 6172  n td_select.shar
-0001a750: 655f 6d65 6d6f 7279 5f28 290d 0a0d 0a20  e_memory_().... 
-0001a760: 2020 2064 6566 2067 6574 5f65 7874 7261     def get_extra
-0001a770: 5f73 7461 7465 2873 656c 6629 202d 3e20  _state(self) -> 
-0001a780: 4f72 6465 7265 6444 6963 743a 0d0a 2020  OrderedDict:..  
-0001a790: 2020 2020 2020 7265 7475 726e 2063 6f6c        return col
-0001a7a0: 6c65 6374 696f 6e73 2e4f 7264 6572 6564  lections.Ordered
-0001a7b0: 4469 6374 287b 226c 6f63 6b22 3a20 7365  Dict({"lock": se
-0001a7c0: 6c66 2e6c 6f63 6b2c 2022 7464 223a 2073  lf.lock, "td": s
-0001a7d0: 656c 662e 5f74 647d 290d 0a0d 0a20 2020  elf._td})....   
-0001a7e0: 2064 6566 2073 6574 5f65 7874 7261 5f73   def set_extra_s
-0001a7f0: 7461 7465 2873 656c 662c 2073 7461 7465  tate(self, state
-0001a800: 3a20 4f72 6465 7265 6444 6963 7429 202d  : OrderedDict) -
-0001a810: 3e20 4e6f 6e65 3a0d 0a20 2020 2020 2020  > None:..       
-0001a820: 206c 6f63 6b20 3d20 7374 6174 655b 226c   lock = state["l
-0001a830: 6f63 6b22 5d0d 0a20 2020 2020 2020 2069  ock"]..        i
-0001a840: 6620 6c6f 636b 2069 7320 6e6f 7420 4e6f  f lock is not No
-0001a850: 6e65 3a0d 0a20 2020 2020 2020 2020 2020  ne:..           
-0001a860: 2022 2222 0d0a 2020 2020 2020 2020 2020   """..          
-0001a870: 2020 7369 6e63 6520 6c6f 636b 7320 6361    since locks ca
-0001a880: 6e27 7420 6265 2073 6572 6961 6c69 7a65  n't be serialize
-0001a890: 642c 2077 6520 6861 7665 2075 7365 2063  d, we have use c
-0001a8a0: 6173 6573 2066 6f72 2073 7472 6970 7069  ases for strippi
-0001a8b0: 6e67 2074 6865 6d0d 0a20 2020 2020 2020  ng them..       
-0001a8c0: 2020 2020 2066 6f72 2065 7861 6d70 6c65       for example
-0001a8d0: 2069 6e20 5061 7261 6c6c 656c 456e 762c   in ParallelEnv,
-0001a8e0: 2069 6e20 7768 6963 6820 6361 7365 206b   in which case k
-0001a8f0: 6565 7020 7468 6520 6c6f 636b 2077 6520  eep the lock we 
-0001a900: 616c 7265 6164 7920 6861 7665 0d0a 2020  already have..  
-0001a910: 2020 2020 2020 2020 2020 746f 2061 766f            to avo
-0001a920: 6964 2061 6e20 7570 6461 7465 6420 7465  id an updated te
-0001a930: 6e73 6f72 2064 6963 7420 6265 696e 6720  nsor dict being 
-0001a940: 7365 6e74 2062 6574 7765 656e 2070 726f  sent between pro
-0001a950: 6365 7373 6573 2074 6f20 6572 6173 6520  cesses to erase 
-0001a960: 6c6f 636b 730d 0a20 2020 2020 2020 2020  locks..         
-0001a970: 2020 2022 2222 0d0a 2020 2020 2020 2020     """..        
-0001a980: 2020 2020 7365 6c66 2e6c 6f63 6b20 3d20      self.lock = 
-0001a990: 6c6f 636b 0d0a 2020 2020 2020 2020 7464  lock..        td
-0001a9a0: 203d 2073 7461 7465 5b22 7464 225d 0d0a   = state["td"]..
-0001a9b0: 2020 2020 2020 2020 6966 2074 6420 6973          if td is
-0001a9c0: 206e 6f74 204e 6f6e 6520 616e 6420 6e6f   not None and no
-0001a9d0: 7420 7464 2e69 735f 7368 6172 6564 2829  t td.is_shared()
-0001a9e0: 3a0d 0a20 2020 2020 2020 2020 2020 2072  :..            r
-0001a9f0: 6169 7365 2052 756e 7469 6d65 4572 726f  aise RuntimeErro
-0001aa00: 7228 0d0a 2020 2020 2020 2020 2020 2020  r(..            
-0001aa10: 2020 2020 224f 6e6c 7920 7368 6172 6564      "Only shared
-0001aa20: 2074 656e 736f 7264 6963 7473 2063 616e   tensordicts can
-0001aa30: 2062 6520 7365 7420 696e 2056 6563 4e6f   be set in VecNo
-0001aa40: 726d 2074 7261 6e73 666f 726d 7322 0d0a  rm transforms"..
-0001aa50: 2020 2020 2020 2020 2020 2020 290d 0a20              ).. 
-0001aa60: 2020 2020 2020 2073 656c 662e 5f74 6420         self._td 
-0001aa70: 3d20 7464 0d0a 0d0a 2020 2020 6465 6620  = td....    def 
-0001aa80: 5f5f 7265 7072 5f5f 2873 656c 6629 202d  __repr__(self) -
-0001aa90: 3e20 7374 723a 0d0a 2020 2020 2020 2020  > str:..        
-0001aaa0: 7265 7475 726e 2028 0d0a 2020 2020 2020  return (..      
-0001aab0: 2020 2020 2020 6622 7b73 656c 662e 5f5f        f"{self.__
-0001aac0: 636c 6173 735f 5f2e 5f5f 6e61 6d65 5f5f  class__.__name__
-0001aad0: 7d28 6465 6361 793d 7b73 656c 662e 6465  }(decay={self.de
-0001aae0: 6361 793a 342e 3466 7d2c 220d 0a20 2020  cay:4.4f},"..   
-0001aaf0: 2020 2020 2020 2020 2066 2265 7073 3d7b           f"eps={
-0001ab00: 7365 6c66 2e65 7073 3a34 2e34 667d 2c20  self.eps:4.4f}, 
-0001ab10: 6b65 7973 3d7b 7365 6c66 2e69 6e5f 6b65  keys={self.in_ke
-0001ab20: 7973 7d29 220d 0a20 2020 2020 2020 2029  ys})"..        )
-0001ab30: 0d0a 0d0a 0d0a 636c 6173 7320 5265 7761  ......class Rewa
-0001ab40: 7264 5375 6d28 5472 616e 7366 6f72 6d29  rdSum(Transform)
-0001ab50: 3a0d 0a20 2020 2022 2222 5472 6163 6b73  :..    """Tracks
-0001ab60: 2065 7069 736f 6465 2063 756d 756c 6174   episode cumulat
-0001ab70: 6976 6520 7265 7761 7264 732e 0d0a 0d0a  ive rewards.....
-0001ab80: 2020 2020 5468 6973 2074 7261 6e73 666f      This transfo
-0001ab90: 726d 2061 6363 6570 7473 2061 206c 6973  rm accepts a lis
-0001aba0: 7420 6f66 2074 656e 736f 7264 6963 7420  t of tensordict 
-0001abb0: 7265 7761 7264 206b 6579 7320 2869 2e65  reward keys (i.e
-0001abc0: 2e20 c2b4 696e 5f6b 6579 73c2 b429 2061  . ..in_keys..) a
-0001abd0: 6e64 2074 7261 636b 7320 7468 6569 7220  nd tracks their 
-0001abe0: 6375 6d75 6c61 7469 7665 0d0a 2020 2020  cumulative..    
-0001abf0: 7661 6c75 6520 616c 6f6e 6720 6561 6368  value along each
-0001ac00: 2065 7069 736f 6465 2e20 5768 656e 2063   episode. When c
-0001ac10: 616c 6c65 642c 2074 6865 2074 7261 6e73  alled, the trans
-0001ac20: 666f 726d 2063 7265 6174 6573 2061 206e  form creates a n
-0001ac30: 6577 2074 656e 736f 7264 6963 7420 6b65  ew tensordict ke
-0001ac40: 7920 666f 7220 6561 6368 2069 6e5f 6b65  y for each in_ke
-0001ac50: 7920 6e61 6d65 640d 0a20 2020 20c2 b465  y named..    ..e
-0001ac60: 7069 736f 6465 5f7b 696e 5f6b 6579 7dc2  pisode_{in_key}.
-0001ac70: b420 7768 6572 6520 2074 6865 2063 756d  . where  the cum
-0001ac80: 756c 6174 6976 6520 7661 6c75 6573 2061  ulative values a
-0001ac90: 7265 2077 7269 7474 656e 2e20 416c 6c20  re written. All 
-0001aca0: c2b4 696e 5f6b 6579 73c2 b420 7368 6f75  ..in_keys.. shou
-0001acb0: 6c64 2062 6520 7061 7274 206f 6620 7468  ld be part of th
-0001acc0: 6520 656e 760d 0a20 2020 2072 6577 6172  e env..    rewar
-0001acd0: 6420 616e 6420 6265 2070 7265 7365 6e74  d and be present
-0001ace0: 2069 6e20 7468 6520 656e 7620 7265 7761   in the env rewa
-0001acf0: 7264 5f73 7065 632e 0d0a 0d0a 2020 2020  rd_spec.....    
-0001ad00: 4966 206e 6f20 696e 5f6b 6579 7320 6172  If no in_keys ar
-0001ad10: 6520 7370 6563 6966 6965 642c 2074 6869  e specified, thi
-0001ad20: 7320 7472 616e 7366 6f72 6d20 6173 7375  s transform assu
-0001ad30: 6d65 7320 c2b4 7265 7761 7264 c2b4 2074  mes ..reward.. t
-0001ad40: 6f20 6265 2074 6865 2069 6e70 7574 206b  o be the input k
-0001ad50: 6579 2e20 486f 7765 7665 722c 206d 756c  ey. However, mul
-0001ad60: 7469 706c 6520 7265 7761 7264 730d 0a20  tiple rewards.. 
-0001ad70: 2020 2028 652e 672e 2072 6577 6172 6431     (e.g. reward1
-0001ad80: 2061 6e64 2072 6577 6172 6432 2920 6361   and reward2) ca
-0001ad90: 6e20 616c 736f 2062 6520 7370 6563 6966  n also be specif
-0001ada0: 6965 642e 2049 6620 c2b4 696e 5f6b 6579  ied. If ..in_key
-0001adb0: 73c2 b420 6172 6520 6e6f 7420 7072 6573  s.. are not pres
-0001adc0: 656e 7420 696e 2074 6865 2070 726f 7669  ent in the provi
-0001add0: 6465 6420 7465 6e73 6f72 6469 6374 2c0d  ded tensordict,.
-0001ade0: 0a20 2020 2074 6869 7320 7472 616e 7366  .    this transf
-0001adf0: 6f72 6d20 686f 7320 6e6f 2065 6666 6563  orm hos no effec
-0001ae00: 742e 0d0a 2020 2020 2222 220d 0a0d 0a20  t...    """.... 
-0001ae10: 2020 2064 6566 205f 5f69 6e69 745f 5f28     def __init__(
-0001ae20: 0d0a 2020 2020 2020 2020 7365 6c66 2c0d  ..        self,.
-0001ae30: 0a20 2020 2020 2020 2069 6e5f 6b65 7973  .        in_keys
-0001ae40: 3a20 4f70 7469 6f6e 616c 5b53 6571 7565  : Optional[Seque
-0001ae50: 6e63 655b 7374 725d 5d20 3d20 4e6f 6e65  nce[str]] = None
-0001ae60: 2c0d 0a20 2020 2020 2020 206f 7574 5f6b  ,..        out_k
-0001ae70: 6579 733a 204f 7074 696f 6e61 6c5b 5365  eys: Optional[Se
-0001ae80: 7175 656e 6365 5b73 7472 5d5d 203d 204e  quence[str]] = N
-0001ae90: 6f6e 652c 0d0a 2020 2020 293a 0d0a 2020  one,..    ):..  
-0001aea0: 2020 2020 2020 2222 2249 6e69 7469 616c        """Initial
-0001aeb0: 6973 6573 2074 6865 2074 7261 6e73 666f  ises the transfo
-0001aec0: 726d 2e20 4669 6c74 6572 7320 6f75 7420  rm. Filters out 
-0001aed0: 6e6f 6e2d 7265 7761 7264 2069 6e70 7574  non-reward input
-0001aee0: 206b 6579 7320 616e 6420 6465 6669 6e65   keys and define
-0001aef0: 7320 6f75 7470 7574 206b 6579 732e 2222  s output keys.""
-0001af00: 220d 0a20 2020 2020 2020 2069 6620 696e  "..        if in
-0001af10: 5f6b 6579 7320 6973 204e 6f6e 653a 0d0a  _keys is None:..
-0001af20: 2020 2020 2020 2020 2020 2020 696e 5f6b              in_k
-0001af30: 6579 7320 3d20 5b28 226e 6578 7422 2c20  eys = [("next", 
-0001af40: 2272 6577 6172 6422 295d 0d0a 2020 2020  "reward")]..    
-0001af50: 2020 2020 6966 206f 7574 5f6b 6579 7320      if out_keys 
-0001af60: 6973 204e 6f6e 6520 616e 6420 696e 5f6b  is None and in_k
-0001af70: 6579 7320 3d3d 205b 2822 6e65 7874 222c  eys == [("next",
-0001af80: 2022 7265 7761 7264 2229 5d3a 0d0a 2020   "reward")]:..  
-0001af90: 2020 2020 2020 2020 2020 6f75 745f 6b65            out_ke
-0001afa0: 7973 203d 205b 2265 7069 736f 6465 5f72  ys = ["episode_r
-0001afb0: 6577 6172 6422 5d0d 0a20 2020 2020 2020  eward"]..       
-0001afc0: 2065 6c69 6620 6f75 745f 6b65 7973 2069   elif out_keys i
-0001afd0: 7320 4e6f 6e65 3a0d 0a20 2020 2020 2020  s None:..       
-0001afe0: 2020 2020 2072 6169 7365 2052 756e 7469       raise Runti
-0001aff0: 6d65 4572 726f 7228 0d0a 2020 2020 2020  meError(..      
-0001b000: 2020 2020 2020 2020 2020 2274 6865 206f            "the o
-0001b010: 7574 5f6b 6579 7320 6d75 7374 2062 6520  ut_keys must be 
-0001b020: 7370 6563 6966 6965 6420 666f 7220 6e6f  specified for no
-0001b030: 6e2d 636f 6e76 656e 7469 6f6e 616c 2069  n-conventional i
-0001b040: 6e2d 6b65 7973 2069 6e20 5265 7761 7264  n-keys in Reward
-0001b050: 5375 6d2e 220d 0a20 2020 2020 2020 2020  Sum."..         
-0001b060: 2020 2029 0d0a 0d0a 2020 2020 2020 2020     )....        
-0001b070: 7375 7065 7228 292e 5f5f 696e 6974 5f5f  super().__init__
-0001b080: 2869 6e5f 6b65 7973 3d69 6e5f 6b65 7973  (in_keys=in_keys
-0001b090: 2c20 6f75 745f 6b65 7973 3d6f 7574 5f6b  , out_keys=out_k
-0001b0a0: 6579 7329 0d0a 0d0a 2020 2020 6465 6620  eys)....    def 
-0001b0b0: 7265 7365 7428 7365 6c66 2c20 7465 6e73  reset(self, tens
-0001b0c0: 6f72 6469 6374 3a20 5465 6e73 6f72 4469  ordict: TensorDi
-0001b0d0: 6374 4261 7365 2920 2d3e 2054 656e 736f  ctBase) -> Tenso
-0001b0e0: 7244 6963 7442 6173 653a 0d0a 2020 2020  rDictBase:..    
-0001b0f0: 2020 2020 2222 2252 6573 6574 7320 6570      """Resets ep
-0001b100: 6973 6f64 6520 7265 7761 7264 732e 2222  isode rewards.""
-0001b110: 220d 0a20 2020 2020 2020 2023 204e 6f6e  "..        # Non
-0001b120: 2d62 6174 6368 6564 2065 6e76 6972 6f6e  -batched environ
-0001b130: 6d65 6e74 730d 0a20 2020 2020 2020 205f  ments..        _
-0001b140: 7265 7365 7420 3d20 7465 6e73 6f72 6469  reset = tensordi
-0001b150: 6374 2e67 6574 280d 0a20 2020 2020 2020  ct.get(..       
-0001b160: 2020 2020 2022 5f72 6573 6574 222c 0d0a       "_reset",..
-0001b170: 2020 2020 2020 2020 2020 2020 746f 7263              torc
-0001b180: 682e 6f6e 6573 280d 0a20 2020 2020 2020  h.ones(..       
-0001b190: 2020 2020 2020 2020 2074 656e 736f 7264           tensord
-0001b1a0: 6963 742e 6261 7463 685f 7369 7a65 2c0d  ict.batch_size,.
-0001b1b0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001b1c0: 2064 7479 7065 3d74 6f72 6368 2e62 6f6f   dtype=torch.boo
-0001b1d0: 6c2c 0d0a 2020 2020 2020 2020 2020 2020  l,..            
-0001b1e0: 2020 2020 6465 7669 6365 3d74 656e 736f      device=tenso
-0001b1f0: 7264 6963 742e 6465 7669 6365 2c0d 0a20  rdict.device,.. 
-0001b200: 2020 2020 2020 2020 2020 2029 2c0d 0a20             ),.. 
-0001b210: 2020 2020 2020 2029 0d0a 2020 2020 2020         )..      
-0001b220: 2020 6966 205f 7265 7365 742e 616e 7928    if _reset.any(
-0001b230: 293a 0d0a 2020 2020 2020 2020 2020 2020  ):..            
-0001b240: 666f 7220 696e 5f6b 6579 2c20 6f75 745f  for in_key, out_
-0001b250: 6b65 7920 696e 207a 6970 2873 656c 662e  key in zip(self.
-0001b260: 696e 5f6b 6579 732c 2073 656c 662e 6f75  in_keys, self.ou
-0001b270: 745f 6b65 7973 293a 0d0a 2020 2020 2020  t_keys):..      
-0001b280: 2020 2020 2020 2020 2020 6966 206f 7574            if out
-0001b290: 5f6b 6579 2069 6e20 7465 6e73 6f72 6469  _key in tensordi
-0001b2a0: 6374 2e6b 6579 7328 293a 0d0a 2020 2020  ct.keys():..    
-0001b2b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b2c0: 7661 6c75 6520 3d20 7465 6e73 6f72 6469  value = tensordi
-0001b2d0: 6374 5b6f 7574 5f6b 6579 5d0d 0a20 2020  ct[out_key]..   
-0001b2e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b2f0: 2074 656e 736f 7264 6963 745b 6f75 745f   tensordict[out_
-0001b300: 6b65 795d 203d 2076 616c 7565 2e6d 6173  key] = value.mas
-0001b310: 6b65 645f 6669 6c6c 280d 0a20 2020 2020  ked_fill(..     
-0001b320: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b330: 2020 2065 7870 616e 645f 6173 5f72 6967     expand_as_rig
-0001b340: 6874 285f 7265 7365 742c 2076 616c 7565  ht(_reset, value
-0001b350: 292c 2030 2e30 0d0a 2020 2020 2020 2020  ), 0.0..        
-0001b360: 2020 2020 2020 2020 2020 2020 290d 0a20              ).. 
-0001b370: 2020 2020 2020 2020 2020 2020 2020 2065                 e
-0001b380: 6c69 6620 696e 5f6b 6579 203d 3d20 2822  lif in_key == ("
-0001b390: 6e65 7874 222c 2022 7265 7761 7264 2229  next", "reward")
-0001b3a0: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
-0001b3b0: 2020 2020 2020 2023 2053 696e 6365 2074         # Since t
-0001b3c0: 6865 2065 7069 736f 6465 2072 6577 6172  he episode rewar
-0001b3d0: 6420 6973 206e 6f74 2069 6e20 7468 6520  d is not in the 
-0001b3e0: 7465 6e73 6f72 6469 6374 2c20 7765 206e  tensordict, we n
-0001b3f0: 6565 6420 746f 2061 6c6c 6f63 6174 6520  eed to allocate 
-0001b400: 6974 0d0a 2020 2020 2020 2020 2020 2020  it..            
-0001b410: 2020 2020 2020 2020 2320 7769 7468 207a          # with z
-0001b420: 6572 6f73 2065 6e74 6972 656c 7920 2872  eros entirely (r
-0001b430: 6567 6172 646c 6573 7320 6f66 2074 6865  egardless of the
-0001b440: 205f 7265 7365 7420 6d61 736b 290d 0a20   _reset mask).. 
-0001b450: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b460: 2020 2074 656e 736f 7264 6963 745b 6f75     tensordict[ou
-0001b470: 745f 6b65 795d 203d 2073 656c 662e 7061  t_key] = self.pa
-0001b480: 7265 6e74 2e72 6577 6172 645f 7370 6563  rent.reward_spec
-0001b490: 2e7a 6572 6f28 290d 0a20 2020 2020 2020  .zero()..       
-0001b4a0: 2020 2020 2020 2020 2065 6c73 653a 0d0a           else:..
+00004cd0: 2e64 6576 6963 650d 0a0d 0a20 2020 2040  .device....    @
+00004ce0: 6465 7669 6365 2e73 6574 7465 720d 0a20  device.setter.. 
+00004cf0: 2020 2064 6566 2064 6576 6963 6528 7365     def device(se
+00004d00: 6c66 2c20 7661 6c75 6529 3a0d 0a20 2020  lf, value):..   
+00004d10: 2020 2020 2072 6169 7365 2052 756e 7469       raise Runti
+00004d20: 6d65 4572 726f 7228 2264 6576 6963 6520  meError("device 
+00004d30: 6973 2061 2072 6561 642d 6f6e 6c79 2070  is a read-only p
+00004d40: 726f 7065 7274 7922 290d 0a0d 0a20 2020  roperty")....   
+00004d50: 2040 7072 6f70 6572 7479 0d0a 2020 2020   @property..    
+00004d60: 6465 6620 6261 7463 685f 6c6f 636b 6564  def batch_locked
+00004d70: 2873 656c 6629 202d 3e20 626f 6f6c 3a0d  (self) -> bool:.
+00004d80: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00004d90: 7365 6c66 2e62 6173 655f 656e 762e 6261  self.base_env.ba
+00004da0: 7463 685f 6c6f 636b 6564 0d0a 0d0a 2020  tch_locked....  
+00004db0: 2020 4062 6174 6368 5f6c 6f63 6b65 642e    @batch_locked.
+00004dc0: 7365 7474 6572 0d0a 2020 2020 6465 6620  setter..    def 
+00004dd0: 6261 7463 685f 6c6f 636b 6564 2873 656c  batch_locked(sel
+00004de0: 662c 2076 616c 7565 293a 0d0a 2020 2020  f, value):..    
+00004df0: 2020 2020 7261 6973 6520 5275 6e74 696d      raise Runtim
+00004e00: 6545 7272 6f72 2822 6261 7463 685f 6c6f  eError("batch_lo
+00004e10: 636b 6564 2069 7320 6120 7265 6164 2d6f  cked is a read-o
+00004e20: 6e6c 7920 7072 6f70 6572 7479 2229 0d0a  nly property")..
+00004e30: 0d0a 2020 2020 4070 726f 7065 7274 790d  ..    @property.
+00004e40: 0a20 2020 2064 6566 2072 756e 5f74 7970  .    def run_typ
+00004e50: 655f 6368 6563 6b73 2873 656c 6629 202d  e_checks(self) -
+00004e60: 3e20 626f 6f6c 3a0d 0a20 2020 2020 2020  > bool:..       
+00004e70: 2072 6574 7572 6e20 7365 6c66 2e62 6173   return self.bas
+00004e80: 655f 656e 762e 7275 6e5f 7479 7065 5f63  e_env.run_type_c
+00004e90: 6865 636b 730d 0a0d 0a20 2020 2040 7275  hecks....    @ru
+00004ea0: 6e5f 7479 7065 5f63 6865 636b 732e 7365  n_type_checks.se
+00004eb0: 7474 6572 0d0a 2020 2020 6465 6620 7275  tter..    def ru
+00004ec0: 6e5f 7479 7065 5f63 6865 636b 7328 7365  n_type_checks(se
+00004ed0: 6c66 2c20 7661 6c75 6529 3a0d 0a20 2020  lf, value):..   
+00004ee0: 2020 2020 2072 6169 7365 2052 756e 7469       raise Runti
+00004ef0: 6d65 4572 726f 7228 0d0a 2020 2020 2020  meError(..      
+00004f00: 2020 2020 2020 2272 756e 5f74 7970 655f        "run_type_
+00004f10: 6368 6563 6b73 2069 7320 6120 7265 6164  checks is a read
+00004f20: 2d6f 6e6c 7920 7072 6f70 6572 7479 2066  -only property f
+00004f30: 6f72 2054 7261 6e73 666f 726d 6564 456e  or TransformedEn
+00004f40: 7673 220d 0a20 2020 2020 2020 2029 0d0a  vs"..        )..
+00004f50: 0d0a 2020 2020 4070 726f 7065 7274 790d  ..    @property.
+00004f60: 0a20 2020 2064 6566 205f 696e 706c 6163  .    def _inplac
+00004f70: 655f 7570 6461 7465 2873 656c 6629 3a0d  e_update(self):.
+00004f80: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00004f90: 7365 6c66 2e62 6173 655f 656e 762e 5f69  self.base_env._i
+00004fa0: 6e70 6c61 6365 5f75 7064 6174 650d 0a0d  nplace_update...
+00004fb0: 0a20 2020 2040 7072 6f70 6572 7479 0d0a  .    @property..
+00004fc0: 2020 2020 6465 6620 6f75 7470 7574 5f73      def output_s
+00004fd0: 7065 6328 7365 6c66 2920 2d3e 2054 656e  pec(self) -> Ten
+00004fe0: 736f 7253 7065 633a 0d0a 2020 2020 2020  sorSpec:..      
+00004ff0: 2020 2222 224f 6273 6572 7661 7469 6f6e    """Observation
+00005000: 2073 7065 6320 6f66 2074 6865 2074 7261   spec of the tra
+00005010: 6e73 666f 726d 6564 2065 6e76 6972 6f6e  nsformed environ
+00005020: 6d65 6e74 2e22 2222 0d0a 2020 2020 2020  ment."""..      
+00005030: 2020 6966 2073 656c 662e 5f6f 7574 7075    if self._outpu
+00005040: 745f 7370 6563 2069 7320 4e6f 6e65 206f  t_spec is None o
+00005050: 7220 6e6f 7420 7365 6c66 2e63 6163 6865  r not self.cache
+00005060: 5f73 7065 6373 3a0d 0a20 2020 2020 2020  _specs:..       
+00005070: 2020 2020 206f 7574 7075 745f 7370 6563       output_spec
+00005080: 203d 2073 656c 662e 6261 7365 5f65 6e76   = self.base_env
+00005090: 2e6f 7574 7075 745f 7370 6563 2e63 6c6f  .output_spec.clo
+000050a0: 6e65 2829 0d0a 2020 2020 2020 2020 2020  ne()..          
+000050b0: 2020 6f75 7470 7574 5f73 7065 6320 3d20    output_spec = 
+000050c0: 7365 6c66 2e74 7261 6e73 666f 726d 2e74  self.transform.t
+000050d0: 7261 6e73 666f 726d 5f6f 7574 7075 745f  ransform_output_
+000050e0: 7370 6563 286f 7574 7075 745f 7370 6563  spec(output_spec
+000050f0: 290d 0a20 2020 2020 2020 2020 2020 2069  )..            i
+00005100: 6620 7365 6c66 2e63 6163 6865 5f73 7065  f self.cache_spe
+00005110: 6373 3a0d 0a20 2020 2020 2020 2020 2020  cs:..           
+00005120: 2020 2020 2073 656c 662e 5f5f 6469 6374       self.__dict
+00005130: 5f5f 5b22 5f6f 7574 7075 745f 7370 6563  __["_output_spec
+00005140: 225d 203d 206f 7574 7075 745f 7370 6563  "] = output_spec
+00005150: 0d0a 2020 2020 2020 2020 656c 7365 3a0d  ..        else:.
+00005160: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
+00005170: 7075 745f 7370 6563 203d 2073 656c 662e  put_spec = self.
+00005180: 5f6f 7574 7075 745f 7370 6563 0d0a 2020  _output_spec..  
+00005190: 2020 2020 2020 7265 7475 726e 206f 7574        return out
+000051a0: 7075 745f 7370 6563 0d0a 0d0a 2020 2020  put_spec....    
+000051b0: 4070 726f 7065 7274 790d 0a20 2020 2064  @property..    d
+000051c0: 6566 2061 6374 696f 6e5f 7370 6563 2873  ef action_spec(s
+000051d0: 656c 6629 202d 3e20 5465 6e73 6f72 5370  elf) -> TensorSp
+000051e0: 6563 3a0d 0a20 2020 2020 2020 2022 2222  ec:..        """
+000051f0: 4163 7469 6f6e 2073 7065 6320 6f66 2074  Action spec of t
+00005200: 6865 2074 7261 6e73 666f 726d 6564 2065  he transformed e
+00005210: 6e76 6972 6f6e 6d65 6e74 2e22 2222 0d0a  nvironment."""..
+00005220: 2020 2020 2020 2020 7265 7475 726e 2073          return s
+00005230: 656c 662e 696e 7075 745f 7370 6563 5b22  elf.input_spec["
+00005240: 6163 7469 6f6e 225d 0d0a 0d0a 2020 2020  action"]....    
+00005250: 4070 726f 7065 7274 790d 0a20 2020 2064  @property..    d
+00005260: 6566 2069 6e70 7574 5f73 7065 6328 7365  ef input_spec(se
+00005270: 6c66 2920 2d3e 2054 656e 736f 7253 7065  lf) -> TensorSpe
+00005280: 633a 0d0a 2020 2020 2020 2020 2222 2241  c:..        """A
+00005290: 6374 696f 6e20 7370 6563 206f 6620 7468  ction spec of th
+000052a0: 6520 7472 616e 7366 6f72 6d65 6420 656e  e transformed en
+000052b0: 7669 726f 6e6d 656e 742e 2222 220d 0a20  vironment.""".. 
+000052c0: 2020 2020 2020 2069 6620 7365 6c66 2e5f         if self._
+000052d0: 696e 7075 745f 7370 6563 2069 7320 4e6f  input_spec is No
+000052e0: 6e65 206f 7220 6e6f 7420 7365 6c66 2e63  ne or not self.c
+000052f0: 6163 6865 5f73 7065 6373 3a0d 0a20 2020  ache_specs:..   
+00005300: 2020 2020 2020 2020 2069 6e70 7574 5f73           input_s
+00005310: 7065 6320 3d20 7365 6c66 2e74 7261 6e73  pec = self.trans
+00005320: 666f 726d 2e74 7261 6e73 666f 726d 5f69  form.transform_i
+00005330: 6e70 7574 5f73 7065 6328 0d0a 2020 2020  nput_spec(..    
+00005340: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+00005350: 2e62 6173 655f 656e 762e 696e 7075 745f  .base_env.input_
+00005360: 7370 6563 2e63 6c6f 6e65 2829 0d0a 2020  spec.clone()..  
+00005370: 2020 2020 2020 2020 2020 290d 0a20 2020            )..   
+00005380: 2020 2020 2020 2020 2069 6620 7365 6c66           if self
+00005390: 2e63 6163 6865 5f73 7065 6373 3a0d 0a20  .cache_specs:.. 
+000053a0: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+000053b0: 656c 662e 5f5f 6469 6374 5f5f 5b22 5f69  elf.__dict__["_i
+000053c0: 6e70 7574 5f73 7065 6322 5d20 3d20 696e  nput_spec"] = in
+000053d0: 7075 745f 7370 6563 0d0a 2020 2020 2020  put_spec..      
+000053e0: 2020 656c 7365 3a0d 0a20 2020 2020 2020    else:..       
+000053f0: 2020 2020 2069 6e70 7574 5f73 7065 6320       input_spec 
+00005400: 3d20 7365 6c66 2e5f 696e 7075 745f 7370  = self._input_sp
+00005410: 6563 0d0a 2020 2020 2020 2020 7265 7475  ec..        retu
+00005420: 726e 2069 6e70 7574 5f73 7065 630d 0a0d  rn input_spec...
+00005430: 0a20 2020 2040 7072 6f70 6572 7479 0d0a  .    @property..
+00005440: 2020 2020 6465 6620 7265 7761 7264 5f73      def reward_s
+00005450: 7065 6328 7365 6c66 2920 2d3e 2054 656e  pec(self) -> Ten
+00005460: 736f 7253 7065 633a 0d0a 2020 2020 2020  sorSpec:..      
+00005470: 2020 2222 2252 6577 6172 6420 7370 6563    """Reward spec
+00005480: 206f 6620 7468 6520 7472 616e 7366 6f72   of the transfor
+00005490: 6d65 6420 656e 7669 726f 6e6d 656e 742e  med environment.
+000054a0: 2222 220d 0a20 2020 2020 2020 2072 6574  """..        ret
+000054b0: 7572 6e20 7365 6c66 2e6f 7574 7075 745f  urn self.output_
+000054c0: 7370 6563 5b22 7265 7761 7264 225d 0d0a  spec["reward"]..
+000054d0: 0d0a 2020 2020 4070 726f 7065 7274 790d  ..    @property.
+000054e0: 0a20 2020 2064 6566 206f 6273 6572 7661  .    def observa
+000054f0: 7469 6f6e 5f73 7065 6328 7365 6c66 2920  tion_spec(self) 
+00005500: 2d3e 2054 656e 736f 7253 7065 633a 0d0a  -> TensorSpec:..
+00005510: 2020 2020 2020 2020 2222 224f 6273 6572          """Obser
+00005520: 7661 7469 6f6e 2073 7065 6320 6f66 2074  vation spec of t
+00005530: 6865 2074 7261 6e73 666f 726d 6564 2065  he transformed e
+00005540: 6e76 6972 6f6e 6d65 6e74 2e22 2222 0d0a  nvironment."""..
+00005550: 2020 2020 2020 2020 7265 7475 726e 2073          return s
+00005560: 656c 662e 6f75 7470 7574 5f73 7065 635b  elf.output_spec[
+00005570: 226f 6273 6572 7661 7469 6f6e 225d 0d0a  "observation"]..
+00005580: 0d0a 2020 2020 4070 726f 7065 7274 790d  ..    @property.
+00005590: 0a20 2020 2064 6566 2064 6f6e 655f 7370  .    def done_sp
+000055a0: 6563 2873 656c 6629 202d 3e20 5465 6e73  ec(self) -> Tens
+000055b0: 6f72 5370 6563 3a0d 0a20 2020 2020 2020  orSpec:..       
+000055c0: 2022 2222 446f 6e65 2073 7065 6320 6f66   """Done spec of
+000055d0: 2074 6865 2074 7261 6e73 666f 726d 6564   the transformed
+000055e0: 2065 6e76 6972 6f6e 6d65 6e74 2e22 2222   environment."""
+000055f0: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
+00005600: 2073 656c 662e 6f75 7470 7574 5f73 7065   self.output_spe
+00005610: 635b 2264 6f6e 6522 5d0d 0a0d 0a20 2020  c["done"]....   
+00005620: 2064 6566 205f 7374 6570 2873 656c 662c   def _step(self,
+00005630: 2074 656e 736f 7264 6963 743a 2054 656e   tensordict: Ten
+00005640: 736f 7244 6963 7442 6173 6529 202d 3e20  sorDictBase) -> 
+00005650: 5465 6e73 6f72 4469 6374 4261 7365 3a0d  TensorDictBase:.
+00005660: 0a20 2020 2020 2020 2074 656e 736f 7264  .        tensord
+00005670: 6963 7420 3d20 7465 6e73 6f72 6469 6374  ict = tensordict
+00005680: 2e63 6c6f 6e65 2846 616c 7365 290d 0a20  .clone(False).. 
+00005690: 2020 2020 2020 2074 656e 736f 7264 6963         tensordic
+000056a0: 745f 696e 203d 2073 656c 662e 7472 616e  t_in = self.tran
+000056b0: 7366 6f72 6d2e 696e 7628 7465 6e73 6f72  sform.inv(tensor
+000056c0: 6469 6374 290d 0a20 2020 2020 2020 2074  dict)..        t
+000056d0: 656e 736f 7264 6963 745f 6f75 7420 3d20  ensordict_out = 
+000056e0: 7365 6c66 2e62 6173 655f 656e 762e 5f73  self.base_env._s
+000056f0: 7465 7028 7465 6e73 6f72 6469 6374 5f69  tep(tensordict_i
+00005700: 6e29 0d0a 2020 2020 2020 2020 2320 7765  n)..        # we
+00005710: 2077 616e 7420 7468 6520 696e 7075 7420   want the input 
+00005720: 656e 7472 6965 7320 746f 2072 656d 6169  entries to remai
+00005730: 6e20 756e 6368 616e 6765 640d 0a20 2020  n unchanged..   
+00005740: 2020 2020 2074 656e 736f 7264 6963 745f       tensordict_
+00005750: 6f75 7420 3d20 7465 6e73 6f72 6469 6374  out = tensordict
+00005760: 2e75 7064 6174 6528 7465 6e73 6f72 6469  .update(tensordi
+00005770: 6374 5f6f 7574 290d 0a20 2020 2020 2020  ct_out)..       
+00005780: 2074 656e 736f 7264 6963 745f 6f75 7420   tensordict_out 
+00005790: 3d20 7365 6c66 2e74 7261 6e73 666f 726d  = self.transform
+000057a0: 2e5f 7374 6570 2874 656e 736f 7264 6963  ._step(tensordic
+000057b0: 745f 6f75 7429 0d0a 2020 2020 2020 2020  t_out)..        
+000057c0: 7265 7475 726e 2074 656e 736f 7264 6963  return tensordic
+000057d0: 745f 6f75 740d 0a0d 0a20 2020 2064 6566  t_out....    def
+000057e0: 2073 6574 5f73 6565 6428 0d0a 2020 2020   set_seed(..    
+000057f0: 2020 2020 7365 6c66 2c20 7365 6564 3a20      self, seed: 
+00005800: 4f70 7469 6f6e 616c 5b69 6e74 5d20 3d20  Optional[int] = 
+00005810: 4e6f 6e65 2c20 7374 6174 6963 5f73 6565  None, static_see
+00005820: 643a 2062 6f6f 6c20 3d20 4661 6c73 650d  d: bool = False.
+00005830: 0a20 2020 2029 202d 3e20 4f70 7469 6f6e  .    ) -> Option
+00005840: 616c 5b69 6e74 5d3a 0d0a 2020 2020 2020  al[int]:..      
+00005850: 2020 2222 2253 6574 2074 6865 2073 6565    """Set the see
+00005860: 6473 206f 6620 7468 6520 656e 7669 726f  ds of the enviro
+00005870: 6e6d 656e 742e 2222 220d 0a20 2020 2020  nment."""..     
+00005880: 2020 2072 6574 7572 6e20 7365 6c66 2e62     return self.b
+00005890: 6173 655f 656e 762e 7365 745f 7365 6564  ase_env.set_seed
+000058a0: 2873 6565 642c 2073 7461 7469 635f 7365  (seed, static_se
+000058b0: 6564 3d73 7461 7469 635f 7365 6564 290d  ed=static_seed).
+000058c0: 0a0d 0a20 2020 2064 6566 205f 7365 745f  ...    def _set_
+000058d0: 7365 6564 2873 656c 662c 2073 6565 643a  seed(self, seed:
+000058e0: 204f 7074 696f 6e61 6c5b 696e 745d 293a   Optional[int]):
+000058f0: 0d0a 2020 2020 2020 2020 2222 2254 6869  ..        """Thi
+00005900: 7320 6d65 7468 6f64 2069 7320 6e6f 7420  s method is not 
+00005910: 7573 6564 2069 6e20 7472 616e 7366 6f72  used in transfor
+00005920: 6d65 6420 656e 7673 2e22 2222 0d0a 2020  med envs."""..  
+00005930: 2020 2020 2020 7061 7373 0d0a 0d0a 2020        pass....  
+00005940: 2020 6465 6620 5f72 6573 6574 2873 656c    def _reset(sel
+00005950: 662c 2074 656e 736f 7264 6963 743a 204f  f, tensordict: O
+00005960: 7074 696f 6e61 6c5b 5465 6e73 6f72 4469  ptional[TensorDi
+00005970: 6374 4261 7365 5d20 3d20 4e6f 6e65 2c20  ctBase] = None, 
+00005980: 2a2a 6b77 6172 6773 293a 0d0a 2020 2020  **kwargs):..    
+00005990: 2020 2020 6966 2074 656e 736f 7264 6963      if tensordic
+000059a0: 7420 6973 206e 6f74 204e 6f6e 653a 0d0a  t is not None:..
+000059b0: 2020 2020 2020 2020 2020 2020 7465 6e73              tens
+000059c0: 6f72 6469 6374 203d 2074 656e 736f 7264  ordict = tensord
+000059d0: 6963 742e 636c 6f6e 6528 7265 6375 7273  ict.clone(recurs
+000059e0: 653d 4661 6c73 6529 0d0a 2020 2020 2020  e=False)..      
+000059f0: 2020 6f75 745f 7465 6e73 6f72 6469 6374    out_tensordict
+00005a00: 203d 2073 656c 662e 6261 7365 5f65 6e76   = self.base_env
+00005a10: 2e72 6573 6574 2874 656e 736f 7264 6963  .reset(tensordic
+00005a20: 743d 7465 6e73 6f72 6469 6374 2c20 2a2a  t=tensordict, **
+00005a30: 6b77 6172 6773 290d 0a20 2020 2020 2020  kwargs)..       
+00005a40: 206f 7574 5f74 656e 736f 7264 6963 7420   out_tensordict 
+00005a50: 3d20 7365 6c66 2e74 7261 6e73 666f 726d  = self.transform
+00005a60: 2e72 6573 6574 286f 7574 5f74 656e 736f  .reset(out_tenso
+00005a70: 7264 6963 7429 0d0a 0d0a 2020 2020 2020  rdict)....      
+00005a80: 2020 6d74 5f6d 6f64 6520 3d20 7365 6c66    mt_mode = self
+00005a90: 2e74 7261 6e73 666f 726d 2e6d 6973 7369  .transform.missi
+00005aa0: 6e67 5f74 6f6c 6572 616e 6365 0d0a 2020  ng_tolerance..  
+00005ab0: 2020 2020 2020 7365 6c66 2e73 6574 5f6d        self.set_m
+00005ac0: 6973 7369 6e67 5f74 6f6c 6572 616e 6365  issing_tolerance
+00005ad0: 2854 7275 6529 0d0a 2020 2020 2020 2020  (True)..        
+00005ae0: 6f75 745f 7465 6e73 6f72 6469 6374 203d  out_tensordict =
+00005af0: 2073 656c 662e 7472 616e 7366 6f72 6d2e   self.transform.
+00005b00: 5f63 616c 6c28 6f75 745f 7465 6e73 6f72  _call(out_tensor
+00005b10: 6469 6374 290d 0a20 2020 2020 2020 2073  dict)..        s
+00005b20: 656c 662e 7365 745f 6d69 7373 696e 675f  elf.set_missing_
+00005b30: 746f 6c65 7261 6e63 6528 6d74 5f6d 6f64  tolerance(mt_mod
+00005b40: 6529 0d0a 2020 2020 2020 2020 7265 7475  e)..        retu
+00005b50: 726e 206f 7574 5f74 656e 736f 7264 6963  rn out_tensordic
+00005b60: 740d 0a0d 0a20 2020 2064 6566 2073 7461  t....    def sta
+00005b70: 7465 5f64 6963 7428 7365 6c66 2c20 2a61  te_dict(self, *a
+00005b80: 7267 732c 202a 2a6b 7761 7267 7329 202d  rgs, **kwargs) -
+00005b90: 3e20 4f72 6465 7265 6444 6963 743a 0d0a  > OrderedDict:..
+00005ba0: 2020 2020 2020 2020 7374 6174 655f 6469          state_di
+00005bb0: 6374 203d 2073 656c 662e 7472 616e 7366  ct = self.transf
+00005bc0: 6f72 6d2e 7374 6174 655f 6469 6374 282a  orm.state_dict(*
+00005bd0: 6172 6773 2c20 2a2a 6b77 6172 6773 290d  args, **kwargs).
+00005be0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00005bf0: 7374 6174 655f 6469 6374 0d0a 0d0a 2020  state_dict....  
+00005c00: 2020 6465 6620 6c6f 6164 5f73 7461 7465    def load_state
+00005c10: 5f64 6963 7428 7365 6c66 2c20 7374 6174  _dict(self, stat
+00005c20: 655f 6469 6374 3a20 4f72 6465 7265 6444  e_dict: OrderedD
+00005c30: 6963 742c 202a 2a6b 7761 7267 7329 202d  ict, **kwargs) -
+00005c40: 3e20 4e6f 6e65 3a0d 0a20 2020 2020 2020  > None:..       
+00005c50: 2073 656c 662e 7472 616e 7366 6f72 6d2e   self.transform.
+00005c60: 6c6f 6164 5f73 7461 7465 5f64 6963 7428  load_state_dict(
+00005c70: 7374 6174 655f 6469 6374 2c20 2a2a 6b77  state_dict, **kw
+00005c80: 6172 6773 290d 0a0d 0a20 2020 2064 6566  args)....    def
+00005c90: 2065 7661 6c28 7365 6c66 2920 2d3e 2054   eval(self) -> T
+00005ca0: 7261 6e73 666f 726d 6564 456e 763a 0d0a  ransformedEnv:..
+00005cb0: 2020 2020 2020 2020 6966 2022 7472 616e          if "tran
+00005cc0: 7366 6f72 6d22 2069 6e20 7365 6c66 2e5f  sform" in self._
+00005cd0: 5f64 6972 5f5f 2829 3a0d 0a20 2020 2020  _dir__():..     
+00005ce0: 2020 2020 2020 2023 2077 6865 6e20 6361         # when ca
+00005cf0: 6c6c 696e 6720 5f5f 696e 6974 5f5f 2c20  lling __init__, 
+00005d00: 6576 616c 2829 2069 7320 6361 6c6c 6564  eval() is called
+00005d10: 2062 7574 2074 7261 6e73 666f 726d 7320   but transforms 
+00005d20: 6172 6520 6e6f 7420 7365 740d 0a20 2020  are not set..   
+00005d30: 2020 2020 2020 2020 2023 2079 6574 2e0d           # yet..
+00005d40: 0a20 2020 2020 2020 2020 2020 2073 656c  .            sel
+00005d50: 662e 7472 616e 7366 6f72 6d2e 6576 616c  f.transform.eval
+00005d60: 2829 0d0a 2020 2020 2020 2020 7265 7475  ()..        retu
+00005d70: 726e 2073 656c 660d 0a0d 0a20 2020 2064  rn self....    d
+00005d80: 6566 2074 7261 696e 2873 656c 662c 206d  ef train(self, m
+00005d90: 6f64 653a 2062 6f6f 6c20 3d20 5472 7565  ode: bool = True
+00005da0: 2920 2d3e 2054 7261 6e73 666f 726d 6564  ) -> Transformed
+00005db0: 456e 763a 0d0a 2020 2020 2020 2020 7365  Env:..        se
+00005dc0: 6c66 2e74 7261 6e73 666f 726d 2e74 7261  lf.transform.tra
+00005dd0: 696e 286d 6f64 6529 0d0a 2020 2020 2020  in(mode)..      
+00005de0: 2020 7265 7475 726e 2073 656c 660d 0a0d    return self...
+00005df0: 0a20 2020 2040 7072 6f70 6572 7479 0d0a  .    @property..
+00005e00: 2020 2020 6465 6620 6973 5f63 6c6f 7365      def is_close
+00005e10: 6428 7365 6c66 2920 2d3e 2062 6f6f 6c3a  d(self) -> bool:
+00005e20: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
+00005e30: 2073 656c 662e 6261 7365 5f65 6e76 2e69   self.base_env.i
+00005e40: 735f 636c 6f73 6564 0d0a 0d0a 2020 2020  s_closed....    
+00005e50: 4069 735f 636c 6f73 6564 2e73 6574 7465  @is_closed.sette
+00005e60: 720d 0a20 2020 2064 6566 2069 735f 636c  r..    def is_cl
+00005e70: 6f73 6564 2873 656c 662c 2076 616c 7565  osed(self, value
+00005e80: 3a20 626f 6f6c 293a 0d0a 2020 2020 2020  : bool):..      
+00005e90: 2020 7365 6c66 2e62 6173 655f 656e 762e    self.base_env.
+00005ea0: 6973 5f63 6c6f 7365 6420 3d20 7661 6c75  is_closed = valu
+00005eb0: 650d 0a0d 0a20 2020 2064 6566 2063 6c6f  e....    def clo
+00005ec0: 7365 2873 656c 6629 3a0d 0a20 2020 2020  se(self):..     
+00005ed0: 2020 2073 656c 662e 6261 7365 5f65 6e76     self.base_env
+00005ee0: 2e63 6c6f 7365 2829 0d0a 2020 2020 2020  .close()..      
+00005ef0: 2020 7365 6c66 2e69 735f 636c 6f73 6564    self.is_closed
+00005f00: 203d 2054 7275 650d 0a0d 0a20 2020 2064   = True....    d
+00005f10: 6566 2065 6d70 7479 5f63 6163 6865 2873  ef empty_cache(s
+00005f20: 656c 6629 3a0d 0a20 2020 2020 2020 2073  elf):..        s
+00005f30: 656c 662e 5f5f 6469 6374 5f5f 5b22 5f6f  elf.__dict__["_o
+00005f40: 7574 7075 745f 7370 6563 225d 203d 204e  utput_spec"] = N
+00005f50: 6f6e 650d 0a20 2020 2020 2020 2073 656c  one..        sel
+00005f60: 662e 5f5f 6469 6374 5f5f 5b22 5f69 6e70  f.__dict__["_inp
+00005f70: 7574 5f73 7065 6322 5d20 3d20 4e6f 6e65  ut_spec"] = None
+00005f80: 0d0a 2020 2020 2020 2020 7365 6c66 2e5f  ..        self._
+00005f90: 5f64 6963 745f 5f5b 225f 6361 6368 655f  _dict__["_cache_
+00005fa0: 696e 5f6b 6579 7322 5d20 3d20 4e6f 6e65  in_keys"] = None
+00005fb0: 0d0a 0d0a 2020 2020 6465 6620 6170 7065  ....    def appe
+00005fc0: 6e64 5f74 7261 6e73 666f 726d 2873 656c  nd_transform(sel
+00005fd0: 662c 2074 7261 6e73 666f 726d 3a20 5472  f, transform: Tr
+00005fe0: 616e 7366 6f72 6d29 202d 3e20 4e6f 6e65  ansform) -> None
+00005ff0: 3a0d 0a20 2020 2020 2020 2073 656c 662e  :..        self.
+00006000: 5f65 7261 7365 5f6d 6574 6164 6174 6128  _erase_metadata(
+00006010: 290d 0a20 2020 2020 2020 2069 6620 6e6f  )..        if no
+00006020: 7420 6973 696e 7374 616e 6365 2874 7261  t isinstance(tra
+00006030: 6e73 666f 726d 2c20 5472 616e 7366 6f72  nsform, Transfor
+00006040: 6d29 3a0d 0a20 2020 2020 2020 2020 2020  m):..           
+00006050: 2072 6169 7365 2056 616c 7565 4572 726f   raise ValueErro
+00006060: 7228 0d0a 2020 2020 2020 2020 2020 2020  r(..            
+00006070: 2020 2020 2254 7261 6e73 666f 726d 6564      "Transformed
+00006080: 456e 762e 6170 7065 6e64 5f74 7261 6e73  Env.append_trans
+00006090: 666f 726d 2065 7870 6563 7465 6420 6120  form expected a 
+000060a0: 7472 616e 7366 6f72 6d20 6275 7420 7265  transform but re
+000060b0: 6365 6976 6564 2061 6e20 6f62 6a65 6374  ceived an object
+000060c0: 206f 6620 220d 0a20 2020 2020 2020 2020   of "..         
+000060d0: 2020 2020 2020 2066 2274 7970 6520 7b74         f"type {t
+000060e0: 7970 6528 7472 616e 7366 6f72 6d29 7d20  ype(transform)} 
+000060f0: 696e 7374 6561 642e 220d 0a20 2020 2020  instead."..     
+00006100: 2020 2020 2020 2029 0d0a 2020 2020 2020         )..      
+00006110: 2020 7472 616e 7366 6f72 6d20 3d20 7472    transform = tr
+00006120: 616e 7366 6f72 6d2e 746f 2873 656c 662e  ansform.to(self.
+00006130: 6465 7669 6365 290d 0a20 2020 2020 2020  device)..       
+00006140: 2069 6620 6e6f 7420 6973 696e 7374 616e   if not isinstan
+00006150: 6365 2873 656c 662e 7472 616e 7366 6f72  ce(self.transfor
+00006160: 6d2c 2043 6f6d 706f 7365 293a 0d0a 2020  m, Compose):..  
+00006170: 2020 2020 2020 2020 2020 7072 6576 5f74            prev_t
+00006180: 7261 6e73 666f 726d 203d 2073 656c 662e  ransform = self.
+00006190: 7472 616e 7366 6f72 6d0d 0a20 2020 2020  transform..     
+000061a0: 2020 2020 2020 2070 7265 765f 7472 616e         prev_tran
+000061b0: 7366 6f72 6d2e 7265 7365 745f 7061 7265  sform.reset_pare
+000061c0: 6e74 2829 0d0a 2020 2020 2020 2020 2020  nt()..          
+000061d0: 2020 7365 6c66 2e74 7261 6e73 666f 726d    self.transform
+000061e0: 203d 2043 6f6d 706f 7365 2829 0d0a 2020   = Compose()..  
+000061f0: 2020 2020 2020 2020 2020 7365 6c66 2e74            self.t
+00006200: 7261 6e73 666f 726d 2e61 7070 656e 6428  ransform.append(
+00006210: 7072 6576 5f74 7261 6e73 666f 726d 290d  prev_transform).
+00006220: 0a0d 0a20 2020 2020 2020 2073 656c 662e  ...        self.
+00006230: 7472 616e 7366 6f72 6d2e 6170 7065 6e64  transform.append
+00006240: 2874 7261 6e73 666f 726d 290d 0a0d 0a20  (transform).... 
+00006250: 2020 2064 6566 2069 6e73 6572 745f 7472     def insert_tr
+00006260: 616e 7366 6f72 6d28 7365 6c66 2c20 696e  ansform(self, in
+00006270: 6465 783a 2069 6e74 2c20 7472 616e 7366  dex: int, transf
+00006280: 6f72 6d3a 2054 7261 6e73 666f 726d 2920  orm: Transform) 
+00006290: 2d3e 204e 6f6e 653a 0d0a 2020 2020 2020  -> None:..      
+000062a0: 2020 6966 206e 6f74 2069 7369 6e73 7461    if not isinsta
+000062b0: 6e63 6528 7472 616e 7366 6f72 6d2c 2054  nce(transform, T
+000062c0: 7261 6e73 666f 726d 293a 0d0a 2020 2020  ransform):..    
+000062d0: 2020 2020 2020 2020 7261 6973 6520 5661          raise Va
+000062e0: 6c75 6545 7272 6f72 280d 0a20 2020 2020  lueError(..     
+000062f0: 2020 2020 2020 2020 2020 2022 5472 616e             "Tran
+00006300: 7366 6f72 6d65 6445 6e76 2e69 6e73 6572  sformedEnv.inser
+00006310: 745f 7472 616e 7366 6f72 6d20 6578 7065  t_transform expe
+00006320: 6374 6564 2061 2074 7261 6e73 666f 726d  cted a transform
+00006330: 2062 7574 2072 6563 6569 7665 6420 616e   but received an
+00006340: 206f 626a 6563 7420 6f66 2022 0d0a 2020   object of "..  
+00006350: 2020 2020 2020 2020 2020 2020 2020 6622                f"
+00006360: 7479 7065 207b 7479 7065 2874 7261 6e73  type {type(trans
+00006370: 666f 726d 297d 2069 6e73 7465 6164 2e22  form)} instead."
+00006380: 0d0a 2020 2020 2020 2020 2020 2020 290d  ..            ).
+00006390: 0a20 2020 2020 2020 2074 7261 6e73 666f  .        transfo
+000063a0: 726d 203d 2074 7261 6e73 666f 726d 2e74  rm = transform.t
+000063b0: 6f28 7365 6c66 2e64 6576 6963 6529 0d0a  o(self.device)..
+000063c0: 2020 2020 2020 2020 6966 206e 6f74 2069          if not i
+000063d0: 7369 6e73 7461 6e63 6528 7365 6c66 2e74  sinstance(self.t
+000063e0: 7261 6e73 666f 726d 2c20 436f 6d70 6f73  ransform, Compos
+000063f0: 6529 3a0d 0a20 2020 2020 2020 2020 2020  e):..           
+00006400: 2063 6f6d 706f 7365 203d 2043 6f6d 706f   compose = Compo
+00006410: 7365 2873 656c 662e 7472 616e 7366 6f72  se(self.transfor
+00006420: 6d2e 636c 6f6e 6528 2929 0d0a 2020 2020  m.clone())..    
+00006430: 2020 2020 2020 2020 7365 6c66 2e74 7261          self.tra
+00006440: 6e73 666f 726d 203d 2063 6f6d 706f 7365  nsform = compose
+00006450: 2020 2320 7061 7265 6e74 2073 6574 2061    # parent set a
+00006460: 7574 6f6d 6174 6963 616c 6c79 0d0a 0d0a  utomatically....
+00006470: 2020 2020 2020 2020 7365 6c66 2e74 7261          self.tra
+00006480: 6e73 666f 726d 2e69 6e73 6572 7428 696e  nsform.insert(in
+00006490: 6465 782c 2074 7261 6e73 666f 726d 290d  dex, transform).
+000064a0: 0a20 2020 2020 2020 2073 656c 662e 5f65  .        self._e
+000064b0: 7261 7365 5f6d 6574 6164 6174 6128 290d  rase_metadata().
+000064c0: 0a0d 0a20 2020 2064 6566 205f 5f67 6574  ...    def __get
+000064d0: 6174 7472 5f5f 2873 656c 662c 2061 7474  attr__(self, att
+000064e0: 723a 2073 7472 2920 2d3e 2041 6e79 3a0d  r: str) -> Any:.
+000064f0: 0a20 2020 2020 2020 2069 6620 6174 7472  .        if attr
+00006500: 2069 6e20 7365 6c66 2e5f 5f64 6972 5f5f   in self.__dir__
+00006510: 2829 3a0d 0a20 2020 2020 2020 2020 2020  ():..           
+00006520: 2072 6574 7572 6e20 7375 7065 7228 292e   return super().
+00006530: 5f5f 6765 7461 7474 725f 5f28 0d0a 2020  __getattr__(..  
+00006540: 2020 2020 2020 2020 2020 2020 2020 6174                at
+00006550: 7472 0d0a 2020 2020 2020 2020 2020 2020  tr..            
+00006560: 2920 2023 206d 616b 6520 7375 7265 2074  )  # make sure t
+00006570: 6861 7420 6170 7072 6f70 7269 6174 6520  hat appropriate 
+00006580: 6578 6365 7074 696f 6e73 2061 7265 2072  exceptions are r
+00006590: 6169 7365 640d 0a20 2020 2020 2020 2065  aised..        e
+000065a0: 6c69 6620 6174 7472 2e73 7461 7274 7377  lif attr.startsw
+000065b0: 6974 6828 225f 5f22 293a 0d0a 2020 2020  ith("__"):..    
+000065c0: 2020 2020 2020 2020 7261 6973 6520 4174          raise At
+000065d0: 7472 6962 7574 6545 7272 6f72 280d 0a20  tributeError(.. 
+000065e0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+000065f0: 7061 7373 696e 6720 6275 696c 742d 696e  passing built-in
+00006600: 2070 7269 7661 7465 206d 6574 686f 6473   private methods
+00006610: 2069 7320 220d 0a20 2020 2020 2020 2020   is "..         
+00006620: 2020 2020 2020 2066 226e 6f74 2070 6572         f"not per
+00006630: 6d69 7474 6564 2077 6974 6820 7479 7065  mitted with type
+00006640: 207b 7479 7065 2873 656c 6629 7d2e 2022   {type(self)}. "
+00006650: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00006660: 2020 6622 476f 7420 6174 7472 6962 7574    f"Got attribut
+00006670: 6520 7b61 7474 727d 2e22 0d0a 2020 2020  e {attr}."..    
+00006680: 2020 2020 2020 2020 290d 0a20 2020 2020          )..     
+00006690: 2020 2065 6c69 6620 2262 6173 655f 656e     elif "base_en
+000066a0: 7622 2069 6e20 7365 6c66 2e5f 5f64 6972  v" in self.__dir
+000066b0: 5f5f 2829 3a0d 0a20 2020 2020 2020 2020  __():..         
+000066c0: 2020 2062 6173 655f 656e 7620 3d20 7365     base_env = se
+000066d0: 6c66 2e5f 5f67 6574 6174 7472 5f5f 2822  lf.__getattr__("
+000066e0: 6261 7365 5f65 6e76 2229 0d0a 2020 2020  base_env")..    
+000066f0: 2020 2020 2020 2020 7265 7475 726e 2067          return g
+00006700: 6574 6174 7472 2862 6173 655f 656e 762c  etattr(base_env,
+00006710: 2061 7474 7229 0d0a 0d0a 2020 2020 2020   attr)....      
+00006720: 2020 7261 6973 6520 4174 7472 6962 7574    raise Attribut
+00006730: 6545 7272 6f72 280d 0a20 2020 2020 2020  eError(..       
+00006740: 2020 2020 2066 2265 6e76 206e 6f74 2073       f"env not s
+00006750: 6574 2069 6e20 7b73 656c 662e 5f5f 636c  et in {self.__cl
+00006760: 6173 735f 5f2e 5f5f 6e61 6d65 5f5f 7d2c  ass__.__name__},
+00006770: 2063 616e 6e6f 7420 6163 6365 7373 207b   cannot access {
+00006780: 6174 7472 7d22 0d0a 2020 2020 2020 2020  attr}"..        
+00006790: 290d 0a0d 0a20 2020 2064 6566 205f 5f72  )....    def __r
+000067a0: 6570 725f 5f28 7365 6c66 2920 2d3e 2073  epr__(self) -> s
+000067b0: 7472 3a0d 0a20 2020 2020 2020 2065 6e76  tr:..        env
+000067c0: 5f73 7472 203d 2069 6e64 656e 7428 6622  _str = indent(f"
+000067d0: 656e 763d 7b73 656c 662e 6261 7365 5f65  env={self.base_e
+000067e0: 6e76 7d22 2c20 3420 2a20 2220 2229 0d0a  nv}", 4 * " ")..
+000067f0: 2020 2020 2020 2020 745f 7374 7220 3d20          t_str = 
+00006800: 696e 6465 6e74 2866 2274 7261 6e73 666f  indent(f"transfo
+00006810: 726d 3d7b 7365 6c66 2e74 7261 6e73 666f  rm={self.transfo
+00006820: 726d 7d22 2c20 3420 2a20 2220 2229 0d0a  rm}", 4 * " ")..
+00006830: 2020 2020 2020 2020 7265 7475 726e 2066          return f
+00006840: 2254 7261 6e73 666f 726d 6564 456e 7628  "TransformedEnv(
+00006850: 5c6e 7b65 6e76 5f73 7472 7d2c 5c6e 7b74  \n{env_str},\n{t
+00006860: 5f73 7472 7d29 220d 0a0d 0a20 2020 2064  _str})"....    d
+00006870: 6566 205f 6572 6173 655f 6d65 7461 6461  ef _erase_metada
+00006880: 7461 2873 656c 6629 3a0d 0a20 2020 2020  ta(self):..     
+00006890: 2020 2069 6620 7365 6c66 2e63 6163 6865     if self.cache
+000068a0: 5f73 7065 6373 3a0d 0a20 2020 2020 2020  _specs:..       
+000068b0: 2020 2020 2073 656c 662e 5f5f 6469 6374       self.__dict
+000068c0: 5f5f 5b22 5f69 6e70 7574 5f73 7065 6322  __["_input_spec"
+000068d0: 5d20 3d20 4e6f 6e65 0d0a 2020 2020 2020  ] = None..      
+000068e0: 2020 2020 2020 7365 6c66 2e5f 5f64 6963        self.__dic
+000068f0: 745f 5f5b 225f 6f75 7470 7574 5f73 7065  t__["_output_spe
+00006900: 6322 5d20 3d20 4e6f 6e65 0d0a 2020 2020  c"] = None..    
+00006910: 2020 2020 2020 2020 7365 6c66 2e5f 5f64          self.__d
+00006920: 6963 745f 5f5b 225f 6361 6368 655f 696e  ict__["_cache_in
+00006930: 5f6b 6579 7322 5d20 3d20 4e6f 6e65 0d0a  _keys"] = None..
+00006940: 0d0a 2020 2020 6465 6620 746f 2873 656c  ..    def to(sel
+00006950: 662c 2064 6576 6963 653a 2044 4556 4943  f, device: DEVIC
+00006960: 455f 5459 5049 4e47 2920 2d3e 2054 7261  E_TYPING) -> Tra
+00006970: 6e73 666f 726d 6564 456e 763a 0d0a 2020  nsformedEnv:..  
+00006980: 2020 2020 2020 7365 6c66 2e62 6173 655f        self.base_
+00006990: 656e 762e 746f 2864 6576 6963 6529 0d0a  env.to(device)..
+000069a0: 2020 2020 2020 2020 7365 6c66 2e74 7261          self.tra
+000069b0: 6e73 666f 726d 2e74 6f28 6465 7669 6365  nsform.to(device
+000069c0: 290d 0a0d 0a20 2020 2020 2020 2069 6620  )....        if 
+000069d0: 7365 6c66 2e63 6163 6865 5f73 7065 6373  self.cache_specs
+000069e0: 3a0d 0a20 2020 2020 2020 2020 2020 2073  :..            s
+000069f0: 656c 662e 5f5f 6469 6374 5f5f 5b22 5f69  elf.__dict__["_i
+00006a00: 6e70 7574 5f73 7065 6322 5d20 3d20 4e6f  nput_spec"] = No
+00006a10: 6e65 0d0a 2020 2020 2020 2020 2020 2020  ne..            
+00006a20: 7365 6c66 2e5f 5f64 6963 745f 5f5b 225f  self.__dict__["_
+00006a30: 6f75 7470 7574 5f73 7065 6322 5d20 3d20  output_spec"] = 
+00006a40: 4e6f 6e65 0d0a 2020 2020 2020 2020 7265  None..        re
+00006a50: 7475 726e 2073 656c 660d 0a0d 0a20 2020  turn self....   
+00006a60: 2064 6566 205f 5f73 6574 6174 7472 5f5f   def __setattr__
+00006a70: 2873 656c 662c 206b 6579 2c20 7661 6c75  (self, key, valu
+00006a80: 6529 3a0d 0a20 2020 2020 2020 2070 726f  e):..        pro
+00006a90: 706f 626a 203d 2067 6574 6174 7472 2873  pobj = getattr(s
+00006aa0: 656c 662e 5f5f 636c 6173 735f 5f2c 206b  elf.__class__, k
+00006ab0: 6579 2c20 4e6f 6e65 290d 0a0d 0a20 2020  ey, None)....   
+00006ac0: 2020 2020 2069 6620 6973 696e 7374 616e       if isinstan
+00006ad0: 6365 2870 726f 706f 626a 2c20 7072 6f70  ce(propobj, prop
+00006ae0: 6572 7479 293a 0d0a 2020 2020 2020 2020  erty):..        
+00006af0: 2020 2020 616e 6365 7374 6f72 7320 3d20      ancestors = 
+00006b00: 6c69 7374 285f 5f63 6c61 7373 5f5f 2e5f  list(__class__._
+00006b10: 5f6d 726f 5f5f 295b 3a3a 2d31 5d0d 0a20  _mro__)[::-1].. 
+00006b20: 2020 2020 2020 2020 2020 2077 6869 6c65             while
+00006b30: 2069 7369 6e73 7461 6e63 6528 7072 6f70   isinstance(prop
+00006b40: 6f62 6a2c 2070 726f 7065 7274 7929 3a0d  obj, property):.
+00006b50: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00006b60: 2069 6620 7072 6f70 6f62 6a2e 6673 6574   if propobj.fset
+00006b70: 2069 7320 6e6f 7420 4e6f 6e65 3a0d 0a20   is not None:.. 
+00006b80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006b90: 2020 2072 6574 7572 6e20 7072 6f70 6f62     return propob
+00006ba0: 6a2e 6673 6574 2873 656c 662c 2076 616c  j.fset(self, val
+00006bb0: 7565 290d 0a20 2020 2020 2020 2020 2020  ue)..           
+00006bc0: 2020 2020 2070 726f 706f 626a 203d 2067       propobj = g
+00006bd0: 6574 6174 7472 2861 6e63 6573 746f 7273  etattr(ancestors
+00006be0: 2e70 6f70 2829 2c20 6b65 792c 204e 6f6e  .pop(), key, Non
+00006bf0: 6529 0d0a 2020 2020 2020 2020 2020 2020  e)..            
+00006c00: 656c 7365 3a0d 0a20 2020 2020 2020 2020  else:..         
+00006c10: 2020 2020 2020 2072 6169 7365 2041 7474         raise Att
+00006c20: 7269 6275 7465 4572 726f 7228 6622 6361  ributeError(f"ca
+00006c30: 6e27 7420 7365 7420 6174 7472 6962 7574  n't set attribut
+00006c40: 6520 7b6b 6579 7d22 290d 0a20 2020 2020  e {key}")..     
+00006c50: 2020 2065 6c73 653a 0d0a 2020 2020 2020     else:..      
+00006c60: 2020 2020 2020 7265 7475 726e 2073 7570        return sup
+00006c70: 6572 2829 2e5f 5f73 6574 6174 7472 5f5f  er().__setattr__
+00006c80: 286b 6579 2c20 7661 6c75 6529 0d0a 0d0a  (key, value)....
+00006c90: 2020 2020 6465 6620 5f5f 6465 6c5f 5f28      def __del__(
+00006ca0: 7365 6c66 293a 0d0a 2020 2020 2020 2020  self):..        
+00006cb0: 2320 7765 206d 6179 2064 656c 6574 6520  # we may delete 
+00006cc0: 6120 5472 616e 7366 6f72 6d65 6445 6e76  a TransformedEnv
+00006cd0: 2074 6861 7420 636f 6e74 6169 6e73 2061   that contains a
+00006ce0: 6e20 656e 7620 636f 6e74 6169 6e65 6420  n env contained 
+00006cf0: 6279 2061 6e6f 7468 6572 0d0a 2020 2020  by another..    
+00006d00: 2020 2020 2320 7472 616e 7366 6f72 6d65      # transforme
+00006d10: 6420 656e 7620 616e 6420 7468 6174 2077  d env and that w
+00006d20: 6520 646f 6e27 7420 7761 6e74 2074 6f20  e don't want to 
+00006d30: 636c 6f73 650d 0a20 2020 2020 2020 2070  close..        p
+00006d40: 6173 730d 0a0d 0a20 2020 2064 6566 2073  ass....    def s
+00006d50: 6574 5f6d 6973 7369 6e67 5f74 6f6c 6572  et_missing_toler
+00006d60: 616e 6365 2873 656c 662c 206d 6f64 653d  ance(self, mode=
+00006d70: 4661 6c73 6529 3a0d 0a20 2020 2020 2020  False):..       
+00006d80: 2022 2222 496e 6469 6361 7465 7320 6966   """Indicates if
+00006d90: 2061 6e20 4b65 7945 7272 6f72 2073 686f   an KeyError sho
+00006da0: 756c 6420 6265 2072 6169 7365 6420 7768  uld be raised wh
+00006db0: 656e 6576 6572 2061 6e20 696e 5f6b 6579  enever an in_key
+00006dc0: 2069 7320 6d69 7373 696e 6720 6672 6f6d   is missing from
+00006dd0: 2074 6865 2069 6e70 7574 2074 656e 736f   the input tenso
+00006de0: 7264 6963 742e 2222 220d 0a20 2020 2020  rdict."""..     
+00006df0: 2020 2073 656c 662e 7472 616e 7366 6f72     self.transfor
+00006e00: 6d2e 7365 745f 6d69 7373 696e 675f 746f  m.set_missing_to
+00006e10: 6c65 7261 6e63 6528 6d6f 6465 290d 0a0d  lerance(mode)...
+00006e20: 0a0d 0a63 6c61 7373 204f 6273 6572 7661  ...class Observa
+00006e30: 7469 6f6e 5472 616e 7366 6f72 6d28 5472  tionTransform(Tr
+00006e40: 616e 7366 6f72 6d29 3a0d 0a20 2020 2022  ansform):..    "
+00006e50: 2222 4162 7374 7261 6374 2063 6c61 7373  ""Abstract class
+00006e60: 2066 6f72 2074 7261 6e73 666f 726d 6174   for transformat
+00006e70: 696f 6e73 206f 6620 7468 6520 6f62 7365  ions of the obse
+00006e80: 7276 6174 696f 6e73 2e22 2222 0d0a 0d0a  rvations."""....
+00006e90: 2020 2020 6465 6620 5f5f 696e 6974 5f5f      def __init__
+00006ea0: 280d 0a20 2020 2020 2020 2073 656c 662c  (..        self,
+00006eb0: 0d0a 2020 2020 2020 2020 696e 5f6b 6579  ..        in_key
+00006ec0: 733a 204f 7074 696f 6e61 6c5b 5365 7175  s: Optional[Sequ
+00006ed0: 656e 6365 5b73 7472 5d5d 203d 204e 6f6e  ence[str]] = Non
+00006ee0: 652c 0d0a 2020 2020 2020 2020 6f75 745f  e,..        out_
+00006ef0: 6b65 7973 3a20 4f70 7469 6f6e 616c 5b53  keys: Optional[S
+00006f00: 6571 7565 6e63 655b 7374 725d 5d20 3d20  equence[str]] = 
+00006f10: 4e6f 6e65 2c0d 0a20 2020 2020 2020 2069  None,..        i
+00006f20: 6e5f 6b65 7973 5f69 6e76 3a20 4f70 7469  n_keys_inv: Opti
+00006f30: 6f6e 616c 5b53 6571 7565 6e63 655b 7374  onal[Sequence[st
+00006f40: 725d 5d20 3d20 4e6f 6e65 2c0d 0a20 2020  r]] = None,..   
+00006f50: 2020 2020 206f 7574 5f6b 6579 735f 696e       out_keys_in
+00006f60: 763a 204f 7074 696f 6e61 6c5b 5365 7175  v: Optional[Sequ
+00006f70: 656e 6365 5b73 7472 5d5d 203d 204e 6f6e  ence[str]] = Non
+00006f80: 652c 0d0a 2020 2020 293a 0d0a 2020 2020  e,..    ):..    
+00006f90: 2020 2020 6966 2069 6e5f 6b65 7973 2069      if in_keys i
+00006fa0: 7320 4e6f 6e65 3a0d 0a20 2020 2020 2020  s None:..       
+00006fb0: 2020 2020 2069 6e5f 6b65 7973 203d 205b       in_keys = [
+00006fc0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00006fd0: 2020 226f 6273 6572 7661 7469 6f6e 222c    "observation",
+00006fe0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00006ff0: 2020 2270 6978 656c 7322 2c0d 0a20 2020    "pixels",..   
+00007000: 2020 2020 2020 2020 205d 0d0a 2020 2020           ]..    
+00007010: 2020 2020 7375 7065 7228 4f62 7365 7276      super(Observ
+00007020: 6174 696f 6e54 7261 6e73 666f 726d 2c20  ationTransform, 
+00007030: 7365 6c66 292e 5f5f 696e 6974 5f5f 280d  self).__init__(.
+00007040: 0a20 2020 2020 2020 2020 2020 2069 6e5f  .            in_
+00007050: 6b65 7973 3d69 6e5f 6b65 7973 2c0d 0a20  keys=in_keys,.. 
+00007060: 2020 2020 2020 2020 2020 206f 7574 5f6b             out_k
+00007070: 6579 733d 6f75 745f 6b65 7973 2c0d 0a20  eys=out_keys,.. 
+00007080: 2020 2020 2020 2020 2020 2069 6e5f 6b65             in_ke
+00007090: 7973 5f69 6e76 3d69 6e5f 6b65 7973 5f69  ys_inv=in_keys_i
+000070a0: 6e76 2c0d 0a20 2020 2020 2020 2020 2020  nv,..           
+000070b0: 206f 7574 5f6b 6579 735f 696e 763d 6f75   out_keys_inv=ou
+000070c0: 745f 6b65 7973 5f69 6e76 2c0d 0a20 2020  t_keys_inv,..   
+000070d0: 2020 2020 2029 0d0a 0d0a 0d0a 636c 6173       )......clas
+000070e0: 7320 436f 6d70 6f73 6528 5472 616e 7366  s Compose(Transf
+000070f0: 6f72 6d29 3a0d 0a20 2020 2022 2222 436f  orm):..    """Co
+00007100: 6d70 6f73 6573 2061 2063 6861 696e 206f  mposes a chain o
+00007110: 6620 7472 616e 7366 6f72 6d73 2e0d 0a0d  f transforms....
+00007120: 0a20 2020 2045 7861 6d70 6c65 733a 0d0a  .    Examples:..
+00007130: 2020 2020 2020 2020 3e3e 3e20 656e 7620          >>> env 
+00007140: 3d20 4779 6d45 6e76 2822 5065 6e64 756c  = GymEnv("Pendul
+00007150: 756d 2d76 3022 290d 0a20 2020 2020 2020  um-v0")..       
+00007160: 203e 3e3e 2074 7261 6e73 666f 726d 7320   >>> transforms 
+00007170: 3d20 5b52 6577 6172 6453 6361 6c69 6e67  = [RewardScaling
+00007180: 2831 2e30 2c20 312e 3029 2c20 5265 7761  (1.0, 1.0), Rewa
+00007190: 7264 436c 6970 7069 6e67 282d 322e 302c  rdClipping(-2.0,
+000071a0: 2032 2e30 295d 0d0a 2020 2020 2020 2020   2.0)]..        
+000071b0: 3e3e 3e20 7472 616e 7366 6f72 6d73 203d  >>> transforms =
+000071c0: 2043 6f6d 706f 7365 282a 7472 616e 7366   Compose(*transf
+000071d0: 6f72 6d73 290d 0a20 2020 2020 2020 203e  orms)..        >
+000071e0: 3e3e 2074 7261 6e73 666f 726d 6564 5f65  >> transformed_e
+000071f0: 6e76 203d 2054 7261 6e73 666f 726d 6564  nv = Transformed
+00007200: 456e 7628 656e 762c 2074 7261 6e73 666f  Env(env, transfo
+00007210: 726d 7329 0d0a 0d0a 2020 2020 2222 220d  rms)....    """.
+00007220: 0a0d 0a20 2020 2064 6566 205f 5f69 6e69  ...    def __ini
+00007230: 745f 5f28 7365 6c66 2c20 2a74 7261 6e73  t__(self, *trans
+00007240: 666f 726d 733a 2054 7261 6e73 666f 726d  forms: Transform
+00007250: 293a 0d0a 2020 2020 2020 2020 7375 7065  ):..        supe
+00007260: 7228 292e 5f5f 696e 6974 5f5f 2869 6e5f  r().__init__(in_
+00007270: 6b65 7973 3d5b 5d29 0d0a 2020 2020 2020  keys=[])..      
+00007280: 2020 7365 6c66 2e74 7261 6e73 666f 726d    self.transform
+00007290: 7320 3d20 6e6e 2e4d 6f64 756c 654c 6973  s = nn.ModuleLis
+000072a0: 7428 7472 616e 7366 6f72 6d73 290d 0a20  t(transforms).. 
+000072b0: 2020 2020 2020 2066 6f72 2074 2069 6e20         for t in 
+000072c0: 7472 616e 7366 6f72 6d73 3a0d 0a20 2020  transforms:..   
+000072d0: 2020 2020 2020 2020 2074 2e73 6574 5f63           t.set_c
+000072e0: 6f6e 7461 696e 6572 2873 656c 6629 0d0a  ontainer(self)..
+000072f0: 0d0a 2020 2020 6465 6620 5f63 616c 6c28  ..    def _call(
+00007300: 7365 6c66 2c20 7465 6e73 6f72 6469 6374  self, tensordict
+00007310: 3a20 5465 6e73 6f72 4469 6374 4261 7365  : TensorDictBase
+00007320: 2920 2d3e 2054 656e 736f 7244 6963 7442  ) -> TensorDictB
+00007330: 6173 653a 0d0a 2020 2020 2020 2020 666f  ase:..        fo
+00007340: 7220 7420 696e 2073 656c 662e 7472 616e  r t in self.tran
+00007350: 7366 6f72 6d73 3a0d 0a20 2020 2020 2020  sforms:..       
+00007360: 2020 2020 2074 656e 736f 7264 6963 7420       tensordict 
+00007370: 3d20 742e 5f63 616c 6c28 7465 6e73 6f72  = t._call(tensor
+00007380: 6469 6374 290d 0a20 2020 2020 2020 2072  dict)..        r
+00007390: 6574 7572 6e20 7465 6e73 6f72 6469 6374  eturn tensordict
+000073a0: 0d0a 0d0a 2020 2020 6465 6620 666f 7277  ....    def forw
+000073b0: 6172 6428 7365 6c66 2c20 7465 6e73 6f72  ard(self, tensor
+000073c0: 6469 6374 3a20 5465 6e73 6f72 4469 6374  dict: TensorDict
+000073d0: 4261 7365 2920 2d3e 2054 656e 736f 7244  Base) -> TensorD
+000073e0: 6963 7442 6173 653a 0d0a 2020 2020 2020  ictBase:..      
+000073f0: 2020 666f 7220 7420 696e 2073 656c 662e    for t in self.
+00007400: 7472 616e 7366 6f72 6d73 3a0d 0a20 2020  transforms:..   
+00007410: 2020 2020 2020 2020 2074 656e 736f 7264           tensord
+00007420: 6963 7420 3d20 7428 7465 6e73 6f72 6469  ict = t(tensordi
+00007430: 6374 290d 0a20 2020 2020 2020 2072 6574  ct)..        ret
+00007440: 7572 6e20 7465 6e73 6f72 6469 6374 0d0a  urn tensordict..
+00007450: 0d0a 2020 2020 6465 6620 5f73 7465 7028  ..    def _step(
+00007460: 7365 6c66 2c20 7465 6e73 6f72 6469 6374  self, tensordict
+00007470: 3a20 5465 6e73 6f72 4469 6374 4261 7365  : TensorDictBase
+00007480: 2920 2d3e 2054 656e 736f 7244 6963 7442  ) -> TensorDictB
+00007490: 6173 653a 0d0a 2020 2020 2020 2020 666f  ase:..        fo
+000074a0: 7220 7420 696e 2073 656c 662e 7472 616e  r t in self.tran
+000074b0: 7366 6f72 6d73 3a0d 0a20 2020 2020 2020  sforms:..       
+000074c0: 2020 2020 2074 656e 736f 7264 6963 7420       tensordict 
+000074d0: 3d20 742e 5f73 7465 7028 7465 6e73 6f72  = t._step(tensor
+000074e0: 6469 6374 290d 0a20 2020 2020 2020 2072  dict)..        r
+000074f0: 6574 7572 6e20 7465 6e73 6f72 6469 6374  eturn tensordict
+00007500: 0d0a 0d0a 2020 2020 6465 6620 5f69 6e76  ....    def _inv
+00007510: 5f63 616c 6c28 7365 6c66 2c20 7465 6e73  _call(self, tens
+00007520: 6f72 6469 6374 3a20 5465 6e73 6f72 4469  ordict: TensorDi
+00007530: 6374 4261 7365 2920 2d3e 2054 656e 736f  ctBase) -> Tenso
+00007540: 7244 6963 7442 6173 653a 0d0a 2020 2020  rDictBase:..    
+00007550: 2020 2020 666f 7220 7420 696e 2072 6576      for t in rev
+00007560: 6572 7365 6428 7365 6c66 2e74 7261 6e73  ersed(self.trans
+00007570: 666f 726d 7329 3a0d 0a20 2020 2020 2020  forms):..       
+00007580: 2020 2020 2074 656e 736f 7264 6963 7420       tensordict 
+00007590: 3d20 742e 5f69 6e76 5f63 616c 6c28 7465  = t._inv_call(te
+000075a0: 6e73 6f72 6469 6374 290d 0a20 2020 2020  nsordict)..     
+000075b0: 2020 2072 6574 7572 6e20 7465 6e73 6f72     return tensor
+000075c0: 6469 6374 0d0a 0d0a 2020 2020 6465 6620  dict....    def 
+000075d0: 7472 616e 7366 6f72 6d5f 696e 7075 745f  transform_input_
+000075e0: 7370 6563 2873 656c 662c 2069 6e70 7574  spec(self, input
+000075f0: 5f73 7065 633a 2054 656e 736f 7253 7065  _spec: TensorSpe
+00007600: 6329 202d 3e20 5465 6e73 6f72 5370 6563  c) -> TensorSpec
+00007610: 3a0d 0a20 2020 2020 2020 2066 6f72 2074  :..        for t
+00007620: 2069 6e20 7365 6c66 2e74 7261 6e73 666f   in self.transfo
+00007630: 726d 735b 3a3a 2d31 5d3a 0d0a 2020 2020  rms[::-1]:..    
+00007640: 2020 2020 2020 2020 696e 7075 745f 7370          input_sp
+00007650: 6563 203d 2074 2e74 7261 6e73 666f 726d  ec = t.transform
+00007660: 5f69 6e70 7574 5f73 7065 6328 696e 7075  _input_spec(inpu
+00007670: 745f 7370 6563 290d 0a20 2020 2020 2020  t_spec)..       
+00007680: 2072 6574 7572 6e20 696e 7075 745f 7370   return input_sp
+00007690: 6563 0d0a 0d0a 2020 2020 6465 6620 7472  ec....    def tr
+000076a0: 616e 7366 6f72 6d5f 6f62 7365 7276 6174  ansform_observat
+000076b0: 696f 6e5f 7370 6563 2873 656c 662c 206f  ion_spec(self, o
+000076c0: 6273 6572 7661 7469 6f6e 5f73 7065 633a  bservation_spec:
+000076d0: 2054 656e 736f 7253 7065 6329 202d 3e20   TensorSpec) -> 
+000076e0: 5465 6e73 6f72 5370 6563 3a0d 0a20 2020  TensorSpec:..   
+000076f0: 2020 2020 2066 6f72 2074 2069 6e20 7365       for t in se
+00007700: 6c66 2e74 7261 6e73 666f 726d 733a 0d0a  lf.transforms:..
+00007710: 2020 2020 2020 2020 2020 2020 6f62 7365              obse
+00007720: 7276 6174 696f 6e5f 7370 6563 203d 2074  rvation_spec = t
+00007730: 2e74 7261 6e73 666f 726d 5f6f 6273 6572  .transform_obser
+00007740: 7661 7469 6f6e 5f73 7065 6328 6f62 7365  vation_spec(obse
+00007750: 7276 6174 696f 6e5f 7370 6563 290d 0a20  rvation_spec).. 
+00007760: 2020 2020 2020 2072 6574 7572 6e20 6f62         return ob
+00007770: 7365 7276 6174 696f 6e5f 7370 6563 0d0a  servation_spec..
+00007780: 0d0a 2020 2020 6465 6620 7472 616e 7366  ..    def transf
+00007790: 6f72 6d5f 6f75 7470 7574 5f73 7065 6328  orm_output_spec(
+000077a0: 7365 6c66 2c20 6f75 7470 7574 5f73 7065  self, output_spe
+000077b0: 633a 2054 656e 736f 7253 7065 6329 202d  c: TensorSpec) -
+000077c0: 3e20 5465 6e73 6f72 5370 6563 3a0d 0a20  > TensorSpec:.. 
+000077d0: 2020 2020 2020 2066 6f72 2074 2069 6e20         for t in 
+000077e0: 7365 6c66 2e74 7261 6e73 666f 726d 733a  self.transforms:
+000077f0: 0d0a 2020 2020 2020 2020 2020 2020 6f75  ..            ou
+00007800: 7470 7574 5f73 7065 6320 3d20 742e 7472  tput_spec = t.tr
+00007810: 616e 7366 6f72 6d5f 6f75 7470 7574 5f73  ansform_output_s
+00007820: 7065 6328 6f75 7470 7574 5f73 7065 6329  pec(output_spec)
+00007830: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
+00007840: 206f 7574 7075 745f 7370 6563 0d0a 0d0a   output_spec....
+00007850: 2020 2020 6465 6620 7472 616e 7366 6f72      def transfor
+00007860: 6d5f 7265 7761 7264 5f73 7065 6328 7365  m_reward_spec(se
+00007870: 6c66 2c20 7265 7761 7264 5f73 7065 633a  lf, reward_spec:
+00007880: 2054 656e 736f 7253 7065 6329 202d 3e20   TensorSpec) -> 
+00007890: 5465 6e73 6f72 5370 6563 3a0d 0a20 2020  TensorSpec:..   
+000078a0: 2020 2020 2066 6f72 2074 2069 6e20 7365       for t in se
+000078b0: 6c66 2e74 7261 6e73 666f 726d 733a 0d0a  lf.transforms:..
+000078c0: 2020 2020 2020 2020 2020 2020 7265 7761              rewa
+000078d0: 7264 5f73 7065 6320 3d20 742e 7472 616e  rd_spec = t.tran
+000078e0: 7366 6f72 6d5f 7265 7761 7264 5f73 7065  sform_reward_spe
+000078f0: 6328 7265 7761 7264 5f73 7065 6329 0d0a  c(reward_spec)..
+00007900: 2020 2020 2020 2020 7265 7475 726e 2072          return r
+00007910: 6577 6172 645f 7370 6563 0d0a 0d0a 2020  eward_spec....  
+00007920: 2020 6465 6620 5f5f 6765 7469 7465 6d5f    def __getitem_
+00007930: 5f28 7365 6c66 2c20 6974 656d 3a20 556e  _(self, item: Un
+00007940: 696f 6e5b 696e 742c 2073 6c69 6365 2c20  ion[int, slice, 
+00007950: 4c69 7374 5d29 202d 3e20 556e 696f 6e3a  List]) -> Union:
+00007960: 0d0a 2020 2020 2020 2020 7472 616e 7366  ..        transf
+00007970: 6f72 6d20 3d20 7365 6c66 2e74 7261 6e73  orm = self.trans
+00007980: 666f 726d 730d 0a20 2020 2020 2020 2074  forms..        t
+00007990: 7261 6e73 666f 726d 203d 2074 7261 6e73  ransform = trans
+000079a0: 666f 726d 5b69 7465 6d5d 0d0a 2020 2020  form[item]..    
+000079b0: 2020 2020 6966 206e 6f74 2069 7369 6e73      if not isins
+000079c0: 7461 6e63 6528 7472 616e 7366 6f72 6d2c  tance(transform,
+000079d0: 2054 7261 6e73 666f 726d 293a 0d0a 2020   Transform):..  
+000079e0: 2020 2020 2020 2020 2020 6f75 7420 3d20            out = 
+000079f0: 436f 6d70 6f73 6528 2a28 742e 636c 6f6e  Compose(*(t.clon
+00007a00: 6528 2920 666f 7220 7420 696e 2073 656c  e() for t in sel
+00007a10: 662e 7472 616e 7366 6f72 6d73 5b69 7465  f.transforms[ite
+00007a20: 6d5d 2929 0d0a 2020 2020 2020 2020 2020  m]))..          
+00007a30: 2020 6f75 742e 7365 745f 636f 6e74 6169    out.set_contai
+00007a40: 6e65 7228 7365 6c66 2e70 6172 656e 7429  ner(self.parent)
+00007a50: 0d0a 2020 2020 2020 2020 2020 2020 7265  ..            re
+00007a60: 7475 726e 206f 7574 0d0a 2020 2020 2020  turn out..      
+00007a70: 2020 7265 7475 726e 2074 7261 6e73 666f    return transfo
+00007a80: 726d 0d0a 0d0a 2020 2020 6465 6620 6475  rm....    def du
+00007a90: 6d70 2873 656c 662c 202a 2a6b 7761 7267  mp(self, **kwarg
+00007aa0: 7329 202d 3e20 4e6f 6e65 3a0d 0a20 2020  s) -> None:..   
+00007ab0: 2020 2020 2066 6f72 2074 2069 6e20 7365       for t in se
+00007ac0: 6c66 3a0d 0a20 2020 2020 2020 2020 2020  lf:..           
+00007ad0: 2074 2e64 756d 7028 2a2a 6b77 6172 6773   t.dump(**kwargs
+00007ae0: 290d 0a0d 0a20 2020 2064 6566 2072 6573  )....    def res
+00007af0: 6574 2873 656c 662c 2074 656e 736f 7264  et(self, tensord
+00007b00: 6963 743a 2054 656e 736f 7244 6963 7442  ict: TensorDictB
+00007b10: 6173 6529 202d 3e20 5465 6e73 6f72 4469  ase) -> TensorDi
+00007b20: 6374 4261 7365 3a0d 0a20 2020 2020 2020  ctBase:..       
+00007b30: 2066 6f72 2074 2069 6e20 7365 6c66 2e74   for t in self.t
+00007b40: 7261 6e73 666f 726d 733a 0d0a 2020 2020  ransforms:..    
+00007b50: 2020 2020 2020 2020 7465 6e73 6f72 6469          tensordi
+00007b60: 6374 203d 2074 2e72 6573 6574 2874 656e  ct = t.reset(ten
+00007b70: 736f 7264 6963 7429 0d0a 2020 2020 2020  sordict)..      
+00007b80: 2020 7265 7475 726e 2074 656e 736f 7264    return tensord
+00007b90: 6963 740d 0a0d 0a20 2020 2064 6566 2069  ict....    def i
+00007ba0: 6e69 7428 7365 6c66 2c20 7465 6e73 6f72  nit(self, tensor
+00007bb0: 6469 6374 3a20 5465 6e73 6f72 4469 6374  dict: TensorDict
+00007bc0: 4261 7365 2920 2d3e 204e 6f6e 653a 0d0a  Base) -> None:..
+00007bd0: 2020 2020 2020 2020 666f 7220 7420 696e          for t in
+00007be0: 2073 656c 662e 7472 616e 7366 6f72 6d73   self.transforms
+00007bf0: 3a0d 0a20 2020 2020 2020 2020 2020 2074  :..            t
+00007c00: 2e69 6e69 7428 7465 6e73 6f72 6469 6374  .init(tensordict
+00007c10: 290d 0a0d 0a20 2020 2064 6566 2061 7070  )....    def app
+00007c20: 656e 6428 7365 6c66 2c20 7472 616e 7366  end(self, transf
+00007c30: 6f72 6d29 3a0d 0a20 2020 2020 2020 2073  orm):..        s
+00007c40: 656c 662e 656d 7074 795f 6361 6368 6528  elf.empty_cache(
+00007c50: 290d 0a20 2020 2020 2020 2069 6620 6e6f  )..        if no
+00007c60: 7420 6973 696e 7374 616e 6365 2874 7261  t isinstance(tra
+00007c70: 6e73 666f 726d 2c20 5472 616e 7366 6f72  nsform, Transfor
+00007c80: 6d29 3a0d 0a20 2020 2020 2020 2020 2020  m):..           
+00007c90: 2072 6169 7365 2056 616c 7565 4572 726f   raise ValueErro
+00007ca0: 7228 0d0a 2020 2020 2020 2020 2020 2020  r(..            
+00007cb0: 2020 2020 2243 6f6d 706f 7365 2e61 7070      "Compose.app
+00007cc0: 656e 6420 6578 7065 6374 6564 2061 2074  end expected a t
+00007cd0: 7261 6e73 666f 726d 2062 7574 2072 6563  ransform but rec
+00007ce0: 6569 7665 6420 616e 206f 626a 6563 7420  eived an object 
+00007cf0: 6f66 2022 0d0a 2020 2020 2020 2020 2020  of "..          
+00007d00: 2020 2020 2020 6622 7479 7065 207b 7479        f"type {ty
+00007d10: 7065 2874 7261 6e73 666f 726d 297d 2069  pe(transform)} i
+00007d20: 6e73 7465 6164 2e22 0d0a 2020 2020 2020  nstead."..      
+00007d30: 2020 2020 2020 290d 0a20 2020 2020 2020        )..       
+00007d40: 2074 7261 6e73 666f 726d 2e65 7661 6c28   transform.eval(
+00007d50: 290d 0a20 2020 2020 2020 2073 656c 662e  )..        self.
+00007d60: 7472 616e 7366 6f72 6d73 2e61 7070 656e  transforms.appen
+00007d70: 6428 7472 616e 7366 6f72 6d29 0d0a 2020  d(transform)..  
+00007d80: 2020 2020 2020 7472 616e 7366 6f72 6d2e        transform.
+00007d90: 7365 745f 636f 6e74 6169 6e65 7228 7365  set_container(se
+00007da0: 6c66 290d 0a0d 0a20 2020 2064 6566 2069  lf)....    def i
+00007db0: 6e73 6572 7428 7365 6c66 2c20 696e 6465  nsert(self, inde
+00007dc0: 783a 2069 6e74 2c20 7472 616e 7366 6f72  x: int, transfor
+00007dd0: 6d3a 2054 7261 6e73 666f 726d 2920 2d3e  m: Transform) ->
+00007de0: 204e 6f6e 653a 0d0a 2020 2020 2020 2020   None:..        
+00007df0: 6966 206e 6f74 2069 7369 6e73 7461 6e63  if not isinstanc
+00007e00: 6528 7472 616e 7366 6f72 6d2c 2054 7261  e(transform, Tra
+00007e10: 6e73 666f 726d 293a 0d0a 2020 2020 2020  nsform):..      
+00007e20: 2020 2020 2020 7261 6973 6520 5661 6c75        raise Valu
+00007e30: 6545 7272 6f72 280d 0a20 2020 2020 2020  eError(..       
+00007e40: 2020 2020 2020 2020 2022 436f 6d70 6f73           "Compos
+00007e50: 652e 6170 7065 6e64 2065 7870 6563 7465  e.append expecte
+00007e60: 6420 6120 7472 616e 7366 6f72 6d20 6275  d a transform bu
+00007e70: 7420 7265 6365 6976 6564 2061 6e20 6f62  t received an ob
+00007e80: 6a65 6374 206f 6620 220d 0a20 2020 2020  ject of "..     
+00007e90: 2020 2020 2020 2020 2020 2066 2274 7970             f"typ
+00007ea0: 6520 7b74 7970 6528 7472 616e 7366 6f72  e {type(transfor
+00007eb0: 6d29 7d20 696e 7374 6561 642e 220d 0a20  m)} instead.".. 
+00007ec0: 2020 2020 2020 2020 2020 2029 0d0a 0d0a             )....
+00007ed0: 2020 2020 2020 2020 6966 2061 6273 2869          if abs(i
+00007ee0: 6e64 6578 2920 3e20 6c65 6e28 7365 6c66  ndex) > len(self
+00007ef0: 2e74 7261 6e73 666f 726d 7329 3a0d 0a20  .transforms):.. 
+00007f00: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+00007f10: 2056 616c 7565 4572 726f 7228 0d0a 2020   ValueError(..  
+00007f20: 2020 2020 2020 2020 2020 2020 2020 6622                f"
+00007f30: 496e 6465 7820 6578 7065 6374 6564 2074  Index expected t
+00007f40: 6f20 6265 2062 6574 7765 656e 205b 2d7b  o be between [-{
+00007f50: 6c65 6e28 7365 6c66 2e74 7261 6e73 666f  len(self.transfo
+00007f60: 726d 7329 7d2c 207b 6c65 6e28 7365 6c66  rms)}, {len(self
+00007f70: 2e74 7261 6e73 666f 726d 7329 7d5d 2067  .transforms)}] g
+00007f80: 6f74 2069 6e64 6578 3d7b 696e 6465 787d  ot index={index}
+00007f90: 220d 0a20 2020 2020 2020 2020 2020 2029  "..            )
+00007fa0: 0d0a 0d0a 2020 2020 2020 2020 2320 656d  ....        # em
+00007fb0: 7074 7920 6361 6368 6520 6f66 2061 6c6c  pty cache of all
+00007fc0: 2074 7261 6e73 666f 726d 7320 746f 2072   transforms to r
+00007fd0: 6573 6574 2070 6172 656e 7473 2061 6e64  eset parents and
+00007fe0: 2073 7065 6373 0d0a 2020 2020 2020 2020   specs..        
+00007ff0: 7365 6c66 2e65 6d70 7479 5f63 6163 6865  self.empty_cache
+00008000: 2829 0d0a 2020 2020 2020 2020 6966 2069  ()..        if i
+00008010: 6e64 6578 203c 2030 3a0d 0a20 2020 2020  ndex < 0:..     
+00008020: 2020 2020 2020 2069 6e64 6578 203d 2069         index = i
+00008030: 6e64 6578 202b 206c 656e 2873 656c 662e  ndex + len(self.
+00008040: 7472 616e 7366 6f72 6d73 290d 0a20 2020  transforms)..   
+00008050: 2020 2020 2074 7261 6e73 666f 726d 2e65       transform.e
+00008060: 7661 6c28 290d 0a20 2020 2020 2020 2073  val()..        s
+00008070: 656c 662e 7472 616e 7366 6f72 6d73 2e69  elf.transforms.i
+00008080: 6e73 6572 7428 696e 6465 782c 2074 7261  nsert(index, tra
+00008090: 6e73 666f 726d 290d 0a20 2020 2020 2020  nsform)..       
+000080a0: 2074 7261 6e73 666f 726d 2e73 6574 5f63   transform.set_c
+000080b0: 6f6e 7461 696e 6572 2873 656c 6629 0d0a  ontainer(self)..
+000080c0: 0d0a 2020 2020 6465 6620 746f 2873 656c  ..    def to(sel
+000080d0: 662c 2064 6573 743a 2055 6e69 6f6e 5b74  f, dest: Union[t
+000080e0: 6f72 6368 2e64 7479 7065 2c20 4445 5649  orch.dtype, DEVI
+000080f0: 4345 5f54 5950 494e 475d 2920 2d3e 2043  CE_TYPING]) -> C
+00008100: 6f6d 706f 7365 3a0d 0a20 2020 2020 2020  ompose:..       
+00008110: 2066 6f72 2074 2069 6e20 7365 6c66 2e74   for t in self.t
+00008120: 7261 6e73 666f 726d 733a 0d0a 2020 2020  ransforms:..    
+00008130: 2020 2020 2020 2020 742e 746f 2864 6573          t.to(des
+00008140: 7429 0d0a 2020 2020 2020 2020 7265 7475  t)..        retu
+00008150: 726e 2073 7570 6572 2829 2e74 6f28 6465  rn super().to(de
+00008160: 7374 290d 0a0d 0a20 2020 2064 6566 205f  st)....    def _
+00008170: 5f69 7465 725f 5f28 7365 6c66 293a 0d0a  _iter__(self):..
+00008180: 2020 2020 2020 2020 7969 656c 6420 6672          yield fr
+00008190: 6f6d 2073 656c 662e 7472 616e 7366 6f72  om self.transfor
+000081a0: 6d73 0d0a 0d0a 2020 2020 6465 6620 5f5f  ms....    def __
+000081b0: 6c65 6e5f 5f28 7365 6c66 293a 0d0a 2020  len__(self):..  
+000081c0: 2020 2020 2020 7265 7475 726e 206c 656e        return len
+000081d0: 2873 656c 662e 7472 616e 7366 6f72 6d73  (self.transforms
+000081e0: 290d 0a0d 0a20 2020 2064 6566 205f 5f72  )....    def __r
+000081f0: 6570 725f 5f28 7365 6c66 2920 2d3e 2073  epr__(self) -> s
+00008200: 7472 3a0d 0a20 2020 2020 2020 206c 6179  tr:..        lay
+00008210: 6572 735f 7374 7220 3d20 222c 5c6e 222e  ers_str = ",\n".
+00008220: 6a6f 696e 280d 0a20 2020 2020 2020 2020  join(..         
+00008230: 2020 205b 696e 6465 6e74 2873 7472 2874     [indent(str(t
+00008240: 7273 6629 2c20 3420 2a20 2220 2229 2066  rsf), 4 * " ") f
+00008250: 6f72 2074 7273 6620 696e 2073 656c 662e  or trsf in self.
+00008260: 7472 616e 7366 6f72 6d73 5d0d 0a20 2020  transforms]..   
+00008270: 2020 2020 2029 0d0a 2020 2020 2020 2020       )..        
+00008280: 7265 7475 726e 2066 227b 7365 6c66 2e5f  return f"{self._
+00008290: 5f63 6c61 7373 5f5f 2e5f 5f6e 616d 655f  _class__.__name_
+000082a0: 5f7d 285c 6e7b 696e 6465 6e74 286c 6179  _}(\n{indent(lay
+000082b0: 6572 735f 7374 722c 2034 202a 2027 2027  ers_str, 4 * ' '
+000082c0: 297d 2922 0d0a 0d0a 2020 2020 6465 6620  )})"....    def 
+000082d0: 656d 7074 795f 6361 6368 6528 7365 6c66  empty_cache(self
+000082e0: 293a 0d0a 2020 2020 2020 2020 666f 7220  ):..        for 
+000082f0: 7420 696e 2073 656c 662e 7472 616e 7366  t in self.transf
+00008300: 6f72 6d73 3a0d 0a20 2020 2020 2020 2020  orms:..         
+00008310: 2020 2074 2e65 6d70 7479 5f63 6163 6865     t.empty_cache
+00008320: 2829 0d0a 2020 2020 2020 2020 7375 7065  ()..        supe
+00008330: 7228 292e 656d 7074 795f 6361 6368 6528  r().empty_cache(
+00008340: 290d 0a0d 0a20 2020 2064 6566 2072 6573  )....    def res
+00008350: 6574 5f70 6172 656e 7428 7365 6c66 293a  et_parent(self):
+00008360: 0d0a 2020 2020 2020 2020 666f 7220 7420  ..        for t 
+00008370: 696e 2073 656c 662e 7472 616e 7366 6f72  in self.transfor
+00008380: 6d73 3a0d 0a20 2020 2020 2020 2020 2020  ms:..           
+00008390: 2074 2e72 6573 6574 5f70 6172 656e 7428   t.reset_parent(
+000083a0: 290d 0a20 2020 2020 2020 2073 7570 6572  )..        super
+000083b0: 2829 2e72 6573 6574 5f70 6172 656e 7428  ().reset_parent(
+000083c0: 290d 0a0d 0a20 2020 2064 6566 2063 6c6f  )....    def clo
+000083d0: 6e65 2873 656c 6629 3a0d 0a20 2020 2020  ne(self):..     
+000083e0: 2020 2074 7261 6e73 666f 726d 7320 3d20     transforms = 
+000083f0: 5b5d 0d0a 2020 2020 2020 2020 666f 7220  []..        for 
+00008400: 7420 696e 2073 656c 662e 7472 616e 7366  t in self.transf
+00008410: 6f72 6d73 3a0d 0a20 2020 2020 2020 2020  orms:..         
+00008420: 2020 2074 7261 6e73 666f 726d 732e 6170     transforms.ap
+00008430: 7065 6e64 2874 2e63 6c6f 6e65 2829 290d  pend(t.clone()).
+00008440: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00008450: 436f 6d70 6f73 6528 2a74 7261 6e73 666f  Compose(*transfo
+00008460: 726d 7329 0d0a 0d0a 2020 2020 6465 6620  rms)....    def 
+00008470: 7365 745f 6d69 7373 696e 675f 746f 6c65  set_missing_tole
+00008480: 7261 6e63 6528 7365 6c66 2c20 6d6f 6465  rance(self, mode
+00008490: 3d46 616c 7365 293a 0d0a 2020 2020 2020  =False):..      
+000084a0: 2020 666f 7220 7420 696e 2073 656c 662e    for t in self.
+000084b0: 7472 616e 7366 6f72 6d73 3a0d 0a20 2020  transforms:..   
+000084c0: 2020 2020 2020 2020 2074 2e73 6574 5f6d           t.set_m
+000084d0: 6973 7369 6e67 5f74 6f6c 6572 616e 6365  issing_tolerance
+000084e0: 286d 6f64 6529 0d0a 2020 2020 2020 2020  (mode)..        
+000084f0: 7375 7065 7228 292e 7365 745f 6d69 7373  super().set_miss
+00008500: 696e 675f 746f 6c65 7261 6e63 6528 6d6f  ing_tolerance(mo
+00008510: 6465 290d 0a0d 0a0d 0a63 6c61 7373 2054  de)......class T
+00008520: 6f54 656e 736f 7249 6d61 6765 284f 6273  oTensorImage(Obs
+00008530: 6572 7661 7469 6f6e 5472 616e 7366 6f72  ervationTransfor
+00008540: 6d29 3a0d 0a20 2020 2022 2222 5472 616e  m):..    """Tran
+00008550: 7366 6f72 6d73 2061 206e 756d 7079 2d6c  sforms a numpy-l
+00008560: 696b 6520 696d 6167 6520 2833 2078 2057  ike image (3 x W
+00008570: 2078 2048 2920 746f 2061 2070 7974 6f72   x H) to a pytor
+00008580: 6368 2069 6d61 6765 2028 3320 7820 5720  ch image (3 x W 
+00008590: 7820 4829 2e0d 0a0d 0a20 2020 2054 7261  x H).....    Tra
+000085a0: 6e73 666f 726d 7320 616e 206f 6273 6572  nsforms an obser
+000085b0: 7661 7469 6f6e 2069 6d61 6765 2066 726f  vation image fro
+000085c0: 6d20 6120 282e 2e2e 2078 2057 2078 2048  m a (... x W x H
+000085d0: 2078 2033 2920 302e 2e32 3535 2075 696e   x 3) 0..255 uin
+000085e0: 7438 0d0a 2020 2020 7465 6e73 6f72 2074  t8..    tensor t
+000085f0: 6f20 6120 7369 6e67 6c65 2f64 6f75 626c  o a single/doubl
+00008600: 6520 7072 6563 6973 696f 6e20 666c 6f61  e precision floa
+00008610: 7469 6e67 2070 6f69 6e74 2028 3320 7820  ting point (3 x 
+00008620: 5720 7820 4829 2074 656e 736f 720d 0a20  W x H) tensor.. 
+00008630: 2020 2077 6974 6820 7661 6c75 6573 2062     with values b
+00008640: 6574 7765 656e 2030 2061 6e64 2031 2e0d  etween 0 and 1..
+00008650: 0a0d 0a20 2020 2041 7267 733a 0d0a 2020  ...    Args:..  
+00008660: 2020 2020 2020 756e 7371 7565 657a 6520        unsqueeze 
+00008670: 2862 6f6f 6c29 3a20 6966 2060 6054 7275  (bool): if ``Tru
+00008680: 6560 602c 2074 6865 206f 6273 6572 7661  e``, the observa
+00008690: 7469 6f6e 2074 656e 736f 7220 6973 2075  tion tensor is u
+000086a0: 6e73 7175 6565 7a65 640d 0a20 2020 2020  nsqueezed..     
+000086b0: 2020 2020 2020 2061 6c6f 6e67 2074 6865         along the
+000086c0: 2066 6972 7374 2064 696d 656e 7369 6f6e   first dimension
+000086d0: 2e20 6465 6661 756c 743d 4661 6c73 652e  . default=False.
+000086e0: 0d0a 2020 2020 2020 2020 6474 7970 6520  ..        dtype 
+000086f0: 2874 6f72 6368 2e64 7479 7065 2c20 6f70  (torch.dtype, op
+00008700: 7469 6f6e 616c 293a 2064 7479 7065 2074  tional): dtype t
+00008710: 6f20 7573 6520 666f 7220 7468 6520 7265  o use for the re
+00008720: 7375 6c74 696e 670d 0a20 2020 2020 2020  sulting..       
+00008730: 2020 2020 206f 6273 6572 7661 7469 6f6e       observation
+00008740: 732e 0d0a 0d0a 2020 2020 4578 616d 706c  s.....    Exampl
+00008750: 6573 3a0d 0a20 2020 2020 2020 203e 3e3e  es:..        >>>
+00008760: 2074 7261 6e73 666f 726d 203d 2054 6f54   transform = ToT
+00008770: 656e 736f 7249 6d61 6765 2869 6e5f 6b65  ensorImage(in_ke
+00008780: 7973 3d5b 2270 6978 656c 7322 5d29 0d0a  ys=["pixels"])..
+00008790: 2020 2020 2020 2020 3e3e 3e20 7269 203d          >>> ri =
+000087a0: 2074 6f72 6368 2e72 616e 6469 6e74 2830   torch.randint(0
+000087b0: 2c20 3235 352c 2028 312c 312c 3130 2c31  , 255, (1,1,10,1
+000087c0: 312c 3329 2c20 6474 7970 653d 746f 7263  1,3), dtype=torc
+000087d0: 682e 7569 6e74 3829 0d0a 2020 2020 2020  h.uint8)..      
+000087e0: 2020 3e3e 3e20 7464 203d 2054 656e 736f    >>> td = Tenso
+000087f0: 7244 6963 7428 0d0a 2020 2020 2020 2020  rDict(..        
+00008800: 2e2e 2e20 2020 2020 7b22 7069 7865 6c73  ...     {"pixels
+00008810: 223a 2072 697d 2c0d 0a20 2020 2020 2020  ": ri},..       
+00008820: 202e 2e2e 2020 2020 205b 312c 2031 5d29   ...     [1, 1])
+00008830: 0d0a 2020 2020 2020 2020 3e3e 3e20 5f20  ..        >>> _ 
+00008840: 3d20 7472 616e 7366 6f72 6d28 7464 290d  = transform(td).
+00008850: 0a20 2020 2020 2020 203e 3e3e 206f 6273  .        >>> obs
+00008860: 203d 2074 642e 6765 7428 2270 6978 656c   = td.get("pixel
+00008870: 7322 290d 0a20 2020 2020 2020 203e 3e3e  s")..        >>>
+00008880: 2070 7269 6e74 286f 6273 2e73 6861 7065   print(obs.shape
+00008890: 2c20 6f62 732e 6474 7970 6529 0d0a 2020  , obs.dtype)..  
+000088a0: 2020 2020 2020 746f 7263 682e 5369 7a65        torch.Size
+000088b0: 285b 312c 2031 2c20 332c 2031 302c 2031  ([1, 1, 3, 10, 1
+000088c0: 315d 2920 746f 7263 682e 666c 6f61 7433  1]) torch.float3
+000088d0: 320d 0a20 2020 2022 2222 0d0a 0d0a 2020  2..    """....  
+000088e0: 2020 6465 6620 5f5f 696e 6974 5f5f 280d    def __init__(.
+000088f0: 0a20 2020 2020 2020 2073 656c 662c 0d0a  .        self,..
+00008900: 2020 2020 2020 2020 756e 7371 7565 657a          unsqueez
+00008910: 653a 2062 6f6f 6c20 3d20 4661 6c73 652c  e: bool = False,
+00008920: 0d0a 2020 2020 2020 2020 6474 7970 653a  ..        dtype:
+00008930: 204f 7074 696f 6e61 6c5b 746f 7263 682e   Optional[torch.
+00008940: 6465 7669 6365 5d20 3d20 4e6f 6e65 2c0d  device] = None,.
+00008950: 0a20 2020 2020 2020 2069 6e5f 6b65 7973  .        in_keys
+00008960: 3a20 4f70 7469 6f6e 616c 5b53 6571 7565  : Optional[Seque
+00008970: 6e63 655b 7374 725d 5d20 3d20 4e6f 6e65  nce[str]] = None
+00008980: 2c0d 0a20 2020 2020 2020 206f 7574 5f6b  ,..        out_k
+00008990: 6579 733a 204f 7074 696f 6e61 6c5b 5365  eys: Optional[Se
+000089a0: 7175 656e 6365 5b73 7472 5d5d 203d 204e  quence[str]] = N
+000089b0: 6f6e 652c 0d0a 2020 2020 293a 0d0a 2020  one,..    ):..  
+000089c0: 2020 2020 2020 6966 2069 6e5f 6b65 7973        if in_keys
+000089d0: 2069 7320 4e6f 6e65 3a0d 0a20 2020 2020   is None:..     
+000089e0: 2020 2020 2020 2069 6e5f 6b65 7973 203d         in_keys =
+000089f0: 2049 4d41 4745 5f4b 4559 5320 2023 2064   IMAGE_KEYS  # d
+00008a00: 6566 6175 6c74 0d0a 2020 2020 2020 2020  efault..        
+00008a10: 7375 7065 7228 292e 5f5f 696e 6974 5f5f  super().__init__
+00008a20: 2869 6e5f 6b65 7973 3d69 6e5f 6b65 7973  (in_keys=in_keys
+00008a30: 2c20 6f75 745f 6b65 7973 3d6f 7574 5f6b  , out_keys=out_k
+00008a40: 6579 7329 0d0a 2020 2020 2020 2020 7365  eys)..        se
+00008a50: 6c66 2e75 6e73 7175 6565 7a65 203d 2075  lf.unsqueeze = u
+00008a60: 6e73 7175 6565 7a65 0d0a 2020 2020 2020  nsqueeze..      
+00008a70: 2020 7365 6c66 2e64 7479 7065 203d 2064    self.dtype = d
+00008a80: 7479 7065 2069 6620 6474 7970 6520 6973  type if dtype is
+00008a90: 206e 6f74 204e 6f6e 6520 656c 7365 2074   not None else t
+00008aa0: 6f72 6368 2e67 6574 5f64 6566 6175 6c74  orch.get_default
+00008ab0: 5f64 7479 7065 2829 0d0a 0d0a 2020 2020  _dtype()....    
+00008ac0: 6465 6620 5f61 7070 6c79 5f74 7261 6e73  def _apply_trans
+00008ad0: 666f 726d 2873 656c 662c 206f 6273 6572  form(self, obser
+00008ae0: 7661 7469 6f6e 3a20 746f 7263 682e 466c  vation: torch.Fl
+00008af0: 6f61 7454 656e 736f 7229 202d 3e20 746f  oatTensor) -> to
+00008b00: 7263 682e 5465 6e73 6f72 3a0d 0a20 2020  rch.Tensor:..   
+00008b10: 2020 2020 206f 6273 6572 7661 7469 6f6e       observation
+00008b20: 203d 206f 6273 6572 7661 7469 6f6e 2e70   = observation.p
+00008b30: 6572 6d75 7465 280d 0a20 2020 2020 2020  ermute(..       
+00008b40: 2020 2020 202a 6c69 7374 2872 616e 6765       *list(range
+00008b50: 286f 6273 6572 7661 7469 6f6e 2e6e 6469  (observation.ndi
+00008b60: 6d65 6e73 696f 6e28 2920 2d20 3329 292c  mension() - 3)),
+00008b70: 202d 312c 202d 332c 202d 320d 0a20 2020   -1, -3, -2..   
+00008b80: 2020 2020 2029 0d0a 2020 2020 2020 2020       )..        
+00008b90: 6f62 7365 7276 6174 696f 6e20 3d20 6f62  observation = ob
+00008ba0: 7365 7276 6174 696f 6e2e 6469 7628 3235  servation.div(25
+00008bb0: 3529 2e74 6f28 7365 6c66 2e64 7479 7065  5).to(self.dtype
+00008bc0: 290d 0a20 2020 2020 2020 2069 6620 6f62  )..        if ob
+00008bd0: 7365 7276 6174 696f 6e2e 6e64 696d 656e  servation.ndimen
+00008be0: 7369 6f6e 2829 203d 3d20 3320 616e 6420  sion() == 3 and 
+00008bf0: 7365 6c66 2e75 6e73 7175 6565 7a65 3a0d  self.unsqueeze:.
+00008c00: 0a20 2020 2020 2020 2020 2020 206f 6273  .            obs
+00008c10: 6572 7661 7469 6f6e 203d 206f 6273 6572  ervation = obser
+00008c20: 7661 7469 6f6e 2e75 6e73 7175 6565 7a65  vation.unsqueeze
+00008c30: 2830 290d 0a20 2020 2020 2020 2072 6574  (0)..        ret
+00008c40: 7572 6e20 6f62 7365 7276 6174 696f 6e0d  urn observation.
+00008c50: 0a0d 0a20 2020 2040 5f61 7070 6c79 5f74  ...    @_apply_t
+00008c60: 6f5f 636f 6d70 6f73 6974 650d 0a20 2020  o_composite..   
+00008c70: 2064 6566 2074 7261 6e73 666f 726d 5f6f   def transform_o
+00008c80: 6273 6572 7661 7469 6f6e 5f73 7065 6328  bservation_spec(
+00008c90: 7365 6c66 2c20 6f62 7365 7276 6174 696f  self, observatio
+00008ca0: 6e5f 7370 6563 3a20 5465 6e73 6f72 5370  n_spec: TensorSp
+00008cb0: 6563 2920 2d3e 2054 656e 736f 7253 7065  ec) -> TensorSpe
+00008cc0: 633a 0d0a 2020 2020 2020 2020 6f62 7365  c:..        obse
+00008cd0: 7276 6174 696f 6e5f 7370 6563 203d 2073  rvation_spec = s
+00008ce0: 656c 662e 5f70 6978 656c 5f6f 6273 6572  elf._pixel_obser
+00008cf0: 7661 7469 6f6e 286f 6273 6572 7661 7469  vation(observati
+00008d00: 6f6e 5f73 7065 6329 0d0a 2020 2020 2020  on_spec)..      
+00008d10: 2020 6f62 7365 7276 6174 696f 6e5f 7370    observation_sp
+00008d20: 6563 2e73 6861 7065 203d 2074 6f72 6368  ec.shape = torch
+00008d30: 2e53 697a 6528 0d0a 2020 2020 2020 2020  .Size(..        
+00008d40: 2020 2020 5b0d 0a20 2020 2020 2020 2020      [..         
+00008d50: 2020 2020 2020 202a 6f62 7365 7276 6174         *observat
+00008d60: 696f 6e5f 7370 6563 2e73 6861 7065 5b3a  ion_spec.shape[:
+00008d70: 2d33 5d2c 0d0a 2020 2020 2020 2020 2020  -3],..          
+00008d80: 2020 2020 2020 6f62 7365 7276 6174 696f        observatio
+00008d90: 6e5f 7370 6563 2e73 6861 7065 5b2d 315d  n_spec.shape[-1]
+00008da0: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
+00008db0: 2020 206f 6273 6572 7661 7469 6f6e 5f73     observation_s
+00008dc0: 7065 632e 7368 6170 655b 2d33 5d2c 0d0a  pec.shape[-3],..
+00008dd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00008de0: 6f62 7365 7276 6174 696f 6e5f 7370 6563  observation_spec
+00008df0: 2e73 6861 7065 5b2d 325d 2c0d 0a20 2020  .shape[-2],..   
+00008e00: 2020 2020 2020 2020 205d 0d0a 2020 2020           ]..    
+00008e10: 2020 2020 290d 0a20 2020 2020 2020 206f      )..        o
+00008e20: 6273 6572 7661 7469 6f6e 5f73 7065 632e  bservation_spec.
+00008e30: 6474 7970 6520 3d20 7365 6c66 2e64 7479  dtype = self.dty
+00008e40: 7065 0d0a 2020 2020 2020 2020 7265 7475  pe..        retu
+00008e50: 726e 206f 6273 6572 7661 7469 6f6e 5f73  rn observation_s
+00008e60: 7065 630d 0a0d 0a20 2020 2064 6566 205f  pec....    def _
+00008e70: 7069 7865 6c5f 6f62 7365 7276 6174 696f  pixel_observatio
+00008e80: 6e28 7365 6c66 2c20 7370 6563 3a20 5465  n(self, spec: Te
+00008e90: 6e73 6f72 5370 6563 2920 2d3e 204e 6f6e  nsorSpec) -> Non
+00008ea0: 653a 0d0a 2020 2020 2020 2020 6966 2069  e:..        if i
+00008eb0: 7369 6e73 7461 6e63 6528 7370 6563 2e73  sinstance(spec.s
+00008ec0: 7061 6365 2c20 436f 6e74 696e 756f 7573  pace, Continuous
+00008ed0: 426f 7829 3a0d 0a20 2020 2020 2020 2020  Box):..         
+00008ee0: 2020 2073 7065 632e 7370 6163 652e 6d61     spec.space.ma
+00008ef0: 7869 6d75 6d20 3d20 7365 6c66 2e5f 6170  ximum = self._ap
+00008f00: 706c 795f 7472 616e 7366 6f72 6d28 7370  ply_transform(sp
+00008f10: 6563 2e73 7061 6365 2e6d 6178 696d 756d  ec.space.maximum
+00008f20: 290d 0a20 2020 2020 2020 2020 2020 2073  )..            s
+00008f30: 7065 632e 7370 6163 652e 6d69 6e69 6d75  pec.space.minimu
+00008f40: 6d20 3d20 7365 6c66 2e5f 6170 706c 795f  m = self._apply_
+00008f50: 7472 616e 7366 6f72 6d28 7370 6563 2e73  transform(spec.s
+00008f60: 7061 6365 2e6d 696e 696d 756d 290d 0a20  pace.minimum).. 
+00008f70: 2020 2020 2020 2072 6574 7572 6e20 7370         return sp
+00008f80: 6563 0d0a 0d0a 0d0a 636c 6173 7320 5461  ec......class Ta
+00008f90: 7267 6574 5265 7475 726e 2854 7261 6e73  rgetReturn(Trans
+00008fa0: 666f 726d 293a 0d0a 2020 2020 2222 2253  form):..    """S
+00008fb0: 6574 7320 6120 7461 7267 6574 2072 6574  ets a target ret
+00008fc0: 7572 6e20 666f 7220 7468 6520 6167 656e  urn for the agen
+00008fd0: 7420 746f 2061 6368 6965 7665 2069 6e20  t to achieve in 
+00008fe0: 7468 6520 656e 7669 726f 6e6d 656e 742e  the environment.
+00008ff0: 0d0a 0d0a 2020 2020 496e 2067 6f61 6c2d  ....    In goal-
+00009000: 636f 6e64 6974 696f 6e65 6420 524c 2c20  conditioned RL, 
+00009010: 7468 6520 3a63 6c61 7373 3a60 7e2e 5461  the :class:`~.Ta
+00009020: 7267 6574 5265 7475 726e 6020 6973 2064  rgetReturn` is d
+00009030: 6566 696e 6564 2061 7320 7468 650d 0a20  efined as the.. 
+00009040: 2020 2065 7870 6563 7465 6420 6375 6d75     expected cumu
+00009050: 6c61 7469 7665 2072 6577 6172 6420 6f62  lative reward ob
+00009060: 7461 696e 6564 2066 726f 6d20 7468 6520  tained from the 
+00009070: 6375 7272 656e 7420 7374 6174 6520 746f  current state to
+00009080: 2074 6865 2067 6f61 6c20 7374 6174 650d   the goal state.
+00009090: 0a20 2020 206f 7220 7468 6520 656e 6420  .    or the end 
+000090a0: 6f66 2074 6865 2065 7069 736f 6465 2e20  of the episode. 
+000090b0: 4974 2069 7320 7573 6564 2061 7320 696e  It is used as in
+000090c0: 7075 7420 666f 7220 7468 6520 706f 6c69  put for the poli
+000090d0: 6379 2074 6f20 6775 6964 6520 6974 7320  cy to guide its 
+000090e0: 6265 6861 7669 6f75 722e 0d0a 2020 2020  behaviour...    
+000090f0: 466f 7220 6120 7472 6169 6e65 6420 706f  For a trained po
+00009100: 6c69 6379 2074 7970 6963 616c 6c79 2074  licy typically t
+00009110: 6865 206d 6178 696d 756d 2072 6574 7572  he maximum retur
+00009120: 6e20 696e 2074 6865 2065 6e76 6972 6f6e  n in the environ
+00009130: 6d65 6e74 2069 730d 0a20 2020 2063 686f  ment is..    cho
+00009140: 7365 6e20 6173 2074 6865 2074 6172 6765  sen as the targe
+00009150: 7420 7265 7475 726e 2e0d 0a20 2020 2048  t return...    H
+00009160: 6f77 6576 6572 2c20 6173 2069 7420 6973  owever, as it is
+00009170: 2075 7365 6420 6173 2069 6e70 7574 2074   used as input t
+00009180: 6f20 7468 6520 706f 6c69 6379 206d 6f64  o the policy mod
+00009190: 756c 652c 2069 7420 7368 6f75 6c64 2062  ule, it should b
+000091a0: 6520 7363 616c 6564 0d0a 2020 2020 6163  e scaled..    ac
+000091b0: 636f 7264 696e 676c 792e 0d0a 2020 2020  cordingly...    
+000091c0: 5769 7468 2074 6865 203a 636c 6173 733a  With the :class:
+000091d0: 607e 2e54 6172 6765 7452 6574 7572 6e60  `~.TargetReturn`
+000091e0: 2074 7261 6e73 666f 726d 2c20 7468 6520   transform, the 
+000091f0: 7465 6e73 6f72 6469 6374 2063 616e 2062  tensordict can b
+00009200: 6520 7570 6461 7465 640d 0a20 2020 2074  e updated..    t
+00009210: 6f20 696e 636c 7564 6520 7468 650d 0a20  o include the.. 
+00009220: 2020 2075 7365 722d 7370 6563 6966 6965     user-specifie
+00009230: 6420 7461 7267 6574 2072 6574 7572 6e2e  d target return.
+00009240: 2054 6865 206d 6f64 6520 7061 7261 6d65   The mode parame
+00009250: 7465 7220 6361 6e20 6265 2075 7365 6420  ter can be used 
+00009260: 746f 2073 7065 6369 6679 0d0a 2020 2020  to specify..    
+00009270: 7768 6574 6865 7220 7468 6520 7461 7267  whether the targ
+00009280: 6574 2072 6574 7572 6e20 6765 7473 2075  et return gets u
+00009290: 7064 6174 6564 2061 7420 6576 6572 7920  pdated at every 
+000092a0: 7374 6570 2062 7920 7375 6274 7261 6374  step by subtract
+000092b0: 696e 6720 7468 650d 0a20 2020 2072 6577  ing the..    rew
+000092c0: 6172 6420 6163 6869 6576 6564 2061 7420  ard achieved at 
+000092d0: 6561 6368 2073 7465 7020 6f72 2072 656d  each step or rem
+000092e0: 6169 6e73 2063 6f6e 7374 616e 742e 0d0a  ains constant...
+000092f0: 2020 2020 3a63 6c61 7373 3a60 7e2e 5461      :class:`~.Ta
+00009300: 7267 6574 5265 7475 726e 6020 7368 6f75  rgetReturn` shou
+00009310: 6c64 2062 6520 6f6e 6c79 2075 7365 6420  ld be only used 
+00009320: 6475 7269 6e67 2069 6e66 6572 656e 6365  during inference
+00009330: 2077 6865 6e0d 0a20 2020 2069 6e74 6572   when..    inter
+00009340: 6163 7469 6e67 2077 6974 6820 7468 6520  acting with the 
+00009350: 656e 7669 726f 6e6d 656e 7420 6173 2074  environment as t
+00009360: 6865 2061 6374 7561 6c0d 0a20 2020 2072  he actual..    r
+00009370: 6574 7572 6e20 7265 6365 6976 6564 2062  eturn received b
+00009380: 7920 7468 6520 656e 7669 726f 6e6d 656e  y the environmen
+00009390: 7420 6d69 6768 7420 6265 2064 6966 6665  t might be diffe
+000093a0: 7265 6e74 2066 726f 6d20 7468 6520 7461  rent from the ta
+000093b0: 7267 6574 0d0a 2020 2020 7265 7475 726e  rget..    return
+000093c0: 2e20 5468 6572 6566 6f72 652c 2074 6f20  . Therefore, to 
+000093d0: 6861 7665 2074 6865 2063 6f72 7265 6374  have the correct
+000093e0: 0d0a 2020 2020 7265 7475 726e 206c 6162  ..    return lab
+000093f0: 656c 7320 666f 7220 7472 6169 6e69 6e67  els for training
+00009400: 2074 6865 2070 6f6c 6963 792c 2074 6865   the policy, the
+00009410: 203a 636c 6173 733a 607e 2e54 6172 6765   :class:`~.Targe
+00009420: 7452 6574 7572 6e60 0d0a 2020 2020 7472  tReturn`..    tr
+00009430: 616e 7366 6f72 6d20 7368 6f75 6c64 2062  ansform should b
+00009440: 6520 7573 6564 2069 6e20 636f 6e6a 756e  e used in conjun
+00009450: 6374 696f 6e20 7769 7468 0d0a 2020 2020  ction with..    
+00009460: 666f 7220 6578 616d 706c 6520 6869 6e64  for example hind
+00009470: 7369 6768 7420 7265 7475 726e 2072 656c  sight return rel
+00009480: 6162 656c 696e 6720 6c69 6b65 2074 6865  abeling like the
+00009490: 0d0a 2020 2020 3a63 6c61 7373 3a60 7e2e  ..    :class:`~.
+000094a0: 5265 7761 7264 3247 6f54 7261 6e73 666f  Reward2GoTransfo
+000094b0: 726d 6020 746f 2075 7064 6174 6520 7468  rm` to update th
+000094c0: 6520 7265 7475 726e 206c 6162 656c 2066  e return label f
+000094d0: 6f72 2074 6865 0d0a 2020 2020 6163 7475  or the..    actu
+000094e0: 616c 6c79 2061 6368 6965 7665 6420 7265  ally achieved re
+000094f0: 7475 726e 2e0d 0a0d 0a20 2020 2041 7267  turn.....    Arg
+00009500: 733a 0d0a 2020 2020 2020 2020 7461 7267  s:..        targ
+00009510: 6574 5f72 6574 7572 6e20 2866 6c6f 6174  et_return (float
+00009520: 293a 2074 6172 6765 7420 7265 7475 726e  ): target return
+00009530: 2074 6f20 6265 2061 6368 6965 7665 6420   to be achieved 
+00009540: 6279 2074 6865 2061 6765 6e74 2e0d 0a20  by the agent... 
+00009550: 2020 2020 2020 206d 6f64 6520 2873 7472         mode (str
+00009560: 293a 206d 6f64 6520 746f 2062 6520 7573  ): mode to be us
+00009570: 6564 2074 6f20 7570 6461 7465 2074 6865  ed to update the
+00009580: 2074 6172 6765 7420 7265 7475 726e 2e20   target return. 
+00009590: 4361 6e20 6265 2065 6974 6865 7220 2272  Can be either "r
+000095a0: 6564 7563 6522 206f 7220 2263 6f6e 7374  educe" or "const
+000095b0: 616e 7422 2e20 4465 6661 756c 743a 2022  ant". Default: "
+000095c0: 7265 6475 6365 222e 0d0a 0d0a 2020 2020  reduce".....    
+000095d0: 4578 616d 706c 6573 3a0d 0a20 2020 2020  Examples:..     
+000095e0: 2020 203e 3e3e 2074 7261 6e73 666f 726d     >>> transform
+000095f0: 203d 2054 6172 6765 7452 6574 7572 6e28   = TargetReturn(
+00009600: 3130 2e30 2c20 6d6f 6465 3d22 7265 6475  10.0, mode="redu
+00009610: 6365 2229 0d0a 2020 2020 2020 2020 3e3e  ce")..        >>
+00009620: 3e20 7464 203d 2054 656e 736f 7244 6963  > td = TensorDic
+00009630: 7428 7b7d 2c20 5b31 305d 290d 0a20 2020  t({}, [10])..   
+00009640: 2020 2020 203e 3e3e 2074 6420 3d20 7472       >>> td = tr
+00009650: 616e 7366 6f72 6d2e 7265 7365 7428 7464  ansform.reset(td
+00009660: 290d 0a20 2020 2020 2020 203e 3e3e 2074  )..        >>> t
+00009670: 645b 2274 6172 6765 745f 7265 7475 726e  d["target_return
+00009680: 225d 0d0a 2020 2020 2020 2020 7465 6e73  "]..        tens
+00009690: 6f72 285b 5b31 302e 5d2c 0d0a 2020 2020  or([[10.],..    
+000096a0: 2020 2020 2020 2020 2020 2020 5b31 302e              [10.
+000096b0: 5d2c 0d0a 2020 2020 2020 2020 2020 2020  ],..            
+000096c0: 2020 2020 5b31 302e 5d2c 0d0a 2020 2020      [10.],..    
+000096d0: 2020 2020 2020 2020 2020 2020 5b31 302e              [10.
+000096e0: 5d2c 0d0a 2020 2020 2020 2020 2020 2020  ],..            
+000096f0: 2020 2020 5b31 302e 5d2c 0d0a 2020 2020      [10.],..    
+00009700: 2020 2020 2020 2020 2020 2020 5b31 302e              [10.
+00009710: 5d2c 0d0a 2020 2020 2020 2020 2020 2020  ],..            
+00009720: 2020 2020 5b31 302e 5d2c 0d0a 2020 2020      [10.],..    
+00009730: 2020 2020 2020 2020 2020 2020 5b31 302e              [10.
+00009740: 5d2c 0d0a 2020 2020 2020 2020 2020 2020  ],..            
+00009750: 2020 2020 5b31 302e 5d2c 0d0a 2020 2020      [10.],..    
+00009760: 2020 2020 2020 2020 2020 2020 5b31 302e              [10.
+00009770: 5d5d 290d 0a20 2020 2020 2020 203e 3e3e  ]])..        >>>
+00009780: 2023 2074 616b 6520 6120 7374 6570 2077   # take a step w
+00009790: 6974 6820 6d6f 6465 2022 7265 6475 6365  ith mode "reduce
+000097a0: 220d 0a20 2020 2020 2020 203e 3e3e 2023  "..        >>> #
+000097b0: 2074 6172 6765 7420 7265 7475 726e 2069   target return i
+000097c0: 7320 7570 6461 7465 6420 6279 2073 7562  s updated by sub
+000097d0: 7472 6163 7469 6e67 2074 6865 2072 6577  tracting the rew
+000097e0: 6172 640d 0a20 2020 2020 2020 203e 3e3e  ard..        >>>
+000097f0: 2072 6577 6172 6420 3d20 746f 7263 682e   reward = torch.
+00009800: 6f6e 6573 2828 3130 2c31 2929 0d0a 2020  ones((10,1))..  
+00009810: 2020 2020 2020 3e3e 3e20 7464 2e73 6574        >>> td.set
+00009820: 2828 226e 6578 7422 2c20 2272 6577 6172  (("next", "rewar
+00009830: 6422 292c 2072 6577 6172 6429 0d0a 2020  d"), reward)..  
+00009840: 2020 2020 2020 3e3e 3e20 7464 203d 2074        >>> td = t
+00009850: 7261 6e73 666f 726d 2e5f 7374 6570 2874  ransform._step(t
+00009860: 6429 0d0a 2020 2020 2020 2020 3e3e 3e20  d)..        >>> 
+00009870: 7464 5b22 6e65 7874 222c 2022 7461 7267  td["next", "targ
+00009880: 6574 5f72 6574 7572 6e22 5d0d 0a20 2020  et_return"]..   
+00009890: 2020 2020 2074 656e 736f 7228 5b5b 392e       tensor([[9.
+000098a0: 5d2c 0d0a 2020 2020 2020 2020 2020 2020  ],..            
+000098b0: 2020 2020 5b39 2e5d 2c0d 0a20 2020 2020      [9.],..     
+000098c0: 2020 2020 2020 2020 2020 205b 392e 5d2c             [9.],
+000098d0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+000098e0: 2020 5b39 2e5d 2c0d 0a20 2020 2020 2020    [9.],..       
+000098f0: 2020 2020 2020 2020 205b 392e 5d2c 0d0a           [9.],..
+00009900: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00009910: 5b39 2e5d 2c0d 0a20 2020 2020 2020 2020  [9.],..         
+00009920: 2020 2020 2020 205b 392e 5d2c 0d0a 2020         [9.],..  
+00009930: 2020 2020 2020 2020 2020 2020 2020 5b39                [9
+00009940: 2e5d 2c0d 0a20 2020 2020 2020 2020 2020  .],..           
+00009950: 2020 2020 205b 392e 5d2c 0d0a 2020 2020       [9.],..    
+00009960: 2020 2020 2020 2020 2020 2020 5b39 2e5d              [9.]
+00009970: 5d29 0d0a 0d0a 2020 2020 2222 220d 0a0d  ])....    """...
+00009980: 0a20 2020 204d 4f44 4553 203d 205b 2272  .    MODES = ["r
+00009990: 6564 7563 6522 2c20 2263 6f6e 7374 616e  educe", "constan
+000099a0: 7422 5d0d 0a20 2020 204d 4f44 455f 4552  t"]..    MODE_ER
+000099b0: 5220 3d20 224d 6f64 6520 6361 6e20 6f6e  R = "Mode can on
+000099c0: 6c79 2062 6520 2772 6564 7563 6527 206f  ly be 'reduce' o
+000099d0: 7220 2763 6f6e 7374 616e 7427 2e22 0d0a  r 'constant'."..
+000099e0: 0d0a 2020 2020 6465 6620 5f5f 696e 6974  ..    def __init
+000099f0: 5f5f 280d 0a20 2020 2020 2020 2073 656c  __(..        sel
+00009a00: 662c 0d0a 2020 2020 2020 2020 7461 7267  f,..        targ
+00009a10: 6574 5f72 6574 7572 6e3a 2066 6c6f 6174  et_return: float
+00009a20: 2c0d 0a20 2020 2020 2020 206d 6f64 653a  ,..        mode:
+00009a30: 2073 7472 203d 2022 7265 6475 6365 222c   str = "reduce",
+00009a40: 0d0a 2020 2020 2020 2020 696e 5f6b 6579  ..        in_key
+00009a50: 733a 204f 7074 696f 6e61 6c5b 5365 7175  s: Optional[Sequ
+00009a60: 656e 6365 5b73 7472 5d5d 203d 204e 6f6e  ence[str]] = Non
+00009a70: 652c 0d0a 2020 2020 2020 2020 6f75 745f  e,..        out_
+00009a80: 6b65 7973 3a20 4f70 7469 6f6e 616c 5b53  keys: Optional[S
+00009a90: 6571 7565 6e63 655b 7374 725d 5d20 3d20  equence[str]] = 
+00009aa0: 4e6f 6e65 2c0d 0a20 2020 2029 3a0d 0a20  None,..    ):.. 
+00009ab0: 2020 2020 2020 2069 6620 696e 5f6b 6579         if in_key
+00009ac0: 7320 6973 204e 6f6e 653a 0d0a 2020 2020  s is None:..    
+00009ad0: 2020 2020 2020 2020 696e 5f6b 6579 7320          in_keys 
+00009ae0: 3d20 5b22 7265 7761 7264 225d 0d0a 2020  = ["reward"]..  
+00009af0: 2020 2020 2020 6966 206f 7574 5f6b 6579        if out_key
+00009b00: 7320 6973 204e 6f6e 653a 0d0a 2020 2020  s is None:..    
+00009b10: 2020 2020 2020 2020 6f75 745f 6b65 7973          out_keys
+00009b20: 203d 205b 2274 6172 6765 745f 7265 7475   = ["target_retu
+00009b30: 726e 225d 0d0a 2020 2020 2020 2020 6966  rn"]..        if
+00009b40: 206d 6f64 6520 6e6f 7420 696e 2073 656c   mode not in sel
+00009b50: 662e 4d4f 4445 533a 0d0a 2020 2020 2020  f.MODES:..      
+00009b60: 2020 2020 2020 7261 6973 6520 5661 6c75        raise Valu
+00009b70: 6545 7272 6f72 2873 656c 662e 4d4f 4445  eError(self.MODE
+00009b80: 5f45 5252 290d 0a0d 0a20 2020 2020 2020  _ERR)....       
+00009b90: 2073 7570 6572 2829 2e5f 5f69 6e69 745f   super().__init_
+00009ba0: 5f28 696e 5f6b 6579 733d 696e 5f6b 6579  _(in_keys=in_key
+00009bb0: 732c 206f 7574 5f6b 6579 733d 6f75 745f  s, out_keys=out_
+00009bc0: 6b65 7973 290d 0a20 2020 2020 2020 2073  keys)..        s
+00009bd0: 656c 662e 7461 7267 6574 5f72 6574 7572  elf.target_retur
+00009be0: 6e20 3d20 7461 7267 6574 5f72 6574 7572  n = target_retur
+00009bf0: 6e0d 0a20 2020 2020 2020 2073 656c 662e  n..        self.
+00009c00: 6d6f 6465 203d 206d 6f64 650d 0a0d 0a20  mode = mode.... 
+00009c10: 2020 2064 6566 2072 6573 6574 2873 656c     def reset(sel
+00009c20: 662c 2074 656e 736f 7264 6963 743a 2054  f, tensordict: T
+00009c30: 656e 736f 7244 6963 7429 3a0d 0a20 2020  ensorDict):..   
+00009c40: 2020 2020 2069 6e69 745f 7461 7267 6574       init_target
+00009c50: 5f72 6574 7572 6e20 3d20 746f 7263 682e  _return = torch.
+00009c60: 6675 6c6c 280d 0a20 2020 2020 2020 2020  full(..         
+00009c70: 2020 2073 697a 653d 282a 7465 6e73 6f72     size=(*tensor
+00009c80: 6469 6374 2e62 6174 6368 5f73 697a 652c  dict.batch_size,
+00009c90: 2031 292c 0d0a 2020 2020 2020 2020 2020   1),..          
+00009ca0: 2020 6669 6c6c 5f76 616c 7565 3d73 656c    fill_value=sel
+00009cb0: 662e 7461 7267 6574 5f72 6574 7572 6e2c  f.target_return,
+00009cc0: 0d0a 2020 2020 2020 2020 2020 2020 6474  ..            dt
+00009cd0: 7970 653d 746f 7263 682e 666c 6f61 7433  ype=torch.float3
+00009ce0: 322c 0d0a 2020 2020 2020 2020 2020 2020  2,..            
+00009cf0: 6465 7669 6365 3d74 656e 736f 7264 6963  device=tensordic
+00009d00: 742e 6465 7669 6365 2c0d 0a20 2020 2020  t.device,..     
+00009d10: 2020 2029 0d0a 0d0a 2020 2020 2020 2020     )....        
+00009d20: 666f 7220 6f75 745f 6b65 7920 696e 2073  for out_key in s
+00009d30: 656c 662e 6f75 745f 6b65 7973 3a0d 0a20  elf.out_keys:.. 
+00009d40: 2020 2020 2020 2020 2020 2074 6172 6765             targe
+00009d50: 745f 7265 7475 726e 203d 2074 656e 736f  t_return = tenso
+00009d60: 7264 6963 742e 6765 7428 6f75 745f 6b65  rdict.get(out_ke
+00009d70: 792c 2064 6566 6175 6c74 3d4e 6f6e 6529  y, default=None)
+00009d80: 0d0a 0d0a 2020 2020 2020 2020 2020 2020  ....            
+00009d90: 6966 2074 6172 6765 745f 7265 7475 726e  if target_return
+00009da0: 2069 7320 4e6f 6e65 3a0d 0a20 2020 2020   is None:..     
+00009db0: 2020 2020 2020 2020 2020 2074 6172 6765             targe
+00009dc0: 745f 7265 7475 726e 203d 2069 6e69 745f  t_return = init_
+00009dd0: 7461 7267 6574 5f72 6574 7572 6e0d 0a0d  target_return...
+00009de0: 0a20 2020 2020 2020 2020 2020 2074 656e  .            ten
+00009df0: 736f 7264 6963 742e 7365 7428 0d0a 2020  sordict.set(..  
+00009e00: 2020 2020 2020 2020 2020 2020 2020 6f75                ou
+00009e10: 745f 6b65 792c 0d0a 2020 2020 2020 2020  t_key,..        
+00009e20: 2020 2020 2020 2020 7461 7267 6574 5f72          target_r
+00009e30: 6574 7572 6e2c 0d0a 2020 2020 2020 2020  eturn,..        
+00009e40: 2020 2020 290d 0a20 2020 2020 2020 2072      )..        r
+00009e50: 6574 7572 6e20 7465 6e73 6f72 6469 6374  eturn tensordict
+00009e60: 0d0a 0d0a 2020 2020 6465 6620 5f63 616c  ....    def _cal
+00009e70: 6c28 7365 6c66 2c20 7465 6e73 6f72 6469  l(self, tensordi
+00009e80: 6374 3a20 5465 6e73 6f72 4469 6374 2920  ct: TensorDict) 
+00009e90: 2d3e 2054 656e 736f 7244 6963 743a 0d0a  -> TensorDict:..
+00009ea0: 2020 2020 2020 2020 666f 7220 696e 5f6b          for in_k
+00009eb0: 6579 2c20 6f75 745f 6b65 7920 696e 207a  ey, out_key in z
+00009ec0: 6970 2873 656c 662e 696e 5f6b 6579 732c  ip(self.in_keys,
+00009ed0: 2073 656c 662e 6f75 745f 6b65 7973 293a   self.out_keys):
+00009ee0: 0d0a 2020 2020 2020 2020 2020 2020 6966  ..            if
+00009ef0: 2069 6e5f 6b65 7920 696e 2074 656e 736f   in_key in tenso
+00009f00: 7264 6963 742e 6b65 7973 2869 6e63 6c75  rdict.keys(inclu
+00009f10: 6465 5f6e 6573 7465 643d 5472 7565 293a  de_nested=True):
+00009f20: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00009f30: 2020 7461 7267 6574 5f72 6574 7572 6e20    target_return 
+00009f40: 3d20 7365 6c66 2e5f 6170 706c 795f 7472  = self._apply_tr
+00009f50: 616e 7366 6f72 6d28 0d0a 2020 2020 2020  ansform(..      
+00009f60: 2020 2020 2020 2020 2020 2020 2020 7465                te
+00009f70: 6e73 6f72 6469 6374 2e67 6574 2869 6e5f  nsordict.get(in_
+00009f80: 6b65 7929 2c20 7465 6e73 6f72 6469 6374  key), tensordict
+00009f90: 2e67 6574 286f 7574 5f6b 6579 290d 0a20  .get(out_key).. 
+00009fa0: 2020 2020 2020 2020 2020 2020 2020 2029                 )
+00009fb0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00009fc0: 2020 7465 6e73 6f72 6469 6374 2e73 6574    tensordict.set
+00009fd0: 286f 7574 5f6b 6579 2c20 7461 7267 6574  (out_key, target
+00009fe0: 5f72 6574 7572 6e29 0d0a 2020 2020 2020  _return)..      
+00009ff0: 2020 2020 2020 656c 6966 206e 6f74 2073        elif not s
+0000a000: 656c 662e 6d69 7373 696e 675f 746f 6c65  elf.missing_tole
+0000a010: 7261 6e63 653a 0d0a 2020 2020 2020 2020  rance:..        
+0000a020: 2020 2020 2020 2020 7261 6973 6520 4b65          raise Ke
+0000a030: 7945 7272 6f72 2866 2227 7b69 6e5f 6b65  yError(f"'{in_ke
+0000a040: 797d 2720 6e6f 7420 666f 756e 6420 696e  y}' not found in
+0000a050: 2074 656e 736f 7264 6963 7420 7b74 656e   tensordict {ten
+0000a060: 736f 7264 6963 747d 2229 0d0a 2020 2020  sordict}")..    
+0000a070: 2020 2020 7265 7475 726e 2074 656e 736f      return tenso
+0000a080: 7264 6963 740d 0a0d 0a20 2020 2064 6566  rdict....    def
+0000a090: 205f 7374 6570 2873 656c 662c 2074 656e   _step(self, ten
+0000a0a0: 736f 7264 6963 743a 2054 656e 736f 7244  sordict: TensorD
+0000a0b0: 6963 7442 6173 6529 202d 3e20 5465 6e73  ictBase) -> Tens
+0000a0c0: 6f72 4469 6374 4261 7365 3a0d 0a20 2020  orDictBase:..   
+0000a0d0: 2020 2020 2066 6f72 206f 7574 5f6b 6579       for out_key
+0000a0e0: 2069 6e20 7365 6c66 2e6f 7574 5f6b 6579   in self.out_key
+0000a0f0: 733a 0d0a 2020 2020 2020 2020 2020 2020  s:..            
+0000a100: 6966 2069 7369 6e73 7461 6e63 6528 6f75  if isinstance(ou
+0000a110: 745f 6b65 792c 2073 7472 293a 0d0a 2020  t_key, str):..  
+0000a120: 2020 2020 2020 2020 2020 2020 2020 6f75                ou
+0000a130: 745f 6b65 7920 3d20 286f 7574 5f6b 6579  t_key = (out_key
+0000a140: 2c29 0d0a 2020 2020 2020 2020 2020 2020  ,)..            
+0000a150: 2020 2020 7465 6e73 6f72 6469 6374 2e73      tensordict.s
+0000a160: 6574 2828 226e 6578 7422 2c20 2a6f 7574  et(("next", *out
+0000a170: 5f6b 6579 292c 2074 656e 736f 7264 6963  _key), tensordic
+0000a180: 742e 6765 7428 6f75 745f 6b65 7929 290d  t.get(out_key)).
+0000a190: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+0000a1a0: 7375 7065 7228 292e 5f73 7465 7028 7465  super()._step(te
+0000a1b0: 6e73 6f72 6469 6374 290d 0a0d 0a20 2020  nsordict)....   
+0000a1c0: 2064 6566 205f 6170 706c 795f 7472 616e   def _apply_tran
+0000a1d0: 7366 6f72 6d28 0d0a 2020 2020 2020 2020  sform(..        
+0000a1e0: 7365 6c66 2c20 7265 7761 7264 3a20 746f  self, reward: to
+0000a1f0: 7263 682e 5465 6e73 6f72 2c20 7461 7267  rch.Tensor, targ
+0000a200: 6574 5f72 6574 7572 6e3a 2074 6f72 6368  et_return: torch
+0000a210: 2e54 656e 736f 720d 0a20 2020 2029 202d  .Tensor..    ) -
+0000a220: 3e20 746f 7263 682e 5465 6e73 6f72 3a0d  > torch.Tensor:.
+0000a230: 0a20 2020 2020 2020 2069 6620 7365 6c66  .        if self
+0000a240: 2e6d 6f64 6520 3d3d 2022 7265 6475 6365  .mode == "reduce
+0000a250: 223a 0d0a 2020 2020 2020 2020 2020 2020  ":..            
+0000a260: 7461 7267 6574 5f72 6574 7572 6e20 3d20  target_return = 
+0000a270: 7461 7267 6574 5f72 6574 7572 6e20 2d20  target_return - 
+0000a280: 7265 7761 7264 0d0a 2020 2020 2020 2020  reward..        
+0000a290: 2020 2020 7265 7475 726e 2074 6172 6765      return targe
+0000a2a0: 745f 7265 7475 726e 0d0a 2020 2020 2020  t_return..      
+0000a2b0: 2020 656c 6966 2073 656c 662e 6d6f 6465    elif self.mode
+0000a2c0: 203d 3d20 2263 6f6e 7374 616e 7422 3a0d   == "constant":.
+0000a2d0: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
+0000a2e0: 7572 6e20 7461 7267 6574 5f72 6574 7572  urn target_retur
+0000a2f0: 6e0d 0a20 2020 2020 2020 2065 6c73 653a  n..        else:
+0000a300: 0d0a 2020 2020 2020 2020 2020 2020 7261  ..            ra
+0000a310: 6973 6520 5661 6c75 6545 7272 6f72 2822  ise ValueError("
+0000a320: 556e 6b6e 6f77 6e20 6d6f 6465 3a20 7b7d  Unknown mode: {}
+0000a330: 222e 666f 726d 6174 2873 656c 662e 6d6f  ".format(self.mo
+0000a340: 6465 2929 0d0a 0d0a 2020 2020 6465 6620  de))....    def 
+0000a350: 666f 7277 6172 6428 7365 6c66 2c20 7465  forward(self, te
+0000a360: 6e73 6f72 6469 6374 3a20 5465 6e73 6f72  nsordict: Tensor
+0000a370: 4469 6374 4261 7365 2920 2d3e 2054 656e  DictBase) -> Ten
+0000a380: 736f 7244 6963 7442 6173 653a 0d0a 2020  sorDictBase:..  
+0000a390: 2020 2020 2020 7261 6973 6520 4e6f 7449        raise NotI
+0000a3a0: 6d70 6c65 6d65 6e74 6564 4572 726f 7228  mplementedError(
+0000a3b0: 0d0a 2020 2020 2020 2020 2020 2020 464f  ..            FO
+0000a3c0: 5257 4152 445f 4e4f 545f 494d 504c 454d  RWARD_NOT_IMPLEM
+0000a3d0: 454e 5445 442e 666f 726d 6174 2873 656c  ENTED.format(sel
+0000a3e0: 662e 5f5f 636c 6173 735f 5f2e 5f5f 6e61  f.__class__.__na
+0000a3f0: 6d65 5f5f 290d 0a20 2020 2020 2020 2029  me__)..        )
+0000a400: 0d0a 0d0a 2020 2020 6465 6620 7472 616e  ....    def tran
+0000a410: 7366 6f72 6d5f 6f62 7365 7276 6174 696f  sform_observatio
+0000a420: 6e5f 7370 6563 280d 0a20 2020 2020 2020  n_spec(..       
+0000a430: 2073 656c 662c 206f 6273 6572 7661 7469   self, observati
+0000a440: 6f6e 5f73 7065 633a 2043 6f6d 706f 7369  on_spec: Composi
+0000a450: 7465 5370 6563 0d0a 2020 2020 2920 2d3e  teSpec..    ) ->
+0000a460: 2043 6f6d 706f 7369 7465 5370 6563 3a0d   CompositeSpec:.
+0000a470: 0a20 2020 2020 2020 2069 6620 6e6f 7420  .        if not 
+0000a480: 6973 696e 7374 616e 6365 286f 6273 6572  isinstance(obser
+0000a490: 7661 7469 6f6e 5f73 7065 632c 2043 6f6d  vation_spec, Com
+0000a4a0: 706f 7369 7465 5370 6563 293a 0d0a 2020  positeSpec):..  
+0000a4b0: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
+0000a4c0: 5661 6c75 6545 7272 6f72 280d 0a20 2020  ValueError(..   
+0000a4d0: 2020 2020 2020 2020 2020 2020 2066 226f               f"o
+0000a4e0: 6273 6572 7661 7469 6f6e 5f73 7065 6320  bservation_spec 
+0000a4f0: 7761 7320 6578 7065 6374 6564 2074 6f20  was expected to 
+0000a500: 6265 206f 6620 7479 7065 2043 6f6d 706f  be of type Compo
+0000a510: 7369 7465 5370 6563 2e20 476f 7420 7b74  siteSpec. Got {t
+0000a520: 7970 6528 6f62 7365 7276 6174 696f 6e5f  ype(observation_
+0000a530: 7370 6563 297d 2069 6e73 7465 6164 2e22  spec)} instead."
+0000a540: 0d0a 2020 2020 2020 2020 2020 2020 290d  ..            ).
+0000a550: 0a0d 0a20 2020 2020 2020 2074 6172 6765  ...        targe
+0000a560: 745f 7265 7475 726e 5f73 7065 6320 3d20  t_return_spec = 
+0000a570: 426f 756e 6465 6454 656e 736f 7253 7065  BoundedTensorSpe
+0000a580: 6328 0d0a 2020 2020 2020 2020 2020 2020  c(..            
+0000a590: 6d69 6e69 6d75 6d3d 2d66 6c6f 6174 2822  minimum=-float("
+0000a5a0: 696e 6622 292c 0d0a 2020 2020 2020 2020  inf"),..        
+0000a5b0: 2020 2020 6d61 7869 6d75 6d3d 7365 6c66      maximum=self
+0000a5c0: 2e74 6172 6765 745f 7265 7475 726e 2c0d  .target_return,.
+0000a5d0: 0a20 2020 2020 2020 2020 2020 2073 6861  .            sha
+0000a5e0: 7065 3d73 656c 662e 7061 7265 6e74 2e72  pe=self.parent.r
+0000a5f0: 6577 6172 645f 7370 6563 2e73 6861 7065  eward_spec.shape
+0000a600: 2c0d 0a20 2020 2020 2020 2020 2020 2064  ,..            d
+0000a610: 7479 7065 3d73 656c 662e 7061 7265 6e74  type=self.parent
+0000a620: 2e72 6577 6172 645f 7370 6563 2e64 7479  .reward_spec.dty
+0000a630: 7065 2c0d 0a20 2020 2020 2020 2020 2020  pe,..           
+0000a640: 2064 6576 6963 653d 7365 6c66 2e70 6172   device=self.par
+0000a650: 656e 742e 7265 7761 7264 5f73 7065 632e  ent.reward_spec.
+0000a660: 6465 7669 6365 2c0d 0a20 2020 2020 2020  device,..       
+0000a670: 2029 0d0a 2020 2020 2020 2020 6f62 7365   )..        obse
+0000a680: 7276 6174 696f 6e5f 7370 6563 5b22 7461  rvation_spec["ta
+0000a690: 7267 6574 5f72 6574 7572 6e22 5d20 3d20  rget_return"] = 
+0000a6a0: 7461 7267 6574 5f72 6574 7572 6e5f 7370  target_return_sp
+0000a6b0: 6563 0d0a 0d0a 2020 2020 2020 2020 7265  ec....        re
+0000a6c0: 7475 726e 206f 6273 6572 7661 7469 6f6e  turn observation
+0000a6d0: 5f73 7065 630d 0a0d 0a0d 0a63 6c61 7373  _spec......class
+0000a6e0: 2052 6577 6172 6443 6c69 7070 696e 6728   RewardClipping(
+0000a6f0: 5472 616e 7366 6f72 6d29 3a0d 0a20 2020  Transform):..   
+0000a700: 2022 2222 436c 6970 7320 7468 6520 7265   """Clips the re
+0000a710: 7761 7264 2062 6574 7765 656e 2060 636c  ward between `cl
+0000a720: 616d 705f 6d69 6e60 2061 6e64 2060 636c  amp_min` and `cl
+0000a730: 616d 705f 6d61 7860 2e0d 0a0d 0a20 2020  amp_max`.....   
+0000a740: 2041 7267 733a 0d0a 2020 2020 2020 2020   Args:..        
+0000a750: 636c 6970 5f6d 696e 2028 7363 616c 6172  clip_min (scalar
+0000a760: 293a 206d 696e 696d 756d 2076 616c 7565  ): minimum value
+0000a770: 206f 6620 7468 6520 7265 7375 6c74 696e   of the resultin
+0000a780: 6720 7265 7761 7264 2e0d 0a20 2020 2020  g reward...     
+0000a790: 2020 2063 6c69 705f 6d61 7820 2873 6361     clip_max (sca
+0000a7a0: 6c61 7229 3a20 6d61 7869 6d75 6d20 7661  lar): maximum va
+0000a7b0: 6c75 6520 6f66 2074 6865 2072 6573 756c  lue of the resul
+0000a7c0: 7469 6e67 2072 6577 6172 642e 0d0a 0d0a  ting reward.....
+0000a7d0: 2020 2020 2222 220d 0a0d 0a20 2020 2064      """....    d
+0000a7e0: 6566 205f 5f69 6e69 745f 5f28 0d0a 2020  ef __init__(..  
+0000a7f0: 2020 2020 2020 7365 6c66 2c0d 0a20 2020        self,..   
+0000a800: 2020 2020 2063 6c61 6d70 5f6d 696e 3a20       clamp_min: 
+0000a810: 666c 6f61 7420 3d20 4e6f 6e65 2c0d 0a20  float = None,.. 
+0000a820: 2020 2020 2020 2063 6c61 6d70 5f6d 6178         clamp_max
+0000a830: 3a20 666c 6f61 7420 3d20 4e6f 6e65 2c0d  : float = None,.
+0000a840: 0a20 2020 2020 2020 2069 6e5f 6b65 7973  .        in_keys
+0000a850: 3a20 4f70 7469 6f6e 616c 5b53 6571 7565  : Optional[Seque
+0000a860: 6e63 655b 7374 725d 5d20 3d20 4e6f 6e65  nce[str]] = None
+0000a870: 2c0d 0a20 2020 2020 2020 206f 7574 5f6b  ,..        out_k
+0000a880: 6579 733a 204f 7074 696f 6e61 6c5b 5365  eys: Optional[Se
+0000a890: 7175 656e 6365 5b73 7472 5d5d 203d 204e  quence[str]] = N
+0000a8a0: 6f6e 652c 0d0a 2020 2020 293a 0d0a 2020  one,..    ):..  
+0000a8b0: 2020 2020 2020 6966 2069 6e5f 6b65 7973        if in_keys
+0000a8c0: 2069 7320 4e6f 6e65 3a0d 0a20 2020 2020   is None:..     
+0000a8d0: 2020 2020 2020 2069 6e5f 6b65 7973 203d         in_keys =
+0000a8e0: 205b 2272 6577 6172 6422 5d0d 0a20 2020   ["reward"]..   
+0000a8f0: 2020 2020 2073 7570 6572 2829 2e5f 5f69       super().__i
+0000a900: 6e69 745f 5f28 696e 5f6b 6579 733d 696e  nit__(in_keys=in
+0000a910: 5f6b 6579 732c 206f 7574 5f6b 6579 733d  _keys, out_keys=
+0000a920: 6f75 745f 6b65 7973 290d 0a20 2020 2020  out_keys)..     
+0000a930: 2020 2063 6c61 6d70 5f6d 696e 5f74 656e     clamp_min_ten
+0000a940: 736f 7220 3d20 280d 0a20 2020 2020 2020  sor = (..       
+0000a950: 2020 2020 2063 6c61 6d70 5f6d 696e 2069       clamp_min i
+0000a960: 6620 6973 696e 7374 616e 6365 2863 6c61  f isinstance(cla
+0000a970: 6d70 5f6d 696e 2c20 5465 6e73 6f72 2920  mp_min, Tensor) 
+0000a980: 656c 7365 2074 6f72 6368 2e74 656e 736f  else torch.tenso
+0000a990: 7228 636c 616d 705f 6d69 6e29 0d0a 2020  r(clamp_min)..  
+0000a9a0: 2020 2020 2020 290d 0a20 2020 2020 2020        )..       
+0000a9b0: 2063 6c61 6d70 5f6d 6178 5f74 656e 736f   clamp_max_tenso
+0000a9c0: 7220 3d20 280d 0a20 2020 2020 2020 2020  r = (..         
+0000a9d0: 2020 2063 6c61 6d70 5f6d 6178 2069 6620     clamp_max if 
+0000a9e0: 6973 696e 7374 616e 6365 2863 6c61 6d70  isinstance(clamp
+0000a9f0: 5f6d 6178 2c20 5465 6e73 6f72 2920 656c  _max, Tensor) el
+0000aa00: 7365 2074 6f72 6368 2e74 656e 736f 7228  se torch.tensor(
+0000aa10: 636c 616d 705f 6d61 7829 0d0a 2020 2020  clamp_max)..    
+0000aa20: 2020 2020 290d 0a20 2020 2020 2020 2073      )..        s
+0000aa30: 656c 662e 7265 6769 7374 6572 5f62 7566  elf.register_buf
+0000aa40: 6665 7228 2263 6c61 6d70 5f6d 696e 222c  fer("clamp_min",
+0000aa50: 2063 6c61 6d70 5f6d 696e 5f74 656e 736f   clamp_min_tenso
+0000aa60: 7229 0d0a 2020 2020 2020 2020 7365 6c66  r)..        self
+0000aa70: 2e72 6567 6973 7465 725f 6275 6666 6572  .register_buffer
+0000aa80: 2822 636c 616d 705f 6d61 7822 2c20 636c  ("clamp_max", cl
+0000aa90: 616d 705f 6d61 785f 7465 6e73 6f72 290d  amp_max_tensor).
+0000aaa0: 0a0d 0a20 2020 2064 6566 205f 6170 706c  ...    def _appl
+0000aab0: 795f 7472 616e 7366 6f72 6d28 7365 6c66  y_transform(self
+0000aac0: 2c20 7265 7761 7264 3a20 746f 7263 682e  , reward: torch.
+0000aad0: 5465 6e73 6f72 2920 2d3e 2074 6f72 6368  Tensor) -> torch
+0000aae0: 2e54 656e 736f 723a 0d0a 2020 2020 2020  .Tensor:..      
+0000aaf0: 2020 6966 2073 656c 662e 636c 616d 705f    if self.clamp_
+0000ab00: 6d61 7820 6973 206e 6f74 204e 6f6e 6520  max is not None 
+0000ab10: 616e 6420 7365 6c66 2e63 6c61 6d70 5f6d  and self.clamp_m
+0000ab20: 696e 2069 7320 6e6f 7420 4e6f 6e65 3a0d  in is not None:.
+0000ab30: 0a20 2020 2020 2020 2020 2020 2072 6577  .            rew
+0000ab40: 6172 6420 3d20 7265 7761 7264 2e63 6c61  ard = reward.cla
+0000ab50: 6d70 2873 656c 662e 636c 616d 705f 6d69  mp(self.clamp_mi
+0000ab60: 6e2c 2073 656c 662e 636c 616d 705f 6d61  n, self.clamp_ma
+0000ab70: 7829 0d0a 2020 2020 2020 2020 656c 6966  x)..        elif
+0000ab80: 2073 656c 662e 636c 616d 705f 6d69 6e20   self.clamp_min 
+0000ab90: 6973 206e 6f74 204e 6f6e 653a 0d0a 2020  is not None:..  
+0000aba0: 2020 2020 2020 2020 2020 7265 7761 7264            reward
+0000abb0: 203d 2072 6577 6172 642e 636c 616d 705f   = reward.clamp_
+0000abc0: 6d69 6e28 7365 6c66 2e63 6c61 6d70 5f6d  min(self.clamp_m
+0000abd0: 696e 290d 0a20 2020 2020 2020 2065 6c69  in)..        eli
+0000abe0: 6620 7365 6c66 2e63 6c61 6d70 5f6d 6178  f self.clamp_max
+0000abf0: 2069 7320 6e6f 7420 4e6f 6e65 3a0d 0a20   is not None:.. 
+0000ac00: 2020 2020 2020 2020 2020 2072 6577 6172             rewar
+0000ac10: 6420 3d20 7265 7761 7264 2e63 6c61 6d70  d = reward.clamp
+0000ac20: 5f6d 6178 2873 656c 662e 636c 616d 705f  _max(self.clamp_
+0000ac30: 6d61 7829 0d0a 2020 2020 2020 2020 7265  max)..        re
+0000ac40: 7475 726e 2072 6577 6172 640d 0a0d 0a20  turn reward.... 
+0000ac50: 2020 2064 6566 2074 7261 6e73 666f 726d     def transform
+0000ac60: 5f72 6577 6172 645f 7370 6563 2873 656c  _reward_spec(sel
+0000ac70: 662c 2072 6577 6172 645f 7370 6563 3a20  f, reward_spec: 
+0000ac80: 5465 6e73 6f72 5370 6563 2920 2d3e 2054  TensorSpec) -> T
+0000ac90: 656e 736f 7253 7065 633a 0d0a 2020 2020  ensorSpec:..    
+0000aca0: 2020 2020 6966 2069 7369 6e73 7461 6e63      if isinstanc
+0000acb0: 6528 7265 7761 7264 5f73 7065 632c 2055  e(reward_spec, U
+0000acc0: 6e62 6f75 6e64 6564 436f 6e74 696e 756f  nboundedContinuo
+0000acd0: 7573 5465 6e73 6f72 5370 6563 293a 0d0a  usTensorSpec):..
+0000ace0: 2020 2020 2020 2020 2020 2020 7265 7475              retu
+0000acf0: 726e 2042 6f75 6e64 6564 5465 6e73 6f72  rn BoundedTensor
+0000ad00: 5370 6563 280d 0a20 2020 2020 2020 2020  Spec(..         
+0000ad10: 2020 2020 2020 2073 656c 662e 636c 616d         self.clam
+0000ad20: 705f 6d69 6e2c 0d0a 2020 2020 2020 2020  p_min,..        
+0000ad30: 2020 2020 2020 2020 7365 6c66 2e63 6c61          self.cla
+0000ad40: 6d70 5f6d 6178 2c0d 0a20 2020 2020 2020  mp_max,..       
+0000ad50: 2020 2020 2020 2020 2073 6861 7065 3d72           shape=r
+0000ad60: 6577 6172 645f 7370 6563 2e73 6861 7065  eward_spec.shape
+0000ad70: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
+0000ad80: 2020 2064 6576 6963 653d 7265 7761 7264     device=reward
+0000ad90: 5f73 7065 632e 6465 7669 6365 2c0d 0a20  _spec.device,.. 
+0000ada0: 2020 2020 2020 2020 2020 2020 2020 2064                 d
+0000adb0: 7479 7065 3d72 6577 6172 645f 7370 6563  type=reward_spec
+0000adc0: 2e64 7479 7065 2c0d 0a20 2020 2020 2020  .dtype,..       
+0000add0: 2020 2020 2029 0d0a 2020 2020 2020 2020       )..        
+0000ade0: 656c 7365 3a0d 0a20 2020 2020 2020 2020  else:..         
+0000adf0: 2020 2072 6169 7365 204e 6f74 496d 706c     raise NotImpl
+0000ae00: 656d 656e 7465 6445 7272 6f72 280d 0a20  ementedError(.. 
+0000ae10: 2020 2020 2020 2020 2020 2020 2020 2066                 f
+0000ae20: 227b 7365 6c66 2e5f 5f63 6c61 7373 5f5f  "{self.__class__
+0000ae30: 2e5f 5f6e 616d 655f 5f7d 2e74 7261 6e73  .__name__}.trans
+0000ae40: 666f 726d 5f72 6577 6172 645f 7370 6563  form_reward_spec
+0000ae50: 206e 6f74 2022 0d0a 2020 2020 2020 2020   not "..        
+0000ae60: 2020 2020 2020 2020 6622 696d 706c 656d          f"implem
+0000ae70: 656e 7465 6420 666f 7220 7465 6e73 6f72  ented for tensor
+0000ae80: 2073 7065 6320 6f66 2074 7970 6522 0d0a   spec of type"..
+0000ae90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000aea0: 6622 207b 7479 7065 2872 6577 6172 645f  f" {type(reward_
+0000aeb0: 7370 6563 292e 5f5f 6e61 6d65 5f5f 7d22  spec).__name__}"
+0000aec0: 0d0a 2020 2020 2020 2020 2020 2020 290d  ..            ).
+0000aed0: 0a0d 0a20 2020 2064 6566 205f 5f72 6570  ...    def __rep
+0000aee0: 725f 5f28 7365 6c66 2920 2d3e 2073 7472  r__(self) -> str
+0000aef0: 3a0d 0a20 2020 2020 2020 2072 6574 7572  :..        retur
+0000af00: 6e20 280d 0a20 2020 2020 2020 2020 2020  n (..           
+0000af10: 2066 227b 7365 6c66 2e5f 5f63 6c61 7373   f"{self.__class
+0000af20: 5f5f 2e5f 5f6e 616d 655f 5f7d 2822 0d0a  __.__name__}("..
+0000af30: 2020 2020 2020 2020 2020 2020 6622 636c              f"cl
+0000af40: 616d 705f 6d69 6e3d 7b66 6c6f 6174 2873  amp_min={float(s
+0000af50: 656c 662e 636c 616d 705f 6d69 6e29 3a34  elf.clamp_min):4
+0000af60: 2e34 667d 2c20 636c 616d 705f 6d61 7822  .4f}, clamp_max"
+0000af70: 0d0a 2020 2020 2020 2020 2020 2020 6622  ..            f"
+0000af80: 3d7b 666c 6f61 7428 7365 6c66 2e63 6c61  ={float(self.cla
+0000af90: 6d70 5f6d 6178 293a 342e 3466 7d2c 206b  mp_max):4.4f}, k
+0000afa0: 6579 733d 7b73 656c 662e 696e 5f6b 6579  eys={self.in_key
+0000afb0: 737d 2922 0d0a 2020 2020 2020 2020 290d  s})"..        ).
+0000afc0: 0a0d 0a0d 0a63 6c61 7373 2042 696e 6172  .....class Binar
+0000afd0: 697a 6552 6577 6172 6428 5472 616e 7366  izeReward(Transf
+0000afe0: 6f72 6d29 3a0d 0a20 2020 2022 2222 4d61  orm):..    """Ma
+0000aff0: 7073 2074 6865 2072 6577 6172 6420 746f  ps the reward to
+0000b000: 2061 2062 696e 6172 7920 7661 6c75 6520   a binary value 
+0000b010: 2830 206f 7220 3129 2069 6620 7468 6520  (0 or 1) if the 
+0000b020: 7265 7761 7264 2069 7320 6e75 6c6c 206f  reward is null o
+0000b030: 7220 6e6f 6e2d 6e75 6c6c 2c20 7265 7370  r non-null, resp
+0000b040: 6563 7469 7665 6c79 2e22 2222 0d0a 0d0a  ectively."""....
+0000b050: 2020 2020 6465 6620 5f5f 696e 6974 5f5f      def __init__
+0000b060: 280d 0a20 2020 2020 2020 2073 656c 662c  (..        self,
+0000b070: 0d0a 2020 2020 2020 2020 696e 5f6b 6579  ..        in_key
+0000b080: 733a 204f 7074 696f 6e61 6c5b 5365 7175  s: Optional[Sequ
+0000b090: 656e 6365 5b73 7472 5d5d 203d 204e 6f6e  ence[str]] = Non
+0000b0a0: 652c 0d0a 2020 2020 2020 2020 6f75 745f  e,..        out_
+0000b0b0: 6b65 7973 3a20 4f70 7469 6f6e 616c 5b53  keys: Optional[S
+0000b0c0: 6571 7565 6e63 655b 7374 725d 5d20 3d20  equence[str]] = 
+0000b0d0: 4e6f 6e65 2c0d 0a20 2020 2029 3a0d 0a20  None,..    ):.. 
+0000b0e0: 2020 2020 2020 2069 6620 696e 5f6b 6579         if in_key
+0000b0f0: 7320 6973 204e 6f6e 653a 0d0a 2020 2020  s is None:..    
+0000b100: 2020 2020 2020 2020 696e 5f6b 6579 7320          in_keys 
+0000b110: 3d20 5b22 7265 7761 7264 225d 0d0a 2020  = ["reward"]..  
+0000b120: 2020 2020 2020 7375 7065 7228 292e 5f5f        super().__
+0000b130: 696e 6974 5f5f 2869 6e5f 6b65 7973 3d69  init__(in_keys=i
+0000b140: 6e5f 6b65 7973 2c20 6f75 745f 6b65 7973  n_keys, out_keys
+0000b150: 3d6f 7574 5f6b 6579 7329 0d0a 0d0a 2020  =out_keys)....  
+0000b160: 2020 6465 6620 5f61 7070 6c79 5f74 7261    def _apply_tra
+0000b170: 6e73 666f 726d 2873 656c 662c 2072 6577  nsform(self, rew
+0000b180: 6172 643a 2074 6f72 6368 2e54 656e 736f  ard: torch.Tenso
+0000b190: 7229 202d 3e20 746f 7263 682e 5465 6e73  r) -> torch.Tens
+0000b1a0: 6f72 3a0d 0a20 2020 2020 2020 2069 6620  or:..        if 
+0000b1b0: 6e6f 7420 7265 7761 7264 2e73 6861 7065  not reward.shape
+0000b1c0: 206f 7220 7265 7761 7264 2e73 6861 7065   or reward.shape
+0000b1d0: 5b2d 315d 2021 3d20 313a 0d0a 2020 2020  [-1] != 1:..    
+0000b1e0: 2020 2020 2020 2020 7261 6973 6520 5275          raise Ru
+0000b1f0: 6e74 696d 6545 7272 6f72 280d 0a20 2020  ntimeError(..   
+0000b200: 2020 2020 2020 2020 2020 2020 2066 2252               f"R
+0000b210: 6577 6172 6420 7368 6170 6520 6c61 7374  eward shape last
+0000b220: 2064 696d 656e 7369 6f6e 206d 7573 7420   dimension must 
+0000b230: 6265 2073 696e 676c 6574 6f6e 2c20 676f  be singleton, go
+0000b240: 7420 7265 7761 7264 206f 6620 7368 6170  t reward of shap
+0000b250: 6520 7b72 6577 6172 642e 7368 6170 657d  e {reward.shape}
+0000b260: 220d 0a20 2020 2020 2020 2020 2020 2029  "..            )
+0000b270: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
+0000b280: 2028 7265 7761 7264 203e 2030 2e30 292e   (reward > 0.0).
+0000b290: 746f 2874 6f72 6368 2e6c 6f6e 6729 0d0a  to(torch.long)..
+0000b2a0: 0d0a 2020 2020 6465 6620 7472 616e 7366  ..    def transf
+0000b2b0: 6f72 6d5f 7265 7761 7264 5f73 7065 6328  orm_reward_spec(
+0000b2c0: 7365 6c66 2c20 7265 7761 7264 5f73 7065  self, reward_spe
+0000b2d0: 633a 2054 656e 736f 7253 7065 6329 202d  c: TensorSpec) -
+0000b2e0: 3e20 5465 6e73 6f72 5370 6563 3a0d 0a20  > TensorSpec:.. 
+0000b2f0: 2020 2020 2020 2072 6574 7572 6e20 4269         return Bi
+0000b300: 6e61 7279 4469 7363 7265 7465 5465 6e73  naryDiscreteTens
+0000b310: 6f72 5370 6563 280d 0a20 2020 2020 2020  orSpec(..       
+0000b320: 2020 2020 206e 3d31 2c20 6465 7669 6365       n=1, device
+0000b330: 3d72 6577 6172 645f 7370 6563 2e64 6576  =reward_spec.dev
+0000b340: 6963 652c 2073 6861 7065 3d72 6577 6172  ice, shape=rewar
+0000b350: 645f 7370 6563 2e73 6861 7065 0d0a 2020  d_spec.shape..  
+0000b360: 2020 2020 2020 290d 0a0d 0a0d 0a63 6c61        )......cla
+0000b370: 7373 2052 6573 697a 6528 4f62 7365 7276  ss Resize(Observ
+0000b380: 6174 696f 6e54 7261 6e73 666f 726d 293a  ationTransform):
+0000b390: 0d0a 2020 2020 2222 2252 6573 697a 6573  ..    """Resizes
+0000b3a0: 2061 6e20 7069 7865 6c20 6f62 7365 7276   an pixel observ
+0000b3b0: 6174 696f 6e2e 0d0a 0d0a 2020 2020 4172  ation.....    Ar
+0000b3c0: 6773 3a0d 0a20 2020 2020 2020 2077 2028  gs:..        w (
+0000b3d0: 696e 7429 3a20 7265 7375 6c74 696e 6720  int): resulting 
+0000b3e0: 7769 6474 680d 0a20 2020 2020 2020 2068  width..        h
+0000b3f0: 2028 696e 7429 3a20 7265 7375 6c74 696e   (int): resultin
+0000b400: 6720 6865 6967 6874 0d0a 2020 2020 2020  g height..      
+0000b410: 2020 696e 7465 7270 6f6c 6174 696f 6e20    interpolation 
+0000b420: 2873 7472 293a 2069 6e74 6572 706f 6c61  (str): interpola
+0000b430: 7469 6f6e 206d 6574 686f 640d 0a20 2020  tion method..   
+0000b440: 2022 2222 0d0a 0d0a 2020 2020 6465 6620   """....    def 
+0000b450: 5f5f 696e 6974 5f5f 280d 0a20 2020 2020  __init__(..     
+0000b460: 2020 2073 656c 662c 0d0a 2020 2020 2020     self,..      
+0000b470: 2020 773a 2069 6e74 2c0d 0a20 2020 2020    w: int,..     
+0000b480: 2020 2068 3a20 696e 742c 0d0a 2020 2020     h: int,..    
+0000b490: 2020 2020 696e 7465 7270 6f6c 6174 696f      interpolatio
+0000b4a0: 6e3a 2073 7472 203d 2022 6269 6c69 6e65  n: str = "biline
+0000b4b0: 6172 222c 0d0a 2020 2020 2020 2020 696e  ar",..        in
+0000b4c0: 5f6b 6579 733a 204f 7074 696f 6e61 6c5b  _keys: Optional[
+0000b4d0: 5365 7175 656e 6365 5b73 7472 5d5d 203d  Sequence[str]] =
+0000b4e0: 204e 6f6e 652c 0d0a 2020 2020 2020 2020   None,..        
+0000b4f0: 6f75 745f 6b65 7973 3a20 4f70 7469 6f6e  out_keys: Option
+0000b500: 616c 5b53 6571 7565 6e63 655b 7374 725d  al[Sequence[str]
+0000b510: 5d20 3d20 4e6f 6e65 2c0d 0a20 2020 2029  ] = None,..    )
+0000b520: 3a0d 0a20 2020 2020 2020 2069 6620 6e6f  :..        if no
+0000b530: 7420 5f68 6173 5f74 763a 0d0a 2020 2020  t _has_tv:..    
+0000b540: 2020 2020 2020 2020 7261 6973 6520 496d          raise Im
+0000b550: 706f 7274 4572 726f 7228 0d0a 2020 2020  portError(..    
+0000b560: 2020 2020 2020 2020 2020 2020 2254 6f72              "Tor
+0000b570: 6368 7669 7369 6f6e 206e 6f74 2066 6f75  chvision not fou
+0000b580: 6e64 2e20 5468 6520 5265 7369 7a65 2074  nd. The Resize t
+0000b590: 7261 6e73 666f 726d 2072 656c 6965 7320  ransform relies 
+0000b5a0: 6f6e 2022 0d0a 2020 2020 2020 2020 2020  on "..          
+0000b5b0: 2020 2020 2020 2274 6f72 6368 7669 7369        "torchvisi
+0000b5c0: 6f6e 2069 6d70 6c65 6d65 6e74 6174 696f  on implementatio
+0000b5d0: 6e2e 2022 0d0a 2020 2020 2020 2020 2020  n. "..          
+0000b5e0: 2020 2020 2020 2243 6f6e 7369 6465 7220        "Consider 
+0000b5f0: 696e 7374 616c 6c69 6e67 2074 6869 7320  installing this 
+0000b600: 6465 7065 6e64 656e 6379 2e22 0d0a 2020  dependency."..  
+0000b610: 2020 2020 2020 2020 2020 290d 0a20 2020            )..   
+0000b620: 2020 2020 2069 6620 696e 5f6b 6579 7320       if in_keys 
+0000b630: 6973 204e 6f6e 653a 0d0a 2020 2020 2020  is None:..      
+0000b640: 2020 2020 2020 696e 5f6b 6579 7320 3d20        in_keys = 
+0000b650: 494d 4147 455f 4b45 5953 2020 2320 6465  IMAGE_KEYS  # de
+0000b660: 6661 756c 740d 0a20 2020 2020 2020 2073  fault..        s
+0000b670: 7570 6572 2829 2e5f 5f69 6e69 745f 5f28  uper().__init__(
+0000b680: 696e 5f6b 6579 733d 696e 5f6b 6579 732c  in_keys=in_keys,
+0000b690: 206f 7574 5f6b 6579 733d 6f75 745f 6b65   out_keys=out_ke
+0000b6a0: 7973 290d 0a20 2020 2020 2020 2073 656c  ys)..        sel
+0000b6b0: 662e 7720 3d20 696e 7428 7729 0d0a 2020  f.w = int(w)..  
+0000b6c0: 2020 2020 2020 7365 6c66 2e68 203d 2069        self.h = i
+0000b6d0: 6e74 2868 290d 0a20 2020 2020 2020 2073  nt(h)..        s
+0000b6e0: 656c 662e 696e 7465 7270 6f6c 6174 696f  elf.interpolatio
+0000b6f0: 6e20 3d20 696e 7465 7270 6f6c 6174 696f  n = interpolatio
+0000b700: 6e5f 666e 2869 6e74 6572 706f 6c61 7469  n_fn(interpolati
+0000b710: 6f6e 290d 0a0d 0a20 2020 2064 6566 205f  on)....    def _
+0000b720: 6170 706c 795f 7472 616e 7366 6f72 6d28  apply_transform(
+0000b730: 7365 6c66 2c20 6f62 7365 7276 6174 696f  self, observatio
+0000b740: 6e3a 2074 6f72 6368 2e54 656e 736f 7229  n: torch.Tensor)
+0000b750: 202d 3e20 746f 7263 682e 5465 6e73 6f72   -> torch.Tensor
+0000b760: 3a0d 0a20 2020 2020 2020 2023 2066 6c61  :..        # fla
+0000b770: 7474 656e 2069 6620 6e65 6365 7373 6172  tten if necessar
+0000b780: 790d 0a20 2020 2020 2020 2069 6620 6f62  y..        if ob
+0000b790: 7365 7276 6174 696f 6e2e 7368 6170 655b  servation.shape[
+0000b7a0: 2d32 3a5d 203d 3d20 746f 7263 682e 5369  -2:] == torch.Si
+0000b7b0: 7a65 285b 7365 6c66 2e77 2c20 7365 6c66  ze([self.w, self
+0000b7c0: 2e68 5d29 3a0d 0a20 2020 2020 2020 2020  .h]):..         
+0000b7d0: 2020 2072 6574 7572 6e20 6f62 7365 7276     return observ
+0000b7e0: 6174 696f 6e0d 0a20 2020 2020 2020 206e  ation..        n
+0000b7f0: 6469 6d20 3d20 6f62 7365 7276 6174 696f  dim = observatio
+0000b800: 6e2e 6e64 696d 656e 7369 6f6e 2829 0d0a  n.ndimension()..
+0000b810: 2020 2020 2020 2020 6966 206e 6469 6d20          if ndim 
+0000b820: 3e20 343a 0d0a 2020 2020 2020 2020 2020  > 4:..          
+0000b830: 2020 7369 7a65 7320 3d20 6f62 7365 7276    sizes = observ
+0000b840: 6174 696f 6e2e 7368 6170 655b 3a2d 335d  ation.shape[:-3]
+0000b850: 0d0a 2020 2020 2020 2020 2020 2020 6f62  ..            ob
+0000b860: 7365 7276 6174 696f 6e20 3d20 746f 7263  servation = torc
+0000b870: 682e 666c 6174 7465 6e28 6f62 7365 7276  h.flatten(observ
+0000b880: 6174 696f 6e2c 2030 2c20 6e64 696d 202d  ation, 0, ndim -
+0000b890: 2034 290d 0a20 2020 2020 2020 206f 6273   4)..        obs
+0000b8a0: 6572 7661 7469 6f6e 203d 2072 6573 697a  ervation = resiz
+0000b8b0: 6528 0d0a 2020 2020 2020 2020 2020 2020  e(..            
+0000b8c0: 6f62 7365 7276 6174 696f 6e2c 0d0a 2020  observation,..  
+0000b8d0: 2020 2020 2020 2020 2020 5b73 656c 662e            [self.
+0000b8e0: 772c 2073 656c 662e 685d 2c0d 0a20 2020  w, self.h],..   
+0000b8f0: 2020 2020 2020 2020 2069 6e74 6572 706f           interpo
+0000b900: 6c61 7469 6f6e 3d73 656c 662e 696e 7465  lation=self.inte
+0000b910: 7270 6f6c 6174 696f 6e2c 0d0a 2020 2020  rpolation,..    
+0000b920: 2020 2020 2020 2020 616e 7469 616c 6961          antialia
+0000b930: 733d 5472 7565 2c0d 0a20 2020 2020 2020  s=True,..       
+0000b940: 2029 0d0a 2020 2020 2020 2020 6966 206e   )..        if n
+0000b950: 6469 6d20 3e20 343a 0d0a 2020 2020 2020  dim > 4:..      
+0000b960: 2020 2020 2020 6f62 7365 7276 6174 696f        observatio
+0000b970: 6e20 3d20 6f62 7365 7276 6174 696f 6e2e  n = observation.
+0000b980: 756e 666c 6174 7465 6e28 302c 2073 697a  unflatten(0, siz
+0000b990: 6573 290d 0a0d 0a20 2020 2020 2020 2072  es)....        r
+0000b9a0: 6574 7572 6e20 6f62 7365 7276 6174 696f  eturn observatio
+0000b9b0: 6e0d 0a0d 0a20 2020 2040 5f61 7070 6c79  n....    @_apply
+0000b9c0: 5f74 6f5f 636f 6d70 6f73 6974 650d 0a20  _to_composite.. 
+0000b9d0: 2020 2064 6566 2074 7261 6e73 666f 726d     def transform
+0000b9e0: 5f6f 6273 6572 7661 7469 6f6e 5f73 7065  _observation_spe
+0000b9f0: 6328 7365 6c66 2c20 6f62 7365 7276 6174  c(self, observat
+0000ba00: 696f 6e5f 7370 6563 3a20 5465 6e73 6f72  ion_spec: Tensor
+0000ba10: 5370 6563 2920 2d3e 2054 656e 736f 7253  Spec) -> TensorS
+0000ba20: 7065 633a 0d0a 2020 2020 2020 2020 7370  pec:..        sp
+0000ba30: 6163 6520 3d20 6f62 7365 7276 6174 696f  ace = observatio
+0000ba40: 6e5f 7370 6563 2e73 7061 6365 0d0a 2020  n_spec.space..  
+0000ba50: 2020 2020 2020 6966 2069 7369 6e73 7461        if isinsta
+0000ba60: 6e63 6528 7370 6163 652c 2043 6f6e 7469  nce(space, Conti
+0000ba70: 6e75 6f75 7342 6f78 293a 0d0a 2020 2020  nuousBox):..    
+0000ba80: 2020 2020 2020 2020 7370 6163 652e 6d69          space.mi
+0000ba90: 6e69 6d75 6d20 3d20 7365 6c66 2e5f 6170  nimum = self._ap
+0000baa0: 706c 795f 7472 616e 7366 6f72 6d28 7370  ply_transform(sp
+0000bab0: 6163 652e 6d69 6e69 6d75 6d29 0d0a 2020  ace.minimum)..  
+0000bac0: 2020 2020 2020 2020 2020 7370 6163 652e            space.
+0000bad0: 6d61 7869 6d75 6d20 3d20 7365 6c66 2e5f  maximum = self._
+0000bae0: 6170 706c 795f 7472 616e 7366 6f72 6d28  apply_transform(
+0000baf0: 7370 6163 652e 6d61 7869 6d75 6d29 0d0a  space.maximum)..
+0000bb00: 2020 2020 2020 2020 2020 2020 6f62 7365              obse
+0000bb10: 7276 6174 696f 6e5f 7370 6563 2e73 6861  rvation_spec.sha
+0000bb20: 7065 203d 2073 7061 6365 2e6d 696e 696d  pe = space.minim
+0000bb30: 756d 2e73 6861 7065 0d0a 2020 2020 2020  um.shape..      
+0000bb40: 2020 656c 7365 3a0d 0a20 2020 2020 2020    else:..       
+0000bb50: 2020 2020 206f 6273 6572 7661 7469 6f6e       observation
+0000bb60: 5f73 7065 632e 7368 6170 6520 3d20 7365  _spec.shape = se
+0000bb70: 6c66 2e5f 6170 706c 795f 7472 616e 7366  lf._apply_transf
+0000bb80: 6f72 6d28 0d0a 2020 2020 2020 2020 2020  orm(..          
+0000bb90: 2020 2020 2020 746f 7263 682e 7a65 726f        torch.zero
+0000bba0: 7328 6f62 7365 7276 6174 696f 6e5f 7370  s(observation_sp
+0000bbb0: 6563 2e73 6861 7065 290d 0a20 2020 2020  ec.shape)..     
+0000bbc0: 2020 2020 2020 2029 2e73 6861 7065 0d0a         ).shape..
+0000bbd0: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
+0000bbe0: 206f 6273 6572 7661 7469 6f6e 5f73 7065   observation_spe
+0000bbf0: 630d 0a0d 0a20 2020 2064 6566 205f 5f72  c....    def __r
+0000bc00: 6570 725f 5f28 7365 6c66 2920 2d3e 2073  epr__(self) -> s
+0000bc10: 7472 3a0d 0a20 2020 2020 2020 2072 6574  tr:..        ret
+0000bc20: 7572 6e20 280d 0a20 2020 2020 2020 2020  urn (..         
+0000bc30: 2020 2066 227b 7365 6c66 2e5f 5f63 6c61     f"{self.__cla
+0000bc40: 7373 5f5f 2e5f 5f6e 616d 655f 5f7d 2822  ss__.__name__}("
+0000bc50: 0d0a 2020 2020 2020 2020 2020 2020 6622  ..            f"
+0000bc60: 773d 7b69 6e74 2873 656c 662e 7729 7d2c  w={int(self.w)},
+0000bc70: 2068 3d7b 696e 7428 7365 6c66 2e68 297d   h={int(self.h)}
+0000bc80: 2c20 220d 0a20 2020 2020 2020 2020 2020  , "..           
+0000bc90: 2066 2269 6e74 6572 706f 6c61 7469 6f6e   f"interpolation
+0000bca0: 3d7b 7365 6c66 2e69 6e74 6572 706f 6c61  ={self.interpola
+0000bcb0: 7469 6f6e 7d2c 206b 6579 733d 7b73 656c  tion}, keys={sel
+0000bcc0: 662e 696e 5f6b 6579 737d 2922 0d0a 2020  f.in_keys})"..  
+0000bcd0: 2020 2020 2020 290d 0a0d 0a0d 0a63 6c61        )......cla
+0000bce0: 7373 2043 656e 7465 7243 726f 7028 4f62  ss CenterCrop(Ob
+0000bcf0: 7365 7276 6174 696f 6e54 7261 6e73 666f  servationTransfo
+0000bd00: 726d 293a 0d0a 2020 2020 2222 2243 726f  rm):..    """Cro
+0000bd10: 7073 2074 6865 2063 656e 7465 7220 6f66  ps the center of
+0000bd20: 2061 6e20 696d 6167 652e 0d0a 0d0a 2020   an image.....  
+0000bd30: 2020 4172 6773 3a0d 0a20 2020 2020 2020    Args:..       
+0000bd40: 2077 2028 696e 7429 3a20 7265 7375 6c74   w (int): result
+0000bd50: 696e 6720 7769 6474 680d 0a20 2020 2020  ing width..     
+0000bd60: 2020 2068 2028 696e 742c 206f 7074 696f     h (int, optio
+0000bd70: 6e61 6c29 3a20 7265 7375 6c74 696e 6720  nal): resulting 
+0000bd80: 6865 6967 6874 2e20 4966 204e 6f6e 652c  height. If None,
+0000bd90: 2074 6865 6e20 7720 6973 2075 7365 6420   then w is used 
+0000bda0: 2873 7175 6172 6520 6372 6f70 292e 0d0a  (square crop)...
+0000bdb0: 2020 2020 2020 2020 696e 5f6b 6579 7320          in_keys 
+0000bdc0: 2873 6571 7565 6e63 6520 6f66 2073 7472  (sequence of str
+0000bdd0: 2c20 6f70 7469 6f6e 616c 293a 2074 6865  , optional): the
+0000bde0: 2065 6e74 7269 6573 2074 6f20 6372 6f70   entries to crop
+0000bdf0: 2e20 4966 206e 6f6e 6520 6973 2070 726f  . If none is pro
+0000be00: 7669 6465 642c 0d0a 2020 2020 2020 2020  vided,..        
+0000be10: 2020 2020 3a6f 626a 3a60 5b22 7069 7865      :obj:`["pixe
+0000be20: 6c73 225d 6020 6973 2061 7373 756d 6564  ls"]` is assumed
+0000be30: 2e0d 0a20 2020 2020 2020 206f 7574 5f6b  ...        out_k
+0000be40: 6579 7320 2873 6571 7565 6e63 6520 6f66  eys (sequence of
+0000be50: 2073 7472 2c20 6f70 7469 6f6e 616c 293a   str, optional):
+0000be60: 2074 6865 2063 726f 7070 6564 2069 6d61   the cropped ima
+0000be70: 6765 7320 6b65 7973 2e20 4966 206e 6f6e  ges keys. If non
+0000be80: 6520 6973 0d0a 2020 2020 2020 2020 2020  e is..          
+0000be90: 2020 7072 6f76 6964 6564 2c20 3a6f 626a    provided, :obj
+0000bea0: 3a60 696e 5f6b 6579 7360 2069 7320 6173  :`in_keys` is as
+0000beb0: 7375 6d65 642e 0d0a 0d0a 2020 2020 2222  sumed.....    ""
+0000bec0: 220d 0a0d 0a20 2020 2064 6566 205f 5f69  "....    def __i
+0000bed0: 6e69 745f 5f28 0d0a 2020 2020 2020 2020  nit__(..        
+0000bee0: 7365 6c66 2c0d 0a20 2020 2020 2020 2077  self,..        w
+0000bef0: 3a20 696e 742c 0d0a 2020 2020 2020 2020  : int,..        
+0000bf00: 683a 2069 6e74 203d 204e 6f6e 652c 0d0a  h: int = None,..
+0000bf10: 2020 2020 2020 2020 696e 5f6b 6579 733a          in_keys:
+0000bf20: 204f 7074 696f 6e61 6c5b 5365 7175 656e   Optional[Sequen
+0000bf30: 6365 5b73 7472 5d5d 203d 204e 6f6e 652c  ce[str]] = None,
+0000bf40: 0d0a 2020 2020 2020 2020 6f75 745f 6b65  ..        out_ke
+0000bf50: 7973 3a20 4f70 7469 6f6e 616c 5b53 6571  ys: Optional[Seq
+0000bf60: 7565 6e63 655b 7374 725d 5d20 3d20 4e6f  uence[str]] = No
+0000bf70: 6e65 2c0d 0a20 2020 2029 3a0d 0a20 2020  ne,..    ):..   
+0000bf80: 2020 2020 2069 6620 696e 5f6b 6579 7320       if in_keys 
+0000bf90: 6973 204e 6f6e 653a 0d0a 2020 2020 2020  is None:..      
+0000bfa0: 2020 2020 2020 696e 5f6b 6579 7320 3d20        in_keys = 
+0000bfb0: 494d 4147 455f 4b45 5953 2020 2320 6465  IMAGE_KEYS  # de
+0000bfc0: 6661 756c 740d 0a20 2020 2020 2020 2073  fault..        s
+0000bfd0: 7570 6572 2829 2e5f 5f69 6e69 745f 5f28  uper().__init__(
+0000bfe0: 696e 5f6b 6579 733d 696e 5f6b 6579 732c  in_keys=in_keys,
+0000bff0: 206f 7574 5f6b 6579 733d 6f75 745f 6b65   out_keys=out_ke
+0000c000: 7973 290d 0a20 2020 2020 2020 2073 656c  ys)..        sel
+0000c010: 662e 7720 3d20 770d 0a20 2020 2020 2020  f.w = w..       
+0000c020: 2073 656c 662e 6820 3d20 6820 6966 2068   self.h = h if h
+0000c030: 2065 6c73 6520 770d 0a0d 0a20 2020 2064   else w....    d
+0000c040: 6566 205f 6170 706c 795f 7472 616e 7366  ef _apply_transf
+0000c050: 6f72 6d28 7365 6c66 2c20 6f62 7365 7276  orm(self, observ
+0000c060: 6174 696f 6e3a 2074 6f72 6368 2e54 656e  ation: torch.Ten
+0000c070: 736f 7229 202d 3e20 746f 7263 682e 5465  sor) -> torch.Te
+0000c080: 6e73 6f72 3a0d 0a20 2020 2020 2020 206f  nsor:..        o
+0000c090: 6273 6572 7661 7469 6f6e 203d 2063 656e  bservation = cen
+0000c0a0: 7465 725f 6372 6f70 286f 6273 6572 7661  ter_crop(observa
+0000c0b0: 7469 6f6e 2c20 5b73 656c 662e 772c 2073  tion, [self.w, s
+0000c0c0: 656c 662e 685d 290d 0a20 2020 2020 2020  elf.h])..       
+0000c0d0: 2072 6574 7572 6e20 6f62 7365 7276 6174   return observat
+0000c0e0: 696f 6e0d 0a0d 0a20 2020 2040 5f61 7070  ion....    @_app
+0000c0f0: 6c79 5f74 6f5f 636f 6d70 6f73 6974 650d  ly_to_composite.
+0000c100: 0a20 2020 2064 6566 2074 7261 6e73 666f  .    def transfo
+0000c110: 726d 5f6f 6273 6572 7661 7469 6f6e 5f73  rm_observation_s
+0000c120: 7065 6328 7365 6c66 2c20 6f62 7365 7276  pec(self, observ
+0000c130: 6174 696f 6e5f 7370 6563 3a20 5465 6e73  ation_spec: Tens
+0000c140: 6f72 5370 6563 2920 2d3e 2054 656e 736f  orSpec) -> Tenso
+0000c150: 7253 7065 633a 0d0a 2020 2020 2020 2020  rSpec:..        
+0000c160: 7370 6163 6520 3d20 6f62 7365 7276 6174  space = observat
+0000c170: 696f 6e5f 7370 6563 2e73 7061 6365 0d0a  ion_spec.space..
+0000c180: 2020 2020 2020 2020 6966 2069 7369 6e73          if isins
+0000c190: 7461 6e63 6528 7370 6163 652c 2043 6f6e  tance(space, Con
+0000c1a0: 7469 6e75 6f75 7342 6f78 293a 0d0a 2020  tinuousBox):..  
+0000c1b0: 2020 2020 2020 2020 2020 7370 6163 652e            space.
+0000c1c0: 6d69 6e69 6d75 6d20 3d20 7365 6c66 2e5f  minimum = self._
+0000c1d0: 6170 706c 795f 7472 616e 7366 6f72 6d28  apply_transform(
+0000c1e0: 7370 6163 652e 6d69 6e69 6d75 6d29 0d0a  space.minimum)..
+0000c1f0: 2020 2020 2020 2020 2020 2020 7370 6163              spac
+0000c200: 652e 6d61 7869 6d75 6d20 3d20 7365 6c66  e.maximum = self
+0000c210: 2e5f 6170 706c 795f 7472 616e 7366 6f72  ._apply_transfor
+0000c220: 6d28 7370 6163 652e 6d61 7869 6d75 6d29  m(space.maximum)
+0000c230: 0d0a 2020 2020 2020 2020 2020 2020 6f62  ..            ob
+0000c240: 7365 7276 6174 696f 6e5f 7370 6563 2e73  servation_spec.s
+0000c250: 6861 7065 203d 2073 7061 6365 2e6d 696e  hape = space.min
+0000c260: 696d 756d 2e73 6861 7065 0d0a 2020 2020  imum.shape..    
+0000c270: 2020 2020 656c 7365 3a0d 0a20 2020 2020      else:..     
+0000c280: 2020 2020 2020 206f 6273 6572 7661 7469         observati
+0000c290: 6f6e 5f73 7065 632e 7368 6170 6520 3d20  on_spec.shape = 
+0000c2a0: 7365 6c66 2e5f 6170 706c 795f 7472 616e  self._apply_tran
+0000c2b0: 7366 6f72 6d28 0d0a 2020 2020 2020 2020  sform(..        
+0000c2c0: 2020 2020 2020 2020 746f 7263 682e 7a65          torch.ze
+0000c2d0: 726f 7328 6f62 7365 7276 6174 696f 6e5f  ros(observation_
+0000c2e0: 7370 6563 2e73 6861 7065 290d 0a20 2020  spec.shape)..   
+0000c2f0: 2020 2020 2020 2020 2029 2e73 6861 7065           ).shape
+0000c300: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
+0000c310: 206f 6273 6572 7661 7469 6f6e 5f73 7065   observation_spe
+0000c320: 630d 0a0d 0a20 2020 2064 6566 205f 5f72  c....    def __r
+0000c330: 6570 725f 5f28 7365 6c66 2920 2d3e 2073  epr__(self) -> s
+0000c340: 7472 3a0d 0a20 2020 2020 2020 2072 6574  tr:..        ret
+0000c350: 7572 6e20 280d 0a20 2020 2020 2020 2020  urn (..         
+0000c360: 2020 2066 227b 7365 6c66 2e5f 5f63 6c61     f"{self.__cla
+0000c370: 7373 5f5f 2e5f 5f6e 616d 655f 5f7d 2822  ss__.__name__}("
+0000c380: 0d0a 2020 2020 2020 2020 2020 2020 6622  ..            f"
+0000c390: 773d 7b66 6c6f 6174 2873 656c 662e 7729  w={float(self.w)
+0000c3a0: 3a34 2e34 667d 2c20 683d 7b66 6c6f 6174  :4.4f}, h={float
+0000c3b0: 2873 656c 662e 6829 3a34 2e34 667d 2c20  (self.h):4.4f}, 
+0000c3c0: 220d 0a20 2020 2020 2020 2029 0d0a 0d0a  "..        )....
+0000c3d0: 0d0a 636c 6173 7320 466c 6174 7465 6e4f  ..class FlattenO
+0000c3e0: 6273 6572 7661 7469 6f6e 284f 6273 6572  bservation(Obser
+0000c3f0: 7661 7469 6f6e 5472 616e 7366 6f72 6d29  vationTransform)
+0000c400: 3a0d 0a20 2020 2022 2222 466c 6174 7465  :..    """Flatte
+0000c410: 6e20 6164 6a61 6365 6e74 2064 696d 656e  n adjacent dimen
+0000c420: 7369 6f6e 7320 6f66 2061 2074 656e 736f  sions of a tenso
+0000c430: 722e 0d0a 0d0a 2020 2020 4172 6773 3a0d  r.....    Args:.
+0000c440: 0a20 2020 2020 2020 2066 6972 7374 5f64  .        first_d
+0000c450: 696d 2028 696e 7429 3a20 6669 7273 7420  im (int): first 
+0000c460: 6469 6d65 6e73 696f 6e20 6f66 2074 6865  dimension of the
+0000c470: 2064 696d 656e 7369 6f6e 7320 746f 2066   dimensions to f
+0000c480: 6c61 7474 656e 2e0d 0a20 2020 2020 2020  latten...       
+0000c490: 206c 6173 745f 6469 6d20 2869 6e74 293a   last_dim (int):
+0000c4a0: 206c 6173 7420 6469 6d65 6e73 696f 6e20   last dimension 
+0000c4b0: 6f66 2074 6865 2064 696d 656e 7369 6f6e  of the dimension
+0000c4c0: 7320 746f 2066 6c61 7474 656e 2e0d 0a20  s to flatten... 
+0000c4d0: 2020 2020 2020 2069 6e5f 6b65 7973 2028         in_keys (
+0000c4e0: 7365 7175 656e 6365 206f 6620 7374 722c  sequence of str,
+0000c4f0: 206f 7074 696f 6e61 6c29 3a20 7468 6520   optional): the 
+0000c500: 656e 7472 6965 7320 746f 2066 6c61 7474  entries to flatt
+0000c510: 656e 2e20 4966 206e 6f6e 6520 6973 2070  en. If none is p
+0000c520: 726f 7669 6465 642c 0d0a 2020 2020 2020  rovided,..      
+0000c530: 2020 2020 2020 3a6f 626a 3a60 5b22 7069        :obj:`["pi
+0000c540: 7865 6c73 225d 6020 6973 2061 7373 756d  xels"]` is assum
+0000c550: 6564 2e0d 0a20 2020 2020 2020 206f 7574  ed...        out
+0000c560: 5f6b 6579 7320 2873 6571 7565 6e63 6520  _keys (sequence 
+0000c570: 6f66 2073 7472 2c20 6f70 7469 6f6e 616c  of str, optional
+0000c580: 293a 2074 6865 2066 6c61 7474 656e 206f  ): the flatten o
+0000c590: 6273 6572 7661 7469 6f6e 206b 6579 732e  bservation keys.
+0000c5a0: 2049 6620 6e6f 6e65 2069 730d 0a20 2020   If none is..   
+0000c5b0: 2020 2020 2020 2020 2070 726f 7669 6465           provide
+0000c5c0: 642c 203a 6f62 6a3a 6069 6e5f 6b65 7973  d, :obj:`in_keys
+0000c5d0: 6020 6973 2061 7373 756d 6564 2e0d 0a20  ` is assumed... 
+0000c5e0: 2020 2020 2020 2061 6c6c 6f77 5f70 6f73         allow_pos
+0000c5f0: 6974 6976 655f 6469 6d20 2862 6f6f 6c2c  itive_dim (bool,
+0000c600: 206f 7074 696f 6e61 6c29 3a20 6966 2060   optional): if `
+0000c610: 6054 7275 6560 602c 2070 6f73 6974 6976  `True``, positiv
+0000c620: 6520 6469 6d65 6e73 696f 6e73 2061 7265  e dimensions are
+0000c630: 2061 6363 6570 7465 642e 0d0a 2020 2020   accepted...    
+0000c640: 2020 2020 2020 2020 3a6f 626a 3a60 466c          :obj:`Fl
+0000c650: 6174 7465 6e4f 6273 6572 7661 7469 6f6e  attenObservation
+0000c660: 6020 7769 6c6c 206d 6170 2074 6865 7365  ` will map these
+0000c670: 2074 6f20 7468 6520 6e5e 7468 2066 6561   to the n^th fea
+0000c680: 7475 7265 2064 696d 656e 7369 6f6e 0d0a  ture dimension..
+0000c690: 2020 2020 2020 2020 2020 2020 2869 6520              (ie 
+0000c6a0: 6e5e 7468 2064 696d 656e 7369 6f6e 2061  n^th dimension a
+0000c6b0: 6674 6572 2062 6174 6368 2073 697a 6520  fter batch size 
+0000c6c0: 6f66 2070 6172 656e 7420 656e 7629 206f  of parent env) o
+0000c6d0: 6620 7468 6520 696e 7075 7420 7465 6e73  f the input tens
+0000c6e0: 6f72 2e0d 0a20 2020 2020 2020 2020 2020  or...           
+0000c6f0: 2044 6566 6175 6c74 7320 746f 2046 616c   Defaults to Fal
+0000c700: 7365 2c20 6965 2e20 6e6f 6e2d 6e65 6761  se, ie. non-nega
+0000c710: 7469 7665 2064 696d 656e 7369 6f6e 7320  tive dimensions 
+0000c720: 6172 6520 6e6f 7420 7065 726d 6974 7465  are not permitte
+0000c730: 642e 0d0a 2020 2020 2222 220d 0a0d 0a20  d...    """.... 
+0000c740: 2020 2064 6566 205f 5f69 6e69 745f 5f28     def __init__(
+0000c750: 0d0a 2020 2020 2020 2020 7365 6c66 2c0d  ..        self,.
+0000c760: 0a20 2020 2020 2020 2066 6972 7374 5f64  .        first_d
+0000c770: 696d 3a20 696e 742c 0d0a 2020 2020 2020  im: int,..      
+0000c780: 2020 6c61 7374 5f64 696d 3a20 696e 742c    last_dim: int,
+0000c790: 0d0a 2020 2020 2020 2020 696e 5f6b 6579  ..        in_key
+0000c7a0: 733a 204f 7074 696f 6e61 6c5b 5365 7175  s: Optional[Sequ
+0000c7b0: 656e 6365 5b73 7472 5d5d 203d 204e 6f6e  ence[str]] = Non
+0000c7c0: 652c 0d0a 2020 2020 2020 2020 6f75 745f  e,..        out_
+0000c7d0: 6b65 7973 3a20 4f70 7469 6f6e 616c 5b53  keys: Optional[S
+0000c7e0: 6571 7565 6e63 655b 7374 725d 5d20 3d20  equence[str]] = 
+0000c7f0: 4e6f 6e65 2c0d 0a20 2020 2020 2020 2061  None,..        a
+0000c800: 6c6c 6f77 5f70 6f73 6974 6976 655f 6469  llow_positive_di
+0000c810: 6d3a 2062 6f6f 6c20 3d20 4661 6c73 652c  m: bool = False,
+0000c820: 0d0a 2020 2020 293a 0d0a 2020 2020 2020  ..    ):..      
+0000c830: 2020 6966 2069 6e5f 6b65 7973 2069 7320    if in_keys is 
+0000c840: 4e6f 6e65 3a0d 0a20 2020 2020 2020 2020  None:..         
+0000c850: 2020 2069 6e5f 6b65 7973 203d 2049 4d41     in_keys = IMA
+0000c860: 4745 5f4b 4559 5320 2023 2064 6566 6175  GE_KEYS  # defau
+0000c870: 6c74 0d0a 2020 2020 2020 2020 7375 7065  lt..        supe
+0000c880: 7228 292e 5f5f 696e 6974 5f5f 2869 6e5f  r().__init__(in_
+0000c890: 6b65 7973 3d69 6e5f 6b65 7973 2c20 6f75  keys=in_keys, ou
+0000c8a0: 745f 6b65 7973 3d6f 7574 5f6b 6579 7329  t_keys=out_keys)
+0000c8b0: 0d0a 2020 2020 2020 2020 6966 206e 6f74  ..        if not
+0000c8c0: 2061 6c6c 6f77 5f70 6f73 6974 6976 655f   allow_positive_
+0000c8d0: 6469 6d20 616e 6420 6669 7273 745f 6469  dim and first_di
+0000c8e0: 6d20 3e3d 2030 3a0d 0a20 2020 2020 2020  m >= 0:..       
+0000c8f0: 2020 2020 2072 6169 7365 2056 616c 7565       raise Value
+0000c900: 4572 726f 7228 0d0a 2020 2020 2020 2020  Error(..        
+0000c910: 2020 2020 2020 2020 2266 6972 7374 5f64          "first_d
+0000c920: 696d 2073 686f 756c 6420 6265 2073 6d61  im should be sma
+0000c930: 6c6c 6572 2074 6861 6e20 3020 746f 2061  ller than 0 to a
+0000c940: 6363 6f6d 6f64 6174 6520 666f 7220 220d  ccomodate for ".
+0000c950: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000c960: 2022 656e 7673 206f 6620 6469 6666 6572   "envs of differ
+0000c970: 656e 7420 6261 7463 685f 7369 7a65 732e  ent batch_sizes.
+0000c980: 220d 0a20 2020 2020 2020 2020 2020 2029  "..            )
+0000c990: 0d0a 2020 2020 2020 2020 6966 206e 6f74  ..        if not
+0000c9a0: 2061 6c6c 6f77 5f70 6f73 6974 6976 655f   allow_positive_
+0000c9b0: 6469 6d20 616e 6420 6c61 7374 5f64 696d  dim and last_dim
+0000c9c0: 203e 3d20 303a 0d0a 2020 2020 2020 2020   >= 0:..        
+0000c9d0: 2020 2020 7261 6973 6520 5661 6c75 6545      raise ValueE
+0000c9e0: 7272 6f72 280d 0a20 2020 2020 2020 2020  rror(..         
+0000c9f0: 2020 2020 2020 2022 6c61 7374 5f64 696d         "last_dim
+0000ca00: 2073 686f 756c 6420 6265 2073 6d61 6c6c   should be small
+0000ca10: 6572 2074 6861 6e20 3020 746f 2061 6363  er than 0 to acc
+0000ca20: 6f6d 6f64 6174 6520 666f 7220 220d 0a20  omodate for ".. 
+0000ca30: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+0000ca40: 656e 7673 206f 6620 6469 6666 6572 656e  envs of differen
+0000ca50: 7420 6261 7463 685f 7369 7a65 732e 220d  t batch_sizes.".
+0000ca60: 0a20 2020 2020 2020 2020 2020 2029 0d0a  .            )..
+0000ca70: 2020 2020 2020 2020 7365 6c66 2e5f 6669          self._fi
+0000ca80: 7273 745f 6469 6d20 3d20 6669 7273 745f  rst_dim = first_
+0000ca90: 6469 6d0d 0a20 2020 2020 2020 2073 656c  dim..        sel
+0000caa0: 662e 5f6c 6173 745f 6469 6d20 3d20 6c61  f._last_dim = la
+0000cab0: 7374 5f64 696d 0d0a 0d0a 2020 2020 4070  st_dim....    @p
+0000cac0: 726f 7065 7274 790d 0a20 2020 2064 6566  roperty..    def
+0000cad0: 2066 6972 7374 5f64 696d 2873 656c 6629   first_dim(self)
+0000cae0: 3a0d 0a20 2020 2020 2020 2069 6620 7365  :..        if se
+0000caf0: 6c66 2e5f 6669 7273 745f 6469 6d20 3e3d  lf._first_dim >=
+0000cb00: 2030 2061 6e64 2073 656c 662e 7061 7265   0 and self.pare
+0000cb10: 6e74 2069 7320 6e6f 7420 4e6f 6e65 3a0d  nt is not None:.
+0000cb20: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
+0000cb30: 7572 6e20 6c65 6e28 7365 6c66 2e70 6172  urn len(self.par
+0000cb40: 656e 742e 6261 7463 685f 7369 7a65 2920  ent.batch_size) 
+0000cb50: 2b20 7365 6c66 2e5f 6669 7273 745f 6469  + self._first_di
+0000cb60: 6d0d 0a20 2020 2020 2020 2072 6574 7572  m..        retur
+0000cb70: 6e20 7365 6c66 2e5f 6669 7273 745f 6469  n self._first_di
+0000cb80: 6d0d 0a0d 0a20 2020 2040 7072 6f70 6572  m....    @proper
+0000cb90: 7479 0d0a 2020 2020 6465 6620 6c61 7374  ty..    def last
+0000cba0: 5f64 696d 2873 656c 6629 3a0d 0a20 2020  _dim(self):..   
+0000cbb0: 2020 2020 2069 6620 7365 6c66 2e5f 6c61       if self._la
+0000cbc0: 7374 5f64 696d 203e 3d20 3020 616e 6420  st_dim >= 0 and 
+0000cbd0: 7365 6c66 2e70 6172 656e 7420 6973 206e  self.parent is n
+0000cbe0: 6f74 204e 6f6e 653a 0d0a 2020 2020 2020  ot None:..      
+0000cbf0: 2020 2020 2020 7265 7475 726e 206c 656e        return len
+0000cc00: 2873 656c 662e 7061 7265 6e74 2e62 6174  (self.parent.bat
+0000cc10: 6368 5f73 697a 6529 202b 2073 656c 662e  ch_size) + self.
+0000cc20: 5f6c 6173 745f 6469 6d0d 0a20 2020 2020  _last_dim..     
+0000cc30: 2020 2072 6574 7572 6e20 7365 6c66 2e5f     return self._
+0000cc40: 6c61 7374 5f64 696d 0d0a 0d0a 2020 2020  last_dim....    
+0000cc50: 6465 6620 5f61 7070 6c79 5f74 7261 6e73  def _apply_trans
+0000cc60: 666f 726d 2873 656c 662c 206f 6273 6572  form(self, obser
+0000cc70: 7661 7469 6f6e 3a20 746f 7263 682e 5465  vation: torch.Te
+0000cc80: 6e73 6f72 2920 2d3e 2074 6f72 6368 2e54  nsor) -> torch.T
+0000cc90: 656e 736f 723a 0d0a 2020 2020 2020 2020  ensor:..        
+0000cca0: 6f62 7365 7276 6174 696f 6e20 3d20 746f  observation = to
+0000ccb0: 7263 682e 666c 6174 7465 6e28 6f62 7365  rch.flatten(obse
+0000ccc0: 7276 6174 696f 6e2c 2073 656c 662e 6669  rvation, self.fi
+0000ccd0: 7273 745f 6469 6d2c 2073 656c 662e 6c61  rst_dim, self.la
+0000cce0: 7374 5f64 696d 290d 0a20 2020 2020 2020  st_dim)..       
+0000ccf0: 2072 6574 7572 6e20 6f62 7365 7276 6174   return observat
+0000cd00: 696f 6e0d 0a0d 0a20 2020 2066 6f72 7761  ion....    forwa
+0000cd10: 7264 203d 204f 6273 6572 7661 7469 6f6e  rd = Observation
+0000cd20: 5472 616e 7366 6f72 6d2e 5f63 616c 6c0d  Transform._call.
+0000cd30: 0a0d 0a20 2020 2040 5f61 7070 6c79 5f74  ...    @_apply_t
+0000cd40: 6f5f 636f 6d70 6f73 6974 650d 0a20 2020  o_composite..   
+0000cd50: 2064 6566 2074 7261 6e73 666f 726d 5f6f   def transform_o
+0000cd60: 6273 6572 7661 7469 6f6e 5f73 7065 6328  bservation_spec(
+0000cd70: 7365 6c66 2c20 6f62 7365 7276 6174 696f  self, observatio
+0000cd80: 6e5f 7370 6563 3a20 5465 6e73 6f72 5370  n_spec: TensorSp
+0000cd90: 6563 2920 2d3e 2054 656e 736f 7253 7065  ec) -> TensorSpe
+0000cda0: 633a 0d0a 2020 2020 2020 2020 7370 6163  c:..        spac
+0000cdb0: 6520 3d20 6f62 7365 7276 6174 696f 6e5f  e = observation_
+0000cdc0: 7370 6563 2e73 7061 6365 0d0a 0d0a 2020  spec.space....  
+0000cdd0: 2020 2020 2020 6966 2069 7369 6e73 7461        if isinsta
+0000cde0: 6e63 6528 7370 6163 652c 2043 6f6e 7469  nce(space, Conti
+0000cdf0: 6e75 6f75 7342 6f78 293a 0d0a 2020 2020  nuousBox):..    
+0000ce00: 2020 2020 2020 2020 7370 6163 652e 6d69          space.mi
+0000ce10: 6e69 6d75 6d20 3d20 7365 6c66 2e5f 6170  nimum = self._ap
+0000ce20: 706c 795f 7472 616e 7366 6f72 6d28 7370  ply_transform(sp
+0000ce30: 6163 652e 6d69 6e69 6d75 6d29 0d0a 2020  ace.minimum)..  
+0000ce40: 2020 2020 2020 2020 2020 7370 6163 652e            space.
+0000ce50: 6d61 7869 6d75 6d20 3d20 7365 6c66 2e5f  maximum = self._
+0000ce60: 6170 706c 795f 7472 616e 7366 6f72 6d28  apply_transform(
+0000ce70: 7370 6163 652e 6d61 7869 6d75 6d29 0d0a  space.maximum)..
+0000ce80: 2020 2020 2020 2020 2020 2020 6f62 7365              obse
+0000ce90: 7276 6174 696f 6e5f 7370 6563 2e73 6861  rvation_spec.sha
+0000cea0: 7065 203d 2073 7061 6365 2e6d 696e 696d  pe = space.minim
+0000ceb0: 756d 2e73 6861 7065 0d0a 2020 2020 2020  um.shape..      
+0000cec0: 2020 656c 7365 3a0d 0a20 2020 2020 2020    else:..       
+0000ced0: 2020 2020 206f 6273 6572 7661 7469 6f6e       observation
+0000cee0: 5f73 7065 632e 7368 6170 6520 3d20 7365  _spec.shape = se
+0000cef0: 6c66 2e5f 6170 706c 795f 7472 616e 7366  lf._apply_transf
+0000cf00: 6f72 6d28 0d0a 2020 2020 2020 2020 2020  orm(..          
+0000cf10: 2020 2020 2020 746f 7263 682e 7a65 726f        torch.zero
+0000cf20: 7328 6f62 7365 7276 6174 696f 6e5f 7370  s(observation_sp
+0000cf30: 6563 2e73 6861 7065 290d 0a20 2020 2020  ec.shape)..     
+0000cf40: 2020 2020 2020 2029 2e73 6861 7065 0d0a         ).shape..
+0000cf50: 2020 2020 2020 2020 7265 7475 726e 206f          return o
+0000cf60: 6273 6572 7661 7469 6f6e 5f73 7065 630d  bservation_spec.
+0000cf70: 0a0d 0a20 2020 2064 6566 205f 5f72 6570  ...    def __rep
+0000cf80: 725f 5f28 7365 6c66 2920 2d3e 2073 7472  r__(self) -> str
+0000cf90: 3a0d 0a20 2020 2020 2020 2072 6574 7572  :..        retur
+0000cfa0: 6e20 280d 0a20 2020 2020 2020 2020 2020  n (..           
+0000cfb0: 2066 227b 7365 6c66 2e5f 5f63 6c61 7373   f"{self.__class
+0000cfc0: 5f5f 2e5f 5f6e 616d 655f 5f7d 2822 0d0a  __.__name__}("..
+0000cfd0: 2020 2020 2020 2020 2020 2020 6622 6669              f"fi
+0000cfe0: 7273 745f 6469 6d3d 7b69 6e74 2873 656c  rst_dim={int(sel
+0000cff0: 662e 6669 7273 745f 6469 6d29 7d2c 206c  f.first_dim)}, l
+0000d000: 6173 745f 6469 6d3d 7b69 6e74 2873 656c  ast_dim={int(sel
+0000d010: 662e 6c61 7374 5f64 696d 297d 2c20 696e  f.last_dim)}, in
+0000d020: 5f6b 6579 733d 7b73 656c 662e 696e 5f6b  _keys={self.in_k
+0000d030: 6579 737d 2c20 6f75 745f 6b65 7973 3d7b  eys}, out_keys={
+0000d040: 7365 6c66 2e6f 7574 5f6b 6579 737d 2922  self.out_keys})"
+0000d050: 0d0a 2020 2020 2020 2020 290d 0a0d 0a0d  ..        ).....
+0000d060: 0a63 6c61 7373 2055 6e73 7175 6565 7a65  .class Unsqueeze
+0000d070: 5472 616e 7366 6f72 6d28 5472 616e 7366  Transform(Transf
+0000d080: 6f72 6d29 3a0d 0a20 2020 2022 2222 496e  orm):..    """In
+0000d090: 7365 7274 7320 6120 6469 6d65 6e73 696f  serts a dimensio
+0000d0a0: 6e20 6f66 2073 697a 6520 6f6e 6520 6174  n of size one at
+0000d0b0: 2074 6865 2073 7065 6369 6669 6564 2070   the specified p
+0000d0c0: 6f73 6974 696f 6e2e 0d0a 0d0a 2020 2020  osition.....    
+0000d0d0: 4172 6773 3a0d 0a20 2020 2020 2020 2075  Args:..        u
+0000d0e0: 6e73 7175 6565 7a65 5f64 696d 2028 696e  nsqueeze_dim (in
+0000d0f0: 7429 3a20 6469 6d65 6e73 696f 6e20 746f  t): dimension to
+0000d100: 2075 6e73 7175 6565 7a65 2e20 4d75 7374   unsqueeze. Must
+0000d110: 2062 6520 6e65 6761 7469 7665 2028 6f72   be negative (or
+0000d120: 2061 6c6c 6f77 5f70 6f73 6974 6976 655f   allow_positive_
+0000d130: 6469 6d0d 0a20 2020 2020 2020 2020 2020  dim..           
+0000d140: 206d 7573 7420 6265 2074 7572 6e65 6420   must be turned 
+0000d150: 6f6e 292e 0d0a 2020 2020 2020 2020 616c  on)...        al
+0000d160: 6c6f 775f 706f 7369 7469 7665 5f64 696d  low_positive_dim
+0000d170: 2028 626f 6f6c 2c20 6f70 7469 6f6e 616c   (bool, optional
+0000d180: 293a 2069 6620 6060 5472 7565 6060 2c20  ): if ``True``, 
+0000d190: 706f 7369 7469 7665 2064 696d 656e 7369  positive dimensi
+0000d1a0: 6f6e 7320 6172 6520 6163 6365 7074 6564  ons are accepted
+0000d1b0: 2e0d 0a20 2020 2020 2020 2020 2020 203a  ...            :
+0000d1c0: 6f62 6a3a 6055 6e73 7175 6565 7a65 5472  obj:`UnsqueezeTr
+0000d1d0: 616e 7366 6f72 6d60 2077 696c 6c20 6d61  ansform` will ma
+0000d1e0: 7020 7468 6573 6520 746f 2074 6865 206e  p these to the n
+0000d1f0: 5e74 6820 6665 6174 7572 6520 6469 6d65  ^th feature dime
+0000d200: 6e73 696f 6e0d 0a20 2020 2020 2020 2020  nsion..         
+0000d210: 2020 2028 6965 206e 5e74 6820 6469 6d65     (ie n^th dime
+0000d220: 6e73 696f 6e20 6166 7465 7220 6261 7463  nsion after batc
+0000d230: 6820 7369 7a65 206f 6620 7061 7265 6e74  h size of parent
+0000d240: 2065 6e76 2920 6f66 2074 6865 2069 6e70   env) of the inp
+0000d250: 7574 2074 656e 736f 722c 0d0a 2020 2020  ut tensor,..    
+0000d260: 2020 2020 2020 2020 696e 6465 7065 6e64          independ
+0000d270: 656e 746c 7920 6672 6f6d 2074 6865 2074  ently from the t
+0000d280: 656e 736f 7264 6963 7420 6261 7463 6820  ensordict batch 
+0000d290: 7369 7a65 2028 6965 2070 6f73 6974 6976  size (ie positiv
+0000d2a0: 6520 6469 6d73 206d 6179 2062 650d 0a20  e dims may be.. 
+0000d2b0: 2020 2020 2020 2020 2020 2064 616e 6765             dange
+0000d2c0: 726f 7573 2069 6e20 636f 6e74 6578 7473  rous in contexts
+0000d2d0: 2077 6865 7265 2074 656e 736f 7264 6963   where tensordic
+0000d2e0: 7420 6f66 2064 6966 6665 7265 6e74 2062  t of different b
+0000d2f0: 6174 6368 2064 696d 656e 7369 6f6e 0d0a  atch dimension..
+0000d300: 2020 2020 2020 2020 2020 2020 6172 6520              are 
+0000d310: 7061 7373 6564 292e 0d0a 2020 2020 2020  passed)...      
+0000d320: 2020 2020 2020 4465 6661 756c 7473 2074        Defaults t
+0000d330: 6f20 4661 6c73 652c 2069 652e 206e 6f6e  o False, ie. non
+0000d340: 2d6e 6567 6174 6976 6520 6469 6d65 6e73  -negative dimens
+0000d350: 696f 6e73 2061 7265 206e 6f74 2070 6572  ions are not per
+0000d360: 6d69 7474 6564 2e0d 0a20 2020 2022 2222  mitted...    """
+0000d370: 0d0a 0d0a 2020 2020 696e 7665 7274 6962  ....    invertib
+0000d380: 6c65 203d 2054 7275 650d 0a0d 0a20 2020  le = True....   
+0000d390: 2040 636c 6173 736d 6574 686f 640d 0a20   @classmethod.. 
+0000d3a0: 2020 2064 6566 205f 5f6e 6577 5f5f 2863     def __new__(c
+0000d3b0: 6c73 2c20 2a61 7267 732c 202a 2a6b 7761  ls, *args, **kwa
+0000d3c0: 7267 7329 3a0d 0a20 2020 2020 2020 2063  rgs):..        c
+0000d3d0: 6c73 2e5f 756e 7371 7565 657a 655f 6469  ls._unsqueeze_di
+0000d3e0: 6d20 3d20 4e6f 6e65 0d0a 2020 2020 2020  m = None..      
+0000d3f0: 2020 7265 7475 726e 2073 7570 6572 2829    return super()
+0000d400: 2e5f 5f6e 6577 5f5f 2863 6c73 290d 0a0d  .__new__(cls)...
+0000d410: 0a20 2020 2064 6566 205f 5f69 6e69 745f  .    def __init_
+0000d420: 5f28 0d0a 2020 2020 2020 2020 7365 6c66  _(..        self
+0000d430: 2c0d 0a20 2020 2020 2020 2075 6e73 7175  ,..        unsqu
+0000d440: 6565 7a65 5f64 696d 3a20 696e 742c 0d0a  eeze_dim: int,..
+0000d450: 2020 2020 2020 2020 616c 6c6f 775f 706f          allow_po
+0000d460: 7369 7469 7665 5f64 696d 3a20 626f 6f6c  sitive_dim: bool
+0000d470: 203d 2046 616c 7365 2c0d 0a20 2020 2020   = False,..     
+0000d480: 2020 2069 6e5f 6b65 7973 3a20 4f70 7469     in_keys: Opti
+0000d490: 6f6e 616c 5b53 6571 7565 6e63 655b 7374  onal[Sequence[st
+0000d4a0: 725d 5d20 3d20 4e6f 6e65 2c0d 0a20 2020  r]] = None,..   
+0000d4b0: 2020 2020 206f 7574 5f6b 6579 733a 204f       out_keys: O
+0000d4c0: 7074 696f 6e61 6c5b 5365 7175 656e 6365  ptional[Sequence
+0000d4d0: 5b73 7472 5d5d 203d 204e 6f6e 652c 0d0a  [str]] = None,..
+0000d4e0: 2020 2020 2020 2020 696e 5f6b 6579 735f          in_keys_
+0000d4f0: 696e 763a 204f 7074 696f 6e61 6c5b 5365  inv: Optional[Se
+0000d500: 7175 656e 6365 5b73 7472 5d5d 203d 204e  quence[str]] = N
+0000d510: 6f6e 652c 0d0a 2020 2020 2020 2020 6f75  one,..        ou
+0000d520: 745f 6b65 7973 5f69 6e76 3a20 4f70 7469  t_keys_inv: Opti
+0000d530: 6f6e 616c 5b53 6571 7565 6e63 655b 7374  onal[Sequence[st
+0000d540: 725d 5d20 3d20 4e6f 6e65 2c0d 0a20 2020  r]] = None,..   
+0000d550: 2029 3a0d 0a20 2020 2020 2020 2069 6620   ):..        if 
+0000d560: 696e 5f6b 6579 7320 6973 204e 6f6e 653a  in_keys is None:
+0000d570: 0d0a 2020 2020 2020 2020 2020 2020 696e  ..            in
+0000d580: 5f6b 6579 7320 3d20 5b5d 2020 2320 6465  _keys = []  # de
+0000d590: 6661 756c 740d 0a20 2020 2020 2020 2073  fault..        s
+0000d5a0: 7570 6572 2829 2e5f 5f69 6e69 745f 5f28  uper().__init__(
+0000d5b0: 0d0a 2020 2020 2020 2020 2020 2020 696e  ..            in
+0000d5c0: 5f6b 6579 733d 696e 5f6b 6579 732c 0d0a  _keys=in_keys,..
+0000d5d0: 2020 2020 2020 2020 2020 2020 6f75 745f              out_
+0000d5e0: 6b65 7973 3d6f 7574 5f6b 6579 732c 0d0a  keys=out_keys,..
+0000d5f0: 2020 2020 2020 2020 2020 2020 696e 5f6b              in_k
+0000d600: 6579 735f 696e 763d 696e 5f6b 6579 735f  eys_inv=in_keys_
+0000d610: 696e 762c 0d0a 2020 2020 2020 2020 2020  inv,..          
+0000d620: 2020 6f75 745f 6b65 7973 5f69 6e76 3d6f    out_keys_inv=o
+0000d630: 7574 5f6b 6579 735f 696e 762c 0d0a 2020  ut_keys_inv,..  
+0000d640: 2020 2020 2020 290d 0a20 2020 2020 2020        )..       
+0000d650: 2073 656c 662e 616c 6c6f 775f 706f 7369   self.allow_posi
+0000d660: 7469 7665 5f64 696d 203d 2061 6c6c 6f77  tive_dim = allow
+0000d670: 5f70 6f73 6974 6976 655f 6469 6d0d 0a20  _positive_dim.. 
+0000d680: 2020 2020 2020 2069 6620 756e 7371 7565         if unsque
+0000d690: 657a 655f 6469 6d20 3e3d 2030 2061 6e64  eze_dim >= 0 and
+0000d6a0: 206e 6f74 2061 6c6c 6f77 5f70 6f73 6974   not allow_posit
+0000d6b0: 6976 655f 6469 6d3a 0d0a 2020 2020 2020  ive_dim:..      
+0000d6c0: 2020 2020 2020 7261 6973 6520 5275 6e74        raise Runt
+0000d6d0: 696d 6545 7272 6f72 280d 0a20 2020 2020  imeError(..     
+0000d6e0: 2020 2020 2020 2020 2020 2022 756e 7371             "unsq
+0000d6f0: 7565 657a 655f 6469 6d20 7368 6f75 6c64  ueeze_dim should
+0000d700: 2062 6520 736d 616c 6c65 7220 7468 616e   be smaller than
+0000d710: 2030 2074 6f20 6163 636f 6d6f 6461 7465   0 to accomodate
+0000d720: 2066 6f72 2022 0d0a 2020 2020 2020 2020   for "..        
+0000d730: 2020 2020 2020 2020 2265 6e76 7320 6f66          "envs of
+0000d740: 2064 6966 6665 7265 6e74 2062 6174 6368   different batch
+0000d750: 5f73 697a 6573 2e20 5475 726e 2061 6c6c  _sizes. Turn all
+0000d760: 6f77 5f70 6f73 6974 6976 655f 6469 6d20  ow_positive_dim 
+0000d770: 746f 2061 6363 6f6d 6f64 6174 6520 220d  to accomodate ".
+0000d780: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000d790: 2022 666f 7220 706f 7369 7469 7665 2075   "for positive u
+0000d7a0: 6e73 7175 6565 7a65 5f64 696d 2e22 0d0a  nsqueeze_dim."..
+0000d7b0: 2020 2020 2020 2020 2020 2020 290d 0a20              ).. 
+0000d7c0: 2020 2020 2020 2073 656c 662e 5f75 6e73         self._uns
+0000d7d0: 7175 6565 7a65 5f64 696d 203d 2075 6e73  queeze_dim = uns
+0000d7e0: 7175 6565 7a65 5f64 696d 0d0a 0d0a 2020  queeze_dim....  
+0000d7f0: 2020 4070 726f 7065 7274 790d 0a20 2020    @property..   
+0000d800: 2064 6566 2075 6e73 7175 6565 7a65 5f64   def unsqueeze_d
+0000d810: 696d 2873 656c 6629 3a0d 0a20 2020 2020  im(self):..     
+0000d820: 2020 2069 6620 7365 6c66 2e5f 756e 7371     if self._unsq
+0000d830: 7565 657a 655f 6469 6d20 3e3d 2030 2061  ueeze_dim >= 0 a
+0000d840: 6e64 2073 656c 662e 7061 7265 6e74 2069  nd self.parent i
+0000d850: 7320 6e6f 7420 4e6f 6e65 3a0d 0a20 2020  s not None:..   
+0000d860: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
+0000d870: 6c65 6e28 7365 6c66 2e70 6172 656e 742e  len(self.parent.
+0000d880: 6261 7463 685f 7369 7a65 2920 2b20 7365  batch_size) + se
+0000d890: 6c66 2e5f 756e 7371 7565 657a 655f 6469  lf._unsqueeze_di
+0000d8a0: 6d0d 0a20 2020 2020 2020 2072 6574 7572  m..        retur
+0000d8b0: 6e20 7365 6c66 2e5f 756e 7371 7565 657a  n self._unsqueez
+0000d8c0: 655f 6469 6d0d 0a0d 0a20 2020 2064 6566  e_dim....    def
+0000d8d0: 205f 6170 706c 795f 7472 616e 7366 6f72   _apply_transfor
+0000d8e0: 6d28 7365 6c66 2c20 6f62 7365 7276 6174  m(self, observat
+0000d8f0: 696f 6e3a 2074 6f72 6368 2e54 656e 736f  ion: torch.Tenso
+0000d900: 7229 202d 3e20 746f 7263 682e 5465 6e73  r) -> torch.Tens
+0000d910: 6f72 3a0d 0a20 2020 2020 2020 206f 6273  or:..        obs
+0000d920: 6572 7661 7469 6f6e 203d 206f 6273 6572  ervation = obser
+0000d930: 7661 7469 6f6e 2e75 6e73 7175 6565 7a65  vation.unsqueeze
+0000d940: 2873 656c 662e 756e 7371 7565 657a 655f  (self.unsqueeze_
+0000d950: 6469 6d29 0d0a 2020 2020 2020 2020 7265  dim)..        re
+0000d960: 7475 726e 206f 6273 6572 7661 7469 6f6e  turn observation
+0000d970: 0d0a 0d0a 2020 2020 6465 6620 5f69 6e76  ....    def _inv
+0000d980: 5f61 7070 6c79 5f74 7261 6e73 666f 726d  _apply_transform
+0000d990: 2873 656c 662c 206f 6273 6572 7661 7469  (self, observati
+0000d9a0: 6f6e 3a20 746f 7263 682e 5465 6e73 6f72  on: torch.Tensor
+0000d9b0: 2920 2d3e 2074 6f72 6368 2e54 656e 736f  ) -> torch.Tenso
+0000d9c0: 723a 0d0a 2020 2020 2020 2020 6f62 7365  r:..        obse
+0000d9d0: 7276 6174 696f 6e20 3d20 6f62 7365 7276  rvation = observ
+0000d9e0: 6174 696f 6e2e 7371 7565 657a 6528 7365  ation.squeeze(se
+0000d9f0: 6c66 2e75 6e73 7175 6565 7a65 5f64 696d  lf.unsqueeze_dim
+0000da00: 290d 0a20 2020 2020 2020 2072 6574 7572  )..        retur
+0000da10: 6e20 6f62 7365 7276 6174 696f 6e0d 0a0d  n observation...
+0000da20: 0a20 2020 2064 6566 205f 7472 616e 7366  .    def _transf
+0000da30: 6f72 6d5f 7370 6563 2873 656c 662c 2073  orm_spec(self, s
+0000da40: 7065 633a 2054 656e 736f 7253 7065 6329  pec: TensorSpec)
+0000da50: 202d 3e20 4e6f 6e65 3a0d 0a20 2020 2020   -> None:..     
+0000da60: 2020 2073 7061 6365 203d 2073 7065 632e     space = spec.
+0000da70: 7370 6163 650d 0a20 2020 2020 2020 2069  space..        i
+0000da80: 6620 6973 696e 7374 616e 6365 2873 7061  f isinstance(spa
+0000da90: 6365 2c20 436f 6e74 696e 756f 7573 426f  ce, ContinuousBo
+0000daa0: 7829 3a0d 0a20 2020 2020 2020 2020 2020  x):..           
+0000dab0: 2073 7061 6365 2e6d 696e 696d 756d 203d   space.minimum =
+0000dac0: 2073 656c 662e 5f61 7070 6c79 5f74 7261   self._apply_tra
+0000dad0: 6e73 666f 726d 2873 7061 6365 2e6d 696e  nsform(space.min
+0000dae0: 696d 756d 290d 0a20 2020 2020 2020 2020  imum)..         
+0000daf0: 2020 2073 7061 6365 2e6d 6178 696d 756d     space.maximum
+0000db00: 203d 2073 656c 662e 5f61 7070 6c79 5f74   = self._apply_t
+0000db10: 7261 6e73 666f 726d 2873 7061 6365 2e6d  ransform(space.m
+0000db20: 6178 696d 756d 290d 0a20 2020 2020 2020  aximum)..       
+0000db30: 2020 2020 2073 7065 632e 7368 6170 6520       spec.shape 
+0000db40: 3d20 7370 6163 652e 6d69 6e69 6d75 6d2e  = space.minimum.
+0000db50: 7368 6170 650d 0a20 2020 2020 2020 2065  shape..        e
+0000db60: 6c73 653a 0d0a 2020 2020 2020 2020 2020  lse:..          
+0000db70: 2020 7370 6563 2e73 6861 7065 203d 2073    spec.shape = s
+0000db80: 656c 662e 5f61 7070 6c79 5f74 7261 6e73  elf._apply_trans
+0000db90: 666f 726d 2874 6f72 6368 2e7a 6572 6f73  form(torch.zeros
+0000dba0: 2873 7065 632e 7368 6170 6529 292e 7368  (spec.shape)).sh
+0000dbb0: 6170 650d 0a20 2020 2020 2020 2072 6574  ape..        ret
+0000dbc0: 7572 6e20 7370 6563 0d0a 0d0a 2020 2020  urn spec....    
+0000dbd0: 6465 6620 5f69 6e76 5f74 7261 6e73 666f  def _inv_transfo
+0000dbe0: 726d 5f73 7065 6328 7365 6c66 2c20 7370  rm_spec(self, sp
+0000dbf0: 6563 3a20 5465 6e73 6f72 5370 6563 2920  ec: TensorSpec) 
+0000dc00: 2d3e 204e 6f6e 653a 0d0a 2020 2020 2020  -> None:..      
+0000dc10: 2020 7370 6163 6520 3d20 7370 6563 2e73    space = spec.s
+0000dc20: 7061 6365 0d0a 2020 2020 2020 2020 6966  pace..        if
+0000dc30: 2069 7369 6e73 7461 6e63 6528 7370 6163   isinstance(spac
+0000dc40: 652c 2043 6f6e 7469 6e75 6f75 7342 6f78  e, ContinuousBox
+0000dc50: 293a 0d0a 2020 2020 2020 2020 2020 2020  ):..            
+0000dc60: 7370 6163 652e 6d69 6e69 6d75 6d20 3d20  space.minimum = 
+0000dc70: 7365 6c66 2e5f 696e 765f 6170 706c 795f  self._inv_apply_
+0000dc80: 7472 616e 7366 6f72 6d28 7370 6163 652e  transform(space.
+0000dc90: 6d69 6e69 6d75 6d29 0d0a 2020 2020 2020  minimum)..      
+0000dca0: 2020 2020 2020 7370 6163 652e 6d61 7869        space.maxi
+0000dcb0: 6d75 6d20 3d20 7365 6c66 2e5f 696e 765f  mum = self._inv_
+0000dcc0: 6170 706c 795f 7472 616e 7366 6f72 6d28  apply_transform(
+0000dcd0: 7370 6163 652e 6d61 7869 6d75 6d29 0d0a  space.maximum)..
+0000dce0: 2020 2020 2020 2020 2020 2020 7370 6563              spec
+0000dcf0: 2e73 6861 7065 203d 2073 7061 6365 2e6d  .shape = space.m
+0000dd00: 696e 696d 756d 2e73 6861 7065 0d0a 2020  inimum.shape..  
+0000dd10: 2020 2020 2020 656c 7365 3a0d 0a20 2020        else:..   
+0000dd20: 2020 2020 2020 2020 2073 7065 632e 7368           spec.sh
+0000dd30: 6170 6520 3d20 7365 6c66 2e5f 696e 765f  ape = self._inv_
+0000dd40: 6170 706c 795f 7472 616e 7366 6f72 6d28  apply_transform(
+0000dd50: 746f 7263 682e 7a65 726f 7328 7370 6563  torch.zeros(spec
+0000dd60: 2e73 6861 7065 2929 2e73 6861 7065 0d0a  .shape)).shape..
+0000dd70: 2020 2020 2020 2020 7265 7475 726e 2073          return s
+0000dd80: 7065 630d 0a0d 0a20 2020 2040 5f61 7070  pec....    @_app
+0000dd90: 6c79 5f74 6f5f 636f 6d70 6f73 6974 655f  ly_to_composite_
+0000dda0: 696e 760d 0a20 2020 2064 6566 2074 7261  inv..    def tra
+0000ddb0: 6e73 666f 726d 5f69 6e70 7574 5f73 7065  nsform_input_spe
+0000ddc0: 6328 7365 6c66 2c20 696e 7075 745f 7370  c(self, input_sp
+0000ddd0: 6563 3a20 5465 6e73 6f72 5370 6563 2920  ec: TensorSpec) 
+0000dde0: 2d3e 2054 656e 736f 7253 7065 633a 0d0a  -> TensorSpec:..
+0000ddf0: 2020 2020 2020 2020 7265 7475 726e 2073          return s
+0000de00: 656c 662e 5f69 6e76 5f74 7261 6e73 666f  elf._inv_transfo
+0000de10: 726d 5f73 7065 6328 696e 7075 745f 7370  rm_spec(input_sp
+0000de20: 6563 290d 0a0d 0a20 2020 2064 6566 2074  ec)....    def t
+0000de30: 7261 6e73 666f 726d 5f72 6577 6172 645f  ransform_reward_
+0000de40: 7370 6563 2873 656c 662c 2072 6577 6172  spec(self, rewar
+0000de50: 645f 7370 6563 3a20 5465 6e73 6f72 5370  d_spec: TensorSp
+0000de60: 6563 2920 2d3e 2054 656e 736f 7253 7065  ec) -> TensorSpe
+0000de70: 633a 0d0a 2020 2020 2020 2020 6966 2022  c:..        if "
+0000de80: 7265 7761 7264 2220 696e 2073 656c 662e  reward" in self.
+0000de90: 696e 5f6b 6579 733a 0d0a 2020 2020 2020  in_keys:..      
+0000dea0: 2020 2020 2020 7265 7761 7264 5f73 7065        reward_spe
+0000deb0: 6320 3d20 7365 6c66 2e5f 7472 616e 7366  c = self._transf
+0000dec0: 6f72 6d5f 7370 6563 2872 6577 6172 645f  orm_spec(reward_
+0000ded0: 7370 6563 290d 0a20 2020 2020 2020 2072  spec)..        r
+0000dee0: 6574 7572 6e20 7265 7761 7264 5f73 7065  eturn reward_spe
+0000def0: 630d 0a0d 0a20 2020 2040 5f61 7070 6c79  c....    @_apply
+0000df00: 5f74 6f5f 636f 6d70 6f73 6974 650d 0a20  _to_composite.. 
+0000df10: 2020 2064 6566 2074 7261 6e73 666f 726d     def transform
+0000df20: 5f6f 6273 6572 7661 7469 6f6e 5f73 7065  _observation_spe
+0000df30: 6328 7365 6c66 2c20 6f62 7365 7276 6174  c(self, observat
+0000df40: 696f 6e5f 7370 6563 3a20 5465 6e73 6f72  ion_spec: Tensor
+0000df50: 5370 6563 2920 2d3e 2054 656e 736f 7253  Spec) -> TensorS
+0000df60: 7065 633a 0d0a 2020 2020 2020 2020 7265  pec:..        re
+0000df70: 7475 726e 2073 656c 662e 5f74 7261 6e73  turn self._trans
+0000df80: 666f 726d 5f73 7065 6328 6f62 7365 7276  form_spec(observ
+0000df90: 6174 696f 6e5f 7370 6563 290d 0a0d 0a20  ation_spec).... 
+0000dfa0: 2020 2064 6566 205f 5f72 6570 725f 5f28     def __repr__(
+0000dfb0: 7365 6c66 2920 2d3e 2073 7472 3a0d 0a20  self) -> str:.. 
+0000dfc0: 2020 2020 2020 2073 203d 2028 0d0a 2020         s = (..  
+0000dfd0: 2020 2020 2020 2020 2020 6622 7b73 656c            f"{sel
+0000dfe0: 662e 5f5f 636c 6173 735f 5f2e 5f5f 6e61  f.__class__.__na
+0000dff0: 6d65 5f5f 7d28 756e 7371 7565 657a 655f  me__}(unsqueeze_
+0000e000: 6469 6d3d 7b73 656c 662e 756e 7371 7565  dim={self.unsque
+0000e010: 657a 655f 6469 6d7d 2c20 696e 5f6b 6579  eze_dim}, in_key
+0000e020: 733d 7b73 656c 662e 696e 5f6b 6579 737d  s={self.in_keys}
+0000e030: 2c20 6f75 745f 6b65 7973 3d7b 7365 6c66  , out_keys={self
+0000e040: 2e6f 7574 5f6b 6579 737d 2c22 0d0a 2020  .out_keys},"..  
+0000e050: 2020 2020 2020 2020 2020 6622 2069 6e5f            f" in_
+0000e060: 6b65 7973 5f69 6e76 3d7b 7365 6c66 2e69  keys_inv={self.i
+0000e070: 6e5f 6b65 7973 5f69 6e76 7d2c 206f 7574  n_keys_inv}, out
+0000e080: 5f6b 6579 735f 696e 763d 7b73 656c 662e  _keys_inv={self.
+0000e090: 6f75 745f 6b65 7973 5f69 6e76 7d29 220d  out_keys_inv})".
+0000e0a0: 0a20 2020 2020 2020 2029 0d0a 2020 2020  .        )..    
+0000e0b0: 2020 2020 7265 7475 726e 2073 0d0a 0d0a      return s....
+0000e0c0: 0d0a 636c 6173 7320 5371 7565 657a 6554  ..class SqueezeT
+0000e0d0: 7261 6e73 666f 726d 2855 6e73 7175 6565  ransform(Unsquee
+0000e0e0: 7a65 5472 616e 7366 6f72 6d29 3a0d 0a20  zeTransform):.. 
+0000e0f0: 2020 2022 2222 5265 6d6f 7665 7320 6120     """Removes a 
+0000e100: 6469 6d65 6e73 696f 6e20 6f66 2073 697a  dimension of siz
+0000e110: 6520 6f6e 6520 6174 2074 6865 2073 7065  e one at the spe
+0000e120: 6369 6669 6564 2070 6f73 6974 696f 6e2e  cified position.
+0000e130: 0d0a 0d0a 2020 2020 4172 6773 3a0d 0a20  ....    Args:.. 
+0000e140: 2020 2020 2020 2073 7175 6565 7a65 5f64         squeeze_d
+0000e150: 696d 2028 696e 7429 3a20 6469 6d65 6e73  im (int): dimens
+0000e160: 696f 6e20 746f 2073 7175 6565 7a65 2e0d  ion to squeeze..
+0000e170: 0a20 2020 2022 2222 0d0a 0d0a 2020 2020  .    """....    
+0000e180: 696e 7665 7274 6962 6c65 203d 2054 7275  invertible = Tru
+0000e190: 650d 0a0d 0a20 2020 2064 6566 205f 5f69  e....    def __i
+0000e1a0: 6e69 745f 5f28 0d0a 2020 2020 2020 2020  nit__(..        
+0000e1b0: 7365 6c66 2c0d 0a20 2020 2020 2020 2073  self,..        s
+0000e1c0: 7175 6565 7a65 5f64 696d 3a20 696e 742c  queeze_dim: int,
+0000e1d0: 0d0a 2020 2020 2020 2020 2a61 7267 732c  ..        *args,
+0000e1e0: 0d0a 2020 2020 2020 2020 696e 5f6b 6579  ..        in_key
+0000e1f0: 733a 204f 7074 696f 6e61 6c5b 5365 7175  s: Optional[Sequ
+0000e200: 656e 6365 5b73 7472 5d5d 203d 204e 6f6e  ence[str]] = Non
+0000e210: 652c 0d0a 2020 2020 2020 2020 6f75 745f  e,..        out_
+0000e220: 6b65 7973 3a20 4f70 7469 6f6e 616c 5b53  keys: Optional[S
+0000e230: 6571 7565 6e63 655b 7374 725d 5d20 3d20  equence[str]] = 
+0000e240: 4e6f 6e65 2c0d 0a20 2020 2020 2020 2069  None,..        i
+0000e250: 6e5f 6b65 7973 5f69 6e76 3a20 4f70 7469  n_keys_inv: Opti
+0000e260: 6f6e 616c 5b53 6571 7565 6e63 655b 7374  onal[Sequence[st
+0000e270: 725d 5d20 3d20 4e6f 6e65 2c0d 0a20 2020  r]] = None,..   
+0000e280: 2020 2020 206f 7574 5f6b 6579 735f 696e       out_keys_in
+0000e290: 763a 204f 7074 696f 6e61 6c5b 5365 7175  v: Optional[Sequ
+0000e2a0: 656e 6365 5b73 7472 5d5d 203d 204e 6f6e  ence[str]] = Non
+0000e2b0: 652c 0d0a 2020 2020 2020 2020 2a2a 6b77  e,..        **kw
+0000e2c0: 6172 6773 2c0d 0a20 2020 2029 3a0d 0a20  args,..    ):.. 
+0000e2d0: 2020 2020 2020 2073 7570 6572 2829 2e5f         super()._
+0000e2e0: 5f69 6e69 745f 5f28 0d0a 2020 2020 2020  _init__(..      
+0000e2f0: 2020 2020 2020 7371 7565 657a 655f 6469        squeeze_di
+0000e300: 6d2c 0d0a 2020 2020 2020 2020 2020 2020  m,..            
+0000e310: 2a61 7267 732c 0d0a 2020 2020 2020 2020  *args,..        
+0000e320: 2020 2020 696e 5f6b 6579 733d 696e 5f6b      in_keys=in_k
+0000e330: 6579 732c 0d0a 2020 2020 2020 2020 2020  eys,..          
+0000e340: 2020 6f75 745f 6b65 7973 3d6f 7574 5f6b    out_keys=out_k
+0000e350: 6579 732c 0d0a 2020 2020 2020 2020 2020  eys,..          
+0000e360: 2020 696e 5f6b 6579 735f 696e 763d 696e    in_keys_inv=in
+0000e370: 5f6b 6579 735f 696e 762c 0d0a 2020 2020  _keys_inv,..    
+0000e380: 2020 2020 2020 2020 6f75 745f 6b65 7973          out_keys
+0000e390: 5f69 6e76 3d6f 7574 5f6b 6579 735f 696e  _inv=out_keys_in
+0000e3a0: 762c 0d0a 2020 2020 2020 2020 2020 2020  v,..            
+0000e3b0: 2a2a 6b77 6172 6773 2c0d 0a20 2020 2020  **kwargs,..     
+0000e3c0: 2020 2029 0d0a 0d0a 2020 2020 4070 726f     )....    @pro
+0000e3d0: 7065 7274 790d 0a20 2020 2064 6566 2073  perty..    def s
+0000e3e0: 7175 6565 7a65 5f64 696d 2873 656c 6629  queeze_dim(self)
+0000e3f0: 3a0d 0a20 2020 2020 2020 2072 6574 7572  :..        retur
+0000e400: 6e20 7375 7065 7228 292e 756e 7371 7565  n super().unsque
+0000e410: 657a 655f 6469 6d0d 0a0d 0a20 2020 205f  eze_dim....    _
+0000e420: 6170 706c 795f 7472 616e 7366 6f72 6d20  apply_transform 
+0000e430: 3d20 556e 7371 7565 657a 6554 7261 6e73  = UnsqueezeTrans
+0000e440: 666f 726d 2e5f 696e 765f 6170 706c 795f  form._inv_apply_
+0000e450: 7472 616e 7366 6f72 6d0d 0a20 2020 205f  transform..    _
+0000e460: 696e 765f 6170 706c 795f 7472 616e 7366  inv_apply_transf
+0000e470: 6f72 6d20 3d20 556e 7371 7565 657a 6554  orm = UnsqueezeT
+0000e480: 7261 6e73 666f 726d 2e5f 6170 706c 795f  ransform._apply_
+0000e490: 7472 616e 7366 6f72 6d0d 0a0d 0a0d 0a63  transform......c
+0000e4a0: 6c61 7373 2047 7261 7953 6361 6c65 284f  lass GrayScale(O
+0000e4b0: 6273 6572 7661 7469 6f6e 5472 616e 7366  bservationTransf
+0000e4c0: 6f72 6d29 3a0d 0a20 2020 2022 2222 5475  orm):..    """Tu
+0000e4d0: 726e 7320 6120 7069 7865 6c20 6f62 7365  rns a pixel obse
+0000e4e0: 7276 6174 696f 6e20 746f 2067 7261 7973  rvation to grays
+0000e4f0: 6361 6c65 2e22 2222 0d0a 0d0a 2020 2020  cale."""....    
+0000e500: 6465 6620 5f5f 696e 6974 5f5f 280d 0a20  def __init__(.. 
+0000e510: 2020 2020 2020 2073 656c 662c 0d0a 2020         self,..  
+0000e520: 2020 2020 2020 696e 5f6b 6579 733a 204f        in_keys: O
+0000e530: 7074 696f 6e61 6c5b 5365 7175 656e 6365  ptional[Sequence
+0000e540: 5b73 7472 5d5d 203d 204e 6f6e 652c 0d0a  [str]] = None,..
+0000e550: 2020 2020 2020 2020 6f75 745f 6b65 7973          out_keys
+0000e560: 3a20 4f70 7469 6f6e 616c 5b53 6571 7565  : Optional[Seque
+0000e570: 6e63 655b 7374 725d 5d20 3d20 4e6f 6e65  nce[str]] = None
+0000e580: 2c0d 0a20 2020 2029 3a0d 0a20 2020 2020  ,..    ):..     
+0000e590: 2020 2069 6620 696e 5f6b 6579 7320 6973     if in_keys is
+0000e5a0: 204e 6f6e 653a 0d0a 2020 2020 2020 2020   None:..        
+0000e5b0: 2020 2020 696e 5f6b 6579 7320 3d20 494d      in_keys = IM
+0000e5c0: 4147 455f 4b45 5953 0d0a 2020 2020 2020  AGE_KEYS..      
+0000e5d0: 2020 7375 7065 7228 4772 6179 5363 616c    super(GrayScal
+0000e5e0: 652c 2073 656c 6629 2e5f 5f69 6e69 745f  e, self).__init_
+0000e5f0: 5f28 696e 5f6b 6579 733d 696e 5f6b 6579  _(in_keys=in_key
+0000e600: 732c 206f 7574 5f6b 6579 733d 6f75 745f  s, out_keys=out_
+0000e610: 6b65 7973 290d 0a0d 0a20 2020 2064 6566  keys)....    def
+0000e620: 205f 6170 706c 795f 7472 616e 7366 6f72   _apply_transfor
+0000e630: 6d28 7365 6c66 2c20 6f62 7365 7276 6174  m(self, observat
+0000e640: 696f 6e3a 2074 6f72 6368 2e54 656e 736f  ion: torch.Tenso
+0000e650: 7229 202d 3e20 746f 7263 682e 5465 6e73  r) -> torch.Tens
+0000e660: 6f72 3a0d 0a20 2020 2020 2020 206f 6273  or:..        obs
+0000e670: 6572 7661 7469 6f6e 203d 2046 2e72 6762  ervation = F.rgb
+0000e680: 5f74 6f5f 6772 6179 7363 616c 6528 6f62  _to_grayscale(ob
+0000e690: 7365 7276 6174 696f 6e29 0d0a 2020 2020  servation)..    
+0000e6a0: 2020 2020 7265 7475 726e 206f 6273 6572      return obser
+0000e6b0: 7661 7469 6f6e 0d0a 0d0a 2020 2020 405f  vation....    @_
+0000e6c0: 6170 706c 795f 746f 5f63 6f6d 706f 7369  apply_to_composi
+0000e6d0: 7465 0d0a 2020 2020 6465 6620 7472 616e  te..    def tran
+0000e6e0: 7366 6f72 6d5f 6f62 7365 7276 6174 696f  sform_observatio
+0000e6f0: 6e5f 7370 6563 2873 656c 662c 206f 6273  n_spec(self, obs
+0000e700: 6572 7661 7469 6f6e 5f73 7065 633a 2054  ervation_spec: T
+0000e710: 656e 736f 7253 7065 6329 202d 3e20 5465  ensorSpec) -> Te
+0000e720: 6e73 6f72 5370 6563 3a0d 0a20 2020 2020  nsorSpec:..     
+0000e730: 2020 2073 7061 6365 203d 206f 6273 6572     space = obser
+0000e740: 7661 7469 6f6e 5f73 7065 632e 7370 6163  vation_spec.spac
+0000e750: 650d 0a20 2020 2020 2020 2069 6620 6973  e..        if is
+0000e760: 696e 7374 616e 6365 2873 7061 6365 2c20  instance(space, 
+0000e770: 436f 6e74 696e 756f 7573 426f 7829 3a0d  ContinuousBox):.
+0000e780: 0a20 2020 2020 2020 2020 2020 2073 7061  .            spa
+0000e790: 6365 2e6d 696e 696d 756d 203d 2073 656c  ce.minimum = sel
+0000e7a0: 662e 5f61 7070 6c79 5f74 7261 6e73 666f  f._apply_transfo
+0000e7b0: 726d 2873 7061 6365 2e6d 696e 696d 756d  rm(space.minimum
+0000e7c0: 290d 0a20 2020 2020 2020 2020 2020 2073  )..            s
+0000e7d0: 7061 6365 2e6d 6178 696d 756d 203d 2073  pace.maximum = s
+0000e7e0: 656c 662e 5f61 7070 6c79 5f74 7261 6e73  elf._apply_trans
+0000e7f0: 666f 726d 2873 7061 6365 2e6d 6178 696d  form(space.maxim
+0000e800: 756d 290d 0a20 2020 2020 2020 2020 2020  um)..           
+0000e810: 206f 6273 6572 7661 7469 6f6e 5f73 7065   observation_spe
+0000e820: 632e 7368 6170 6520 3d20 7370 6163 652e  c.shape = space.
+0000e830: 6d69 6e69 6d75 6d2e 7368 6170 650d 0a20  minimum.shape.. 
+0000e840: 2020 2020 2020 2065 6c73 653a 0d0a 2020         else:..  
+0000e850: 2020 2020 2020 2020 2020 6f62 7365 7276            observ
+0000e860: 6174 696f 6e5f 7370 6563 2e73 6861 7065  ation_spec.shape
+0000e870: 203d 2073 656c 662e 5f61 7070 6c79 5f74   = self._apply_t
+0000e880: 7261 6e73 666f 726d 280d 0a20 2020 2020  ransform(..     
+0000e890: 2020 2020 2020 2020 2020 2074 6f72 6368             torch
+0000e8a0: 2e7a 6572 6f73 286f 6273 6572 7661 7469  .zeros(observati
+0000e8b0: 6f6e 5f73 7065 632e 7368 6170 6529 0d0a  on_spec.shape)..
+0000e8c0: 2020 2020 2020 2020 2020 2020 292e 7368              ).sh
+0000e8d0: 6170 650d 0a20 2020 2020 2020 2072 6574  ape..        ret
+0000e8e0: 7572 6e20 6f62 7365 7276 6174 696f 6e5f  urn observation_
+0000e8f0: 7370 6563 0d0a 0d0a 0d0a 636c 6173 7320  spec......class 
+0000e900: 4f62 7365 7276 6174 696f 6e4e 6f72 6d28  ObservationNorm(
+0000e910: 4f62 7365 7276 6174 696f 6e54 7261 6e73  ObservationTrans
+0000e920: 666f 726d 293a 0d0a 2020 2020 2222 224f  form):..    """O
+0000e930: 6273 6572 7661 7469 6f6e 2061 6666 696e  bservation affin
+0000e940: 6520 7472 616e 7366 6f72 6d61 7469 6f6e  e transformation
+0000e950: 206c 6179 6572 2e0d 0a0d 0a20 2020 204e   layer.....    N
+0000e960: 6f72 6d61 6c69 7a65 7320 616e 206f 6273  ormalizes an obs
+0000e970: 6572 7661 7469 6f6e 2061 6363 6f72 6469  ervation accordi
+0000e980: 6e67 2074 6f0d 0a0d 0a20 2020 202e 2e20  ng to....    .. 
+0000e990: 6d61 7468 3a3a 0d0a 2020 2020 2020 2020  math::..        
+0000e9a0: 6f62 7320 3d20 6f62 7320 2a20 7363 616c  obs = obs * scal
+0000e9b0: 6520 2b20 6c6f 630d 0a0d 0a20 2020 2041  e + loc....    A
+0000e9c0: 7267 733a 0d0a 2020 2020 2020 2020 6c6f  rgs:..        lo
+0000e9d0: 6320 286e 756d 6265 7220 6f72 2074 656e  c (number or ten
+0000e9e0: 736f 7229 3a20 6c6f 6361 7469 6f6e 206f  sor): location o
+0000e9f0: 6620 7468 6520 6166 6669 6e65 2074 7261  f the affine tra
+0000ea00: 6e73 666f 726d 0d0a 2020 2020 2020 2020  nsform..        
+0000ea10: 7363 616c 6520 286e 756d 6265 7220 6f72  scale (number or
+0000ea20: 2074 656e 736f 7229 3a20 7363 616c 6520   tensor): scale 
+0000ea30: 6f66 2074 6865 2061 6666 696e 6520 7472  of the affine tr
+0000ea40: 616e 7366 6f72 6d0d 0a20 2020 2020 2020  ansform..       
+0000ea50: 2069 6e5f 6b65 7973 2028 6c69 7374 206f   in_keys (list o
+0000ea60: 6620 696e 742c 206f 7074 696f 6e61 6c29  f int, optional)
+0000ea70: 3a20 656e 7472 6965 7320 746f 2062 6520  : entries to be 
+0000ea80: 6e6f 726d 616c 697a 6564 2e20 4465 6661  normalized. Defa
+0000ea90: 756c 7473 2074 6f20 5b22 6f62 7365 7276  ults to ["observ
+0000eaa0: 6174 696f 6e22 2c20 2270 6978 656c 7322  ation", "pixels"
+0000eab0: 5d2e 0d0a 2020 2020 2020 2020 2020 2020  ]...            
+0000eac0: 416c 6c20 656e 7472 6965 7320 7769 6c6c  All entries will
+0000ead0: 2062 6520 6e6f 726d 616c 697a 6564 2077   be normalized w
+0000eae0: 6974 6820 7468 6520 7361 6d65 2076 616c  ith the same val
+0000eaf0: 7565 733a 2069 6620 6120 6469 6666 6572  ues: if a differ
+0000eb00: 656e 7420 6265 6861 7669 6f75 7220 6973  ent behaviour is
+0000eb10: 2064 6573 6972 6564 0d0a 2020 2020 2020   desired..      
+0000eb20: 2020 2020 2020 2865 2e67 2e20 6120 6469        (e.g. a di
+0000eb30: 6666 6572 656e 7420 6e6f 726d 616c 697a  fferent normaliz
+0000eb40: 6174 696f 6e20 666f 7220 7069 7865 6c73  ation for pixels
+0000eb50: 2061 6e64 2073 7461 7465 7329 2064 6966   and states) dif
+0000eb60: 6665 7265 6e74 203a 6f62 6a3a 604f 6273  ferent :obj:`Obs
+0000eb70: 6572 7661 7469 6f6e 4e6f 726d 600d 0a20  ervationNorm`.. 
+0000eb80: 2020 2020 2020 2020 2020 206f 626a 6563             objec
+0000eb90: 7473 2073 686f 756c 6420 6265 2075 7365  ts should be use
+0000eba0: 642e 0d0a 2020 2020 2020 2020 6f75 745f  d...        out_
+0000ebb0: 6b65 7973 2028 6c69 7374 206f 6620 696e  keys (list of in
+0000ebc0: 742c 206f 7074 696f 6e61 6c29 3a20 6f75  t, optional): ou
+0000ebd0: 7470 7574 2065 6e74 7269 6573 2e20 4465  tput entries. De
+0000ebe0: 6661 756c 7473 2074 6f20 7468 6520 7661  faults to the va
+0000ebf0: 6c75 6520 6f66 2060 696e 5f6b 6579 7360  lue of `in_keys`
+0000ec00: 2e0d 0a20 2020 2020 2020 2069 6e5f 6b65  ...        in_ke
+0000ec10: 7973 5f69 6e76 2028 6c69 7374 206f 6620  ys_inv (list of 
+0000ec20: 696e 742c 206f 7074 696f 6e61 6c29 3a20  int, optional): 
+0000ec30: 4f62 7365 7276 6174 696f 6e4e 6f72 6d20  ObservationNorm 
+0000ec40: 616c 736f 2073 7570 706f 7274 7320 696e  also supports in
+0000ec50: 7665 7273 6520 7472 616e 7366 6f72 6d73  verse transforms
+0000ec60: 2e20 5468 6973 2077 696c 6c0d 0a20 2020  . This will..   
+0000ec70: 2020 2020 2020 2020 206f 6e6c 7920 6f63           only oc
+0000ec80: 6375 7220 6966 2061 206c 6973 7420 6f66  cur if a list of
+0000ec90: 206b 6579 7320 6973 2070 726f 7669 6465   keys is provide
+0000eca0: 6420 746f 203a 6f62 6a3a 6069 6e5f 6b65  d to :obj:`in_ke
+0000ecb0: 7973 5f69 6e76 602e 2049 6620 6e6f 6e65  ys_inv`. If none
+0000ecc0: 2069 7320 7072 6f76 6964 6564 2c0d 0a20   is provided,.. 
+0000ecd0: 2020 2020 2020 2020 2020 206f 6e6c 7920             only 
+0000ece0: 7468 6520 666f 7277 6172 6420 7472 616e  the forward tran
+0000ecf0: 7366 6f72 6d20 7769 6c6c 2062 6520 6361  sform will be ca
+0000ed00: 6c6c 6564 2e0d 0a20 2020 2020 2020 206f  lled...        o
+0000ed10: 7574 5f6b 6579 735f 696e 7620 286c 6973  ut_keys_inv (lis
+0000ed20: 7420 6f66 2069 6e74 2c20 6f70 7469 6f6e  t of int, option
+0000ed30: 616c 293a 206f 7574 7075 7420 656e 7472  al): output entr
+0000ed40: 6965 7320 666f 7220 7468 6520 696e 7665  ies for the inve
+0000ed50: 7273 6520 7472 616e 7366 6f72 6d2e 0d0a  rse transform...
+0000ed60: 2020 2020 2020 2020 2020 2020 4465 6661              Defa
+0000ed70: 756c 7473 2074 6f20 7468 6520 7661 6c75  ults to the valu
+0000ed80: 6520 6f66 2060 696e 5f6b 6579 735f 696e  e of `in_keys_in
+0000ed90: 7660 2e0d 0a20 2020 2020 2020 2073 7461  v`...        sta
+0000eda0: 6e64 6172 645f 6e6f 726d 616c 2028 626f  ndard_normal (bo
+0000edb0: 6f6c 2c20 6f70 7469 6f6e 616c 293a 2069  ol, optional): i
+0000edc0: 6620 6060 5472 7565 6060 2c20 7468 6520  f ``True``, the 
+0000edd0: 7472 616e 7366 6f72 6d20 7769 6c6c 2062  transform will b
+0000ede0: 650d 0a0d 0a20 2020 2020 2020 2020 2020  e....           
+0000edf0: 202e 2e20 6d61 7468 3a3a 0d0a 2020 2020   .. math::..    
+0000ee00: 2020 2020 2020 2020 2020 2020 6f62 7320              obs 
+0000ee10: 3d20 286f 6273 2d6c 6f63 292f 7363 616c  = (obs-loc)/scal
+0000ee20: 650d 0a0d 0a20 2020 2020 2020 2020 2020  e....           
+0000ee30: 2061 7320 6974 2069 7320 646f 6e65 2066   as it is done f
+0000ee40: 6f72 2073 7461 6e64 6172 6469 7a61 7469  or standardizati
+0000ee50: 6f6e 2e20 4465 6661 756c 7420 6973 2060  on. Default is `
+0000ee60: 4661 6c73 6560 2e0d 0a0d 0a20 2020 2045  False`.....    E
+0000ee70: 7861 6d70 6c65 733a 0d0a 2020 2020 2020  xamples:..      
+0000ee80: 2020 3e3e 3e20 746f 7263 682e 7365 745f    >>> torch.set_
+0000ee90: 6465 6661 756c 745f 7465 6e73 6f72 5f74  default_tensor_t
+0000eea0: 7970 6528 746f 7263 682e 446f 7562 6c65  ype(torch.Double
+0000eeb0: 5465 6e73 6f72 290d 0a20 2020 2020 2020  Tensor)..       
+0000eec0: 203e 3e3e 2072 203d 2074 6f72 6368 2e72   >>> r = torch.r
+0000eed0: 616e 646e 2831 3030 2c20 3329 2a74 6f72  andn(100, 3)*tor
+0000eee0: 6368 2e72 616e 646e 2833 2920 2b20 746f  ch.randn(3) + to
+0000eef0: 7263 682e 7261 6e64 6e28 3329 0d0a 2020  rch.randn(3)..  
+0000ef00: 2020 2020 2020 3e3e 3e20 7464 203d 2054        >>> td = T
+0000ef10: 656e 736f 7244 6963 7428 7b27 6f62 7327  ensorDict({'obs'
+0000ef20: 3a20 727d 2c20 5b31 3030 5d29 0d0a 2020  : r}, [100])..  
+0000ef30: 2020 2020 2020 3e3e 3e20 7472 616e 7366        >>> transf
+0000ef40: 6f72 6d20 3d20 4f62 7365 7276 6174 696f  orm = Observatio
+0000ef50: 6e4e 6f72 6d28 0d0a 2020 2020 2020 2020  nNorm(..        
+0000ef60: 2e2e 2e20 2020 2020 6c6f 6320 3d20 7464  ...     loc = td
+0000ef70: 2e67 6574 2827 6f62 7327 292e 6d65 616e  .get('obs').mean
+0000ef80: 2830 292c 0d0a 2020 2020 2020 2020 2e2e  (0),..        ..
+0000ef90: 2e20 2020 2020 7363 616c 6520 3d20 7464  .     scale = td
+0000efa0: 2e67 6574 2827 6f62 7327 292e 7374 6428  .get('obs').std(
+0000efb0: 3029 2c0d 0a20 2020 2020 2020 202e 2e2e  0),..        ...
+0000efc0: 2020 2020 2069 6e5f 6b65 7973 3d5b 226f       in_keys=["o
+0000efd0: 6273 225d 2c0d 0a20 2020 2020 2020 202e  bs"],..        .
+0000efe0: 2e2e 2020 2020 2073 7461 6e64 6172 645f  ..     standard_
+0000eff0: 6e6f 726d 616c 3d54 7275 6529 0d0a 2020  normal=True)..  
+0000f000: 2020 2020 2020 3e3e 3e20 5f20 3d20 7472        >>> _ = tr
+0000f010: 616e 7366 6f72 6d28 7464 290d 0a20 2020  ansform(td)..   
+0000f020: 2020 2020 203e 3e3e 2070 7269 6e74 2874       >>> print(t
+0000f030: 6f72 6368 2e69 7363 6c6f 7365 2874 642e  orch.isclose(td.
+0000f040: 6765 7428 276f 6273 2729 2e6d 6561 6e28  get('obs').mean(
+0000f050: 3029 2c0d 0a20 2020 2020 2020 202e 2e2e  0),..        ...
+0000f060: 2020 2020 2074 6f72 6368 2e7a 6572 6f73       torch.zeros
+0000f070: 2833 2929 2e61 6c6c 2829 290d 0a20 2020  (3)).all())..   
+0000f080: 2020 2020 2074 656e 736f 7228 5472 7565       tensor(True
+0000f090: 290d 0a20 2020 2020 2020 203e 3e3e 2070  )..        >>> p
+0000f0a0: 7269 6e74 2874 6f72 6368 2e69 7363 6c6f  rint(torch.isclo
+0000f0b0: 7365 2874 642e 6765 7428 276e 6578 745f  se(td.get('next_
+0000f0c0: 6f62 7327 292e 7374 6428 3029 2c0d 0a20  obs').std(0),.. 
+0000f0d0: 2020 2020 2020 202e 2e2e 2020 2020 2074         ...     t
+0000f0e0: 6f72 6368 2e6f 6e65 7328 3329 292e 616c  orch.ones(3)).al
+0000f0f0: 6c28 2929 0d0a 2020 2020 2020 2020 7465  l())..        te
+0000f100: 6e73 6f72 2854 7275 6529 0d0a 0d0a 2020  nsor(True)....  
+0000f110: 2020 5468 6520 6e6f 726d 616c 697a 6174    The normalizat
+0000f120: 696f 6e20 7374 6174 7320 6361 6e20 6265  ion stats can be
+0000f130: 2061 7574 6f6d 6174 6963 616c 6c79 2063   automatically c
+0000f140: 6f6d 7075 7465 643a 0d0a 2020 2020 4578  omputed:..    Ex
+0000f150: 616d 706c 6573 3a0d 0a20 2020 2020 2020  amples:..       
+0000f160: 203e 3e3e 2066 726f 6d20 746f 7263 6872   >>> from torchr
+0000f170: 6c2e 656e 7673 2e6c 6962 732e 6779 6d20  l.envs.libs.gym 
+0000f180: 696d 706f 7274 2047 796d 456e 760d 0a20  import GymEnv.. 
+0000f190: 2020 2020 2020 203e 3e3e 2074 6f72 6368         >>> torch
+0000f1a0: 2e6d 616e 7561 6c5f 7365 6564 2830 290d  .manual_seed(0).
+0000f1b0: 0a20 2020 2020 2020 203e 3e3e 2065 6e76  .        >>> env
+0000f1c0: 203d 2047 796d 456e 7628 2250 656e 6475   = GymEnv("Pendu
+0000f1d0: 6c75 6d2d 7631 2229 0d0a 2020 2020 2020  lum-v1")..      
+0000f1e0: 2020 3e3e 3e20 656e 7620 3d20 5472 616e    >>> env = Tran
+0000f1f0: 7366 6f72 6d65 6445 6e76 2865 6e76 2c20  sformedEnv(env, 
+0000f200: 4f62 7365 7276 6174 696f 6e4e 6f72 6d28  ObservationNorm(
+0000f210: 696e 5f6b 6579 733d 5b22 6f62 7365 7276  in_keys=["observ
+0000f220: 6174 696f 6e22 5d29 290d 0a20 2020 2020  ation"]))..     
+0000f230: 2020 203e 3e3e 2065 6e76 2e73 6574 5f73     >>> env.set_s
+0000f240: 6565 6428 3029 0d0a 2020 2020 2020 2020  eed(0)..        
+0000f250: 3e3e 3e20 656e 762e 7472 616e 7366 6f72  >>> env.transfor
+0000f260: 6d2e 696e 6974 5f73 7461 7473 2831 3030  m.init_stats(100
+0000f270: 290d 0a20 2020 2020 2020 203e 3e3e 2070  )..        >>> p
+0000f280: 7269 6e74 2865 6e76 2e74 7261 6e73 666f  rint(env.transfo
+0000f290: 726d 2e6c 6f63 2c20 656e 762e 7472 616e  rm.loc, env.tran
+0000f2a0: 7366 6f72 6d2e 7363 616c 6529 0d0a 2020  sform.scale)..  
+0000f2b0: 2020 2020 2020 7465 6e73 6f72 285b 2d31        tensor([-1
+0000f2c0: 2e33 3735 3265 2b30 312c 202d 362e 3530  .3752e+01, -6.50
+0000f2d0: 3837 652d 3033 2c20 2032 2e39 3239 3465  87e-03,  2.9294e
+0000f2e0: 2d30 335d 2c20 6474 7970 653d 746f 7263  -03], dtype=torc
+0000f2f0: 682e 666c 6f61 7433 3229 2074 656e 736f  h.float32) tenso
+0000f300: 7228 5b31 342e 3936 3336 2c20 2032 2e35  r([14.9636,  2.5
+0000f310: 3630 382c 2020 302e 3634 3038 5d2c 2064  608,  0.6408], d
+0000f320: 7479 7065 3d74 6f72 6368 2e66 6c6f 6174  type=torch.float
+0000f330: 3332 290d 0a0d 0a20 2020 2022 2222 0d0a  32)....    """..
+0000f340: 0d0a 2020 2020 5f45 5252 5f49 4e49 545f  ..    _ERR_INIT_
+0000f350: 4d53 4720 3d20 2243 616e 6e6f 7420 6861  MSG = "Cannot ha
+0000f360: 7665 2061 6e20 6d69 7865 6420 696e 6974  ve an mixed init
+0000f370: 6961 6c69 7a65 6420 616e 6420 756e 696e  ialized and unin
+0000f380: 6974 6961 6c69 7a65 6420 6c6f 6320 616e  itialized loc an
+0000f390: 6420 7363 616c 6522 0d0a 0d0a 2020 2020  d scale"....    
+0000f3a0: 6465 6620 5f5f 696e 6974 5f5f 280d 0a20  def __init__(.. 
+0000f3b0: 2020 2020 2020 2073 656c 662c 0d0a 2020         self,..  
+0000f3c0: 2020 2020 2020 6c6f 633a 204f 7074 696f        loc: Optio
+0000f3d0: 6e61 6c5b 666c 6f61 742c 2074 6f72 6368  nal[float, torch
+0000f3e0: 2e54 656e 736f 725d 203d 204e 6f6e 652c  .Tensor] = None,
+0000f3f0: 0d0a 2020 2020 2020 2020 7363 616c 653a  ..        scale:
+0000f400: 204f 7074 696f 6e61 6c5b 666c 6f61 742c   Optional[float,
+0000f410: 2074 6f72 6368 2e54 656e 736f 725d 203d   torch.Tensor] =
+0000f420: 204e 6f6e 652c 0d0a 2020 2020 2020 2020   None,..        
+0000f430: 696e 5f6b 6579 733a 204f 7074 696f 6e61  in_keys: Optiona
+0000f440: 6c5b 5365 7175 656e 6365 5b73 7472 5d5d  l[Sequence[str]]
+0000f450: 203d 204e 6f6e 652c 0d0a 2020 2020 2020   = None,..      
+0000f460: 2020 6f75 745f 6b65 7973 3a20 4f70 7469    out_keys: Opti
+0000f470: 6f6e 616c 5b53 6571 7565 6e63 655b 7374  onal[Sequence[st
+0000f480: 725d 5d20 3d20 4e6f 6e65 2c0d 0a20 2020  r]] = None,..   
+0000f490: 2020 2020 2069 6e5f 6b65 7973 5f69 6e76       in_keys_inv
+0000f4a0: 3a20 4f70 7469 6f6e 616c 5b53 6571 7565  : Optional[Seque
+0000f4b0: 6e63 655b 7374 725d 5d20 3d20 4e6f 6e65  nce[str]] = None
+0000f4c0: 2c0d 0a20 2020 2020 2020 206f 7574 5f6b  ,..        out_k
+0000f4d0: 6579 735f 696e 763a 204f 7074 696f 6e61  eys_inv: Optiona
+0000f4e0: 6c5b 5365 7175 656e 6365 5b73 7472 5d5d  l[Sequence[str]]
+0000f4f0: 203d 204e 6f6e 652c 0d0a 2020 2020 2020   = None,..      
+0000f500: 2020 7374 616e 6461 7264 5f6e 6f72 6d61    standard_norma
+0000f510: 6c3a 2062 6f6f 6c20 3d20 4661 6c73 652c  l: bool = False,
+0000f520: 0d0a 2020 2020 293a 0d0a 2020 2020 2020  ..    ):..      
+0000f530: 2020 6966 2069 6e5f 6b65 7973 2069 7320    if in_keys is 
+0000f540: 4e6f 6e65 3a0d 0a20 2020 2020 2020 2020  None:..         
+0000f550: 2020 2069 6e5f 6b65 7973 203d 205b 0d0a     in_keys = [..
+0000f560: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f570: 226f 6273 6572 7661 7469 6f6e 222c 0d0a  "observation",..
+0000f580: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f590: 2270 6978 656c 7322 2c0d 0a20 2020 2020  "pixels",..     
+0000f5a0: 2020 2020 2020 205d 0d0a 2020 2020 2020         ]..      
+0000f5b0: 2020 7375 7065 7228 292e 5f5f 696e 6974    super().__init
+0000f5c0: 5f5f 280d 0a20 2020 2020 2020 2020 2020  __(..           
+0000f5d0: 2069 6e5f 6b65 7973 3d69 6e5f 6b65 7973   in_keys=in_keys
+0000f5e0: 2c0d 0a20 2020 2020 2020 2020 2020 206f  ,..            o
+0000f5f0: 7574 5f6b 6579 733d 6f75 745f 6b65 7973  ut_keys=out_keys
+0000f600: 2c0d 0a20 2020 2020 2020 2020 2020 2069  ,..            i
+0000f610: 6e5f 6b65 7973 5f69 6e76 3d69 6e5f 6b65  n_keys_inv=in_ke
+0000f620: 7973 5f69 6e76 2c0d 0a20 2020 2020 2020  ys_inv,..       
+0000f630: 2020 2020 206f 7574 5f6b 6579 735f 696e       out_keys_in
+0000f640: 763d 6f75 745f 6b65 7973 5f69 6e76 2c0d  v=out_keys_inv,.
+0000f650: 0a20 2020 2020 2020 2029 0d0a 2020 2020  .        )..    
+0000f660: 2020 2020 6966 206e 6f74 2069 7369 6e73      if not isins
+0000f670: 7461 6e63 6528 7374 616e 6461 7264 5f6e  tance(standard_n
+0000f680: 6f72 6d61 6c2c 2074 6f72 6368 2e54 656e  ormal, torch.Ten
+0000f690: 736f 7229 3a0d 0a20 2020 2020 2020 2020  sor):..         
+0000f6a0: 2020 2073 7461 6e64 6172 645f 6e6f 726d     standard_norm
+0000f6b0: 616c 203d 2074 6f72 6368 2e74 656e 736f  al = torch.tenso
+0000f6c0: 7228 7374 616e 6461 7264 5f6e 6f72 6d61  r(standard_norma
+0000f6d0: 6c29 0d0a 2020 2020 2020 2020 7365 6c66  l)..        self
+0000f6e0: 2e72 6567 6973 7465 725f 6275 6666 6572  .register_buffer
+0000f6f0: 2822 7374 616e 6461 7264 5f6e 6f72 6d61  ("standard_norma
+0000f700: 6c22 2c20 7374 616e 6461 7264 5f6e 6f72  l", standard_nor
+0000f710: 6d61 6c29 0d0a 2020 2020 2020 2020 7365  mal)..        se
+0000f720: 6c66 2e65 7073 203d 2031 652d 360d 0a0d  lf.eps = 1e-6...
+0000f730: 0a20 2020 2020 2020 2069 6620 6c6f 6320  .        if loc 
+0000f740: 6973 206e 6f74 204e 6f6e 6520 616e 6420  is not None and 
+0000f750: 6e6f 7420 6973 696e 7374 616e 6365 286c  not isinstance(l
+0000f760: 6f63 2c20 746f 7263 682e 5465 6e73 6f72  oc, torch.Tensor
+0000f770: 293a 0d0a 2020 2020 2020 2020 2020 2020  ):..            
+0000f780: 6c6f 6320 3d20 746f 7263 682e 7465 6e73  loc = torch.tens
+0000f790: 6f72 286c 6f63 2c20 6474 7970 653d 746f  or(loc, dtype=to
+0000f7a0: 7263 682e 6765 745f 6465 6661 756c 745f  rch.get_default_
+0000f7b0: 6474 7970 6528 2929 0d0a 2020 2020 2020  dtype())..      
+0000f7c0: 2020 656c 6966 206c 6f63 2069 7320 4e6f    elif loc is No
+0000f7d0: 6e65 3a0d 0a20 2020 2020 2020 2020 2020  ne:..           
+0000f7e0: 2069 6620 7363 616c 6520 6973 206e 6f74   if scale is not
+0000f7f0: 204e 6f6e 653a 0d0a 2020 2020 2020 2020   None:..        
+0000f800: 2020 2020 2020 2020 7261 6973 6520 5661          raise Va
+0000f810: 6c75 6545 7272 6f72 2873 656c 662e 5f45  lueError(self._E
+0000f820: 5252 5f49 4e49 545f 4d53 4729 0d0a 2020  RR_INIT_MSG)..  
+0000f830: 2020 2020 2020 2020 2020 6c6f 6320 3d20            loc = 
+0000f840: 6e6e 2e55 6e69 6e69 7469 616c 697a 6564  nn.Uninitialized
+0000f850: 4275 6666 6572 2829 0d0a 0d0a 2020 2020  Buffer()....    
+0000f860: 2020 2020 6966 2073 6361 6c65 2069 7320      if scale is 
+0000f870: 6e6f 7420 4e6f 6e65 2061 6e64 206e 6f74  not None and not
+0000f880: 2069 7369 6e73 7461 6e63 6528 7363 616c   isinstance(scal
+0000f890: 652c 2074 6f72 6368 2e54 656e 736f 7229  e, torch.Tensor)
+0000f8a0: 3a0d 0a20 2020 2020 2020 2020 2020 2073  :..            s
+0000f8b0: 6361 6c65 203d 2074 6f72 6368 2e74 656e  cale = torch.ten
+0000f8c0: 736f 7228 7363 616c 652c 2064 7479 7065  sor(scale, dtype
+0000f8d0: 3d74 6f72 6368 2e67 6574 5f64 6566 6175  =torch.get_defau
+0000f8e0: 6c74 5f64 7479 7065 2829 290d 0a20 2020  lt_dtype())..   
+0000f8f0: 2020 2020 2020 2020 2073 6361 6c65 203d           scale =
+0000f900: 2073 6361 6c65 2e63 6c61 6d70 5f6d 696e   scale.clamp_min
+0000f910: 2873 656c 662e 6570 7329 0d0a 2020 2020  (self.eps)..    
+0000f920: 2020 2020 656c 6966 2073 6361 6c65 2069      elif scale i
+0000f930: 7320 4e6f 6e65 3a0d 0a20 2020 2020 2020  s None:..       
+0000f940: 2020 2020 2023 2063 6865 636b 2074 6861       # check tha
+0000f950: 7420 6c6f 6320 6973 204e 6f6e 6520 746f  t loc is None to
+0000f960: 6f0d 0a20 2020 2020 2020 2020 2020 2069  o..            i
+0000f970: 6620 6e6f 7420 6973 696e 7374 616e 6365  f not isinstance
+0000f980: 286c 6f63 2c20 6e6e 2e55 6e69 6e69 7469  (loc, nn.Uniniti
+0000f990: 616c 697a 6564 4275 6666 6572 293a 0d0a  alizedBuffer):..
+0000f9a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f9b0: 7261 6973 6520 5661 6c75 6545 7272 6f72  raise ValueError
+0000f9c0: 2873 656c 662e 5f45 5252 5f49 4e49 545f  (self._ERR_INIT_
+0000f9d0: 4d53 4729 0d0a 2020 2020 2020 2020 2020  MSG)..          
+0000f9e0: 2020 7363 616c 6520 3d20 6e6e 2e55 6e69    scale = nn.Uni
+0000f9f0: 6e69 7469 616c 697a 6564 4275 6666 6572  nitializedBuffer
+0000fa00: 2829 0d0a 0d0a 2020 2020 2020 2020 2320  ()....        # 
+0000fa10: 7365 6c66 2e6f 6273 6572 7661 7469 6f6e  self.observation
+0000fa20: 5f73 7065 635f 6b65 7920 3d20 6f62 7365  _spec_key = obse
+0000fa30: 7276 6174 696f 6e5f 7370 6563 5f6b 6579  rvation_spec_key
+0000fa40: 0d0a 2020 2020 2020 2020 7365 6c66 2e72  ..        self.r
+0000fa50: 6567 6973 7465 725f 6275 6666 6572 2822  egister_buffer("
+0000fa60: 6c6f 6322 2c20 6c6f 6329 0d0a 2020 2020  loc", loc)..    
+0000fa70: 2020 2020 7365 6c66 2e72 6567 6973 7465      self.registe
+0000fa80: 725f 6275 6666 6572 2822 7363 616c 6522  r_buffer("scale"
+0000fa90: 2c20 7363 616c 6529 0d0a 0d0a 2020 2020  , scale)....    
+0000faa0: 4070 726f 7065 7274 790d 0a20 2020 2064  @property..    d
+0000fab0: 6566 2069 6e69 7469 616c 697a 6564 2873  ef initialized(s
+0000fac0: 656c 6629 3a0d 0a20 2020 2020 2020 2072  elf):..        r
+0000fad0: 6574 7572 6e20 6e6f 7420 6973 696e 7374  eturn not isinst
+0000fae0: 616e 6365 2873 656c 662e 6c6f 632c 206e  ance(self.loc, n
+0000faf0: 6e2e 556e 696e 6974 6961 6c69 7a65 6442  n.UninitializedB
+0000fb00: 7566 6665 7229 0d0a 0d0a 2020 2020 6465  uffer)....    de
+0000fb10: 6620 696e 6974 5f73 7461 7473 280d 0a20  f init_stats(.. 
+0000fb20: 2020 2020 2020 2073 656c 662c 0d0a 2020         self,..  
+0000fb30: 2020 2020 2020 6e75 6d5f 6974 6572 3a20        num_iter: 
+0000fb40: 696e 742c 0d0a 2020 2020 2020 2020 7265  int,..        re
+0000fb50: 6475 6365 5f64 696d 3a20 556e 696f 6e5b  duce_dim: Union[
+0000fb60: 696e 742c 2054 7570 6c65 5b69 6e74 5d5d  int, Tuple[int]]
+0000fb70: 203d 2030 2c0d 0a20 2020 2020 2020 2063   = 0,..        c
+0000fb80: 6174 5f64 696d 3a20 4f70 7469 6f6e 616c  at_dim: Optional
+0000fb90: 5b69 6e74 5d20 3d20 4e6f 6e65 2c0d 0a20  [int] = None,.. 
+0000fba0: 2020 2020 2020 206b 6579 3a20 4f70 7469         key: Opti
+0000fbb0: 6f6e 616c 5b73 7472 5d20 3d20 4e6f 6e65  onal[str] = None
+0000fbc0: 2c0d 0a20 2020 2020 2020 206b 6565 705f  ,..        keep_
+0000fbd0: 6469 6d73 3a20 4f70 7469 6f6e 616c 5b54  dims: Optional[T
+0000fbe0: 7570 6c65 5b69 6e74 5d5d 203d 204e 6f6e  uple[int]] = Non
+0000fbf0: 652c 0d0a 2020 2020 2920 2d3e 204e 6f6e  e,..    ) -> Non
+0000fc00: 653a 0d0a 2020 2020 2020 2020 2222 2249  e:..        """I
+0000fc10: 6e69 7469 616c 697a 6573 2074 6865 206c  nitializes the l
+0000fc20: 6f63 2061 6e64 2073 6361 6c65 2073 7461  oc and scale sta
+0000fc30: 7473 206f 6620 7468 6520 7061 7265 6e74  ts of the parent
+0000fc40: 2065 6e76 6972 6f6e 6d65 6e74 2e0d 0a0d   environment....
+0000fc50: 0a20 2020 2020 2020 204e 6f72 6d61 6c69  .        Normali
+0000fc60: 7a61 7469 6f6e 2063 6f6e 7374 616e 7420  zation constant 
+0000fc70: 7368 6f75 6c64 2069 6465 616c 6c79 206d  should ideally m
+0000fc80: 616b 6520 7468 6520 6f62 7365 7276 6174  ake the observat
+0000fc90: 696f 6e20 7374 6174 6973 7469 6373 2061  ion statistics a
+0000fca0: 7070 726f 6163 680d 0a20 2020 2020 2020  pproach..       
+0000fcb0: 2074 686f 7365 206f 6620 6120 7374 616e   those of a stan
+0000fcc0: 6461 7264 2047 6175 7373 6961 6e20 6469  dard Gaussian di
+0000fcd0: 7374 7269 6275 7469 6f6e 2e20 5468 6973  stribution. This
+0000fce0: 206d 6574 686f 6420 636f 6d70 7574 6573   method computes
+0000fcf0: 2061 206c 6f63 6174 696f 6e0d 0a20 2020   a location..   
+0000fd00: 2020 2020 2061 6e64 2073 6361 6c65 2074       and scale t
+0000fd10: 656e 736f 7220 7468 6174 2077 696c 6c20  ensor that will 
+0000fd20: 656d 7069 7269 6361 6c6c 7920 636f 6d70  empirically comp
+0000fd30: 7574 6520 7468 6520 6d65 616e 2061 6e64  ute the mean and
+0000fd40: 2073 7461 6e64 6172 640d 0a20 2020 2020   standard..     
+0000fd50: 2020 2064 6576 6961 7469 6f6e 206f 6620     deviation of 
+0000fd60: 6120 4761 7573 7369 616e 2064 6973 7472  a Gaussian distr
+0000fd70: 6962 7574 696f 6e20 6669 7474 6564 206f  ibution fitted o
+0000fd80: 6e20 6461 7461 2067 656e 6572 6174 6564  n data generated
+0000fd90: 2072 616e 646f 6d6c 7920 7769 7468 0d0a   randomly with..
+0000fda0: 2020 2020 2020 2020 7468 6520 7061 7265          the pare
+0000fdb0: 6e74 2065 6e76 6972 6f6e 6d65 6e74 2066  nt environment f
+0000fdc0: 6f72 2061 2067 6976 656e 206e 756d 6265  or a given numbe
+0000fdd0: 7220 6f66 2073 7465 7073 2e0d 0a0d 0a20  r of steps..... 
+0000fde0: 2020 2020 2020 2041 7267 733a 0d0a 2020         Args:..  
+0000fdf0: 2020 2020 2020 2020 2020 6e75 6d5f 6974            num_it
+0000fe00: 6572 2028 696e 7429 3a20 6e75 6d62 6572  er (int): number
+0000fe10: 206f 6620 7261 6e64 6f6d 2069 7465 7261   of random itera
+0000fe20: 7469 6f6e 7320 746f 2072 756e 2069 6e20  tions to run in 
+0000fe30: 7468 6520 656e 7669 726f 6e6d 656e 742e  the environment.
+0000fe40: 0d0a 2020 2020 2020 2020 2020 2020 7265  ..            re
+0000fe50: 6475 6365 5f64 696d 2028 696e 7420 6f72  duce_dim (int or
+0000fe60: 2074 7570 6c65 206f 6620 696e 742c 206f   tuple of int, o
+0000fe70: 7074 696f 6e61 6c29 3a20 6469 6d65 6e73  ptional): dimens
+0000fe80: 696f 6e20 746f 2063 6f6d 7075 7465 2074  ion to compute t
+0000fe90: 6865 206d 6561 6e20 616e 6420 7374 6420  he mean and std 
+0000fea0: 6f76 6572 2e0d 0a20 2020 2020 2020 2020  over...         
+0000feb0: 2020 2020 2020 2044 6566 6175 6c74 7320         Defaults 
+0000fec0: 746f 2030 2e0d 0a20 2020 2020 2020 2020  to 0...         
+0000fed0: 2020 2063 6174 5f64 696d 2028 696e 742c     cat_dim (int,
+0000fee0: 206f 7074 696f 6e61 6c29 3a20 6469 6d65   optional): dime
+0000fef0: 6e73 696f 6e20 616c 6f6e 6720 7768 6963  nsion along whic
+0000ff00: 6820 7468 6520 6261 7463 6865 7320 636f  h the batches co
+0000ff10: 6c6c 6563 7465 6420 7769 6c6c 2062 6520  llected will be 
+0000ff20: 636f 6e63 6174 656e 6174 6564 2e0d 0a20  concatenated... 
+0000ff30: 2020 2020 2020 2020 2020 2020 2020 2049                 I
+0000ff40: 7420 6d75 7374 2062 6520 7061 7274 2065  t must be part e
+0000ff50: 7175 616c 2074 6f20 7265 6475 6365 5f64  qual to reduce_d
+0000ff60: 696d 2028 6966 2069 6e74 6567 6572 2920  im (if integer) 
+0000ff70: 6f72 2070 6172 7420 6f66 2074 6865 2072  or part of the r
+0000ff80: 6564 7563 655f 6469 6d20 7475 706c 652e  educe_dim tuple.
+0000ff90: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+0000ffa0: 2020 4465 6661 756c 7473 2074 6f20 7468    Defaults to th
+0000ffb0: 6520 7361 6d65 2076 616c 7565 2061 7320  e same value as 
+0000ffc0: 7265 6475 6365 5f64 696d 2e0d 0a20 2020  reduce_dim...   
+0000ffd0: 2020 2020 2020 2020 206b 6579 2028 7374           key (st
+0000ffe0: 722c 206f 7074 696f 6e61 6c29 3a20 6966  r, optional): if
+0000fff0: 2070 726f 7669 6465 642c 2074 6865 2073   provided, the s
+00010000: 756d 6d61 7279 2073 7461 7469 7374 6963  ummary statistic
+00010010: 7320 7769 6c6c 2062 650d 0a20 2020 2020  s will be..     
+00010020: 2020 2020 2020 2020 2020 2072 6574 7269             retri
+00010030: 6576 6564 2066 726f 6d20 7468 6174 206b  eved from that k
+00010040: 6579 2069 6e20 7468 6520 7265 7375 6c74  ey in the result
+00010050: 696e 6720 7465 6e73 6f72 6469 6374 732e  ing tensordicts.
+00010060: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00010070: 2020 4f74 6865 7277 6973 652c 2074 6865    Otherwise, the
+00010080: 2066 6972 7374 206b 6579 2069 6e20 3a6f   first key in :o
+00010090: 626a 3a60 4f62 7365 7276 6174 696f 6e4e  bj:`ObservationN
+000100a0: 6f72 6d2e 696e 5f6b 6579 7360 2077 696c  orm.in_keys` wil
+000100b0: 6c20 6265 2075 7365 642e 0d0a 2020 2020  l be used...    
+000100c0: 2020 2020 2020 2020 6b65 6570 5f64 696d          keep_dim
+000100d0: 7320 2874 7570 6c65 206f 6620 696e 742c  s (tuple of int,
+000100e0: 206f 7074 696f 6e61 6c29 3a20 7468 6520   optional): the 
+000100f0: 6469 6d65 6e73 696f 6e73 2074 6f20 6b65  dimensions to ke
+00010100: 6570 2069 6e20 7468 6520 6c6f 6320 616e  ep in the loc an
+00010110: 6420 7363 616c 652e 0d0a 2020 2020 2020  d scale...      
+00010120: 2020 2020 2020 2020 2020 466f 7220 696e            For in
+00010130: 7374 616e 6365 2c20 6f6e 6520 6d61 7920  stance, one may 
+00010140: 7761 6e74 2074 6865 206c 6f63 6174 696f  want the locatio
+00010150: 6e20 616e 6420 7363 616c 6520 746f 2068  n and scale to h
+00010160: 6176 6520 7368 6170 6520 5b43 2c20 312c  ave shape [C, 1,
+00010170: 2031 5d0d 0a20 2020 2020 2020 2020 2020   1]..           
+00010180: 2020 2020 2077 6865 6e20 6e6f 726d 616c       when normal
+00010190: 697a 696e 6720 6120 3344 2074 656e 736f  izing a 3D tenso
+000101a0: 7220 6f76 6572 2074 6865 206c 6173 7420  r over the last 
+000101b0: 7477 6f20 6469 6d65 6e73 696f 6e73 2c20  two dimensions, 
+000101c0: 6275 7420 6e6f 7420 7468 650d 0a20 2020  but not the..   
+000101d0: 2020 2020 2020 2020 2020 2020 2074 6869               thi
+000101e0: 7264 2e20 4465 6661 756c 7473 2074 6f20  rd. Defaults to 
+000101f0: 4e6f 6e65 2e0d 0a0d 0a20 2020 2020 2020  None.....       
+00010200: 2022 2222 0d0a 2020 2020 2020 2020 6966   """..        if
+00010210: 2063 6174 5f64 696d 2069 7320 4e6f 6e65   cat_dim is None
+00010220: 3a0d 0a20 2020 2020 2020 2020 2020 2063  :..            c
+00010230: 6174 5f64 696d 203d 2072 6564 7563 655f  at_dim = reduce_
+00010240: 6469 6d0d 0a20 2020 2020 2020 2020 2020  dim..           
+00010250: 2069 6620 6e6f 7420 6973 696e 7374 616e   if not isinstan
+00010260: 6365 2863 6174 5f64 696d 2c20 696e 7429  ce(cat_dim, int)
+00010270: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
+00010280: 2020 2072 6169 7365 2056 616c 7565 4572     raise ValueEr
+00010290: 726f 7228 0d0a 2020 2020 2020 2020 2020  ror(..          
+000102a0: 2020 2020 2020 2020 2020 2263 6174 5f64            "cat_d
+000102b0: 696d 206d 7573 7420 6265 2073 7065 6369  im must be speci
+000102c0: 6669 6564 2069 6620 7265 6475 6365 5f64  fied if reduce_d
+000102d0: 696d 2069 7320 6e6f 7420 616e 2069 6e74  im is not an int
+000102e0: 6567 6572 2e22 0d0a 2020 2020 2020 2020  eger."..        
+000102f0: 2020 2020 2020 2020 290d 0a20 2020 2020          )..     
+00010300: 2020 2069 6620 2869 7369 6e73 7461 6e63     if (isinstanc
+00010310: 6528 7265 6475 6365 5f64 696d 2c20 7475  e(reduce_dim, tu
+00010320: 706c 6529 2061 6e64 2063 6174 5f64 696d  ple) and cat_dim
+00010330: 206e 6f74 2069 6e20 7265 6475 6365 5f64   not in reduce_d
+00010340: 696d 2920 6f72 2028 0d0a 2020 2020 2020  im) or (..      
+00010350: 2020 2020 2020 6973 696e 7374 616e 6365        isinstance
+00010360: 2872 6564 7563 655f 6469 6d2c 2069 6e74  (reduce_dim, int
+00010370: 2920 616e 6420 6361 745f 6469 6d20 213d  ) and cat_dim !=
+00010380: 2072 6564 7563 655f 6469 6d0d 0a20 2020   reduce_dim..   
+00010390: 2020 2020 2029 3a0d 0a20 2020 2020 2020       ):..       
+000103a0: 2020 2020 2072 6169 7365 2056 616c 7565       raise Value
+000103b0: 4572 726f 7228 2263 6174 5f64 696d 206d  Error("cat_dim m
+000103c0: 7573 7420 6265 2070 6172 7420 6f66 206f  ust be part of o
+000103d0: 7220 6571 7561 6c20 746f 2072 6564 7563  r equal to reduc
+000103e0: 655f 6469 6d2e 2229 0d0a 2020 2020 2020  e_dim.")..      
+000103f0: 2020 6966 2073 656c 662e 696e 6974 6961    if self.initia
+00010400: 6c69 7a65 643a 0d0a 2020 2020 2020 2020  lized:..        
+00010410: 2020 2020 7261 6973 6520 5275 6e74 696d      raise Runtim
+00010420: 6545 7272 6f72 280d 0a20 2020 2020 2020  eError(..       
+00010430: 2020 2020 2020 2020 2066 224c 6f63 2f53           f"Loc/S
+00010440: 6361 6c65 2061 7265 2061 6c72 6561 6479  cale are already
+00010450: 2069 6e69 7469 616c 697a 6564 3a20 287b   initialized: ({
+00010460: 7365 6c66 2e6c 6f63 7d2c 207b 7365 6c66  self.loc}, {self
+00010470: 2e73 6361 6c65 7d29 220d 0a20 2020 2020  .scale})"..     
+00010480: 2020 2020 2020 2029 0d0a 0d0a 2020 2020         )....    
+00010490: 2020 2020 6966 206c 656e 2873 656c 662e      if len(self.
+000104a0: 696e 5f6b 6579 7329 203e 2031 2061 6e64  in_keys) > 1 and
+000104b0: 206b 6579 2069 7320 4e6f 6e65 3a0d 0a20   key is None:.. 
+000104c0: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+000104d0: 2052 756e 7469 6d65 4572 726f 7228 0d0a   RuntimeError(..
+000104e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000104f0: 2254 7261 6e73 666f 726d 2068 6173 206d  "Transform has m
+00010500: 756c 7469 706c 6520 696e 5f6b 6579 7320  ultiple in_keys 
+00010510: 6275 7420 6e6f 2073 7065 6369 6669 6320  but no specific 
+00010520: 6b65 7920 7761 7320 7061 7373 6564 2061  key was passed a
+00010530: 7320 616e 2061 7267 756d 656e 7422 0d0a  s an argument"..
+00010540: 2020 2020 2020 2020 2020 2020 290d 0a20              ).. 
+00010550: 2020 2020 2020 206b 6579 203d 2073 656c         key = sel
+00010560: 662e 696e 5f6b 6579 735b 305d 2069 6620  f.in_keys[0] if 
+00010570: 6b65 7920 6973 204e 6f6e 6520 656c 7365  key is None else
+00010580: 206b 6579 0d0a 0d0a 2020 2020 2020 2020   key....        
+00010590: 6465 6620 7261 6973 655f 696e 6974 6961  def raise_initia
+000105a0: 6c69 7a61 7469 6f6e 5f65 7863 6570 7469  lization_excepti
+000105b0: 6f6e 286d 6f64 756c 6529 3a0d 0a20 2020  on(module):..   
+000105c0: 2020 2020 2020 2020 2069 6620 6973 696e           if isin
+000105d0: 7374 616e 6365 286d 6f64 756c 652c 204f  stance(module, O
+000105e0: 6273 6572 7661 7469 6f6e 4e6f 726d 2920  bservationNorm) 
+000105f0: 616e 6420 6e6f 7420 6d6f 6475 6c65 2e69  and not module.i
+00010600: 6e69 7469 616c 697a 6564 3a0d 0a20 2020  nitialized:..   
+00010610: 2020 2020 2020 2020 2020 2020 2072 6169               rai
+00010620: 7365 2052 756e 7469 6d65 4572 726f 7228  se RuntimeError(
+00010630: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00010640: 2020 2020 2020 224f 6273 6572 7661 7469        "Observati
+00010650: 6f6e 4e6f 726d 7320 6e65 6564 2074 6f20  onNorms need to 
+00010660: 6265 2069 6e69 7469 616c 697a 6564 2069  be initialized i
+00010670: 6e20 7468 6520 7269 6768 7420 6f72 6465  n the right orde
+00010680: 722e 220d 0a20 2020 2020 2020 2020 2020  r."..           
+00010690: 2020 2020 2020 2020 2022 5472 7969 6e67           "Trying
+000106a0: 2074 6f20 696e 6974 6961 6c69 7a65 2061   to initialize a
+000106b0: 6e20 4f62 7365 7276 6174 696f 6e4e 6f72  n ObservationNor
+000106c0: 6d20 220d 0a20 2020 2020 2020 2020 2020  m "..           
+000106d0: 2020 2020 2020 2020 2022 7768 696c 6520           "while 
+000106e0: 6120 7061 7265 6e74 204f 6273 6572 7661  a parent Observa
+000106f0: 7469 6f6e 4e6f 726d 2074 7261 6e73 666f  tionNorm transfo
+00010700: 726d 2069 7320 7374 696c 6c20 756e 696e  rm is still unin
+00010710: 6974 6961 6c69 7a65 6422 0d0a 2020 2020  itialized"..    
+00010720: 2020 2020 2020 2020 2020 2020 290d 0a0d              )...
+00010730: 0a20 2020 2020 2020 2070 6172 656e 7420  .        parent 
+00010740: 3d20 7365 6c66 2e70 6172 656e 740d 0a20  = self.parent.. 
+00010750: 2020 2020 2020 2069 6620 7061 7265 6e74         if parent
+00010760: 2069 7320 4e6f 6e65 3a0d 0a20 2020 2020   is None:..     
+00010770: 2020 2020 2020 2072 6169 7365 2052 756e         raise Run
+00010780: 7469 6d65 4572 726f 7228 0d0a 2020 2020  timeError(..    
+00010790: 2020 2020 2020 2020 2020 2020 2243 616e              "Can
+000107a0: 6e6f 7420 696e 6974 6961 6c69 7a65 2074  not initialize t
+000107b0: 6865 2074 7261 6e73 666f 726d 2069 6620  he transform if 
+000107c0: 7061 7265 6e74 2065 6e76 2069 7320 6e6f  parent env is no
+000107d0: 7420 6465 6669 6e65 642e 220d 0a20 2020  t defined."..   
+000107e0: 2020 2020 2020 2020 2029 0d0a 2020 2020           )..    
+000107f0: 2020 2020 7061 7265 6e74 2e61 7070 6c79      parent.apply
+00010800: 2872 6169 7365 5f69 6e69 7469 616c 697a  (raise_initializ
+00010810: 6174 696f 6e5f 6578 6365 7074 696f 6e29  ation_exception)
+00010820: 0d0a 0d0a 2020 2020 2020 2020 636f 6c6c  ....        coll
+00010830: 6563 7465 645f 6672 616d 6573 203d 2030  ected_frames = 0
+00010840: 0d0a 2020 2020 2020 2020 6461 7461 203d  ..        data =
+00010850: 205b 5d0d 0a20 2020 2020 2020 2077 6869   []..        whi
+00010860: 6c65 2063 6f6c 6c65 6374 6564 5f66 7261  le collected_fra
+00010870: 6d65 7320 3c20 6e75 6d5f 6974 6572 3a0d  mes < num_iter:.
+00010880: 0a20 2020 2020 2020 2020 2020 2074 656e  .            ten
+00010890: 736f 7264 6963 7420 3d20 7061 7265 6e74  sordict = parent
+000108a0: 2e72 6f6c 6c6f 7574 286d 6178 5f73 7465  .rollout(max_ste
+000108b0: 7073 3d6e 756d 5f69 7465 7229 0d0a 2020  ps=num_iter)..  
+000108c0: 2020 2020 2020 2020 2020 636f 6c6c 6563            collec
+000108d0: 7465 645f 6672 616d 6573 202b 3d20 7465  ted_frames += te
+000108e0: 6e73 6f72 6469 6374 2e6e 756d 656c 2829  nsordict.numel()
+000108f0: 0d0a 2020 2020 2020 2020 2020 2020 6461  ..            da
+00010900: 7461 2e61 7070 656e 6428 7465 6e73 6f72  ta.append(tensor
+00010910: 6469 6374 2e67 6574 286b 6579 2929 0d0a  dict.get(key))..
+00010920: 0d0a 2020 2020 2020 2020 6461 7461 203d  ..        data =
+00010930: 2074 6f72 6368 2e63 6174 2864 6174 612c   torch.cat(data,
+00010940: 2063 6174 5f64 696d 290d 0a20 2020 2020   cat_dim)..     
+00010950: 2020 2069 6620 6973 696e 7374 616e 6365     if isinstance
+00010960: 2872 6564 7563 655f 6469 6d2c 2069 6e74  (reduce_dim, int
+00010970: 293a 0d0a 2020 2020 2020 2020 2020 2020  ):..            
+00010980: 7265 6475 6365 5f64 696d 203d 205b 7265  reduce_dim = [re
+00010990: 6475 6365 5f64 696d 5d0d 0a20 2020 2020  duce_dim]..     
+000109a0: 2020 2069 6620 6b65 6570 5f64 696d 7320     if keep_dims 
+000109b0: 6973 206e 6f74 204e 6f6e 653a 0d0a 2020  is not None:..  
+000109c0: 2020 2020 2020 2020 2020 6966 206e 6f74            if not
+000109d0: 2061 6c6c 286b 2069 6e20 7265 6475 6365   all(k in reduce
+000109e0: 5f64 696d 2066 6f72 206b 2069 6e20 6b65  _dim for k in ke
+000109f0: 6570 5f64 696d 7329 3a0d 0a20 2020 2020  ep_dims):..     
+00010a00: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+00010a10: 2056 616c 7565 4572 726f 7228 226b 6565   ValueError("kee
+00010a20: 705f 6469 6d20 656c 656d 656e 7473 206d  p_dim elements m
+00010a30: 7573 7420 6265 2070 6172 7420 6f66 2072  ust be part of r
+00010a40: 6564 7563 655f 6469 6d20 6c69 7374 2e22  educe_dim list."
+00010a50: 290d 0a20 2020 2020 2020 2065 6c73 653a  )..        else:
+00010a60: 0d0a 2020 2020 2020 2020 2020 2020 6b65  ..            ke
+00010a70: 6570 5f64 696d 7320 3d20 5b5d 0d0a 2020  ep_dims = []..  
+00010a80: 2020 2020 2020 6c6f 6320 3d20 6461 7461        loc = data
+00010a90: 2e6d 6561 6e28 7265 6475 6365 5f64 696d  .mean(reduce_dim
+00010aa0: 2c20 6b65 6570 6469 6d3d 5472 7565 290d  , keepdim=True).
+00010ab0: 0a20 2020 2020 2020 2073 6361 6c65 203d  .        scale =
+00010ac0: 2064 6174 612e 7374 6428 7265 6475 6365   data.std(reduce
+00010ad0: 5f64 696d 2c20 6b65 6570 6469 6d3d 5472  _dim, keepdim=Tr
+00010ae0: 7565 290d 0a20 2020 2020 2020 2066 6f72  ue)..        for
+00010af0: 2072 2069 6e20 736f 7274 6564 2872 6564   r in sorted(red
+00010b00: 7563 655f 6469 6d2c 2072 6576 6572 7365  uce_dim, reverse
+00010b10: 3d54 7275 6529 3a0d 0a20 2020 2020 2020  =True):..       
+00010b20: 2020 2020 2069 6620 7220 6e6f 7420 696e       if r not in
+00010b30: 206b 6565 705f 6469 6d73 3a0d 0a20 2020   keep_dims:..   
+00010b40: 2020 2020 2020 2020 2020 2020 206c 6f63               loc
+00010b50: 203d 206c 6f63 2e73 7175 6565 7a65 2872   = loc.squeeze(r
+00010b60: 290d 0a20 2020 2020 2020 2020 2020 2020  )..             
+00010b70: 2020 2073 6361 6c65 203d 2073 6361 6c65     scale = scale
+00010b80: 2e73 7175 6565 7a65 2872 290d 0a0d 0a20  .squeeze(r).... 
+00010b90: 2020 2020 2020 2069 6620 6e6f 7420 7365         if not se
+00010ba0: 6c66 2e73 7461 6e64 6172 645f 6e6f 726d  lf.standard_norm
+00010bb0: 616c 3a0d 0a20 2020 2020 2020 2020 2020  al:..           
+00010bc0: 2073 6361 6c65 203d 2031 202f 2073 6361   scale = 1 / sca
+00010bd0: 6c65 2e63 6c61 6d70 5f6d 696e 2873 656c  le.clamp_min(sel
+00010be0: 662e 6570 7329 0d0a 2020 2020 2020 2020  f.eps)..        
+00010bf0: 2020 2020 6c6f 6320 3d20 2d6c 6f63 202a      loc = -loc *
+00010c00: 2073 6361 6c65 0d0a 0d0a 2020 2020 2020   scale....      
+00010c10: 2020 6966 206e 6f74 2074 6f72 6368 2e69    if not torch.i
+00010c20: 7366 696e 6974 6528 6c6f 6329 2e61 6c6c  sfinite(loc).all
+00010c30: 2829 3a0d 0a20 2020 2020 2020 2020 2020  ():..           
+00010c40: 2072 6169 7365 2052 756e 7469 6d65 4572   raise RuntimeEr
+00010c50: 726f 7228 224e 6f6e 2d66 696e 6974 6520  ror("Non-finite 
+00010c60: 7661 6c75 6573 2066 6f75 6e64 2069 6e20  values found in 
+00010c70: 6c6f 6322 290d 0a20 2020 2020 2020 2069  loc")..        i
+00010c80: 6620 6e6f 7420 746f 7263 682e 6973 6669  f not torch.isfi
+00010c90: 6e69 7465 2873 6361 6c65 292e 616c 6c28  nite(scale).all(
+00010ca0: 293a 0d0a 2020 2020 2020 2020 2020 2020  ):..            
+00010cb0: 7261 6973 6520 5275 6e74 696d 6545 7272  raise RuntimeErr
+00010cc0: 6f72 2822 4e6f 6e2d 6669 6e69 7465 2076  or("Non-finite v
+00010cd0: 616c 7565 7320 666f 756e 6420 696e 2073  alues found in s
+00010ce0: 6361 6c65 2229 0d0a 2020 2020 2020 2020  cale")..        
+00010cf0: 7365 6c66 2e6c 6f63 2e6d 6174 6572 6961  self.loc.materia
+00010d00: 6c69 7a65 2873 6861 7065 3d6c 6f63 2e73  lize(shape=loc.s
+00010d10: 6861 7065 2c20 6474 7970 653d 6c6f 632e  hape, dtype=loc.
+00010d20: 6474 7970 6529 0d0a 2020 2020 2020 2020  dtype)..        
+00010d30: 7365 6c66 2e6c 6f63 2e63 6f70 795f 286c  self.loc.copy_(l
+00010d40: 6f63 290d 0a20 2020 2020 2020 2073 656c  oc)..        sel
+00010d50: 662e 7363 616c 652e 6d61 7465 7269 616c  f.scale.material
+00010d60: 697a 6528 7368 6170 653d 7363 616c 652e  ize(shape=scale.
+00010d70: 7368 6170 652c 2064 7479 7065 3d73 6361  shape, dtype=sca
+00010d80: 6c65 2e64 7479 7065 290d 0a20 2020 2020  le.dtype)..     
+00010d90: 2020 2073 656c 662e 7363 616c 652e 636f     self.scale.co
+00010da0: 7079 5f28 7363 616c 652e 636c 616d 705f  py_(scale.clamp_
+00010db0: 6d69 6e28 7365 6c66 2e65 7073 2929 0d0a  min(self.eps))..
+00010dc0: 0d0a 2020 2020 6465 6620 5f61 7070 6c79  ..    def _apply
+00010dd0: 5f74 7261 6e73 666f 726d 2873 656c 662c  _transform(self,
+00010de0: 206f 6273 3a20 746f 7263 682e 5465 6e73   obs: torch.Tens
+00010df0: 6f72 2920 2d3e 2074 6f72 6368 2e54 656e  or) -> torch.Ten
+00010e00: 736f 723a 0d0a 2020 2020 2020 2020 6966  sor:..        if
+00010e10: 206e 6f74 2073 656c 662e 696e 6974 6961   not self.initia
+00010e20: 6c69 7a65 643a 0d0a 2020 2020 2020 2020  lized:..        
+00010e30: 2020 2020 7261 6973 6520 5275 6e74 696d      raise Runtim
+00010e40: 6545 7272 6f72 280d 0a20 2020 2020 2020  eError(..       
+00010e50: 2020 2020 2020 2020 2022 4c6f 632f 5363           "Loc/Sc
+00010e60: 616c 6520 6861 7665 206e 6f74 2062 6565  ale have not bee
+00010e70: 6e20 696e 6974 6961 6c69 7a65 642e 2045  n initialized. E
+00010e80: 6974 6865 7220 7061 7373 2069 6e20 7661  ither pass in va
+00010e90: 6c75 6573 2069 6e20 7468 6520 636f 6e73  lues in the cons
+00010ea0: 7472 7563 746f 7220 220d 0a20 2020 2020  tructor "..     
+00010eb0: 2020 2020 2020 2020 2020 2022 6f72 2063             "or c
+00010ec0: 616c 6c20 7468 6520 696e 6974 5f73 7461  all the init_sta
+00010ed0: 7473 206d 6574 686f 6422 0d0a 2020 2020  ts method"..    
+00010ee0: 2020 2020 2020 2020 290d 0a20 2020 2020          )..     
+00010ef0: 2020 2069 6620 7365 6c66 2e73 7461 6e64     if self.stand
+00010f00: 6172 645f 6e6f 726d 616c 3a0d 0a20 2020  ard_normal:..   
+00010f10: 2020 2020 2020 2020 206c 6f63 203d 2073           loc = s
+00010f20: 656c 662e 6c6f 630d 0a20 2020 2020 2020  elf.loc..       
+00010f30: 2020 2020 2073 6361 6c65 203d 2073 656c       scale = sel
+00010f40: 662e 7363 616c 650d 0a20 2020 2020 2020  f.scale..       
+00010f50: 2020 2020 2072 6574 7572 6e20 286f 6273       return (obs
+00010f60: 202d 206c 6f63 2920 2f20 7363 616c 650d   - loc) / scale.
+00010f70: 0a20 2020 2020 2020 2065 6c73 653a 0d0a  .        else:..
+00010f80: 2020 2020 2020 2020 2020 2020 7363 616c              scal
+00010f90: 6520 3d20 7365 6c66 2e73 6361 6c65 0d0a  e = self.scale..
+00010fa0: 2020 2020 2020 2020 2020 2020 6c6f 6320              loc 
+00010fb0: 3d20 7365 6c66 2e6c 6f63 0d0a 2020 2020  = self.loc..    
+00010fc0: 2020 2020 2020 2020 7265 7475 726e 206f          return o
+00010fd0: 6273 202a 2073 6361 6c65 202b 206c 6f63  bs * scale + loc
+00010fe0: 0d0a 0d0a 2020 2020 6465 6620 5f69 6e76  ....    def _inv
+00010ff0: 5f61 7070 6c79 5f74 7261 6e73 666f 726d  _apply_transform
+00011000: 2873 656c 662c 206f 6273 3a20 746f 7263  (self, obs: torc
+00011010: 682e 5465 6e73 6f72 2920 2d3e 2074 6f72  h.Tensor) -> tor
+00011020: 6368 2e54 656e 736f 723a 0d0a 2020 2020  ch.Tensor:..    
+00011030: 2020 2020 6966 2073 656c 662e 6c6f 6320      if self.loc 
+00011040: 6973 204e 6f6e 6520 6f72 2073 656c 662e  is None or self.
+00011050: 7363 616c 6520 6973 204e 6f6e 653a 0d0a  scale is None:..
+00011060: 2020 2020 2020 2020 2020 2020 7261 6973              rais
+00011070: 6520 5275 6e74 696d 6545 7272 6f72 280d  e RuntimeError(.
+00011080: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00011090: 2022 4c6f 632f 5363 616c 6520 6861 7665   "Loc/Scale have
+000110a0: 206e 6f74 2062 6565 6e20 696e 6974 6961   not been initia
+000110b0: 6c69 7a65 642e 2045 6974 6865 7220 7061  lized. Either pa
+000110c0: 7373 2069 6e20 7661 6c75 6573 2069 6e20  ss in values in 
+000110d0: 7468 6520 636f 6e73 7472 7563 746f 7220  the constructor 
+000110e0: 220d 0a20 2020 2020 2020 2020 2020 2020  "..             
+000110f0: 2020 2022 6f72 2063 616c 6c20 7468 6520     "or call the 
+00011100: 696e 6974 5f73 7461 7473 206d 6574 686f  init_stats metho
+00011110: 6422 0d0a 2020 2020 2020 2020 2020 2020  d"..            
+00011120: 290d 0a20 2020 2020 2020 2069 6620 6e6f  )..        if no
+00011130: 7420 7365 6c66 2e73 7461 6e64 6172 645f  t self.standard_
+00011140: 6e6f 726d 616c 3a0d 0a20 2020 2020 2020  normal:..       
+00011150: 2020 2020 206c 6f63 203d 2073 656c 662e       loc = self.
+00011160: 6c6f 630d 0a20 2020 2020 2020 2020 2020  loc..           
+00011170: 2073 6361 6c65 203d 2073 656c 662e 7363   scale = self.sc
+00011180: 616c 650d 0a20 2020 2020 2020 2020 2020  ale..           
+00011190: 2072 6574 7572 6e20 286f 6273 202d 206c   return (obs - l
+000111a0: 6f63 2920 2f20 7363 616c 650d 0a20 2020  oc) / scale..   
+000111b0: 2020 2020 2065 6c73 653a 0d0a 2020 2020       else:..    
+000111c0: 2020 2020 2020 2020 7363 616c 6520 3d20          scale = 
+000111d0: 7365 6c66 2e73 6361 6c65 0d0a 2020 2020  self.scale..    
+000111e0: 2020 2020 2020 2020 6c6f 6320 3d20 7365          loc = se
+000111f0: 6c66 2e6c 6f63 0d0a 2020 2020 2020 2020  lf.loc..        
+00011200: 2020 2020 7265 7475 726e 206f 6273 202a      return obs *
+00011210: 2073 6361 6c65 202b 206c 6f63 0d0a 0d0a   scale + loc....
+00011220: 2020 2020 405f 6170 706c 795f 746f 5f63      @_apply_to_c
+00011230: 6f6d 706f 7369 7465 0d0a 2020 2020 6465  omposite..    de
+00011240: 6620 7472 616e 7366 6f72 6d5f 6f62 7365  f transform_obse
+00011250: 7276 6174 696f 6e5f 7370 6563 2873 656c  rvation_spec(sel
+00011260: 662c 206f 6273 6572 7661 7469 6f6e 5f73  f, observation_s
+00011270: 7065 633a 2054 656e 736f 7253 7065 6329  pec: TensorSpec)
+00011280: 202d 3e20 5465 6e73 6f72 5370 6563 3a0d   -> TensorSpec:.
+00011290: 0a20 2020 2020 2020 2073 7061 6365 203d  .        space =
+000112a0: 206f 6273 6572 7661 7469 6f6e 5f73 7065   observation_spe
+000112b0: 632e 7370 6163 650d 0a20 2020 2020 2020  c.space..       
+000112c0: 2069 6620 6973 696e 7374 616e 6365 2873   if isinstance(s
+000112d0: 7061 6365 2c20 436f 6e74 696e 756f 7573  pace, Continuous
+000112e0: 426f 7829 3a0d 0a20 2020 2020 2020 2020  Box):..         
+000112f0: 2020 2073 7061 6365 2e6d 696e 696d 756d     space.minimum
+00011300: 203d 2073 656c 662e 5f61 7070 6c79 5f74   = self._apply_t
+00011310: 7261 6e73 666f 726d 2873 7061 6365 2e6d  ransform(space.m
+00011320: 696e 696d 756d 290d 0a20 2020 2020 2020  inimum)..       
+00011330: 2020 2020 2073 7061 6365 2e6d 6178 696d       space.maxim
+00011340: 756d 203d 2073 656c 662e 5f61 7070 6c79  um = self._apply
+00011350: 5f74 7261 6e73 666f 726d 2873 7061 6365  _transform(space
+00011360: 2e6d 6178 696d 756d 290d 0a20 2020 2020  .maximum)..     
+00011370: 2020 2072 6574 7572 6e20 6f62 7365 7276     return observ
+00011380: 6174 696f 6e5f 7370 6563 0d0a 0d0a 2020  ation_spec....  
+00011390: 2020 405f 6170 706c 795f 746f 5f63 6f6d    @_apply_to_com
+000113a0: 706f 7369 7465 5f69 6e76 0d0a 2020 2020  posite_inv..    
+000113b0: 6465 6620 7472 616e 7366 6f72 6d5f 696e  def transform_in
+000113c0: 7075 745f 7370 6563 2873 656c 662c 2069  put_spec(self, i
+000113d0: 6e70 7574 5f73 7065 633a 2054 656e 736f  nput_spec: Tenso
+000113e0: 7253 7065 6329 202d 3e20 5465 6e73 6f72  rSpec) -> Tensor
+000113f0: 5370 6563 3a0d 0a20 2020 2020 2020 2073  Spec:..        s
+00011400: 7061 6365 203d 2069 6e70 7574 5f73 7065  pace = input_spe
+00011410: 632e 7370 6163 650d 0a20 2020 2020 2020  c.space..       
+00011420: 2069 6620 6973 696e 7374 616e 6365 2873   if isinstance(s
+00011430: 7061 6365 2c20 436f 6e74 696e 756f 7573  pace, Continuous
+00011440: 426f 7829 3a0d 0a20 2020 2020 2020 2020  Box):..         
+00011450: 2020 2073 7061 6365 2e6d 696e 696d 756d     space.minimum
+00011460: 203d 2073 656c 662e 5f61 7070 6c79 5f74   = self._apply_t
+00011470: 7261 6e73 666f 726d 2873 7061 6365 2e6d  ransform(space.m
+00011480: 696e 696d 756d 290d 0a20 2020 2020 2020  inimum)..       
+00011490: 2020 2020 2073 7061 6365 2e6d 6178 696d       space.maxim
+000114a0: 756d 203d 2073 656c 662e 5f61 7070 6c79  um = self._apply
+000114b0: 5f74 7261 6e73 666f 726d 2873 7061 6365  _transform(space
+000114c0: 2e6d 6178 696d 756d 290d 0a20 2020 2020  .maximum)..     
+000114d0: 2020 2072 6574 7572 6e20 696e 7075 745f     return input_
+000114e0: 7370 6563 0d0a 0d0a 2020 2020 6465 6620  spec....    def 
+000114f0: 5f5f 7265 7072 5f5f 2873 656c 6629 202d  __repr__(self) -
+00011500: 3e20 7374 723a 0d0a 2020 2020 2020 2020  > str:..        
+00011510: 6966 2073 656c 662e 696e 6974 6961 6c69  if self.initiali
+00011520: 7a65 6420 616e 6420 2873 656c 662e 6c6f  zed and (self.lo
+00011530: 632e 6e75 6d65 6c28 2920 3d3d 2031 2061  c.numel() == 1 a
+00011540: 6e64 2073 656c 662e 7363 616c 652e 6e75  nd self.scale.nu
+00011550: 6d65 6c28 2920 3d3d 2031 293a 0d0a 2020  mel() == 1):..  
+00011560: 2020 2020 2020 2020 2020 7265 7475 726e            return
+00011570: 2028 0d0a 2020 2020 2020 2020 2020 2020   (..            
+00011580: 2020 2020 6622 7b73 656c 662e 5f5f 636c      f"{self.__cl
+00011590: 6173 735f 5f2e 5f5f 6e61 6d65 5f5f 7d28  ass__.__name__}(
+000115a0: 220d 0a20 2020 2020 2020 2020 2020 2020  "..             
+000115b0: 2020 2066 226c 6f63 3d7b 666c 6f61 7428     f"loc={float(
+000115c0: 7365 6c66 2e6c 6f63 293a 342e 3466 7d2c  self.loc):4.4f},
+000115d0: 2073 6361 6c65 220d 0a20 2020 2020 2020   scale"..       
+000115e0: 2020 2020 2020 2020 2066 223d 7b66 6c6f           f"={flo
+000115f0: 6174 2873 656c 662e 7363 616c 6529 3a34  at(self.scale):4
+00011600: 2e34 667d 2c20 6b65 7973 3d7b 7365 6c66  .4f}, keys={self
+00011610: 2e69 6e5f 6b65 7973 7d29 220d 0a20 2020  .in_keys})"..   
+00011620: 2020 2020 2020 2020 2029 0d0a 2020 2020           )..    
+00011630: 2020 2020 656c 7365 3a0d 0a20 2020 2020      else:..     
+00011640: 2020 2020 2020 2072 6574 7572 6e20 7375         return su
+00011650: 7065 7228 292e 5f5f 7265 7072 5f5f 2829  per().__repr__()
+00011660: 0d0a 0d0a 0d0a 636c 6173 7320 4361 7446  ......class CatF
+00011670: 7261 6d65 7328 4f62 7365 7276 6174 696f  rames(Observatio
+00011680: 6e54 7261 6e73 666f 726d 293a 0d0a 2020  nTransform):..  
+00011690: 2020 2222 2243 6f6e 6361 7465 6e61 7465    """Concatenate
+000116a0: 7320 7375 6363 6573 7369 7665 206f 6273  s successive obs
+000116b0: 6572 7661 7469 6f6e 2066 7261 6d65 7320  ervation frames 
+000116c0: 696e 746f 2061 2073 696e 676c 6520 7465  into a single te
+000116d0: 6e73 6f72 2e0d 0a0d 0a20 2020 2054 6869  nsor.....    Thi
+000116e0: 7320 6361 6e2c 2066 6f72 2069 6e73 7461  s can, for insta
+000116f0: 6e63 652c 2061 6363 6f75 6e74 2066 6f72  nce, account for
+00011700: 206d 6f76 656d 656e 742f 7665 6c6f 6369   movement/veloci
+00011710: 7479 206f 6620 7468 6520 6f62 7365 7276  ty of the observ
+00011720: 6564 0d0a 2020 2020 6665 6174 7572 652e  ed..    feature.
+00011730: 2050 726f 706f 7365 6420 696e 2022 506c   Proposed in "Pl
+00011740: 6179 696e 6720 4174 6172 6920 7769 7468  aying Atari with
+00011750: 2044 6565 7020 5265 696e 666f 7263 656d   Deep Reinforcem
+00011760: 656e 7420 4c65 6172 6e69 6e67 2220 280d  ent Learning" (.
+00011770: 0a20 2020 2068 7474 7073 3a2f 2f61 7278  .    https://arx
+00011780: 6976 2e6f 7267 2f70 6466 2f31 3331 322e  iv.org/pdf/1312.
+00011790: 3536 3032 2e70 6466 292e 0d0a 0d0a 2020  5602.pdf).....  
+000117a0: 2020 5768 656e 2075 7365 6420 7769 7468    When used with
+000117b0: 696e 2061 2074 7261 6e73 666f 726d 6564  in a transformed
+000117c0: 2065 6e76 6972 6f6e 6d65 6e74 2c0d 0a20   environment,.. 
+000117d0: 2020 203a 636c 6173 733a 6043 6174 4672     :class:`CatFr
+000117e0: 616d 6573 6020 6973 2061 2073 7461 7465  ames` is a state
+000117f0: 6675 6c20 636c 6173 732c 2061 6e64 2069  ful class, and i
+00011800: 7420 6361 6e20 6265 2072 6573 6574 2074  t can be reset t
+00011810: 6f20 6974 7320 6e61 7469 7665 2073 7461  o its native sta
+00011820: 7465 2062 790d 0a20 2020 2063 616c 6c69  te by..    calli
+00011830: 6e67 2074 6865 203a 6d65 7468 3a60 7e2e  ng the :meth:`~.
+00011840: 7265 7365 7460 206d 6574 686f 642e 2054  reset` method. T
+00011850: 6869 7320 6d65 7468 6f64 2061 6363 6570  his method accep
+00011860: 7473 2074 656e 736f 7264 6963 7473 2077  ts tensordicts w
+00011870: 6974 6820 610d 0a20 2020 2060 6022 5f72  ith a..    ``"_r
+00011880: 6573 6574 2260 6020 656e 7472 7920 7468  eset"`` entry th
+00011890: 6174 2069 6e64 6963 6174 6573 2077 6869  at indicates whi
+000118a0: 6368 2062 7566 6665 7220 746f 2072 6573  ch buffer to res
+000118b0: 6574 2e0d 0a0d 0a20 2020 2041 7267 733a  et.....    Args:
+000118c0: 0d0a 2020 2020 2020 2020 4e20 2869 6e74  ..        N (int
+000118d0: 293a 206e 756d 6265 7220 6f66 206f 6273  ): number of obs
+000118e0: 6572 7661 7469 6f6e 2074 6f20 636f 6e63  ervation to conc
+000118f0: 6174 656e 6174 652e 0d0a 2020 2020 2020  atenate...      
+00011900: 2020 6469 6d20 2869 6e74 293a 2064 696d    dim (int): dim
+00011910: 656e 7369 6f6e 2061 6c6f 6e67 2077 6869  ension along whi
+00011920: 6368 2063 6f6e 6361 7465 6e61 7465 2074  ch concatenate t
+00011930: 6865 0d0a 2020 2020 2020 2020 2020 2020  he..            
+00011940: 6f62 7365 7276 6174 696f 6e73 2e20 5368  observations. Sh
+00011950: 6f75 6c64 2062 6520 6e65 6761 7469 7665  ould be negative
+00011960: 2c20 746f 2065 6e73 7572 6520 7468 6174  , to ensure that
+00011970: 2069 7420 6973 2063 6f6d 7061 7469 626c   it is compatibl
+00011980: 650d 0a20 2020 2020 2020 2020 2020 2077  e..            w
+00011990: 6974 6820 656e 7669 726f 6e6d 656e 7473  ith environments
+000119a0: 206f 6620 6469 6666 6572 656e 7420 6261   of different ba
+000119b0: 7463 685f 7369 7a65 2e0d 0a20 2020 2020  tch_size...     
+000119c0: 2020 2069 6e5f 6b65 7973 2028 6c69 7374     in_keys (list
+000119d0: 206f 6620 696e 742c 206f 7074 696f 6e61   of int, optiona
+000119e0: 6c29 3a20 6b65 7973 2070 6f69 6e74 696e  l): keys pointin
+000119f0: 6720 746f 2074 6865 2066 7261 6d65 7320  g to the frames 
+00011a00: 7468 6174 2068 6176 650d 0a20 2020 2020  that have..     
+00011a10: 2020 2020 2020 2074 6f20 6265 2063 6f6e         to be con
+00011a20: 6361 7465 6e61 7465 642e 2044 6566 6175  catenated. Defau
+00011a30: 6c74 7320 746f 205b 2270 6978 656c 7322  lts to ["pixels"
+00011a40: 5d2e 0d0a 2020 2020 2020 2020 6f75 745f  ]...        out_
+00011a50: 6b65 7973 2028 6c69 7374 206f 6620 696e  keys (list of in
+00011a60: 742c 206f 7074 696f 6e61 6c29 3a20 6b65  t, optional): ke
+00011a70: 7973 2070 6f69 6e74 696e 6720 746f 2077  ys pointing to w
+00011a80: 6865 7265 2074 6865 206f 7574 7075 740d  here the output.
+00011a90: 0a20 2020 2020 2020 2020 2020 2068 6173  .            has
+00011aa0: 2074 6f20 6265 2077 7269 7474 656e 2e20   to be written. 
+00011ab0: 4465 6661 756c 7473 2074 6f20 7468 6520  Defaults to the 
+00011ac0: 7661 6c75 6520 6f66 2060 696e 5f6b 6579  value of `in_key
+00011ad0: 7360 2e0d 0a20 2020 2020 2020 2070 6164  s`...        pad
+00011ae0: 6469 6e67 2028 7374 722c 206f 7074 696f  ding (str, optio
+00011af0: 6e61 6c29 3a20 7468 6520 7061 6464 696e  nal): the paddin
+00011b00: 6720 6d65 7468 6f64 2e20 4f6e 6520 6f66  g method. One of
+00011b10: 2060 6022 7361 6d65 2260 6020 6f72 2060   ``"same"`` or `
+00011b20: 6022 7a65 726f 7322 6060 2e0d 0a20 2020  `"zeros"``...   
+00011b30: 2020 2020 2020 2020 2044 6566 6175 6c74           Default
+00011b40: 7320 746f 2060 6022 7361 6d65 2260 602c  s to ``"same"``,
+00011b50: 2069 652e 2074 6865 2066 6972 7374 2076   ie. the first v
+00011b60: 616c 7565 2069 7320 7565 7364 2066 6f72  alue is uesd for
+00011b70: 2070 6164 6469 6e67 2e0d 0a0d 0a20 2020   padding.....   
+00011b80: 2045 7861 6d70 6c65 733a 0d0a 2020 2020   Examples:..    
+00011b90: 2020 2020 3e3e 3e20 6672 6f6d 2074 6f72      >>> from tor
+00011ba0: 6368 726c 2e65 6e76 732e 6c69 6273 2e67  chrl.envs.libs.g
+00011bb0: 796d 2069 6d70 6f72 7420 4779 6d45 6e76  ym import GymEnv
+00011bc0: 0d0a 2020 2020 2020 2020 3e3e 3e20 656e  ..        >>> en
+00011bd0: 7620 3d20 5472 616e 7366 6f72 6d65 6445  v = TransformedE
+00011be0: 6e76 2847 796d 456e 7628 2750 656e 6475  nv(GymEnv('Pendu
+00011bf0: 6c75 6d2d 7631 2729 2c0d 0a20 2020 2020  lum-v1'),..     
+00011c00: 2020 202e 2e2e 2020 2020 2043 6f6d 706f     ...     Compo
+00011c10: 7365 280d 0a20 2020 2020 2020 202e 2e2e  se(..        ...
+00011c20: 2020 2020 2020 2020 2055 6e73 7175 6565           Unsquee
+00011c30: 7a65 5472 616e 7366 6f72 6d28 2d31 2c20  zeTransform(-1, 
+00011c40: 696e 5f6b 6579 733d 5b22 6f62 7365 7276  in_keys=["observ
+00011c50: 6174 696f 6e22 5d29 2c0d 0a20 2020 2020  ation"]),..     
+00011c60: 2020 202e 2e2e 2020 2020 2020 2020 2043     ...         C
+00011c70: 6174 4672 616d 6573 284e 3d34 2c20 6469  atFrames(N=4, di
+00011c80: 6d3d 2d31 2c20 696e 5f6b 6579 733d 5b22  m=-1, in_keys=["
+00011c90: 6f62 7365 7276 6174 696f 6e22 5d29 2c0d  observation"]),.
+00011ca0: 0a20 2020 2020 2020 202e 2e2e 2020 2020  .        ...    
+00011cb0: 2029 0d0a 2020 2020 2020 2020 2e2e 2e20   )..        ... 
+00011cc0: 290d 0a20 2020 2020 2020 203e 3e3e 2070  )..        >>> p
+00011cd0: 7269 6e74 2865 6e76 2e72 6f6c 6c6f 7574  rint(env.rollout
+00011ce0: 2833 2929 0d0a 0d0a 2020 2020 5468 6520  (3))....    The 
+00011cf0: 3a63 6c61 7373 3a60 4361 7446 7261 6d65  :class:`CatFrame
+00011d00: 7360 2074 7261 6e73 666f 726d 2063 616e  s` transform can
+00011d10: 2061 6c73 6f20 6265 2075 7365 6420 6f66   also be used of
+00011d20: 666c 696e 6520 746f 2072 6570 726f 6475  fline to reprodu
+00011d30: 6365 2074 6865 0d0a 2020 2020 6566 6665  ce the..    effe
+00011d40: 6374 206f 6620 7468 6520 6f6e 6c69 6e65  ct of the online
+00011d50: 2066 7261 6d65 2063 6f6e 6361 7465 6e61   frame concatena
+00011d60: 7469 6f6e 2061 7420 6120 6469 6666 6572  tion at a differ
+00011d70: 656e 7420 7363 616c 6520 286f 7220 666f  ent scale (or fo
+00011d80: 7220 7468 650d 0a20 2020 2070 7572 706f  r the..    purpo
+00011d90: 7365 206f 6620 6c69 6d69 7469 6e67 2074  se of limiting t
+00011da0: 6865 206d 656d 6f72 7920 636f 6e73 756d  he memory consum
+00011db0: 7074 696f 6e29 2e20 5468 6520 666f 6c6c  ption). The foll
+00011dc0: 6f77 696e 2065 7861 6d70 6c65 0d0a 2020  owin example..  
+00011dd0: 2020 6769 7665 7320 7468 6520 636f 6d70    gives the comp
+00011de0: 6c65 7465 2070 6963 7475 7265 2c20 746f  lete picture, to
+00011df0: 6765 7468 6572 2077 6974 6820 7468 6520  gether with the 
+00011e00: 7573 6167 6520 6f66 2061 203a 636c 6173  usage of a :clas
+00011e10: 733a 6074 6f72 6368 726c 2e64 6174 612e  s:`torchrl.data.
+00011e20: 5265 706c 6179 4275 6666 6572 603a 0d0a  ReplayBuffer`:..
+00011e30: 0d0a 2020 2020 4578 616d 706c 6573 3a0d  ..    Examples:.
+00011e40: 0a20 2020 2020 2020 203e 3e3e 2066 726f  .        >>> fro
+00011e50: 6d20 746f 7263 6872 6c2e 656e 7673 2069  m torchrl.envs i
+00011e60: 6d70 6f72 7420 556e 7371 7565 657a 6554  mport UnsqueezeT
+00011e70: 7261 6e73 666f 726d 2c20 4361 7446 7261  ransform, CatFra
+00011e80: 6d65 730d 0a20 2020 2020 2020 203e 3e3e  mes..        >>>
+00011e90: 2066 726f 6d20 746f 7263 6872 6c2e 636f   from torchrl.co
+00011ea0: 6c6c 6563 746f 7273 2069 6d70 6f72 7420  llectors import 
+00011eb0: 5379 6e63 4461 7461 436f 6c6c 6563 746f  SyncDataCollecto
+00011ec0: 722c 2052 616e 646f 6d50 6f6c 6963 790d  r, RandomPolicy.
+00011ed0: 0a20 2020 2020 2020 203e 3e3e 2023 2043  .        >>> # C
+00011ee0: 7265 6174 6520 6120 7472 616e 7366 6f72  reate a transfor
+00011ef0: 6d65 6420 656e 7669 726f 6e6d 656e 7420  med environment 
+00011f00: 7769 7468 2043 6174 4672 616d 6573 3a20  with CatFrames: 
+00011f10: 6e6f 7469 6365 2074 6865 2075 7361 6765  notice the usage
+00011f20: 206f 6620 556e 7371 7565 657a 6554 7261   of UnsqueezeTra
+00011f30: 6e73 666f 726d 2074 6f20 6372 6561 7465  nsform to create
+00011f40: 2061 6e20 6578 7472 6120 6469 6d65 6e73   an extra dimens
+00011f50: 696f 6e0d 0a20 2020 2020 2020 203e 3e3e  ion..        >>>
+00011f60: 2065 6e76 203d 2054 7261 6e73 666f 726d   env = Transform
+00011f70: 6564 456e 7628 0d0a 2020 2020 2020 2020  edEnv(..        
+00011f80: 2e2e 2e20 2020 2020 4779 6d45 6e76 2822  ...     GymEnv("
+00011f90: 4361 7274 506f 6c65 2d76 3122 2c20 6672  CartPole-v1", fr
+00011fa0: 6f6d 5f70 6978 656c 733d 5472 7565 292c  om_pixels=True),
+00011fb0: 0d0a 2020 2020 2020 2020 2e2e 2e20 2020  ..        ...   
+00011fc0: 2020 436f 6d70 6f73 6528 0d0a 2020 2020    Compose(..    
+00011fd0: 2020 2020 2e2e 2e20 2020 2020 2020 2020      ...         
+00011fe0: 546f 5465 6e73 6f72 496d 6167 6528 696e  ToTensorImage(in
+00011ff0: 5f6b 6579 733d 5b22 7069 7865 6c73 225d  _keys=["pixels"]
+00012000: 2c20 6f75 745f 6b65 7973 3d5b 2270 6978  , out_keys=["pix
+00012010: 656c 735f 7472 7366 225d 292c 0d0a 2020  els_trsf"]),..  
+00012020: 2020 2020 2020 2e2e 2e20 2020 2020 2020        ...       
+00012030: 2020 5265 7369 7a65 2869 6e5f 6b65 7973    Resize(in_keys
+00012040: 3d5b 2270 6978 656c 735f 7472 7366 225d  =["pixels_trsf"]
+00012050: 2c20 773d 3634 2c20 683d 3634 292c 0d0a  , w=64, h=64),..
+00012060: 2020 2020 2020 2020 2e2e 2e20 2020 2020          ...     
+00012070: 2020 2020 4772 6179 5363 616c 6528 696e      GrayScale(in
+00012080: 5f6b 6579 733d 5b22 7069 7865 6c73 5f74  _keys=["pixels_t
+00012090: 7273 6622 5d29 2c0d 0a20 2020 2020 2020  rsf"]),..       
+000120a0: 202e 2e2e 2020 2020 2020 2020 2055 6e73   ...         Uns
+000120b0: 7175 6565 7a65 5472 616e 7366 6f72 6d28  queezeTransform(
+000120c0: 2d34 2c20 696e 5f6b 6579 733d 5b22 7069  -4, in_keys=["pi
+000120d0: 7865 6c73 5f74 7273 6622 5d29 2c0d 0a20  xels_trsf"]),.. 
+000120e0: 2020 2020 2020 202e 2e2e 2020 2020 2020         ...      
+000120f0: 2020 2043 6174 4672 616d 6573 2864 696d     CatFrames(dim
+00012100: 3d2d 342c 204e 3d34 2c20 696e 5f6b 6579  =-4, N=4, in_key
+00012110: 733d 5b22 7069 7865 6c73 5f74 7273 6622  s=["pixels_trsf"
+00012120: 5d29 2c0d 0a20 2020 2020 2020 202e 2e2e  ]),..        ...
+00012130: 2020 2020 2029 0d0a 2020 2020 2020 2020       )..        
+00012140: 2e2e 2e20 290d 0a20 2020 2020 2020 203e  ... )..        >
+00012150: 3e3e 2023 2077 6520 6465 7369 676e 2061  >> # we design a
+00012160: 2063 6f6c 6c65 6374 6f72 0d0a 2020 2020   collector..    
+00012170: 2020 2020 3e3e 3e20 636f 6c6c 6563 746f      >>> collecto
+00012180: 7220 3d20 5379 6e63 4461 7461 436f 6c6c  r = SyncDataColl
+00012190: 6563 746f 7228 0d0a 2020 2020 2020 2020  ector(..        
+000121a0: 2e2e 2e20 2020 2020 656e 762c 0d0a 2020  ...     env,..  
+000121b0: 2020 2020 2020 2e2e 2e20 2020 2020 5261        ...     Ra
+000121c0: 6e64 6f6d 506f 6c69 6379 2865 6e76 2e61  ndomPolicy(env.a
+000121d0: 6374 696f 6e5f 7370 6563 292c 0d0a 2020  ction_spec),..  
+000121e0: 2020 2020 2020 2e2e 2e20 2020 2020 6672        ...     fr
+000121f0: 616d 6573 5f70 6572 5f62 6174 6368 3d31  ames_per_batch=1
+00012200: 302c 0d0a 2020 2020 2020 2020 2e2e 2e20  0,..        ... 
+00012210: 2020 2020 746f 7461 6c5f 6672 616d 6573      total_frames
+00012220: 3d31 3030 302c 0d0a 2020 2020 2020 2020  =1000,..        
+00012230: 2e2e 2e20 290d 0a20 2020 2020 2020 203e  ... )..        >
+00012240: 3e3e 2066 6f72 2064 6174 6120 696e 2063  >> for data in c
+00012250: 6f6c 6c65 6374 6f72 3a0d 0a20 2020 2020  ollector:..     
+00012260: 2020 202e 2e2e 2020 2020 2070 7269 6e74     ...     print
+00012270: 2864 6174 6129 0d0a 2020 2020 2020 2020  (data)..        
+00012280: 2e2e 2e20 2020 2020 6272 6561 6b0d 0a20  ...     break.. 
+00012290: 2020 2020 2020 203e 3e3e 2023 206e 6f77         >>> # now
+000122a0: 206c 6574 2773 2063 7265 6174 6520 6120   let's create a 
+000122b0: 7472 616e 7366 6f72 6d20 666f 7220 7468  transform for th
+000122c0: 6520 7265 706c 6179 2062 7566 6665 722e  e replay buffer.
+000122d0: 2057 6520 646f 6e27 7420 6e65 6564 2074   We don't need t
+000122e0: 6f20 756e 7371 7565 657a 6520 7468 6520  o unsqueeze the 
+000122f0: 6461 7461 2068 6572 652e 0d0a 2020 2020  data here...    
+00012300: 2020 2020 3e3e 3e20 2320 686f 7765 7665      >>> # howeve
+00012310: 722c 2077 6520 6e65 6564 2074 6f20 706f  r, we need to po
+00012320: 696e 7420 746f 2062 6f74 6820 7468 6520  int to both the 
+00012330: 7069 7865 6c20 656e 7472 7920 6174 2074  pixel entry at t
+00012340: 6865 2072 6f6f 7420 616e 6420 6174 2074  he root and at t
+00012350: 6865 206e 6578 7420 6c65 7665 6c73 3a0d  he next levels:.
+00012360: 0a20 2020 2020 2020 203e 3e3e 2074 203d  .        >>> t =
+00012370: 2043 6f6d 706f 7365 280d 0a20 2020 2020   Compose(..     
+00012380: 2020 202e 2e2e 2020 2020 2020 2020 2054     ...         T
+00012390: 6f54 656e 736f 7249 6d61 6765 2869 6e5f  oTensorImage(in_
+000123a0: 6b65 7973 3d5b 2270 6978 656c 7322 2c20  keys=["pixels", 
+000123b0: 2822 6e65 7874 222c 2022 7069 7865 6c73  ("next", "pixels
+000123c0: 2229 5d2c 206f 7574 5f6b 6579 733d 5b22  ")], out_keys=["
+000123d0: 7069 7865 6c73 5f74 7273 6622 2c20 2822  pixels_trsf", ("
+000123e0: 6e65 7874 222c 2022 7069 7865 6c73 5f74  next", "pixels_t
+000123f0: 7273 6622 295d 292c 0d0a 2020 2020 2020  rsf")]),..      
+00012400: 2020 2e2e 2e20 2020 2020 2020 2020 5265    ...         Re
+00012410: 7369 7a65 2869 6e5f 6b65 7973 3d5b 2270  size(in_keys=["p
+00012420: 6978 656c 735f 7472 7366 222c 2028 226e  ixels_trsf", ("n
+00012430: 6578 7422 2c20 2270 6978 656c 735f 7472  ext", "pixels_tr
+00012440: 7366 2229 5d2c 2077 3d36 342c 2068 3d36  sf")], w=64, h=6
+00012450: 3429 2c0d 0a20 2020 2020 2020 202e 2e2e  4),..        ...
+00012460: 2020 2020 2020 2020 2047 7261 7953 6361           GraySca
+00012470: 6c65 2869 6e5f 6b65 7973 3d5b 2270 6978  le(in_keys=["pix
+00012480: 656c 735f 7472 7366 222c 2028 226e 6578  els_trsf", ("nex
+00012490: 7422 2c20 2270 6978 656c 735f 7472 7366  t", "pixels_trsf
+000124a0: 2229 5d29 2c0d 0a20 2020 2020 2020 202e  ")]),..        .
+000124b0: 2e2e 2020 2020 2020 2020 2043 6174 4672  ..         CatFr
+000124c0: 616d 6573 2864 696d 3d2d 342c 204e 3d34  ames(dim=-4, N=4
+000124d0: 2c20 696e 5f6b 6579 733d 5b22 7069 7865  , in_keys=["pixe
+000124e0: 6c73 5f74 7273 6622 2c20 2822 6e65 7874  ls_trsf", ("next
+000124f0: 222c 2022 7069 7865 6c73 5f74 7273 6622  ", "pixels_trsf"
+00012500: 295d 292c 0d0a 2020 2020 2020 2020 2e2e  )]),..        ..
+00012510: 2e20 290d 0a20 2020 2020 2020 203e 3e3e  . )..        >>>
+00012520: 2066 726f 6d20 746f 7263 6872 6c2e 6461   from torchrl.da
+00012530: 7461 2069 6d70 6f72 7420 5465 6e73 6f72  ta import Tensor
+00012540: 4469 6374 5265 706c 6179 4275 6666 6572  DictReplayBuffer
+00012550: 2c20 4c61 7a79 4d65 6d6d 6170 5374 6f72  , LazyMemmapStor
+00012560: 6167 650d 0a20 2020 2020 2020 203e 3e3e  age..        >>>
+00012570: 2072 6220 3d20 5465 6e73 6f72 4469 6374   rb = TensorDict
+00012580: 5265 706c 6179 4275 6666 6572 2873 746f  ReplayBuffer(sto
+00012590: 7261 6765 3d4c 617a 794d 656d 6d61 7053  rage=LazyMemmapS
+000125a0: 746f 7261 6765 2831 3030 3029 2c20 7472  torage(1000), tr
+000125b0: 616e 7366 6f72 6d3d 742c 2062 6174 6368  ansform=t, batch
+000125c0: 5f73 697a 653d 3136 290d 0a20 2020 2020  _size=16)..     
+000125d0: 2020 203e 3e3e 2064 6174 615f 6578 636c     >>> data_excl
+000125e0: 7564 6520 3d20 6461 7461 2e65 7863 6c75  ude = data.exclu
+000125f0: 6465 2822 7069 7865 6c73 5f74 7273 6622  de("pixels_trsf"
+00012600: 2c20 2822 6e65 7874 222c 2022 7069 7865  , ("next", "pixe
+00012610: 6c73 5f74 7273 6622 2929 0d0a 2020 2020  ls_trsf"))..    
+00012620: 2020 2020 3e3e 3e20 7262 2e61 6464 2864      >>> rb.add(d
+00012630: 6174 615f 6578 636c 7564 6529 0d0a 2020  ata_exclude)..  
+00012640: 2020 2020 2020 3e3e 3e20 7320 3d20 7262        >>> s = rb
+00012650: 2e73 616d 706c 6528 3129 2023 2074 6865  .sample(1) # the
+00012660: 2062 7566 6665 7220 6861 7320 6f6e 6c79   buffer has only
+00012670: 206f 6e65 2065 6c65 6d65 6e74 0d0a 2020   one element..  
+00012680: 2020 2020 2020 3e3e 3e20 2320 6c65 7427        >>> # let'
+00012690: 7320 6368 6563 6b20 7468 6174 206f 7572  s check that our
+000126a0: 2073 616d 706c 6520 6973 2074 6865 2073   sample is the s
+000126b0: 616d 6520 6173 2074 6865 2062 6174 6368  ame as the batch
+000126c0: 2063 6f6c 6c65 6374 6564 2064 7572 696e   collected durin
+000126d0: 6720 696e 6665 7265 6e63 650d 0a20 2020  g inference..   
+000126e0: 2020 2020 203e 3e3e 2061 7373 6572 7420       >>> assert 
+000126f0: 2864 6174 612e 6578 636c 7564 6528 2263  (data.exclude("c
+00012700: 6f6c 6c65 6374 6f72 2229 3d3d 732e 7371  ollector")==s.sq
+00012710: 7565 657a 6528 3029 2e65 7863 6c75 6465  ueeze(0).exclude
+00012720: 2822 696e 6465 7822 2c20 2263 6f6c 6c65  ("index", "colle
+00012730: 6374 6f72 2229 292e 616c 6c28 290d 0a0d  ctor")).all()...
+00012740: 0a20 2020 2022 2222 0d0a 0d0a 2020 2020  .    """....    
+00012750: 696e 706c 6163 6520 3d20 4661 6c73 650d  inplace = False.
+00012760: 0a20 2020 205f 4341 545f 4449 4d5f 4552  .    _CAT_DIM_ER
+00012770: 5220 3d20 280d 0a20 2020 2020 2020 2022  R = (..        "
+00012780: 6469 6d20 6d75 7374 2062 6520 3e20 3020  dim must be > 0 
+00012790: 746f 2061 6363 6f6d 6f64 6174 6520 666f  to accomodate fo
+000127a0: 7220 7465 6e73 6f72 6469 6374 206f 6620  r tensordict of 
+000127b0: 220d 0a20 2020 2020 2020 2022 6469 6666  "..        "diff
+000127c0: 6572 656e 7420 6261 7463 682d 7369 7a65  erent batch-size
+000127d0: 7320 2873 696e 6365 206e 6567 6174 6976  s (since negativ
+000127e0: 6520 6469 6d73 2061 7265 2062 6174 6368  e dims are batch
+000127f0: 2069 6e76 6172 6961 6e74 292e 220d 0a20   invariant).".. 
+00012800: 2020 2029 0d0a 2020 2020 4143 4345 5054     )..    ACCEPT
+00012810: 4544 5f50 4144 4449 4e47 203d 207b 2273  ED_PADDING = {"s
+00012820: 616d 6522 2c20 227a 6572 6f73 227d 0d0a  ame", "zeros"}..
+00012830: 0d0a 2020 2020 6465 6620 5f5f 696e 6974  ..    def __init
+00012840: 5f5f 280d 0a20 2020 2020 2020 2073 656c  __(..        sel
+00012850: 662c 0d0a 2020 2020 2020 2020 4e3a 2069  f,..        N: i
+00012860: 6e74 2c0d 0a20 2020 2020 2020 2064 696d  nt,..        dim
+00012870: 3a20 696e 742c 0d0a 2020 2020 2020 2020  : int,..        
+00012880: 696e 5f6b 6579 733a 204f 7074 696f 6e61  in_keys: Optiona
+00012890: 6c5b 5365 7175 656e 6365 5b73 7472 5d5d  l[Sequence[str]]
+000128a0: 203d 204e 6f6e 652c 0d0a 2020 2020 2020   = None,..      
+000128b0: 2020 6f75 745f 6b65 7973 3a20 4f70 7469    out_keys: Opti
+000128c0: 6f6e 616c 5b53 6571 7565 6e63 655b 7374  onal[Sequence[st
+000128d0: 725d 5d20 3d20 4e6f 6e65 2c0d 0a20 2020  r]] = None,..   
+000128e0: 2020 2020 2070 6164 6469 6e67 3d22 7361       padding="sa
+000128f0: 6d65 222c 0d0a 2020 2020 293a 0d0a 2020  me",..    ):..  
+00012900: 2020 2020 2020 6966 2069 6e5f 6b65 7973        if in_keys
+00012910: 2069 7320 4e6f 6e65 3a0d 0a20 2020 2020   is None:..     
+00012920: 2020 2020 2020 2069 6e5f 6b65 7973 203d         in_keys =
+00012930: 2049 4d41 4745 5f4b 4559 530d 0a20 2020   IMAGE_KEYS..   
+00012940: 2020 2020 2073 7570 6572 2829 2e5f 5f69       super().__i
+00012950: 6e69 745f 5f28 696e 5f6b 6579 733d 696e  nit__(in_keys=in
+00012960: 5f6b 6579 732c 206f 7574 5f6b 6579 733d  _keys, out_keys=
+00012970: 6f75 745f 6b65 7973 290d 0a20 2020 2020  out_keys)..     
+00012980: 2020 2073 656c 662e 4e20 3d20 4e0d 0a20     self.N = N.. 
+00012990: 2020 2020 2020 2069 6620 6469 6d20 3e20         if dim > 
+000129a0: 303a 0d0a 2020 2020 2020 2020 2020 2020  0:..            
+000129b0: 7261 6973 6520 5661 6c75 6545 7272 6f72  raise ValueError
+000129c0: 2873 656c 662e 5f43 4154 5f44 494d 5f45  (self._CAT_DIM_E
+000129d0: 5252 290d 0a20 2020 2020 2020 2073 656c  RR)..        sel
+000129e0: 662e 6469 6d20 3d20 6469 6d0d 0a20 2020  f.dim = dim..   
+000129f0: 2020 2020 2069 6620 7061 6464 696e 6720       if padding 
+00012a00: 6e6f 7420 696e 2073 656c 662e 4143 4345  not in self.ACCE
+00012a10: 5054 4544 5f50 4144 4449 4e47 3a0d 0a20  PTED_PADDING:.. 
+00012a20: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+00012a30: 2056 616c 7565 4572 726f 7228 6622 7061   ValueError(f"pa
+00012a40: 6464 696e 6720 6d75 7374 2062 6520 6f6e  dding must be on
+00012a50: 6520 6f66 207b 7365 6c66 2e41 4343 4550  e of {self.ACCEP
+00012a60: 5445 445f 5041 4444 494e 477d 2229 0d0a  TED_PADDING}")..
+00012a70: 2020 2020 2020 2020 7365 6c66 2e70 6164          self.pad
+00012a80: 6469 6e67 203d 2070 6164 6469 6e67 0d0a  ding = padding..
+00012a90: 2020 2020 2020 2020 666f 7220 696e 5f6b          for in_k
+00012aa0: 6579 2069 6e20 7365 6c66 2e69 6e5f 6b65  ey in self.in_ke
+00012ab0: 7973 3a0d 0a20 2020 2020 2020 2020 2020  ys:..           
+00012ac0: 2062 7566 6665 725f 6e61 6d65 203d 2066   buffer_name = f
+00012ad0: 225f 6361 745f 6275 6666 6572 735f 7b69  "_cat_buffers_{i
+00012ae0: 6e5f 6b65 797d 220d 0a20 2020 2020 2020  n_key}"..       
+00012af0: 2020 2020 2073 6574 6174 7472 280d 0a20       setattr(.. 
+00012b00: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+00012b10: 656c 662c 0d0a 2020 2020 2020 2020 2020  elf,..          
+00012b20: 2020 2020 2020 6275 6666 6572 5f6e 616d        buffer_nam
+00012b30: 652c 0d0a 2020 2020 2020 2020 2020 2020  e,..            
+00012b40: 2020 2020 746f 7263 682e 6e6e 2e70 6172      torch.nn.par
+00012b50: 616d 6574 6572 2e55 6e69 6e69 7469 616c  ameter.Uninitial
+00012b60: 697a 6564 4275 6666 6572 280d 0a20 2020  izedBuffer(..   
+00012b70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012b80: 2064 6576 6963 653d 746f 7263 682e 6465   device=torch.de
+00012b90: 7669 6365 2822 6370 7522 292c 2064 7479  vice("cpu"), dty
+00012ba0: 7065 3d74 6f72 6368 2e67 6574 5f64 6566  pe=torch.get_def
+00012bb0: 6175 6c74 5f64 7479 7065 2829 0d0a 2020  ault_dtype()..  
+00012bc0: 2020 2020 2020 2020 2020 2020 2020 292c                ),
+00012bd0: 0d0a 2020 2020 2020 2020 2020 2020 290d  ..            ).
+00012be0: 0a20 2020 2020 2020 2023 206b 6565 7073  .        # keeps
+00012bf0: 2074 7261 636b 206f 6620 6361 6c6c 7320   track of calls 
+00012c00: 746f 205f 7265 7365 7420 7369 6e63 6520  to _reset since 
+00012c10: 6974 2773 206f 6e6c 7920 5f63 616c 6c20  it's only _call 
+00012c20: 7468 6174 2077 696c 6c20 706f 7075 6c61  that will popula
+00012c30: 7465 2074 6865 2062 7566 6665 720d 0a20  te the buffer.. 
+00012c40: 2020 2020 2020 2073 656c 662e 5f6a 7573         self._jus
+00012c50: 745f 7265 7365 7420 3d20 4661 6c73 650d  t_reset = False.
+00012c60: 0a0d 0a20 2020 2064 6566 2072 6573 6574  ...    def reset
+00012c70: 2873 656c 662c 2074 656e 736f 7264 6963  (self, tensordic
+00012c80: 743a 2054 656e 736f 7244 6963 7442 6173  t: TensorDictBas
+00012c90: 6529 202d 3e20 5465 6e73 6f72 4469 6374  e) -> TensorDict
+00012ca0: 4261 7365 3a0d 0a20 2020 2020 2020 2022  Base:..        "
+00012cb0: 2222 5265 7365 7473 205f 6275 6666 6572  ""Resets _buffer
+00012cc0: 732e 2222 220d 0a20 2020 2020 2020 205f  s."""..        _
+00012cd0: 7265 7365 7420 3d20 7465 6e73 6f72 6469  reset = tensordi
+00012ce0: 6374 2e67 6574 2822 5f72 6573 6574 222c  ct.get("_reset",
+00012cf0: 204e 6f6e 6529 0d0a 2020 2020 2020 2020   None)..        
+00012d00: 6966 205f 7265 7365 7420 6973 204e 6f6e  if _reset is Non
+00012d10: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
+00012d20: 5f72 6573 6574 203d 2074 6f72 6368 2e6f  _reset = torch.o
+00012d30: 6e65 7328 0d0a 2020 2020 2020 2020 2020  nes(..          
+00012d40: 2020 2020 2020 7365 6c66 2e70 6172 656e        self.paren
+00012d50: 742e 646f 6e65 5f73 7065 632e 7368 6170  t.done_spec.shap
+00012d60: 6520 6966 2073 656c 662e 7061 7265 6e74  e if self.parent
+00012d70: 2065 6c73 6520 7465 6e73 6f72 6469 6374   else tensordict
+00012d80: 2e62 6174 6368 5f73 697a 652c 0d0a 2020  .batch_size,..  
+00012d90: 2020 2020 2020 2020 2020 2020 2020 6474                dt
+00012da0: 7970 653d 746f 7263 682e 626f 6f6c 2c0d  ype=torch.bool,.
+00012db0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00012dc0: 2064 6576 6963 653d 7465 6e73 6f72 6469   device=tensordi
+00012dd0: 6374 2e64 6576 6963 650d 0a20 2020 2020  ct.device..     
+00012de0: 2020 2020 2020 2020 2020 2069 6620 7465             if te
+00012df0: 6e73 6f72 6469 6374 2e64 6576 6963 6520  nsordict.device 
+00012e00: 6973 206e 6f74 204e 6f6e 650d 0a20 2020  is not None..   
+00012e10: 2020 2020 2020 2020 2020 2020 2065 6c73               els
+00012e20: 6520 746f 7263 682e 6465 7669 6365 2822  e torch.device("
+00012e30: 6370 7522 292c 0d0a 2020 2020 2020 2020  cpu"),..        
+00012e40: 2020 2020 290d 0a20 2020 2020 2020 205f      )..        _
+00012e50: 7265 7365 7420 3d20 5f72 6573 6574 2e73  reset = _reset.s
+00012e60: 756d 280d 0a20 2020 2020 2020 2020 2020  um(..           
+00012e70: 2074 7570 6c65 2872 616e 6765 2874 656e   tuple(range(ten
+00012e80: 736f 7264 6963 742e 6261 7463 685f 6469  sordict.batch_di
+00012e90: 6d73 2c20 5f72 6573 6574 2e6e 6469 6d29  ms, _reset.ndim)
+00012ea0: 292c 2064 7479 7065 3d74 6f72 6368 2e62  ), dtype=torch.b
+00012eb0: 6f6f 6c0d 0a20 2020 2020 2020 2029 0d0a  ool..        )..
+00012ec0: 0d0a 2020 2020 2020 2020 666f 7220 696e  ..        for in
+00012ed0: 5f6b 6579 2069 6e20 7365 6c66 2e69 6e5f  _key in self.in_
+00012ee0: 6b65 7973 3a0d 0a20 2020 2020 2020 2020  keys:..         
+00012ef0: 2020 2062 7566 6665 725f 6e61 6d65 203d     buffer_name =
+00012f00: 2066 225f 6361 745f 6275 6666 6572 735f   f"_cat_buffers_
+00012f10: 7b69 6e5f 6b65 797d 220d 0a20 2020 2020  {in_key}"..     
+00012f20: 2020 2020 2020 2062 7566 6665 7220 3d20         buffer = 
+00012f30: 6765 7461 7474 7228 7365 6c66 2c20 6275  getattr(self, bu
+00012f40: 6666 6572 5f6e 616d 6529 0d0a 2020 2020  ffer_name)..    
+00012f50: 2020 2020 2020 2020 6966 2069 7369 6e73          if isins
+00012f60: 7461 6e63 6528 6275 6666 6572 2c20 746f  tance(buffer, to
+00012f70: 7263 682e 6e6e 2e70 6172 616d 6574 6572  rch.nn.parameter
+00012f80: 2e55 6e69 6e69 7469 616c 697a 6564 4275  .UninitializedBu
+00012f90: 6666 6572 293a 0d0a 2020 2020 2020 2020  ffer):..        
+00012fa0: 2020 2020 2020 2020 636f 6e74 696e 7565          continue
+00012fb0: 0d0a 2020 2020 2020 2020 2020 2020 6275  ..            bu
+00012fc0: 6666 6572 5b5f 7265 7365 745d 203d 2030  ffer[_reset] = 0
+00012fd0: 0d0a 0d0a 2020 2020 2020 2020 7365 6c66  ....        self
+00012fe0: 2e5f 6a75 7374 5f72 6573 6574 203d 2054  ._just_reset = T
+00012ff0: 7275 650d 0a20 2020 2020 2020 2072 6574  rue..        ret
+00013000: 7572 6e20 7465 6e73 6f72 6469 6374 0d0a  urn tensordict..
+00013010: 0d0a 2020 2020 6465 6620 5f6d 616b 655f  ..    def _make_
+00013020: 6d69 7373 696e 675f 6275 6666 6572 2873  missing_buffer(s
+00013030: 656c 662c 2064 6174 612c 2062 7566 6665  elf, data, buffe
+00013040: 725f 6e61 6d65 293a 0d0a 2020 2020 2020  r_name):..      
+00013050: 2020 7368 6170 6520 3d20 6c69 7374 2864    shape = list(d
+00013060: 6174 612e 7368 6170 6529 0d0a 2020 2020  ata.shape)..    
+00013070: 2020 2020 6420 3d20 7368 6170 655b 7365      d = shape[se
+00013080: 6c66 2e64 696d 5d0d 0a20 2020 2020 2020  lf.dim]..       
+00013090: 2073 6861 7065 5b73 656c 662e 6469 6d5d   shape[self.dim]
+000130a0: 203d 2064 202a 2073 656c 662e 4e0d 0a20   = d * self.N.. 
+000130b0: 2020 2020 2020 2073 6861 7065 203d 2074         shape = t
+000130c0: 6f72 6368 2e53 697a 6528 7368 6170 6529  orch.Size(shape)
+000130d0: 0d0a 2020 2020 2020 2020 6765 7461 7474  ..        getatt
+000130e0: 7228 7365 6c66 2c20 6275 6666 6572 5f6e  r(self, buffer_n
+000130f0: 616d 6529 2e6d 6174 6572 6961 6c69 7a65  ame).materialize
+00013100: 2873 6861 7065 290d 0a20 2020 2020 2020  (shape)..       
+00013110: 2062 7566 6665 7220 3d20 6765 7461 7474   buffer = getatt
+00013120: 7228 7365 6c66 2c20 6275 6666 6572 5f6e  r(self, buffer_n
+00013130: 616d 6529 2e74 6f28 6461 7461 2e64 7479  ame).to(data.dty
+00013140: 7065 292e 746f 2864 6174 612e 6465 7669  pe).to(data.devi
+00013150: 6365 292e 7a65 726f 5f28 290d 0a20 2020  ce).zero_()..   
+00013160: 2020 2020 2073 6574 6174 7472 2873 656c       setattr(sel
+00013170: 662c 2062 7566 6665 725f 6e61 6d65 2c20  f, buffer_name, 
+00013180: 6275 6666 6572 290d 0a20 2020 2020 2020  buffer)..       
+00013190: 2072 6574 7572 6e20 6275 6666 6572 0d0a   return buffer..
+000131a0: 0d0a 2020 2020 6465 6620 5f63 616c 6c28  ..    def _call(
+000131b0: 7365 6c66 2c20 7465 6e73 6f72 6469 6374  self, tensordict
+000131c0: 3a20 5465 6e73 6f72 4469 6374 4261 7365  : TensorDictBase
+000131d0: 2920 2d3e 2054 656e 736f 7244 6963 7442  ) -> TensorDictB
+000131e0: 6173 653a 0d0a 2020 2020 2020 2020 2222  ase:..        ""
+000131f0: 2255 7064 6174 6520 7468 6520 6570 6973  "Update the epis
+00013200: 6f64 6520 7465 6e73 6f72 6469 6374 2077  ode tensordict w
+00013210: 6974 6820 6d61 7820 706f 6f6c 6564 206b  ith max pooled k
+00013220: 6579 732e 2222 220d 0a20 2020 2020 2020  eys."""..       
+00013230: 205f 7265 7365 7420 3d20 7465 6e73 6f72   _reset = tensor
+00013240: 6469 6374 2e67 6574 2822 5f72 6573 6574  dict.get("_reset
+00013250: 222c 204e 6f6e 6529 0d0a 2020 2020 2020  ", None)..      
+00013260: 2020 6966 205f 7265 7365 7420 6973 206e    if _reset is n
+00013270: 6f74 204e 6f6e 653a 0d0a 2020 2020 2020  ot None:..      
+00013280: 2020 2020 2020 5f72 6573 6574 203d 205f        _reset = _
+00013290: 7265 7365 742e 7375 6d28 0d0a 2020 2020  reset.sum(..    
+000132a0: 2020 2020 2020 2020 2020 2020 7475 706c              tupl
+000132b0: 6528 7261 6e67 6528 7465 6e73 6f72 6469  e(range(tensordi
+000132c0: 6374 2e62 6174 6368 5f64 696d 732c 205f  ct.batch_dims, _
+000132d0: 7265 7365 742e 6e64 696d 2929 2c20 6474  reset.ndim)), dt
+000132e0: 7970 653d 746f 7263 682e 626f 6f6c 0d0a  ype=torch.bool..
+000132f0: 2020 2020 2020 2020 2020 2020 290d 0a0d              )...
+00013300: 0a20 2020 2020 2020 2066 6f72 2069 6e5f  .        for in_
+00013310: 6b65 792c 206f 7574 5f6b 6579 2069 6e20  key, out_key in 
+00013320: 7a69 7028 7365 6c66 2e69 6e5f 6b65 7973  zip(self.in_keys
+00013330: 2c20 7365 6c66 2e6f 7574 5f6b 6579 7329  , self.out_keys)
+00013340: 3a0d 0a20 2020 2020 2020 2020 2020 2023  :..            #
+00013350: 204c 617a 7920 696e 6974 206f 6620 6275   Lazy init of bu
+00013360: 6666 6572 730d 0a20 2020 2020 2020 2020  ffers..         
+00013370: 2020 2062 7566 6665 725f 6e61 6d65 203d     buffer_name =
+00013380: 2066 225f 6361 745f 6275 6666 6572 735f   f"_cat_buffers_
+00013390: 7b69 6e5f 6b65 797d 220d 0a20 2020 2020  {in_key}"..     
+000133a0: 2020 2020 2020 2064 6174 6120 3d20 7465         data = te
+000133b0: 6e73 6f72 6469 6374 5b69 6e5f 6b65 795d  nsordict[in_key]
+000133c0: 0d0a 2020 2020 2020 2020 2020 2020 6420  ..            d 
+000133d0: 3d20 6461 7461 2e73 697a 6528 7365 6c66  = data.size(self
+000133e0: 2e64 696d 290d 0a20 2020 2020 2020 2020  .dim)..         
+000133f0: 2020 2062 7566 6665 7220 3d20 6765 7461     buffer = geta
+00013400: 7474 7228 7365 6c66 2c20 6275 6666 6572  ttr(self, buffer
+00013410: 5f6e 616d 6529 0d0a 2020 2020 2020 2020  _name)..        
+00013420: 2020 2020 6966 2069 7369 6e73 7461 6e63      if isinstanc
+00013430: 6528 6275 6666 6572 2c20 746f 7263 682e  e(buffer, torch.
+00013440: 6e6e 2e70 6172 616d 6574 6572 2e55 6e69  nn.parameter.Uni
+00013450: 6e69 7469 616c 697a 6564 4275 6666 6572  nitializedBuffer
+00013460: 293a 0d0a 2020 2020 2020 2020 2020 2020  ):..            
+00013470: 2020 2020 6275 6666 6572 203d 2073 656c      buffer = sel
+00013480: 662e 5f6d 616b 655f 6d69 7373 696e 675f  f._make_missing_
+00013490: 6275 6666 6572 2864 6174 612c 2062 7566  buffer(data, buf
+000134a0: 6665 725f 6e61 6d65 290d 0a20 2020 2020  fer_name)..     
+000134b0: 2020 2020 2020 2023 2073 6869 6674 206f         # shift o
+000134c0: 6273 2031 2070 6f73 6974 696f 6e20 746f  bs 1 position to
+000134d0: 2074 6865 2072 6967 6874 0d0a 2020 2020   the right..    
+000134e0: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
+000134f0: 5f6a 7573 745f 7265 7365 7420 6f72 2028  _just_reset or (
+00013500: 5f72 6573 6574 2069 7320 6e6f 7420 4e6f  _reset is not No
+00013510: 6e65 2061 6e64 205f 7265 7365 742e 616e  ne and _reset.an
+00013520: 7928 2929 3a0d 0a20 2020 2020 2020 2020  y()):..         
+00013530: 2020 2020 2020 2064 6174 615f 696e 203d         data_in =
+00013540: 2062 7566 6665 725b 5f72 6573 6574 5d0d   buffer[_reset].
+00013550: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00013560: 2073 6861 7065 203d 205b 3120 666f 7220   shape = [1 for 
+00013570: 5f20 696e 2064 6174 615f 696e 2e73 6861  _ in data_in.sha
+00013580: 7065 5d0d 0a20 2020 2020 2020 2020 2020  pe]..           
+00013590: 2020 2020 2073 6861 7065 5b73 656c 662e       shape[self.
+000135a0: 6469 6d5d 203d 2073 656c 662e 4e0d 0a20  dim] = self.N.. 
+000135b0: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+000135c0: 6620 7365 6c66 2e70 6164 6469 6e67 203d  f self.padding =
+000135d0: 3d20 2273 616d 6522 3a0d 0a20 2020 2020  = "same":..     
+000135e0: 2020 2020 2020 2020 2020 2020 2020 2062                 b
+000135f0: 7566 6665 725b 5f72 6573 6574 5d20 3d20  uffer[_reset] = 
+00013600: 6275 6666 6572 5b5f 7265 7365 745d 2e63  buffer[_reset].c
+00013610: 6f70 795f 280d 0a20 2020 2020 2020 2020  opy_(..         
+00013620: 2020 2020 2020 2020 2020 2020 2020 2064                 d
+00013630: 6174 615b 5f72 6573 6574 5d2e 7265 7065  ata[_reset].repe
+00013640: 6174 2873 6861 7065 292e 636c 6f6e 6528  at(shape).clone(
+00013650: 290d 0a20 2020 2020 2020 2020 2020 2020  )..             
+00013660: 2020 2020 2020 2029 0d0a 2020 2020 2020         )..      
+00013670: 2020 2020 2020 2020 2020 656c 6966 2073            elif s
+00013680: 656c 662e 7061 6464 696e 6720 3d3d 2022  elf.padding == "
+00013690: 7a65 726f 7322 3a0d 0a20 2020 2020 2020  zeros":..       
+000136a0: 2020 2020 2020 2020 2020 2020 2062 7566               buf
+000136b0: 6665 725b 5f72 6573 6574 5d20 3d20 300d  fer[_reset] = 0.
+000136c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000136d0: 2065 6c73 653a 0d0a 2020 2020 2020 2020   else:..        
+000136e0: 2020 2020 2020 2020 2020 2020 2320 6d61              # ma
+000136f0: 6b65 206c 696e 7465 7220 6861 7070 792e  ke linter happy.
+00013700: 2041 6e20 6578 6365 7074 696f 6e20 6861   An exception ha
+00013710: 7320 616c 7265 6164 7920 6265 656e 2072  s already been r
+00013720: 6169 7365 640d 0a20 2020 2020 2020 2020  aised..         
+00013730: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+00013740: 204e 6f74 496d 706c 656d 656e 7465 6445   NotImplementedE
+00013750: 7272 6f72 0d0a 2020 2020 2020 2020 2020  rror..          
+00013760: 2020 6275 6666 6572 2e63 6f70 795f 2874    buffer.copy_(t
+00013770: 6f72 6368 2e72 6f6c 6c28 6275 6666 6572  orch.roll(buffer
+00013780: 2c20 7368 6966 7473 3d2d 642c 2064 696d  , shifts=-d, dim
+00013790: 733d 7365 6c66 2e64 696d 2929 0d0a 2020  s=self.dim))..  
+000137a0: 2020 2020 2020 2020 2020 2320 6164 6420            # add 
+000137b0: 6e65 7720 6f62 730d 0a20 2020 2020 2020  new obs..       
+000137c0: 2020 2020 2069 6478 203d 2073 656c 662e       idx = self.
+000137d0: 6469 6d0d 0a20 2020 2020 2020 2020 2020  dim..           
+000137e0: 2069 6620 6964 7820 3c20 303a 0d0a 2020   if idx < 0:..  
+000137f0: 2020 2020 2020 2020 2020 2020 2020 6964                id
+00013800: 7820 3d20 6275 6666 6572 2e6e 6469 6d65  x = buffer.ndime
+00013810: 6e73 696f 6e28 2920 2b20 6964 780d 0a20  nsion() + idx.. 
+00013820: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
+00013830: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00013840: 2020 7261 6973 6520 5661 6c75 6545 7272    raise ValueErr
+00013850: 6f72 2873 656c 662e 5f43 4154 5f44 494d  or(self._CAT_DIM
+00013860: 5f45 5252 290d 0a20 2020 2020 2020 2020  _ERR)..         
+00013870: 2020 2069 6478 203d 205b 736c 6963 6528     idx = [slice(
+00013880: 4e6f 6e65 2c20 4e6f 6e65 2920 666f 7220  None, None) for 
+00013890: 5f20 696e 2072 616e 6765 2869 6478 295d  _ in range(idx)]
+000138a0: 202b 205b 736c 6963 6528 2d64 2c20 4e6f   + [slice(-d, No
+000138b0: 6e65 295d 0d0a 2020 2020 2020 2020 2020  ne)]..          
+000138c0: 2020 6275 6666 6572 5b69 6478 5d2e 636f    buffer[idx].co
+000138d0: 7079 5f28 6461 7461 290d 0a20 2020 2020  py_(data)..     
+000138e0: 2020 2020 2020 2023 2061 6464 2074 6f20         # add to 
+000138f0: 7465 6e73 6f72 6469 6374 0d0a 2020 2020  tensordict..    
+00013900: 2020 2020 2020 2020 7465 6e73 6f72 6469          tensordi
+00013910: 6374 2e73 6574 286f 7574 5f6b 6579 2c20  ct.set(out_key, 
+00013920: 6275 6666 6572 2e63 6c6f 6e65 2829 290d  buffer.clone()).
+00013930: 0a20 2020 2020 2020 2073 656c 662e 5f6a  .        self._j
+00013940: 7573 745f 7265 7365 7420 3d20 4661 6c73  ust_reset = Fals
+00013950: 650d 0a20 2020 2020 2020 2072 6574 7572  e..        retur
+00013960: 6e20 7465 6e73 6f72 6469 6374 0d0a 0d0a  n tensordict....
+00013970: 2020 2020 405f 6170 706c 795f 746f 5f63      @_apply_to_c
+00013980: 6f6d 706f 7369 7465 0d0a 2020 2020 6465  omposite..    de
+00013990: 6620 7472 616e 7366 6f72 6d5f 6f62 7365  f transform_obse
+000139a0: 7276 6174 696f 6e5f 7370 6563 2873 656c  rvation_spec(sel
+000139b0: 662c 206f 6273 6572 7661 7469 6f6e 5f73  f, observation_s
+000139c0: 7065 633a 2054 656e 736f 7253 7065 6329  pec: TensorSpec)
+000139d0: 202d 3e20 5465 6e73 6f72 5370 6563 3a0d   -> TensorSpec:.
+000139e0: 0a20 2020 2020 2020 2073 7061 6365 203d  .        space =
+000139f0: 206f 6273 6572 7661 7469 6f6e 5f73 7065   observation_spe
+00013a00: 632e 7370 6163 650d 0a20 2020 2020 2020  c.space..       
+00013a10: 2069 6620 6973 696e 7374 616e 6365 2873   if isinstance(s
+00013a20: 7061 6365 2c20 436f 6e74 696e 756f 7573  pace, Continuous
+00013a30: 426f 7829 3a0d 0a20 2020 2020 2020 2020  Box):..         
+00013a40: 2020 2073 7061 6365 2e6d 696e 696d 756d     space.minimum
+00013a50: 203d 2074 6f72 6368 2e63 6174 285b 7370   = torch.cat([sp
+00013a60: 6163 652e 6d69 6e69 6d75 6d5d 202a 2073  ace.minimum] * s
+00013a70: 656c 662e 4e2c 2073 656c 662e 6469 6d29  elf.N, self.dim)
+00013a80: 0d0a 2020 2020 2020 2020 2020 2020 7370  ..            sp
+00013a90: 6163 652e 6d61 7869 6d75 6d20 3d20 746f  ace.maximum = to
+00013aa0: 7263 682e 6361 7428 5b73 7061 6365 2e6d  rch.cat([space.m
+00013ab0: 6178 696d 756d 5d20 2a20 7365 6c66 2e4e  aximum] * self.N
+00013ac0: 2c20 7365 6c66 2e64 696d 290d 0a20 2020  , self.dim)..   
+00013ad0: 2020 2020 2020 2020 206f 6273 6572 7661           observa
+00013ae0: 7469 6f6e 5f73 7065 632e 7368 6170 6520  tion_spec.shape 
+00013af0: 3d20 7370 6163 652e 6d69 6e69 6d75 6d2e  = space.minimum.
+00013b00: 7368 6170 650d 0a20 2020 2020 2020 2065  shape..        e
+00013b10: 6c73 653a 0d0a 2020 2020 2020 2020 2020  lse:..          
+00013b20: 2020 7368 6170 6520 3d20 6c69 7374 286f    shape = list(o
+00013b30: 6273 6572 7661 7469 6f6e 5f73 7065 632e  bservation_spec.
+00013b40: 7368 6170 6529 0d0a 2020 2020 2020 2020  shape)..        
+00013b50: 2020 2020 7368 6170 655b 7365 6c66 2e64      shape[self.d
+00013b60: 696d 5d20 3d20 7365 6c66 2e4e 202a 2073  im] = self.N * s
+00013b70: 6861 7065 5b73 656c 662e 6469 6d5d 0d0a  hape[self.dim]..
+00013b80: 2020 2020 2020 2020 2020 2020 6f62 7365              obse
+00013b90: 7276 6174 696f 6e5f 7370 6563 2e73 6861  rvation_spec.sha
+00013ba0: 7065 203d 2074 6f72 6368 2e53 697a 6528  pe = torch.Size(
+00013bb0: 7368 6170 6529 0d0a 2020 2020 2020 2020  shape)..        
+00013bc0: 7265 7475 726e 206f 6273 6572 7661 7469  return observati
+00013bd0: 6f6e 5f73 7065 630d 0a0d 0a20 2020 2064  on_spec....    d
+00013be0: 6566 2066 6f72 7761 7264 2873 656c 662c  ef forward(self,
+00013bf0: 2074 656e 736f 7264 6963 743a 2054 656e   tensordict: Ten
+00013c00: 736f 7244 6963 7442 6173 6529 202d 3e20  sorDictBase) -> 
+00013c10: 5465 6e73 6f72 4469 6374 4261 7365 3a0d  TensorDictBase:.
+00013c20: 0a20 2020 2020 2020 2023 2069 7420 6973  .        # it is
+00013c30: 2061 7373 756d 6564 2074 6861 7420 7468   assumed that th
+00013c40: 6520 6c61 7374 2064 696d 656e 7369 6f6e  e last dimension
+00013c50: 206f 6620 7468 6520 7465 6e73 6f72 6469   of the tensordi
+00013c60: 6374 2069 7320 7468 6520 7469 6d65 2064  ct is the time d
+00013c70: 696d 656e 7369 6f6e 0d0a 2020 2020 2020  imension..      
+00013c80: 2020 6966 206e 6f74 2074 656e 736f 7264    if not tensord
+00013c90: 6963 742e 6e64 696d 206f 7220 280d 0a20  ict.ndim or (.. 
+00013ca0: 2020 2020 2020 2020 2020 2074 656e 736f             tenso
+00013cb0: 7264 6963 742e 6e61 6d65 735b 2d31 5d20  rdict.names[-1] 
+00013cc0: 6973 206e 6f74 204e 6f6e 6520 616e 6420  is not None and 
+00013cd0: 7465 6e73 6f72 6469 6374 2e6e 616d 6573  tensordict.names
+00013ce0: 5b2d 315d 2021 3d20 2274 696d 6522 0d0a  [-1] != "time"..
+00013cf0: 2020 2020 2020 2020 293a 0d0a 2020 2020          ):..    
+00013d00: 2020 2020 2020 2020 7261 6973 6520 5661          raise Va
+00013d10: 6c75 6545 7272 6f72 280d 0a20 2020 2020  lueError(..     
+00013d20: 2020 2020 2020 2020 2020 2022 5468 6520             "The 
+00013d30: 6c61 7374 2064 696d 656e 7369 6f6e 206f  last dimension o
+00013d40: 6620 7468 6520 7465 6e73 6f72 6469 6374  f the tensordict
+00013d50: 206d 7573 7420 6265 206d 6172 6b65 6420   must be marked 
+00013d60: 6173 2027 7469 6d65 272e 220d 0a20 2020  as 'time'."..   
+00013d70: 2020 2020 2020 2020 2029 0d0a 2020 2020           )..    
+00013d80: 2020 2020 2320 6669 7273 7420 736f 7274      # first sort
+00013d90: 2074 6865 2069 6e5f 6b65 7973 2077 6974   the in_keys wit
+00013da0: 6820 7374 7269 6e67 7320 616e 6420 6e6f  h strings and no
+00013db0: 6e2d 7374 7269 6e67 730d 0a20 2020 2020  n-strings..     
+00013dc0: 2020 2069 6e5f 6b65 7973 203d 206c 6973     in_keys = lis
+00013dd0: 7428 0d0a 2020 2020 2020 2020 2020 2020  t(..            
+00013de0: 7a69 7028 0d0a 2020 2020 2020 2020 2020  zip(..          
+00013df0: 2020 2020 2020 2869 6e5f 6b65 792c 206f        (in_key, o
+00013e00: 7574 5f6b 6579 290d 0a20 2020 2020 2020  ut_key)..       
+00013e10: 2020 2020 2020 2020 2066 6f72 2069 6e5f           for in_
+00013e20: 6b65 792c 206f 7574 5f6b 6579 2069 6e20  key, out_key in 
+00013e30: 7a69 7028 7365 6c66 2e69 6e5f 6b65 7973  zip(self.in_keys
+00013e40: 2c20 7365 6c66 2e6f 7574 5f6b 6579 7329  , self.out_keys)
+00013e50: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00013e60: 2020 6966 2069 7369 6e73 7461 6e63 6528    if isinstance(
+00013e70: 696e 5f6b 6579 2c20 7374 7229 206f 7220  in_key, str) or 
+00013e80: 6c65 6e28 696e 5f6b 6579 2920 3d3d 2031  len(in_key) == 1
+00013e90: 0d0a 2020 2020 2020 2020 2020 2020 290d  ..            ).
+00013ea0: 0a20 2020 2020 2020 2029 0d0a 2020 2020  .        )..    
+00013eb0: 2020 2020 696e 5f6b 6579 7320 2b3d 206c      in_keys += l
+00013ec0: 6973 7428 0d0a 2020 2020 2020 2020 2020  ist(..          
+00013ed0: 2020 7a69 7028 0d0a 2020 2020 2020 2020    zip(..        
+00013ee0: 2020 2020 2020 2020 2869 6e5f 6b65 792c          (in_key,
+00013ef0: 206f 7574 5f6b 6579 290d 0a20 2020 2020   out_key)..     
+00013f00: 2020 2020 2020 2020 2020 2066 6f72 2069             for i
+00013f10: 6e5f 6b65 792c 206f 7574 5f6b 6579 2069  n_key, out_key i
+00013f20: 6e20 7a69 7028 7365 6c66 2e69 6e5f 6b65  n zip(self.in_ke
+00013f30: 7973 2c20 7365 6c66 2e6f 7574 5f6b 6579  ys, self.out_key
+00013f40: 7329 0d0a 2020 2020 2020 2020 2020 2020  s)..            
+00013f50: 2020 2020 6966 206e 6f74 2069 7369 6e73      if not isins
+00013f60: 7461 6e63 6528 696e 5f6b 6579 2c20 7374  tance(in_key, st
+00013f70: 7229 2061 6e64 206e 6f74 206c 656e 2869  r) and not len(i
+00013f80: 6e5f 6b65 7929 203d 3d20 310d 0a20 2020  n_key) == 1..   
+00013f90: 2020 2020 2020 2020 2029 0d0a 2020 2020           )..    
+00013fa0: 2020 2020 290d 0a20 2020 2020 2020 2066      )..        f
+00013fb0: 6f72 2069 6e5f 6b65 792c 206f 7574 5f6b  or in_key, out_k
+00013fc0: 6579 2069 6e20 7a69 7028 7365 6c66 2e69  ey in zip(self.i
+00013fd0: 6e5f 6b65 7973 2c20 7365 6c66 2e6f 7574  n_keys, self.out
+00013fe0: 5f6b 6579 7329 3a0d 0a20 2020 2020 2020  _keys):..       
+00013ff0: 2020 2020 2023 2063 6865 636b 2069 6620       # check if 
+00014000: 7765 2068 6176 6520 616e 206f 6273 2069  we have an obs i
+00014010: 6e20 226e 6578 7422 2074 6861 7420 6861  n "next" that ha
+00014020: 7320 616c 7265 6164 7920 6265 656e 2070  s already been p
+00014030: 726f 6365 7373 6564 2e0d 0a20 2020 2020  rocessed...     
+00014040: 2020 2020 2020 2023 2049 6620 736f 2c20         # If so, 
+00014050: 7765 206d 7573 7420 6164 6420 616e 206f  we must add an o
+00014060: 6666 7365 740d 0a20 2020 2020 2020 2020  ffset..         
+00014070: 2020 2064 6174 6120 3d20 7465 6e73 6f72     data = tensor
+00014080: 6469 6374 2e67 6574 2869 6e5f 6b65 7929  dict.get(in_key)
+00014090: 0d0a 2020 2020 2020 2020 2020 2020 6966  ..            if
+000140a0: 2069 7369 6e73 7461 6e63 6528 696e 5f6b   isinstance(in_k
+000140b0: 6579 2c20 7475 706c 6529 2061 6e64 2069  ey, tuple) and i
+000140c0: 6e5f 6b65 795b 305d 203d 3d20 226e 6578  n_key[0] == "nex
+000140d0: 7422 3a0d 0a0d 0a20 2020 2020 2020 2020  t":....         
+000140e0: 2020 2020 2020 2023 206c 6574 2773 2067         # let's g
+000140f0: 6574 2074 6865 206f 7574 5f6b 6579 2077  et the out_key w
+00014100: 6520 6861 7665 2061 6c72 6561 6479 2070  e have already p
+00014110: 726f 6365 7373 6564 0d0a 2020 2020 2020  rocessed..      
+00014120: 2020 2020 2020 2020 2020 7072 6576 5f6f            prev_o
+00014130: 7574 5f6b 6579 203d 2064 6963 7428 7a69  ut_key = dict(zi
+00014140: 7028 7365 6c66 2e69 6e5f 6b65 7973 2c20  p(self.in_keys, 
+00014150: 7365 6c66 2e6f 7574 5f6b 6579 7329 295b  self.out_keys))[
+00014160: 696e 5f6b 6579 5b31 5d5d 0d0a 2020 2020  in_key[1]]..    
+00014170: 2020 2020 2020 2020 2020 2020 7072 6576              prev
+00014180: 5f76 616c 203d 2074 656e 736f 7264 6963  _val = tensordic
+00014190: 742e 6765 7428 7072 6576 5f6f 7574 5f6b  t.get(prev_out_k
+000141a0: 6579 290d 0a20 2020 2020 2020 2020 2020  ey)..           
+000141b0: 2020 2020 2023 2074 6865 2066 6972 7374       # the first
+000141c0: 2069 7465 6d20 6973 206c 6f63 6174 6564   item is located
+000141d0: 2061 6c6f 6e67 2060 6469 6d2b 3160 2061   along `dim+1` a
+000141e0: 7420 7468 6520 6c61 7374 2069 6e64 6578  t the last index
+000141f0: 206f 6620 7468 650d 0a20 2020 2020 2020   of the..       
+00014200: 2020 2020 2020 2020 2023 2066 6972 7374           # first
+00014210: 2074 696d 6520 696e 6465 780d 0a20 2020   time index..   
+00014220: 2020 2020 2020 2020 2020 2020 2069 6478               idx
+00014230: 203d 2028 0d0a 2020 2020 2020 2020 2020   = (..          
+00014240: 2020 2020 2020 2020 2020 5b73 6c69 6365            [slice
+00014250: 284e 6f6e 6529 5d20 2a20 2874 656e 736f  (None)] * (tenso
+00014260: 7264 6963 742e 6e64 696d 202d 2031 290d  rdict.ndim - 1).
+00014270: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00014280: 2020 2020 202b 205b 305d 0d0a 2020 2020       + [0]..    
+00014290: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000142a0: 2b20 5b2e 2e2e 2c20 2d31 5d0d 0a20 2020  + [..., -1]..   
+000142b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000142c0: 202b 205b 736c 6963 6528 4e6f 6e65 295d   + [slice(None)]
+000142d0: 202a 2028 6162 7328 7365 6c66 2e64 696d   * (abs(self.dim
+000142e0: 2920 2d20 3129 0d0a 2020 2020 2020 2020  ) - 1)..        
+000142f0: 2020 2020 2020 2020 290d 0a20 2020 2020          )..     
+00014300: 2020 2020 2020 2020 2020 2066 6972 7374             first
+00014310: 5f76 616c 203d 2070 7265 765f 7661 6c5b  _val = prev_val[
+00014320: 7475 706c 6528 6964 7829 5d2e 756e 7371  tuple(idx)].unsq
+00014330: 7565 657a 6528 7465 6e73 6f72 6469 6374  ueeze(tensordict
+00014340: 2e6e 6469 6d20 2d20 3129 0d0a 2020 2020  .ndim - 1)..    
+00014350: 2020 2020 2020 2020 2020 2020 6461 7461              data
+00014360: 3020 3d20 5b66 6972 7374 5f76 616c 5d20  0 = [first_val] 
+00014370: 2a20 2873 656c 662e 4e20 2d20 3129 0d0a  * (self.N - 1)..
+00014380: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00014390: 6966 2073 656c 662e 7061 6464 696e 6720  if self.padding 
+000143a0: 3d3d 2022 7a65 726f 7322 3a0d 0a20 2020  == "zeros":..   
+000143b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000143c0: 2064 6174 6130 203d 205b 746f 7263 682e   data0 = [torch.
+000143d0: 7a65 726f 735f 6c69 6b65 2865 6c74 2920  zeros_like(elt) 
+000143e0: 666f 7220 656c 7420 696e 2064 6174 6130  for elt in data0
+000143f0: 5b3a 2d31 5d5d 202b 2064 6174 6130 5b2d  [:-1]] + data0[-
+00014400: 313a 5d0d 0a20 2020 2020 2020 2020 2020  1:]..           
+00014410: 2020 2020 2065 6c69 6620 7365 6c66 2e70       elif self.p
+00014420: 6164 6469 6e67 203d 3d20 2273 616d 6522  adding == "same"
+00014430: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
+00014440: 2020 2020 2020 2070 6173 730d 0a20 2020         pass..   
+00014450: 2020 2020 2020 2020 2020 2020 2065 6c73               els
+00014460: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
+00014470: 2020 2020 2020 2020 2320 6d61 6b65 206c          # make l
+00014480: 696e 7465 7220 6861 7070 792e 2041 6e20  inter happy. An 
+00014490: 6578 6365 7074 696f 6e20 6861 7320 616c  exception has al
+000144a0: 7265 6164 7920 6265 656e 2072 6169 7365  ready been raise
+000144b0: 640d 0a20 2020 2020 2020 2020 2020 2020  d..             
+000144c0: 2020 2020 2020 2072 6169 7365 204e 6f74         raise Not
+000144d0: 496d 706c 656d 656e 7465 6445 7272 6f72  ImplementedError
+000144e0: 0d0a 2020 2020 2020 2020 2020 2020 656c  ..            el
+000144f0: 6966 2073 656c 662e 7061 6464 696e 6720  if self.padding 
+00014500: 3d3d 2022 7361 6d65 223a 0d0a 2020 2020  == "same":..    
+00014510: 2020 2020 2020 2020 2020 2020 6964 7820              idx 
+00014520: 3d20 5b73 6c69 6365 284e 6f6e 6529 5d20  = [slice(None)] 
+00014530: 2a20 2874 656e 736f 7264 6963 742e 6e64  * (tensordict.nd
+00014540: 696d 202d 2031 2920 2b20 5b30 5d0d 0a20  im - 1) + [0].. 
+00014550: 2020 2020 2020 2020 2020 2020 2020 2064                 d
+00014560: 6174 6130 203d 205b 6461 7461 5b74 7570  ata0 = [data[tup
+00014570: 6c65 2869 6478 295d 2e75 6e73 7175 6565  le(idx)].unsquee
+00014580: 7a65 2874 656e 736f 7264 6963 742e 6e64  ze(tensordict.nd
+00014590: 696d 202d 2031 295d 202a 2028 7365 6c66  im - 1)] * (self
+000145a0: 2e4e 202d 2031 290d 0a20 2020 2020 2020  .N - 1)..       
+000145b0: 2020 2020 2065 6c69 6620 7365 6c66 2e70       elif self.p
+000145c0: 6164 6469 6e67 203d 3d20 227a 6572 6f73  adding == "zeros
+000145d0: 223a 0d0a 2020 2020 2020 2020 2020 2020  ":..            
+000145e0: 2020 2020 6964 7820 3d20 5b73 6c69 6365      idx = [slice
+000145f0: 284e 6f6e 6529 5d20 2a20 2874 656e 736f  (None)] * (tenso
+00014600: 7264 6963 742e 6e64 696d 202d 2031 2920  rdict.ndim - 1) 
+00014610: 2b20 5b30 5d0d 0a20 2020 2020 2020 2020  + [0]..         
+00014620: 2020 2020 2020 2064 6174 6130 203d 205b         data0 = [
+00014630: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00014640: 2020 2020 2020 746f 7263 682e 7a65 726f        torch.zero
+00014650: 735f 6c69 6b65 2864 6174 615b 7475 706c  s_like(data[tupl
+00014660: 6528 6964 7829 5d29 2e75 6e73 7175 6565  e(idx)]).unsquee
+00014670: 7a65 2874 656e 736f 7264 6963 742e 6e64  ze(tensordict.nd
+00014680: 696d 202d 2031 290d 0a20 2020 2020 2020  im - 1)..       
+00014690: 2020 2020 2020 2020 205d 202a 2028 7365           ] * (se
+000146a0: 6c66 2e4e 202d 2031 290d 0a20 2020 2020  lf.N - 1)..     
+000146b0: 2020 2020 2020 2065 6c73 653a 0d0a 2020         else:..  
+000146c0: 2020 2020 2020 2020 2020 2020 2020 2320                # 
+000146d0: 6d61 6b65 206c 696e 7465 7220 6861 7070  make linter happ
+000146e0: 792e 2041 6e20 6578 6365 7074 696f 6e20  y. An exception 
+000146f0: 6861 7320 616c 7265 6164 7920 6265 656e  has already been
+00014700: 2072 6169 7365 640d 0a20 2020 2020 2020   raised..       
+00014710: 2020 2020 2020 2020 2072 6169 7365 204e           raise N
+00014720: 6f74 496d 706c 656d 656e 7465 6445 7272  otImplementedErr
+00014730: 6f72 0d0a 0d0a 2020 2020 2020 2020 2020  or....          
+00014740: 2020 6461 7461 203d 2074 6f72 6368 2e63    data = torch.c
+00014750: 6174 2864 6174 6130 202b 205b 6461 7461  at(data0 + [data
+00014760: 5d2c 2074 656e 736f 7264 6963 742e 6e64  ], tensordict.nd
+00014770: 696d 202d 2031 290d 0a0d 0a20 2020 2020  im - 1)....     
+00014780: 2020 2020 2020 2064 6174 6120 3d20 6461         data = da
+00014790: 7461 2e75 6e66 6f6c 6428 7465 6e73 6f72  ta.unfold(tensor
+000147a0: 6469 6374 2e6e 6469 6d20 2d20 312c 2073  dict.ndim - 1, s
+000147b0: 656c 662e 4e2c 2031 290d 0a20 2020 2020  elf.N, 1)..     
+000147c0: 2020 2020 2020 2064 6174 6120 3d20 6461         data = da
+000147d0: 7461 2e70 6572 6d75 7465 280d 0a20 2020  ta.permute(..   
+000147e0: 2020 2020 2020 2020 2020 2020 202a 7261               *ra
+000147f0: 6e67 6528 302c 2064 6174 612e 6e64 696d  nge(0, data.ndim
+00014800: 202b 2073 656c 662e 6469 6d29 2c0d 0a20   + self.dim),.. 
+00014810: 2020 2020 2020 2020 2020 2020 2020 202d                 -
+00014820: 312c 0d0a 2020 2020 2020 2020 2020 2020  1,..            
+00014830: 2020 2020 2a72 616e 6765 2864 6174 612e      *range(data.
+00014840: 6e64 696d 202b 2073 656c 662e 6469 6d2c  ndim + self.dim,
+00014850: 2064 6174 612e 6e64 696d 202d 2031 292c   data.ndim - 1),
+00014860: 0d0a 2020 2020 2020 2020 2020 2020 290d  ..            ).
+00014870: 0a20 2020 2020 2020 2020 2020 2074 656e  .            ten
+00014880: 736f 7264 6963 742e 7365 7428 6f75 745f  sordict.set(out_
+00014890: 6b65 792c 2064 6174 6129 0d0a 2020 2020  key, data)..    
+000148a0: 2020 2020 7265 7475 726e 2074 656e 736f      return tenso
+000148b0: 7264 6963 740d 0a0d 0a20 2020 2064 6566  rdict....    def
+000148c0: 205f 5f72 6570 725f 5f28 7365 6c66 2920   __repr__(self) 
+000148d0: 2d3e 2073 7472 3a0d 0a20 2020 2020 2020  -> str:..       
+000148e0: 2072 6574 7572 6e20 280d 0a20 2020 2020   return (..     
+000148f0: 2020 2020 2020 2066 227b 7365 6c66 2e5f         f"{self._
+00014900: 5f63 6c61 7373 5f5f 2e5f 5f6e 616d 655f  _class__.__name_
+00014910: 5f7d 284e 3d7b 7365 6c66 2e4e 7d2c 2064  _}(N={self.N}, d
+00014920: 696d 220d 0a20 2020 2020 2020 2020 2020  im"..           
+00014930: 2066 223d 7b73 656c 662e 6469 6d7d 2c20   f"={self.dim}, 
+00014940: 6b65 7973 3d7b 7365 6c66 2e69 6e5f 6b65  keys={self.in_ke
+00014950: 7973 7d29 220d 0a20 2020 2020 2020 2029  ys})"..        )
+00014960: 0d0a 0d0a 0d0a 636c 6173 7320 5265 7761  ......class Rewa
+00014970: 7264 5363 616c 696e 6728 5472 616e 7366  rdScaling(Transf
+00014980: 6f72 6d29 3a0d 0a20 2020 2022 2222 4166  orm):..    """Af
+00014990: 6669 6e65 2074 7261 6e73 666f 726d 206f  fine transform o
+000149a0: 6620 7468 6520 7265 7761 7264 2e0d 0a0d  f the reward....
+000149b0: 0a20 2020 2020 5468 6520 7265 7761 7264  .     The reward
+000149c0: 2069 7320 7472 616e 7366 6f72 6d65 6420   is transformed 
+000149d0: 6163 636f 7264 696e 6720 746f 3a0d 0a0d  according to:...
+000149e0: 0a20 2020 202e 2e20 6d61 7468 3a3a 0d0a  .    .. math::..
+000149f0: 2020 2020 2020 2020 7265 7761 7264 203d          reward =
+00014a00: 2072 6577 6172 6420 2a20 7363 616c 6520   reward * scale 
+00014a10: 2b20 6c6f 630d 0a0d 0a20 2020 2041 7267  + loc....    Arg
+00014a20: 733a 0d0a 2020 2020 2020 2020 6c6f 6320  s:..        loc 
+00014a30: 286e 756d 6265 7220 6f72 2074 6f72 6368  (number or torch
+00014a40: 2e54 656e 736f 7229 3a20 6c6f 6361 7469  .Tensor): locati
+00014a50: 6f6e 206f 6620 7468 6520 6166 6669 6e65  on of the affine
+00014a60: 2074 7261 6e73 666f 726d 0d0a 2020 2020   transform..    
+00014a70: 2020 2020 7363 616c 6520 286e 756d 6265      scale (numbe
+00014a80: 7220 6f72 2074 6f72 6368 2e54 656e 736f  r or torch.Tenso
+00014a90: 7229 3a20 7363 616c 6520 6f66 2074 6865  r): scale of the
+00014aa0: 2061 6666 696e 6520 7472 616e 7366 6f72   affine transfor
+00014ab0: 6d0d 0a20 2020 2020 2020 2073 7461 6e64  m..        stand
+00014ac0: 6172 645f 6e6f 726d 616c 2028 626f 6f6c  ard_normal (bool
+00014ad0: 2c20 6f70 7469 6f6e 616c 293a 2069 6620  , optional): if 
+00014ae0: 6060 5472 7565 6060 2c20 7468 6520 7472  ``True``, the tr
+00014af0: 616e 7366 6f72 6d20 7769 6c6c 2062 650d  ansform will be.
+00014b00: 0a0d 0a20 2020 2020 2020 2020 2020 202e  ...            .
+00014b10: 2e20 6d61 7468 3a3a 0d0a 2020 2020 2020  . math::..      
+00014b20: 2020 2020 2020 2020 2020 7265 7761 7264            reward
+00014b30: 203d 2028 7265 7761 7264 2d6c 6f63 292f   = (reward-loc)/
+00014b40: 7363 616c 650d 0a0d 0a20 2020 2020 2020  scale....       
+00014b50: 2020 2020 2061 7320 6974 2069 7320 646f       as it is do
+00014b60: 6e65 2066 6f72 2073 7461 6e64 6172 6469  ne for standardi
+00014b70: 7a61 7469 6f6e 2e20 4465 6661 756c 7420  zation. Default 
+00014b80: 6973 2060 4661 6c73 6560 2e0d 0a20 2020  is `False`...   
+00014b90: 2022 2222 0d0a 0d0a 2020 2020 6465 6620   """....    def 
+00014ba0: 5f5f 696e 6974 5f5f 280d 0a20 2020 2020  __init__(..     
+00014bb0: 2020 2073 656c 662c 0d0a 2020 2020 2020     self,..      
+00014bc0: 2020 6c6f 633a 2055 6e69 6f6e 5b66 6c6f    loc: Union[flo
+00014bd0: 6174 2c20 746f 7263 682e 5465 6e73 6f72  at, torch.Tensor
+00014be0: 5d2c 0d0a 2020 2020 2020 2020 7363 616c  ],..        scal
+00014bf0: 653a 2055 6e69 6f6e 5b66 6c6f 6174 2c20  e: Union[float, 
+00014c00: 746f 7263 682e 5465 6e73 6f72 5d2c 0d0a  torch.Tensor],..
+00014c10: 2020 2020 2020 2020 696e 5f6b 6579 733a          in_keys:
+00014c20: 204f 7074 696f 6e61 6c5b 5365 7175 656e   Optional[Sequen
+00014c30: 6365 5b73 7472 5d5d 203d 204e 6f6e 652c  ce[str]] = None,
+00014c40: 0d0a 2020 2020 2020 2020 7374 616e 6461  ..        standa
+00014c50: 7264 5f6e 6f72 6d61 6c3a 2062 6f6f 6c20  rd_normal: bool 
+00014c60: 3d20 4661 6c73 652c 0d0a 2020 2020 293a  = False,..    ):
+00014c70: 0d0a 2020 2020 2020 2020 6966 2069 6e5f  ..        if in_
+00014c80: 6b65 7973 2069 7320 4e6f 6e65 3a0d 0a20  keys is None:.. 
+00014c90: 2020 2020 2020 2020 2020 2069 6e5f 6b65             in_ke
+00014ca0: 7973 203d 205b 2272 6577 6172 6422 5d0d  ys = ["reward"].
+00014cb0: 0a20 2020 2020 2020 2073 7570 6572 2829  .        super()
+00014cc0: 2e5f 5f69 6e69 745f 5f28 696e 5f6b 6579  .__init__(in_key
+00014cd0: 733d 696e 5f6b 6579 7329 0d0a 2020 2020  s=in_keys)..    
+00014ce0: 2020 2020 6966 206e 6f74 2069 7369 6e73      if not isins
+00014cf0: 7461 6e63 6528 7374 616e 6461 7264 5f6e  tance(standard_n
+00014d00: 6f72 6d61 6c2c 2074 6f72 6368 2e54 656e  ormal, torch.Ten
+00014d10: 736f 7229 3a0d 0a20 2020 2020 2020 2020  sor):..         
+00014d20: 2020 2073 7461 6e64 6172 645f 6e6f 726d     standard_norm
+00014d30: 616c 203d 2074 6f72 6368 2e74 656e 736f  al = torch.tenso
+00014d40: 7228 7374 616e 6461 7264 5f6e 6f72 6d61  r(standard_norma
+00014d50: 6c29 0d0a 2020 2020 2020 2020 7365 6c66  l)..        self
+00014d60: 2e72 6567 6973 7465 725f 6275 6666 6572  .register_buffer
+00014d70: 2822 7374 616e 6461 7264 5f6e 6f72 6d61  ("standard_norma
+00014d80: 6c22 2c20 7374 616e 6461 7264 5f6e 6f72  l", standard_nor
+00014d90: 6d61 6c29 0d0a 0d0a 2020 2020 2020 2020  mal)....        
+00014da0: 6966 206e 6f74 2069 7369 6e73 7461 6e63  if not isinstanc
+00014db0: 6528 6c6f 632c 2074 6f72 6368 2e54 656e  e(loc, torch.Ten
+00014dc0: 736f 7229 3a0d 0a20 2020 2020 2020 2020  sor):..         
+00014dd0: 2020 206c 6f63 203d 2074 6f72 6368 2e74     loc = torch.t
+00014de0: 656e 736f 7228 6c6f 6329 0d0a 2020 2020  ensor(loc)..    
+00014df0: 2020 2020 6966 206e 6f74 2069 7369 6e73      if not isins
+00014e00: 7461 6e63 6528 7363 616c 652c 2074 6f72  tance(scale, tor
+00014e10: 6368 2e54 656e 736f 7229 3a0d 0a20 2020  ch.Tensor):..   
+00014e20: 2020 2020 2020 2020 2073 6361 6c65 203d           scale =
+00014e30: 2074 6f72 6368 2e74 656e 736f 7228 7363   torch.tensor(sc
+00014e40: 616c 6529 0d0a 0d0a 2020 2020 2020 2020  ale)....        
+00014e50: 7365 6c66 2e72 6567 6973 7465 725f 6275  self.register_bu
+00014e60: 6666 6572 2822 6c6f 6322 2c20 6c6f 6329  ffer("loc", loc)
+00014e70: 0d0a 2020 2020 2020 2020 7365 6c66 2e72  ..        self.r
+00014e80: 6567 6973 7465 725f 6275 6666 6572 2822  egister_buffer("
+00014e90: 7363 616c 6522 2c20 7363 616c 652e 636c  scale", scale.cl
+00014ea0: 616d 705f 6d69 6e28 3165 2d36 2929 0d0a  amp_min(1e-6))..
+00014eb0: 0d0a 2020 2020 6465 6620 5f61 7070 6c79  ..    def _apply
+00014ec0: 5f74 7261 6e73 666f 726d 2873 656c 662c  _transform(self,
+00014ed0: 2072 6577 6172 643a 2074 6f72 6368 2e54   reward: torch.T
+00014ee0: 656e 736f 7229 202d 3e20 746f 7263 682e  ensor) -> torch.
+00014ef0: 5465 6e73 6f72 3a0d 0a20 2020 2020 2020  Tensor:..       
+00014f00: 2069 6620 7365 6c66 2e73 7461 6e64 6172   if self.standar
+00014f10: 645f 6e6f 726d 616c 3a0d 0a20 2020 2020  d_normal:..     
+00014f20: 2020 2020 2020 206c 6f63 203d 2073 656c         loc = sel
+00014f30: 662e 6c6f 630d 0a20 2020 2020 2020 2020  f.loc..         
+00014f40: 2020 2073 6361 6c65 203d 2073 656c 662e     scale = self.
+00014f50: 7363 616c 650d 0a20 2020 2020 2020 2020  scale..         
+00014f60: 2020 2072 6577 6172 6420 3d20 2872 6577     reward = (rew
+00014f70: 6172 6420 2d20 6c6f 6329 202f 2073 6361  ard - loc) / sca
+00014f80: 6c65 0d0a 2020 2020 2020 2020 2020 2020  le..            
+00014f90: 7265 7475 726e 2072 6577 6172 640d 0a20  return reward.. 
+00014fa0: 2020 2020 2020 2065 6c73 653a 0d0a 2020         else:..  
+00014fb0: 2020 2020 2020 2020 2020 7363 616c 6520            scale 
+00014fc0: 3d20 7365 6c66 2e73 6361 6c65 0d0a 2020  = self.scale..  
+00014fd0: 2020 2020 2020 2020 2020 6c6f 6320 3d20            loc = 
+00014fe0: 7365 6c66 2e6c 6f63 0d0a 2020 2020 2020  self.loc..      
+00014ff0: 2020 2020 2020 7265 7761 7264 203d 2072        reward = r
+00015000: 6577 6172 6420 2a20 7363 616c 6520 2b20  eward * scale + 
+00015010: 6c6f 630d 0a20 2020 2020 2020 2020 2020  loc..           
+00015020: 2072 6574 7572 6e20 7265 7761 7264 0d0a   return reward..
+00015030: 0d0a 2020 2020 6465 6620 7472 616e 7366  ..    def transf
+00015040: 6f72 6d5f 7265 7761 7264 5f73 7065 6328  orm_reward_spec(
+00015050: 7365 6c66 2c20 7265 7761 7264 5f73 7065  self, reward_spe
+00015060: 633a 2054 656e 736f 7253 7065 6329 202d  c: TensorSpec) -
+00015070: 3e20 5465 6e73 6f72 5370 6563 3a0d 0a20  > TensorSpec:.. 
+00015080: 2020 2020 2020 2069 6620 6973 696e 7374         if isinst
+00015090: 616e 6365 2872 6577 6172 645f 7370 6563  ance(reward_spec
+000150a0: 2c20 556e 626f 756e 6465 6443 6f6e 7469  , UnboundedConti
+000150b0: 6e75 6f75 7354 656e 736f 7253 7065 6329  nuousTensorSpec)
+000150c0: 3a0d 0a20 2020 2020 2020 2020 2020 2072  :..            r
+000150d0: 6574 7572 6e20 7265 7761 7264 5f73 7065  eturn reward_spe
+000150e0: 630d 0a20 2020 2020 2020 2065 6c73 653a  c..        else:
+000150f0: 0d0a 2020 2020 2020 2020 2020 2020 7261  ..            ra
+00015100: 6973 6520 4e6f 7449 6d70 6c65 6d65 6e74  ise NotImplement
+00015110: 6564 4572 726f 7228 0d0a 2020 2020 2020  edError(..      
+00015120: 2020 2020 2020 2020 2020 6622 7b73 656c            f"{sel
+00015130: 662e 5f5f 636c 6173 735f 5f2e 5f5f 6e61  f.__class__.__na
+00015140: 6d65 5f5f 7d2e 7472 616e 7366 6f72 6d5f  me__}.transform_
+00015150: 7265 7761 7264 5f73 7065 6320 6e6f 7420  reward_spec not 
+00015160: 220d 0a20 2020 2020 2020 2020 2020 2020  "..             
+00015170: 2020 2066 2269 6d70 6c65 6d65 6e74 6564     f"implemented
+00015180: 2066 6f72 2074 656e 736f 7220 7370 6563   for tensor spec
+00015190: 206f 6620 7479 7065 220d 0a20 2020 2020   of type"..     
+000151a0: 2020 2020 2020 2020 2020 2066 2220 7b74             f" {t
+000151b0: 7970 6528 7265 7761 7264 5f73 7065 6329  ype(reward_spec)
+000151c0: 2e5f 5f6e 616d 655f 5f7d 220d 0a20 2020  .__name__}"..   
+000151d0: 2020 2020 2020 2020 2029 0d0a 0d0a 2020           )....  
+000151e0: 2020 6465 6620 5f5f 7265 7072 5f5f 2873    def __repr__(s
+000151f0: 656c 6629 202d 3e20 7374 723a 0d0a 2020  elf) -> str:..  
+00015200: 2020 2020 2020 7265 7475 726e 2028 0d0a        return (..
+00015210: 2020 2020 2020 2020 2020 2020 6622 7b73              f"{s
+00015220: 656c 662e 5f5f 636c 6173 735f 5f2e 5f5f  elf.__class__.__
+00015230: 6e61 6d65 5f5f 7d28 220d 0a20 2020 2020  name__}("..     
+00015240: 2020 2020 2020 2066 226c 6f63 3d7b 7365         f"loc={se
+00015250: 6c66 2e6c 6f63 2e69 7465 6d28 293a 342e  lf.loc.item():4.
+00015260: 3466 7d2c 2073 6361 6c65 3d7b 7365 6c66  4f}, scale={self
+00015270: 2e73 6361 6c65 2e69 7465 6d28 293a 342e  .scale.item():4.
+00015280: 3466 7d2c 2022 0d0a 2020 2020 2020 2020  4f}, "..        
+00015290: 2020 2020 6622 6b65 7973 3d7b 7365 6c66      f"keys={self
+000152a0: 2e69 6e5f 6b65 7973 7d29 220d 0a20 2020  .in_keys})"..   
+000152b0: 2020 2020 2029 0d0a 0d0a 0d0a 636c 6173       )......clas
+000152c0: 7320 4669 6e69 7465 5465 6e73 6f72 4469  s FiniteTensorDi
+000152d0: 6374 4368 6563 6b28 5472 616e 7366 6f72  ctCheck(Transfor
+000152e0: 6d29 3a0d 0a20 2020 2022 2222 5468 6973  m):..    """This
+000152f0: 2074 7261 6e73 666f 726d 2077 696c 6c20   transform will 
+00015300: 6368 6563 6b20 7468 6174 2061 6c6c 2074  check that all t
+00015310: 6865 2069 7465 6d73 206f 6620 7468 6520  he items of the 
+00015320: 7465 6e73 6f72 6469 6374 2061 7265 2066  tensordict are f
+00015330: 696e 6974 652c 2061 6e64 2072 6169 7365  inite, and raise
+00015340: 2061 6e20 6578 6365 7074 696f 6e20 6966   an exception if
+00015350: 2074 6865 7920 6172 6520 6e6f 742e 2222   they are not.""
+00015360: 220d 0a0d 0a20 2020 2064 6566 205f 5f69  "....    def __i
+00015370: 6e69 745f 5f28 7365 6c66 293a 0d0a 2020  nit__(self):..  
+00015380: 2020 2020 2020 7375 7065 7228 292e 5f5f        super().__
+00015390: 696e 6974 5f5f 2869 6e5f 6b65 7973 3d5b  init__(in_keys=[
+000153a0: 5d29 0d0a 0d0a 2020 2020 6465 6620 5f63  ])....    def _c
+000153b0: 616c 6c28 7365 6c66 2c20 7465 6e73 6f72  all(self, tensor
+000153c0: 6469 6374 3a20 5465 6e73 6f72 4469 6374  dict: TensorDict
+000153d0: 4261 7365 2920 2d3e 2054 656e 736f 7244  Base) -> TensorD
+000153e0: 6963 7442 6173 653a 0d0a 2020 2020 2020  ictBase:..      
+000153f0: 2020 7465 6e73 6f72 6469 6374 2e61 7070    tensordict.app
+00015400: 6c79 2863 6865 636b 5f66 696e 6974 6529  ly(check_finite)
+00015410: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
+00015420: 2074 656e 736f 7264 6963 740d 0a0d 0a20   tensordict.... 
+00015430: 2020 2066 6f72 7761 7264 203d 205f 6361     forward = _ca
+00015440: 6c6c 0d0a 0d0a 0d0a 636c 6173 7320 446f  ll......class Do
+00015450: 7562 6c65 546f 466c 6f61 7428 5472 616e  ubleToFloat(Tran
+00015460: 7366 6f72 6d29 3a0d 0a20 2020 2022 2222  sform):..    """
+00015470: 4d61 7073 2061 6374 696f 6e73 2066 6c6f  Maps actions flo
+00015480: 6174 2074 6f20 646f 7562 6c65 2062 6566  at to double bef
+00015490: 6f72 6520 7468 6579 2061 7265 2063 616c  ore they are cal
+000154a0: 6c65 6420 6f6e 2074 6865 2065 6e76 6972  led on the envir
+000154b0: 6f6e 6d65 6e74 2e0d 0a0d 0a20 2020 2041  onment.....    A
+000154c0: 7267 733a 0d0a 2020 2020 2020 2020 696e  rgs:..        in
+000154d0: 5f6b 6579 7320 286c 6973 7420 6f66 2073  _keys (list of s
+000154e0: 7472 2c20 6f70 7469 6f6e 616c 293a 206c  tr, optional): l
+000154f0: 6973 7420 6f66 2064 6f75 626c 6520 6b65  ist of double ke
+00015500: 7973 2074 6f20 6265 2063 6f6e 7665 7274  ys to be convert
+00015510: 6564 2074 6f0d 0a20 2020 2020 2020 2020  ed to..         
+00015520: 2020 2066 6c6f 6174 2062 6566 6f72 6520     float before 
+00015530: 6265 696e 6720 6578 706f 7365 6420 746f  being exposed to
+00015540: 2065 7874 6572 6e61 6c20 6f62 6a65 6374   external object
+00015550: 7320 616e 6420 6675 6e63 7469 6f6e 732e  s and functions.
+00015560: 0d0a 2020 2020 2020 2020 696e 5f6b 6579  ..        in_key
+00015570: 735f 696e 7620 286c 6973 7420 6f66 2073  s_inv (list of s
+00015580: 7472 2c20 6f70 7469 6f6e 616c 293a 206c  tr, optional): l
+00015590: 6973 7420 6f66 2066 6c6f 6174 206b 6579  ist of float key
+000155a0: 7320 746f 2062 6520 636f 6e76 6572 7465  s to be converte
+000155b0: 6420 746f 0d0a 2020 2020 2020 2020 2020  d to..          
+000155c0: 2020 646f 7562 6c65 2062 6566 6f72 6520    double before 
+000155d0: 6265 696e 6720 7061 7373 6564 2074 6f20  being passed to 
+000155e0: 7468 6520 636f 6e74 6169 6e65 6420 6261  the contained ba
+000155f0: 7365 5f65 6e76 206f 7220 7374 6f72 6167  se_env or storag
+00015600: 652e 0d0a 0d0a 2020 2020 4578 616d 706c  e.....    Exampl
+00015610: 6573 3a0d 0a20 2020 2020 2020 203e 3e3e  es:..        >>>
+00015620: 2074 6420 3d20 5465 6e73 6f72 4469 6374   td = TensorDict
+00015630: 280d 0a20 2020 2020 2020 202e 2e2e 2020  (..        ...  
+00015640: 2020 207b 276f 6273 273a 2074 6f72 6368     {'obs': torch
+00015650: 2e6f 6e65 7328 312c 2064 7479 7065 3d74  .ones(1, dtype=t
+00015660: 6f72 6368 2e64 6f75 626c 6529 7d2c 205b  orch.double)}, [
+00015670: 5d29 0d0a 2020 2020 2020 2020 3e3e 3e20  ])..        >>> 
+00015680: 7472 616e 7366 6f72 6d20 3d20 446f 7562  transform = Doub
+00015690: 6c65 546f 466c 6f61 7428 696e 5f6b 6579  leToFloat(in_key
+000156a0: 733d 5b22 6f62 7322 5d29 0d0a 2020 2020  s=["obs"])..    
+000156b0: 2020 2020 3e3e 3e20 5f20 3d20 7472 616e      >>> _ = tran
+000156c0: 7366 6f72 6d28 7464 290d 0a20 2020 2020  sform(td)..     
+000156d0: 2020 203e 3e3e 2070 7269 6e74 2874 642e     >>> print(td.
+000156e0: 6765 7428 226f 6273 2229 2e64 7479 7065  get("obs").dtype
+000156f0: 290d 0a20 2020 2020 2020 2074 6f72 6368  )..        torch
+00015700: 2e66 6c6f 6174 3332 0d0a 0d0a 2020 2020  .float32....    
+00015710: 2222 220d 0a0d 0a20 2020 2069 6e76 6572  """....    inver
+00015720: 7469 626c 6520 3d20 5472 7565 0d0a 0d0a  tible = True....
+00015730: 2020 2020 6465 6620 5f5f 696e 6974 5f5f      def __init__
+00015740: 280d 0a20 2020 2020 2020 2073 656c 662c  (..        self,
+00015750: 0d0a 2020 2020 2020 2020 696e 5f6b 6579  ..        in_key
+00015760: 733a 204f 7074 696f 6e61 6c5b 5365 7175  s: Optional[Sequ
+00015770: 656e 6365 5b73 7472 5d5d 203d 204e 6f6e  ence[str]] = Non
+00015780: 652c 0d0a 2020 2020 2020 2020 696e 5f6b  e,..        in_k
+00015790: 6579 735f 696e 763a 204f 7074 696f 6e61  eys_inv: Optiona
+000157a0: 6c5b 5365 7175 656e 6365 5b73 7472 5d5d  l[Sequence[str]]
+000157b0: 203d 204e 6f6e 652c 0d0a 2020 2020 293a   = None,..    ):
+000157c0: 0d0a 2020 2020 2020 2020 7375 7065 7228  ..        super(
+000157d0: 292e 5f5f 696e 6974 5f5f 2869 6e5f 6b65  ).__init__(in_ke
+000157e0: 7973 3d69 6e5f 6b65 7973 2c20 696e 5f6b  ys=in_keys, in_k
+000157f0: 6579 735f 696e 763d 696e 5f6b 6579 735f  eys_inv=in_keys_
+00015800: 696e 7629 0d0a 0d0a 2020 2020 6465 6620  inv)....    def 
+00015810: 5f61 7070 6c79 5f74 7261 6e73 666f 726d  _apply_transform
+00015820: 2873 656c 662c 206f 6273 3a20 746f 7263  (self, obs: torc
+00015830: 682e 5465 6e73 6f72 2920 2d3e 2074 6f72  h.Tensor) -> tor
+00015840: 6368 2e54 656e 736f 723a 0d0a 2020 2020  ch.Tensor:..    
+00015850: 2020 2020 7265 7475 726e 206f 6273 2e74      return obs.t
+00015860: 6f28 746f 7263 682e 666c 6f61 7429 0d0a  o(torch.float)..
+00015870: 0d0a 2020 2020 6465 6620 5f69 6e76 5f61  ..    def _inv_a
+00015880: 7070 6c79 5f74 7261 6e73 666f 726d 2873  pply_transform(s
+00015890: 656c 662c 206f 6273 3a20 746f 7263 682e  elf, obs: torch.
+000158a0: 5465 6e73 6f72 2920 2d3e 2074 6f72 6368  Tensor) -> torch
+000158b0: 2e54 656e 736f 723a 0d0a 2020 2020 2020  .Tensor:..      
+000158c0: 2020 7265 7475 726e 206f 6273 2e74 6f28    return obs.to(
+000158d0: 746f 7263 682e 646f 7562 6c65 290d 0a0d  torch.double)...
+000158e0: 0a20 2020 2064 6566 205f 7472 616e 7366  .    def _transf
+000158f0: 6f72 6d5f 7370 6563 2873 656c 662c 2073  orm_spec(self, s
+00015900: 7065 633a 2054 656e 736f 7253 7065 6329  pec: TensorSpec)
+00015910: 202d 3e20 4e6f 6e65 3a0d 0a20 2020 2020   -> None:..     
+00015920: 2020 2069 6620 6973 696e 7374 616e 6365     if isinstance
+00015930: 2873 7065 632c 2043 6f6d 706f 7369 7465  (spec, Composite
+00015940: 5370 6563 293a 0d0a 2020 2020 2020 2020  Spec):..        
+00015950: 2020 2020 666f 7220 6b65 7920 696e 2073      for key in s
+00015960: 7065 633a 0d0a 2020 2020 2020 2020 2020  pec:..          
+00015970: 2020 2020 2020 7365 6c66 2e5f 7472 616e        self._tran
+00015980: 7366 6f72 6d5f 7370 6563 2873 7065 635b  sform_spec(spec[
+00015990: 6b65 795d 290d 0a20 2020 2020 2020 2065  key])..        e
+000159a0: 6c73 653a 0d0a 2020 2020 2020 2020 2020  lse:..          
+000159b0: 2020 7370 6563 2e64 7479 7065 203d 2074    spec.dtype = t
+000159c0: 6f72 6368 2e66 6c6f 6174 0d0a 2020 2020  orch.float..    
+000159d0: 2020 2020 2020 2020 7370 6163 6520 3d20          space = 
+000159e0: 7370 6563 2e73 7061 6365 0d0a 2020 2020  spec.space..    
+000159f0: 2020 2020 2020 2020 6966 2069 7369 6e73          if isins
+00015a00: 7461 6e63 6528 7370 6163 652c 2043 6f6e  tance(space, Con
+00015a10: 7469 6e75 6f75 7342 6f78 293a 0d0a 2020  tinuousBox):..  
+00015a20: 2020 2020 2020 2020 2020 2020 2020 7370                sp
+00015a30: 6163 652e 6d69 6e69 6d75 6d20 3d20 7370  ace.minimum = sp
+00015a40: 6163 652e 6d69 6e69 6d75 6d2e 746f 2874  ace.minimum.to(t
+00015a50: 6f72 6368 2e66 6c6f 6174 290d 0a20 2020  orch.float)..   
+00015a60: 2020 2020 2020 2020 2020 2020 2073 7061               spa
+00015a70: 6365 2e6d 6178 696d 756d 203d 2073 7061  ce.maximum = spa
+00015a80: 6365 2e6d 6178 696d 756d 2e74 6f28 746f  ce.maximum.to(to
+00015a90: 7263 682e 666c 6f61 7429 0d0a 0d0a 2020  rch.float)....  
+00015aa0: 2020 6465 6620 7472 616e 7366 6f72 6d5f    def transform_
+00015ab0: 696e 7075 745f 7370 6563 2873 656c 662c  input_spec(self,
+00015ac0: 2069 6e70 7574 5f73 7065 633a 2054 656e   input_spec: Ten
+00015ad0: 736f 7253 7065 6329 202d 3e20 5465 6e73  sorSpec) -> Tens
+00015ae0: 6f72 5370 6563 3a0d 0a20 2020 2020 2020  orSpec:..       
+00015af0: 2066 6f72 206b 6579 2069 6e20 7365 6c66   for key in self
+00015b00: 2e69 6e5f 6b65 7973 5f69 6e76 3a0d 0a20  .in_keys_inv:.. 
+00015b10: 2020 2020 2020 2020 2020 2069 6620 696e             if in
+00015b20: 7075 745f 7370 6563 5b6b 6579 5d2e 6474  put_spec[key].dt
+00015b30: 7970 6520 6973 206e 6f74 2074 6f72 6368  ype is not torch
+00015b40: 2e64 6f75 626c 653a 0d0a 2020 2020 2020  .double:..      
+00015b50: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
+00015b60: 5479 7065 4572 726f 7228 0d0a 2020 2020  TypeError(..    
+00015b70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015b80: 6622 696e 7075 745f 7370 6563 5b7b 6b65  f"input_spec[{ke
+00015b90: 797d 5d2e 6474 7970 6520 6973 206e 6f74  y}].dtype is not
+00015ba0: 2064 6f75 626c 653a 207b 696e 7075 745f   double: {input_
+00015bb0: 7370 6563 5b6b 6579 5d2e 6474 7970 657d  spec[key].dtype}
+00015bc0: 220d 0a20 2020 2020 2020 2020 2020 2020  "..             
+00015bd0: 2020 2029 0d0a 2020 2020 2020 2020 2020     )..          
+00015be0: 2020 7365 6c66 2e5f 7472 616e 7366 6f72    self._transfor
+00015bf0: 6d5f 7370 6563 2869 6e70 7574 5f73 7065  m_spec(input_spe
+00015c00: 635b 6b65 795d 290d 0a20 2020 2020 2020  c[key])..       
+00015c10: 2072 6574 7572 6e20 696e 7075 745f 7370   return input_sp
+00015c20: 6563 0d0a 0d0a 2020 2020 6465 6620 7472  ec....    def tr
+00015c30: 616e 7366 6f72 6d5f 7265 7761 7264 5f73  ansform_reward_s
+00015c40: 7065 6328 7365 6c66 2c20 7265 7761 7264  pec(self, reward
+00015c50: 5f73 7065 633a 2054 656e 736f 7253 7065  _spec: TensorSpe
+00015c60: 6329 202d 3e20 5465 6e73 6f72 5370 6563  c) -> TensorSpec
+00015c70: 3a0d 0a20 2020 2020 2020 2069 6620 2272  :..        if "r
+00015c80: 6577 6172 6422 2069 6e20 7365 6c66 2e69  eward" in self.i
+00015c90: 6e5f 6b65 7973 3a0d 0a20 2020 2020 2020  n_keys:..       
+00015ca0: 2020 2020 2069 6620 7265 7761 7264 5f73       if reward_s
+00015cb0: 7065 632e 6474 7970 6520 6973 206e 6f74  pec.dtype is not
+00015cc0: 2074 6f72 6368 2e64 6f75 626c 653a 0d0a   torch.double:..
+00015cd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00015ce0: 7261 6973 6520 5479 7065 4572 726f 7228  raise TypeError(
+00015cf0: 2272 6577 6172 645f 7370 6563 2e64 7479  "reward_spec.dty
+00015d00: 7065 2069 7320 6e6f 7420 646f 7562 6c65  pe is not double
+00015d10: 2229 0d0a 0d0a 2020 2020 2020 2020 2020  ")....          
+00015d20: 2020 7365 6c66 2e5f 7472 616e 7366 6f72    self._transfor
+00015d30: 6d5f 7370 6563 2872 6577 6172 645f 7370  m_spec(reward_sp
+00015d40: 6563 290d 0a20 2020 2020 2020 2072 6574  ec)..        ret
+00015d50: 7572 6e20 7265 7761 7264 5f73 7065 630d  urn reward_spec.
+00015d60: 0a0d 0a20 2020 2040 5f61 7070 6c79 5f74  ...    @_apply_t
+00015d70: 6f5f 636f 6d70 6f73 6974 650d 0a20 2020  o_composite..   
+00015d80: 2064 6566 2074 7261 6e73 666f 726d 5f6f   def transform_o
+00015d90: 6273 6572 7661 7469 6f6e 5f73 7065 6328  bservation_spec(
+00015da0: 7365 6c66 2c20 6f62 7365 7276 6174 696f  self, observatio
+00015db0: 6e5f 7370 6563 3a20 5465 6e73 6f72 5370  n_spec: TensorSp
+00015dc0: 6563 2920 2d3e 2054 656e 736f 7253 7065  ec) -> TensorSpe
+00015dd0: 633a 0d0a 2020 2020 2020 2020 7365 6c66  c:..        self
+00015de0: 2e5f 7472 616e 7366 6f72 6d5f 7370 6563  ._transform_spec
+00015df0: 286f 6273 6572 7661 7469 6f6e 5f73 7065  (observation_spe
+00015e00: 6329 0d0a 2020 2020 2020 2020 7265 7475  c)..        retu
+00015e10: 726e 206f 6273 6572 7661 7469 6f6e 5f73  rn observation_s
+00015e20: 7065 630d 0a0d 0a20 2020 2064 6566 205f  pec....    def _
+00015e30: 5f72 6570 725f 5f28 7365 6c66 2920 2d3e  _repr__(self) ->
+00015e40: 2073 7472 3a0d 0a20 2020 2020 2020 2073   str:..        s
+00015e50: 203d 2028 0d0a 2020 2020 2020 2020 2020   = (..          
+00015e60: 2020 6622 7b73 656c 662e 5f5f 636c 6173    f"{self.__clas
+00015e70: 735f 5f2e 5f5f 6e61 6d65 5f5f 7d28 696e  s__.__name__}(in
+00015e80: 5f6b 6579 733d 7b73 656c 662e 696e 5f6b  _keys={self.in_k
+00015e90: 6579 737d 2c20 6f75 745f 6b65 7973 3d7b  eys}, out_keys={
+00015ea0: 7365 6c66 2e6f 7574 5f6b 6579 737d 2c20  self.out_keys}, 
+00015eb0: 220d 0a20 2020 2020 2020 2020 2020 2066  "..            f
+00015ec0: 2269 6e5f 6b65 7973 5f69 6e76 3d7b 7365  "in_keys_inv={se
+00015ed0: 6c66 2e69 6e5f 6b65 7973 5f69 6e76 7d2c  lf.in_keys_inv},
+00015ee0: 206f 7574 5f6b 6579 735f 696e 763d 7b73   out_keys_inv={s
+00015ef0: 656c 662e 6f75 745f 6b65 7973 5f69 6e76  elf.out_keys_inv
+00015f00: 7d29 220d 0a20 2020 2020 2020 2029 0d0a  })"..        )..
+00015f10: 2020 2020 2020 2020 7265 7475 726e 2073          return s
+00015f20: 0d0a 0d0a 0d0a 636c 6173 7320 4361 7454  ......class CatT
+00015f30: 656e 736f 7273 2854 7261 6e73 666f 726d  ensors(Transform
+00015f40: 293a 0d0a 2020 2020 2222 2243 6f6e 6361  ):..    """Conca
+00015f50: 7465 6e61 7465 7320 7365 7665 7261 6c20  tenates several 
+00015f60: 6b65 7973 2069 6e20 6120 7369 6e67 6c65  keys in a single
+00015f70: 2074 656e 736f 722e 0d0a 0d0a 2020 2020   tensor.....    
+00015f80: 5468 6973 2069 7320 6573 7065 6369 616c  This is especial
+00015f90: 6c79 2075 7365 6675 6c20 6966 206d 756c  ly useful if mul
+00015fa0: 7469 706c 6520 6b65 7973 2064 6573 6372  tiple keys descr
+00015fb0: 6962 6520 6120 7369 6e67 6c65 2073 7461  ibe a single sta
+00015fc0: 7465 2028 652e 672e 0d0a 2020 2020 226f  te (e.g...    "o
+00015fd0: 6273 6572 7661 7469 6f6e 5f70 6f73 6974  bservation_posit
+00015fe0: 696f 6e22 2061 6e64 0d0a 2020 2020 226f  ion" and..    "o
+00015ff0: 6273 6572 7661 7469 6f6e 5f76 656c 6f63  bservation_veloc
+00016000: 6974 7922 290d 0a0d 0a20 2020 2041 7267  ity")....    Arg
+00016010: 733a 0d0a 2020 2020 2020 2020 696e 5f6b  s:..        in_k
+00016020: 6579 7320 2853 6571 7565 6e63 6520 6f66  eys (Sequence of
+00016030: 2073 7472 293a 206b 6579 7320 746f 2062   str): keys to b
+00016040: 6520 636f 6e63 6174 656e 6174 6564 2e20  e concatenated. 
+00016050: 4966 2060 4e6f 6e65 6020 286f 7220 6e6f  If `None` (or no
+00016060: 7420 7072 6f76 6964 6564 290d 0a20 2020  t provided)..   
+00016070: 2020 2020 2020 2020 2074 6865 206b 6579           the key
+00016080: 7320 7769 6c6c 2062 6520 7265 7472 6965  s will be retrie
+00016090: 7665 6420 6672 6f6d 2074 6865 2070 6172  ved from the par
+000160a0: 656e 7420 656e 7669 726f 6e6d 656e 7420  ent environment 
+000160b0: 7468 6520 6669 7273 7420 7469 6d65 0d0a  the first time..
+000160c0: 2020 2020 2020 2020 2020 2020 7468 6520              the 
+000160d0: 7472 616e 7366 6f72 6d20 6973 2075 7365  transform is use
+000160e0: 642e 2054 6869 7320 6265 6861 7669 6f75  d. This behaviou
+000160f0: 7220 7769 6c6c 206f 6e6c 7920 776f 726b  r will only work
+00016100: 2069 6620 6120 7061 7265 6e74 2069 7320   if a parent is 
+00016110: 7365 742e 0d0a 2020 2020 2020 2020 6f75  set...        ou
+00016120: 745f 6b65 793a 206b 6579 206f 6620 7468  t_key: key of th
+00016130: 6520 7265 7375 6c74 696e 6720 7465 6e73  e resulting tens
+00016140: 6f72 2e0d 0a20 2020 2020 2020 2064 696d  or...        dim
+00016150: 2028 696e 742c 206f 7074 696f 6e61 6c29   (int, optional)
+00016160: 3a20 6469 6d65 6e73 696f 6e20 616c 6f6e  : dimension alon
+00016170: 6720 7768 6963 6820 7468 6520 636f 6e63  g which the conc
+00016180: 6174 656e 6174 696f 6e20 7769 6c6c 206f  atenation will o
+00016190: 6363 7572 2e0d 0a20 2020 2020 2020 2020  ccur...         
+000161a0: 2020 2044 6566 6175 6c74 2069 7320 2d31     Default is -1
+000161b0: 2e0d 0a20 2020 2020 2020 2064 656c 5f6b  ...        del_k
+000161c0: 6579 7320 2862 6f6f 6c2c 206f 7074 696f  eys (bool, optio
+000161d0: 6e61 6c29 3a20 6966 2060 6054 7275 6560  nal): if ``True`
+000161e0: 602c 2074 6865 2069 6e70 7574 2076 616c  `, the input val
+000161f0: 7565 7320 7769 6c6c 2062 6520 6465 6c65  ues will be dele
+00016200: 7465 6420 6166 7465 720d 0a20 2020 2020  ted after..     
+00016210: 2020 2020 2020 2063 6f6e 6361 7465 6e61         concatena
+00016220: 7469 6f6e 2e20 4465 6661 756c 7420 6973  tion. Default is
+00016230: 2054 7275 652e 0d0a 2020 2020 2020 2020   True...        
+00016240: 756e 7371 7565 657a 655f 6966 5f6f 6f72  unsqueeze_if_oor
+00016250: 2028 626f 6f6c 2c20 6f70 7469 6f6e 616c   (bool, optional
+00016260: 293a 2069 6620 6060 5472 7565 6060 2c20  ): if ``True``, 
+00016270: 4361 7454 656e 736f 7220 7769 6c6c 2063  CatTensor will c
+00016280: 6865 636b 2074 6861 740d 0a20 2020 2020  heck that..     
+00016290: 2020 2020 2020 2074 6865 2064 696d 656e         the dimen
+000162a0: 7369 6f6e 2069 6e64 6963 6174 6564 2065  sion indicated e
+000162b0: 7869 7374 2066 6f72 2074 6865 2074 656e  xist for the ten
+000162c0: 736f 7273 2074 6f20 636f 6e63 6174 656e  sors to concaten
+000162d0: 6174 652e 2049 6620 6e6f 742c 0d0a 2020  ate. If not,..  
+000162e0: 2020 2020 2020 2020 2020 7468 6520 7465            the te
+000162f0: 6e73 6f72 7320 7769 6c6c 2062 6520 756e  nsors will be un
+00016300: 7371 7565 657a 6564 2061 6c6f 6e67 2074  squeezed along t
+00016310: 6861 7420 6469 6d65 6e73 696f 6e2e 0d0a  hat dimension...
+00016320: 2020 2020 2020 2020 2020 2020 4465 6661              Defa
+00016330: 756c 7420 6973 2046 616c 7365 2e0d 0a0d  ult is False....
+00016340: 0a20 2020 2045 7861 6d70 6c65 733a 0d0a  .    Examples:..
+00016350: 2020 2020 2020 2020 3e3e 3e20 7472 616e          >>> tran
+00016360: 7366 6f72 6d20 3d20 4361 7454 656e 736f  sform = CatTenso
+00016370: 7273 2869 6e5f 6b65 7973 3d5b 226b 6579  rs(in_keys=["key
+00016380: 3122 2c20 226b 6579 3222 5d29 0d0a 2020  1", "key2"])..  
+00016390: 2020 2020 2020 3e3e 3e20 7464 203d 2054        >>> td = T
+000163a0: 656e 736f 7244 6963 7428 7b22 6b65 7931  ensorDict({"key1
+000163b0: 223a 2074 6f72 6368 2e7a 6572 6f73 2831  ": torch.zeros(1
+000163c0: 2c20 3129 2c0d 0a20 2020 2020 2020 202e  , 1),..        .
+000163d0: 2e2e 2020 2020 2022 6b65 7932 223a 2074  ..     "key2": t
+000163e0: 6f72 6368 2e6f 6e65 7328 312c 2031 297d  orch.ones(1, 1)}
+000163f0: 2c20 5b31 5d29 0d0a 2020 2020 2020 2020  , [1])..        
+00016400: 3e3e 3e20 5f20 3d20 7472 616e 7366 6f72  >>> _ = transfor
+00016410: 6d28 7464 290d 0a20 2020 2020 2020 203e  m(td)..        >
+00016420: 3e3e 2070 7269 6e74 2874 642e 6765 7428  >> print(td.get(
+00016430: 226f 6273 6572 7661 7469 6f6e 5f76 6563  "observation_vec
+00016440: 746f 7222 2929 0d0a 2020 2020 2020 2020  tor"))..        
+00016450: 7465 6e73 6f72 285b 5b30 2e2c 2031 2e5d  tensor([[0., 1.]
+00016460: 5d29 0d0a 2020 2020 2020 2020 3e3e 3e20  ])..        >>> 
+00016470: 7472 616e 7366 6f72 6d20 3d20 4361 7454  transform = CatT
+00016480: 656e 736f 7273 2869 6e5f 6b65 7973 3d5b  ensors(in_keys=[
+00016490: 226b 6579 3122 2c20 226b 6579 3222 5d2c  "key1", "key2"],
+000164a0: 2064 696d 3d2d 322c 2075 6e73 7175 6565   dim=-2, unsquee
+000164b0: 7a65 5f69 665f 6f6f 723d 5472 7565 290d  ze_if_oor=True).
+000164c0: 0a20 2020 2020 2020 203e 3e3e 2074 6420  .        >>> td 
+000164d0: 3d20 5465 6e73 6f72 4469 6374 287b 226b  = TensorDict({"k
+000164e0: 6579 3122 3a20 746f 7263 682e 7a65 726f  ey1": torch.zero
+000164f0: 7328 3129 2c0d 0a20 2020 2020 2020 202e  s(1),..        .
+00016500: 2e2e 2020 2020 2022 6b65 7932 223a 2074  ..     "key2": t
+00016510: 6f72 6368 2e6f 6e65 7328 3129 7d2c 205b  orch.ones(1)}, [
+00016520: 5d29 0d0a 2020 2020 2020 2020 3e3e 3e20  ])..        >>> 
+00016530: 5f20 3d20 7472 616e 7366 6f72 6d28 7464  _ = transform(td
+00016540: 290d 0a20 2020 2020 2020 203e 3e3e 2070  )..        >>> p
+00016550: 7269 6e74 2874 642e 6765 7428 226f 6273  rint(td.get("obs
+00016560: 6572 7661 7469 6f6e 5f76 6563 746f 7222  ervation_vector"
+00016570: 292e 7368 6170 6529 0d0a 2020 2020 2020  ).shape)..      
+00016580: 2020 746f 7263 682e 5369 7a65 285b 322c    torch.Size([2,
+00016590: 2031 5d29 0d0a 0d0a 2020 2020 2222 220d   1])....    """.
+000165a0: 0a0d 0a20 2020 2069 6e76 6572 7469 626c  ...    invertibl
+000165b0: 6520 3d20 4661 6c73 650d 0a0d 0a20 2020  e = False....   
+000165c0: 2064 6566 205f 5f69 6e69 745f 5f28 0d0a   def __init__(..
+000165d0: 2020 2020 2020 2020 7365 6c66 2c0d 0a20          self,.. 
+000165e0: 2020 2020 2020 2069 6e5f 6b65 7973 3a20         in_keys: 
+000165f0: 4f70 7469 6f6e 616c 5b53 6571 7565 6e63  Optional[Sequenc
+00016600: 655b 7374 725d 5d20 3d20 4e6f 6e65 2c0d  e[str]] = None,.
+00016610: 0a20 2020 2020 2020 206f 7574 5f6b 6579  .        out_key
+00016620: 3a20 7374 7220 3d20 226f 6273 6572 7661  : str = "observa
+00016630: 7469 6f6e 5f76 6563 746f 7222 2c0d 0a20  tion_vector",.. 
+00016640: 2020 2020 2020 2064 696d 3a20 696e 7420         dim: int 
+00016650: 3d20 2d31 2c0d 0a20 2020 2020 2020 2064  = -1,..        d
+00016660: 656c 5f6b 6579 733a 2062 6f6f 6c20 3d20  el_keys: bool = 
+00016670: 5472 7565 2c0d 0a20 2020 2020 2020 2075  True,..        u
+00016680: 6e73 7175 6565 7a65 5f69 665f 6f6f 723a  nsqueeze_if_oor:
+00016690: 2062 6f6f 6c20 3d20 4661 6c73 652c 0d0a   bool = False,..
+000166a0: 2020 2020 293a 0d0a 2020 2020 2020 2020      ):..        
+000166b0: 7365 6c66 2e5f 696e 6974 6961 6c69 7a65  self._initialize
+000166c0: 6420 3d20 696e 5f6b 6579 7320 6973 206e  d = in_keys is n
+000166d0: 6f74 204e 6f6e 650d 0a20 2020 2020 2020  ot None..       
+000166e0: 2069 6620 6e6f 7420 7365 6c66 2e5f 696e   if not self._in
+000166f0: 6974 6961 6c69 7a65 643a 0d0a 2020 2020  itialized:..    
+00016700: 2020 2020 2020 2020 6966 2064 696d 2021          if dim !
+00016710: 3d20 2d31 3a0d 0a20 2020 2020 2020 2020  = -1:..         
+00016720: 2020 2020 2020 2072 6169 7365 2056 616c         raise Val
+00016730: 7565 4572 726f 7228 0d0a 2020 2020 2020  ueError(..      
+00016740: 2020 2020 2020 2020 2020 2020 2020 224c                "L
+00016750: 617a 7920 6361 6c6c 2074 6f20 4361 7454  azy call to CatT
+00016760: 656e 736f 7273 2069 7320 6f6e 6c79 2073  ensors is only s
+00016770: 7570 706f 7274 6564 2077 6865 6e20 6064  upported when `d
+00016780: 696d 3d2d 3160 2e22 0d0a 2020 2020 2020  im=-1`."..      
+00016790: 2020 2020 2020 2020 2020 290d 0a20 2020            )..   
+000167a0: 2020 2020 2065 6c73 653a 0d0a 2020 2020       else:..    
+000167b0: 2020 2020 2020 2020 696e 5f6b 6579 7320          in_keys 
+000167c0: 3d20 736f 7274 6564 2869 6e5f 6b65 7973  = sorted(in_keys
+000167d0: 2c20 6b65 793d 5f73 6f72 745f 6b65 7973  , key=_sort_keys
+000167e0: 290d 0a20 2020 2020 2020 2069 6620 7479  )..        if ty
+000167f0: 7065 286f 7574 5f6b 6579 2920 213d 2073  pe(out_key) != s
+00016800: 7472 3a0d 0a20 2020 2020 2020 2020 2020  tr:..           
+00016810: 2072 6169 7365 2045 7863 6570 7469 6f6e   raise Exception
+00016820: 2822 4361 7454 656e 736f 7273 2072 6571  ("CatTensors req
+00016830: 7569 7265 7320 6f75 745f 6b65 7920 746f  uires out_key to
+00016840: 2062 6520 6f66 2074 7970 6520 7374 7269   be of type stri
+00016850: 6e67 2229 0d0a 2020 2020 2020 2020 2320  ng")..        # 
+00016860: 7375 7065 7228 292e 5f5f 696e 6974 5f5f  super().__init__
+00016870: 2869 6e5f 6b65 7973 3d69 6e5f 6b65 7973  (in_keys=in_keys
+00016880: 290d 0a20 2020 2020 2020 2073 7570 6572  )..        super
+00016890: 2843 6174 5465 6e73 6f72 732c 2073 656c  (CatTensors, sel
+000168a0: 6629 2e5f 5f69 6e69 745f 5f28 696e 5f6b  f).__init__(in_k
+000168b0: 6579 733d 696e 5f6b 6579 732c 206f 7574  eys=in_keys, out
+000168c0: 5f6b 6579 733d 5b6f 7574 5f6b 6579 5d29  _keys=[out_key])
+000168d0: 0d0a 2020 2020 2020 2020 7365 6c66 2e64  ..        self.d
+000168e0: 696d 203d 2064 696d 0d0a 2020 2020 2020  im = dim..      
+000168f0: 2020 7365 6c66 2e5f 6465 6c5f 6b65 7973    self._del_keys
+00016900: 203d 2064 656c 5f6b 6579 730d 0a20 2020   = del_keys..   
+00016910: 2020 2020 2073 656c 662e 5f6b 6579 735f       self._keys_
+00016920: 746f 5f65 7863 6c75 6465 203d 204e 6f6e  to_exclude = Non
+00016930: 650d 0a20 2020 2020 2020 2073 656c 662e  e..        self.
+00016940: 756e 7371 7565 657a 655f 6966 5f6f 6f72  unsqueeze_if_oor
+00016950: 203d 2075 6e73 7175 6565 7a65 5f69 665f   = unsqueeze_if_
+00016960: 6f6f 720d 0a0d 0a20 2020 2040 7072 6f70  oor....    @prop
+00016970: 6572 7479 0d0a 2020 2020 6465 6620 6b65  erty..    def ke
+00016980: 7973 5f74 6f5f 6578 636c 7564 6528 7365  ys_to_exclude(se
+00016990: 6c66 293a 0d0a 2020 2020 2020 2020 6966  lf):..        if
+000169a0: 2073 656c 662e 5f6b 6579 735f 746f 5f65   self._keys_to_e
+000169b0: 7863 6c75 6465 2069 7320 4e6f 6e65 3a0d  xclude is None:.
+000169c0: 0a20 2020 2020 2020 2020 2020 2073 656c  .            sel
+000169d0: 662e 5f6b 6579 735f 746f 5f65 7863 6c75  f._keys_to_exclu
+000169e0: 6465 203d 205b 0d0a 2020 2020 2020 2020  de = [..        
+000169f0: 2020 2020 2020 2020 6b65 7920 666f 7220          key for 
+00016a00: 6b65 7920 696e 2073 656c 662e 696e 5f6b  key in self.in_k
+00016a10: 6579 7320 6966 206b 6579 2021 3d20 7365  eys if key != se
+00016a20: 6c66 2e6f 7574 5f6b 6579 735b 305d 0d0a  lf.out_keys[0]..
+00016a30: 2020 2020 2020 2020 2020 2020 5d0d 0a20              ].. 
+00016a40: 2020 2020 2020 2072 6574 7572 6e20 7365         return se
+00016a50: 6c66 2e5f 6b65 7973 5f74 6f5f 6578 636c  lf._keys_to_excl
+00016a60: 7564 650d 0a0d 0a20 2020 2064 6566 205f  ude....    def _
+00016a70: 6669 6e64 5f69 6e5f 6b65 7973 2873 656c  find_in_keys(sel
+00016a80: 6629 3a0d 0a20 2020 2020 2020 2070 6172  f):..        par
+00016a90: 656e 7420 3d20 7365 6c66 2e70 6172 656e  ent = self.paren
+00016aa0: 740d 0a20 2020 2020 2020 206f 6273 5f73  t..        obs_s
+00016ab0: 7065 6320 3d20 7061 7265 6e74 2e6f 6273  pec = parent.obs
+00016ac0: 6572 7661 7469 6f6e 5f73 7065 630d 0a20  ervation_spec.. 
+00016ad0: 2020 2020 2020 2069 6e5f 6b65 7973 203d         in_keys =
+00016ae0: 205b 5d0d 0a20 2020 2020 2020 2066 6f72   []..        for
+00016af0: 206b 6579 2c20 7661 6c75 6520 696e 206f   key, value in o
+00016b00: 6273 5f73 7065 632e 6974 656d 7328 293a  bs_spec.items():
+00016b10: 0d0a 2020 2020 2020 2020 2020 2020 6966  ..            if
+00016b20: 206c 656e 2876 616c 7565 2e73 6861 7065   len(value.shape
+00016b30: 2920 3d3d 2031 3a0d 0a20 2020 2020 2020  ) == 1:..       
+00016b40: 2020 2020 2020 2020 2069 6e5f 6b65 7973           in_keys
+00016b50: 2e61 7070 656e 6428 6b65 7929 0d0a 2020  .append(key)..  
+00016b60: 2020 2020 2020 7265 7475 726e 2073 6f72        return sor
+00016b70: 7465 6428 696e 5f6b 6579 732c 206b 6579  ted(in_keys, key
+00016b80: 3d5f 736f 7274 5f6b 6579 7329 0d0a 0d0a  =_sort_keys)....
+00016b90: 2020 2020 6465 6620 5f63 616c 6c28 7365      def _call(se
+00016ba0: 6c66 2c20 7465 6e73 6f72 6469 6374 3a20  lf, tensordict: 
+00016bb0: 5465 6e73 6f72 4469 6374 4261 7365 2920  TensorDictBase) 
+00016bc0: 2d3e 2054 656e 736f 7244 6963 7442 6173  -> TensorDictBas
+00016bd0: 653a 0d0a 2020 2020 2020 2020 6966 206e  e:..        if n
+00016be0: 6f74 2073 656c 662e 5f69 6e69 7469 616c  ot self._initial
+00016bf0: 697a 6564 3a0d 0a20 2020 2020 2020 2020  ized:..         
+00016c00: 2020 2073 656c 662e 696e 5f6b 6579 7320     self.in_keys 
+00016c10: 3d20 7365 6c66 2e5f 6669 6e64 5f69 6e5f  = self._find_in_
+00016c20: 6b65 7973 2829 0d0a 2020 2020 2020 2020  keys()..        
+00016c30: 2020 2020 7365 6c66 2e5f 696e 6974 6961      self._initia
+00016c40: 6c69 7a65 6420 3d20 5472 7565 0d0a 0d0a  lized = True....
+00016c50: 2020 2020 2020 2020 6966 2061 6c6c 286b          if all(k
+00016c60: 6579 2069 6e20 7465 6e73 6f72 6469 6374  ey in tensordict
+00016c70: 2e6b 6579 7328 696e 636c 7564 655f 6e65  .keys(include_ne
+00016c80: 7374 6564 3d54 7275 6529 2066 6f72 206b  sted=True) for k
+00016c90: 6579 2069 6e20 7365 6c66 2e69 6e5f 6b65  ey in self.in_ke
+00016ca0: 7973 293a 0d0a 2020 2020 2020 2020 2020  ys):..          
+00016cb0: 2020 7661 6c75 6573 203d 205b 7465 6e73    values = [tens
+00016cc0: 6f72 6469 6374 2e67 6574 286b 6579 2920  ordict.get(key) 
+00016cd0: 666f 7220 6b65 7920 696e 2073 656c 662e  for key in self.
+00016ce0: 696e 5f6b 6579 735d 0d0a 2020 2020 2020  in_keys]..      
+00016cf0: 2020 2020 2020 6966 2073 656c 662e 756e        if self.un
+00016d00: 7371 7565 657a 655f 6966 5f6f 6f72 3a0d  squeeze_if_oor:.
+00016d10: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00016d20: 2070 6f73 5f69 6478 203d 2073 656c 662e   pos_idx = self.
+00016d30: 6469 6d20 3e20 300d 0a20 2020 2020 2020  dim > 0..       
+00016d40: 2020 2020 2020 2020 2061 6273 5f69 6478           abs_idx
+00016d50: 203d 2073 656c 662e 6469 6d20 6966 2070   = self.dim if p
+00016d60: 6f73 5f69 6478 2065 6c73 6520 2d73 656c  os_idx else -sel
+00016d70: 662e 6469 6d20 2d20 310d 0a20 2020 2020  f.dim - 1..     
+00016d80: 2020 2020 2020 2020 2020 2076 616c 7565             value
+00016d90: 7320 3d20 5b0d 0a20 2020 2020 2020 2020  s = [..         
+00016da0: 2020 2020 2020 2020 2020 2076 0d0a 2020             v..  
+00016db0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016dc0: 2020 6966 2061 6273 5f69 6478 203c 2076    if abs_idx < v
+00016dd0: 2e6e 6469 6d65 6e73 696f 6e28 290d 0a20  .ndimension().. 
+00016de0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016df0: 2020 2065 6c73 6520 762e 756e 7371 7565     else v.unsque
+00016e00: 657a 6528 3029 0d0a 2020 2020 2020 2020  eze(0)..        
+00016e10: 2020 2020 2020 2020 2020 2020 6966 206e              if n
+00016e20: 6f74 2070 6f73 5f69 6478 0d0a 2020 2020  ot pos_idx..    
+00016e30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00016e40: 656c 7365 2076 2e75 6e73 7175 6565 7a65  else v.unsqueeze
+00016e50: 282d 3129 0d0a 2020 2020 2020 2020 2020  (-1)..          
+00016e60: 2020 2020 2020 2020 2020 666f 7220 7620            for v 
+00016e70: 696e 2076 616c 7565 730d 0a20 2020 2020  in values..     
+00016e80: 2020 2020 2020 2020 2020 205d 0d0a 0d0a             ]....
+00016e90: 2020 2020 2020 2020 2020 2020 6f75 745f              out_
+00016ea0: 7465 6e73 6f72 203d 2074 6f72 6368 2e63  tensor = torch.c
+00016eb0: 6174 2876 616c 7565 732c 2064 696d 3d73  at(values, dim=s
+00016ec0: 656c 662e 6469 6d29 0d0a 2020 2020 2020  elf.dim)..      
+00016ed0: 2020 2020 2020 7465 6e73 6f72 6469 6374        tensordict
+00016ee0: 2e73 6574 2873 656c 662e 6f75 745f 6b65  .set(self.out_ke
+00016ef0: 7973 5b30 5d2c 206f 7574 5f74 656e 736f  ys[0], out_tenso
+00016f00: 7229 0d0a 2020 2020 2020 2020 2020 2020  r)..            
+00016f10: 6966 2073 656c 662e 5f64 656c 5f6b 6579  if self._del_key
+00016f20: 733a 0d0a 2020 2020 2020 2020 2020 2020  s:..            
+00016f30: 2020 2020 7465 6e73 6f72 6469 6374 2e65      tensordict.e
+00016f40: 7863 6c75 6465 282a 7365 6c66 2e6b 6579  xclude(*self.key
+00016f50: 735f 746f 5f65 7863 6c75 6465 2c20 696e  s_to_exclude, in
+00016f60: 706c 6163 653d 5472 7565 290d 0a20 2020  place=True)..   
+00016f70: 2020 2020 2065 6c73 653a 0d0a 2020 2020       else:..    
+00016f80: 2020 2020 2020 2020 7261 6973 6520 4578          raise Ex
+00016f90: 6365 7074 696f 6e28 0d0a 2020 2020 2020  ception(..      
+00016fa0: 2020 2020 2020 2020 2020 6622 4361 7454            f"CatT
+00016fb0: 656e 736f 7220 6661 696c 6564 2c20 6173  ensor failed, as
+00016fc0: 2069 7420 6578 7065 6374 6564 2069 6e70   it expected inp
+00016fd0: 7574 206b 6579 7320 3d22 0d0a 2020 2020  ut keys ="..    
+00016fe0: 2020 2020 2020 2020 2020 2020 6622 207b              f" {
+00016ff0: 736f 7274 6564 2873 656c 662e 696e 5f6b  sorted(self.in_k
+00017000: 6579 732c 206b 6579 3d5f 736f 7274 5f6b  eys, key=_sort_k
+00017010: 6579 7329 7d20 6275 7420 676f 7420 6120  eys)} but got a 
+00017020: 5465 6e73 6f72 4469 6374 2077 6974 6820  TensorDict with 
+00017030: 6b65 7973 220d 0a20 2020 2020 2020 2020  keys"..         
+00017040: 2020 2020 2020 2066 2220 7b73 6f72 7465         f" {sorte
+00017050: 6428 7465 6e73 6f72 6469 6374 2e6b 6579  d(tensordict.key
+00017060: 7328 696e 636c 7564 655f 6e65 7374 6564  s(include_nested
+00017070: 3d54 7275 6529 2c20 6b65 793d 5f73 6f72  =True), key=_sor
+00017080: 745f 6b65 7973 297d 220d 0a20 2020 2020  t_keys)}"..     
+00017090: 2020 2020 2020 2029 0d0a 2020 2020 2020         )..      
+000170a0: 2020 7265 7475 726e 2074 656e 736f 7264    return tensord
+000170b0: 6963 740d 0a0d 0a20 2020 2066 6f72 7761  ict....    forwa
+000170c0: 7264 203d 205f 6361 6c6c 0d0a 0d0a 2020  rd = _call....  
+000170d0: 2020 6465 6620 7472 616e 7366 6f72 6d5f    def transform_
+000170e0: 6f62 7365 7276 6174 696f 6e5f 7370 6563  observation_spec
+000170f0: 2873 656c 662c 206f 6273 6572 7661 7469  (self, observati
+00017100: 6f6e 5f73 7065 633a 2054 656e 736f 7253  on_spec: TensorS
+00017110: 7065 6329 202d 3e20 5465 6e73 6f72 5370  pec) -> TensorSp
+00017120: 6563 3a0d 0a20 2020 2020 2020 2023 2063  ec:..        # c
+00017130: 6865 636b 2074 6861 7420 616c 6c20 6b65  heck that all ke
+00017140: 7973 2061 7265 2069 6e20 6f62 7365 7276  ys are in observ
+00017150: 6174 696f 6e5f 7370 6563 0d0a 2020 2020  ation_spec..    
+00017160: 2020 2020 6966 206c 656e 2873 656c 662e      if len(self.
+00017170: 696e 5f6b 6579 7329 203e 2031 2061 6e64  in_keys) > 1 and
+00017180: 206e 6f74 2069 7369 6e73 7461 6e63 6528   not isinstance(
+00017190: 6f62 7365 7276 6174 696f 6e5f 7370 6563  observation_spec
+000171a0: 2c20 436f 6d70 6f73 6974 6553 7065 6329  , CompositeSpec)
+000171b0: 3a0d 0a20 2020 2020 2020 2020 2020 2072  :..            r
+000171c0: 6169 7365 2056 616c 7565 4572 726f 7228  aise ValueError(
+000171d0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+000171e0: 2020 2243 6174 5465 6e73 6f72 2063 616e    "CatTensor can
+000171f0: 6e6f 7420 696e 6665 7220 7468 6520 6f75  not infer the ou
+00017200: 7470 7574 206f 6273 6572 7661 7469 6f6e  tput observation
+00017210: 2073 7065 6320 6173 2074 6865 7265 2061   spec as there a
+00017220: 7265 206d 756c 7469 706c 6520 696e 7075  re multiple inpu
+00017230: 7420 6b65 7973 2062 7574 2022 0d0a 2020  t keys but "..  
+00017240: 2020 2020 2020 2020 2020 2020 2020 226f                "o
+00017250: 6e6c 7920 6f6e 6520 6f62 7365 7276 6174  nly one observat
+00017260: 696f 6e5f 7370 6563 2e22 0d0a 2020 2020  ion_spec."..    
+00017270: 2020 2020 2020 2020 290d 0a0d 0a20 2020          )....   
+00017280: 2020 2020 2069 6620 6973 696e 7374 616e       if isinstan
+00017290: 6365 286f 6273 6572 7661 7469 6f6e 5f73  ce(observation_s
+000172a0: 7065 632c 2043 6f6d 706f 7369 7465 5370  pec, CompositeSp
+000172b0: 6563 2920 616e 6420 6c65 6e28 0d0a 2020  ec) and len(..  
+000172c0: 2020 2020 2020 2020 2020 5b6b 6579 2066            [key f
+000172d0: 6f72 206b 6579 2069 6e20 7365 6c66 2e69  or key in self.i
+000172e0: 6e5f 6b65 7973 2069 6620 6b65 7920 6e6f  n_keys if key no
+000172f0: 7420 696e 206f 6273 6572 7661 7469 6f6e  t in observation
+00017300: 5f73 7065 632e 6b65 7973 2854 7275 6529  _spec.keys(True)
+00017310: 5d0d 0a20 2020 2020 2020 2029 3a0d 0a20  ]..        ):.. 
+00017320: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+00017330: 2056 616c 7565 4572 726f 7228 0d0a 2020   ValueError(..  
+00017340: 2020 2020 2020 2020 2020 2020 2020 2243                "C
+00017350: 6174 5465 6e73 6f72 2067 6f74 2061 206c  atTensor got a l
+00017360: 6973 7420 6f66 206b 6579 7320 7468 6174  ist of keys that
+00017370: 2064 6f65 7320 6e6f 7420 6d61 7463 6820   does not match 
+00017380: 7468 6520 6b65 7973 2069 6e20 6f62 7365  the keys in obse
+00017390: 7276 6174 696f 6e5f 7370 6563 2e20 220d  rvation_spec. ".
+000173a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000173b0: 2022 4d61 6b65 2073 7572 6520 7468 6520   "Make sure the 
+000173c0: 656e 7669 726f 6e6d 656e 7420 6861 7320  environment has 
+000173d0: 616e 206f 6273 6572 7661 7469 6f6e 5f73  an observation_s
+000173e0: 7065 6320 6174 7472 6962 7574 6520 7468  pec attribute th
+000173f0: 6174 2069 6e63 6c75 6465 7320 616c 6c20  at includes all 
+00017400: 7468 6520 7370 6563 7320 6e65 6564 6564  the specs needed
+00017410: 2066 6f72 2043 6174 5465 6e73 6f72 2e22   for CatTensor."
+00017420: 0d0a 2020 2020 2020 2020 2020 2020 290d  ..            ).
+00017430: 0a0d 0a20 2020 2020 2020 2069 6620 6e6f  ...        if no
+00017440: 7420 6973 696e 7374 616e 6365 286f 6273  t isinstance(obs
+00017450: 6572 7661 7469 6f6e 5f73 7065 632c 2043  ervation_spec, C
+00017460: 6f6d 706f 7369 7465 5370 6563 293a 0d0a  ompositeSpec):..
+00017470: 2020 2020 2020 2020 2020 2020 2320 6279              # by
+00017480: 2064 6566 2c20 7468 6572 6520 6d75 7374   def, there must
+00017490: 2062 6520 6f6e 6c79 206f 6e65 206b 6579   be only one key
+000174a0: 0d0a 2020 2020 2020 2020 2020 2020 7265  ..            re
+000174b0: 7475 726e 206f 6273 6572 7661 7469 6f6e  turn observation
+000174c0: 5f73 7065 630d 0a0d 0a20 2020 2020 2020  _spec....       
+000174d0: 206b 6579 7320 3d20 5b6b 6579 2066 6f72   keys = [key for
+000174e0: 206b 6579 2069 6e20 6f62 7365 7276 6174   key in observat
+000174f0: 696f 6e5f 7370 6563 2e6b 6579 7328 5472  ion_spec.keys(Tr
+00017500: 7565 2c20 5472 7565 2920 6966 206b 6579  ue, True) if key
+00017510: 2069 6e20 7365 6c66 2e69 6e5f 6b65 7973   in self.in_keys
+00017520: 5d0d 0a0d 0a20 2020 2020 2020 2073 756d  ]....        sum
+00017530: 5f73 6861 7065 203d 2073 756d 280d 0a20  _shape = sum(.. 
+00017540: 2020 2020 2020 2020 2020 205b 0d0a 2020             [..  
+00017550: 2020 2020 2020 2020 2020 2020 2020 6f62                ob
+00017560: 7365 7276 6174 696f 6e5f 7370 6563 5b6b  servation_spec[k
+00017570: 6579 5d2e 7368 6170 655b 7365 6c66 2e64  ey].shape[self.d
+00017580: 696d 5d0d 0a20 2020 2020 2020 2020 2020  im]..           
+00017590: 2020 2020 2069 6620 6f62 7365 7276 6174       if observat
+000175a0: 696f 6e5f 7370 6563 5b6b 6579 5d2e 7368  ion_spec[key].sh
+000175b0: 6170 650d 0a20 2020 2020 2020 2020 2020  ape..           
+000175c0: 2020 2020 2065 6c73 6520 310d 0a20 2020       else 1..   
+000175d0: 2020 2020 2020 2020 2020 2020 2066 6f72               for
+000175e0: 206b 6579 2069 6e20 6b65 7973 0d0a 2020   key in keys..  
+000175f0: 2020 2020 2020 2020 2020 5d0d 0a20 2020            ]..   
+00017600: 2020 2020 2029 0d0a 2020 2020 2020 2020       )..        
+00017610: 7370 6563 3020 3d20 6f62 7365 7276 6174  spec0 = observat
+00017620: 696f 6e5f 7370 6563 5b6b 6579 735b 305d  ion_spec[keys[0]
+00017630: 5d0d 0a20 2020 2020 2020 206f 7574 5f6b  ]..        out_k
+00017640: 6579 203d 2073 656c 662e 6f75 745f 6b65  ey = self.out_ke
+00017650: 7973 5b30 5d0d 0a20 2020 2020 2020 2073  ys[0]..        s
+00017660: 6861 7065 203d 206c 6973 7428 7370 6563  hape = list(spec
+00017670: 302e 7368 6170 6529 0d0a 2020 2020 2020  0.shape)..      
+00017680: 2020 6465 7669 6365 203d 2073 7065 6330    device = spec0
+00017690: 2e64 6576 6963 650d 0a20 2020 2020 2020  .device..       
+000176a0: 2073 6861 7065 5b73 656c 662e 6469 6d5d   shape[self.dim]
+000176b0: 203d 2073 756d 5f73 6861 7065 0d0a 2020   = sum_shape..  
+000176c0: 2020 2020 2020 7368 6170 6520 3d20 746f        shape = to
+000176d0: 7263 682e 5369 7a65 2873 6861 7065 290d  rch.Size(shape).
+000176e0: 0a20 2020 2020 2020 206f 6273 6572 7661  .        observa
+000176f0: 7469 6f6e 5f73 7065 635b 6f75 745f 6b65  tion_spec[out_ke
+00017700: 795d 203d 2055 6e62 6f75 6e64 6564 436f  y] = UnboundedCo
+00017710: 6e74 696e 756f 7573 5465 6e73 6f72 5370  ntinuousTensorSp
+00017720: 6563 280d 0a20 2020 2020 2020 2020 2020  ec(..           
+00017730: 2073 6861 7065 3d73 6861 7065 2c0d 0a20   shape=shape,.. 
+00017740: 2020 2020 2020 2020 2020 2064 7479 7065             dtype
+00017750: 3d73 7065 6330 2e64 7479 7065 2c0d 0a20  =spec0.dtype,.. 
+00017760: 2020 2020 2020 2020 2020 2064 6576 6963             devic
+00017770: 653d 6465 7669 6365 2c0d 0a20 2020 2020  e=device,..     
+00017780: 2020 2029 0d0a 2020 2020 2020 2020 6966     )..        if
+00017790: 2073 656c 662e 5f64 656c 5f6b 6579 733a   self._del_keys:
+000177a0: 0d0a 2020 2020 2020 2020 2020 2020 666f  ..            fo
+000177b0: 7220 6b65 7920 696e 2073 656c 662e 6b65  r key in self.ke
+000177c0: 7973 5f74 6f5f 6578 636c 7564 653a 0d0a  ys_to_exclude:..
+000177d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000177e0: 6966 206b 6579 2069 6e20 6f62 7365 7276  if key in observ
+000177f0: 6174 696f 6e5f 7370 6563 2e6b 6579 7328  ation_spec.keys(
+00017800: 5472 7565 293a 0d0a 2020 2020 2020 2020  True):..        
+00017810: 2020 2020 2020 2020 2020 2020 6465 6c20              del 
+00017820: 6f62 7365 7276 6174 696f 6e5f 7370 6563  observation_spec
+00017830: 5b6b 6579 5d0d 0a20 2020 2020 2020 2072  [key]..        r
+00017840: 6574 7572 6e20 6f62 7365 7276 6174 696f  eturn observatio
+00017850: 6e5f 7370 6563 0d0a 0d0a 2020 2020 6465  n_spec....    de
+00017860: 6620 5f5f 7265 7072 5f5f 2873 656c 6629  f __repr__(self)
+00017870: 202d 3e20 7374 723a 0d0a 2020 2020 2020   -> str:..      
+00017880: 2020 7265 7475 726e 2028 0d0a 2020 2020    return (..    
+00017890: 2020 2020 2020 2020 6622 7b73 656c 662e          f"{self.
+000178a0: 5f5f 636c 6173 735f 5f2e 5f5f 6e61 6d65  __class__.__name
+000178b0: 5f5f 7d28 696e 5f6b 6579 733d 7b73 656c  __}(in_keys={sel
+000178c0: 662e 696e 5f6b 6579 737d 2c20 6f75 745f  f.in_keys}, out_
+000178d0: 6b65 7922 0d0a 2020 2020 2020 2020 2020  key"..          
+000178e0: 2020 6622 3d7b 7365 6c66 2e6f 7574 5f6b    f"={self.out_k
+000178f0: 6579 735b 305d 7d29 220d 0a20 2020 2020  eys[0]})"..     
+00017900: 2020 2029 0d0a 0d0a 0d0a 636c 6173 7320     )......class 
+00017910: 4469 7363 7265 7465 4163 7469 6f6e 5072  DiscreteActionPr
+00017920: 6f6a 6563 7469 6f6e 2854 7261 6e73 666f  ojection(Transfo
+00017930: 726d 293a 0d0a 2020 2020 2222 2250 726f  rm):..    """Pro
+00017940: 6a65 6374 7320 6469 7363 7265 7465 2061  jects discrete a
+00017950: 6374 696f 6e73 2066 726f 6d20 6120 6869  ctions from a hi
+00017960: 6768 2064 696d 656e 7369 6f6e 616c 2073  gh dimensional s
+00017970: 7061 6365 2074 6f20 6120 6c6f 7720 6469  pace to a low di
+00017980: 6d65 6e73 696f 6e61 6c20 7370 6163 652e  mensional space.
+00017990: 0d0a 0d0a 2020 2020 4769 7665 6e20 6120  ....    Given a 
+000179a0: 6469 7363 7265 7465 2061 6374 696f 6e20  discrete action 
+000179b0: 2866 726f 6d20 3120 746f 204e 2920 656e  (from 1 to N) en
+000179c0: 636f 6465 6420 6173 2061 206f 6e65 2d68  coded as a one-h
+000179d0: 6f74 2076 6563 746f 7220 616e 6420 610d  ot vector and a.
+000179e0: 0a20 2020 206d 6178 696d 756d 2061 6374  .    maximum act
+000179f0: 696f 6e20 696e 6465 7820 6e75 6d5f 6163  ion index num_ac
+00017a00: 7469 6f6e 7320 2877 6974 6820 6e75 6d5f  tions (with num_
+00017a10: 6163 7469 6f6e 7320 3c20 4e29 2c20 7472  actions < N), tr
+00017a20: 616e 7366 6f72 6d73 2074 6865 2061 6374  ansforms the act
+00017a30: 696f 6e20 7375 6368 2074 6861 740d 0a20  ion such that.. 
+00017a40: 2020 2061 6374 696f 6e5f 6f75 7420 6973     action_out is
+00017a50: 2061 7420 6d6f 7374 206e 756d 5f61 6374   at most num_act
+00017a60: 696f 6e73 2e0d 0a0d 0a20 2020 2049 6620  ions.....    If 
+00017a70: 7468 6520 696e 7075 7420 6163 7469 6f6e  the input action
+00017a80: 2069 7320 3e20 6e75 6d5f 6163 7469 6f6e   is > num_action
+00017a90: 732c 2069 7420 6973 2062 6569 6e67 2072  s, it is being r
+00017aa0: 6570 6c61 6365 6420 6279 2061 2072 616e  eplaced by a ran
+00017ab0: 646f 6d20 7661 6c75 650d 0a20 2020 2062  dom value..    b
+00017ac0: 6574 7765 656e 2030 2061 6e64 206e 756d  etween 0 and num
+00017ad0: 5f61 6374 696f 6e73 2d31 2e20 4f74 6865  _actions-1. Othe
+00017ae0: 7277 6973 6520 7468 6520 7361 6d65 2061  rwise the same a
+00017af0: 6374 696f 6e20 6973 206b 6570 742e 0d0a  ction is kept...
+00017b00: 2020 2020 5468 6973 2069 7320 696e 7465      This is inte
+00017b10: 6e64 6564 2074 6f20 6265 2075 7365 6420  nded to be used 
+00017b20: 7769 7468 2070 6f6c 6963 6965 7320 6170  with policies ap
+00017b30: 706c 6965 6420 6f76 6572 206d 756c 7469  plied over multi
+00017b40: 706c 6520 6469 7363 7265 7465 0d0a 2020  ple discrete..  
+00017b50: 2020 636f 6e74 726f 6c20 656e 7669 726f    control enviro
+00017b60: 6e6d 656e 7473 2077 6974 6820 6469 6666  nments with diff
+00017b70: 6572 656e 7420 6163 7469 6f6e 2073 7061  erent action spa
+00017b80: 6365 2e0d 0a0d 0a20 2020 2041 2063 616c  ce.....    A cal
+00017b90: 6c20 746f 2044 6973 6372 6574 6541 6374  l to DiscreteAct
+00017ba0: 696f 6e50 726f 6a65 6374 696f 6e2e 666f  ionProjection.fo
+00017bb0: 7277 6172 6420 2865 6720 6672 6f6d 2061  rward (eg from a
+00017bc0: 2072 6570 6c61 7920 6275 6666 6572 206f   replay buffer o
+00017bd0: 7220 696e 2061 0d0a 2020 2020 7365 7175  r in a..    sequ
+00017be0: 656e 6365 206f 6620 6e6e 2e4d 6f64 756c  ence of nn.Modul
+00017bf0: 6573 2920 7769 6c6c 2063 616c 6c20 7468  es) will call th
+00017c00: 6520 7472 616e 7366 6f72 6d20 6e75 6d5f  e transform num_
+00017c10: 6163 7469 6f6e 735f 6566 6665 6374 6976  actions_effectiv
+00017c20: 6520 2d3e 206d 6178 5f61 6374 696f 6e73  e -> max_actions
+00017c30: 0d0a 2020 2020 6f6e 2074 6865 203a 6f62  ..    on the :ob
+00017c40: 6a3a 6022 696e 5f6b 6579 7322 602c 2077  j:`"in_keys"`, w
+00017c50: 6865 7265 6173 2061 2063 616c 6c20 746f  hereas a call to
+00017c60: 205f 6361 6c6c 2077 696c 6c20 6265 2069   _call will be i
+00017c70: 676e 6f72 6564 2e20 496e 6465 6564 2c0d  gnored. Indeed,.
+00017c80: 0a20 2020 2074 7261 6e73 666f 726d 6564  .    transformed
+00017c90: 2065 6e76 7320 6172 6520 696e 7374 7275   envs are instru
+00017ca0: 6374 6564 2074 6f20 7570 6461 7465 2074  cted to update t
+00017cb0: 6865 2069 6e70 7574 206b 6579 7320 6f6e  he input keys on
+00017cc0: 6c79 2066 6f72 2074 6865 2069 6e6e 6572  ly for the inner
+00017cd0: 0d0a 2020 2020 6261 7365 5f65 6e76 2c20  ..    base_env, 
+00017ce0: 6275 7420 7468 6520 6f72 6967 696e 616c  but the original
+00017cf0: 2069 6e70 7574 206b 6579 7320 7769 6c6c   input keys will
+00017d00: 2072 656d 6169 6e20 756e 6368 616e 6765   remain unchange
+00017d10: 642e 0d0a 0d0a 2020 2020 4172 6773 3a0d  d.....    Args:.
+00017d20: 0a20 2020 2020 2020 206e 756d 5f61 6374  .        num_act
+00017d30: 696f 6e73 5f65 6666 6563 7469 7665 2028  ions_effective (
+00017d40: 696e 7429 3a20 6d61 7820 6e75 6d62 6572  int): max number
+00017d50: 206f 6620 6163 7469 6f6e 2063 6f6e 7369   of action consi
+00017d60: 6465 7265 642e 0d0a 2020 2020 2020 2020  dered...        
+00017d70: 6d61 785f 6163 7469 6f6e 7320 2869 6e74  max_actions (int
+00017d80: 293a 206d 6178 696d 756d 206e 756d 6265  ): maximum numbe
+00017d90: 7220 6f66 2061 6374 696f 6e73 2074 6861  r of actions tha
+00017da0: 7420 7468 6973 206d 6f64 756c 6520 6361  t this module ca
+00017db0: 6e20 7265 6164 2e0d 0a20 2020 2020 2020  n read...       
+00017dc0: 2061 6374 696f 6e5f 6b65 7920 2873 7472   action_key (str
+00017dd0: 2c20 6f70 7469 6f6e 616c 293a 206b 6579  , optional): key
+00017de0: 206e 616d 6520 6f66 2074 6865 2061 6374   name of the act
+00017df0: 696f 6e2e 2044 6566 6175 6c74 7320 746f  ion. Defaults to
+00017e00: 2022 6163 7469 6f6e 222e 0d0a 2020 2020   "action"...    
+00017e10: 2020 2020 696e 636c 7564 655f 666f 7277      include_forw
+00017e20: 6172 6420 2862 6f6f 6c2c 206f 7074 696f  ard (bool, optio
+00017e30: 6e61 6c29 3a20 6966 2060 6054 7275 6560  nal): if ``True`
+00017e40: 602c 2061 2063 616c 6c20 746f 2066 6f72  `, a call to for
+00017e50: 7761 7264 2077 696c 6c20 616c 736f 0d0a  ward will also..
+00017e60: 2020 2020 2020 2020 2020 2020 6d61 7020              map 
+00017e70: 7468 6520 6163 7469 6f6e 2066 726f 6d20  the action from 
+00017e80: 6f6e 6520 646f 6d61 696e 2074 6f20 7468  one domain to th
+00017e90: 6520 6f74 6865 7220 7768 656e 2074 6865  e other when the
+00017ea0: 206d 6f64 756c 6520 6973 2063 616c 6c65   module is calle
+00017eb0: 640d 0a20 2020 2020 2020 2020 2020 2062  d..            b
+00017ec0: 7920 6120 7265 706c 6179 2062 7566 6665  y a replay buffe
+00017ed0: 7220 6f72 2061 6e20 6e6e 2e4d 6f64 756c  r or an nn.Modul
+00017ee0: 6520 6368 6169 6e2e 2044 6566 6175 6c74  e chain. Default
+00017ef0: 7320 746f 2054 7275 652e 0d0a 0d0a 2020  s to True.....  
+00017f00: 2020 4578 616d 706c 6573 3a0d 0a20 2020    Examples:..   
+00017f10: 2020 2020 203e 3e3e 2074 6f72 6368 2e6d       >>> torch.m
+00017f20: 616e 7561 6c5f 7365 6564 2830 290d 0a20  anual_seed(0).. 
+00017f30: 2020 2020 2020 203e 3e3e 204e 203d 2033         >>> N = 3
+00017f40: 0d0a 2020 2020 2020 2020 3e3e 3e20 4d20  ..        >>> M 
+00017f50: 3d20 320d 0a20 2020 2020 2020 203e 3e3e  = 2..        >>>
+00017f60: 2061 6374 696f 6e20 3d20 746f 7263 682e   action = torch.
+00017f70: 7a65 726f 7328 4e2c 2064 7479 7065 3d74  zeros(N, dtype=t
+00017f80: 6f72 6368 2e6c 6f6e 6729 0d0a 2020 2020  orch.long)..    
+00017f90: 2020 2020 3e3e 3e20 6163 7469 6f6e 5b2d      >>> action[-
+00017fa0: 315d 203d 2031 0d0a 2020 2020 2020 2020  1] = 1..        
+00017fb0: 3e3e 3e20 7464 203d 2054 656e 736f 7244  >>> td = TensorD
+00017fc0: 6963 7428 7b22 6163 7469 6f6e 223a 2061  ict({"action": a
+00017fd0: 6374 696f 6e7d 2c20 5b5d 290d 0a20 2020  ction}, [])..   
+00017fe0: 2020 2020 203e 3e3e 2074 7261 6e73 666f       >>> transfo
+00017ff0: 726d 203d 2044 6973 6372 6574 6541 6374  rm = DiscreteAct
+00018000: 696f 6e50 726f 6a65 6374 696f 6e28 6e75  ionProjection(nu
+00018010: 6d5f 6163 7469 6f6e 735f 6566 6665 6374  m_actions_effect
+00018020: 6976 653d 4d2c 206d 6178 5f61 6374 696f  ive=M, max_actio
+00018030: 6e73 3d4e 290d 0a20 2020 2020 2020 203e  ns=N)..        >
+00018040: 3e3e 205f 203d 2074 7261 6e73 666f 726d  >> _ = transform
+00018050: 2e69 6e76 2874 6429 0d0a 2020 2020 2020  .inv(td)..      
+00018060: 2020 3e3e 3e20 7072 696e 7428 7464 2e67    >>> print(td.g
+00018070: 6574 2822 6163 7469 6f6e 2229 290d 0a20  et("action")).. 
+00018080: 2020 2020 2020 2074 656e 736f 7228 5b31         tensor([1
+00018090: 5d29 0d0a 2020 2020 2222 220d 0a0d 0a20  ])..    """.... 
+000180a0: 2020 2064 6566 205f 5f69 6e69 745f 5f28     def __init__(
+000180b0: 0d0a 2020 2020 2020 2020 7365 6c66 2c0d  ..        self,.
+000180c0: 0a20 2020 2020 2020 206e 756d 5f61 6374  .        num_act
+000180d0: 696f 6e73 5f65 6666 6563 7469 7665 3a20  ions_effective: 
+000180e0: 696e 742c 0d0a 2020 2020 2020 2020 6d61  int,..        ma
+000180f0: 785f 6163 7469 6f6e 733a 2069 6e74 2c0d  x_actions: int,.
+00018100: 0a20 2020 2020 2020 2061 6374 696f 6e5f  .        action_
+00018110: 6b65 793a 2073 7472 203d 2022 6163 7469  key: str = "acti
+00018120: 6f6e 222c 0d0a 2020 2020 2020 2020 696e  on",..        in
+00018130: 636c 7564 655f 666f 7277 6172 643a 2062  clude_forward: b
+00018140: 6f6f 6c20 3d20 5472 7565 2c0d 0a20 2020  ool = True,..   
+00018150: 2029 3a0d 0a20 2020 2020 2020 2069 6e5f   ):..        in_
+00018160: 6b65 7973 5f69 6e76 203d 205b 6163 7469  keys_inv = [acti
+00018170: 6f6e 5f6b 6579 5d0d 0a20 2020 2020 2020  on_key]..       
+00018180: 2069 6620 696e 636c 7564 655f 666f 7277   if include_forw
+00018190: 6172 643a 0d0a 2020 2020 2020 2020 2020  ard:..          
+000181a0: 2020 696e 5f6b 6579 7320 3d20 696e 5f6b    in_keys = in_k
+000181b0: 6579 735f 696e 760d 0a20 2020 2020 2020  eys_inv..       
+000181c0: 2065 6c73 653a 0d0a 2020 2020 2020 2020   else:..        
+000181d0: 2020 2020 696e 5f6b 6579 7320 3d20 5b5d      in_keys = []
+000181e0: 0d0a 2020 2020 2020 2020 7375 7065 7228  ..        super(
+000181f0: 292e 5f5f 696e 6974 5f5f 280d 0a20 2020  ).__init__(..   
+00018200: 2020 2020 2020 2020 2069 6e5f 6b65 7973           in_keys
+00018210: 3d69 6e5f 6b65 7973 2c0d 0a20 2020 2020  =in_keys,..     
+00018220: 2020 2020 2020 206f 7574 5f6b 6579 733d         out_keys=
+00018230: 696e 5f6b 6579 732c 0d0a 2020 2020 2020  in_keys,..      
+00018240: 2020 2020 2020 696e 5f6b 6579 735f 696e        in_keys_in
+00018250: 763d 696e 5f6b 6579 735f 696e 762c 0d0a  v=in_keys_inv,..
+00018260: 2020 2020 2020 2020 2020 2020 6f75 745f              out_
+00018270: 6b65 7973 5f69 6e76 3d69 6e5f 6b65 7973  keys_inv=in_keys
+00018280: 5f69 6e76 2c0d 0a20 2020 2020 2020 2029  _inv,..        )
+00018290: 0d0a 2020 2020 2020 2020 7365 6c66 2e6e  ..        self.n
+000182a0: 756d 5f61 6374 696f 6e73 5f65 6666 6563  um_actions_effec
+000182b0: 7469 7665 203d 206e 756d 5f61 6374 696f  tive = num_actio
+000182c0: 6e73 5f65 6666 6563 7469 7665 0d0a 2020  ns_effective..  
+000182d0: 2020 2020 2020 7365 6c66 2e6d 6178 5f61        self.max_a
+000182e0: 6374 696f 6e73 203d 206d 6178 5f61 6374  ctions = max_act
+000182f0: 696f 6e73 0d0a 2020 2020 2020 2020 6966  ions..        if
+00018300: 206d 6178 5f61 6374 696f 6e73 203c 206e   max_actions < n
+00018310: 756d 5f61 6374 696f 6e73 5f65 6666 6563  um_actions_effec
+00018320: 7469 7665 3a0d 0a20 2020 2020 2020 2020  tive:..         
+00018330: 2020 2072 6169 7365 2052 756e 7469 6d65     raise Runtime
+00018340: 4572 726f 7228 0d0a 2020 2020 2020 2020  Error(..        
+00018350: 2020 2020 2020 2020 2254 6865 2060 6d61          "The `ma
+00018360: 785f 6163 7469 6f6e 7360 2069 6e74 206d  x_actions` int m
+00018370: 7573 7420 6265 2067 7265 6174 6572 206f  ust be greater o
+00018380: 7220 6571 7561 6c20 746f 2060 6e75 6d5f  r equal to `num_
+00018390: 6163 7469 6f6e 735f 6566 6665 6374 6976  actions_effectiv
+000183a0: 6560 2e22 0d0a 2020 2020 2020 2020 2020  e`."..          
+000183b0: 2020 290d 0a0d 0a20 2020 2064 6566 205f    )....    def _
+000183c0: 6361 6c6c 2873 656c 662c 2074 656e 736f  call(self, tenso
+000183d0: 7264 6963 743a 2054 656e 736f 7244 6963  rdict: TensorDic
+000183e0: 7442 6173 6529 202d 3e20 5465 6e73 6f72  tBase) -> Tensor
+000183f0: 4469 6374 4261 7365 3a0d 0a20 2020 2020  DictBase:..     
+00018400: 2020 2023 2057 6520 646f 6e27 7420 646f     # We don't do
+00018410: 2061 6e79 7468 696e 6720 6865 7265 2062   anything here b
+00018420: 6563 6175 7365 2074 6865 2061 6374 696f  ecause the actio
+00018430: 6e20 6973 206d 6f64 6966 6965 6420 6279  n is modified by
+00018440: 2074 6865 2069 6e76 0d0a 2020 2020 2020   the inv..      
+00018450: 2020 2320 6d65 7468 6f64 2062 7574 2077    # method but w
+00018460: 6520 646f 6e27 7420 6e65 6564 2074 6f20  e don't need to 
+00018470: 6d61 7020 6974 2062 6163 6b20 6173 2069  map it back as i
+00018480: 7420 776f 6e27 7420 6265 2075 7064 6174  t won't be updat
+00018490: 6564 2069 6e20 7468 6520 6f72 6967 696e  ed in the origin
+000184a0: 616c 0d0a 2020 2020 2020 2020 2320 7465  al..        # te
+000184b0: 6e73 6f72 6469 6374 0d0a 2020 2020 2020  nsordict..      
+000184c0: 2020 7265 7475 726e 2074 656e 736f 7264    return tensord
+000184d0: 6963 740d 0a0d 0a20 2020 2064 6566 205f  ict....    def _
+000184e0: 6170 706c 795f 7472 616e 7366 6f72 6d28  apply_transform(
+000184f0: 7365 6c66 2c20 6163 7469 6f6e 3a20 746f  self, action: to
+00018500: 7263 682e 5465 6e73 6f72 2920 2d3e 204e  rch.Tensor) -> N
+00018510: 6f6e 653a 0d0a 2020 2020 2020 2020 2320  one:..        # 
+00018520: 5765 2073 7469 6c6c 206e 6565 6420 746f  We still need to
+00018530: 2063 6f64 6520 7468 6520 666f 7277 6172   code the forwar
+00018540: 6420 7472 616e 7366 6f72 6d20 666f 7220  d transform for 
+00018550: 7265 706c 6179 2062 7566 6665 7273 2061  replay buffers a
+00018560: 6e64 206d 6f64 656c 730d 0a20 2020 2020  nd models..     
+00018570: 2020 2061 6374 696f 6e20 3d20 6163 7469     action = acti
+00018580: 6f6e 2e61 7267 6d61 7828 2d31 2920 2023  on.argmax(-1)  #
+00018590: 2062 6f6f 6c20 746f 2069 6e74 0d0a 2020   bool to int..  
+000185a0: 2020 2020 2020 6163 7469 6f6e 203d 206e        action = n
+000185b0: 6e2e 6675 6e63 7469 6f6e 616c 2e6f 6e65  n.functional.one
+000185c0: 5f68 6f74 2861 6374 696f 6e2c 2073 656c  _hot(action, sel
+000185d0: 662e 6d61 785f 6163 7469 6f6e 7329 0d0a  f.max_actions)..
+000185e0: 2020 2020 2020 2020 7265 7475 726e 2061          return a
+000185f0: 6374 696f 6e0d 0a0d 0a20 2020 2064 6566  ction....    def
+00018600: 205f 696e 765f 6170 706c 795f 7472 616e   _inv_apply_tran
+00018610: 7366 6f72 6d28 7365 6c66 2c20 6163 7469  sform(self, acti
+00018620: 6f6e 3a20 746f 7263 682e 5465 6e73 6f72  on: torch.Tensor
+00018630: 2920 2d3e 2074 6f72 6368 2e54 656e 736f  ) -> torch.Tenso
+00018640: 723a 0d0a 2020 2020 2020 2020 6966 2061  r:..        if a
+00018650: 6374 696f 6e2e 7368 6170 655b 2d31 5d20  ction.shape[-1] 
+00018660: 213d 2073 656c 662e 6d61 785f 6163 7469  != self.max_acti
+00018670: 6f6e 733a 0d0a 2020 2020 2020 2020 2020  ons:..          
+00018680: 2020 7261 6973 6520 5275 6e74 696d 6545    raise RuntimeE
+00018690: 7272 6f72 280d 0a20 2020 2020 2020 2020  rror(..         
+000186a0: 2020 2020 2020 2066 2261 6374 696f 6e2e         f"action.
+000186b0: 7368 6170 655b 2d31 5d3d 7b61 6374 696f  shape[-1]={actio
+000186c0: 6e2e 7368 6170 655b 2d31 5d7d 206d 7573  n.shape[-1]} mus
+000186d0: 7420 6d61 7463 6820 7365 6c66 2e6d 6178  t match self.max
+000186e0: 5f61 6374 696f 6e73 3d7b 7365 6c66 2e6d  _actions={self.m
+000186f0: 6178 5f61 6374 696f 6e73 7d2e 220d 0a20  ax_actions}.".. 
+00018700: 2020 2020 2020 2020 2020 2029 0d0a 2020             )..  
+00018710: 2020 2020 2020 6163 7469 6f6e 203d 2061        action = a
+00018720: 6374 696f 6e2e 6172 676d 6178 282d 3129  ction.argmax(-1)
+00018730: 2020 2320 626f 6f6c 2074 6f20 696e 740d    # bool to int.
+00018740: 0a20 2020 2020 2020 2069 6478 203d 2061  .        idx = a
+00018750: 6374 696f 6e20 3e3d 2073 656c 662e 6e75  ction >= self.nu
+00018760: 6d5f 6163 7469 6f6e 735f 6566 6665 6374  m_actions_effect
+00018770: 6976 650d 0a20 2020 2020 2020 2069 6620  ive..        if 
+00018780: 6964 782e 616e 7928 293a 0d0a 2020 2020  idx.any():..    
+00018790: 2020 2020 2020 2020 6163 7469 6f6e 5b69          action[i
+000187a0: 6478 5d20 3d20 746f 7263 682e 7261 6e64  dx] = torch.rand
+000187b0: 696e 7428 7365 6c66 2e6e 756d 5f61 6374  int(self.num_act
+000187c0: 696f 6e73 5f65 6666 6563 7469 7665 2c20  ions_effective, 
+000187d0: 2869 6478 2e73 756d 2829 2c29 290d 0a20  (idx.sum(),)).. 
+000187e0: 2020 2020 2020 2061 6374 696f 6e20 3d20         action = 
+000187f0: 6e6e 2e66 756e 6374 696f 6e61 6c2e 6f6e  nn.functional.on
+00018800: 655f 686f 7428 6163 7469 6f6e 2c20 7365  e_hot(action, se
+00018810: 6c66 2e6e 756d 5f61 6374 696f 6e73 5f65  lf.num_actions_e
+00018820: 6666 6563 7469 7665 290d 0a20 2020 2020  ffective)..     
+00018830: 2020 2072 6574 7572 6e20 6163 7469 6f6e     return action
+00018840: 0d0a 0d0a 2020 2020 6465 6620 7472 616e  ....    def tran
+00018850: 7366 6f72 6d5f 696e 7075 745f 7370 6563  sform_input_spec
+00018860: 2873 656c 662c 2069 6e70 7574 5f73 7065  (self, input_spe
+00018870: 633a 2043 6f6d 706f 7369 7465 5370 6563  c: CompositeSpec
+00018880: 293a 0d0a 2020 2020 2020 2020 696e 7075  ):..        inpu
+00018890: 745f 7370 6563 203d 2069 6e70 7574 5f73  t_spec = input_s
+000188a0: 7065 632e 636c 6f6e 6528 290d 0a20 2020  pec.clone()..   
+000188b0: 2020 2020 2069 6e70 7574 5f73 7065 635b       input_spec[
+000188c0: 2261 6374 696f 6e22 5d20 3d20 4f6e 6548  "action"] = OneH
+000188d0: 6f74 4469 7363 7265 7465 5465 6e73 6f72  otDiscreteTensor
+000188e0: 5370 6563 280d 0a20 2020 2020 2020 2020  Spec(..         
+000188f0: 2020 2073 656c 662e 6d61 785f 6163 7469     self.max_acti
+00018900: 6f6e 732c 0d0a 2020 2020 2020 2020 2020  ons,..          
+00018910: 2020 7368 6170 653d 282a 696e 7075 745f    shape=(*input_
+00018920: 7370 6563 5b22 6163 7469 6f6e 225d 2e73  spec["action"].s
+00018930: 6861 7065 5b3a 2d31 5d2c 2073 656c 662e  hape[:-1], self.
+00018940: 6d61 785f 6163 7469 6f6e 7329 2c0d 0a20  max_actions),.. 
+00018950: 2020 2020 2020 2020 2020 2064 6576 6963             devic
+00018960: 653d 696e 7075 745f 7370 6563 2e64 6576  e=input_spec.dev
+00018970: 6963 652c 0d0a 2020 2020 2020 2020 2020  ice,..          
+00018980: 2020 6474 7970 653d 696e 7075 745f 7370    dtype=input_sp
+00018990: 6563 5b22 6163 7469 6f6e 225d 2e64 7479  ec["action"].dty
+000189a0: 7065 2c0d 0a20 2020 2020 2020 2029 0d0a  pe,..        )..
+000189b0: 2020 2020 2020 2020 7265 7475 726e 2069          return i
+000189c0: 6e70 7574 5f73 7065 630d 0a0d 0a20 2020  nput_spec....   
+000189d0: 2064 6566 205f 5f72 6570 725f 5f28 7365   def __repr__(se
+000189e0: 6c66 2920 2d3e 2073 7472 3a0d 0a20 2020  lf) -> str:..   
+000189f0: 2020 2020 2072 6574 7572 6e20 280d 0a20       return (.. 
+00018a00: 2020 2020 2020 2020 2020 2066 227b 7365             f"{se
+00018a10: 6c66 2e5f 5f63 6c61 7373 5f5f 2e5f 5f6e  lf.__class__.__n
+00018a20: 616d 655f 5f7d 286e 756d 5f61 6374 696f  ame__}(num_actio
+00018a30: 6e73 5f65 6666 6563 7469 7665 3d7b 7365  ns_effective={se
+00018a40: 6c66 2e6e 756d 5f61 6374 696f 6e73 5f65  lf.num_actions_e
+00018a50: 6666 6563 7469 7665 7d2c 206d 6178 5f61  ffective}, max_a
+00018a60: 6374 696f 6e73 3d7b 7365 6c66 2e6d 6178  ctions={self.max
+00018a70: 5f61 6374 696f 6e73 7d2c 2022 0d0a 2020  _actions}, "..  
+00018a80: 2020 2020 2020 2020 2020 6622 696e 5f6b            f"in_k
+00018a90: 6579 735f 696e 763d 7b73 656c 662e 696e  eys_inv={self.in
+00018aa0: 5f6b 6579 735f 696e 767d 2922 0d0a 2020  _keys_inv})"..  
+00018ab0: 2020 2020 2020 290d 0a0d 0a0d 0a63 6c61        )......cla
+00018ac0: 7373 2046 7261 6d65 536b 6970 5472 616e  ss FrameSkipTran
+00018ad0: 7366 6f72 6d28 5472 616e 7366 6f72 6d29  sform(Transform)
+00018ae0: 3a0d 0a20 2020 2022 2222 4120 6672 616d  :..    """A fram
+00018af0: 652d 736b 6970 2074 7261 6e73 666f 726d  e-skip transform
+00018b00: 2e0d 0a0d 0a20 2020 2054 6869 7320 7472  .....    This tr
+00018b10: 616e 7366 6f72 6d20 6170 706c 6965 7320  ansform applies 
+00018b20: 7468 6520 7361 6d65 2061 6374 696f 6e20  the same action 
+00018b30: 7265 7065 6174 6564 6c79 2069 6e20 7468  repeatedly in th
+00018b40: 6520 7061 7265 6e74 2065 6e76 6972 6f6e  e parent environ
+00018b50: 6d65 6e74 2c0d 0a20 2020 2077 6869 6368  ment,..    which
+00018b60: 2069 6d70 726f 7665 7320 7374 6162 696c   improves stabil
+00018b70: 6974 7920 6f6e 2063 6572 7461 696e 2074  ity on certain t
+00018b80: 7261 696e 696e 6720 616c 676f 7269 7468  raining algorith
+00018b90: 6d73 2e0d 0a0d 0a20 2020 2041 7267 733a  ms.....    Args:
+00018ba0: 0d0a 2020 2020 2020 2020 6672 616d 655f  ..        frame_
+00018bb0: 736b 6970 2028 696e 742c 206f 7074 696f  skip (int, optio
+00018bc0: 6e61 6c29 3a20 6120 706f 7369 7469 7665  nal): a positive
+00018bd0: 2069 6e74 6567 6572 2072 6570 7265 7365   integer represe
+00018be0: 6e74 696e 6720 7468 6520 6e75 6d62 6572  nting the number
+00018bf0: 0d0a 2020 2020 2020 2020 2020 2020 6f66  ..            of
+00018c00: 2066 7261 6d65 7320 6475 7269 6e67 2077   frames during w
+00018c10: 6869 6368 2074 6865 2073 616d 6520 6163  hich the same ac
+00018c20: 7469 6f6e 206d 7573 7420 6265 2061 7070  tion must be app
+00018c30: 6c69 6564 2e0d 0a0d 0a20 2020 2022 2222  lied.....    """
+00018c40: 0d0a 0d0a 2020 2020 6465 6620 5f5f 696e  ....    def __in
+00018c50: 6974 5f5f 2873 656c 662c 2066 7261 6d65  it__(self, frame
+00018c60: 5f73 6b69 703a 2069 6e74 203d 2031 293a  _skip: int = 1):
+00018c70: 0d0a 2020 2020 2020 2020 7375 7065 7228  ..        super(
+00018c80: 292e 5f5f 696e 6974 5f5f 285b 5d29 0d0a  ).__init__([])..
+00018c90: 2020 2020 2020 2020 6966 2066 7261 6d65          if frame
+00018ca0: 5f73 6b69 7020 3c20 313a 0d0a 2020 2020  _skip < 1:..    
+00018cb0: 2020 2020 2020 2020 7261 6973 6520 5661          raise Va
+00018cc0: 6c75 6545 7272 6f72 2822 6672 616d 655f  lueError("frame_
+00018cd0: 736b 6970 2073 686f 756c 6420 6861 7665  skip should have
+00018ce0: 2061 2076 616c 7565 2067 7265 6174 6572   a value greater
+00018cf0: 206f 7220 6571 7561 6c20 746f 206f 6e65   or equal to one
+00018d00: 2e22 290d 0a20 2020 2020 2020 2073 656c  .")..        sel
+00018d10: 662e 6672 616d 655f 736b 6970 203d 2066  f.frame_skip = f
+00018d20: 7261 6d65 5f73 6b69 700d 0a0d 0a20 2020  rame_skip....   
+00018d30: 2064 6566 205f 7374 6570 2873 656c 662c   def _step(self,
+00018d40: 2074 656e 736f 7264 6963 743a 2054 656e   tensordict: Ten
+00018d50: 736f 7244 6963 7442 6173 6529 202d 3e20  sorDictBase) -> 
+00018d60: 5465 6e73 6f72 4469 6374 4261 7365 3a0d  TensorDictBase:.
+00018d70: 0a20 2020 2020 2020 2070 6172 656e 7420  .        parent 
+00018d80: 3d20 7365 6c66 2e70 6172 656e 740d 0a20  = self.parent.. 
+00018d90: 2020 2020 2020 2069 6620 7061 7265 6e74         if parent
+00018da0: 2069 7320 4e6f 6e65 3a0d 0a20 2020 2020   is None:..     
+00018db0: 2020 2020 2020 2072 6169 7365 2052 756e         raise Run
+00018dc0: 7469 6d65 4572 726f 7228 2270 6172 656e  timeError("paren
+00018dd0: 7420 6e6f 7420 666f 756e 6420 666f 7220  t not found for 
+00018de0: 4672 616d 6553 6b69 7054 7261 6e73 666f  FrameSkipTransfo
+00018df0: 726d 2229 0d0a 2020 2020 2020 2020 7265  rm")..        re
+00018e00: 7761 7264 203d 2074 656e 736f 7264 6963  ward = tensordic
+00018e10: 742e 6765 7428 2822 6e65 7874 222c 2022  t.get(("next", "
+00018e20: 7265 7761 7264 2229 290d 0a20 2020 2020  reward"))..     
+00018e30: 2020 2066 6f72 205f 2069 6e20 7261 6e67     for _ in rang
+00018e40: 6528 7365 6c66 2e66 7261 6d65 5f73 6b69  e(self.frame_ski
+00018e50: 7020 2d20 3129 3a0d 0a20 2020 2020 2020  p - 1):..       
+00018e60: 2020 2020 2074 656e 736f 7264 6963 7420       tensordict 
+00018e70: 3d20 7061 7265 6e74 2e5f 7374 6570 2874  = parent._step(t
+00018e80: 656e 736f 7264 6963 7429 0d0a 2020 2020  ensordict)..    
+00018e90: 2020 2020 2020 2020 7265 7761 7264 203d          reward =
+00018ea0: 2072 6577 6172 6420 2b20 7465 6e73 6f72   reward + tensor
+00018eb0: 6469 6374 2e67 6574 2828 226e 6578 7422  dict.get(("next"
+00018ec0: 2c20 2272 6577 6172 6422 2929 0d0a 2020  , "reward"))..  
+00018ed0: 2020 2020 2020 7265 7475 726e 2074 656e        return ten
+00018ee0: 736f 7264 6963 742e 7365 7428 2822 6e65  sordict.set(("ne
+00018ef0: 7874 222c 2022 7265 7761 7264 2229 2c20  xt", "reward"), 
+00018f00: 7265 7761 7264 290d 0a0d 0a20 2020 2064  reward)....    d
+00018f10: 6566 2066 6f72 7761 7264 2873 656c 662c  ef forward(self,
+00018f20: 2074 656e 736f 7264 6963 7429 3a0d 0a20   tensordict):.. 
+00018f30: 2020 2020 2020 2072 6169 7365 2052 756e         raise Run
+00018f40: 7469 6d65 4572 726f 7228 0d0a 2020 2020  timeError(..    
+00018f50: 2020 2020 2020 2020 2246 7261 6d65 536b          "FrameSk
+00018f60: 6970 5472 616e 7366 6f72 6d20 6361 6e20  ipTransform can 
+00018f70: 6f6e 6c79 2062 6520 7573 6564 2077 6865  only be used whe
+00018f80: 6e20 6170 7065 6e64 6564 2074 6f20 6120  n appended to a 
+00018f90: 7472 616e 7366 6f72 6d65 6420 656e 762e  transformed env.
+00018fa0: 220d 0a20 2020 2020 2020 2029 0d0a 0d0a  "..        )....
+00018fb0: 0d0a 636c 6173 7320 4e6f 6f70 5265 7365  ..class NoopRese
+00018fc0: 7445 6e76 2854 7261 6e73 666f 726d 293a  tEnv(Transform):
+00018fd0: 0d0a 2020 2020 2222 2252 756e 7320 6120  ..    """Runs a 
+00018fe0: 7365 7269 6573 206f 6620 7261 6e64 6f6d  series of random
+00018ff0: 2061 6374 696f 6e73 2077 6865 6e20 616e   actions when an
+00019000: 2065 6e76 6972 6f6e 6d65 6e74 2069 7320   environment is 
+00019010: 7265 7365 742e 0d0a 0d0a 2020 2020 4172  reset.....    Ar
+00019020: 6773 3a0d 0a20 2020 2020 2020 2065 6e76  gs:..        env
+00019030: 2028 456e 7642 6173 6529 3a20 656e 7620   (EnvBase): env 
+00019040: 6f6e 2077 6869 6368 2074 6865 2072 616e  on which the ran
+00019050: 646f 6d20 6163 7469 6f6e 7320 6861 7665  dom actions have
+00019060: 2074 6f20 6265 0d0a 2020 2020 2020 2020   to be..        
+00019070: 2020 2020 7065 7266 6f72 6d65 642e 2043      performed. C
+00019080: 616e 2062 6520 7468 6520 7361 6d65 2065  an be the same e
+00019090: 6e76 2061 7320 7468 6520 6f6e 6520 7072  nv as the one pr
+000190a0: 6f76 6964 6564 2074 6f20 7468 650d 0a20  ovided to the.. 
+000190b0: 2020 2020 2020 2020 2020 2054 7261 6e73             Trans
+000190c0: 666f 726d 6564 456e 7620 636c 6173 730d  formedEnv class.
+000190d0: 0a20 2020 2020 2020 206e 6f6f 7073 2028  .        noops (
+000190e0: 696e 742c 206f 7074 696f 6e61 6c29 3a20  int, optional): 
+000190f0: 6e75 6d62 6572 206f 6620 6163 7469 6f6e  number of action
+00019100: 7320 7065 7266 6f72 6d65 6420 6166 7465  s performed afte
+00019110: 7220 7265 7365 742e 0d0a 2020 2020 2020  r reset...      
+00019120: 2020 2020 2020 4465 6661 756c 7420 6973        Default is
+00019130: 2060 3330 602e 0d0a 2020 2020 2020 2020   `30`...        
+00019140: 7261 6e64 6f6d 2028 626f 6f6c 2c20 6f70  random (bool, op
+00019150: 7469 6f6e 616c 293a 2069 6620 4661 6c73  tional): if Fals
+00019160: 652c 2074 6865 206e 756d 6265 7220 6f66  e, the number of
+00019170: 2072 616e 646f 6d20 6f70 7320 7769 6c6c   random ops will
+00019180: 0d0a 2020 2020 2020 2020 2020 2020 616c  ..            al
+00019190: 7761 7973 2062 6520 6571 7561 6c20 746f  ways be equal to
+000191a0: 2074 6865 206e 6f6f 7073 2076 616c 7565   the noops value
+000191b0: 2e20 4966 2054 7275 652c 2074 6865 206e  . If True, the n
+000191c0: 756d 6265 7220 6f66 0d0a 2020 2020 2020  umber of..      
+000191d0: 2020 2020 2020 7261 6e64 6f6d 2061 6374        random act
+000191e0: 696f 6e73 2077 696c 6c20 6265 2072 616e  ions will be ran
+000191f0: 646f 6d6c 7920 7365 6c65 6374 6564 2062  domly selected b
+00019200: 6574 7765 656e 2030 2061 6e64 206e 6f6f  etween 0 and noo
+00019210: 7073 2e0d 0a20 2020 2020 2020 2020 2020  ps...           
+00019220: 2044 6566 6175 6c74 2069 7320 6054 7275   Default is `Tru
+00019230: 6560 2e0d 0a0d 0a20 2020 2022 2222 0d0a  e`.....    """..
+00019240: 0d0a 2020 2020 6465 6620 5f5f 696e 6974  ..    def __init
+00019250: 5f5f 2873 656c 662c 206e 6f6f 7073 3a20  __(self, noops: 
+00019260: 696e 7420 3d20 3330 2c20 7261 6e64 6f6d  int = 30, random
+00019270: 3a20 626f 6f6c 203d 2054 7275 6529 3a0d  : bool = True):.
+00019280: 0a20 2020 2020 2020 2022 2222 5361 6d70  .        """Samp
+00019290: 6c65 2069 6e69 7469 616c 2073 7461 7465  le initial state
+000192a0: 7320 6279 2074 616b 696e 6720 7261 6e64  s by taking rand
+000192b0: 6f6d 206e 756d 6265 7220 6f66 206e 6f2d  om number of no-
+000192c0: 6f70 7320 6f6e 2072 6573 6574 2e0d 0a0d  ops on reset....
+000192d0: 0a20 2020 2020 2020 204e 6f2d 6f70 2069  .        No-op i
+000192e0: 7320 6173 7375 6d65 6420 746f 2062 6520  s assumed to be 
+000192f0: 6163 7469 6f6e 2030 2e0d 0a20 2020 2020  action 0...     
+00019300: 2020 2022 2222 0d0a 2020 2020 2020 2020     """..        
+00019310: 7375 7065 7228 292e 5f5f 696e 6974 5f5f  super().__init__
+00019320: 285b 5d29 0d0a 2020 2020 2020 2020 7365  ([])..        se
+00019330: 6c66 2e6e 6f6f 7073 203d 206e 6f6f 7073  lf.noops = noops
+00019340: 0d0a 2020 2020 2020 2020 7365 6c66 2e72  ..        self.r
+00019350: 616e 646f 6d20 3d20 7261 6e64 6f6d 0d0a  andom = random..
+00019360: 0d0a 2020 2020 4070 726f 7065 7274 790d  ..    @property.
+00019370: 0a20 2020 2064 6566 2062 6173 655f 656e  .    def base_en
+00019380: 7628 7365 6c66 293a 0d0a 2020 2020 2020  v(self):..      
+00019390: 2020 7265 7475 726e 2073 656c 662e 7061    return self.pa
+000193a0: 7265 6e74 0d0a 0d0a 2020 2020 6465 6620  rent....    def 
+000193b0: 7265 7365 7428 7365 6c66 2c20 7465 6e73  reset(self, tens
+000193c0: 6f72 6469 6374 3a20 5465 6e73 6f72 4469  ordict: TensorDi
+000193d0: 6374 4261 7365 2920 2d3e 2054 656e 736f  ctBase) -> Tenso
+000193e0: 7244 6963 7442 6173 653a 0d0a 2020 2020  rDictBase:..    
+000193f0: 2020 2020 2222 2244 6f20 6e6f 2d6f 7020      """Do no-op 
+00019400: 6163 7469 6f6e 2066 6f72 2061 206e 756d  action for a num
+00019410: 6265 7220 6f66 2073 7465 7073 2069 6e20  ber of steps in 
+00019420: 5b31 2c20 6e6f 6f70 5f6d 6178 5d2e 2222  [1, noop_max].""
+00019430: 220d 0a20 2020 2020 2020 2074 645f 7265  "..        td_re
+00019440: 7365 7420 3d20 7465 6e73 6f72 6469 6374  set = tensordict
+00019450: 2e63 6c6f 6e65 2846 616c 7365 290d 0a20  .clone(False).. 
+00019460: 2020 2020 2020 2074 656e 736f 7264 6963         tensordic
+00019470: 7420 3d20 7465 6e73 6f72 6469 6374 2e63  t = tensordict.c
+00019480: 6c6f 6e65 2846 616c 7365 290d 0a20 2020  lone(False)..   
+00019490: 2020 2020 2023 2063 6865 636b 2074 6861       # check tha
+000194a0: 7420 7468 6572 6520 6973 2061 2073 696e  t there is a sin
+000194b0: 676c 6520 646f 6e65 2073 7461 7465 202d  gle done state -
+000194c0: 2d20 6265 6861 7669 6f75 7220 6973 2075  - behaviour is u
+000194d0: 6e64 6566 696e 6564 2066 6f72 206d 756c  ndefined for mul
+000194e0: 7469 706c 6520 646f 6e65 730d 0a20 2020  tiple dones..   
+000194f0: 2020 2020 2070 6172 656e 7420 3d20 7365       parent = se
+00019500: 6c66 2e70 6172 656e 740d 0a20 2020 2020  lf.parent..     
+00019510: 2020 2069 6620 7061 7265 6e74 2069 7320     if parent is 
+00019520: 4e6f 6e65 3a0d 0a20 2020 2020 2020 2020  None:..         
+00019530: 2020 2072 6169 7365 2052 756e 7469 6d65     raise Runtime
+00019540: 4572 726f 7228 0d0a 2020 2020 2020 2020  Error(..        
+00019550: 2020 2020 2020 2020 224e 6f6f 7052 6573          "NoopRes
+00019560: 6574 456e 762e 7061 7265 6e74 206e 6f74  etEnv.parent not
+00019570: 2066 6f75 6e64 2e20 4d61 6b65 2073 7572   found. Make sur
+00019580: 6520 7468 6174 2074 6865 2070 6172 656e  e that the paren
+00019590: 7420 6973 2073 6574 2e22 0d0a 2020 2020  t is set."..    
+000195a0: 2020 2020 2020 2020 290d 0a20 2020 2020          )..     
+000195b0: 2020 2069 6620 7465 6e73 6f72 6469 6374     if tensordict
+000195c0: 2e67 6574 2822 646f 6e65 2229 2e6e 756d  .get("done").num
+000195d0: 656c 2829 203e 2031 3a0d 0a20 2020 2020  el() > 1:..     
+000195e0: 2020 2020 2020 2072 6169 7365 2056 616c         raise Val
+000195f0: 7565 4572 726f 7228 0d0a 2020 2020 2020  ueError(..      
+00019600: 2020 2020 2020 2020 2020 2274 6865 7265            "there
+00019610: 2069 7320 6d6f 7265 2074 6861 6e20 6f6e   is more than on
+00019620: 6520 646f 6e65 2073 7461 7465 2069 6e20  e done state in 
+00019630: 7468 6520 7061 7265 6e74 2065 6e76 6972  the parent envir
+00019640: 6f6e 6d65 6e74 2e20 220d 0a20 2020 2020  onment. "..     
+00019650: 2020 2020 2020 2020 2020 2022 4e6f 6f70             "Noop
+00019660: 5265 7365 7445 6e76 2069 7320 6465 7369  ResetEnv is desi
+00019670: 676e 6564 2074 6f20 776f 726b 206f 6e20  gned to work on 
+00019680: 7369 6e67 6c65 2065 6e76 2069 6e73 7461  single env insta
+00019690: 6e63 6573 2c20 6173 2070 6172 7469 616c  nces, as partial
+000196a0: 2072 6573 6574 2022 0d0a 2020 2020 2020   reset "..      
+000196b0: 2020 2020 2020 2020 2020 2269 7320 6375            "is cu
+000196c0: 7272 656e 746c 7920 6e6f 7420 7375 7070  rrently not supp
+000196d0: 6f72 7465 642e 2049 6620 796f 7520 6665  orted. If you fe
+000196e0: 656c 206c 696b 6520 7468 6973 2069 7320  el like this is 
+000196f0: 6120 6d69 7373 696e 6720 6665 6174 7572  a missing featur
+00019700: 652c 2073 7562 6d69 7420 220d 0a20 2020  e, submit "..   
+00019710: 2020 2020 2020 2020 2020 2020 2022 616e               "an
+00019720: 2069 7373 7565 206f 6e20 546f 7263 6852   issue on TorchR
+00019730: 4c20 6769 7468 7562 2072 6570 6f2e 2022  L github repo. "
+00019740: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00019750: 2020 2249 6e20 6361 7365 2079 6f75 2061    "In case you a
+00019760: 7265 2074 7279 696e 6720 746f 2075 7365  re trying to use
+00019770: 204e 6f6f 7052 6573 6574 456e 7620 6f76   NoopResetEnv ov
+00019780: 6572 2061 2062 6174 6368 206f 6620 656e  er a batch of en
+00019790: 7669 726f 6e6d 656e 7473 2c20 6b6e 6f77  vironments, know
+000197a0: 2022 0d0a 2020 2020 2020 2020 2020 2020   "..            
+000197b0: 2020 2020 2274 6861 7420 796f 7520 6361      "that you ca
+000197c0: 6e20 6861 7665 2061 2074 7261 6e73 666f  n have a transfo
+000197d0: 726d 6564 2062 6174 6368 206f 6620 7472  rmed batch of tr
+000197e0: 616e 7366 6f72 6d65 6420 656e 7673 2c20  ansformed envs, 
+000197f0: 7375 6368 2061 733a 2022 0d0a 2020 2020  such as: "..    
+00019800: 2020 2020 2020 2020 2020 2020 2260 5472              "`Tr
+00019810: 616e 7366 6f72 6d65 6445 6e76 2850 6172  ansformedEnv(Par
+00019820: 616c 6c65 6c45 6e76 2833 2c20 6c61 6d62  allelEnv(3, lamb
+00019830: 6461 3a20 5472 616e 7366 6f72 6d65 6445  da: TransformedE
+00019840: 6e76 284d 7945 6e76 2829 2c20 4e6f 6f70  nv(MyEnv(), Noop
+00019850: 5265 7365 7445 6e76 2833 2929 292c 204f  ResetEnv(3))), O
+00019860: 7468 6572 5472 616e 7366 6f72 6d28 2929  therTransform())
+00019870: 602e 220d 0a20 2020 2020 2020 2020 2020  `."..           
+00019880: 2029 0d0a 2020 2020 2020 2020 6e6f 6f70   )..        noop
+00019890: 7320 3d20 280d 0a20 2020 2020 2020 2020  s = (..         
+000198a0: 2020 2073 656c 662e 6e6f 6f70 7320 6966     self.noops if
+000198b0: 206e 6f74 2073 656c 662e 7261 6e64 6f6d   not self.random
+000198c0: 2065 6c73 6520 746f 7263 682e 7261 6e64   else torch.rand
+000198d0: 696e 7428 7365 6c66 2e6e 6f6f 7073 2c20  int(self.noops, 
+000198e0: 2831 2c29 292e 6974 656d 2829 0d0a 2020  (1,)).item()..  
+000198f0: 2020 2020 2020 290d 0a20 2020 2020 2020        )..       
+00019900: 2074 7269 616c 203d 2030 0d0a 0d0a 2020   trial = 0....  
+00019910: 2020 2020 2020 7768 696c 6520 5472 7565        while True
+00019920: 3a0d 0a20 2020 2020 2020 2020 2020 2069  :..            i
+00019930: 203d 2030 0d0a 2020 2020 2020 2020 2020   = 0..          
+00019940: 2020 7768 696c 6520 6920 3c20 6e6f 6f70    while i < noop
+00019950: 733a 0d0a 2020 2020 2020 2020 2020 2020  s:..            
+00019960: 2020 2020 6920 2b3d 2031 0d0a 2020 2020      i += 1..    
+00019970: 2020 2020 2020 2020 2020 2020 7465 6e73              tens
+00019980: 6f72 6469 6374 203d 2070 6172 656e 742e  ordict = parent.
+00019990: 7261 6e64 5f73 7465 7028 7465 6e73 6f72  rand_step(tensor
+000199a0: 6469 6374 290d 0a20 2020 2020 2020 2020  dict)..         
+000199b0: 2020 2020 2020 2074 656e 736f 7264 6963         tensordic
+000199c0: 7420 3d20 7374 6570 5f6d 6470 2874 656e  t = step_mdp(ten
+000199d0: 736f 7264 6963 742c 2065 7863 6c75 6465  sordict, exclude
+000199e0: 5f64 6f6e 653d 4661 6c73 6529 0d0a 2020  _done=False)..  
+000199f0: 2020 2020 2020 2020 2020 2020 2020 6966                if
+00019a00: 2074 656e 736f 7264 6963 742e 6765 7428   tensordict.get(
+00019a10: 2264 6f6e 6522 293a 0d0a 2020 2020 2020  "done"):..      
+00019a20: 2020 2020 2020 2020 2020 2020 2020 7465                te
+00019a30: 6e73 6f72 6469 6374 203d 2070 6172 656e  nsordict = paren
+00019a40: 742e 7265 7365 7428 7464 5f72 6573 6574  t.reset(td_reset
+00019a50: 2e63 6c6f 6e65 2846 616c 7365 2929 0d0a  .clone(False))..
+00019a60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019a70: 2020 2020 6272 6561 6b0d 0a20 2020 2020      break..     
+00019a80: 2020 2020 2020 2065 6c73 653a 0d0a 2020         else:..  
+00019a90: 2020 2020 2020 2020 2020 2020 2020 6272                br
+00019aa0: 6561 6b0d 0a0d 0a20 2020 2020 2020 2020  eak....         
+00019ab0: 2020 2074 7269 616c 202b 3d20 310d 0a20     trial += 1.. 
+00019ac0: 2020 2020 2020 2020 2020 2069 6620 7472             if tr
+00019ad0: 6961 6c20 3e20 5f4d 4158 5f4e 4f4f 5053  ial > _MAX_NOOPS
+00019ae0: 5f54 5249 414c 533a 0d0a 2020 2020 2020  _TRIALS:..      
+00019af0: 2020 2020 2020 2020 2020 7465 6e73 6f72            tensor
+00019b00: 6469 6374 203d 2070 6172 656e 742e 7261  dict = parent.ra
+00019b10: 6e64 5f73 7465 7028 7465 6e73 6f72 6469  nd_step(tensordi
+00019b20: 6374 290d 0a20 2020 2020 2020 2020 2020  ct)..           
+00019b30: 2020 2020 2069 6620 7465 6e73 6f72 6469       if tensordi
+00019b40: 6374 2e67 6574 2828 226e 6578 7422 2c20  ct.get(("next", 
+00019b50: 2264 6f6e 6522 2929 3a0d 0a20 2020 2020  "done")):..     
+00019b60: 2020 2020 2020 2020 2020 2020 2020 2072                 r
+00019b70: 6169 7365 2052 756e 7469 6d65 4572 726f  aise RuntimeErro
+00019b80: 7228 0d0a 2020 2020 2020 2020 2020 2020  r(..            
+00019b90: 2020 2020 2020 2020 2020 2020 6622 7061              f"pa
+00019ba0: 7265 6e74 2069 7320 7374 696c 6c20 646f  rent is still do
+00019bb0: 6e65 2061 6674 6572 2061 2073 696e 676c  ne after a singl
+00019bc0: 6520 7261 6e64 6f6d 2073 7465 7020 2869  e random step (i
+00019bd0: 3d7b 697d 292e 220d 0a20 2020 2020 2020  ={i})."..       
+00019be0: 2020 2020 2020 2020 2020 2020 2029 0d0a               )..
+00019bf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00019c00: 6272 6561 6b0d 0a0d 0a20 2020 2020 2020  break....       
+00019c10: 2069 6620 7465 6e73 6f72 6469 6374 2e67   if tensordict.g
+00019c20: 6574 2822 646f 6e65 2229 3a0d 0a20 2020  et("done"):..   
+00019c30: 2020 2020 2020 2020 2072 6169 7365 2052           raise R
+00019c40: 756e 7469 6d65 4572 726f 7228 224e 6f6f  untimeError("Noo
+00019c50: 7052 6573 6574 456e 7620 636f 6e63 6c75  pResetEnv conclu
+00019c60: 6465 6420 7769 7468 2064 6f6e 6520 656e  ded with done en
+00019c70: 7669 726f 6e6d 656e 7422 290d 0a20 2020  vironment")..   
+00019c80: 2020 2020 2072 6574 7572 6e20 7465 6e73       return tens
+00019c90: 6f72 6469 6374 0d0a 0d0a 2020 2020 6465  ordict....    de
+00019ca0: 6620 5f5f 7265 7072 5f5f 2873 656c 6629  f __repr__(self)
+00019cb0: 202d 3e20 7374 723a 0d0a 2020 2020 2020   -> str:..      
+00019cc0: 2020 7261 6e64 6f6d 203d 2073 656c 662e    random = self.
+00019cd0: 7261 6e64 6f6d 0d0a 2020 2020 2020 2020  random..        
+00019ce0: 6e6f 6f70 7320 3d20 7365 6c66 2e6e 6f6f  noops = self.noo
+00019cf0: 7073 0d0a 2020 2020 2020 2020 636c 6173  ps..        clas
+00019d00: 735f 6e61 6d65 203d 2073 656c 662e 5f5f  s_name = self.__
+00019d10: 636c 6173 735f 5f2e 5f5f 6e61 6d65 5f5f  class__.__name__
+00019d20: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
+00019d30: 2066 227b 636c 6173 735f 6e61 6d65 7d28   f"{class_name}(
+00019d40: 6e6f 6f70 733d 7b6e 6f6f 7073 7d2c 2072  noops={noops}, r
+00019d50: 616e 646f 6d3d 7b72 616e 646f 6d7d 2922  andom={random})"
+00019d60: 0d0a 0d0a 0d0a 636c 6173 7320 5465 6e73  ......class Tens
+00019d70: 6f72 4469 6374 5072 696d 6572 2854 7261  orDictPrimer(Tra
+00019d80: 6e73 666f 726d 293a 0d0a 2020 2020 2222  nsform):..    ""
+00019d90: 2241 2070 7269 6d65 7220 666f 7220 5465  "A primer for Te
+00019da0: 6e73 6f72 4469 6374 2069 6e69 7469 616c  nsorDict initial
+00019db0: 697a 6174 696f 6e20 6174 2072 6573 6574  ization at reset
+00019dc0: 2074 696d 652e 0d0a 0d0a 2020 2020 5468   time.....    Th
+00019dd0: 6973 2074 7261 6e73 666f 726d 2077 696c  is transform wil
+00019de0: 6c20 706f 7075 6c61 7465 2074 6865 2074  l populate the t
+00019df0: 656e 736f 7264 6963 7420 6174 2072 6573  ensordict at res
+00019e00: 6574 2077 6974 6820 7661 6c75 6573 2064  et with values d
+00019e10: 7261 776e 2066 726f 6d0d 0a20 2020 2074  rawn from..    t
+00019e20: 6865 2072 656c 6174 6976 6520 7465 6e73  he relative tens
+00019e30: 6f72 7370 6563 7320 7072 6f76 6964 6564  orspecs provided
+00019e40: 2061 7420 696e 6974 6961 6c69 7a61 7469   at initializati
+00019e50: 6f6e 2e0d 0a20 2020 2049 6620 7468 6520  on...    If the 
+00019e60: 7472 616e 7366 6f72 6d20 6973 2075 7365  transform is use
+00019e70: 6420 6f75 7420 6f66 2074 6865 2065 6e76  d out of the env
+00019e80: 2063 6f6e 7465 7874 2028 652e 672e 2061   context (e.g. a
+00019e90: 7320 616e 206e 6e2e 4d6f 6475 6c65 206f  s an nn.Module o
+00019ea0: 720d 0a20 2020 2061 7070 656e 6465 6420  r..    appended 
+00019eb0: 746f 2061 2072 6570 6c61 7920 6275 6666  to a replay buff
+00019ec0: 6572 292c 2061 2063 616c 6c20 746f 2060  er), a call to `
+00019ed0: 666f 7277 6172 6460 2077 696c 6c20 616c  forward` will al
+00019ee0: 736f 2070 6f70 756c 6174 6520 7468 650d  so populate the.
+00019ef0: 0a20 2020 2074 656e 736f 7264 6963 7420  .    tensordict 
+00019f00: 7769 7468 2074 6865 2064 6573 6972 6564  with the desired
+00019f10: 2066 6561 7475 7265 732e 0d0a 0d0a 2020   features.....  
+00019f20: 2020 4172 6773 3a0d 0a20 2020 2020 2020    Args:..       
+00019f30: 2070 7269 6d65 7273 2028 6469 6374 2c20   primers (dict, 
+00019f40: 6f70 7469 6f6e 616c 293a 2061 2064 6963  optional): a dic
+00019f50: 7469 6f6e 6172 7920 636f 6e74 6169 6e69  tionary containi
+00019f60: 6e67 206b 6579 2d73 7065 6320 7061 6972  ng key-spec pair
+00019f70: 7320 7768 6963 6820 7769 6c6c 0d0a 2020  s which will..  
+00019f80: 2020 2020 2020 2020 2020 6265 2075 7365            be use
+00019f90: 6420 746f 2070 6f70 756c 6174 6520 7468  d to populate th
+00019fa0: 6520 696e 7075 7420 7465 6e73 6f72 6469  e input tensordi
+00019fb0: 6374 2e0d 0a20 2020 2020 2020 2072 616e  ct...        ran
+00019fc0: 646f 6d20 2862 6f6f 6c2c 206f 7074 696f  dom (bool, optio
+00019fd0: 6e61 6c29 3a20 6966 2060 6054 7275 6560  nal): if ``True`
+00019fe0: 602c 2074 6865 2076 616c 7565 7320 7769  `, the values wi
+00019ff0: 6c6c 2062 6520 6472 6177 6e20 7261 6e64  ll be drawn rand
+0001a000: 6f6d 6c79 2066 726f 6d0d 0a20 2020 2020  omly from..     
+0001a010: 2020 2020 2020 2074 6865 2054 656e 736f         the Tenso
+0001a020: 7253 7065 6320 646f 6d61 696e 2028 6f72  rSpec domain (or
+0001a030: 2061 2075 6e69 7420 4761 7573 7369 616e   a unit Gaussian
+0001a040: 2069 6620 756e 626f 756e 6465 6429 2e20   if unbounded). 
+0001a050: 4f74 6865 7277 6973 6520 6120 6669 7865  Otherwise a fixe
+0001a060: 6420 7661 6c75 6520 7769 6c6c 2062 6520  d value will be 
+0001a070: 6173 7375 6d65 642e 0d0a 2020 2020 2020  assumed...      
+0001a080: 2020 2020 2020 4465 6661 756c 7473 2074        Defaults t
+0001a090: 6f20 6046 616c 7365 602e 0d0a 2020 2020  o `False`...    
+0001a0a0: 2020 2020 6465 6661 756c 745f 7661 6c75      default_valu
+0001a0b0: 6520 2866 6c6f 6174 2c20 6f70 7469 6f6e  e (float, option
+0001a0c0: 616c 293a 2069 6620 6e6f 6e2d 7261 6e64  al): if non-rand
+0001a0d0: 6f6d 2066 696c 6c69 6e67 2069 7320 6368  om filling is ch
+0001a0e0: 6f73 656e 2c20 7468 6973 0d0a 2020 2020  osen, this..    
+0001a0f0: 2020 2020 2020 2020 7661 6c75 6520 7769          value wi
+0001a100: 6c6c 2062 6520 7573 6564 2074 6f20 706f  ll be used to po
+0001a110: 7075 6c61 7465 2074 6865 2074 656e 736f  pulate the tenso
+0001a120: 7273 2e20 4465 6661 756c 7473 2074 6f20  rs. Defaults to 
+0001a130: 6030 2e30 602e 0d0a 2020 2020 2020 2020  `0.0`...        
+0001a140: 2a2a 6b77 6172 6773 3a20 6561 6368 206b  **kwargs: each k
+0001a150: 6579 776f 7264 2061 7267 756d 656e 7420  eyword argument 
+0001a160: 636f 7272 6573 706f 6e64 7320 746f 2061  corresponds to a
+0001a170: 206b 6579 2069 6e20 7468 6520 7465 6e73   key in the tens
+0001a180: 6f72 6469 6374 2e0d 0a20 2020 2020 2020  ordict...       
+0001a190: 2020 2020 2054 6865 2063 6f72 7265 7370       The corresp
+0001a1a0: 6f6e 6469 6e67 2076 616c 7565 2068 6173  onding value has
+0001a1b0: 2074 6f20 6265 2061 2054 656e 736f 7253   to be a TensorS
+0001a1c0: 7065 6320 696e 7374 616e 6365 2069 6e64  pec instance ind
+0001a1d0: 6963 6174 696e 670d 0a20 2020 2020 2020  icating..       
+0001a1e0: 2020 2020 2077 6861 7420 7468 6520 7661       what the va
+0001a1f0: 6c75 6520 6d75 7374 2062 652e 0d0a 0d0a  lue must be.....
+0001a200: 2020 2020 5768 656e 2075 7365 6420 696e      When used in
+0001a210: 2061 2054 7261 6e73 666f 6d65 6445 6e76   a TransfomedEnv
+0001a220: 2c20 7468 6520 7370 6563 2073 6861 7065  , the spec shape
+0001a230: 7320 6d75 7374 206d 6174 6368 2074 6865  s must match the
+0001a240: 2065 6e76 7320 7368 6170 6520 6966 0d0a   envs shape if..
+0001a250: 2020 2020 7468 6520 7061 7265 6e74 2065      the parent e
+0001a260: 6e76 2069 7320 6261 7463 682d 6c6f 636b  nv is batch-lock
+0001a270: 6564 2028 3a6f 626a 3a60 656e 762e 6261  ed (:obj:`env.ba
+0001a280: 7463 685f 6c6f 636b 6564 3d54 7275 6560  tch_locked=True`
+0001a290: 292e 0d0a 2020 2020 4966 2074 6865 2065  )...    If the e
+0001a2a0: 6e76 2069 7320 6e6f 7420 6261 7463 682d  nv is not batch-
+0001a2b0: 6c6f 636b 6564 2028 652e 672e 206d 6f64  locked (e.g. mod
+0001a2c0: 656c 2d62 6173 6564 2065 6e76 7329 2c20  el-based envs), 
+0001a2d0: 6974 2069 7320 6173 7375 6d65 6420 7468  it is assumed th
+0001a2e0: 6174 2074 6865 2062 6174 6368 2069 730d  at the batch is.
+0001a2f0: 0a20 2020 2067 6976 656e 2062 7920 7468  .    given by th
+0001a300: 6520 696e 7075 7420 7465 6e73 6f72 6469  e input tensordi
+0001a310: 6374 2069 6e73 7465 6164 2e0d 0a0d 0a20  ct instead..... 
+0001a320: 2020 2045 7861 6d70 6c65 733a 0d0a 2020     Examples:..  
+0001a330: 2020 2020 2020 3e3e 3e20 6672 6f6d 2074        >>> from t
+0001a340: 6f72 6368 726c 2e65 6e76 732e 6c69 6273  orchrl.envs.libs
+0001a350: 2e67 796d 2069 6d70 6f72 7420 4779 6d45  .gym import GymE
+0001a360: 6e76 0d0a 2020 2020 2020 2020 3e3e 3e20  nv..        >>> 
+0001a370: 6672 6f6d 2074 6f72 6368 726c 2e65 6e76  from torchrl.env
+0001a380: 7320 696d 706f 7274 2053 6572 6961 6c45  s import SerialE
+0001a390: 6e76 0d0a 2020 2020 2020 2020 3e3e 3e20  nv..        >>> 
+0001a3a0: 6261 7365 5f65 6e76 203d 2053 6572 6961  base_env = Seria
+0001a3b0: 6c45 6e76 2832 2c20 6c61 6d62 6461 3a20  lEnv(2, lambda: 
+0001a3c0: 4779 6d45 6e76 2822 5065 6e64 756c 756d  GymEnv("Pendulum
+0001a3d0: 2d76 3122 2929 0d0a 2020 2020 2020 2020  -v1"))..        
+0001a3e0: 3e3e 3e20 656e 7620 3d20 5472 616e 7366  >>> env = Transf
+0001a3f0: 6f72 6d65 6445 6e76 2862 6173 655f 656e  ormedEnv(base_en
+0001a400: 7629 0d0a 2020 2020 2020 2020 3e3e 3e20  v)..        >>> 
+0001a410: 2320 7468 6520 656e 7620 6973 2062 6174  # the env is bat
+0001a420: 6368 2d6c 6f63 6b65 642c 2073 6f20 7468  ch-locked, so th
+0001a430: 6520 6c65 6164 696e 6720 6469 6d73 206f  e leading dims o
+0001a440: 6620 7468 6520 7370 6563 206d 7573 7420  f the spec must 
+0001a450: 6d61 7463 6820 7468 6f73 6520 6f66 2074  match those of t
+0001a460: 6865 2065 6e76 0d0a 2020 2020 2020 2020  he env..        
+0001a470: 3e3e 3e20 656e 762e 6170 7065 6e64 5f74  >>> env.append_t
+0001a480: 7261 6e73 666f 726d 2854 656e 736f 7244  ransform(TensorD
+0001a490: 6963 7450 7269 6d65 7228 6d79 6b65 793d  ictPrimer(mykey=
+0001a4a0: 556e 626f 756e 6465 6443 6f6e 7469 6e75  UnboundedContinu
+0001a4b0: 6f75 7354 656e 736f 7253 7065 6328 5b32  ousTensorSpec([2
+0001a4c0: 2c20 335d 2929 290d 0a20 2020 2020 2020  , 3])))..       
+0001a4d0: 203e 3e3e 2074 6420 3d20 656e 762e 7265   >>> td = env.re
+0001a4e0: 7365 7428 290d 0a20 2020 2020 2020 203e  set()..        >
+0001a4f0: 3e3e 2070 7269 6e74 2874 6429 0d0a 2020  >> print(td)..  
+0001a500: 2020 2020 2020 5465 6e73 6f72 4469 6374        TensorDict
+0001a510: 280d 0a20 2020 2020 2020 2020 2020 2066  (..            f
+0001a520: 6965 6c64 733d 7b0d 0a20 2020 2020 2020  ields={..       
+0001a530: 2020 2020 2020 2020 2064 6f6e 653a 2054           done: T
+0001a540: 656e 736f 7228 7368 6170 653d 746f 7263  ensor(shape=torc
+0001a550: 682e 5369 7a65 285b 322c 2031 5d29 2c20  h.Size([2, 1]), 
+0001a560: 6465 7669 6365 3d63 7075 2c20 6474 7970  device=cpu, dtyp
+0001a570: 653d 746f 7263 682e 626f 6f6c 2c20 6973  e=torch.bool, is
+0001a580: 5f73 6861 7265 643d 4661 6c73 6529 2c0d  _shared=False),.
+0001a590: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001a5a0: 206d 796b 6579 3a20 5465 6e73 6f72 2873   mykey: Tensor(s
+0001a5b0: 6861 7065 3d74 6f72 6368 2e53 697a 6528  hape=torch.Size(
+0001a5c0: 5b32 2c20 335d 292c 2064 6576 6963 653d  [2, 3]), device=
+0001a5d0: 6370 752c 2064 7479 7065 3d74 6f72 6368  cpu, dtype=torch
+0001a5e0: 2e66 6c6f 6174 3332 2c20 6973 5f73 6861  .float32, is_sha
+0001a5f0: 7265 643d 4661 6c73 6529 2c0d 0a20 2020  red=False),..   
+0001a600: 2020 2020 2020 2020 2020 2020 206f 6273               obs
+0001a610: 6572 7661 7469 6f6e 3a20 5465 6e73 6f72  ervation: Tensor
+0001a620: 2873 6861 7065 3d74 6f72 6368 2e53 697a  (shape=torch.Siz
+0001a630: 6528 5b32 2c20 335d 292c 2064 6576 6963  e([2, 3]), devic
+0001a640: 653d 6370 752c 2064 7479 7065 3d74 6f72  e=cpu, dtype=tor
+0001a650: 6368 2e66 6c6f 6174 3332 2c20 6973 5f73  ch.float32, is_s
+0001a660: 6861 7265 643d 4661 6c73 6529 7d2c 0d0a  hared=False)},..
+0001a670: 2020 2020 2020 2020 2020 2020 6261 7463              batc
+0001a680: 685f 7369 7a65 3d74 6f72 6368 2e53 697a  h_size=torch.Siz
+0001a690: 6528 5b32 5d29 2c0d 0a20 2020 2020 2020  e([2]),..       
+0001a6a0: 2020 2020 2064 6576 6963 653d 6370 752c       device=cpu,
+0001a6b0: 0d0a 2020 2020 2020 2020 2020 2020 6973  ..            is
+0001a6c0: 5f73 6861 7265 643d 4661 6c73 6529 0d0a  _shared=False)..
+0001a6d0: 2020 2020 2020 2020 3e3e 3e20 2320 7468          >>> # th
+0001a6e0: 6520 656e 7472 7920 6973 2070 6f70 756c  e entry is popul
+0001a6f0: 6174 6564 2077 6974 6820 3073 0d0a 2020  ated with 0s..  
+0001a700: 2020 2020 2020 3e3e 3e20 7072 696e 7428        >>> print(
+0001a710: 7464 2e67 6574 2822 6d79 6b65 7922 2929  td.get("mykey"))
+0001a720: 0d0a 2020 2020 2020 2020 7465 6e73 6f72  ..        tensor
+0001a730: 285b 5b30 2e2c 2030 2e2c 2030 2e5d 2c0d  ([[0., 0., 0.],.
+0001a740: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001a750: 205b 302e 2c20 302e 2c20 302e 5d5d 290d   [0., 0., 0.]]).
+0001a760: 0a0d 0a20 2020 2057 6865 6e20 6361 6c6c  ...    When call
+0001a770: 696e 6720 6060 656e 762e 7374 6570 2829  ing ``env.step()
+0001a780: 6060 2c20 7468 6520 6375 7272 656e 7420  ``, the current 
+0001a790: 7661 6c75 6520 6f66 2074 6865 206b 6579  value of the key
+0001a7a0: 2077 696c 6c20 6265 2063 6172 7269 6564   will be carried
+0001a7b0: 0d0a 2020 2020 696e 2074 6865 2060 6022  ..    in the ``"
+0001a7c0: 6e65 7874 2260 6020 7465 6e73 6f72 6469  next"`` tensordi
+0001a7d0: 6374 205f 5f75 6e6c 6573 7320 6974 2061  ct __unless it a
+0001a7e0: 6c72 6561 6479 2065 7869 7374 735f 5f2e  lready exists__.
+0001a7f0: 0d0a 0d0a 2020 2020 4578 616d 706c 6573  ....    Examples
+0001a800: 3a0d 0a20 2020 2020 2020 203e 3e3e 2074  :..        >>> t
+0001a810: 6420 3d20 656e 762e 7261 6e64 5f73 7465  d = env.rand_ste
+0001a820: 7028 7464 290d 0a20 2020 2020 2020 203e  p(td)..        >
+0001a830: 3e3e 2070 7269 6e74 2874 642e 6765 7428  >> print(td.get(
+0001a840: 2822 6e65 7874 222c 2022 6d79 6b65 7922  ("next", "mykey"
+0001a850: 2929 290d 0a20 2020 2020 2020 2074 656e  )))..        ten
+0001a860: 736f 7228 5b5b 302e 2c20 302e 2c20 302e  sor([[0., 0., 0.
+0001a870: 5d2c 0d0a 2020 2020 2020 2020 2020 2020  ],..            
+0001a880: 2020 2020 5b30 2e2c 2030 2e2c 2030 2e5d      [0., 0., 0.]
+0001a890: 5d29 0d0a 2020 2020 2020 2020 3e3e 3e20  ])..        >>> 
+0001a8a0: 2320 7769 7468 2061 6e6f 7468 6572 2076  # with another v
+0001a8b0: 616c 7565 2066 6f72 2022 6d79 6b65 7922  alue for "mykey"
+0001a8c0: 2c20 7468 6520 7072 6576 696f 7573 2076  , the previous v
+0001a8d0: 616c 7565 2069 7320 6e6f 7420 6361 7272  alue is not carr
+0001a8e0: 6965 6420 6f6e 0d0a 2020 2020 2020 2020  ied on..        
+0001a8f0: 3e3e 3e20 7464 203d 2065 6e76 2e72 6573  >>> td = env.res
+0001a900: 6574 2829 0d0a 2020 2020 2020 2020 3e3e  et()..        >>
+0001a910: 3e20 7464 203d 2074 642e 7365 7428 2822  > td = td.set(("
+0001a920: 6e65 7874 222c 2022 6d79 6b65 7922 292c  next", "mykey"),
+0001a930: 2074 6f72 6368 2e6f 6e65 7328 322c 2033   torch.ones(2, 3
+0001a940: 2929 0d0a 2020 2020 2020 2020 3e3e 3e20  ))..        >>> 
+0001a950: 7464 203d 2065 6e76 2e72 616e 645f 7374  td = env.rand_st
+0001a960: 6570 2874 6429 0d0a 2020 2020 2020 2020  ep(td)..        
+0001a970: 3e3e 3e20 7072 696e 7428 7464 2e67 6574  >>> print(td.get
+0001a980: 2828 226e 6578 7422 2c20 226d 796b 6579  (("next", "mykey
+0001a990: 2229 2929 0d0a 2020 2020 2020 2020 7465  ")))..        te
+0001a9a0: 6e73 6f72 285b 5b31 2e2c 2031 2e2c 2031  nsor([[1., 1., 1
+0001a9b0: 2e5d 2c0d 0a20 2020 2020 2020 2020 2020  .],..           
+0001a9c0: 2020 2020 205b 312e 2c20 312e 2c20 312e       [1., 1., 1.
+0001a9d0: 5d5d 290d 0a0d 0a20 2020 2022 2222 0d0a  ]])....    """..
+0001a9e0: 0d0a 2020 2020 6465 6620 5f5f 696e 6974  ..    def __init
+0001a9f0: 5f5f 2873 656c 662c 2070 7269 6d65 7273  __(self, primers
+0001aa00: 3a20 6469 6374 203d 204e 6f6e 652c 2072  : dict = None, r
+0001aa10: 616e 646f 6d3d 4661 6c73 652c 2064 6566  andom=False, def
+0001aa20: 6175 6c74 5f76 616c 7565 3d30 2e30 2c20  ault_value=0.0, 
+0001aa30: 2a2a 6b77 6172 6773 293a 0d0a 2020 2020  **kwargs):..    
+0001aa40: 2020 2020 7365 6c66 2e64 6576 6963 6520      self.device 
+0001aa50: 3d20 6b77 6172 6773 2e70 6f70 2822 6465  = kwargs.pop("de
+0001aa60: 7669 6365 222c 204e 6f6e 6529 0d0a 2020  vice", None)..  
+0001aa70: 2020 2020 2020 6966 2070 7269 6d65 7273        if primers
+0001aa80: 2069 7320 6e6f 7420 4e6f 6e65 3a0d 0a20   is not None:.. 
+0001aa90: 2020 2020 2020 2020 2020 2069 6620 6b77             if kw
+0001aaa0: 6172 6773 3a0d 0a20 2020 2020 2020 2020  args:..         
+0001aab0: 2020 2020 2020 2072 6169 7365 2052 756e         raise Run
+0001aac0: 7469 6d65 4572 726f 7228 0d0a 2020 2020  timeError(..    
+0001aad0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001aae0: 2270 726f 7669 6469 6e67 2074 6865 2070  "providing the p
+0001aaf0: 7269 6d65 7273 2061 7320 6120 6469 6374  rimers as a dict
+0001ab00: 696f 6e61 7279 2069 7320 696e 636f 6d70  ionary is incomp
+0001ab10: 6174 6962 6c65 2077 6974 6820 6578 7472  atible with extr
+0001ab20: 6120 6b65 7973 2070 726f 7669 6465 6420  a keys provided 
+0001ab30: 220d 0a20 2020 2020 2020 2020 2020 2020  "..             
+0001ab40: 2020 2020 2020 2022 6173 206b 7761 7267         "as kwarg
+0001ab50: 732e 220d 0a20 2020 2020 2020 2020 2020  s."..           
+0001ab60: 2020 2020 2029 0d0a 2020 2020 2020 2020       )..        
+0001ab70: 2020 2020 6b77 6172 6773 203d 2070 7269      kwargs = pri
+0001ab80: 6d65 7273 0d0a 2020 2020 2020 2020 7365  mers..        se
+0001ab90: 6c66 2e70 7269 6d65 7273 203d 206b 7761  lf.primers = kwa
+0001aba0: 7267 730d 0a20 2020 2020 2020 2073 656c  rgs..        sel
+0001abb0: 662e 7261 6e64 6f6d 203d 2072 616e 646f  f.random = rando
+0001abc0: 6d0d 0a20 2020 2020 2020 2073 656c 662e  m..        self.
+0001abd0: 6465 6661 756c 745f 7661 6c75 6520 3d20  default_value = 
+0001abe0: 6465 6661 756c 745f 7661 6c75 650d 0a0d  default_value...
+0001abf0: 0a20 2020 2020 2020 2023 2073 616e 6974  .        # sanit
+0001ac00: 7920 6368 6563 6b0d 0a20 2020 2020 2020  y check..       
+0001ac10: 2066 6f72 2073 7065 6320 696e 2073 656c   for spec in sel
+0001ac20: 662e 7072 696d 6572 732e 7661 6c75 6573  f.primers.values
+0001ac30: 2829 3a0d 0a20 2020 2020 2020 2020 2020  ():..           
+0001ac40: 2069 6620 6e6f 7420 6973 696e 7374 616e   if not isinstan
+0001ac50: 6365 2873 7065 632c 2054 656e 736f 7253  ce(spec, TensorS
+0001ac60: 7065 6329 3a0d 0a20 2020 2020 2020 2020  pec):..         
+0001ac70: 2020 2020 2020 2072 6169 7365 2056 616c         raise Val
+0001ac80: 7565 4572 726f 7228 0d0a 2020 2020 2020  ueError(..      
+0001ac90: 2020 2020 2020 2020 2020 2020 2020 2254                "T
+0001aca0: 6865 2076 616c 7565 7320 6f66 2074 6865  he values of the
+0001acb0: 2070 7269 6d65 7273 206d 7573 7420 6265   primers must be
+0001acc0: 2061 2073 7562 7479 7065 206f 6620 7468   a subtype of th
+0001acd0: 6520 5465 6e73 6f72 5370 6563 2063 6c61  e TensorSpec cla
+0001ace0: 7373 2e20 220d 0a20 2020 2020 2020 2020  ss. "..         
+0001acf0: 2020 2020 2020 2020 2020 2066 2247 6f74             f"Got
+0001ad00: 207b 7479 7065 2873 7065 6329 7d20 696e   {type(spec)} in
+0001ad10: 7374 6561 642e 220d 0a20 2020 2020 2020  stead."..       
+0001ad20: 2020 2020 2020 2020 2029 0d0a 2020 2020           )..    
+0001ad30: 2020 2020 7375 7065 7228 292e 5f5f 696e      super().__in
+0001ad40: 6974 5f5f 285b 5d29 0d0a 0d0a 2020 2020  it__([])....    
+0001ad50: 4070 726f 7065 7274 790d 0a20 2020 2064  @property..    d
+0001ad60: 6566 2064 6576 6963 6528 7365 6c66 293a  ef device(self):
+0001ad70: 0d0a 2020 2020 2020 2020 6465 7669 6365  ..        device
+0001ad80: 203d 2073 656c 662e 5f64 6576 6963 650d   = self._device.
+0001ad90: 0a20 2020 2020 2020 2069 6620 6465 7669  .        if devi
+0001ada0: 6365 2069 7320 4e6f 6e65 2061 6e64 2073  ce is None and s
+0001adb0: 656c 662e 7061 7265 6e74 2069 7320 6e6f  elf.parent is no
+0001adc0: 7420 4e6f 6e65 3a0d 0a20 2020 2020 2020  t None:..       
+0001add0: 2020 2020 2064 6576 6963 6520 3d20 7365       device = se
+0001ade0: 6c66 2e70 6172 656e 742e 6465 7669 6365  lf.parent.device
+0001adf0: 0d0a 2020 2020 2020 2020 2020 2020 7365  ..            se
+0001ae00: 6c66 2e5f 6465 7669 6365 203d 2064 6576  lf._device = dev
+0001ae10: 6963 650d 0a20 2020 2020 2020 2072 6574  ice..        ret
+0001ae20: 7572 6e20 6465 7669 6365 0d0a 0d0a 2020  urn device....  
+0001ae30: 2020 4064 6576 6963 652e 7365 7474 6572    @device.setter
+0001ae40: 0d0a 2020 2020 6465 6620 6465 7669 6365  ..    def device
+0001ae50: 2873 656c 662c 2076 616c 7565 293a 0d0a  (self, value):..
+0001ae60: 2020 2020 2020 2020 6966 2076 616c 7565          if value
+0001ae70: 2069 7320 4e6f 6e65 3a0d 0a20 2020 2020   is None:..     
+0001ae80: 2020 2020 2020 2073 656c 662e 5f64 6576         self._dev
+0001ae90: 6963 6520 3d20 4e6f 6e65 0d0a 2020 2020  ice = None..    
+0001aea0: 2020 2020 2020 2020 7265 7475 726e 0d0a          return..
+0001aeb0: 2020 2020 2020 2020 7365 6c66 2e5f 6465          self._de
+0001aec0: 7669 6365 203d 2074 6f72 6368 2e64 6576  vice = torch.dev
+0001aed0: 6963 6528 7661 6c75 6529 0d0a 0d0a 2020  ice(value)....  
+0001aee0: 2020 6465 6620 746f 2873 656c 662c 2064    def to(self, d
+0001aef0: 7479 7065 5f6f 725f 6465 7669 6365 293a  type_or_device):
+0001af00: 0d0a 2020 2020 2020 2020 6966 206e 6f74  ..        if not
+0001af10: 2069 7369 6e73 7461 6e63 6528 6474 7970   isinstance(dtyp
+0001af20: 655f 6f72 5f64 6576 6963 652c 2074 6f72  e_or_device, tor
+0001af30: 6368 2e64 7479 7065 293a 0d0a 2020 2020  ch.dtype):..    
+0001af40: 2020 2020 2020 2020 7365 6c66 2e64 6576          self.dev
+0001af50: 6963 6520 3d20 6474 7970 655f 6f72 5f64  ice = dtype_or_d
+0001af60: 6576 6963 650d 0a20 2020 2020 2020 2072  evice..        r
+0001af70: 6574 7572 6e20 7375 7065 7228 292e 746f  eturn super().to
+0001af80: 2864 7479 7065 5f6f 725f 6465 7669 6365  (dtype_or_device
+0001af90: 290d 0a0d 0a20 2020 2064 6566 2074 7261  )....    def tra
+0001afa0: 6e73 666f 726d 5f6f 6273 6572 7661 7469  nsform_observati
+0001afb0: 6f6e 5f73 7065 6328 0d0a 2020 2020 2020  on_spec(..      
+0001afc0: 2020 7365 6c66 2c20 6f62 7365 7276 6174    self, observat
+0001afd0: 696f 6e5f 7370 6563 3a20 436f 6d70 6f73  ion_spec: Compos
+0001afe0: 6974 6553 7065 630d 0a20 2020 2029 202d  iteSpec..    ) -
+0001aff0: 3e20 436f 6d70 6f73 6974 6553 7065 633a  > CompositeSpec:
+0001b000: 0d0a 2020 2020 2020 2020 6966 206e 6f74  ..        if not
+0001b010: 2069 7369 6e73 7461 6e63 6528 6f62 7365   isinstance(obse
+0001b020: 7276 6174 696f 6e5f 7370 6563 2c20 436f  rvation_spec, Co
+0001b030: 6d70 6f73 6974 6553 7065 6329 3a0d 0a20  mpositeSpec):.. 
+0001b040: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+0001b050: 2056 616c 7565 4572 726f 7228 0d0a 2020   ValueError(..  
+0001b060: 2020 2020 2020 2020 2020 2020 2020 6622                f"
+0001b070: 6f62 7365 7276 6174 696f 6e5f 7370 6563  observation_spec
+0001b080: 2077 6173 2065 7870 6563 7465 6420 746f   was expected to
+0001b090: 2062 6520 6f66 2074 7970 6520 436f 6d70   be of type Comp
+0001b0a0: 6f73 6974 6553 7065 632e 2047 6f74 207b  ositeSpec. Got {
+0001b0b0: 7479 7065 286f 6273 6572 7661 7469 6f6e  type(observation
+0001b0c0: 5f73 7065 6329 7d20 696e 7374 6561 642e  _spec)} instead.
+0001b0d0: 220d 0a20 2020 2020 2020 2020 2020 2029  "..            )
+0001b0e0: 0d0a 2020 2020 2020 2020 666f 7220 6b65  ..        for ke
+0001b0f0: 792c 2073 7065 6320 696e 2073 656c 662e  y, spec in self.
+0001b100: 7072 696d 6572 732e 6974 656d 7328 293a  primers.items():
+0001b110: 0d0a 2020 2020 2020 2020 2020 2020 6966  ..            if
+0001b120: 2073 7065 632e 7368 6170 655b 3a20 6c65   spec.shape[: le
+0001b130: 6e28 6f62 7365 7276 6174 696f 6e5f 7370  n(observation_sp
+0001b140: 6563 2e73 6861 7065 295d 2021 3d20 6f62  ec.shape)] != ob
+0001b150: 7365 7276 6174 696f 6e5f 7370 6563 2e73  servation_spec.s
+0001b160: 6861 7065 3a0d 0a20 2020 2020 2020 2020  hape:..         
+0001b170: 2020 2020 2020 2072 6169 7365 2052 756e         raise Run
+0001b180: 7469 6d65 4572 726f 7228 0d0a 2020 2020  timeError(..    
+0001b190: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001b1a0: 6622 5468 6520 6c65 6164 696e 6720 7368  f"The leading sh
+0001b1b0: 6170 6520 6f66 2074 6865 2070 7269 6d65  ape of the prime
+0001b1c0: 7220 7370 6563 7320 287b 7365 6c66 2e5f  r specs ({self._
+0001b1d0: 5f63 6c61 7373 5f5f 7d29 2073 686f 756c  _class__}) shoul
+0001b1e0: 6420 6d61 7463 6820 7468 6520 6f6e 6520  d match the one 
+0001b1f0: 6f66 2074 6865 2070 6172 656e 7420 656e  of the parent en
+0001b200: 762e 2022 0d0a 2020 2020 2020 2020 2020  v. "..          
+0001b210: 2020 2020 2020 2020 2020 6622 476f 7420            f"Got 
+0001b220: 6f62 7365 7276 6174 696f 6e5f 7370 6563  observation_spec
+0001b230: 2e73 6861 7065 3d7b 6f62 7365 7276 6174  .shape={observat
+0001b240: 696f 6e5f 7370 6563 2e73 6861 7065 7d20  ion_spec.shape} 
+0001b250: 6275 7420 7468 6520 277b 6b65 797d 2720  but the '{key}' 
+0001b260: 656e 7472 7927 7320 7368 6170 6520 6973  entry's shape is
+0001b270: 207b 7370 6563 2e73 6861 7065 7d2e 220d   {spec.shape}.".
+0001b280: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001b290: 2029 0d0a 2020 2020 2020 2020 2020 2020   )..            
+0001b2a0: 7472 793a 0d0a 2020 2020 2020 2020 2020  try:..          
+0001b2b0: 2020 2020 2020 6465 7669 6365 203d 206f        device = o
+0001b2c0: 6273 6572 7661 7469 6f6e 5f73 7065 632e  bservation_spec.
+0001b2d0: 6465 7669 6365 0d0a 2020 2020 2020 2020  device..        
+0001b2e0: 2020 2020 6578 6365 7074 2052 756e 7469      except Runti
+0001b2f0: 6d65 4572 726f 723a 0d0a 2020 2020 2020  meError:..      
+0001b300: 2020 2020 2020 2020 2020 6465 7669 6365            device
+0001b310: 203d 2073 656c 662e 6465 7669 6365 0d0a   = self.device..
+0001b320: 2020 2020 2020 2020 2020 2020 6f62 7365              obse
+0001b330: 7276 6174 696f 6e5f 7370 6563 5b6b 6579  rvation_spec[key
+0001b340: 5d20 3d20 7370 6563 2e74 6f28 6465 7669  ] = spec.to(devi
+0001b350: 6365 290d 0a20 2020 2020 2020 2072 6574  ce)..        ret
+0001b360: 7572 6e20 6f62 7365 7276 6174 696f 6e5f  urn observation_
+0001b370: 7370 6563 0d0a 0d0a 2020 2020 4070 726f  spec....    @pro
+0001b380: 7065 7274 790d 0a20 2020 2064 6566 205f  perty..    def _
+0001b390: 6261 7463 685f 7369 7a65 2873 656c 6629  batch_size(self)
+0001b3a0: 3a0d 0a20 2020 2020 2020 2072 6574 7572  :..        retur
+0001b3b0: 6e20 7365 6c66 2e70 6172 656e 742e 6261  n self.parent.ba
+0001b3c0: 7463 685f 7369 7a65 0d0a 0d0a 2020 2020  tch_size....    
+0001b3d0: 6465 6620 666f 7277 6172 6428 7365 6c66  def forward(self
+0001b3e0: 2c20 7465 6e73 6f72 6469 6374 3a20 5465  , tensordict: Te
+0001b3f0: 6e73 6f72 4469 6374 4261 7365 2920 2d3e  nsorDictBase) ->
+0001b400: 2054 656e 736f 7244 6963 7442 6173 653a   TensorDictBase:
+0001b410: 0d0a 2020 2020 2020 2020 666f 7220 6b65  ..        for ke
+0001b420: 792c 2073 7065 6320 696e 2073 656c 662e  y, spec in self.
+0001b430: 7072 696d 6572 732e 6974 656d 7328 293a  primers.items():
+0001b440: 0d0a 2020 2020 2020 2020 2020 2020 6966  ..            if
+0001b450: 2073 7065 632e 7368 6170 655b 3a20 6c65   spec.shape[: le
+0001b460: 6e28 7465 6e73 6f72 6469 6374 2e73 6861  n(tensordict.sha
+0001b470: 7065 295d 2021 3d20 7465 6e73 6f72 6469  pe)] != tensordi
+0001b480: 6374 2e73 6861 7065 3a0d 0a20 2020 2020  ct.shape:..     
+0001b490: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+0001b4a0: 2052 756e 7469 6d65 4572 726f 7228 0d0a   RuntimeError(..
 0001b4b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b4c0: 2020 2020 7472 793a 0d0a 2020 2020 2020      try:..      
-0001b4d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b4e0: 2020 7465 6e73 6f72 6469 6374 5b6f 7574    tensordict[out
-0001b4f0: 5f6b 6579 5d20 3d20 7365 6c66 2e70 6172  _key] = self.par
-0001b500: 656e 742e 6f62 7365 7276 6174 696f 6e5f  ent.observation_
-0001b510: 7370 6563 5b0d 0a20 2020 2020 2020 2020  spec[..         
-0001b520: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b530: 2020 2069 6e5f 6b65 790d 0a20 2020 2020     in_key..     
-0001b540: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b550: 2020 205d 2e7a 6572 6f28 290d 0a20 2020     ].zero()..   
-0001b560: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b570: 2065 7863 6570 7420 4b65 7945 7272 6f72   except KeyError
-0001b580: 2061 7320 6572 723a 0d0a 2020 2020 2020   as err:..      
-0001b590: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b5a0: 2020 7261 6973 6520 4b65 7945 7272 6f72    raise KeyError
-0001b5b0: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
-0001b5c0: 2020 2020 2020 2020 2020 2020 2020 2066                 f
-0001b5d0: 2254 6865 206b 6579 207b 696e 5f6b 6579  "The key {in_key
-0001b5e0: 7d20 7761 7320 6e6f 7420 666f 756e 6420  } was not found 
-0001b5f0: 696e 2074 6865 2070 6172 656e 7420 220d  in the parent ".
-0001b600: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001b610: 2020 2020 2020 2020 2020 2020 2066 226f               f"o
-0001b620: 6273 6572 7661 7469 6f6e 5f73 7065 6320  bservation_spec 
-0001b630: 7769 7468 206b 6579 7320 220d 0a20 2020  with keys "..   
-0001b640: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b650: 2020 2020 2020 2020 2066 227b 6c69 7374           f"{list
-0001b660: 2873 656c 662e 7061 7265 6e74 2e6f 6273  (self.parent.obs
-0001b670: 6572 7661 7469 6f6e 5f73 7065 632e 6b65  ervation_spec.ke
-0001b680: 7973 2854 7275 6529 297d 2e20 220d 0a20  ys(True))}. ".. 
-0001b690: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b6a0: 2020 2020 2020 2029 2066 726f 6d20 6572         ) from er
-0001b6b0: 720d 0a0d 0a20 2020 2020 2020 2072 6574  r....        ret
-0001b6c0: 7572 6e20 7465 6e73 6f72 6469 6374 0d0a  urn tensordict..
-0001b6d0: 0d0a 2020 2020 6465 6620 5f73 7465 7028  ..    def _step(
-0001b6e0: 7365 6c66 2c20 7465 6e73 6f72 6469 6374  self, tensordict
-0001b6f0: 3a20 5465 6e73 6f72 4469 6374 4261 7365  : TensorDictBase
-0001b700: 2920 2d3e 2054 656e 736f 7244 6963 7442  ) -> TensorDictB
-0001b710: 6173 653a 0d0a 2020 2020 2020 2020 2222  ase:..        ""
-0001b720: 2255 7064 6174 6573 2074 6865 2065 7069  "Updates the epi
-0001b730: 736f 6465 2072 6577 6172 6473 2077 6974  sode rewards wit
-0001b740: 6820 7468 6520 7374 6570 2072 6577 6172  h the step rewar
-0001b750: 6473 2e22 2222 0d0a 2020 2020 2020 2020  ds."""..        
-0001b760: 2320 5570 6461 7465 2065 7069 736f 6465  # Update episode
-0001b770: 2072 6577 6172 6473 0d0a 2020 2020 2020   rewards..      
-0001b780: 2020 666f 7220 696e 5f6b 6579 2c20 6f75    for in_key, ou
-0001b790: 745f 6b65 7920 696e 207a 6970 2873 656c  t_key in zip(sel
-0001b7a0: 662e 696e 5f6b 6579 732c 2073 656c 662e  f.in_keys, self.
-0001b7b0: 6f75 745f 6b65 7973 293a 0d0a 2020 2020  out_keys):..    
-0001b7c0: 2020 2020 2020 2020 6966 2069 6e5f 6b65          if in_ke
-0001b7d0: 7920 696e 2074 656e 736f 7264 6963 742e  y in tensordict.
-0001b7e0: 6b65 7973 2869 7369 6e73 7461 6e63 6528  keys(isinstance(
-0001b7f0: 696e 5f6b 6579 2c20 7475 706c 6529 293a  in_key, tuple)):
-0001b800: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-0001b810: 2020 7265 7761 7264 203d 2074 656e 736f    reward = tenso
-0001b820: 7264 6963 742e 6765 7428 696e 5f6b 6579  rdict.get(in_key
-0001b830: 290d 0a20 2020 2020 2020 2020 2020 2020  )..             
-0001b840: 2020 2069 6620 6f75 745f 6b65 7920 6e6f     if out_key no
-0001b850: 7420 696e 2074 656e 736f 7264 6963 742e  t in tensordict.
-0001b860: 6b65 7973 2829 3a0d 0a20 2020 2020 2020  keys():..       
-0001b870: 2020 2020 2020 2020 2020 2020 2074 656e               ten
-0001b880: 736f 7264 6963 742e 7365 7428 2822 6e65  sordict.set(("ne
-0001b890: 7874 222c 206f 7574 5f6b 6579 292c 2074  xt", out_key), t
-0001b8a0: 6f72 6368 2e7a 6572 6f73 5f6c 696b 6528  orch.zeros_like(
-0001b8b0: 7265 7761 7264 2929 0d0a 2020 2020 2020  reward))..      
-0001b8c0: 2020 2020 2020 2020 2020 7465 6e73 6f72            tensor
-0001b8d0: 6469 6374 5b22 6e65 7874 222c 206f 7574  dict["next", out
-0001b8e0: 5f6b 6579 5d20 3d20 7465 6e73 6f72 6469  _key] = tensordi
-0001b8f0: 6374 5b6f 7574 5f6b 6579 5d20 2b20 7265  ct[out_key] + re
-0001b900: 7761 7264 0d0a 2020 2020 2020 2020 7265  ward..        re
-0001b910: 7475 726e 2074 656e 736f 7264 6963 740d  turn tensordict.
-0001b920: 0a0d 0a20 2020 2064 6566 2074 7261 6e73  ...    def trans
-0001b930: 666f 726d 5f6f 6273 6572 7661 7469 6f6e  form_observation
-0001b940: 5f73 7065 6328 7365 6c66 2c20 6f62 7365  _spec(self, obse
-0001b950: 7276 6174 696f 6e5f 7370 6563 3a20 5465  rvation_spec: Te
-0001b960: 6e73 6f72 5370 6563 2920 2d3e 2054 656e  nsorSpec) -> Ten
-0001b970: 736f 7253 7065 633a 0d0a 2020 2020 2020  sorSpec:..      
-0001b980: 2020 2222 2254 7261 6e73 666f 726d 7320    """Transforms 
-0001b990: 7468 6520 6f62 7365 7276 6174 696f 6e20  the observation 
-0001b9a0: 7370 6563 2c20 6164 6469 6e67 2074 6865  spec, adding the
-0001b9b0: 206e 6577 206b 6579 7320 6765 6e65 7261   new keys genera
-0001b9c0: 7465 6420 6279 2052 6577 6172 6453 756d  ted by RewardSum
-0001b9d0: 2e22 2222 0d0a 2020 2020 2020 2020 2320  ."""..        # 
-0001b9e0: 5265 7472 6965 7665 2070 6172 656e 7420  Retrieve parent 
-0001b9f0: 7265 7761 7264 2073 7065 630d 0a20 2020  reward spec..   
-0001ba00: 2020 2020 2072 6577 6172 645f 7370 6563       reward_spec
-0001ba10: 203d 2073 656c 662e 7061 7265 6e74 2e72   = self.parent.r
-0001ba20: 6577 6172 645f 7370 6563 0d0a 0d0a 2020  eward_spec....  
-0001ba30: 2020 2020 2020 6570 6973 6f64 655f 7370        episode_sp
-0001ba40: 6563 7320 3d20 7b7d 0d0a 2020 2020 2020  ecs = {}..      
-0001ba50: 2020 6966 2069 7369 6e73 7461 6e63 6528    if isinstance(
-0001ba60: 7265 7761 7264 5f73 7065 632c 2043 6f6d  reward_spec, Com
-0001ba70: 706f 7369 7465 5370 6563 293a 0d0a 2020  positeSpec):..  
-0001ba80: 2020 2020 2020 2020 2020 2320 4966 2072            # If r
-0001ba90: 6577 6172 645f 7370 6563 2069 7320 6120  eward_spec is a 
-0001baa0: 436f 6d70 6f73 6974 6553 7065 632c 2061  CompositeSpec, a
-0001bab0: 6c6c 2069 6e5f 6b65 7973 2073 686f 756c  ll in_keys shoul
-0001bac0: 6420 6265 206b 6579 7320 6f66 2072 6577  d be keys of rew
-0001bad0: 6172 645f 7370 6563 0d0a 2020 2020 2020  ard_spec..      
-0001bae0: 2020 2020 2020 6966 206e 6f74 2061 6c6c        if not all
-0001baf0: 286b 2069 6e20 7265 7761 7264 5f73 7065  (k in reward_spe
-0001bb00: 632e 6b65 7973 2854 7275 652c 2054 7275  c.keys(True, Tru
-0001bb10: 6529 2066 6f72 206b 2069 6e20 7365 6c66  e) for k in self
-0001bb20: 2e69 6e5f 6b65 7973 293a 0d0a 2020 2020  .in_keys):..    
-0001bb30: 2020 2020 2020 2020 2020 2020 7261 6973              rais
-0001bb40: 6520 4b65 7945 7272 6f72 2822 4e6f 7420  e KeyError("Not 
-0001bb50: 616c 6c20 696e 5f6b 6579 7320 6172 6520  all in_keys are 
-0001bb60: 7072 6573 656e 7420 696e 20c2 b472 6577  present in ..rew
-0001bb70: 6172 645f 7370 6563 c2b4 2229 0d0a 0d0a  ard_spec..")....
-0001bb80: 2020 2020 2020 2020 2020 2020 2320 4465              # De
-0001bb90: 6669 6e65 2065 7069 736f 6465 2073 7065  fine episode spe
-0001bba0: 6373 2066 6f72 2061 6c6c 206f 7574 5f6b  cs for all out_k
-0001bbb0: 6579 730d 0a20 2020 2020 2020 2020 2020  eys..           
-0001bbc0: 2066 6f72 206f 7574 5f6b 6579 2069 6e20   for out_key in 
-0001bbd0: 7365 6c66 2e6f 7574 5f6b 6579 733a 0d0a  self.out_keys:..
-0001bbe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001bbf0: 6570 6973 6f64 655f 7370 6563 203d 2055  episode_spec = U
-0001bc00: 6e62 6f75 6e64 6564 436f 6e74 696e 756f  nboundedContinuo
-0001bc10: 7573 5465 6e73 6f72 5370 6563 280d 0a20  usTensorSpec(.. 
-0001bc20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001bc30: 2020 2073 6861 7065 3d72 6577 6172 645f     shape=reward_
-0001bc40: 7370 6563 2e73 6861 7065 2c0d 0a20 2020  spec.shape,..   
-0001bc50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001bc60: 2064 6576 6963 653d 7265 7761 7264 5f73   device=reward_s
-0001bc70: 7065 632e 6465 7669 6365 2c0d 0a20 2020  pec.device,..   
-0001bc80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001bc90: 2064 7479 7065 3d72 6577 6172 645f 7370   dtype=reward_sp
-0001bca0: 6563 2e64 7479 7065 2c0d 0a20 2020 2020  ec.dtype,..     
-0001bcb0: 2020 2020 2020 2020 2020 2029 0d0a 2020             )..  
-0001bcc0: 2020 2020 2020 2020 2020 2020 2020 6570                ep
-0001bcd0: 6973 6f64 655f 7370 6563 732e 7570 6461  isode_specs.upda
-0001bce0: 7465 287b 6f75 745f 6b65 793a 2065 7069  te({out_key: epi
-0001bcf0: 736f 6465 5f73 7065 637d 290d 0a0d 0a20  sode_spec}).... 
-0001bd00: 2020 2020 2020 2065 6c73 653a 0d0a 2020         else:..  
-0001bd10: 2020 2020 2020 2020 2020 2320 4966 2072            # If r
-0001bd20: 6577 6172 645f 7370 6563 2069 7320 6e6f  eward_spec is no
-0001bd30: 7420 6120 436f 6d70 6f73 6974 6553 7065  t a CompositeSpe
-0001bd40: 632c 2074 6865 206f 6e6c 7920 696e 5f6b  c, the only in_k
-0001bd50: 6579 2073 686f 756c 6420 6265 20c2 b472  ey should be ..r
-0001bd60: 6577 6172 64c2 b40d 0a20 2020 2020 2020  eward....       
-0001bd70: 2020 2020 2069 6620 7365 7428 7365 6c66       if set(self
-0001bd80: 2e69 6e5f 6b65 7973 2920 213d 207b 2822  .in_keys) != {("
-0001bd90: 6e65 7874 222c 2022 7265 7761 7264 2229  next", "reward")
-0001bda0: 7d3a 0d0a 2020 2020 2020 2020 2020 2020  }:..            
-0001bdb0: 2020 2020 7261 6973 6520 4b65 7945 7272      raise KeyErr
-0001bdc0: 6f72 280d 0a20 2020 2020 2020 2020 2020  or(..           
-0001bdd0: 2020 2020 2020 2020 2022 7265 7761 7264           "reward
-0001bde0: 5f73 7065 6320 6973 206e 6f74 2061 2043  _spec is not a C
-0001bdf0: 6f6d 706f 7369 7465 5370 6563 2063 6c61  ompositeSpec cla
-0001be00: 7373 2c20 696e 5f6b 6579 7320 7368 6f75  ss, in_keys shou
-0001be10: 6c64 206f 6e6c 7920 696e 636c 7564 6520  ld only include 
-0001be20: c2b4 7265 7761 7264 c2b4 220d 0a20 2020  ..reward.."..   
-0001be30: 2020 2020 2020 2020 2020 2020 2029 0d0a               )..
-0001be40: 0d0a 2020 2020 2020 2020 2020 2020 2320  ..            # 
-0001be50: 4465 6669 6e65 2065 7069 736f 6465 2073  Define episode s
-0001be60: 7065 630d 0a20 2020 2020 2020 2020 2020  pec..           
-0001be70: 2065 7069 736f 6465 5f73 7065 6320 3d20   episode_spec = 
-0001be80: 556e 626f 756e 6465 6443 6f6e 7469 6e75  UnboundedContinu
-0001be90: 6f75 7354 656e 736f 7253 7065 6328 0d0a  ousTensorSpec(..
-0001bea0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001beb0: 6465 7669 6365 3d72 6577 6172 645f 7370  device=reward_sp
-0001bec0: 6563 2e64 6576 6963 652c 0d0a 2020 2020  ec.device,..    
-0001bed0: 2020 2020 2020 2020 2020 2020 6474 7970              dtyp
-0001bee0: 653d 7265 7761 7264 5f73 7065 632e 6474  e=reward_spec.dt
-0001bef0: 7970 652c 0d0a 2020 2020 2020 2020 2020  ype,..          
-0001bf00: 2020 2020 2020 7368 6170 653d 7265 7761        shape=rewa
-0001bf10: 7264 5f73 7065 632e 7368 6170 652c 0d0a  rd_spec.shape,..
-0001bf20: 2020 2020 2020 2020 2020 2020 290d 0a20              ).. 
-0001bf30: 2020 2020 2020 2020 2020 2065 7069 736f             episo
-0001bf40: 6465 5f73 7065 6373 2e75 7064 6174 6528  de_specs.update(
-0001bf50: 7b22 6570 6973 6f64 655f 7265 7761 7264  {"episode_reward
-0001bf60: 223a 2065 7069 736f 6465 5f73 7065 637d  ": episode_spec}
-0001bf70: 290d 0a0d 0a20 2020 2020 2020 2023 2055  )....        # U
-0001bf80: 7064 6174 6520 6f62 7365 7276 6174 696f  pdate observatio
-0001bf90: 6e5f 7370 6563 2077 6974 6820 6570 6973  n_spec with epis
-0001bfa0: 6f64 655f 7370 6563 730d 0a20 2020 2020  ode_specs..     
-0001bfb0: 2020 2069 6620 6e6f 7420 6973 696e 7374     if not isinst
-0001bfc0: 616e 6365 286f 6273 6572 7661 7469 6f6e  ance(observation
-0001bfd0: 5f73 7065 632c 2043 6f6d 706f 7369 7465  _spec, Composite
-0001bfe0: 5370 6563 293a 0d0a 2020 2020 2020 2020  Spec):..        
-0001bff0: 2020 2020 6f62 7365 7276 6174 696f 6e5f      observation_
-0001c000: 7370 6563 203d 2043 6f6d 706f 7369 7465  spec = Composite
-0001c010: 5370 6563 280d 0a20 2020 2020 2020 2020  Spec(..         
-0001c020: 2020 2020 2020 206f 6273 6572 7661 7469         observati
-0001c030: 6f6e 3d6f 6273 6572 7661 7469 6f6e 5f73  on=observation_s
-0001c040: 7065 632c 2073 6861 7065 3d73 656c 662e  pec, shape=self.
-0001c050: 7061 7265 6e74 2e62 6174 6368 5f73 697a  parent.batch_siz
-0001c060: 650d 0a20 2020 2020 2020 2020 2020 2029  e..            )
-0001c070: 0d0a 2020 2020 2020 2020 6f62 7365 7276  ..        observ
-0001c080: 6174 696f 6e5f 7370 6563 2e75 7064 6174  ation_spec.updat
-0001c090: 6528 6570 6973 6f64 655f 7370 6563 7329  e(episode_specs)
-0001c0a0: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
-0001c0b0: 206f 6273 6572 7661 7469 6f6e 5f73 7065   observation_spe
-0001c0c0: 630d 0a0d 0a20 2020 2064 6566 2066 6f72  c....    def for
-0001c0d0: 7761 7264 2873 656c 662c 2074 656e 736f  ward(self, tenso
-0001c0e0: 7264 6963 743a 2054 656e 736f 7244 6963  rdict: TensorDic
-0001c0f0: 7442 6173 6529 202d 3e20 5465 6e73 6f72  tBase) -> Tensor
-0001c100: 4469 6374 4261 7365 3a0d 0a20 2020 2020  DictBase:..     
-0001c110: 2020 2072 6169 7365 204e 6f74 496d 706c     raise NotImpl
-0001c120: 656d 656e 7465 6445 7272 6f72 280d 0a20  ementedError(.. 
-0001c130: 2020 2020 2020 2020 2020 2046 4f52 5741             FORWA
-0001c140: 5244 5f4e 4f54 5f49 4d50 4c45 4d45 4e54  RD_NOT_IMPLEMENT
-0001c150: 4544 2e66 6f72 6d61 7428 7365 6c66 2e5f  ED.format(self._
-0001c160: 5f63 6c61 7373 5f5f 2e5f 5f6e 616d 655f  _class__.__name_
-0001c170: 5f29 0d0a 2020 2020 2020 2020 290d 0a0d  _)..        )...
-0001c180: 0a0d 0a63 6c61 7373 2053 7465 7043 6f75  ...class StepCou
-0001c190: 6e74 6572 2854 7261 6e73 666f 726d 293a  nter(Transform):
-0001c1a0: 0d0a 2020 2020 2222 2243 6f75 6e74 7320  ..    """Counts 
-0001c1b0: 7468 6520 7374 6570 7320 6672 6f6d 2061  the steps from a
-0001c1c0: 2072 6573 6574 2061 6e64 2073 6574 7320   reset and sets 
-0001c1d0: 7468 6520 646f 6e65 2073 7461 7465 2074  the done state t
-0001c1e0: 6f20 5472 7565 2061 6674 6572 2061 2063  o True after a c
-0001c1f0: 6572 7461 696e 206e 756d 6265 7220 6f66  ertain number of
-0001c200: 2073 7465 7073 2e0d 0a0d 0a20 2020 2041   steps.....    A
-0001c210: 7267 733a 0d0a 2020 2020 2020 2020 6d61  rgs:..        ma
-0001c220: 785f 7374 6570 7320 2869 6e74 2c20 6f70  x_steps (int, op
-0001c230: 7469 6f6e 616c 293a 2061 2070 6f73 6974  tional): a posit
-0001c240: 6976 6520 696e 7465 6765 7220 7468 6174  ive integer that
-0001c250: 2069 6e64 6963 6174 6573 2074 6865 0d0a   indicates the..
-0001c260: 2020 2020 2020 2020 2020 2020 6d61 7869              maxi
-0001c270: 6d75 6d20 6e75 6d62 6572 206f 6620 7374  mum number of st
-0001c280: 6570 7320 746f 2074 616b 6520 6265 666f  eps to take befo
-0001c290: 7265 2073 6574 7469 6e67 2074 6865 2060  re setting the `
-0001c2a0: 6074 7275 6e63 6174 6564 5f6b 6579 6060  `truncated_key``
-0001c2b0: 0d0a 2020 2020 2020 2020 2020 2020 656e  ..            en
-0001c2c0: 7472 7920 746f 2060 6054 7275 6560 602e  try to ``True``.
-0001c2d0: 0d0a 2020 2020 2020 2020 2020 2020 486f  ..            Ho
-0001c2e0: 7765 7665 722c 2074 6865 2073 7465 7020  wever, the step 
-0001c2f0: 636f 756e 7420 7769 6c6c 2073 7469 6c6c  count will still
-0001c300: 2062 650d 0a20 2020 2020 2020 2020 2020   be..           
-0001c310: 2069 6e63 7265 6d65 6e74 6564 206f 6e20   incremented on 
-0001c320: 6561 6368 2063 616c 6c20 746f 2073 7465  each call to ste
-0001c330: 7028 2920 696e 746f 2074 6865 2060 7374  p() into the `st
-0001c340: 6570 5f63 6f75 6e74 6020 6174 7472 6962  ep_count` attrib
-0001c350: 7574 652e 0d0a 2020 2020 2020 2020 7472  ute...        tr
-0001c360: 756e 6361 7465 645f 6b65 7920 2873 7472  uncated_key (str
-0001c370: 2c20 6f70 7469 6f6e 616c 293a 2074 6865  , optional): the
-0001c380: 206b 6579 2077 6865 7265 2074 6865 2074   key where the t
-0001c390: 7275 6e63 6174 6564 206b 6579 2073 686f  runcated key sho
-0001c3a0: 756c 640d 0a20 2020 2020 2020 2020 2020  uld..           
-0001c3b0: 2062 6520 7772 6974 7465 6e2e 2044 6566   be written. Def
-0001c3c0: 6175 6c74 7320 746f 2060 6022 7472 756e  aults to ``"trun
-0001c3d0: 6361 7465 6422 6060 2c20 7768 6963 6820  cated"``, which 
-0001c3e0: 6973 2072 6563 6f67 6e69 7365 6420 6279  is recognised by
-0001c3f0: 0d0a 2020 2020 2020 2020 2020 2020 6461  ..            da
-0001c400: 7461 2063 6f6c 6c65 6374 6f72 7320 6173  ta collectors as
-0001c410: 2061 2072 6573 6574 2073 6967 6e61 6c2e   a reset signal.
-0001c420: 0d0a 2020 2020 2222 220d 0a0d 0a20 2020  ..    """....   
-0001c430: 2069 6e76 6572 7469 626c 6520 3d20 4661   invertible = Fa
-0001c440: 6c73 650d 0a0d 0a20 2020 2064 6566 205f  lse....    def _
-0001c450: 5f69 6e69 745f 5f28 0d0a 2020 2020 2020  _init__(..      
-0001c460: 2020 7365 6c66 2c20 6d61 785f 7374 6570    self, max_step
-0001c470: 733a 204f 7074 696f 6e61 6c5b 696e 745d  s: Optional[int]
-0001c480: 203d 204e 6f6e 652c 2074 7275 6e63 6174   = None, truncat
-0001c490: 6564 5f6b 6579 3a20 7374 7220 3d20 2274  ed_key: str = "t
-0001c4a0: 7275 6e63 6174 6564 220d 0a20 2020 2029  runcated"..    )
-0001c4b0: 3a0d 0a20 2020 2020 2020 2069 6620 6d61  :..        if ma
-0001c4c0: 785f 7374 6570 7320 6973 206e 6f74 204e  x_steps is not N
-0001c4d0: 6f6e 6520 616e 6420 6d61 785f 7374 6570  one and max_step
-0001c4e0: 7320 3c20 313a 0d0a 2020 2020 2020 2020  s < 1:..        
-0001c4f0: 2020 2020 7261 6973 6520 5661 6c75 6545      raise ValueE
-0001c500: 7272 6f72 2822 6d61 785f 7374 6570 7320  rror("max_steps 
-0001c510: 7368 6f75 6c64 2068 6176 6520 6120 7661  should have a va
-0001c520: 6c75 6520 6772 6561 7465 7220 6f72 2065  lue greater or e
-0001c530: 7175 616c 2074 6f20 6f6e 652e 2229 0d0a  qual to one.")..
-0001c540: 2020 2020 2020 2020 7365 6c66 2e6d 6178          self.max
-0001c550: 5f73 7465 7073 203d 206d 6178 5f73 7465  _steps = max_ste
-0001c560: 7073 0d0a 2020 2020 2020 2020 7365 6c66  ps..        self
-0001c570: 2e74 7275 6e63 6174 6564 5f6b 6579 203d  .truncated_key =
-0001c580: 2074 7275 6e63 6174 6564 5f6b 6579 0d0a   truncated_key..
-0001c590: 2020 2020 2020 2020 7375 7065 7228 292e          super().
-0001c5a0: 5f5f 696e 6974 5f5f 285b 5d29 0d0a 0d0a  __init__([])....
-0001c5b0: 2020 2020 6465 6620 7265 7365 7428 7365      def reset(se
-0001c5c0: 6c66 2c20 7465 6e73 6f72 6469 6374 3a20  lf, tensordict: 
-0001c5d0: 5465 6e73 6f72 4469 6374 4261 7365 2920  TensorDictBase) 
-0001c5e0: 2d3e 2054 656e 736f 7244 6963 7442 6173  -> TensorDictBas
-0001c5f0: 653a 0d0a 2020 2020 2020 2020 646f 6e65  e:..        done
-0001c600: 203d 2074 656e 736f 7264 6963 742e 6765   = tensordict.ge
-0001c610: 7428 2264 6f6e 6522 2c20 4e6f 6e65 290d  t("done", None).
-0001c620: 0a20 2020 2020 2020 2069 6620 646f 6e65  .        if done
-0001c630: 2069 7320 4e6f 6e65 3a0d 0a20 2020 2020   is None:..     
-0001c640: 2020 2020 2020 2064 6f6e 6520 3d20 746f         done = to
-0001c650: 7263 682e 6f6e 6573 280d 0a20 2020 2020  rch.ones(..     
-0001c660: 2020 2020 2020 2020 2020 2073 656c 662e             self.
-0001c670: 7061 7265 6e74 2e64 6f6e 655f 7370 6563  parent.done_spec
-0001c680: 2e73 6861 7065 2c0d 0a20 2020 2020 2020  .shape,..       
-0001c690: 2020 2020 2020 2020 2064 7479 7065 3d73           dtype=s
-0001c6a0: 656c 662e 7061 7265 6e74 2e64 6f6e 655f  elf.parent.done_
-0001c6b0: 7370 6563 2e64 7479 7065 2c0d 0a20 2020  spec.dtype,..   
-0001c6c0: 2020 2020 2020 2020 2020 2020 2064 6576               dev
-0001c6d0: 6963 653d 7365 6c66 2e70 6172 656e 742e  ice=self.parent.
-0001c6e0: 646f 6e65 5f73 7065 632e 6465 7669 6365  done_spec.device
-0001c6f0: 2c0d 0a20 2020 2020 2020 2020 2020 2029  ,..            )
-0001c700: 0d0a 2020 2020 2020 2020 5f72 6573 6574  ..        _reset
-0001c710: 203d 2074 656e 736f 7264 6963 742e 6765   = tensordict.ge
-0001c720: 7428 0d0a 2020 2020 2020 2020 2020 2020  t(..            
-0001c730: 225f 7265 7365 7422 2c0d 0a20 2020 2020  "_reset",..     
-0001c740: 2020 2020 2020 2023 2054 4f44 4f3a 2064         # TODO: d
-0001c750: 6563 6964 6520 6966 2075 7369 6e67 2064  ecide if using d
-0001c760: 6f6e 6520 6865 7265 2c20 6f72 2075 7369  one here, or usi
-0001c770: 6e67 2061 2064 6566 6175 6c74 2060 5472  ng a default `Tr
-0001c780: 7565 6020 7465 6e73 6f72 0d0a 2020 2020  ue` tensor..    
-0001c790: 2020 2020 2020 2020 6465 6661 756c 743d          default=
-0001c7a0: 746f 7263 682e 6f6e 6573 5f6c 696b 6528  torch.ones_like(
-0001c7b0: 646f 6e65 2e73 7175 6565 7a65 282d 3129  done.squeeze(-1)
-0001c7c0: 292c 0d0a 2020 2020 2020 2020 290d 0a20  ),..        ).. 
-0001c7d0: 2020 2020 2020 2073 7465 705f 636f 756e         step_coun
-0001c7e0: 7420 3d20 7465 6e73 6f72 6469 6374 2e67  t = tensordict.g
-0001c7f0: 6574 280d 0a20 2020 2020 2020 2020 2020  et(..           
-0001c800: 2022 7374 6570 5f63 6f75 6e74 222c 0d0a   "step_count",..
-0001c810: 2020 2020 2020 2020 2020 2020 4e6f 6e65              None
-0001c820: 2c0d 0a20 2020 2020 2020 2029 0d0a 2020  ,..        )..  
-0001c830: 2020 2020 2020 6966 2073 7465 705f 636f        if step_co
-0001c840: 756e 7420 6973 204e 6f6e 653a 0d0a 2020  unt is None:..  
-0001c850: 2020 2020 2020 2020 2020 7374 6570 5f63            step_c
-0001c860: 6f75 6e74 203d 2074 6f72 6368 2e7a 6572  ount = torch.zer
-0001c870: 6f73 280d 0a20 2020 2020 2020 2020 2020  os(..           
-0001c880: 2020 2020 2074 656e 736f 7264 6963 742e       tensordict.
-0001c890: 6261 7463 685f 7369 7a65 2c0d 0a20 2020  batch_size,..   
-0001c8a0: 2020 2020 2020 2020 2020 2020 2064 7479               dty
-0001c8b0: 7065 3d74 6f72 6368 2e69 6e74 3634 2c0d  pe=torch.int64,.
-0001c8c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001c8d0: 2064 6576 6963 653d 7465 6e73 6f72 6469   device=tensordi
-0001c8e0: 6374 2e64 6576 6963 652c 0d0a 2020 2020  ct.device,..    
-0001c8f0: 2020 2020 2020 2020 290d 0a20 2020 2020          )..     
-0001c900: 2020 2073 7465 705f 636f 756e 745b 5f72     step_count[_r
-0001c910: 6573 6574 5d20 3d20 300d 0a20 2020 2020  eset] = 0..     
-0001c920: 2020 2074 656e 736f 7264 6963 742e 7365     tensordict.se
-0001c930: 7428 0d0a 2020 2020 2020 2020 2020 2020  t(..            
-0001c940: 2273 7465 705f 636f 756e 7422 2c0d 0a20  "step_count",.. 
-0001c950: 2020 2020 2020 2020 2020 2073 7465 705f             step_
-0001c960: 636f 756e 742c 0d0a 2020 2020 2020 2020  count,..        
-0001c970: 290d 0a20 2020 2020 2020 2069 6620 7365  )..        if se
-0001c980: 6c66 2e6d 6178 5f73 7465 7073 2069 7320  lf.max_steps is 
-0001c990: 6e6f 7420 4e6f 6e65 3a0d 0a20 2020 2020  not None:..     
-0001c9a0: 2020 2020 2020 2074 7275 6e63 6174 6564         truncated
-0001c9b0: 203d 2028 7374 6570 5f63 6f75 6e74 203e   = (step_count >
-0001c9c0: 3d20 7365 6c66 2e6d 6178 5f73 7465 7073  = self.max_steps
-0001c9d0: 292e 756e 7371 7565 657a 6528 2d31 290d  ).unsqueeze(-1).
-0001c9e0: 0a20 2020 2020 2020 2020 2020 2074 656e  .            ten
-0001c9f0: 736f 7264 6963 742e 7365 7428 7365 6c66  sordict.set(self
-0001ca00: 2e74 7275 6e63 6174 6564 5f6b 6579 2c20  .truncated_key, 
-0001ca10: 7472 756e 6361 7465 6429 0d0a 2020 2020  truncated)..    
-0001ca20: 2020 2020 7265 7475 726e 2074 656e 736f      return tenso
-0001ca30: 7264 6963 740d 0a0d 0a20 2020 2064 6566  rdict....    def
-0001ca40: 205f 7374 6570 2873 656c 662c 2074 656e   _step(self, ten
-0001ca50: 736f 7264 6963 743a 2054 656e 736f 7244  sordict: TensorD
-0001ca60: 6963 7442 6173 6529 202d 3e20 5465 6e73  ictBase) -> Tens
-0001ca70: 6f72 4469 6374 4261 7365 3a0d 0a20 2020  orDictBase:..   
-0001ca80: 2020 2020 2074 656e 736f 7264 6963 7420       tensordict 
-0001ca90: 3d20 7465 6e73 6f72 6469 6374 2e63 6c6f  = tensordict.clo
-0001caa0: 6e65 2846 616c 7365 290d 0a20 2020 2020  ne(False)..     
-0001cab0: 2020 2073 7465 705f 636f 756e 7420 3d20     step_count = 
-0001cac0: 7465 6e73 6f72 6469 6374 2e67 6574 280d  tensordict.get(.
-0001cad0: 0a20 2020 2020 2020 2020 2020 2022 7374  .            "st
-0001cae0: 6570 5f63 6f75 6e74 222c 0d0a 2020 2020  ep_count",..    
-0001caf0: 2020 2020 290d 0a20 2020 2020 2020 206e      )..        n
-0001cb00: 6578 745f 7374 6570 5f63 6f75 6e74 203d  ext_step_count =
-0001cb10: 2073 7465 705f 636f 756e 7420 2b20 310d   step_count + 1.
-0001cb20: 0a20 2020 2020 2020 2074 656e 736f 7264  .        tensord
-0001cb30: 6963 742e 7365 7428 2822 6e65 7874 222c  ict.set(("next",
-0001cb40: 2022 7374 6570 5f63 6f75 6e74 2229 2c20   "step_count"), 
-0001cb50: 6e65 7874 5f73 7465 705f 636f 756e 7429  next_step_count)
-0001cb60: 0d0a 2020 2020 2020 2020 6966 2073 656c  ..        if sel
-0001cb70: 662e 6d61 785f 7374 6570 7320 6973 206e  f.max_steps is n
-0001cb80: 6f74 204e 6f6e 653a 0d0a 2020 2020 2020  ot None:..      
-0001cb90: 2020 2020 2020 7472 756e 6361 7465 6420        truncated 
-0001cba0: 3d20 286e 6578 745f 7374 6570 5f63 6f75  = (next_step_cou
-0001cbb0: 6e74 203e 3d20 7365 6c66 2e6d 6178 5f73  nt >= self.max_s
-0001cbc0: 7465 7073 292e 756e 7371 7565 657a 6528  teps).unsqueeze(
-0001cbd0: 2d31 290d 0a20 2020 2020 2020 2020 2020  -1)..           
-0001cbe0: 2074 656e 736f 7264 6963 742e 7365 7428   tensordict.set(
-0001cbf0: 2822 6e65 7874 222c 2073 656c 662e 7472  ("next", self.tr
-0001cc00: 756e 6361 7465 645f 6b65 7929 2c20 7472  uncated_key), tr
-0001cc10: 756e 6361 7465 6429 0d0a 2020 2020 2020  uncated)..      
-0001cc20: 2020 7265 7475 726e 2074 656e 736f 7264    return tensord
-0001cc30: 6963 740d 0a0d 0a20 2020 2064 6566 2074  ict....    def t
-0001cc40: 7261 6e73 666f 726d 5f6f 6273 6572 7661  ransform_observa
-0001cc50: 7469 6f6e 5f73 7065 6328 0d0a 2020 2020  tion_spec(..    
-0001cc60: 2020 2020 7365 6c66 2c20 6f62 7365 7276      self, observ
-0001cc70: 6174 696f 6e5f 7370 6563 3a20 436f 6d70  ation_spec: Comp
-0001cc80: 6f73 6974 6553 7065 630d 0a20 2020 2029  ositeSpec..    )
-0001cc90: 202d 3e20 436f 6d70 6f73 6974 6553 7065   -> CompositeSpe
-0001cca0: 633a 0d0a 2020 2020 2020 2020 6966 206e  c:..        if n
-0001ccb0: 6f74 2069 7369 6e73 7461 6e63 6528 6f62  ot isinstance(ob
-0001ccc0: 7365 7276 6174 696f 6e5f 7370 6563 2c20  servation_spec, 
-0001ccd0: 436f 6d70 6f73 6974 6553 7065 6329 3a0d  CompositeSpec):.
-0001cce0: 0a20 2020 2020 2020 2020 2020 2072 6169  .            rai
-0001ccf0: 7365 2056 616c 7565 4572 726f 7228 0d0a  se ValueError(..
-0001cd00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001cd10: 6622 6f62 7365 7276 6174 696f 6e5f 7370  f"observation_sp
-0001cd20: 6563 2077 6173 2065 7870 6563 7465 6420  ec was expected 
-0001cd30: 746f 2062 6520 6f66 2074 7970 6520 436f  to be of type Co
-0001cd40: 6d70 6f73 6974 6553 7065 632e 2047 6f74  mpositeSpec. Got
-0001cd50: 207b 7479 7065 286f 6273 6572 7661 7469   {type(observati
-0001cd60: 6f6e 5f73 7065 6329 7d20 696e 7374 6561  on_spec)} instea
-0001cd70: 642e 220d 0a20 2020 2020 2020 2020 2020  d."..           
-0001cd80: 2029 0d0a 2020 2020 2020 2020 6f62 7365   )..        obse
-0001cd90: 7276 6174 696f 6e5f 7370 6563 5b22 7374  rvation_spec["st
-0001cda0: 6570 5f63 6f75 6e74 225d 203d 2055 6e62  ep_count"] = Unb
-0001cdb0: 6f75 6e64 6564 4469 7363 7265 7465 5465  oundedDiscreteTe
-0001cdc0: 6e73 6f72 5370 6563 280d 0a20 2020 2020  nsorSpec(..     
-0001cdd0: 2020 2020 2020 2073 6861 7065 3d6f 6273         shape=obs
-0001cde0: 6572 7661 7469 6f6e 5f73 7065 632e 7368  ervation_spec.sh
-0001cdf0: 6170 652c 0d0a 2020 2020 2020 2020 2020  ape,..          
-0001ce00: 2020 6474 7970 653d 746f 7263 682e 696e    dtype=torch.in
-0001ce10: 7436 342c 0d0a 2020 2020 2020 2020 2020  t64,..          
-0001ce20: 2020 6465 7669 6365 3d6f 6273 6572 7661    device=observa
-0001ce30: 7469 6f6e 5f73 7065 632e 6465 7669 6365  tion_spec.device
-0001ce40: 2c0d 0a20 2020 2020 2020 2029 0d0a 2020  ,..        )..  
-0001ce50: 2020 2020 2020 6f62 7365 7276 6174 696f        observatio
-0001ce60: 6e5f 7370 6563 5b22 7374 6570 5f63 6f75  n_spec["step_cou
-0001ce70: 6e74 225d 2e73 7061 6365 2e6d 696e 696d  nt"].space.minim
-0001ce80: 756d 203d 2028 0d0a 2020 2020 2020 2020  um = (..        
-0001ce90: 2020 2020 6f62 7365 7276 6174 696f 6e5f      observation_
-0001cea0: 7370 6563 5b22 7374 6570 5f63 6f75 6e74  spec["step_count
-0001ceb0: 225d 2e73 7061 6365 2e6d 696e 696d 756d  "].space.minimum
-0001cec0: 202a 2030 0d0a 2020 2020 2020 2020 290d   * 0..        ).
-0001ced0: 0a20 2020 2020 2020 2069 6620 7365 6c66  .        if self
-0001cee0: 2e6d 6178 5f73 7465 7073 2069 7320 6e6f  .max_steps is no
-0001cef0: 7420 4e6f 6e65 2061 6e64 2073 656c 662e  t None and self.
-0001cf00: 7472 756e 6361 7465 645f 6b65 7920 213d  truncated_key !=
-0001cf10: 2022 646f 6e65 223a 0d0a 2020 2020 2020   "done":..      
-0001cf20: 2020 2020 2020 6f62 7365 7276 6174 696f        observatio
-0001cf30: 6e5f 7370 6563 5b73 656c 662e 7472 756e  n_spec[self.trun
-0001cf40: 6361 7465 645f 6b65 795d 203d 2073 656c  cated_key] = sel
-0001cf50: 662e 7061 7265 6e74 2e64 6f6e 655f 7370  f.parent.done_sp
-0001cf60: 6563 2e63 6c6f 6e65 2829 0d0a 2020 2020  ec.clone()..    
-0001cf70: 2020 2020 7265 7475 726e 206f 6273 6572      return obser
-0001cf80: 7661 7469 6f6e 5f73 7065 630d 0a0d 0a20  vation_spec.... 
-0001cf90: 2020 2064 6566 2074 7261 6e73 666f 726d     def transform
-0001cfa0: 5f69 6e70 7574 5f73 7065 6328 7365 6c66  _input_spec(self
-0001cfb0: 2c20 696e 7075 745f 7370 6563 3a20 436f  , input_spec: Co
-0001cfc0: 6d70 6f73 6974 6553 7065 6329 202d 3e20  mpositeSpec) -> 
-0001cfd0: 436f 6d70 6f73 6974 6553 7065 633a 0d0a  CompositeSpec:..
-0001cfe0: 2020 2020 2020 2020 6966 206e 6f74 2069          if not i
-0001cff0: 7369 6e73 7461 6e63 6528 696e 7075 745f  sinstance(input_
-0001d000: 7370 6563 2c20 436f 6d70 6f73 6974 6553  spec, CompositeS
-0001d010: 7065 6329 3a0d 0a20 2020 2020 2020 2020  pec):..         
-0001d020: 2020 2072 6169 7365 2056 616c 7565 4572     raise ValueEr
-0001d030: 726f 7228 0d0a 2020 2020 2020 2020 2020  ror(..          
-0001d040: 2020 2020 2020 6622 696e 7075 745f 7370        f"input_sp
-0001d050: 6563 2077 6173 2065 7870 6563 7465 6420  ec was expected 
-0001d060: 746f 2062 6520 6f66 2074 7970 6520 436f  to be of type Co
-0001d070: 6d70 6f73 6974 6553 7065 632e 2047 6f74  mpositeSpec. Got
-0001d080: 207b 7479 7065 2869 6e70 7574 5f73 7065   {type(input_spe
-0001d090: 6329 7d20 696e 7374 6561 642e 220d 0a20  c)} instead.".. 
-0001d0a0: 2020 2020 2020 2020 2020 2029 0d0a 2020             )..  
-0001d0b0: 2020 2020 2020 696e 7075 745f 7370 6563        input_spec
-0001d0c0: 5b22 7374 6570 5f63 6f75 6e74 225d 203d  ["step_count"] =
-0001d0d0: 2055 6e62 6f75 6e64 6564 4469 7363 7265   UnboundedDiscre
-0001d0e0: 7465 5465 6e73 6f72 5370 6563 280d 0a20  teTensorSpec(.. 
-0001d0f0: 2020 2020 2020 2020 2020 2073 6861 7065             shape
-0001d100: 3d69 6e70 7574 5f73 7065 632e 7368 6170  =input_spec.shap
-0001d110: 652c 0d0a 2020 2020 2020 2020 2020 2020  e,..            
-0001d120: 6474 7970 653d 746f 7263 682e 696e 7436  dtype=torch.int6
-0001d130: 342c 0d0a 2020 2020 2020 2020 2020 2020  4,..            
-0001d140: 6465 7669 6365 3d69 6e70 7574 5f73 7065  device=input_spe
-0001d150: 632e 6465 7669 6365 2c0d 0a20 2020 2020  c.device,..     
-0001d160: 2020 2029 0d0a 2020 2020 2020 2020 696e     )..        in
-0001d170: 7075 745f 7370 6563 5b22 7374 6570 5f63  put_spec["step_c
-0001d180: 6f75 6e74 225d 2e73 7061 6365 2e6d 696e  ount"].space.min
-0001d190: 696d 756d 203d 2028 0d0a 2020 2020 2020  imum = (..      
-0001d1a0: 2020 2020 2020 696e 7075 745f 7370 6563        input_spec
-0001d1b0: 5b22 7374 6570 5f63 6f75 6e74 225d 2e73  ["step_count"].s
-0001d1c0: 7061 6365 2e6d 696e 696d 756d 202a 2030  pace.minimum * 0
-0001d1d0: 0d0a 2020 2020 2020 2020 290d 0a20 2020  ..        )..   
-0001d1e0: 2020 2020 2072 6574 7572 6e20 696e 7075       return inpu
-0001d1f0: 745f 7370 6563 0d0a 0d0a 2020 2020 6465  t_spec....    de
-0001d200: 6620 666f 7277 6172 6428 7365 6c66 2c20  f forward(self, 
-0001d210: 7465 6e73 6f72 6469 6374 3a20 5465 6e73  tensordict: Tens
-0001d220: 6f72 4469 6374 4261 7365 2920 2d3e 2054  orDictBase) -> T
-0001d230: 656e 736f 7244 6963 7442 6173 653a 0d0a  ensorDictBase:..
-0001d240: 2020 2020 2020 2020 7261 6973 6520 4e6f          raise No
-0001d250: 7449 6d70 6c65 6d65 6e74 6564 4572 726f  tImplementedErro
-0001d260: 7228 0d0a 2020 2020 2020 2020 2020 2020  r(..            
-0001d270: 2253 7465 7043 6f75 6e74 6572 2063 616e  "StepCounter can
-0001d280: 6e6f 7420 6265 2063 616c 6c65 6420 696e  not be called in
-0001d290: 6465 7065 6e64 656e 746c 792c 206f 6e6c  dependently, onl
-0001d2a0: 7920 6974 7320 7374 6570 2061 6e64 2072  y its step and r
-0001d2b0: 6573 6574 206d 6574 686f 6473 2022 0d0a  eset methods "..
-0001d2c0: 2020 2020 2020 2020 2020 2020 2261 7265              "are
-0001d2d0: 2066 756e 6374 696f 6e61 6c2e 2054 6865   functional. The
-0001d2e0: 2072 6561 736f 6e20 666f 7220 7468 6973   reason for this
-0001d2f0: 2069 7320 7468 6174 2069 7420 6973 2068   is that it is h
-0001d300: 6172 6420 746f 2063 6f6e 7369 6465 7220  ard to consider 
-0001d310: 7573 696e 6720 220d 0a20 2020 2020 2020  using "..       
-0001d320: 2020 2020 2022 5374 6570 436f 756e 7465       "StepCounte
-0001d330: 7220 7769 7468 206e 6f6e 2d73 6571 7565  r with non-seque
-0001d340: 6e74 6961 6c20 6461 7461 2c20 7375 6368  ntial data, such
-0001d350: 2061 7320 7468 6f73 6520 636f 6c6c 6563   as those collec
-0001d360: 7465 6420 6279 2061 2072 6570 6c61 7920  ted by a replay 
-0001d370: 6275 6666 6572 2022 0d0a 2020 2020 2020  buffer "..      
-0001d380: 2020 2020 2020 226f 7220 6120 6461 7461        "or a data
-0001d390: 7365 742e 2049 6620 796f 7520 6e65 6564  set. If you need
-0001d3a0: 2053 7465 7043 6f75 6e74 6572 2074 6f20   StepCounter to 
-0001d3b0: 776f 726b 206f 6e20 6120 6261 7463 6820  work on a batch 
-0001d3c0: 6f66 2073 6571 7565 6e74 6961 6c20 6461  of sequential da
-0001d3d0: 7461 2022 0d0a 2020 2020 2020 2020 2020  ta "..          
-0001d3e0: 2020 2228 6965 2061 7320 4c53 544d 2077    "(ie as LSTM w
-0001d3f0: 6f75 6c64 2077 6f72 6b20 6f76 6572 2061  ould work over a
-0001d400: 2077 686f 6c65 2073 6571 7565 6e63 6520   whole sequence 
-0001d410: 6f66 2064 6174 6129 2c20 6669 6c65 2061  of data), file a
-0001d420: 6e20 6973 7375 6520 6f6e 2022 0d0a 2020  n issue on "..  
-0001d430: 2020 2020 2020 2020 2020 2254 6f72 6368            "Torch
-0001d440: 524c 2072 6571 7565 7374 696e 6720 7468  RL requesting th
-0001d450: 6174 2066 6561 7475 7265 2e22 0d0a 2020  at feature."..  
-0001d460: 2020 2020 2020 290d 0a0d 0a0d 0a63 6c61        )......cla
-0001d470: 7373 2045 7863 6c75 6465 5472 616e 7366  ss ExcludeTransf
-0001d480: 6f72 6d28 5472 616e 7366 6f72 6d29 3a0d  orm(Transform):.
-0001d490: 0a20 2020 2022 2222 4578 636c 7564 6573  .    """Excludes
-0001d4a0: 206b 6579 7320 6672 6f6d 2074 6865 2069   keys from the i
-0001d4b0: 6e70 7574 2074 656e 736f 7264 6963 742e  nput tensordict.
-0001d4c0: 0d0a 0d0a 2020 2020 4172 6773 3a0d 0a20  ....    Args:.. 
-0001d4d0: 2020 2020 2020 202a 6578 636c 7564 6564         *excluded
-0001d4e0: 5f6b 6579 7320 2869 7465 7261 626c 6520  _keys (iterable 
-0001d4f0: 6f66 2073 7472 293a 2054 6865 206e 616d  of str): The nam
-0001d500: 6520 6f66 2074 6865 206b 6579 7320 746f  e of the keys to
-0001d510: 2065 7863 6c75 6465 2e20 4966 2074 6865   exclude. If the
-0001d520: 206b 6579 2069 730d 0a20 2020 2020 2020   key is..       
-0001d530: 2020 2020 206e 6f74 2070 7265 7365 6e74       not present
-0001d540: 2c20 6974 2069 7320 7369 6d70 6c79 2069  , it is simply i
-0001d550: 676e 6f72 6564 2e0d 0a0d 0a20 2020 2022  gnored.....    "
-0001d560: 2222 0d0a 0d0a 2020 2020 6465 6620 5f5f  ""....    def __
-0001d570: 696e 6974 5f5f 2873 656c 662c 202a 6578  init__(self, *ex
-0001d580: 636c 7564 6564 5f6b 6579 7329 3a0d 0a20  cluded_keys):.. 
-0001d590: 2020 2020 2020 2073 7570 6572 2829 2e5f         super()._
-0001d5a0: 5f69 6e69 745f 5f28 696e 5f6b 6579 733d  _init__(in_keys=
-0001d5b0: 5b5d 2c20 696e 5f6b 6579 735f 696e 763d  [], in_keys_inv=
-0001d5c0: 5b5d 2c20 6f75 745f 6b65 7973 3d5b 5d2c  [], out_keys=[],
-0001d5d0: 206f 7574 5f6b 6579 735f 696e 763d 5b5d   out_keys_inv=[]
-0001d5e0: 290d 0a20 2020 2020 2020 2069 6620 6e6f  )..        if no
-0001d5f0: 7420 616c 6c28 6973 696e 7374 616e 6365  t all(isinstance
-0001d600: 2869 7465 6d2c 2073 7472 2920 666f 7220  (item, str) for 
-0001d610: 6974 656d 2069 6e20 6578 636c 7564 6564  item in excluded
-0001d620: 5f6b 6579 7329 3a0d 0a20 2020 2020 2020  _keys):..       
-0001d630: 2020 2020 2072 6169 7365 2056 616c 7565       raise Value
-0001d640: 4572 726f 7228 2265 7863 6c75 6465 645f  Error("excluded_
-0001d650: 6b65 7973 206d 7573 7420 6265 2061 206c  keys must be a l
-0001d660: 6973 7420 6f72 2074 7570 6c65 206f 6620  ist or tuple of 
-0001d670: 7374 7269 6e67 732e 2229 0d0a 2020 2020  strings.")..    
-0001d680: 2020 2020 7365 6c66 2e65 7863 6c75 6465      self.exclude
-0001d690: 645f 6b65 7973 203d 2065 7863 6c75 6465  d_keys = exclude
-0001d6a0: 645f 6b65 7973 0d0a 2020 2020 2020 2020  d_keys..        
-0001d6b0: 6966 2022 7265 7761 7264 2220 696e 2065  if "reward" in e
-0001d6c0: 7863 6c75 6465 645f 6b65 7973 3a0d 0a20  xcluded_keys:.. 
-0001d6d0: 2020 2020 2020 2020 2020 2072 6169 7365             raise
-0001d6e0: 2052 756e 7469 6d65 4572 726f 7228 2227   RuntimeError("'
-0001d6f0: 7265 7761 7264 2720 6361 6e6e 6f74 2062  reward' cannot b
-0001d700: 6520 6578 636c 7564 6564 2066 726f 6d20  e excluded from 
-0001d710: 7468 6520 6b65 7973 2e22 290d 0a0d 0a20  the keys.").... 
-0001d720: 2020 2064 6566 205f 6361 6c6c 2873 656c     def _call(sel
-0001d730: 662c 2074 656e 736f 7264 6963 743a 2054  f, tensordict: T
-0001d740: 656e 736f 7244 6963 7442 6173 6529 202d  ensorDictBase) -
-0001d750: 3e20 5465 6e73 6f72 4469 6374 4261 7365  > TensorDictBase
-0001d760: 3a0d 0a20 2020 2020 2020 2072 6574 7572  :..        retur
-0001d770: 6e20 7465 6e73 6f72 6469 6374 2e65 7863  n tensordict.exc
-0001d780: 6c75 6465 282a 7365 6c66 2e65 7863 6c75  lude(*self.exclu
-0001d790: 6465 645f 6b65 7973 290d 0a0d 0a20 2020  ded_keys)....   
-0001d7a0: 2066 6f72 7761 7264 203d 205f 6361 6c6c   forward = _call
-0001d7b0: 0d0a 0d0a 2020 2020 6465 6620 7265 7365  ....    def rese
-0001d7c0: 7428 7365 6c66 2c20 7465 6e73 6f72 6469  t(self, tensordi
-0001d7d0: 6374 3a20 5465 6e73 6f72 4469 6374 4261  ct: TensorDictBa
-0001d7e0: 7365 2920 2d3e 2054 656e 736f 7244 6963  se) -> TensorDic
-0001d7f0: 7442 6173 653a 0d0a 2020 2020 2020 2020  tBase:..        
-0001d800: 7265 7475 726e 2074 656e 736f 7264 6963  return tensordic
-0001d810: 742e 6578 636c 7564 6528 2a73 656c 662e  t.exclude(*self.
-0001d820: 6578 636c 7564 6564 5f6b 6579 7329 0d0a  excluded_keys)..
-0001d830: 0d0a 2020 2020 6465 6620 7472 616e 7366  ..    def transf
-0001d840: 6f72 6d5f 6f62 7365 7276 6174 696f 6e5f  orm_observation_
-0001d850: 7370 6563 2873 656c 662c 206f 6273 6572  spec(self, obser
-0001d860: 7661 7469 6f6e 5f73 7065 633a 2054 656e  vation_spec: Ten
-0001d870: 736f 7253 7065 6329 202d 3e20 5465 6e73  sorSpec) -> Tens
-0001d880: 6f72 5370 6563 3a0d 0a20 2020 2020 2020  orSpec:..       
-0001d890: 2069 6620 616e 7928 6b65 7920 696e 206f   if any(key in o
-0001d8a0: 6273 6572 7661 7469 6f6e 5f73 7065 632e  bservation_spec.
-0001d8b0: 6b65 7973 2854 7275 652c 2054 7275 6529  keys(True, True)
-0001d8c0: 2066 6f72 206b 6579 2069 6e20 7365 6c66   for key in self
-0001d8d0: 2e65 7863 6c75 6465 645f 6b65 7973 293a  .excluded_keys):
-0001d8e0: 0d0a 2020 2020 2020 2020 2020 2020 7265  ..            re
-0001d8f0: 7475 726e 2043 6f6d 706f 7369 7465 5370  turn CompositeSp
-0001d900: 6563 280d 0a20 2020 2020 2020 2020 2020  ec(..           
-0001d910: 2020 2020 202a 2a7b 0d0a 2020 2020 2020       **{..      
-0001d920: 2020 2020 2020 2020 2020 2020 2020 6b65                ke
-0001d930: 793a 2076 616c 7565 0d0a 2020 2020 2020  y: value..      
-0001d940: 2020 2020 2020 2020 2020 2020 2020 666f                fo
-0001d950: 7220 6b65 792c 2076 616c 7565 2069 6e20  r key, value in 
-0001d960: 6f62 7365 7276 6174 696f 6e5f 7370 6563  observation_spec
-0001d970: 2e69 7465 6d73 2829 0d0a 2020 2020 2020  .items()..      
-0001d980: 2020 2020 2020 2020 2020 2020 2020 6966                if
-0001d990: 206b 6579 206e 6f74 2069 6e20 7365 6c66   key not in self
-0001d9a0: 2e65 7863 6c75 6465 645f 6b65 7973 0d0a  .excluded_keys..
-0001d9b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001d9c0: 7d2c 0d0a 2020 2020 2020 2020 2020 2020  },..            
-0001d9d0: 2020 2020 7368 6170 653d 6f62 7365 7276      shape=observ
-0001d9e0: 6174 696f 6e5f 7370 6563 2e73 6861 7065  ation_spec.shape
-0001d9f0: 2c0d 0a20 2020 2020 2020 2020 2020 2029  ,..            )
-0001da00: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
-0001da10: 206f 6273 6572 7661 7469 6f6e 5f73 7065   observation_spe
-0001da20: 630d 0a0d 0a0d 0a63 6c61 7373 2053 656c  c......class Sel
-0001da30: 6563 7454 7261 6e73 666f 726d 2854 7261  ectTransform(Tra
-0001da40: 6e73 666f 726d 293a 0d0a 2020 2020 2222  nsform):..    ""
-0001da50: 2253 656c 6563 7420 6b65 7973 2066 726f  "Select keys fro
-0001da60: 6d20 7468 6520 696e 7075 7420 7465 6e73  m the input tens
-0001da70: 6f72 6469 6374 2e0d 0a0d 0a20 2020 2049  ordict.....    I
-0001da80: 6e20 6765 6e65 7261 6c2c 2074 6865 203a  n general, the :
-0001da90: 6f62 6a3a 6045 7863 6c75 6465 5472 616e  obj:`ExcludeTran
-0001daa0: 7366 6f72 6d60 2073 686f 756c 6420 6265  sform` should be
-0001dab0: 2070 7265 6665 7272 6564 3a20 7468 6973   preferred: this
-0001dac0: 2074 7261 6e73 666f 726d 7320 616c 736f   transforms also
-0001dad0: 0d0a 2020 2020 2020 2020 7365 6c65 6374  ..        select
-0001dae0: 7320 7468 6520 2261 6374 696f 6e22 2028  s the "action" (
-0001daf0: 6f72 206f 7468 6572 206b 6579 7320 6672  or other keys fr
-0001db00: 6f6d 2069 6e70 7574 5f73 7065 6329 2c20  om input_spec), 
-0001db10: 2264 6f6e 6522 2061 6e64 2022 7265 7761  "done" and "rewa
-0001db20: 7264 220d 0a20 2020 2020 2020 206b 6579  rd"..        key
-0001db30: 7320 6275 7420 6f74 6865 7220 6d61 7920  s but other may 
-0001db40: 6265 206e 6563 6573 7361 7279 2e0d 0a0d  be necessary....
-0001db50: 0a20 2020 2041 7267 733a 0d0a 2020 2020  .    Args:..    
-0001db60: 2020 2020 2a73 656c 6563 7465 645f 6b65      *selected_ke
-0001db70: 7973 2028 6974 6572 6162 6c65 206f 6620  ys (iterable of 
-0001db80: 7374 7229 3a20 5468 6520 6e61 6d65 206f  str): The name o
-0001db90: 6620 7468 6520 6b65 7973 2074 6f20 7365  f the keys to se
-0001dba0: 6c65 6374 2e20 4966 2074 6865 206b 6579  lect. If the key
-0001dbb0: 2069 730d 0a20 2020 2020 2020 2020 2020   is..           
-0001dbc0: 206e 6f74 2070 7265 7365 6e74 2c20 6974   not present, it
-0001dbd0: 2069 7320 7369 6d70 6c79 2069 676e 6f72   is simply ignor
-0001dbe0: 6564 2e0d 0a0d 0a20 2020 2022 2222 0d0a  ed.....    """..
-0001dbf0: 0d0a 2020 2020 6465 6620 5f5f 696e 6974  ..    def __init
-0001dc00: 5f5f 2873 656c 662c 202a 7365 6c65 6374  __(self, *select
-0001dc10: 6564 5f6b 6579 7329 3a0d 0a20 2020 2020  ed_keys):..     
-0001dc20: 2020 2073 7570 6572 2829 2e5f 5f69 6e69     super().__ini
-0001dc30: 745f 5f28 696e 5f6b 6579 733d 5b5d 2c20  t__(in_keys=[], 
-0001dc40: 696e 5f6b 6579 735f 696e 763d 5b5d 2c20  in_keys_inv=[], 
-0001dc50: 6f75 745f 6b65 7973 3d5b 5d2c 206f 7574  out_keys=[], out
-0001dc60: 5f6b 6579 735f 696e 763d 5b5d 290d 0a20  _keys_inv=[]).. 
-0001dc70: 2020 2020 2020 2069 6620 6e6f 7420 616c         if not al
-0001dc80: 6c28 6973 696e 7374 616e 6365 2869 7465  l(isinstance(ite
-0001dc90: 6d2c 2073 7472 2920 666f 7220 6974 656d  m, str) for item
-0001dca0: 2069 6e20 7365 6c65 6374 6564 5f6b 6579   in selected_key
-0001dcb0: 7329 3a0d 0a20 2020 2020 2020 2020 2020  s):..           
-0001dcc0: 2072 6169 7365 2056 616c 7565 4572 726f   raise ValueErro
-0001dcd0: 7228 2265 7863 6c75 6465 645f 6b65 7973  r("excluded_keys
-0001dce0: 206d 7573 7420 6265 2061 206c 6973 7420   must be a list 
-0001dcf0: 6f72 2074 7570 6c65 206f 6620 7374 7269  or tuple of stri
-0001dd00: 6e67 732e 2229 0d0a 2020 2020 2020 2020  ngs.")..        
-0001dd10: 7365 6c66 2e73 656c 6563 7465 645f 6b65  self.selected_ke
-0001dd20: 7973 203d 2073 656c 6563 7465 645f 6b65  ys = selected_ke
-0001dd30: 7973 0d0a 0d0a 2020 2020 6465 6620 5f63  ys....    def _c
-0001dd40: 616c 6c28 7365 6c66 2c20 7465 6e73 6f72  all(self, tensor
-0001dd50: 6469 6374 3a20 5465 6e73 6f72 4469 6374  dict: TensorDict
-0001dd60: 4261 7365 2920 2d3e 2054 656e 736f 7244  Base) -> TensorD
-0001dd70: 6963 7442 6173 653a 0d0a 2020 2020 2020  ictBase:..      
-0001dd80: 2020 6966 2073 656c 662e 7061 7265 6e74    if self.parent
-0001dd90: 3a0d 0a20 2020 2020 2020 2020 2020 2069  :..            i
-0001dda0: 6e70 7574 5f6b 6579 7320 3d20 7365 6c66  nput_keys = self
-0001ddb0: 2e70 6172 656e 742e 696e 7075 745f 7370  .parent.input_sp
-0001ddc0: 6563 2e6b 6579 7328 5472 7565 2c20 5472  ec.keys(True, Tr
-0001ddd0: 7565 290d 0a20 2020 2020 2020 2065 6c73  ue)..        els
-0001dde0: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
-0001ddf0: 696e 7075 745f 6b65 7973 203d 205b 5d0d  input_keys = [].
-0001de00: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-0001de10: 7465 6e73 6f72 6469 6374 2e73 656c 6563  tensordict.selec
-0001de20: 7428 0d0a 2020 2020 2020 2020 2020 2020  t(..            
-0001de30: 2a73 656c 662e 7365 6c65 6374 6564 5f6b  *self.selected_k
-0001de40: 6579 732c 2022 7265 7761 7264 222c 2022  eys, "reward", "
-0001de50: 646f 6e65 222c 202a 696e 7075 745f 6b65  done", *input_ke
-0001de60: 7973 2c20 7374 7269 6374 3d46 616c 7365  ys, strict=False
-0001de70: 0d0a 2020 2020 2020 2020 290d 0a0d 0a20  ..        ).... 
-0001de80: 2020 2066 6f72 7761 7264 203d 205f 6361     forward = _ca
-0001de90: 6c6c 0d0a 0d0a 2020 2020 6465 6620 7265  ll....    def re
-0001dea0: 7365 7428 7365 6c66 2c20 7465 6e73 6f72  set(self, tensor
-0001deb0: 6469 6374 3a20 5465 6e73 6f72 4469 6374  dict: TensorDict
-0001dec0: 4261 7365 2920 2d3e 2054 656e 736f 7244  Base) -> TensorD
-0001ded0: 6963 7442 6173 653a 0d0a 2020 2020 2020  ictBase:..      
-0001dee0: 2020 6966 2073 656c 662e 7061 7265 6e74    if self.parent
-0001def0: 3a0d 0a20 2020 2020 2020 2020 2020 2069  :..            i
-0001df00: 6e70 7574 5f6b 6579 7320 3d20 7365 6c66  nput_keys = self
-0001df10: 2e70 6172 656e 742e 696e 7075 745f 7370  .parent.input_sp
-0001df20: 6563 2e6b 6579 7328 5472 7565 2c20 5472  ec.keys(True, Tr
-0001df30: 7565 290d 0a20 2020 2020 2020 2065 6c73  ue)..        els
-0001df40: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
-0001df50: 696e 7075 745f 6b65 7973 203d 205b 5d0d  input_keys = [].
-0001df60: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-0001df70: 7465 6e73 6f72 6469 6374 2e73 656c 6563  tensordict.selec
-0001df80: 7428 0d0a 2020 2020 2020 2020 2020 2020  t(..            
-0001df90: 2a73 656c 662e 7365 6c65 6374 6564 5f6b  *self.selected_k
-0001dfa0: 6579 732c 2022 7265 7761 7264 222c 2022  eys, "reward", "
-0001dfb0: 646f 6e65 222c 202a 696e 7075 745f 6b65  done", *input_ke
-0001dfc0: 7973 2c20 7374 7269 6374 3d46 616c 7365  ys, strict=False
-0001dfd0: 0d0a 2020 2020 2020 2020 290d 0a0d 0a20  ..        ).... 
-0001dfe0: 2020 2064 6566 2074 7261 6e73 666f 726d     def transform
-0001dff0: 5f6f 6273 6572 7661 7469 6f6e 5f73 7065  _observation_spe
-0001e000: 6328 7365 6c66 2c20 6f62 7365 7276 6174  c(self, observat
-0001e010: 696f 6e5f 7370 6563 3a20 5465 6e73 6f72  ion_spec: Tensor
-0001e020: 5370 6563 2920 2d3e 2054 656e 736f 7253  Spec) -> TensorS
-0001e030: 7065 633a 0d0a 2020 2020 2020 2020 7265  pec:..        re
-0001e040: 7475 726e 2043 6f6d 706f 7369 7465 5370  turn CompositeSp
-0001e050: 6563 280d 0a20 2020 2020 2020 2020 2020  ec(..           
-0001e060: 202a 2a7b 0d0a 2020 2020 2020 2020 2020   **{..          
-0001e070: 2020 2020 2020 6b65 793a 2076 616c 7565        key: value
-0001e080: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-0001e090: 2020 666f 7220 6b65 792c 2076 616c 7565    for key, value
-0001e0a0: 2069 6e20 6f62 7365 7276 6174 696f 6e5f   in observation_
-0001e0b0: 7370 6563 2e69 7465 6d73 2829 0d0a 2020  spec.items()..  
-0001e0c0: 2020 2020 2020 2020 2020 2020 2020 6966                if
-0001e0d0: 206b 6579 2069 6e20 7365 6c66 2e73 656c   key in self.sel
-0001e0e0: 6563 7465 645f 6b65 7973 0d0a 2020 2020  ected_keys..    
-0001e0f0: 2020 2020 2020 2020 7d2c 0d0a 2020 2020          },..    
-0001e100: 2020 2020 2020 2020 7368 6170 653d 6f62          shape=ob
-0001e110: 7365 7276 6174 696f 6e5f 7370 6563 2e73  servation_spec.s
-0001e120: 6861 7065 2c0d 0a20 2020 2020 2020 2029  hape,..        )
-0001e130: 0d0a 0d0a 0d0a 636c 6173 7320 5469 6d65  ......class Time
-0001e140: 4d61 7850 6f6f 6c28 5472 616e 7366 6f72  MaxPool(Transfor
-0001e150: 6d29 3a0d 0a20 2020 2022 2222 5461 6b65  m):..    """Take
-0001e160: 2074 6865 206d 6178 696d 756d 2076 616c   the maximum val
-0001e170: 7565 2069 6e20 6561 6368 2070 6f73 6974  ue in each posit
-0001e180: 696f 6e20 6f76 6572 2074 6865 206c 6173  ion over the las
-0001e190: 7420 5420 6f62 7365 7276 6174 696f 6e73  t T observations
-0001e1a0: 2e0d 0a0d 0a20 2020 2054 6869 7320 7472  .....    This tr
-0001e1b0: 616e 7366 6f72 6d20 7461 6b65 2074 6865  ansform take the
-0001e1c0: 206d 6178 696d 756d 2076 616c 7565 2069   maximum value i
-0001e1d0: 6e20 6561 6368 2070 6f73 6974 696f 6e20  n each position 
-0001e1e0: 666f 7220 616c 6c20 696e 5f6b 6579 7320  for all in_keys 
-0001e1f0: 7465 6e73 6f72 7320 6f76 6572 2074 6865  tensors over the
-0001e200: 206c 6173 7420 5420 7469 6d65 2073 7465   last T time ste
-0001e210: 7073 2e0d 0a0d 0a20 2020 2041 7267 733a  ps.....    Args:
-0001e220: 0d0a 2020 2020 2020 2020 696e 5f6b 6579  ..        in_key
-0001e230: 7320 2873 6571 7565 6e63 6520 6f66 2073  s (sequence of s
-0001e240: 7472 2c20 6f70 7469 6f6e 616c 293a 2069  tr, optional): i
-0001e250: 6e70 7574 206b 6579 7320 6f6e 2077 6869  nput keys on whi
-0001e260: 6368 2074 6865 206d 6178 2070 6f6f 6c20  ch the max pool 
-0001e270: 7769 6c6c 2062 6520 6170 706c 6965 642e  will be applied.
-0001e280: 2044 6566 6175 6c74 7320 746f 2022 6f62   Defaults to "ob
-0001e290: 7365 7276 6174 696f 6e22 2069 6620 6c65  servation" if le
-0001e2a0: 6674 2065 6d70 7479 2e0d 0a20 2020 2020  ft empty...     
-0001e2b0: 2020 206f 7574 5f6b 6579 7320 2873 6571     out_keys (seq
-0001e2c0: 7565 6e63 6520 6f66 2073 7472 2c20 6f70  uence of str, op
-0001e2d0: 7469 6f6e 616c 293a 206f 7574 7075 7420  tional): output 
-0001e2e0: 6b65 7973 2077 6865 7265 2074 6865 206f  keys where the o
-0001e2f0: 7574 7075 7420 7769 6c6c 2062 6520 7772  utput will be wr
-0001e300: 6974 7465 6e2e 2044 6566 6175 6c74 7320  itten. Defaults 
-0001e310: 746f 2060 696e 5f6b 6579 7360 2069 6620  to `in_keys` if 
-0001e320: 6c65 6674 2065 6d70 7479 2e0d 0a20 2020  left empty...   
-0001e330: 2020 2020 2054 2028 696e 742c 206f 7074       T (int, opt
-0001e340: 696f 6e61 6c29 3a20 4e75 6d62 6572 206f  ional): Number o
-0001e350: 6620 7469 6d65 2073 7465 7073 206f 7665  f time steps ove
-0001e360: 7220 7768 6963 6820 746f 2061 7070 6c79  r which to apply
-0001e370: 206d 6178 2070 6f6f 6c69 6e67 2e0d 0a20   max pooling... 
-0001e380: 2020 2022 2222 0d0a 0d0a 2020 2020 696e     """....    in
-0001e390: 7665 7274 6962 6c65 203d 2046 616c 7365  vertible = False
-0001e3a0: 0d0a 0d0a 2020 2020 6465 6620 5f5f 696e  ....    def __in
-0001e3b0: 6974 5f5f 280d 0a20 2020 2020 2020 2073  it__(..        s
-0001e3c0: 656c 662c 0d0a 2020 2020 2020 2020 696e  elf,..        in
-0001e3d0: 5f6b 6579 733a 204f 7074 696f 6e61 6c5b  _keys: Optional[
-0001e3e0: 5365 7175 656e 6365 5b73 7472 5d5d 203d  Sequence[str]] =
-0001e3f0: 204e 6f6e 652c 0d0a 2020 2020 2020 2020   None,..        
-0001e400: 6f75 745f 6b65 7973 3a20 4f70 7469 6f6e  out_keys: Option
-0001e410: 616c 5b53 6571 7565 6e63 655b 7374 725d  al[Sequence[str]
-0001e420: 5d20 3d20 4e6f 6e65 2c0d 0a20 2020 2020  ] = None,..     
-0001e430: 2020 2054 3a20 696e 7420 3d20 312c 0d0a     T: int = 1,..
-0001e440: 2020 2020 293a 0d0a 2020 2020 2020 2020      ):..        
-0001e450: 6966 2069 6e5f 6b65 7973 2069 7320 4e6f  if in_keys is No
-0001e460: 6e65 3a0d 0a20 2020 2020 2020 2020 2020  ne:..           
-0001e470: 2069 6e5f 6b65 7973 203d 205b 226f 6273   in_keys = ["obs
-0001e480: 6572 7661 7469 6f6e 225d 0d0a 2020 2020  ervation"]..    
-0001e490: 2020 2020 7375 7065 7228 292e 5f5f 696e      super().__in
-0001e4a0: 6974 5f5f 2869 6e5f 6b65 7973 3d69 6e5f  it__(in_keys=in_
-0001e4b0: 6b65 7973 2c20 6f75 745f 6b65 7973 3d6f  keys, out_keys=o
-0001e4c0: 7574 5f6b 6579 7329 0d0a 2020 2020 2020  ut_keys)..      
-0001e4d0: 2020 6966 2054 203c 2031 3a0d 0a20 2020    if T < 1:..   
-0001e4e0: 2020 2020 2020 2020 2072 6169 7365 2056           raise V
-0001e4f0: 616c 7565 4572 726f 7228 0d0a 2020 2020  alueError(..    
-0001e500: 2020 2020 2020 2020 2020 2020 2254 696d              "Tim
-0001e510: 654d 6178 506f 6f6c 5472 616e 666f 726d  eMaxPoolTranform
-0001e520: 2054 2070 6172 616d 6574 6572 2073 686f   T parameter sho
-0001e530: 756c 6420 6861 7665 2061 2076 616c 7565  uld have a value
-0001e540: 2067 7265 6174 6572 206f 7220 6571 7561   greater or equa
-0001e550: 6c20 746f 206f 6e65 2e22 0d0a 2020 2020  l to one."..    
-0001e560: 2020 2020 2020 2020 290d 0a20 2020 2020          )..     
-0001e570: 2020 2069 6620 6c65 6e28 7365 6c66 2e69     if len(self.i
-0001e580: 6e5f 6b65 7973 2920 213d 206c 656e 2873  n_keys) != len(s
-0001e590: 656c 662e 6f75 745f 6b65 7973 293a 0d0a  elf.out_keys):..
-0001e5a0: 2020 2020 2020 2020 2020 2020 7261 6973              rais
-0001e5b0: 6520 5661 6c75 6545 7272 6f72 280d 0a20  e ValueError(.. 
-0001e5c0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
-0001e5d0: 5469 6d65 4d61 7850 6f6f 6c54 7261 6e66  TimeMaxPoolTranf
-0001e5e0: 6f72 6d20 696e 5f6b 6579 7320 616e 6420  orm in_keys and 
-0001e5f0: 6f75 745f 6b65 7973 2064 6f6e 2774 2068  out_keys don't h
-0001e600: 6176 6520 7468 6520 7361 6d65 206e 756d  ave the same num
-0001e610: 6265 7220 6f66 2065 6c65 6d65 6e74 7322  ber of elements"
-0001e620: 0d0a 2020 2020 2020 2020 2020 2020 290d  ..            ).
-0001e630: 0a20 2020 2020 2020 2073 656c 662e 6275  .        self.bu
-0001e640: 6666 6572 5f73 697a 6520 3d20 540d 0a20  ffer_size = T.. 
-0001e650: 2020 2020 2020 2066 6f72 2069 6e5f 6b65         for in_ke
-0001e660: 7920 696e 2073 656c 662e 696e 5f6b 6579  y in self.in_key
-0001e670: 733a 0d0a 2020 2020 2020 2020 2020 2020  s:..            
-0001e680: 6275 6666 6572 5f6e 616d 6520 3d20 6622  buffer_name = f"
-0001e690: 5f6d 6178 706f 6f6c 5f62 7566 6665 725f  _maxpool_buffer_
-0001e6a0: 7b69 6e5f 6b65 797d 220d 0a20 2020 2020  {in_key}"..     
-0001e6b0: 2020 2020 2020 2073 6574 6174 7472 280d         setattr(.
-0001e6c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001e6d0: 2073 656c 662c 0d0a 2020 2020 2020 2020   self,..        
-0001e6e0: 2020 2020 2020 2020 6275 6666 6572 5f6e          buffer_n
-0001e6f0: 616d 652c 0d0a 2020 2020 2020 2020 2020  ame,..          
-0001e700: 2020 2020 2020 746f 7263 682e 6e6e 2e70        torch.nn.p
-0001e710: 6172 616d 6574 6572 2e55 6e69 6e69 7469  arameter.Uniniti
-0001e720: 616c 697a 6564 4275 6666 6572 280d 0a20  alizedBuffer(.. 
-0001e730: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e740: 2020 2064 6576 6963 653d 746f 7263 682e     device=torch.
-0001e750: 6465 7669 6365 2822 6370 7522 292c 2064  device("cpu"), d
-0001e760: 7479 7065 3d74 6f72 6368 2e67 6574 5f64  type=torch.get_d
-0001e770: 6566 6175 6c74 5f64 7479 7065 2829 0d0a  efault_dtype()..
-0001e780: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001e790: 292c 0d0a 2020 2020 2020 2020 2020 2020  ),..            
-0001e7a0: 290d 0a0d 0a20 2020 2064 6566 2072 6573  )....    def res
-0001e7b0: 6574 2873 656c 662c 2074 656e 736f 7264  et(self, tensord
-0001e7c0: 6963 743a 2054 656e 736f 7244 6963 7442  ict: TensorDictB
-0001e7d0: 6173 6529 202d 3e20 5465 6e73 6f72 4469  ase) -> TensorDi
-0001e7e0: 6374 4261 7365 3a0d 0a20 2020 2020 2020  ctBase:..       
-0001e7f0: 2022 2222 5265 7365 7473 205f 6275 6666   """Resets _buff
-0001e800: 6572 732e 2222 220d 0a20 2020 2020 2020  ers."""..       
-0001e810: 2023 204e 6f6e 2d62 6174 6368 6564 2065   # Non-batched e
-0001e820: 6e76 6972 6f6e 6d65 6e74 730d 0a20 2020  nvironments..   
-0001e830: 2020 2020 2069 6620 6c65 6e28 7465 6e73       if len(tens
-0001e840: 6f72 6469 6374 2e62 6174 6368 5f73 697a  ordict.batch_siz
-0001e850: 6529 203c 2031 206f 7220 7465 6e73 6f72  e) < 1 or tensor
-0001e860: 6469 6374 2e62 6174 6368 5f73 697a 655b  dict.batch_size[
-0001e870: 305d 203d 3d20 313a 0d0a 2020 2020 2020  0] == 1:..      
-0001e880: 2020 2020 2020 666f 7220 696e 5f6b 6579        for in_key
-0001e890: 2069 6e20 7365 6c66 2e69 6e5f 6b65 7973   in self.in_keys
-0001e8a0: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
-0001e8b0: 2020 2062 7566 6665 725f 6e61 6d65 203d     buffer_name =
-0001e8c0: 2066 225f 6d61 7870 6f6f 6c5f 6275 6666   f"_maxpool_buff
-0001e8d0: 6572 5f7b 696e 5f6b 6579 7d22 0d0a 2020  er_{in_key}"..  
-0001e8e0: 2020 2020 2020 2020 2020 2020 2020 6275                bu
-0001e8f0: 6666 6572 203d 2067 6574 6174 7472 2873  ffer = getattr(s
-0001e900: 656c 662c 2062 7566 6665 725f 6e61 6d65  elf, buffer_name
-0001e910: 290d 0a20 2020 2020 2020 2020 2020 2020  )..             
-0001e920: 2020 2069 6620 6973 696e 7374 616e 6365     if isinstance
-0001e930: 2862 7566 6665 722c 2074 6f72 6368 2e6e  (buffer, torch.n
-0001e940: 6e2e 7061 7261 6d65 7465 722e 556e 696e  n.parameter.Unin
-0001e950: 6974 6961 6c69 7a65 6442 7566 6665 7229  itializedBuffer)
-0001e960: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
-0001e970: 2020 2020 2020 2063 6f6e 7469 6e75 650d         continue.
-0001e980: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001e990: 2062 7566 6665 722e 6669 6c6c 5f28 302e   buffer.fill_(0.
-0001e9a0: 3029 0d0a 0d0a 2020 2020 2020 2020 2320  0)....        # 
-0001e9b0: 4261 7463 6865 6420 656e 7669 726f 6e6d  Batched environm
-0001e9c0: 656e 7473 0d0a 2020 2020 2020 2020 656c  ents..        el
-0001e9d0: 7365 3a0d 0a20 2020 2020 2020 2020 2020  se:..           
-0001e9e0: 205f 7265 7365 7420 3d20 7465 6e73 6f72   _reset = tensor
-0001e9f0: 6469 6374 2e67 6574 280d 0a20 2020 2020  dict.get(..     
-0001ea00: 2020 2020 2020 2020 2020 2022 5f72 6573             "_res
-0001ea10: 6574 222c 0d0a 2020 2020 2020 2020 2020  et",..          
-0001ea20: 2020 2020 2020 746f 7263 682e 6f6e 6573        torch.ones
-0001ea30: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
-0001ea40: 2020 2020 2020 2074 656e 736f 7264 6963         tensordic
-0001ea50: 742e 6261 7463 685f 7369 7a65 2c0d 0a20  t.batch_size,.. 
-0001ea60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001ea70: 2020 2064 7479 7065 3d74 6f72 6368 2e62     dtype=torch.b
-0001ea80: 6f6f 6c2c 0d0a 2020 2020 2020 2020 2020  ool,..          
-0001ea90: 2020 2020 2020 2020 2020 6465 7669 6365            device
-0001eaa0: 3d74 656e 736f 7264 6963 742e 6465 7669  =tensordict.devi
-0001eab0: 6365 2c0d 0a20 2020 2020 2020 2020 2020  ce,..           
-0001eac0: 2020 2020 2029 2c0d 0a20 2020 2020 2020       ),..       
-0001ead0: 2020 2020 2029 0d0a 2020 2020 2020 2020       )..        
-0001eae0: 2020 2020 666f 7220 696e 5f6b 6579 2069      for in_key i
-0001eaf0: 6e20 7365 6c66 2e69 6e5f 6b65 7973 3a0d  n self.in_keys:.
-0001eb00: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001eb10: 2062 7566 6665 725f 6e61 6d65 203d 2066   buffer_name = f
-0001eb20: 225f 6d61 7870 6f6f 6c5f 6275 6666 6572  "_maxpool_buffer
-0001eb30: 5f7b 696e 5f6b 6579 7d22 0d0a 2020 2020  _{in_key}"..    
-0001eb40: 2020 2020 2020 2020 2020 2020 6275 6666              buff
-0001eb50: 6572 203d 2067 6574 6174 7472 2873 656c  er = getattr(sel
-0001eb60: 662c 2062 7566 6665 725f 6e61 6d65 290d  f, buffer_name).
-0001eb70: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001eb80: 2069 6620 6973 696e 7374 616e 6365 2862   if isinstance(b
-0001eb90: 7566 6665 722c 2074 6f72 6368 2e6e 6e2e  uffer, torch.nn.
-0001eba0: 7061 7261 6d65 7465 722e 556e 696e 6974  parameter.Uninit
-0001ebb0: 6961 6c69 7a65 6442 7566 6665 7229 3a0d  ializedBuffer):.
-0001ebc0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0001ebd0: 2020 2020 2063 6f6e 7469 6e75 650d 0a20       continue.. 
-0001ebe0: 2020 2020 2020 2020 2020 2020 2020 2062                 b
-0001ebf0: 7566 6665 725b 3a2c 205f 7265 7365 745d  uffer[:, _reset]
-0001ec00: 203d 2030 2e30 0d0a 0d0a 2020 2020 2020   = 0.0....      
-0001ec10: 2020 7265 7475 726e 2074 656e 736f 7264    return tensord
-0001ec20: 6963 740d 0a0d 0a20 2020 2064 6566 205f  ict....    def _
-0001ec30: 6d61 6b65 5f6d 6973 7369 6e67 5f62 7566  make_missing_buf
-0001ec40: 6665 7228 7365 6c66 2c20 6461 7461 2c20  fer(self, data, 
-0001ec50: 6275 6666 6572 5f6e 616d 6529 3a0d 0a20  buffer_name):.. 
-0001ec60: 2020 2020 2020 2062 7566 6665 7220 3d20         buffer = 
-0001ec70: 6765 7461 7474 7228 7365 6c66 2c20 6275  getattr(self, bu
-0001ec80: 6666 6572 5f6e 616d 6529 0d0a 2020 2020  ffer_name)..    
-0001ec90: 2020 2020 6275 6666 6572 2e6d 6174 6572      buffer.mater
-0001eca0: 6961 6c69 7a65 2828 7365 6c66 2e62 7566  ialize((self.buf
-0001ecb0: 6665 725f 7369 7a65 2c29 202b 2064 6174  fer_size,) + dat
-0001ecc0: 612e 7368 6170 6529 0d0a 2020 2020 2020  a.shape)..      
-0001ecd0: 2020 6275 6666 6572 203d 2062 7566 6665    buffer = buffe
-0001ece0: 722e 746f 2864 6174 612e 6474 7970 6529  r.to(data.dtype)
-0001ecf0: 2e74 6f28 6461 7461 2e64 6576 6963 6529  .to(data.device)
-0001ed00: 2e7a 6572 6f5f 2829 0d0a 2020 2020 2020  .zero_()..      
-0001ed10: 2020 7365 7461 7474 7228 7365 6c66 2c20    setattr(self, 
-0001ed20: 6275 6666 6572 5f6e 616d 652c 2062 7566  buffer_name, buf
-0001ed30: 6665 7229 0d0a 0d0a 2020 2020 6465 6620  fer)....    def 
-0001ed40: 5f63 616c 6c28 7365 6c66 2c20 7465 6e73  _call(self, tens
-0001ed50: 6f72 6469 6374 3a20 5465 6e73 6f72 4469  ordict: TensorDi
-0001ed60: 6374 4261 7365 2920 2d3e 2054 656e 736f  ctBase) -> Tenso
-0001ed70: 7244 6963 7442 6173 653a 0d0a 2020 2020  rDictBase:..    
-0001ed80: 2020 2020 2222 2255 7064 6174 6520 7468      """Update th
-0001ed90: 6520 6570 6973 6f64 6520 7465 6e73 6f72  e episode tensor
-0001eda0: 6469 6374 2077 6974 6820 6d61 7820 706f  dict with max po
-0001edb0: 6f6c 6564 206b 6579 732e 2222 220d 0a20  oled keys.""".. 
-0001edc0: 2020 2020 2020 2066 6f72 2069 6e5f 6b65         for in_ke
-0001edd0: 792c 206f 7574 5f6b 6579 2069 6e20 7a69  y, out_key in zi
-0001ede0: 7028 7365 6c66 2e69 6e5f 6b65 7973 2c20  p(self.in_keys, 
-0001edf0: 7365 6c66 2e6f 7574 5f6b 6579 7329 3a0d  self.out_keys):.
-0001ee00: 0a20 2020 2020 2020 2020 2020 2023 204c  .            # L
-0001ee10: 617a 7920 696e 6974 206f 6620 6275 6666  azy init of buff
-0001ee20: 6572 730d 0a20 2020 2020 2020 2020 2020  ers..           
-0001ee30: 2062 7566 6665 725f 6e61 6d65 203d 2066   buffer_name = f
-0001ee40: 225f 6d61 7870 6f6f 6c5f 6275 6666 6572  "_maxpool_buffer
-0001ee50: 5f7b 696e 5f6b 6579 7d22 0d0a 2020 2020  _{in_key}"..    
-0001ee60: 2020 2020 2020 2020 6275 6666 6572 203d          buffer =
-0001ee70: 2067 6574 6174 7472 2873 656c 662c 2062   getattr(self, b
-0001ee80: 7566 6665 725f 6e61 6d65 290d 0a20 2020  uffer_name)..   
-0001ee90: 2020 2020 2020 2020 2069 6620 6973 696e           if isin
-0001eea0: 7374 616e 6365 2862 7566 6665 722c 2074  stance(buffer, t
-0001eeb0: 6f72 6368 2e6e 6e2e 7061 7261 6d65 7465  orch.nn.paramete
-0001eec0: 722e 556e 696e 6974 6961 6c69 7a65 6442  r.UninitializedB
-0001eed0: 7566 6665 7229 3a0d 0a20 2020 2020 2020  uffer):..       
-0001eee0: 2020 2020 2020 2020 2064 6174 6120 3d20           data = 
-0001eef0: 7465 6e73 6f72 6469 6374 5b69 6e5f 6b65  tensordict[in_ke
-0001ef00: 795d 0d0a 2020 2020 2020 2020 2020 2020  y]..            
-0001ef10: 2020 2020 7365 6c66 2e5f 6d61 6b65 5f6d      self._make_m
-0001ef20: 6973 7369 6e67 5f62 7566 6665 7228 6461  issing_buffer(da
-0001ef30: 7461 2c20 6275 6666 6572 5f6e 616d 6529  ta, buffer_name)
-0001ef40: 0d0a 2020 2020 2020 2020 2020 2020 2320  ..            # 
-0001ef50: 7368 6966 7420 6f62 7320 3120 706f 7369  shift obs 1 posi
-0001ef60: 7469 6f6e 2074 6f20 7468 6520 7269 6768  tion to the righ
-0001ef70: 740d 0a20 2020 2020 2020 2020 2020 2062  t..            b
-0001ef80: 7566 6665 722e 636f 7079 5f28 746f 7263  uffer.copy_(torc
-0001ef90: 682e 726f 6c6c 2862 7566 6665 722c 2073  h.roll(buffer, s
-0001efa0: 6869 6674 733d 312c 2064 696d 733d 3029  hifts=1, dims=0)
-0001efb0: 290d 0a20 2020 2020 2020 2020 2020 2023  )..            #
-0001efc0: 2061 6464 206e 6577 206f 6273 0d0a 2020   add new obs..  
-0001efd0: 2020 2020 2020 2020 2020 6275 6666 6572            buffer
-0001efe0: 5b30 5d2e 636f 7079 5f28 7465 6e73 6f72  [0].copy_(tensor
-0001eff0: 6469 6374 5b69 6e5f 6b65 795d 290d 0a20  dict[in_key]).. 
-0001f000: 2020 2020 2020 2020 2020 2023 2061 7070             # app
-0001f010: 6c79 206d 6178 2070 6f6f 6c69 6e67 0d0a  ly max pooling..
-0001f020: 2020 2020 2020 2020 2020 2020 706f 6f6c              pool
-0001f030: 6564 5f74 656e 736f 722c 205f 203d 2062  ed_tensor, _ = b
-0001f040: 7566 6665 722e 6d61 7828 6469 6d3d 3029  uffer.max(dim=0)
-0001f050: 0d0a 2020 2020 2020 2020 2020 2020 2320  ..            # 
-0001f060: 6164 6420 746f 2074 656e 736f 7264 6963  add to tensordic
-0001f070: 740d 0a20 2020 2020 2020 2020 2020 2074  t..            t
-0001f080: 656e 736f 7264 6963 742e 7365 7428 6f75  ensordict.set(ou
-0001f090: 745f 6b65 792c 2070 6f6f 6c65 645f 7465  t_key, pooled_te
-0001f0a0: 6e73 6f72 290d 0a0d 0a20 2020 2020 2020  nsor)....       
-0001f0b0: 2072 6574 7572 6e20 7465 6e73 6f72 6469   return tensordi
-0001f0c0: 6374 0d0a 0d0a 2020 2020 405f 6170 706c  ct....    @_appl
-0001f0d0: 795f 746f 5f63 6f6d 706f 7369 7465 0d0a  y_to_composite..
-0001f0e0: 2020 2020 6465 6620 7472 616e 7366 6f72      def transfor
-0001f0f0: 6d5f 6f62 7365 7276 6174 696f 6e5f 7370  m_observation_sp
-0001f100: 6563 2873 656c 662c 206f 6273 6572 7661  ec(self, observa
-0001f110: 7469 6f6e 5f73 7065 633a 2054 656e 736f  tion_spec: Tenso
-0001f120: 7253 7065 6329 202d 3e20 5465 6e73 6f72  rSpec) -> Tensor
-0001f130: 5370 6563 3a0d 0a20 2020 2020 2020 2072  Spec:..        r
-0001f140: 6574 7572 6e20 6f62 7365 7276 6174 696f  eturn observatio
-0001f150: 6e5f 7370 6563 0d0a 0d0a 2020 2020 6465  n_spec....    de
-0001f160: 6620 666f 7277 6172 6428 7365 6c66 2c20  f forward(self, 
-0001f170: 7465 6e73 6f72 6469 6374 3a20 5465 6e73  tensordict: Tens
-0001f180: 6f72 4469 6374 4261 7365 2920 2d3e 2054  orDictBase) -> T
-0001f190: 656e 736f 7244 6963 7442 6173 653a 0d0a  ensorDictBase:..
-0001f1a0: 2020 2020 2020 2020 7261 6973 6520 4e6f          raise No
-0001f1b0: 7449 6d70 6c65 6d65 6e74 6564 4572 726f  tImplementedErro
-0001f1c0: 7228 0d0a 2020 2020 2020 2020 2020 2020  r(..            
-0001f1d0: 2254 696d 654d 6178 506f 6f6c 2063 616e  "TimeMaxPool can
-0001f1e0: 6e6f 7420 6265 2063 616c 6c65 6420 696e  not be called in
-0001f1f0: 6465 7065 6e64 656e 746c 792c 206f 6e6c  dependently, onl
-0001f200: 7920 6974 7320 7374 6570 2061 6e64 2072  y its step and r
-0001f210: 6573 6574 206d 6574 686f 6473 2022 0d0a  eset methods "..
-0001f220: 2020 2020 2020 2020 2020 2020 2261 7265              "are
-0001f230: 2066 756e 6374 696f 6e61 6c2e 2054 6865   functional. The
-0001f240: 2072 6561 736f 6e20 666f 7220 7468 6973   reason for this
-0001f250: 2069 7320 7468 6174 2069 7420 6973 2068   is that it is h
-0001f260: 6172 6420 746f 2063 6f6e 7369 6465 7220  ard to consider 
-0001f270: 7573 696e 6720 220d 0a20 2020 2020 2020  using "..       
-0001f280: 2020 2020 2022 5469 6d65 4d61 7850 6f6f       "TimeMaxPoo
-0001f290: 6c20 7769 7468 206e 6f6e 2d73 6571 7565  l with non-seque
-0001f2a0: 6e74 6961 6c20 6461 7461 2c20 7375 6368  ntial data, such
-0001f2b0: 2061 7320 7468 6f73 6520 636f 6c6c 6563   as those collec
-0001f2c0: 7465 6420 6279 2061 2072 6570 6c61 7920  ted by a replay 
-0001f2d0: 6275 6666 6572 2022 0d0a 2020 2020 2020  buffer "..      
-0001f2e0: 2020 2020 2020 226f 7220 6120 6461 7461        "or a data
-0001f2f0: 7365 742e 2049 6620 796f 7520 6e65 6564  set. If you need
-0001f300: 2054 696d 654d 6178 506f 6f6c 2074 6f20   TimeMaxPool to 
-0001f310: 776f 726b 206f 6e20 6120 6261 7463 6820  work on a batch 
-0001f320: 6f66 2073 6571 7565 6e74 6961 6c20 6461  of sequential da
-0001f330: 7461 2022 0d0a 2020 2020 2020 2020 2020  ta "..          
-0001f340: 2020 2228 6965 2061 7320 4c53 544d 2077    "(ie as LSTM w
-0001f350: 6f75 6c64 2077 6f72 6b20 6f76 6572 2061  ould work over a
-0001f360: 2077 686f 6c65 2073 6571 7565 6e63 6520   whole sequence 
-0001f370: 6f66 2064 6174 6129 2c20 6669 6c65 2061  of data), file a
-0001f380: 6e20 6973 7375 6520 6f6e 2022 0d0a 2020  n issue on "..  
-0001f390: 2020 2020 2020 2020 2020 2254 6f72 6368            "Torch
-0001f3a0: 524c 2072 6571 7565 7374 696e 6720 7468  RL requesting th
-0001f3b0: 6174 2066 6561 7475 7265 2e22 0d0a 2020  at feature."..  
-0001f3c0: 2020 2020 2020 290d 0a0d 0a0d 0a63 6c61        )......cla
-0001f3d0: 7373 2052 616e 646f 6d43 726f 7054 656e  ss RandomCropTen
-0001f3e0: 736f 7244 6963 7428 5472 616e 7366 6f72  sorDict(Transfor
-0001f3f0: 6d29 3a0d 0a20 2020 2022 2222 4120 7472  m):..    """A tr
-0001f400: 616a 6563 746f 7279 2073 7562 2d73 616d  ajectory sub-sam
-0001f410: 706c 6572 2066 6f72 2052 6570 6c61 7942  pler for ReplayB
-0001f420: 7566 6665 7220 616e 6420 6d6f 6475 6c65  uffer and module
-0001f430: 732e 0d0a 0d0a 2020 2020 4761 7468 6572  s.....    Gather
-0001f440: 7320 6120 7375 622d 7365 7175 656e 6365  s a sub-sequence
-0001f450: 206f 6620 6120 6465 6669 6e65 6420 6c65   of a defined le
-0001f460: 6e67 7468 2061 6c6f 6e67 2074 6865 206c  ngth along the l
-0001f470: 6173 7420 6469 6d65 6e73 696f 6e20 6f66  ast dimension of
-0001f480: 2074 6865 2069 6e70 7574 0d0a 2020 2020   the input..    
-0001f490: 7465 6e73 6f72 6469 6374 2e0d 0a20 2020  tensordict...   
-0001f4a0: 2054 6869 7320 6361 6e20 6265 2075 7365   This can be use
-0001f4b0: 6420 746f 2067 6574 2063 726f 7070 6564  d to get cropped
-0001f4c0: 2074 7261 6a65 6374 6f72 6965 7320 6672   trajectories fr
-0001f4d0: 6f6d 2074 7261 6a65 6374 6f72 6965 7320  om trajectories 
-0001f4e0: 7361 6d70 6c65 640d 0a20 2020 2066 726f  sampled..    fro
-0001f4f0: 6d20 6120 5265 706c 6179 4275 6666 6572  m a ReplayBuffer
-0001f500: 2e0d 0a0d 0a20 2020 2054 6869 7320 7472  .....    This tr
-0001f510: 616e 7366 6f72 6d20 6973 2070 7269 6d61  ansform is prima
-0001f520: 7269 6c79 2064 6573 6967 6e65 6420 746f  rily designed to
-0001f530: 2062 6520 7573 6564 2077 6974 6820 7265   be used with re
-0001f540: 706c 6179 2062 7566 6665 7273 2061 6e64  play buffers and
-0001f550: 206d 6f64 756c 6573 2e0d 0a20 2020 2043   modules...    C
-0001f560: 7572 7265 6e74 6c79 2c20 6974 2063 616e  urrently, it can
-0001f570: 6e6f 7420 6265 2075 7365 6420 6173 2061  not be used as a
-0001f580: 6e20 656e 7669 726f 6e6d 656e 7420 7472  n environment tr
-0001f590: 616e 7366 6f72 6d2e 0d0a 2020 2020 446f  ansform...    Do
-0001f5a0: 206e 6f74 2068 6573 6974 6174 6520 746f   not hesitate to
-0001f5b0: 2072 6571 7565 7374 2066 6f72 2074 6869   request for thi
-0001f5c0: 7320 6265 6861 7669 6f75 7220 7468 726f  s behaviour thro
-0001f5d0: 7567 6820 616e 2069 7373 7565 2069 6620  ugh an issue if 
-0001f5e0: 7468 6973 2069 730d 0a20 2020 2064 6573  this is..    des
-0001f5f0: 6972 6564 2e0d 0a0d 0a20 2020 2041 7267  ired.....    Arg
-0001f600: 733a 0d0a 2020 2020 2020 2020 7375 625f  s:..        sub_
-0001f610: 7365 715f 6c65 6e20 2869 6e74 293a 2074  seq_len (int): t
-0001f620: 6865 206c 656e 6774 6820 6f66 2074 6865  he length of the
-0001f630: 2073 7562 2d74 7261 6a65 6374 6f72 7920   sub-trajectory 
-0001f640: 746f 2073 616d 706c 650d 0a20 2020 2020  to sample..     
-0001f650: 2020 2073 616d 706c 655f 6469 6d20 2869     sample_dim (i
-0001f660: 6e74 2c20 6f70 7469 6f6e 616c 293a 2074  nt, optional): t
-0001f670: 6865 2064 696d 656e 7369 6f6e 2061 6c6f  he dimension alo
-0001f680: 6e67 2077 6869 6368 2074 6865 2063 726f  ng which the cro
-0001f690: 7070 696e 670d 0a20 2020 2020 2020 2020  pping..         
-0001f6a0: 2020 2073 686f 756c 6420 6f63 6375 722e     should occur.
-0001f6b0: 204e 6567 6174 6976 6520 6469 6d65 6e73   Negative dimens
-0001f6c0: 696f 6e73 2073 686f 756c 6420 6265 2070  ions should be p
-0001f6d0: 7265 6665 7272 6564 2074 6f20 6d61 6b65  referred to make
-0001f6e0: 0d0a 2020 2020 2020 2020 2020 2020 7468  ..            th
-0001f6f0: 6520 7472 616e 7366 6f72 6d20 726f 6275  e transform robu
-0001f700: 7374 2074 6f20 7465 6e73 6f72 6469 6374  st to tensordict
-0001f710: 7320 6f66 2076 6172 7969 6e67 2062 6174  s of varying bat
-0001f720: 6368 2064 696d 656e 7369 6f6e 732e 0d0a  ch dimensions...
-0001f730: 2020 2020 2020 2020 2020 2020 4465 6661              Defa
-0001f740: 756c 7473 2074 6f20 2d31 2028 7468 6520  ults to -1 (the 
-0001f750: 6465 6661 756c 7420 7469 6d65 2064 696d  default time dim
-0001f760: 656e 7369 6f6e 2069 6e20 546f 7263 6852  ension in TorchR
-0001f770: 4c29 2e0d 0a20 2020 2020 2020 206d 6173  L)...        mas
-0001f780: 6b5f 6b65 7920 2873 7472 293a 2049 6620  k_key (str): If 
-0001f790: 7072 6f76 6964 6564 2c20 7468 6973 2072  provided, this r
-0001f7a0: 6570 7265 7365 6e74 7320 7468 6520 6d61  epresents the ma
-0001f7b0: 736b 206b 6579 2074 6f20 6265 206c 6f6f  sk key to be loo
-0001f7c0: 6b65 640d 0a20 2020 2020 2020 2020 2020  ked..           
-0001f7d0: 2066 6f72 2077 6865 6e20 646f 696e 6720   for when doing 
-0001f7e0: 7468 6520 7361 6d70 6c69 6e67 2e20 4966  the sampling. If
-0001f7f0: 2070 726f 7669 6465 642c 2069 7420 6f6e   provided, it on
-0001f800: 6c79 2076 616c 6964 2065 6c65 6d65 6e74  ly valid element
-0001f810: 7320 7769 6c6c 0d0a 2020 2020 2020 2020  s will..        
-0001f820: 2020 2020 6265 2072 6574 7572 6e65 642e      be returned.
-0001f830: 2049 7420 6973 2061 7373 756d 6564 2074   It is assumed t
-0001f840: 6861 7420 7468 6520 6d61 736b 2069 7320  hat the mask is 
-0001f850: 6120 626f 6f6c 6561 6e20 7465 6e73 6f72  a boolean tensor
-0001f860: 2077 6974 680d 0a20 2020 2020 2020 2020   with..         
-0001f870: 2020 2066 6972 7374 2054 7275 6520 7661     first True va
-0001f880: 6c75 6573 2061 6e64 2074 6865 6e20 4661  lues and then Fa
-0001f890: 6c73 6520 7661 6c75 6573 2c20 6e6f 7420  lse values, not 
-0001f8a0: 6d69 7865 6420 746f 6765 7468 6572 2e0d  mixed together..
-0001f8b0: 0a20 2020 2020 2020 2020 2020 203a 636c  .            :cl
-0001f8c0: 6173 733a 6052 616e 646f 6d43 726f 7054  ass:`RandomCropT
-0001f8d0: 656e 736f 7244 6963 7460 2077 696c 6c20  ensorDict` will 
-0001f8e0: 4e4f 5420 6368 6563 6b20 7468 6174 2074  NOT check that t
-0001f8f0: 6869 7320 6973 2072 6573 7065 6374 6564  his is respected
-0001f900: 0d0a 2020 2020 2020 2020 2020 2020 6865  ..            he
-0001f910: 6e63 6520 616e 7920 6572 726f 7220 6361  nce any error ca
-0001f920: 7573 6564 2062 7920 616e 2069 6d70 726f  used by an impro
-0001f930: 7065 7220 6d61 736b 2072 6973 6b73 2074  per mask risks t
-0001f940: 6f20 676f 2075 6e6e 6f74 6963 6564 2e0d  o go unnoticed..
-0001f950: 0a20 2020 2020 2020 2020 2020 2044 6566  .            Def
-0001f960: 6175 6c74 733a 204e 6f6e 6520 286e 6f20  aults: None (no 
-0001f970: 6d61 736b 206b 6579 292e 0d0a 2020 2020  mask key)...    
-0001f980: 2222 220d 0a0d 0a20 2020 2064 6566 205f  """....    def _
-0001f990: 5f69 6e69 745f 5f28 0d0a 2020 2020 2020  _init__(..      
-0001f9a0: 2020 7365 6c66 2c20 7375 625f 7365 715f    self, sub_seq_
-0001f9b0: 6c65 6e3a 2069 6e74 2c20 7361 6d70 6c65  len: int, sample
-0001f9c0: 5f64 696d 3a20 696e 7420 3d20 2d31 2c20  _dim: int = -1, 
-0001f9d0: 6d61 736b 5f6b 6579 3a20 4f70 7469 6f6e  mask_key: Option
-0001f9e0: 616c 5b73 7472 5d20 3d20 4e6f 6e65 0d0a  al[str] = None..
-0001f9f0: 2020 2020 293a 0d0a 2020 2020 2020 2020      ):..        
-0001fa00: 7365 6c66 2e73 7562 5f73 6571 5f6c 656e  self.sub_seq_len
-0001fa10: 203d 2073 7562 5f73 6571 5f6c 656e 0d0a   = sub_seq_len..
-0001fa20: 2020 2020 2020 2020 6966 2073 616d 706c          if sampl
-0001fa30: 655f 6469 6d20 3e20 303a 0d0a 2020 2020  e_dim > 0:..    
-0001fa40: 2020 2020 2020 2020 7761 726e 696e 6773          warnings
-0001fa50: 2e77 6172 6e28 0d0a 2020 2020 2020 2020  .warn(..        
-0001fa60: 2020 2020 2020 2020 2241 2070 6f73 6974          "A posit
-0001fa70: 6976 6520 7368 6170 6520 6861 7320 6265  ive shape has be
-0001fa80: 656e 2070 6173 7365 6420 746f 2074 6865  en passed to the
-0001fa90: 2052 616e 646f 6d43 726f 7054 656e 736f   RandomCropTenso
-0001faa0: 7244 6963 7420 220d 0a20 2020 2020 2020  rDict "..       
-0001fab0: 2020 2020 2020 2020 2022 636f 6e73 7472           "constr
-0001fac0: 7563 746f 722e 2054 6869 7320 6d61 7920  uctor. This may 
-0001fad0: 6861 7665 2075 6e65 7870 6563 7465 6420  have unexpected 
-0001fae0: 6265 6861 7669 6f75 7273 2077 6865 6e20  behaviours when 
-0001faf0: 7468 6520 220d 0a20 2020 2020 2020 2020  the "..         
-0001fb00: 2020 2020 2020 2022 7061 7373 6564 2074         "passed t
-0001fb10: 656e 736f 7264 6963 7473 2068 6176 6520  ensordicts have 
-0001fb20: 696e 636f 6e73 6973 7465 6e74 2062 6174  inconsistent bat
-0001fb30: 6368 2064 696d 656e 7369 6f6e 732e 2022  ch dimensions. "
-0001fb40: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-0001fb50: 2020 2246 6f72 2063 6f6e 7465 7874 2c20    "For context, 
-0001fb60: 6279 2063 6f6e 7665 6e74 696f 6e2c 2054  by convention, T
-0001fb70: 6f72 6368 524c 2063 6f6e 6361 7465 6e61  orchRL concatena
-0001fb80: 7465 7320 7469 6d65 2073 7465 7073 2022  tes time steps "
-0001fb90: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-0001fba0: 2020 2261 6c6f 6e67 2074 6865 206c 6173    "along the las
-0001fbb0: 7420 6469 6d65 6e73 696f 6e20 6f66 2074  t dimension of t
-0001fbc0: 6865 2074 656e 736f 7264 6963 742e 220d  he tensordict.".
-0001fbd0: 0a20 2020 2020 2020 2020 2020 2029 0d0a  .            )..
-0001fbe0: 2020 2020 2020 2020 7365 6c66 2e73 616d          self.sam
-0001fbf0: 706c 655f 6469 6d20 3d20 7361 6d70 6c65  ple_dim = sample
-0001fc00: 5f64 696d 0d0a 2020 2020 2020 2020 7365  _dim..        se
-0001fc10: 6c66 2e6d 6173 6b5f 6b65 7920 3d20 6d61  lf.mask_key = ma
-0001fc20: 736b 5f6b 6579 0d0a 2020 2020 2020 2020  sk_key..        
-0001fc30: 7375 7065 7228 292e 5f5f 696e 6974 5f5f  super().__init__
-0001fc40: 285b 5d29 0d0a 0d0a 2020 2020 6465 6620  ([])....    def 
-0001fc50: 666f 7277 6172 6428 7365 6c66 2c20 7465  forward(self, te
-0001fc60: 6e73 6f72 6469 6374 3a20 5465 6e73 6f72  nsordict: Tensor
-0001fc70: 4469 6374 4261 7365 2920 2d3e 2054 656e  DictBase) -> Ten
-0001fc80: 736f 7244 6963 7442 6173 653a 0d0a 2020  sorDictBase:..  
-0001fc90: 2020 2020 2020 7368 6170 6520 3d20 7465        shape = te
-0001fca0: 6e73 6f72 6469 6374 2e73 6861 7065 0d0a  nsordict.shape..
-0001fcb0: 2020 2020 2020 2020 6469 6d20 3d20 7365          dim = se
-0001fcc0: 6c66 2e73 616d 706c 655f 6469 6d0d 0a20  lf.sample_dim.. 
-0001fcd0: 2020 2020 2020 2023 2073 6861 7065 206d         # shape m
-0001fce0: 7573 7420 6861 7665 2061 7420 6c65 6173  ust have at leas
-0001fcf0: 7420 6f6e 6520 6469 6d65 6e73 696f 6e0d  t one dimension.
-0001fd00: 0a20 2020 2020 2020 2069 6620 6e6f 7420  .        if not 
-0001fd10: 6c65 6e28 7368 6170 6529 3a0d 0a20 2020  len(shape):..   
-0001fd20: 2020 2020 2020 2020 2072 6169 7365 2052           raise R
-0001fd30: 756e 7469 6d65 4572 726f 7228 0d0a 2020  untimeError(..  
-0001fd40: 2020 2020 2020 2020 2020 2020 2020 2243                "C
-0001fd50: 616e 6e6f 7420 7375 622d 7361 6d70 6c65  annot sub-sample
-0001fd60: 2066 726f 6d20 6120 7465 6e73 6f72 6469   from a tensordi
-0001fd70: 6374 2077 6974 6820 616e 2065 6d70 7479  ct with an empty
-0001fd80: 2073 6861 7065 2e22 0d0a 2020 2020 2020   shape."..      
-0001fd90: 2020 2020 2020 290d 0a20 2020 2020 2020        )..       
-0001fda0: 2069 6620 7368 6170 655b 6469 6d5d 203c   if shape[dim] <
-0001fdb0: 2073 656c 662e 7375 625f 7365 715f 6c65   self.sub_seq_le
-0001fdc0: 6e3a 0d0a 2020 2020 2020 2020 2020 2020  n:..            
-0001fdd0: 7261 6973 6520 5275 6e74 696d 6545 7272  raise RuntimeErr
-0001fde0: 6f72 280d 0a20 2020 2020 2020 2020 2020  or(..           
-0001fdf0: 2020 2020 2066 2243 616e 6e6f 7420 7361       f"Cannot sa
-0001fe00: 6d70 6c65 2074 7261 6a65 6374 6f72 6965  mple trajectorie
-0001fe10: 7320 6f66 206c 656e 6774 6820 7b73 656c  s of length {sel
-0001fe20: 662e 7375 625f 7365 715f 6c65 6e7d 2061  f.sub_seq_len} a
-0001fe30: 6c6f 6e67 220d 0a20 2020 2020 2020 2020  long"..         
-0001fe40: 2020 2020 2020 2066 2220 6469 6d65 6e73         f" dimens
-0001fe50: 696f 6e20 7b64 696d 7d20 6769 7665 6e20  ion {dim} given 
-0001fe60: 6120 7465 6e73 6f72 6469 6374 206f 6620  a tensordict of 
-0001fe70: 7368 6170 6520 220d 0a20 2020 2020 2020  shape "..       
-0001fe80: 2020 2020 2020 2020 2066 227b 7465 6e73           f"{tens
-0001fe90: 6f72 6469 6374 2e73 6861 7065 7d2e 2043  ordict.shape}. C
-0001fea0: 6f6e 7369 6465 7220 7265 6475 6369 6e67  onsider reducing
-0001feb0: 2074 6865 2073 7562 5f73 6571 5f6c 656e   the sub_seq_len
-0001fec0: 2022 0d0a 2020 2020 2020 2020 2020 2020   "..            
-0001fed0: 2020 2020 6622 7061 7261 6d65 7465 7220      f"parameter 
-0001fee0: 6f72 2069 6e63 7265 6173 6520 7361 6d70  or increase samp
-0001fef0: 6c65 206c 656e 6774 682e 220d 0a20 2020  le length."..   
-0001ff00: 2020 2020 2020 2020 2029 0d0a 2020 2020           )..    
-0001ff10: 2020 2020 6d61 785f 6964 785f 3020 3d20      max_idx_0 = 
-0001ff20: 7368 6170 655b 6469 6d5d 202d 2073 656c  shape[dim] - sel
-0001ff30: 662e 7375 625f 7365 715f 6c65 6e0d 0a20  f.sub_seq_len.. 
-0001ff40: 2020 2020 2020 2069 6478 5f73 6861 7065         idx_shape
-0001ff50: 203d 206c 6973 7428 7465 6e73 6f72 6469   = list(tensordi
-0001ff60: 6374 2e73 6861 7065 290d 0a20 2020 2020  ct.shape)..     
-0001ff70: 2020 2069 6478 5f73 6861 7065 5b64 696d     idx_shape[dim
-0001ff80: 5d20 3d20 310d 0a20 2020 2020 2020 2064  ] = 1..        d
-0001ff90: 6576 6963 6520 3d20 7465 6e73 6f72 6469  evice = tensordi
-0001ffa0: 6374 2e64 6576 6963 650d 0a20 2020 2020  ct.device..     
-0001ffb0: 2020 2069 6620 6465 7669 6365 2069 7320     if device is 
-0001ffc0: 4e6f 6e65 3a0d 0a20 2020 2020 2020 2020  None:..         
-0001ffd0: 2020 2064 6576 6963 6520 3d20 746f 7263     device = torc
-0001ffe0: 682e 6465 7669 6365 2822 6370 7522 290d  h.device("cpu").
-0001fff0: 0a20 2020 2020 2020 2069 6620 7365 6c66  .        if self
-00020000: 2e6d 6173 6b5f 6b65 7920 6973 204e 6f6e  .mask_key is Non
-00020010: 6520 6f72 2073 656c 662e 6d61 736b 5f6b  e or self.mask_k
-00020020: 6579 206e 6f74 2069 6e20 7465 6e73 6f72  ey not in tensor
-00020030: 6469 6374 2e6b 6579 7328 0d0a 2020 2020  dict.keys(..    
-00020040: 2020 2020 2020 2020 6973 696e 7374 616e          isinstan
-00020050: 6365 2873 656c 662e 6d61 736b 5f6b 6579  ce(self.mask_key
-00020060: 2c20 7475 706c 6529 0d0a 2020 2020 2020  , tuple)..      
-00020070: 2020 293a 0d0a 2020 2020 2020 2020 2020    ):..          
-00020080: 2020 6964 785f 3020 3d20 746f 7263 682e    idx_0 = torch.
-00020090: 7261 6e64 696e 7428 6d61 785f 6964 785f  randint(max_idx_
-000200a0: 302c 2069 6478 5f73 6861 7065 2c20 6465  0, idx_shape, de
-000200b0: 7669 6365 3d64 6576 6963 6529 0d0a 2020  vice=device)..  
-000200c0: 2020 2020 2020 656c 7365 3a0d 0a20 2020        else:..   
-000200d0: 2020 2020 2020 2020 2023 2067 6574 2074           # get t
-000200e0: 6865 2074 7261 6a20 6c65 6e67 7468 2066  he traj length f
-000200f0: 6f72 2065 6163 6820 656e 7472 790d 0a20  or each entry.. 
-00020100: 2020 2020 2020 2020 2020 206d 6173 6b20             mask 
-00020110: 3d20 7465 6e73 6f72 6469 6374 2e67 6574  = tensordict.get
-00020120: 2873 656c 662e 6d61 736b 5f6b 6579 290d  (self.mask_key).
-00020130: 0a20 2020 2020 2020 2020 2020 2069 6620  .            if 
-00020140: 6d61 736b 2e73 6861 7065 2021 3d20 7465  mask.shape != te
-00020150: 6e73 6f72 6469 6374 2e73 6861 7065 3a0d  nsordict.shape:.
-00020160: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00020170: 2072 6169 7365 2056 616c 7565 4572 726f   raise ValueErro
-00020180: 7228 0d0a 2020 2020 2020 2020 2020 2020  r(..            
-00020190: 2020 2020 2020 2020 2245 7870 6563 7465          "Expecte
-000201a0: 6420 6120 6d61 736b 206f 6620 7468 6520  d a mask of the 
-000201b0: 7361 6d65 2073 6861 7065 2061 7320 7468  same shape as th
-000201c0: 6520 7465 6e73 6f72 6469 6374 2e20 476f  e tensordict. Go
-000201d0: 7420 220d 0a20 2020 2020 2020 2020 2020  t "..           
-000201e0: 2020 2020 2020 2020 2066 226d 6173 6b2e           f"mask.
-000201f0: 7368 6170 653d 7b6d 6173 6b2e 7368 6170  shape={mask.shap
-00020200: 657d 2061 6e64 2074 656e 736f 7264 6963  e} and tensordic
-00020210: 742e 7368 6170 653d 220d 0a20 2020 2020  t.shape="..     
-00020220: 2020 2020 2020 2020 2020 2020 2020 2066                 f
-00020230: 227b 7465 6e73 6f72 6469 6374 2e73 6861  "{tensordict.sha
-00020240: 7065 7d20 696e 7374 6561 642e 220d 0a20  pe} instead.".. 
-00020250: 2020 2020 2020 2020 2020 2020 2020 2029                 )
-00020260: 0d0a 2020 2020 2020 2020 2020 2020 7472  ..            tr
-00020270: 616a 5f6c 656e 6774 6873 203d 206d 6173  aj_lengths = mas
-00020280: 6b2e 6375 6d73 756d 2873 656c 662e 7361  k.cumsum(self.sa
-00020290: 6d70 6c65 5f64 696d 292e 6d61 7828 7365  mple_dim).max(se
-000202a0: 6c66 2e73 616d 706c 655f 6469 6d2c 2054  lf.sample_dim, T
-000202b0: 7275 6529 5b30 5d0d 0a20 2020 2020 2020  rue)[0]..       
-000202c0: 2020 2020 2069 6620 2874 7261 6a5f 6c65       if (traj_le
-000202d0: 6e67 7468 7320 3c20 7365 6c66 2e73 7562  ngths < self.sub
-000202e0: 5f73 6571 5f6c 656e 292e 616e 7928 293a  _seq_len).any():
-000202f0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00020300: 2020 7261 6973 6520 5275 6e74 696d 6545    raise RuntimeE
-00020310: 7272 6f72 280d 0a20 2020 2020 2020 2020  rror(..         
-00020320: 2020 2020 2020 2020 2020 2066 2243 616e             f"Can
-00020330: 6e6f 7420 7361 6d70 6c65 2074 7261 6a65  not sample traje
-00020340: 6374 6f72 6965 7320 6f66 206c 656e 6774  ctories of lengt
-00020350: 6820 7b73 656c 662e 7375 625f 7365 715f  h {self.sub_seq_
-00020360: 6c65 6e7d 2077 6865 6e20 7468 6520 6d69  len} when the mi
-00020370: 6e69 6d75 6d20 220d 0a20 2020 2020 2020  nimum "..       
-00020380: 2020 2020 2020 2020 2020 2020 2066 2274               f"t
-00020390: 7261 6a65 6374 6f72 7920 6c65 6e67 7468  rajectory length
-000203a0: 2069 7320 7b74 7261 6a5f 6c65 6e67 7468   is {traj_length
-000203b0: 732e 6d69 6e28 297d 2e22 0d0a 2020 2020  s.min()}."..    
-000203c0: 2020 2020 2020 2020 2020 2020 290d 0a20              ).. 
-000203d0: 2020 2020 2020 2020 2020 2023 2074 616b             # tak
-000203e0: 6520 6120 7261 6e64 6f6d 206e 756d 6265  e a random numbe
-000203f0: 7220 6265 7477 6565 6e20 3020 616e 6420  r between 0 and 
-00020400: 7472 616a 5f6c 656e 6774 6873 202d 2073  traj_lengths - s
-00020410: 656c 662e 7375 625f 7365 715f 6c65 6e0d  elf.sub_seq_len.
-00020420: 0a20 2020 2020 2020 2020 2020 2069 6478  .            idx
-00020430: 5f30 203d 2028 0d0a 2020 2020 2020 2020  _0 = (..        
-00020440: 2020 2020 2020 2020 746f 7263 682e 7261          torch.ra
-00020450: 6e64 2869 6478 5f73 6861 7065 2c20 6465  nd(idx_shape, de
-00020460: 7669 6365 3d64 6576 6963 6529 202a 2028  vice=device) * (
-00020470: 7472 616a 5f6c 656e 6774 6873 202d 2073  traj_lengths - s
-00020480: 656c 662e 7375 625f 7365 715f 6c65 6e29  elf.sub_seq_len)
-00020490: 0d0a 2020 2020 2020 2020 2020 2020 292e  ..            ).
-000204a0: 746f 2874 6f72 6368 2e6c 6f6e 6729 0d0a  to(torch.long)..
-000204b0: 2020 2020 2020 2020 6172 616e 6765 203d          arange =
-000204c0: 2074 6f72 6368 2e61 7261 6e67 6528 7365   torch.arange(se
-000204d0: 6c66 2e73 7562 5f73 6571 5f6c 656e 2c20  lf.sub_seq_len, 
-000204e0: 6465 7669 6365 3d69 6478 5f30 2e64 6576  device=idx_0.dev
-000204f0: 6963 6529 0d0a 2020 2020 2020 2020 6172  ice)..        ar
-00020500: 616e 6765 5f73 6861 7065 203d 205b 3120  ange_shape = [1 
-00020510: 666f 7220 5f20 696e 2072 616e 6765 2874  for _ in range(t
-00020520: 656e 736f 7264 6963 742e 6e64 696d 656e  ensordict.ndimen
-00020530: 7369 6f6e 2829 295d 0d0a 2020 2020 2020  sion())]..      
-00020540: 2020 6172 616e 6765 5f73 6861 7065 5b64    arange_shape[d
-00020550: 696d 5d20 3d20 6c65 6e28 6172 616e 6765  im] = len(arange
-00020560: 290d 0a20 2020 2020 2020 2061 7261 6e67  )..        arang
-00020570: 6520 3d20 6172 616e 6765 2e76 6965 7728  e = arange.view(
-00020580: 6172 616e 6765 5f73 6861 7065 290d 0a20  arange_shape).. 
-00020590: 2020 2020 2020 2069 6478 203d 2069 6478         idx = idx
-000205a0: 5f30 202b 2061 7261 6e67 650d 0a20 2020  _0 + arange..   
-000205b0: 2020 2020 2072 6574 7572 6e20 7465 6e73       return tens
-000205c0: 6f72 6469 6374 2e67 6174 6865 7228 6469  ordict.gather(di
-000205d0: 6d3d 7365 6c66 2e73 616d 706c 655f 6469  m=self.sample_di
-000205e0: 6d2c 2069 6e64 6578 3d69 6478 290d 0a0d  m, index=idx)...
-000205f0: 0a0d 0a63 6c61 7373 2049 6e69 7454 7261  ...class InitTra
-00020600: 636b 6572 2854 7261 6e73 666f 726d 293a  cker(Transform):
-00020610: 0d0a 2020 2020 2222 2252 6573 6574 2074  ..    """Reset t
-00020620: 7261 636b 6572 2e0d 0a0d 0a20 2020 2054  racker.....    T
-00020630: 6869 7320 7472 616e 7366 6f72 6d20 706f  his transform po
-00020640: 7075 6c61 7465 7320 7468 6520 7374 6570  pulates the step
-00020650: 2f72 6573 6574 2074 656e 736f 7264 6963  /reset tensordic
-00020660: 7420 7769 7468 2061 2072 6573 6574 2074  t with a reset t
-00020670: 7261 636b 6572 2065 6e74 7279 0d0a 2020  racker entry..  
-00020680: 2020 7468 6174 2069 7320 7365 7420 746f    that is set to
-00020690: 2060 6054 7275 6560 6020 7768 656e 6576   ``True`` whenev
-000206a0: 6572 203a 6d65 7468 3a60 7e2e 7265 7365  er :meth:`~.rese
-000206b0: 7460 2069 7320 6361 6c6c 6564 2e0d 0a0d  t` is called....
-000206c0: 0a20 2020 2041 7267 733a 0d0a 2020 2020  .    Args:..    
-000206d0: 2020 2020 2069 6e69 745f 6b65 7920 2873       init_key (s
-000206e0: 7472 2c20 6f70 7469 6f6e 616c 293a 2074  tr, optional): t
-000206f0: 6865 206b 6579 2074 6f20 6265 2075 7365  he key to be use
-00020700: 6420 666f 7220 7468 6520 7472 6163 6b65  d for the tracke
-00020710: 7220 656e 7472 792e 0d0a 0d0a 2020 2020  r entry.....    
-00020720: 4578 616d 706c 6573 3a0d 0a20 2020 2020  Examples:..     
-00020730: 2020 203e 3e3e 2066 726f 6d20 746f 7263     >>> from torc
-00020740: 6872 6c2e 656e 7673 2e6c 6962 732e 6779  hrl.envs.libs.gy
-00020750: 6d20 696d 706f 7274 2047 796d 456e 760d  m import GymEnv.
-00020760: 0a20 2020 2020 2020 203e 3e3e 2065 6e76  .        >>> env
-00020770: 203d 2054 7261 6e73 666f 726d 6564 456e   = TransformedEn
-00020780: 7628 4779 6d45 6e76 2822 5065 6e64 756c  v(GymEnv("Pendul
-00020790: 756d 2d76 3122 292c 2049 6e69 7454 7261  um-v1"), InitTra
-000207a0: 636b 6572 2829 290d 0a20 2020 2020 2020  cker())..       
-000207b0: 203e 3e3e 2074 6420 3d20 656e 762e 7265   >>> td = env.re
-000207c0: 7365 7428 290d 0a20 2020 2020 2020 203e  set()..        >
-000207d0: 3e3e 2070 7269 6e74 2874 645b 2269 735f  >> print(td["is_
-000207e0: 696e 6974 225d 290d 0a20 2020 2020 2020  init"])..       
-000207f0: 2074 656e 736f 7228 5472 7565 290d 0a20   tensor(True).. 
-00020800: 2020 2020 2020 203e 3e3e 2074 6420 3d20         >>> td = 
-00020810: 656e 762e 7261 6e64 5f73 7465 7028 7464  env.rand_step(td
-00020820: 290d 0a20 2020 2020 2020 203e 3e3e 2070  )..        >>> p
-00020830: 7269 6e74 2874 645b 226e 6578 7422 2c20  rint(td["next", 
-00020840: 2269 735f 696e 6974 225d 290d 0a20 2020  "is_init"])..   
-00020850: 2020 2020 2074 656e 736f 7228 4661 6c73       tensor(Fals
-00020860: 6529 0d0a 0d0a 2020 2020 2222 220d 0a0d  e)....    """...
-00020870: 0a20 2020 2064 6566 205f 5f69 6e69 745f  .    def __init_
-00020880: 5f28 7365 6c66 2c20 696e 6974 5f6b 6579  _(self, init_key
-00020890: 3a20 626f 6f6c 203d 2022 6973 5f69 6e69  : bool = "is_ini
-000208a0: 7422 293a 0d0a 2020 2020 2020 2020 7375  t"):..        su
-000208b0: 7065 7228 292e 5f5f 696e 6974 5f5f 2869  per().__init__(i
-000208c0: 6e5f 6b65 7973 3d5b 5d2c 206f 7574 5f6b  n_keys=[], out_k
-000208d0: 6579 733d 5b69 6e69 745f 6b65 795d 290d  eys=[init_key]).
-000208e0: 0a0d 0a20 2020 2064 6566 205f 6361 6c6c  ...    def _call
-000208f0: 2873 656c 662c 2074 656e 736f 7264 6963  (self, tensordic
-00020900: 743a 2054 656e 736f 7244 6963 7442 6173  t: TensorDictBas
-00020910: 6529 202d 3e20 5465 6e73 6f72 4469 6374  e) -> TensorDict
-00020920: 4261 7365 3a0d 0a20 2020 2020 2020 2069  Base:..        i
-00020930: 6620 7365 6c66 2e6f 7574 5f6b 6579 735b  f self.out_keys[
-00020940: 305d 206e 6f74 2069 6e20 7465 6e73 6f72  0] not in tensor
-00020950: 6469 6374 2e6b 6579 7328 293a 0d0a 2020  dict.keys():..  
-00020960: 2020 2020 2020 2020 2020 6465 7669 6365            device
-00020970: 203d 2074 656e 736f 7264 6963 742e 6465   = tensordict.de
-00020980: 7669 6365 0d0a 2020 2020 2020 2020 2020  vice..          
-00020990: 2020 6966 2064 6576 6963 6520 6973 204e    if device is N
-000209a0: 6f6e 653a 0d0a 2020 2020 2020 2020 2020  one:..          
-000209b0: 2020 2020 2020 6465 7669 6365 203d 2074        device = t
-000209c0: 6f72 6368 2e64 6576 6963 6528 2263 7075  orch.device("cpu
-000209d0: 2229 0d0a 2020 2020 2020 2020 2020 2020  ")..            
-000209e0: 7465 6e73 6f72 6469 6374 2e73 6574 280d  tensordict.set(.
-000209f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00020a00: 2073 656c 662e 6f75 745f 6b65 7973 5b30   self.out_keys[0
-00020a10: 5d2c 0d0a 2020 2020 2020 2020 2020 2020  ],..            
-00020a20: 2020 2020 746f 7263 682e 7a65 726f 7328      torch.zeros(
-00020a30: 7465 6e73 6f72 6469 6374 2e73 6861 7065  tensordict.shape
-00020a40: 2c20 6465 7669 6365 3d64 6576 6963 652c  , device=device,
-00020a50: 2064 7479 7065 3d74 6f72 6368 2e62 6f6f   dtype=torch.boo
-00020a60: 6c29 2c0d 0a20 2020 2020 2020 2020 2020  l),..           
-00020a70: 2029 0d0a 2020 2020 2020 2020 7265 7475   )..        retu
-00020a80: 726e 2074 656e 736f 7264 6963 740d 0a0d  rn tensordict...
-00020a90: 0a20 2020 2064 6566 2072 6573 6574 2873  .    def reset(s
-00020aa0: 656c 662c 2074 656e 736f 7264 6963 743a  elf, tensordict:
-00020ab0: 2054 656e 736f 7244 6963 7442 6173 6529   TensorDictBase)
-00020ac0: 202d 3e20 5465 6e73 6f72 4469 6374 4261   -> TensorDictBa
-00020ad0: 7365 3a0d 0a20 2020 2020 2020 2064 6576  se:..        dev
-00020ae0: 6963 6520 3d20 7465 6e73 6f72 6469 6374  ice = tensordict
-00020af0: 2e64 6576 6963 650d 0a20 2020 2020 2020  .device..       
-00020b00: 2069 6620 6465 7669 6365 2069 7320 4e6f   if device is No
-00020b10: 6e65 3a0d 0a20 2020 2020 2020 2020 2020  ne:..           
-00020b20: 2064 6576 6963 6520 3d20 746f 7263 682e   device = torch.
-00020b30: 6465 7669 6365 2822 6370 7522 290d 0a20  device("cpu").. 
-00020b40: 2020 2020 2020 205f 7265 7365 7420 3d20         _reset = 
-00020b50: 7465 6e73 6f72 6469 6374 2e67 6574 2822  tensordict.get("
-00020b60: 5f72 6573 6574 222c 204e 6f6e 6529 0d0a  _reset", None)..
-00020b70: 2020 2020 2020 2020 6966 205f 7265 7365          if _rese
-00020b80: 7420 6973 204e 6f6e 653a 0d0a 2020 2020  t is None:..    
-00020b90: 2020 2020 2020 2020 5f72 6573 6574 203d          _reset =
-00020ba0: 2074 6f72 6368 2e6f 6e65 7328 7465 6e73   torch.ones(tens
-00020bb0: 6f72 6469 6374 2e73 6861 7065 2c20 6465  ordict.shape, de
-00020bc0: 7669 6365 3d64 6576 6963 652c 2064 7479  vice=device, dty
-00020bd0: 7065 3d74 6f72 6368 2e62 6f6f 6c29 0d0a  pe=torch.bool)..
-00020be0: 2020 2020 2020 2020 7465 6e73 6f72 6469          tensordi
-00020bf0: 6374 2e73 6574 2873 656c 662e 6f75 745f  ct.set(self.out_
-00020c00: 6b65 7973 5b30 5d2c 205f 7265 7365 742e  keys[0], _reset.
-00020c10: 636c 6f6e 6528 2929 0d0a 2020 2020 2020  clone())..      
-00020c20: 2020 7265 7475 726e 2074 656e 736f 7264    return tensord
-00020c30: 6963 740d 0a0d 0a20 2020 2064 6566 2074  ict....    def t
-00020c40: 7261 6e73 666f 726d 5f6f 6273 6572 7661  ransform_observa
-00020c50: 7469 6f6e 5f73 7065 6328 7365 6c66 2c20  tion_spec(self, 
-00020c60: 6f62 7365 7276 6174 696f 6e5f 7370 6563  observation_spec
-00020c70: 3a20 5465 6e73 6f72 5370 6563 2920 2d3e  : TensorSpec) ->
-00020c80: 2054 656e 736f 7253 7065 633a 0d0a 2020   TensorSpec:..  
-00020c90: 2020 2020 2020 6f62 7365 7276 6174 696f        observatio
-00020ca0: 6e5f 7370 6563 5b73 656c 662e 6f75 745f  n_spec[self.out_
-00020cb0: 6b65 7973 5b30 5d5d 203d 2044 6973 6372  keys[0]] = Discr
-00020cc0: 6574 6554 656e 736f 7253 7065 6328 0d0a  eteTensorSpec(..
-00020cd0: 2020 2020 2020 2020 2020 2020 322c 0d0a              2,..
-00020ce0: 2020 2020 2020 2020 2020 2020 6474 7970              dtyp
-00020cf0: 653d 746f 7263 682e 626f 6f6c 2c0d 0a20  e=torch.bool,.. 
-00020d00: 2020 2020 2020 2020 2020 2064 6576 6963             devic
-00020d10: 653d 7365 6c66 2e70 6172 656e 742e 6465  e=self.parent.de
-00020d20: 7669 6365 2c0d 0a20 2020 2020 2020 2020  vice,..         
-00020d30: 2020 2073 6861 7065 3d73 656c 662e 7061     shape=self.pa
-00020d40: 7265 6e74 2e62 6174 6368 5f73 697a 652c  rent.batch_size,
-00020d50: 0d0a 2020 2020 2020 2020 290d 0a20 2020  ..        )..   
-00020d60: 2020 2020 2072 6574 7572 6e20 6f62 7365       return obse
-00020d70: 7276 6174 696f 6e5f 7370 6563 0d0a 0d0a  rvation_spec....
-00020d80: 2020 2020 6465 6620 666f 7277 6172 6428      def forward(
-00020d90: 7365 6c66 2c20 7465 6e73 6f72 6469 6374  self, tensordict
-00020da0: 3a20 5465 6e73 6f72 4469 6374 4261 7365  : TensorDictBase
-00020db0: 2920 2d3e 2054 656e 736f 7244 6963 7442  ) -> TensorDictB
-00020dc0: 6173 653a 0d0a 2020 2020 2020 2020 7261  ase:..        ra
-00020dd0: 6973 6520 4e6f 7449 6d70 6c65 6d65 6e74  ise NotImplement
-00020de0: 6564 4572 726f 7228 0d0a 2020 2020 2020  edError(..      
-00020df0: 2020 2020 2020 464f 5257 4152 445f 4e4f        FORWARD_NO
-00020e00: 545f 494d 504c 454d 454e 5445 442e 666f  T_IMPLEMENTED.fo
-00020e10: 726d 6174 2873 656c 662e 5f5f 636c 6173  rmat(self.__clas
-00020e20: 735f 5f2e 5f5f 6e61 6d65 5f5f 290d 0a20  s__.__name__).. 
-00020e30: 2020 2020 2020 2029 0d0a 0d0a 0d0a 636c         )......cl
-00020e40: 6173 7320 5265 6e61 6d65 5472 616e 7366  ass RenameTransf
-00020e50: 6f72 6d28 5472 616e 7366 6f72 6d29 3a0d  orm(Transform):.
-00020e60: 0a20 2020 2022 2222 4120 7472 616e 7366  .    """A transf
-00020e70: 6f72 6d20 746f 2072 656e 616d 6520 656e  orm to rename en
-00020e80: 7472 6965 7320 696e 2074 6865 206f 7574  tries in the out
-00020e90: 7075 7420 7465 6e73 6f72 6469 6374 2e0d  put tensordict..
-00020ea0: 0a0d 0a20 2020 2041 7267 733a 0d0a 2020  ...    Args:..  
-00020eb0: 2020 2020 2020 696e 5f6b 6579 7320 286c        in_keys (l
-00020ec0: 6973 7420 6f66 2073 7472 2f74 7570 6c65  ist of str/tuple
-00020ed0: 7320 6f66 2073 7472 293a 2074 6865 2065  s of str): the e
-00020ee0: 6e74 7269 6573 2074 6f20 7265 6e61 6d65  ntries to rename
-00020ef0: 0d0a 2020 2020 2020 2020 6f75 745f 6b65  ..        out_ke
-00020f00: 7973 2028 6c69 7374 206f 6620 7374 722f  ys (list of str/
-00020f10: 7475 706c 6573 206f 6620 7374 7229 3a20  tuples of str): 
-00020f20: 7468 6520 6e61 6d65 206f 6620 7468 6520  the name of the 
-00020f30: 656e 7472 6965 7320 6166 7465 7220 7265  entries after re
-00020f40: 6e61 6d69 6e67 2e0d 0a20 2020 2020 2020  naming...       
-00020f50: 2069 6e5f 6b65 7973 5f69 6e76 2028 6c69   in_keys_inv (li
-00020f60: 7374 206f 6620 7374 722f 7475 706c 6573  st of str/tuples
-00020f70: 206f 6620 7374 7229 3a20 7468 6520 656e   of str): the en
-00020f80: 7472 6965 7320 746f 2072 656e 616d 6520  tries to rename 
-00020f90: 6265 666f 7265 0d0a 2020 2020 2020 2020  before..        
-00020fa0: 2020 2020 7061 7373 696e 6720 7468 6520      passing the 
-00020fb0: 696e 7075 7420 7465 6e73 6f72 6469 6374  input tensordict
-00020fc0: 2074 6f20 3a6d 6574 683a 6045 6e76 4261   to :meth:`EnvBa
-00020fd0: 7365 2e5f 7374 6570 602e 0d0a 2020 2020  se._step`...    
-00020fe0: 2020 2020 6f75 745f 6b65 7973 5f69 6e76      out_keys_inv
-00020ff0: 2028 6c69 7374 206f 6620 7374 722f 7475   (list of str/tu
-00021000: 706c 6573 206f 6620 7374 7229 3a20 7468  ples of str): th
-00021010: 6520 6e61 6d65 7320 6f66 2074 6865 2072  e names of the r
-00021020: 656e 616d 6564 0d0a 2020 2020 2020 2020  enamed..        
-00021030: 2020 2020 656e 7472 6965 7320 7061 7373      entries pass
-00021040: 6564 2074 6f20 3a6d 6574 683a 6045 6e76  ed to :meth:`Env
-00021050: 4261 7365 2e5f 7374 6570 602e 0d0a 2020  Base._step`...  
-00021060: 2020 2020 2020 6372 6561 7465 5f63 6f70        create_cop
-00021070: 7920 2862 6f6f 6c2c 206f 7074 696f 6e61  y (bool, optiona
-00021080: 6c29 3a20 6966 2060 6054 7275 6560 602c  l): if ``True``,
-00021090: 2074 6865 2065 6e74 7269 6573 2077 696c   the entries wil
-000210a0: 6c20 6265 2063 6f70 6965 640d 0a20 2020  l be copied..   
-000210b0: 2020 2020 2020 2020 2077 6974 6820 6120           with a 
-000210c0: 6469 6666 6572 656e 7420 6e61 6d65 2072  different name r
-000210d0: 6174 6865 7220 7468 616e 2062 6569 6e67  ather than being
-000210e0: 2072 656e 616d 6564 2e20 5468 6973 2061   renamed. This a
-000210f0: 6c6c 6f77 7320 666f 720d 0a20 2020 2020  llows for..     
-00021100: 2020 2020 2020 2072 656e 616d 696e 6720         renaming 
-00021110: 696d 6d75 7461 626c 6520 656e 7472 6965  immutable entrie
-00021120: 7320 7375 6368 2061 7320 6060 2272 6577  s such as ``"rew
-00021130: 6172 6422 6060 2061 6e64 2060 6022 646f  ard"`` and ``"do
-00021140: 6e65 2260 602e 0d0a 0d0a 2020 2020 4578  ne"``.....    Ex
-00021150: 616d 706c 6573 3a0d 0a20 2020 2020 2020  amples:..       
-00021160: 203e 3e3e 2066 726f 6d20 746f 7263 6872   >>> from torchr
-00021170: 6c2e 656e 7673 2e6c 6962 732e 6779 6d20  l.envs.libs.gym 
-00021180: 696d 706f 7274 2047 796d 456e 760d 0a20  import GymEnv.. 
-00021190: 2020 2020 2020 203e 3e3e 2065 6e76 203d         >>> env =
-000211a0: 2054 7261 6e73 666f 726d 6564 456e 7628   TransformedEnv(
-000211b0: 0d0a 2020 2020 2020 2020 2e2e 2e20 2020  ..        ...   
-000211c0: 2020 4779 6d45 6e76 2822 5065 6e64 756c    GymEnv("Pendul
-000211d0: 756d 2d76 3122 292c 0d0a 2020 2020 2020  um-v1"),..      
-000211e0: 2020 2e2e 2e20 2020 2020 5265 6e61 6d65    ...     Rename
-000211f0: 5472 616e 7366 6f72 6d28 5b22 6f62 7365  Transform(["obse
-00021200: 7276 6174 696f 6e22 2c20 5d2c 205b 2273  rvation", ], ["s
-00021210: 7475 6666 222c 5d2c 2063 7265 6174 655f  tuff",], create_
-00021220: 636f 7079 3d46 616c 7365 292c 0d0a 2020  copy=False),..  
-00021230: 2020 2020 2020 2e2e 2e20 290d 0a20 2020        ... )..   
-00021240: 2020 2020 203e 3e3e 2074 656e 736f 7264       >>> tensord
-00021250: 6963 7420 3d20 656e 762e 726f 6c6c 6f75  ict = env.rollou
-00021260: 7428 3329 0d0a 2020 2020 2020 2020 3e3e  t(3)..        >>
-00021270: 3e20 7072 696e 7428 7465 6e73 6f72 6469  > print(tensordi
-00021280: 6374 290d 0a20 2020 2020 2020 2054 656e  ct)..        Ten
-00021290: 736f 7244 6963 7428 0d0a 2020 2020 2020  sorDict(..      
-000212a0: 2020 2020 2020 6669 656c 6473 3d7b 0d0a        fields={..
-000212b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000212c0: 6163 7469 6f6e 3a20 5465 6e73 6f72 2873  action: Tensor(s
-000212d0: 6861 7065 3d74 6f72 6368 2e53 697a 6528  hape=torch.Size(
-000212e0: 5b33 2c20 315d 292c 2064 6576 6963 653d  [3, 1]), device=
-000212f0: 6370 752c 2064 7479 7065 3d74 6f72 6368  cpu, dtype=torch
-00021300: 2e66 6c6f 6174 3332 2c20 6973 5f73 6861  .float32, is_sha
-00021310: 7265 643d 4661 6c73 6529 2c0d 0a20 2020  red=False),..   
-00021320: 2020 2020 2020 2020 2020 2020 2064 6f6e               don
-00021330: 653a 2054 656e 736f 7228 7368 6170 653d  e: Tensor(shape=
-00021340: 746f 7263 682e 5369 7a65 285b 332c 2031  torch.Size([3, 1
-00021350: 5d29 2c20 6465 7669 6365 3d63 7075 2c20  ]), device=cpu, 
-00021360: 6474 7970 653d 746f 7263 682e 626f 6f6c  dtype=torch.bool
-00021370: 2c20 6973 5f73 6861 7265 643d 4661 6c73  , is_shared=Fals
-00021380: 6529 2c0d 0a20 2020 2020 2020 2020 2020  e),..           
-00021390: 2020 2020 206e 6578 743a 2054 656e 736f       next: Tenso
-000213a0: 7244 6963 7428 0d0a 2020 2020 2020 2020  rDict(..        
-000213b0: 2020 2020 2020 2020 2020 2020 6669 656c              fiel
-000213c0: 6473 3d7b 0d0a 2020 2020 2020 2020 2020  ds={..          
-000213d0: 2020 2020 2020 2020 2020 2020 2020 646f                do
-000213e0: 6e65 3a20 5465 6e73 6f72 2873 6861 7065  ne: Tensor(shape
-000213f0: 3d74 6f72 6368 2e53 697a 6528 5b33 2c20  =torch.Size([3, 
-00021400: 315d 292c 2064 6576 6963 653d 6370 752c  1]), device=cpu,
-00021410: 2064 7479 7065 3d74 6f72 6368 2e62 6f6f   dtype=torch.boo
-00021420: 6c2c 2069 735f 7368 6172 6564 3d46 616c  l, is_shared=Fal
-00021430: 7365 292c 0d0a 2020 2020 2020 2020 2020  se),..          
-00021440: 2020 2020 2020 2020 2020 2020 2020 7265                re
-00021450: 7761 7264 3a20 5465 6e73 6f72 2873 6861  ward: Tensor(sha
-00021460: 7065 3d74 6f72 6368 2e53 697a 6528 5b33  pe=torch.Size([3
-00021470: 2c20 315d 292c 2064 6576 6963 653d 6370  , 1]), device=cp
-00021480: 752c 2064 7479 7065 3d74 6f72 6368 2e66  u, dtype=torch.f
-00021490: 6c6f 6174 3332 2c20 6973 5f73 6861 7265  loat32, is_share
-000214a0: 643d 4661 6c73 6529 2c0d 0a20 2020 2020  d=False),..     
-000214b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000214c0: 2020 2073 7475 6666 3a20 5465 6e73 6f72     stuff: Tensor
-000214d0: 2873 6861 7065 3d74 6f72 6368 2e53 697a  (shape=torch.Siz
-000214e0: 6528 5b33 2c20 335d 292c 2064 6576 6963  e([3, 3]), devic
-000214f0: 653d 6370 752c 2064 7479 7065 3d74 6f72  e=cpu, dtype=tor
-00021500: 6368 2e66 6c6f 6174 3332 2c20 6973 5f73  ch.float32, is_s
-00021510: 6861 7265 643d 4661 6c73 6529 7d2c 0d0a  hared=False)},..
-00021520: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00021530: 2020 2020 6261 7463 685f 7369 7a65 3d74      batch_size=t
-00021540: 6f72 6368 2e53 697a 6528 5b33 5d29 2c0d  orch.Size([3]),.
-00021550: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00021560: 2020 2020 2064 6576 6963 653d 6370 752c       device=cpu,
-00021570: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00021580: 2020 2020 2020 6973 5f73 6861 7265 643d        is_shared=
-00021590: 4661 6c73 6529 2c0d 0a20 2020 2020 2020  False),..       
-000215a0: 2020 2020 2020 2020 2072 6577 6172 643a           reward:
-000215b0: 2054 656e 736f 7228 7368 6170 653d 746f   Tensor(shape=to
-000215c0: 7263 682e 5369 7a65 285b 332c 2031 5d29  rch.Size([3, 1])
-000215d0: 2c20 6465 7669 6365 3d63 7075 2c20 6474  , device=cpu, dt
-000215e0: 7970 653d 746f 7263 682e 666c 6f61 7433  ype=torch.float3
-000215f0: 322c 2069 735f 7368 6172 6564 3d46 616c  2, is_shared=Fal
-00021600: 7365 292c 0d0a 2020 2020 2020 2020 2020  se),..          
-00021610: 2020 2020 2020 7374 7566 663a 2054 656e        stuff: Ten
-00021620: 736f 7228 7368 6170 653d 746f 7263 682e  sor(shape=torch.
-00021630: 5369 7a65 285b 332c 2033 5d29 2c20 6465  Size([3, 3]), de
-00021640: 7669 6365 3d63 7075 2c20 6474 7970 653d  vice=cpu, dtype=
-00021650: 746f 7263 682e 666c 6f61 7433 322c 2069  torch.float32, i
-00021660: 735f 7368 6172 6564 3d46 616c 7365 297d  s_shared=False)}
-00021670: 2c0d 0a20 2020 2020 2020 2020 2020 2062  ,..            b
-00021680: 6174 6368 5f73 697a 653d 746f 7263 682e  atch_size=torch.
-00021690: 5369 7a65 285b 335d 292c 0d0a 2020 2020  Size([3]),..    
-000216a0: 2020 2020 2020 2020 6465 7669 6365 3d63          device=c
-000216b0: 7075 2c0d 0a20 2020 2020 2020 2020 2020  pu,..           
-000216c0: 2069 735f 7368 6172 6564 3d46 616c 7365   is_shared=False
-000216d0: 290d 0a20 2020 2020 2020 203e 3e3e 2023  )..        >>> #
-000216e0: 2069 6620 7468 6520 6f75 7470 7574 2069   if the output i
-000216f0: 7320 616c 736f 2061 6e20 696e 7075 742c  s also an input,
-00021700: 2077 6520 6e65 6564 2074 6f20 7265 6e61   we need to rena
-00021710: 6d65 2069 6620 626f 7468 2077 6179 733a  me if both ways:
-00021720: 0d0a 2020 2020 2020 2020 3e3e 3e20 6672  ..        >>> fr
-00021730: 6f6d 2074 6f72 6368 726c 2e65 6e76 732e  om torchrl.envs.
-00021740: 6c69 6273 2e62 7261 7820 696d 706f 7274  libs.brax import
-00021750: 2042 7261 7845 6e76 0d0a 2020 2020 2020   BraxEnv..      
-00021760: 2020 3e3e 3e20 656e 7620 3d20 5472 616e    >>> env = Tran
-00021770: 7366 6f72 6d65 6445 6e76 280d 0a20 2020  sformedEnv(..   
-00021780: 2020 2020 202e 2e2e 2020 2020 2042 7261       ...     Bra
-00021790: 7845 6e76 2822 6661 7374 2229 2c0d 0a20  xEnv("fast"),.. 
-000217a0: 2020 2020 2020 202e 2e2e 2020 2020 2052         ...     R
-000217b0: 656e 616d 6554 7261 6e73 666f 726d 285b  enameTransform([
-000217c0: 2273 7461 7465 225d 2c20 5b22 6e65 776e  "state"], ["newn
-000217d0: 616d 6522 5d2c 205b 2273 7461 7465 225d  ame"], ["state"]
-000217e0: 2c20 5b22 6e65 776e 616d 6522 5d29 0d0a  , ["newname"])..
-000217f0: 2020 2020 2020 2020 2e2e 2e20 290d 0a20          ... ).. 
-00021800: 2020 2020 2020 203e 3e3e 205f 203d 2065         >>> _ = e
-00021810: 6e76 2e73 6574 5f73 6565 6428 3129 0d0a  nv.set_seed(1)..
-00021820: 2020 2020 2020 2020 3e3e 3e20 7465 6e73          >>> tens
-00021830: 6f72 6469 6374 203d 2065 6e76 2e72 6f6c  ordict = env.rol
-00021840: 6c6f 7574 2833 290d 0a20 2020 2020 2020  lout(3)..       
-00021850: 203e 3e3e 2061 7373 6572 7420 226e 6577   >>> assert "new
-00021860: 6e61 6d65 2220 696e 2074 656e 736f 7264  name" in tensord
-00021870: 6963 742e 6b65 7973 2829 0d0a 2020 2020  ict.keys()..    
-00021880: 2020 2020 3e3e 3e20 6173 7365 7274 2022      >>> assert "
-00021890: 7374 6174 6522 206e 6f74 2069 6e20 7465  state" not in te
-000218a0: 6e73 6f72 6469 6374 2e6b 6579 7328 290d  nsordict.keys().
-000218b0: 0a0d 0a20 2020 2022 2222 0d0a 0d0a 2020  ...    """....  
-000218c0: 2020 6465 6620 5f5f 696e 6974 5f5f 280d    def __init__(.
-000218d0: 0a20 2020 2020 2020 2073 656c 662c 2069  .        self, i
-000218e0: 6e5f 6b65 7973 2c20 6f75 745f 6b65 7973  n_keys, out_keys
-000218f0: 2c20 696e 5f6b 6579 735f 696e 763d 4e6f  , in_keys_inv=No
-00021900: 6e65 2c20 6f75 745f 6b65 7973 5f69 6e76  ne, out_keys_inv
-00021910: 3d4e 6f6e 652c 2063 7265 6174 655f 636f  =None, create_co
-00021920: 7079 3d46 616c 7365 0d0a 2020 2020 293a  py=False..    ):
-00021930: 0d0a 2020 2020 2020 2020 6966 2022 646f  ..        if "do
-00021940: 6e65 2220 696e 2069 6e5f 6b65 7973 2061  ne" in in_keys a
-00021950: 6e64 206e 6f74 2063 7265 6174 655f 636f  nd not create_co
-00021960: 7079 3a0d 0a20 2020 2020 2020 2020 2020  py:..           
-00021970: 2072 6169 7365 2056 616c 7565 4572 726f   raise ValueErro
-00021980: 7228 0d0a 2020 2020 2020 2020 2020 2020  r(..            
-00021990: 2020 2020 2252 656e 616d 696e 6720 2764      "Renaming 'd
-000219a0: 6f6e 6527 2069 7320 6e6f 7420 616c 6c6f  one' is not allo
-000219b0: 7765 642e 2053 6574 2060 6372 6561 7465  wed. Set `create
-000219c0: 5f63 6f70 7960 2074 6f20 6054 7275 6560  _copy` to `True`
-000219d0: 2022 0d0a 2020 2020 2020 2020 2020 2020   "..            
-000219e0: 2020 2020 2274 6f20 6372 6561 7465 2061      "to create a
-000219f0: 2063 6f70 7920 6f66 2074 6865 2064 6f6e   copy of the don
-00021a00: 6520 7374 6174 652e 220d 0a20 2020 2020  e state."..     
-00021a10: 2020 2020 2020 2029 0d0a 2020 2020 2020         )..      
-00021a20: 2020 6966 2022 7265 7761 7264 2220 696e    if "reward" in
-00021a30: 2069 6e5f 6b65 7973 2061 6e64 206e 6f74   in_keys and not
-00021a40: 2063 7265 6174 655f 636f 7079 3a0d 0a20   create_copy:.. 
-00021a50: 2020 2020 2020 2020 2020 2072 6169 7365             raise
-00021a60: 2056 616c 7565 4572 726f 7228 0d0a 2020   ValueError(..  
-00021a70: 2020 2020 2020 2020 2020 2020 2020 2252                "R
-00021a80: 656e 616d 696e 6720 2772 6577 6172 6427  enaming 'reward'
-00021a90: 2069 7320 6e6f 7420 616c 6c6f 7765 642e   is not allowed.
-00021aa0: 2053 6574 2060 6372 6561 7465 5f63 6f70   Set `create_cop
-00021ab0: 7960 2074 6f20 6054 7275 6560 2022 0d0a  y` to `True` "..
-00021ac0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00021ad0: 2274 6f20 6372 6561 7465 2061 2063 6f70  "to create a cop
-00021ae0: 7920 6f66 2074 6865 2072 6577 6172 6420  y of the reward 
-00021af0: 656e 7472 792e 220d 0a20 2020 2020 2020  entry."..       
-00021b00: 2020 2020 2029 0d0a 2020 2020 2020 2020       )..        
-00021b10: 6966 2069 6e5f 6b65 7973 5f69 6e76 2069  if in_keys_inv i
-00021b20: 7320 4e6f 6e65 3a0d 0a20 2020 2020 2020  s None:..       
-00021b30: 2020 2020 2069 6e5f 6b65 7973 5f69 6e76       in_keys_inv
-00021b40: 203d 205b 5d0d 0a20 2020 2020 2020 2069   = []..        i
-00021b50: 6620 6f75 745f 6b65 7973 5f69 6e76 2069  f out_keys_inv i
-00021b60: 7320 4e6f 6e65 3a0d 0a20 2020 2020 2020  s None:..       
-00021b70: 2020 2020 206f 7574 5f6b 6579 735f 696e       out_keys_in
-00021b80: 7620 3d20 636f 7079 2869 6e5f 6b65 7973  v = copy(in_keys
-00021b90: 5f69 6e76 290d 0a20 2020 2020 2020 2073  _inv)..        s
-00021ba0: 656c 662e 6372 6561 7465 5f63 6f70 7920  elf.create_copy 
-00021bb0: 3d20 6372 6561 7465 5f63 6f70 790d 0a20  = create_copy.. 
-00021bc0: 2020 2020 2020 2073 7570 6572 2829 2e5f         super()._
-00021bd0: 5f69 6e69 745f 5f28 696e 5f6b 6579 732c  _init__(in_keys,
-00021be0: 206f 7574 5f6b 6579 732c 2069 6e5f 6b65   out_keys, in_ke
-00021bf0: 7973 5f69 6e76 2c20 6f75 745f 6b65 7973  ys_inv, out_keys
-00021c00: 5f69 6e76 290d 0a20 2020 2020 2020 2069  _inv)..        i
-00021c10: 6620 6c65 6e28 7365 6c66 2e69 6e5f 6b65  f len(self.in_ke
-00021c20: 7973 2920 213d 206c 656e 2873 656c 662e  ys) != len(self.
-00021c30: 6f75 745f 6b65 7973 293a 0d0a 2020 2020  out_keys):..    
-00021c40: 2020 2020 2020 2020 7261 6973 6520 5661          raise Va
-00021c50: 6c75 6545 7272 6f72 280d 0a20 2020 2020  lueError(..     
-00021c60: 2020 2020 2020 2020 2020 2066 2254 6865             f"The
-00021c70: 206e 756d 6265 7220 6f66 2069 6e5f 6b65   number of in_ke
-00021c80: 7973 2028 7b6c 656e 2873 656c 662e 696e  ys ({len(self.in
-00021c90: 5f6b 6579 7329 7d29 2073 686f 756c 6420  _keys)}) should 
-00021ca0: 6d61 7463 6820 7468 6520 6e75 6d62 6572  match the number
-00021cb0: 206f 6620 6f75 745f 6b65 7973 2028 7b6c   of out_keys ({l
-00021cc0: 656e 2873 656c 662e 6f75 745f 6b65 7973  en(self.out_keys
-00021cd0: 297d 292e 220d 0a20 2020 2020 2020 2020  )})."..         
-00021ce0: 2020 2029 0d0a 2020 2020 2020 2020 6966     )..        if
-00021cf0: 206c 656e 2873 656c 662e 696e 5f6b 6579   len(self.in_key
-00021d00: 735f 696e 7629 2021 3d20 6c65 6e28 7365  s_inv) != len(se
-00021d10: 6c66 2e6f 7574 5f6b 6579 735f 696e 7629  lf.out_keys_inv)
-00021d20: 3a0d 0a20 2020 2020 2020 2020 2020 2072  :..            r
-00021d30: 6169 7365 2056 616c 7565 4572 726f 7228  aise ValueError(
-00021d40: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00021d50: 2020 6622 5468 6520 6e75 6d62 6572 206f    f"The number o
-00021d60: 6620 696e 5f6b 6579 735f 696e 7620 287b  f in_keys_inv ({
-00021d70: 6c65 6e28 7365 6c66 2e69 6e5f 6b65 7973  len(self.in_keys
-00021d80: 5f69 6e76 297d 2920 7368 6f75 6c64 206d  _inv)}) should m
-00021d90: 6174 6368 2074 6865 206e 756d 6265 7220  atch the number 
-00021da0: 6f66 206f 7574 5f6b 6579 735f 696e 7620  of out_keys_inv 
-00021db0: 287b 6c65 6e28 7365 6c66 2e6f 7574 5f6b  ({len(self.out_k
-00021dc0: 6579 7329 7d29 2e22 0d0a 2020 2020 2020  eys)})."..      
-00021dd0: 2020 2020 2020 290d 0a20 2020 2020 2020        )..       
-00021de0: 2069 6620 6c65 6e28 7365 7428 6f75 745f   if len(set(out_
-00021df0: 6b65 7973 292e 696e 7465 7273 6563 7469  keys).intersecti
-00021e00: 6f6e 2869 6e5f 6b65 7973 2929 3a0d 0a20  on(in_keys)):.. 
-00021e10: 2020 2020 2020 2020 2020 2072 6169 7365             raise
-00021e20: 2056 616c 7565 4572 726f 7228 0d0a 2020   ValueError(..  
-00021e30: 2020 2020 2020 2020 2020 2020 2020 6622                f"
-00021e40: 4361 6e6e 6f74 2068 6176 6520 6d61 7463  Cannot have matc
-00021e50: 6869 6e67 2069 6e20 616e 6420 6f75 745f  hing in and out_
-00021e60: 6b65 7973 2062 6563 6175 7365 206f 7264  keys because ord
-00021e70: 6572 2069 7320 756e 636c 6561 722e 2022  er is unclear. "
-00021e80: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00021e90: 2020 6622 506c 6561 7365 2075 7365 2073    f"Please use s
-00021ea0: 6570 6172 6174 6564 2074 7261 6e73 666f  eparated transfo
-00021eb0: 726d 732e 2022 0d0a 2020 2020 2020 2020  rms. "..        
-00021ec0: 2020 2020 2020 2020 6622 476f 7420 696e          f"Got in
-00021ed0: 5f6b 6579 733d 7b69 6e5f 6b65 7973 7d20  _keys={in_keys} 
-00021ee0: 616e 6420 6f75 745f 6b65 7973 3d7b 6f75  and out_keys={ou
-00021ef0: 745f 6b65 7973 7d2e 220d 0a20 2020 2020  t_keys}."..     
-00021f00: 2020 2020 2020 2029 0d0a 0d0a 2020 2020         )....    
-00021f10: 6465 6620 5f63 616c 6c28 7365 6c66 2c20  def _call(self, 
-00021f20: 7465 6e73 6f72 6469 6374 3a20 5465 6e73  tensordict: Tens
-00021f30: 6f72 4469 6374 4261 7365 2920 2d3e 2054  orDictBase) -> T
-00021f40: 656e 736f 7244 6963 7442 6173 653a 0d0a  ensorDictBase:..
-00021f50: 2020 2020 2020 2020 6966 2073 656c 662e          if self.
-00021f60: 6372 6561 7465 5f63 6f70 793a 0d0a 2020  create_copy:..  
-00021f70: 2020 2020 2020 2020 2020 6f75 7420 3d20            out = 
-00021f80: 7465 6e73 6f72 6469 6374 2e73 656c 6563  tensordict.selec
-00021f90: 7428 2a73 656c 662e 696e 5f6b 6579 7329  t(*self.in_keys)
-00021fa0: 0d0a 2020 2020 2020 2020 2020 2020 666f  ..            fo
-00021fb0: 7220 696e 5f6b 6579 2c20 6f75 745f 6b65  r in_key, out_ke
-00021fc0: 7920 696e 207a 6970 2873 656c 662e 696e  y in zip(self.in
-00021fd0: 5f6b 6579 732c 2073 656c 662e 6f75 745f  _keys, self.out_
-00021fe0: 6b65 7973 293a 0d0a 2020 2020 2020 2020  keys):..        
-00021ff0: 2020 2020 2020 2020 6f75 742e 7265 6e61          out.rena
-00022000: 6d65 5f6b 6579 5f28 696e 5f6b 6579 2c20  me_key_(in_key, 
-00022010: 6f75 745f 6b65 7929 0d0a 2020 2020 2020  out_key)..      
-00022020: 2020 2020 2020 7465 6e73 6f72 6469 6374        tensordict
-00022030: 203d 2074 656e 736f 7264 6963 742e 7570   = tensordict.up
-00022040: 6461 7465 286f 7574 290d 0a20 2020 2020  date(out)..     
-00022050: 2020 2065 6c73 653a 0d0a 2020 2020 2020     else:..      
-00022060: 2020 2020 2020 666f 7220 696e 5f6b 6579        for in_key
-00022070: 2c20 6f75 745f 6b65 7920 696e 207a 6970  , out_key in zip
-00022080: 2873 656c 662e 696e 5f6b 6579 732c 2073  (self.in_keys, s
-00022090: 656c 662e 6f75 745f 6b65 7973 293a 0d0a  elf.out_keys):..
-000220a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000220b0: 7465 6e73 6f72 6469 6374 2e72 656e 616d  tensordict.renam
-000220c0: 655f 6b65 795f 2869 6e5f 6b65 792c 206f  e_key_(in_key, o
-000220d0: 7574 5f6b 6579 290d 0a20 2020 2020 2020  ut_key)..       
-000220e0: 2072 6574 7572 6e20 7465 6e73 6f72 6469   return tensordi
-000220f0: 6374 0d0a 0d0a 2020 2020 666f 7277 6172  ct....    forwar
-00022100: 6420 3d20 5f63 616c 6c0d 0a0d 0a20 2020  d = _call....   
-00022110: 2064 6566 205f 696e 765f 6361 6c6c 2873   def _inv_call(s
-00022120: 656c 662c 2074 656e 736f 7264 6963 743a  elf, tensordict:
-00022130: 2054 656e 736f 7244 6963 7442 6173 6529   TensorDictBase)
-00022140: 202d 3e20 5465 6e73 6f72 4469 6374 4261   -> TensorDictBa
-00022150: 7365 3a0d 0a20 2020 2020 2020 2023 206e  se:..        # n
-00022160: 6f20 696e 2d70 6c61 6365 206d 6f64 6966  o in-place modif
-00022170: 0d0a 2020 2020 2020 2020 6966 2073 656c  ..        if sel
-00022180: 662e 6372 6561 7465 5f63 6f70 793a 0d0a  f.create_copy:..
-00022190: 2020 2020 2020 2020 2020 2020 6f75 7420              out 
-000221a0: 3d20 7465 6e73 6f72 6469 6374 2e73 656c  = tensordict.sel
-000221b0: 6563 7428 2a73 656c 662e 6f75 745f 6b65  ect(*self.out_ke
-000221c0: 7973 5f69 6e76 290d 0a20 2020 2020 2020  ys_inv)..       
-000221d0: 2020 2020 2066 6f72 2069 6e5f 6b65 792c       for in_key,
-000221e0: 206f 7574 5f6b 6579 2069 6e20 7a69 7028   out_key in zip(
-000221f0: 7365 6c66 2e69 6e5f 6b65 7973 5f69 6e76  self.in_keys_inv
-00022200: 2c20 7365 6c66 2e6f 7574 5f6b 6579 735f  , self.out_keys_
-00022210: 696e 7629 3a0d 0a20 2020 2020 2020 2020  inv):..         
-00022220: 2020 2020 2020 206f 7574 2e72 656e 616d         out.renam
-00022230: 655f 6b65 795f 286f 7574 5f6b 6579 2c20  e_key_(out_key, 
-00022240: 696e 5f6b 6579 290d 0a20 2020 2020 2020  in_key)..       
-00022250: 2020 2020 2074 656e 736f 7264 6963 7420       tensordict 
-00022260: 3d20 7465 6e73 6f72 6469 6374 2e75 7064  = tensordict.upd
-00022270: 6174 6528 6f75 7429 0d0a 2020 2020 2020  ate(out)..      
-00022280: 2020 656c 7365 3a0d 0a20 2020 2020 2020    else:..       
-00022290: 2020 2020 2066 6f72 2069 6e5f 6b65 792c       for in_key,
-000222a0: 206f 7574 5f6b 6579 2069 6e20 7a69 7028   out_key in zip(
-000222b0: 7365 6c66 2e69 6e5f 6b65 7973 5f69 6e76  self.in_keys_inv
-000222c0: 2c20 7365 6c66 2e6f 7574 5f6b 6579 735f  , self.out_keys_
-000222d0: 696e 7629 3a0d 0a20 2020 2020 2020 2020  inv):..         
-000222e0: 2020 2020 2020 2074 656e 736f 7264 6963         tensordic
-000222f0: 742e 7265 6e61 6d65 5f6b 6579 5f28 6f75  t.rename_key_(ou
-00022300: 745f 6b65 792c 2069 6e5f 6b65 7929 0d0a  t_key, in_key)..
-00022310: 2020 2020 2020 2020 7265 7475 726e 2074          return t
-00022320: 656e 736f 7264 6963 740d 0a0d 0a20 2020  ensordict....   
-00022330: 2064 6566 2074 7261 6e73 666f 726d 5f6f   def transform_o
-00022340: 7574 7075 745f 7370 6563 2873 656c 662c  utput_spec(self,
-00022350: 206f 7574 7075 745f 7370 6563 3a20 436f   output_spec: Co
-00022360: 6d70 6f73 6974 6553 7065 6329 202d 3e20  mpositeSpec) -> 
-00022370: 436f 6d70 6f73 6974 6553 7065 633a 0d0a  CompositeSpec:..
-00022380: 2020 2020 2020 2020 2320 7765 206e 6565          # we nee
-00022390: 6420 746f 2063 6865 636b 2077 6865 7468  d to check wheth
-000223a0: 6572 2074 6865 7265 2061 7265 2073 7065  er there are spe
-000223b0: 6369 616c 206b 6579 730d 0a20 2020 2020  cial keys..     
-000223c0: 2020 206f 7574 7075 745f 7370 6563 203d     output_spec =
-000223d0: 206f 7574 7075 745f 7370 6563 2e63 6c6f   output_spec.clo
-000223e0: 6e65 2829 0d0a 2020 2020 2020 2020 6966  ne()..        if
-000223f0: 2022 646f 6e65 2220 696e 2073 656c 662e   "done" in self.
-00022400: 696e 5f6b 6579 733a 0d0a 2020 2020 2020  in_keys:..      
-00022410: 2020 2020 2020 666f 7220 692c 206f 7574        for i, out
-00022420: 5f6b 6579 2069 6e20 656e 756d 6572 6174  _key in enumerat
-00022430: 6528 7365 6c66 2e6f 7574 5f6b 6579 7329  e(self.out_keys)
-00022440: 3a20 2023 206e 6f71 613a 2042 3030 370d  :  # noqa: B007.
-00022450: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00022460: 2069 6620 7365 6c66 2e69 6e5f 6b65 7973   if self.in_keys
-00022470: 5b69 5d20 3d3d 2022 646f 6e65 223a 0d0a  [i] == "done":..
-00022480: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00022490: 2020 2020 6272 6561 6b0d 0a20 2020 2020      break..     
-000224a0: 2020 2020 2020 2065 6c73 653a 0d0a 2020         else:..  
-000224b0: 2020 2020 2020 2020 2020 2020 2020 7261                ra
-000224c0: 6973 6520 5275 6e74 696d 6545 7272 6f72  ise RuntimeError
-000224d0: 2822 4578 7065 6374 6564 206f 6e65 206b  ("Expected one k
-000224e0: 6579 2074 6f20 6265 2027 646f 6e65 2722  ey to be 'done'"
-000224f0: 290d 0a20 2020 2020 2020 2020 2020 206f  )..            o
-00022500: 7574 7075 745f 7370 6563 5b22 6f62 7365  utput_spec["obse
-00022510: 7276 6174 696f 6e22 5d5b 6f75 745f 6b65  rvation"][out_ke
-00022520: 795d 203d 206f 7574 7075 745f 7370 6563  y] = output_spec
-00022530: 5b22 646f 6e65 225d 2e63 6c6f 6e65 2829  ["done"].clone()
-00022540: 0d0a 2020 2020 2020 2020 6966 2022 7265  ..        if "re
-00022550: 7761 7264 2220 696e 2073 656c 662e 696e  ward" in self.in
-00022560: 5f6b 6579 733a 0d0a 2020 2020 2020 2020  _keys:..        
-00022570: 2020 2020 666f 7220 692c 206f 7574 5f6b      for i, out_k
-00022580: 6579 2069 6e20 656e 756d 6572 6174 6528  ey in enumerate(
-00022590: 7365 6c66 2e6f 7574 5f6b 6579 7329 3a20  self.out_keys): 
-000225a0: 2023 206e 6f71 613a 2042 3030 370d 0a20   # noqa: B007.. 
-000225b0: 2020 2020 2020 2020 2020 2020 2020 2069                 i
-000225c0: 6620 7365 6c66 2e69 6e5f 6b65 7973 5b69  f self.in_keys[i
-000225d0: 5d20 3d3d 2022 7265 7761 7264 223a 0d0a  ] == "reward":..
-000225e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000225f0: 2020 2020 6272 6561 6b0d 0a20 2020 2020      break..     
-00022600: 2020 2020 2020 2065 6c73 653a 0d0a 2020         else:..  
-00022610: 2020 2020 2020 2020 2020 2020 2020 7261                ra
-00022620: 6973 6520 5275 6e74 696d 6545 7272 6f72  ise RuntimeError
-00022630: 2822 4578 7065 6374 6564 206f 6e65 206b  ("Expected one k
-00022640: 6579 2074 6f20 6265 2027 7265 7761 7264  ey to be 'reward
-00022650: 2722 290d 0a20 2020 2020 2020 2020 2020  '")..           
-00022660: 206f 7574 7075 745f 7370 6563 5b22 6f62   output_spec["ob
-00022670: 7365 7276 6174 696f 6e22 5d5b 6f75 745f  servation"][out_
-00022680: 6b65 795d 203d 206f 7574 7075 745f 7370  key] = output_sp
-00022690: 6563 5b22 7265 7761 7264 225d 2e63 6c6f  ec["reward"].clo
-000226a0: 6e65 2829 0d0a 2020 2020 2020 2020 666f  ne()..        fo
-000226b0: 7220 696e 5f6b 6579 2c20 6f75 745f 6b65  r in_key, out_ke
-000226c0: 7920 696e 207a 6970 2873 656c 662e 696e  y in zip(self.in
-000226d0: 5f6b 6579 732c 2073 656c 662e 6f75 745f  _keys, self.out_
-000226e0: 6b65 7973 293a 0d0a 2020 2020 2020 2020  keys):..        
-000226f0: 2020 2020 6966 2069 6e5f 6b65 7920 696e      if in_key in
-00022700: 2028 2272 6577 6172 6422 2c20 2264 6f6e   ("reward", "don
-00022710: 6522 293a 0d0a 2020 2020 2020 2020 2020  e"):..          
-00022720: 2020 2020 2020 636f 6e74 696e 7565 0d0a        continue..
-00022730: 2020 2020 2020 2020 2020 2020 6966 206f              if o
-00022740: 7574 5f6b 6579 2069 6e20 2822 646f 6e65  ut_key in ("done
-00022750: 222c 2022 7265 7761 7264 2229 3a0d 0a20  ", "reward"):.. 
-00022760: 2020 2020 2020 2020 2020 2020 2020 206f                 o
-00022770: 7574 7075 745f 7370 6563 5b6f 7574 5f6b  utput_spec[out_k
-00022780: 6579 5d20 3d20 6f75 7470 7574 5f73 7065  ey] = output_spe
-00022790: 635b 226f 6273 6572 7661 7469 6f6e 225d  c["observation"]
-000227a0: 5b69 6e5f 6b65 795d 2e63 6c6f 6e65 2829  [in_key].clone()
-000227b0: 0d0a 2020 2020 2020 2020 2020 2020 656c  ..            el
-000227c0: 7365 3a0d 0a20 2020 2020 2020 2020 2020  se:..           
-000227d0: 2020 2020 206f 7574 7075 745f 7370 6563       output_spec
-000227e0: 5b22 6f62 7365 7276 6174 696f 6e22 5d5b  ["observation"][
-000227f0: 6f75 745f 6b65 795d 203d 206f 7574 7075  out_key] = outpu
-00022800: 745f 7370 6563 5b22 6f62 7365 7276 6174  t_spec["observat
-00022810: 696f 6e22 5d5b 0d0a 2020 2020 2020 2020  ion"][..        
-00022820: 2020 2020 2020 2020 2020 2020 696e 5f6b              in_k
-00022830: 6579 0d0a 2020 2020 2020 2020 2020 2020  ey..            
-00022840: 2020 2020 5d2e 636c 6f6e 6528 290d 0a20      ].clone().. 
-00022850: 2020 2020 2020 2020 2020 2069 6620 6e6f             if no
-00022860: 7420 7365 6c66 2e63 7265 6174 655f 636f  t self.create_co
-00022870: 7079 3a0d 0a20 2020 2020 2020 2020 2020  py:..           
-00022880: 2020 2020 2064 656c 206f 7574 7075 745f       del output_
-00022890: 7370 6563 5b22 6f62 7365 7276 6174 696f  spec["observatio
-000228a0: 6e22 5d5b 696e 5f6b 6579 5d0d 0a20 2020  n"][in_key]..   
-000228b0: 2020 2020 2072 6574 7572 6e20 6f75 7470       return outp
-000228c0: 7574 5f73 7065 630d 0a0d 0a20 2020 2064  ut_spec....    d
-000228d0: 6566 2074 7261 6e73 666f 726d 5f69 6e70  ef transform_inp
-000228e0: 7574 5f73 7065 6328 7365 6c66 2c20 696e  ut_spec(self, in
-000228f0: 7075 745f 7370 6563 3a20 436f 6d70 6f73  put_spec: Compos
-00022900: 6974 6553 7065 6329 202d 3e20 436f 6d70  iteSpec) -> Comp
-00022910: 6f73 6974 6553 7065 633a 0d0a 2020 2020  ositeSpec:..    
-00022920: 2020 2020 2320 7765 206e 6565 6420 746f      # we need to
-00022930: 2063 6865 636b 2077 6865 7468 6572 2074   check whether t
-00022940: 6865 7265 2061 7265 2073 7065 6369 616c  here are special
-00022950: 206b 6579 730d 0a20 2020 2020 2020 2069   keys..        i
-00022960: 6e70 7574 5f73 7065 6320 3d20 696e 7075  nput_spec = inpu
-00022970: 745f 7370 6563 2e63 6c6f 6e65 2829 0d0a  t_spec.clone()..
-00022980: 2020 2020 2020 2020 666f 7220 696e 5f6b          for in_k
-00022990: 6579 2c20 6f75 745f 6b65 7920 696e 207a  ey, out_key in z
-000229a0: 6970 2873 656c 662e 696e 5f6b 6579 735f  ip(self.in_keys_
-000229b0: 696e 762c 2073 656c 662e 6f75 745f 6b65  inv, self.out_ke
-000229c0: 7973 5f69 6e76 293a 0d0a 2020 2020 2020  ys_inv):..      
-000229d0: 2020 2020 2020 696e 7075 745f 7370 6563        input_spec
-000229e0: 5b6f 7574 5f6b 6579 5d20 3d20 696e 7075  [out_key] = inpu
-000229f0: 745f 7370 6563 5b69 6e5f 6b65 795d 2e63  t_spec[in_key].c
-00022a00: 6c6f 6e65 2829 0d0a 2020 2020 2020 2020  lone()..        
-00022a10: 2020 2020 6966 206e 6f74 2073 656c 662e      if not self.
-00022a20: 6372 6561 7465 5f63 6f70 793a 0d0a 2020  create_copy:..  
-00022a30: 2020 2020 2020 2020 2020 2020 2020 6465                de
-00022a40: 6c20 696e 7075 745f 7370 6563 5b69 6e5f  l input_spec[in_
-00022a50: 6b65 795d 0d0a 2020 2020 2020 2020 7265  key]..        re
-00022a60: 7475 726e 2069 6e70 7574 5f73 7065 630d  turn input_spec.
-00022a70: 0a                                       .
+0001b4c0: 2020 2020 2254 6865 206c 6561 6469 6e67      "The leading
+0001b4d0: 2073 6861 7065 206f 6620 7468 6520 7370   shape of the sp
+0001b4e0: 6563 206d 7573 7420 6d61 7463 6820 7468  ec must match th
+0001b4f0: 6520 7465 6e73 6f72 6469 6374 2773 2c20  e tensordict's, 
+0001b500: 220d 0a20 2020 2020 2020 2020 2020 2020  "..             
+0001b510: 2020 2020 2020 2022 6275 7420 6974 2064         "but it d
+0001b520: 6f65 7320 6e6f 743a 2067 6f74 2022 0d0a  oes not: got "..
+0001b530: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001b540: 2020 2020 6622 7465 6e73 6f72 6469 6374      f"tensordict
+0001b550: 2e73 6861 7065 3d7b 7465 6e73 6f72 6469  .shape={tensordi
+0001b560: 6374 2e73 6861 7065 7d20 7768 6572 6561  ct.shape} wherea
+0001b570: 7320 7b6b 6579 7d20 7370 6563 2773 2073  s {key} spec's s
+0001b580: 6861 7065 2069 7320 220d 0a20 2020 2020  hape is "..     
+0001b590: 2020 2020 2020 2020 2020 2020 2020 2066                 f
+0001b5a0: 227b 7370 6563 2e73 6861 7065 7d2e 220d  "{spec.shape}.".
+0001b5b0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001b5c0: 2029 0d0a 2020 2020 2020 2020 2020 2020   )..            
+0001b5d0: 6966 2073 656c 662e 7261 6e64 6f6d 3a0d  if self.random:.
+0001b5e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001b5f0: 2076 616c 7565 203d 2073 7065 632e 7261   value = spec.ra
+0001b600: 6e64 2829 0d0a 2020 2020 2020 2020 2020  nd()..          
+0001b610: 2020 656c 7365 3a0d 0a20 2020 2020 2020    else:..       
+0001b620: 2020 2020 2020 2020 2076 616c 7565 203d           value =
+0001b630: 2074 6f72 6368 2e66 756c 6c5f 6c69 6b65   torch.full_like
+0001b640: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
+0001b650: 2020 2020 2020 2073 7065 632e 7a65 726f         spec.zero
+0001b660: 2829 2c0d 0a20 2020 2020 2020 2020 2020  (),..           
+0001b670: 2020 2020 2020 2020 2073 656c 662e 6465           self.de
+0001b680: 6661 756c 745f 7661 6c75 652c 0d0a 2020  fault_value,..  
+0001b690: 2020 2020 2020 2020 2020 2020 2020 290d                ).
+0001b6a0: 0a20 2020 2020 2020 2020 2020 2074 656e  .            ten
+0001b6b0: 736f 7264 6963 742e 7365 7428 6b65 792c  sordict.set(key,
+0001b6c0: 2076 616c 7565 290d 0a20 2020 2020 2020   value)..       
+0001b6d0: 2072 6574 7572 6e20 7465 6e73 6f72 6469   return tensordi
+0001b6e0: 6374 0d0a 0d0a 2020 2020 6465 6620 5f73  ct....    def _s
+0001b6f0: 7465 7028 7365 6c66 2c20 7465 6e73 6f72  tep(self, tensor
+0001b700: 6469 6374 3a20 5465 6e73 6f72 4469 6374  dict: TensorDict
+0001b710: 4261 7365 2920 2d3e 2054 656e 736f 7244  Base) -> TensorD
+0001b720: 6963 7442 6173 653a 0d0a 2020 2020 2020  ictBase:..      
+0001b730: 2020 666f 7220 6b65 7920 696e 2073 656c    for key in sel
+0001b740: 662e 7072 696d 6572 732e 6b65 7973 2829  f.primers.keys()
+0001b750: 3a0d 0a20 2020 2020 2020 2020 2020 2069  :..            i
+0001b760: 6620 6973 696e 7374 616e 6365 286b 6579  f isinstance(key
+0001b770: 2c20 7374 7229 3a0d 0a20 2020 2020 2020  , str):..       
+0001b780: 2020 2020 2020 2020 206b 6579 203d 2028           key = (
+0001b790: 6b65 792c 290d 0a20 2020 2020 2020 2020  key,)..         
+0001b7a0: 2020 2074 656e 736f 7264 6963 742e 7365     tensordict.se
+0001b7b0: 7464 6566 6175 6c74 2828 226e 6578 7422  tdefault(("next"
+0001b7c0: 2c20 2a6b 6579 292c 2074 656e 736f 7264  , *key), tensord
+0001b7d0: 6963 742e 6765 7428 6b65 792c 2064 6566  ict.get(key, def
+0001b7e0: 6175 6c74 3d4e 6f6e 6529 290d 0a20 2020  ault=None))..   
+0001b7f0: 2020 2020 2072 6574 7572 6e20 7465 6e73       return tens
+0001b800: 6f72 6469 6374 0d0a 0d0a 2020 2020 6465  ordict....    de
+0001b810: 6620 7265 7365 7428 7365 6c66 2c20 7465  f reset(self, te
+0001b820: 6e73 6f72 6469 6374 3a20 5465 6e73 6f72  nsordict: Tensor
+0001b830: 4469 6374 4261 7365 2920 2d3e 2054 656e  DictBase) -> Ten
+0001b840: 736f 7244 6963 7442 6173 653a 0d0a 2020  sorDictBase:..  
+0001b850: 2020 2020 2020 2222 2253 6574 7320 7468        """Sets th
+0001b860: 6520 6465 6661 756c 7420 7661 6c75 6573  e default values
+0001b870: 2069 6e20 7468 6520 696e 7075 7420 7465   in the input te
+0001b880: 6e73 6f72 6469 6374 2e0d 0a0d 0a20 2020  nsordict.....   
+0001b890: 2020 2020 2049 6620 7468 6520 7061 7265       If the pare
+0001b8a0: 6e74 2069 7320 6261 7463 682d 6c6f 636b  nt is batch-lock
+0001b8b0: 6564 2c20 7765 2061 7373 756d 6520 7468  ed, we assume th
+0001b8c0: 6174 2074 6865 2073 7065 6373 2068 6176  at the specs hav
+0001b8d0: 6520 7468 6520 6170 7072 6f70 7269 6174  e the appropriat
+0001b8e0: 6520 6c65 6164 696e 670d 0a20 2020 2020  e leading..     
+0001b8f0: 2020 2073 6861 7065 2e20 5765 2061 6c6c     shape. We all
+0001b900: 6f77 2066 6f72 2065 7865 6375 7469 6f6e  ow for execution
+0001b910: 2077 6865 6e20 7468 6520 7061 7265 6e74   when the parent
+0001b920: 2069 7320 6d69 7373 696e 672c 2069 6e20   is missing, in 
+0001b930: 7768 6963 6820 6361 7365 2074 6865 0d0a  which case the..
+0001b940: 2020 2020 2020 2020 7370 6563 2073 6861          spec sha
+0001b950: 7065 2069 7320 6173 7375 6d65 6420 746f  pe is assumed to
+0001b960: 206d 6174 6368 2074 6865 2074 656e 736f   match the tenso
+0001b970: 7264 6963 7427 732e 0d0a 0d0a 2020 2020  rdict's.....    
+0001b980: 2020 2020 2222 220d 0a20 2020 2020 2020      """..       
+0001b990: 2073 6861 7065 203d 2028 0d0a 2020 2020   shape = (..    
+0001b9a0: 2020 2020 2020 2020 2829 0d0a 2020 2020          ()..    
+0001b9b0: 2020 2020 2020 2020 6966 2028 6e6f 7420          if (not 
+0001b9c0: 7365 6c66 2e70 6172 656e 7420 6f72 2073  self.parent or s
+0001b9d0: 656c 662e 7061 7265 6e74 2e62 6174 6368  elf.parent.batch
+0001b9e0: 5f6c 6f63 6b65 6429 0d0a 2020 2020 2020  _locked)..      
+0001b9f0: 2020 2020 2020 656c 7365 2074 656e 736f        else tenso
+0001ba00: 7264 6963 742e 6261 7463 685f 7369 7a65  rdict.batch_size
+0001ba10: 0d0a 2020 2020 2020 2020 290d 0a20 2020  ..        )..   
+0001ba20: 2020 2020 2066 6f72 206b 6579 2c20 7370       for key, sp
+0001ba30: 6563 2069 6e20 7365 6c66 2e70 7269 6d65  ec in self.prime
+0001ba40: 7273 2e69 7465 6d73 2829 3a0d 0a20 2020  rs.items():..   
+0001ba50: 2020 2020 2020 2020 2069 6620 7365 6c66           if self
+0001ba60: 2e72 616e 646f 6d3a 0d0a 2020 2020 2020  .random:..      
+0001ba70: 2020 2020 2020 2020 2020 7661 6c75 6520            value 
+0001ba80: 3d20 7370 6563 2e72 616e 6428 7368 6170  = spec.rand(shap
+0001ba90: 6529 0d0a 2020 2020 2020 2020 2020 2020  e)..            
+0001baa0: 656c 7365 3a0d 0a20 2020 2020 2020 2020  else:..         
+0001bab0: 2020 2020 2020 2076 616c 7565 203d 2074         value = t
+0001bac0: 6f72 6368 2e66 756c 6c5f 6c69 6b65 280d  orch.full_like(.
+0001bad0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001bae0: 2020 2020 2073 7065 632e 7a65 726f 2873       spec.zero(s
+0001baf0: 6861 7065 292c 0d0a 2020 2020 2020 2020  hape),..        
+0001bb00: 2020 2020 2020 2020 2020 2020 7365 6c66              self
+0001bb10: 2e64 6566 6175 6c74 5f76 616c 7565 2c0d  .default_value,.
+0001bb20: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001bb30: 2029 0d0a 2020 2020 2020 2020 2020 2020   )..            
+0001bb40: 7465 6e73 6f72 6469 6374 2e73 6574 286b  tensordict.set(k
+0001bb50: 6579 2c20 7661 6c75 6529 0d0a 2020 2020  ey, value)..    
+0001bb60: 2020 2020 7265 7475 726e 2074 656e 736f      return tenso
+0001bb70: 7264 6963 740d 0a0d 0a20 2020 2064 6566  rdict....    def
+0001bb80: 205f 5f72 6570 725f 5f28 7365 6c66 2920   __repr__(self) 
+0001bb90: 2d3e 2073 7472 3a0d 0a20 2020 2020 2020  -> str:..       
+0001bba0: 2063 6c61 7373 5f6e 616d 6520 3d20 7365   class_name = se
+0001bbb0: 6c66 2e5f 5f63 6c61 7373 5f5f 2e5f 5f6e  lf.__class__.__n
+0001bbc0: 616d 655f 5f0d 0a20 2020 2020 2020 2072  ame__..        r
+0001bbd0: 6574 7572 6e20 6622 7b63 6c61 7373 5f6e  eturn f"{class_n
+0001bbe0: 616d 657d 2870 7269 6d65 7273 3d7b 7365  ame}(primers={se
+0001bbf0: 6c66 2e70 7269 6d65 7273 7d2c 2064 6566  lf.primers}, def
+0001bc00: 6175 6c74 5f76 616c 7565 3d7b 7365 6c66  ault_value={self
+0001bc10: 2e64 6566 6175 6c74 5f76 616c 7565 7d2c  .default_value},
+0001bc20: 2072 616e 646f 6d3d 7b73 656c 662e 7261   random={self.ra
+0001bc30: 6e64 6f6d 7d29 220d 0a0d 0a0d 0a63 6c61  ndom})"......cla
+0001bc40: 7373 2050 696e 4d65 6d6f 7279 5472 616e  ss PinMemoryTran
+0001bc50: 7366 6f72 6d28 5472 616e 7366 6f72 6d29  sform(Transform)
+0001bc60: 3a0d 0a20 2020 2022 2222 4361 6c6c 7320  :..    """Calls 
+0001bc70: 7069 6e5f 6d65 6d6f 7279 206f 6e20 7468  pin_memory on th
+0001bc80: 6520 7465 6e73 6f72 6469 6374 2074 6f20  e tensordict to 
+0001bc90: 6661 6369 6c69 7461 7465 2077 7269 7469  facilitate writi
+0001bca0: 6e67 206f 6e20 4355 4441 2064 6576 6963  ng on CUDA devic
+0001bcb0: 6573 2e22 2222 0d0a 0d0a 2020 2020 6465  es."""....    de
+0001bcc0: 6620 5f5f 696e 6974 5f5f 2873 656c 6629  f __init__(self)
+0001bcd0: 3a0d 0a20 2020 2020 2020 2073 7570 6572  :..        super
+0001bce0: 2829 2e5f 5f69 6e69 745f 5f28 5b5d 290d  ().__init__([]).
+0001bcf0: 0a0d 0a20 2020 2064 6566 205f 6361 6c6c  ...    def _call
+0001bd00: 2873 656c 662c 2074 656e 736f 7264 6963  (self, tensordic
+0001bd10: 743a 2054 656e 736f 7244 6963 7442 6173  t: TensorDictBas
+0001bd20: 6529 202d 3e20 5465 6e73 6f72 4469 6374  e) -> TensorDict
+0001bd30: 4261 7365 3a0d 0a20 2020 2020 2020 2072  Base:..        r
+0001bd40: 6574 7572 6e20 7465 6e73 6f72 6469 6374  eturn tensordict
+0001bd50: 2e70 696e 5f6d 656d 6f72 7928 290d 0a0d  .pin_memory()...
+0001bd60: 0a20 2020 2066 6f72 7761 7264 203d 205f  .    forward = _
+0001bd70: 6361 6c6c 0d0a 0d0a 0d0a 6465 6620 5f73  call......def _s
+0001bd80: 756d 5f6c 6566 7428 7661 6c2c 2064 6573  um_left(val, des
+0001bd90: 7429 3a0d 0a20 2020 2077 6869 6c65 2076  t):..    while v
+0001bda0: 616c 2e6e 6469 6d65 6e73 696f 6e28 2920  al.ndimension() 
+0001bdb0: 3e20 6465 7374 2e6e 6469 6d65 6e73 696f  > dest.ndimensio
+0001bdc0: 6e28 293a 0d0a 2020 2020 2020 2020 7661  n():..        va
+0001bdd0: 6c20 3d20 7661 6c2e 7375 6d28 3029 0d0a  l = val.sum(0)..
+0001bde0: 2020 2020 7265 7475 726e 2076 616c 0d0a      return val..
+0001bdf0: 0d0a 0d0a 636c 6173 7320 6753 4445 4e6f  ....class gSDENo
+0001be00: 6973 6528 5465 6e73 6f72 4469 6374 5072  ise(TensorDictPr
+0001be10: 696d 6572 293a 0d0a 2020 2020 2222 2241  imer):..    """A
+0001be20: 2067 5344 4520 6e6f 6973 6520 696e 6974   gSDE noise init
+0001be30: 6961 6c69 7a65 722e 0d0a 0d0a 2020 2020  ializer.....    
+0001be40: 5365 6520 7468 6520 3a66 756e 633a 607e  See the :func:`~
+0001be50: 746f 7263 6872 6c2e 6d6f 6475 6c65 732e  torchrl.modules.
+0001be60: 6d6f 6465 6c73 2e65 7870 6c6f 7261 7469  models.explorati
+0001be70: 6f6e 2e67 5344 454d 6f64 756c 6527 2066  on.gSDEModule' f
+0001be80: 6f72 206d 6f72 6520 696e 666f 2e0d 0a20  or more info... 
+0001be90: 2020 2022 2222 0d0a 0d0a 2020 2020 6465     """....    de
+0001bea0: 6620 5f5f 696e 6974 5f5f 280d 0a20 2020  f __init__(..   
+0001beb0: 2020 2020 2073 656c 662c 0d0a 2020 2020       self,..    
+0001bec0: 2020 2020 7374 6174 655f 6469 6d3d 4e6f      state_dim=No
+0001bed0: 6e65 2c0d 0a20 2020 2020 2020 2061 6374  ne,..        act
+0001bee0: 696f 6e5f 6469 6d3d 4e6f 6e65 2c0d 0a20  ion_dim=None,.. 
+0001bef0: 2020 2020 2020 2073 6861 7065 3d4e 6f6e         shape=Non
+0001bf00: 652c 0d0a 2020 2020 2920 2d3e 204e 6f6e  e,..    ) -> Non
+0001bf10: 653a 0d0a 2020 2020 2020 2020 7365 6c66  e:..        self
+0001bf20: 2e73 7461 7465 5f64 696d 203d 2073 7461  .state_dim = sta
+0001bf30: 7465 5f64 696d 0d0a 2020 2020 2020 2020  te_dim..        
+0001bf40: 7365 6c66 2e61 6374 696f 6e5f 6469 6d20  self.action_dim 
+0001bf50: 3d20 6163 7469 6f6e 5f64 696d 0d0a 2020  = action_dim..  
+0001bf60: 2020 2020 2020 6966 2073 6861 7065 2069        if shape i
+0001bf70: 7320 4e6f 6e65 3a0d 0a20 2020 2020 2020  s None:..       
+0001bf80: 2020 2020 2073 6861 7065 203d 2028 290d       shape = ().
+0001bf90: 0a20 2020 2020 2020 2074 6169 6c5f 6469  .        tail_di
+0001bfa0: 6d20 3d20 280d 0a20 2020 2020 2020 2020  m = (..         
+0001bfb0: 2020 2028 312c 2920 6966 2073 7461 7465     (1,) if state
+0001bfc0: 5f64 696d 2069 7320 4e6f 6e65 206f 7220  _dim is None or 
+0001bfd0: 6163 7469 6f6e 5f64 696d 2069 7320 4e6f  action_dim is No
+0001bfe0: 6e65 2065 6c73 6520 2861 6374 696f 6e5f  ne else (action_
+0001bff0: 6469 6d2c 2073 7461 7465 5f64 696d 290d  dim, state_dim).
+0001c000: 0a20 2020 2020 2020 2029 0d0a 2020 2020  .        )..    
+0001c010: 2020 2020 7261 6e64 6f6d 203d 2073 7461      random = sta
+0001c020: 7465 5f64 696d 2069 7320 6e6f 7420 4e6f  te_dim is not No
+0001c030: 6e65 2061 6e64 2061 6374 696f 6e5f 6469  ne and action_di
+0001c040: 6d20 6973 206e 6f74 204e 6f6e 650d 0a20  m is not None.. 
+0001c050: 2020 2020 2020 2073 6861 7065 203d 2074         shape = t
+0001c060: 7570 6c65 2873 6861 7065 2920 2b20 7461  uple(shape) + ta
+0001c070: 696c 5f64 696d 0d0a 2020 2020 2020 2020  il_dim..        
+0001c080: 7072 696d 6572 7320 3d20 7b22 5f65 7073  primers = {"_eps
+0001c090: 5f67 5344 4522 3a20 556e 626f 756e 6465  _gSDE": Unbounde
+0001c0a0: 6443 6f6e 7469 6e75 6f75 7354 656e 736f  dContinuousTenso
+0001c0b0: 7253 7065 6328 7368 6170 653d 7368 6170  rSpec(shape=shap
+0001c0c0: 6529 7d0d 0a20 2020 2020 2020 2073 7570  e)}..        sup
+0001c0d0: 6572 2829 2e5f 5f69 6e69 745f 5f28 7072  er().__init__(pr
+0001c0e0: 696d 6572 733d 7072 696d 6572 732c 2072  imers=primers, r
+0001c0f0: 616e 646f 6d3d 7261 6e64 6f6d 290d 0a0d  andom=random)...
+0001c100: 0a0d 0a63 6c61 7373 2056 6563 4e6f 726d  ...class VecNorm
+0001c110: 2854 7261 6e73 666f 726d 293a 0d0a 2020  (Transform):..  
+0001c120: 2020 2222 224d 6f76 696e 6720 6176 6572    """Moving aver
+0001c130: 6167 6520 6e6f 726d 616c 697a 6174 696f  age normalizatio
+0001c140: 6e20 6c61 7965 7220 666f 7220 746f 7263  n layer for torc
+0001c150: 6872 6c20 656e 7669 726f 6e6d 656e 7473  hrl environments
+0001c160: 2e0d 0a0d 0a20 2020 2056 6563 4e6f 726d  .....    VecNorm
+0001c170: 206b 6565 7073 2074 7261 636b 206f 6620   keeps track of 
+0001c180: 7468 6520 7375 6d6d 6172 7920 7374 6174  the summary stat
+0001c190: 6973 7469 6373 206f 6620 6120 6461 7461  istics of a data
+0001c1a0: 7365 7420 746f 2073 7461 6e64 6172 6469  set to standardi
+0001c1b0: 7a65 0d0a 2020 2020 6974 206f 6e2d 7468  ze..    it on-th
+0001c1c0: 652d 666c 792e 2049 6620 7468 6520 7472  e-fly. If the tr
+0001c1d0: 616e 7366 6f72 6d20 6973 2069 6e20 2765  ansform is in 'e
+0001c1e0: 7661 6c27 206d 6f64 652c 2074 6865 2072  val' mode, the r
+0001c1f0: 756e 6e69 6e67 0d0a 2020 2020 7374 6174  unning..    stat
+0001c200: 6973 7469 6373 2061 7265 206e 6f74 2075  istics are not u
+0001c210: 7064 6174 6564 2e0d 0a0d 0a20 2020 2049  pdated.....    I
+0001c220: 6620 6d75 6c74 6970 6c65 2070 726f 6365  f multiple proce
+0001c230: 7373 6573 2061 7265 2072 756e 6e69 6e67  sses are running
+0001c240: 2061 2073 696d 696c 6172 2065 6e76 6972   a similar envir
+0001c250: 6f6e 6d65 6e74 2c20 6f6e 6520 6361 6e20  onment, one can 
+0001c260: 7061 7373 2061 0d0a 2020 2020 5465 6e73  pass a..    Tens
+0001c270: 6f72 4469 6374 4261 7365 2069 6e73 7461  orDictBase insta
+0001c280: 6e63 6520 7468 6174 2069 7320 706c 6163  nce that is plac
+0001c290: 6564 2069 6e20 7368 6172 6564 206d 656d  ed in shared mem
+0001c2a0: 6f72 793a 2069 6620 736f 2c20 6576 6572  ory: if so, ever
+0001c2b0: 7920 7469 6d65 0d0a 2020 2020 7468 6520  y time..    the 
+0001c2c0: 6e6f 726d 616c 697a 6174 696f 6e20 6c61  normalization la
+0001c2d0: 7965 7220 6973 2071 7565 7269 6564 2069  yer is queried i
+0001c2e0: 7420 7769 6c6c 2075 7064 6174 6520 7468  t will update th
+0001c2f0: 6520 7661 6c75 6573 2066 6f72 2061 6c6c  e values for all
+0001c300: 0d0a 2020 2020 7072 6f63 6573 7365 7320  ..    processes 
+0001c310: 7468 6174 2073 6861 7265 2074 6865 2073  that share the s
+0001c320: 616d 6520 7265 6665 7265 6e63 652e 0d0a  ame reference...
+0001c330: 0d0a 2020 2020 546f 2075 7365 2056 6563  ..    To use Vec
+0001c340: 4e6f 726d 2061 7420 696e 6665 7265 6e63  Norm at inferenc
+0001c350: 6520 7469 6d65 2061 6e64 2061 766f 6964  e time and avoid
+0001c360: 2075 7064 6174 696e 6720 7468 6520 7661   updating the va
+0001c370: 6c75 6573 2077 6974 6820 7468 6520 6e65  lues with the ne
+0001c380: 770d 0a20 2020 206f 6273 6572 7661 7469  w..    observati
+0001c390: 6f6e 732c 206f 6e65 2073 686f 756c 6420  ons, one should 
+0001c3a0: 7375 6273 7469 7475 7465 2074 6869 7320  substitute this 
+0001c3b0: 6c61 7965 7220 6279 2060 7665 636e 6f72  layer by `vecnor
+0001c3c0: 6d2e 746f 5f6f 6273 6572 7661 7469 6f6e  m.to_observation
+0001c3d0: 5f6e 6f72 6d28 2960 2e0d 0a0d 0a20 2020  _norm()`.....   
+0001c3e0: 2041 7267 733a 0d0a 2020 2020 2020 2020   Args:..        
+0001c3f0: 696e 5f6b 6579 7320 2869 7465 7261 626c  in_keys (iterabl
+0001c400: 6520 6f66 2073 7472 2c20 6f70 7469 6f6e  e of str, option
+0001c410: 616c 293a 206b 6579 7320 746f 2062 6520  al): keys to be 
+0001c420: 7570 6461 7465 642e 0d0a 2020 2020 2020  updated...      
+0001c430: 2020 2020 2020 6465 6661 756c 743a 205b        default: [
+0001c440: 226f 6273 6572 7661 7469 6f6e 222c 2022  "observation", "
+0001c450: 7265 7761 7264 225d 0d0a 2020 2020 2020  reward"]..      
+0001c460: 2020 7368 6172 6564 5f74 6420 2854 656e    shared_td (Ten
+0001c470: 736f 7244 6963 7442 6173 652c 206f 7074  sorDictBase, opt
+0001c480: 696f 6e61 6c29 3a20 4120 7368 6172 6564  ional): A shared
+0001c490: 2074 656e 736f 7264 6963 7420 636f 6e74   tensordict cont
+0001c4a0: 6169 6e69 6e67 2074 6865 0d0a 2020 2020  aining the..    
+0001c4b0: 2020 2020 2020 2020 6b65 7973 206f 6620          keys of 
+0001c4c0: 7468 6520 7472 616e 7366 6f72 6d2e 0d0a  the transform...
+0001c4d0: 2020 2020 2020 2020 6465 6361 7920 286e          decay (n
+0001c4e0: 756d 6265 722c 206f 7074 696f 6e61 6c29  umber, optional)
+0001c4f0: 3a20 6465 6361 7920 7261 7465 206f 6620  : decay rate of 
+0001c500: 7468 6520 6d6f 7669 6e67 2061 7665 7261  the moving avera
+0001c510: 6765 2e0d 0a20 2020 2020 2020 2020 2020  ge...           
+0001c520: 2064 6566 6175 6c74 3a20 302e 3939 0d0a   default: 0.99..
+0001c530: 2020 2020 2020 2020 6570 7320 286e 756d          eps (num
+0001c540: 6265 722c 206f 7074 696f 6e61 6c29 3a20  ber, optional): 
+0001c550: 6c6f 7765 7220 626f 756e 6420 6f66 2074  lower bound of t
+0001c560: 6865 2072 756e 6e69 6e67 2073 7461 6e64  he running stand
+0001c570: 6172 640d 0a20 2020 2020 2020 2020 2020  ard..           
+0001c580: 2064 6576 6961 7469 6f6e 2028 666f 7220   deviation (for 
+0001c590: 6e75 6d65 7269 6361 6c20 756e 6465 7266  numerical underf
+0001c5a0: 6c6f 7729 2e20 4465 6661 756c 7420 6973  low). Default is
+0001c5b0: 2031 652d 342e 0d0a 2020 2020 2020 2020   1e-4...        
+0001c5c0: 7368 6170 6573 2028 4c69 7374 5b74 6f72  shapes (List[tor
+0001c5d0: 6368 2e53 697a 655d 2c20 6f70 7469 6f6e  ch.Size], option
+0001c5e0: 616c 293a 2069 6620 7072 6f76 6964 6564  al): if provided
+0001c5f0: 2c20 7265 7072 6573 656e 7473 2074 6865  , represents the
+0001c600: 2073 6861 7065 0d0a 2020 2020 2020 2020   shape..        
+0001c610: 2020 2020 6f66 2065 6163 6820 696e 5f6b      of each in_k
+0001c620: 6579 732e 2049 7473 206c 656e 6774 6820  eys. Its length 
+0001c630: 6d75 7374 206d 6174 6368 2074 6865 206f  must match the o
+0001c640: 6e65 206f 6620 6060 696e 5f6b 6579 7360  ne of ``in_keys`
+0001c650: 602e 0d0a 2020 2020 2020 2020 2020 2020  `...            
+0001c660: 4561 6368 2073 6861 7065 206d 7573 7420  Each shape must 
+0001c670: 6d61 7463 6820 7468 6520 7472 6169 6c69  match the traili
+0001c680: 6e67 2064 696d 656e 7369 6f6e 206f 6620  ng dimension of 
+0001c690: 7468 6520 636f 7272 6573 706f 6e64 696e  the correspondin
+0001c6a0: 670d 0a20 2020 2020 2020 2020 2020 2065  g..            e
+0001c6b0: 6e74 7279 2e0d 0a20 2020 2020 2020 2020  ntry...         
+0001c6c0: 2020 2049 6620 6e6f 742c 2074 6865 2066     If not, the f
+0001c6d0: 6561 7475 7265 2064 696d 656e 7369 6f6e  eature dimension
+0001c6e0: 7320 6f66 2074 6865 2065 6e74 7279 2028  s of the entry (
+0001c6f0: 6965 2061 6c6c 2064 696d 7320 7468 6174  ie all dims that
+0001c700: 2064 6f0d 0a20 2020 2020 2020 2020 2020   do..           
+0001c710: 206e 6f74 2062 656c 6f6e 6720 746f 2074   not belong to t
+0001c720: 6865 2074 656e 736f 7264 6963 7420 6261  he tensordict ba
+0001c730: 7463 682d 7369 7a65 2920 7769 6c6c 2062  tch-size) will b
+0001c740: 6520 636f 6e73 6964 6572 6564 2061 730d  e considered as.
+0001c750: 0a20 2020 2020 2020 2020 2020 2066 6561  .            fea
+0001c760: 7475 7265 2064 696d 656e 7369 6f6e 2e0d  ture dimension..
+0001c770: 0a0d 0a20 2020 2045 7861 6d70 6c65 733a  ...    Examples:
+0001c780: 0d0a 2020 2020 2020 2020 3e3e 3e20 6672  ..        >>> fr
+0001c790: 6f6d 2074 6f72 6368 726c 2e65 6e76 732e  om torchrl.envs.
+0001c7a0: 6c69 6273 2e67 796d 2069 6d70 6f72 7420  libs.gym import 
+0001c7b0: 4779 6d45 6e76 0d0a 2020 2020 2020 2020  GymEnv..        
+0001c7c0: 3e3e 3e20 7420 3d20 5665 634e 6f72 6d28  >>> t = VecNorm(
+0001c7d0: 6465 6361 793d 302e 3929 0d0a 2020 2020  decay=0.9)..    
+0001c7e0: 2020 2020 3e3e 3e20 656e 7620 3d20 4779      >>> env = Gy
+0001c7f0: 6d45 6e76 2822 5065 6e64 756c 756d 2d76  mEnv("Pendulum-v
+0001c800: 3022 290d 0a20 2020 2020 2020 203e 3e3e  0")..        >>>
+0001c810: 2065 6e76 203d 2054 7261 6e73 666f 726d   env = Transform
+0001c820: 6564 456e 7628 656e 762c 2074 290d 0a20  edEnv(env, t).. 
+0001c830: 2020 2020 2020 203e 3e3e 2074 6473 203d         >>> tds =
+0001c840: 205b 5d0d 0a20 2020 2020 2020 203e 3e3e   []..        >>>
+0001c850: 2066 6f72 205f 2069 6e20 7261 6e67 6528   for _ in range(
+0001c860: 3130 3030 293a 0d0a 2020 2020 2020 2020  1000):..        
+0001c870: 2e2e 2e20 2020 2020 7464 203d 2065 6e76  ...     td = env
+0001c880: 2e72 616e 645f 7374 6570 2829 0d0a 2020  .rand_step()..  
+0001c890: 2020 2020 2020 2e2e 2e20 2020 2020 6966        ...     if
+0001c8a0: 2074 642e 6765 7428 2264 6f6e 6522 293a   td.get("done"):
+0001c8b0: 0d0a 2020 2020 2020 2020 2e2e 2e20 2020  ..        ...   
+0001c8c0: 2020 2020 2020 5f20 3d20 656e 762e 7265        _ = env.re
+0001c8d0: 7365 7428 290d 0a20 2020 2020 2020 202e  set()..        .
+0001c8e0: 2e2e 2020 2020 2074 6473 202b 3d20 5b74  ..     tds += [t
+0001c8f0: 645d 0d0a 2020 2020 2020 2020 3e3e 3e20  d]..        >>> 
+0001c900: 7464 7320 3d20 746f 7263 682e 7374 6163  tds = torch.stac
+0001c910: 6b28 7464 732c 2030 290d 0a20 2020 2020  k(tds, 0)..     
+0001c920: 2020 203e 3e3e 2070 7269 6e74 2828 6162     >>> print((ab
+0001c930: 7328 7464 732e 6765 7428 2822 6e65 7874  s(tds.get(("next
+0001c940: 222c 2022 6f62 7365 7276 6174 696f 6e22  ", "observation"
+0001c950: 2929 2e6d 6561 6e28 3029 293c 302e 3229  )).mean(0))<0.2)
+0001c960: 2e61 6c6c 2829 290d 0a20 2020 2020 2020  .all())..       
+0001c970: 2074 656e 736f 7228 5472 7565 290d 0a20   tensor(True).. 
+0001c980: 2020 2020 2020 203e 3e3e 2070 7269 6e74         >>> print
+0001c990: 2828 6162 7328 7464 732e 6765 7428 2822  ((abs(tds.get(("
+0001c9a0: 6e65 7874 222c 2022 6f62 7365 7276 6174  next", "observat
+0001c9b0: 696f 6e22 2929 2e73 7464 2830 292d 3129  ion")).std(0)-1)
+0001c9c0: 3c30 2e32 292e 616c 6c28 2929 0d0a 2020  <0.2).all())..  
+0001c9d0: 2020 2020 2020 7465 6e73 6f72 2854 7275        tensor(Tru
+0001c9e0: 6529 0d0a 0d0a 2020 2020 2222 220d 0a0d  e)....    """...
+0001c9f0: 0a20 2020 2064 6566 205f 5f69 6e69 745f  .    def __init_
+0001ca00: 5f28 0d0a 2020 2020 2020 2020 7365 6c66  _(..        self
+0001ca10: 2c0d 0a20 2020 2020 2020 2069 6e5f 6b65  ,..        in_ke
+0001ca20: 7973 3a20 4f70 7469 6f6e 616c 5b53 6571  ys: Optional[Seq
+0001ca30: 7565 6e63 655b 7374 725d 5d20 3d20 4e6f  uence[str]] = No
+0001ca40: 6e65 2c0d 0a20 2020 2020 2020 2073 6861  ne,..        sha
+0001ca50: 7265 645f 7464 3a20 4f70 7469 6f6e 616c  red_td: Optional
+0001ca60: 5b54 656e 736f 7244 6963 7442 6173 655d  [TensorDictBase]
+0001ca70: 203d 204e 6f6e 652c 0d0a 2020 2020 2020   = None,..      
+0001ca80: 2020 6c6f 636b 3a20 6d70 2e4c 6f63 6b20    lock: mp.Lock 
+0001ca90: 3d20 4e6f 6e65 2c0d 0a20 2020 2020 2020  = None,..       
+0001caa0: 2064 6563 6179 3a20 666c 6f61 7420 3d20   decay: float = 
+0001cab0: 302e 3939 3939 2c0d 0a20 2020 2020 2020  0.9999,..       
+0001cac0: 2065 7073 3a20 666c 6f61 7420 3d20 3165   eps: float = 1e
+0001cad0: 2d34 2c0d 0a20 2020 2020 2020 2073 6861  -4,..        sha
+0001cae0: 7065 733a 204c 6973 745b 746f 7263 682e  pes: List[torch.
+0001caf0: 5369 7a65 5d20 3d20 4e6f 6e65 2c0d 0a20  Size] = None,.. 
+0001cb00: 2020 2029 202d 3e20 4e6f 6e65 3a0d 0a20     ) -> None:.. 
+0001cb10: 2020 2020 2020 2069 6620 6c6f 636b 2069         if lock i
+0001cb20: 7320 4e6f 6e65 3a0d 0a20 2020 2020 2020  s None:..       
+0001cb30: 2020 2020 206c 6f63 6b20 3d20 6d70 2e4c       lock = mp.L
+0001cb40: 6f63 6b28 290d 0a20 2020 2020 2020 2069  ock()..        i
+0001cb50: 6620 696e 5f6b 6579 7320 6973 204e 6f6e  f in_keys is Non
+0001cb60: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
+0001cb70: 696e 5f6b 6579 7320 3d20 5b22 6f62 7365  in_keys = ["obse
+0001cb80: 7276 6174 696f 6e22 2c20 2272 6577 6172  rvation", "rewar
+0001cb90: 6422 5d0d 0a20 2020 2020 2020 2073 7570  d"]..        sup
+0001cba0: 6572 2829 2e5f 5f69 6e69 745f 5f28 696e  er().__init__(in
+0001cbb0: 5f6b 6579 7329 0d0a 2020 2020 2020 2020  _keys)..        
+0001cbc0: 7365 6c66 2e5f 7464 203d 2073 6861 7265  self._td = share
+0001cbd0: 645f 7464 0d0a 2020 2020 2020 2020 6966  d_td..        if
+0001cbe0: 2073 6861 7265 645f 7464 2069 7320 6e6f   shared_td is no
+0001cbf0: 7420 4e6f 6e65 2061 6e64 206e 6f74 2028  t None and not (
+0001cc00: 0d0a 2020 2020 2020 2020 2020 2020 7368  ..            sh
+0001cc10: 6172 6564 5f74 642e 6973 5f73 6861 7265  ared_td.is_share
+0001cc20: 6428 2920 6f72 2073 6861 7265 645f 7464  d() or shared_td
+0001cc30: 2e69 735f 6d65 6d6d 6170 2829 0d0a 2020  .is_memmap()..  
+0001cc40: 2020 2020 2020 293a 0d0a 2020 2020 2020        ):..      
+0001cc50: 2020 2020 2020 7261 6973 6520 5275 6e74        raise Runt
+0001cc60: 696d 6545 7272 6f72 280d 0a20 2020 2020  imeError(..     
+0001cc70: 2020 2020 2020 2020 2020 2022 7368 6172             "shar
+0001cc80: 6564 5f74 6420 6d75 7374 2062 6520 6569  ed_td must be ei
+0001cc90: 7468 6572 2069 6e20 7368 6172 6564 206d  ther in shared m
+0001cca0: 656d 6f72 7920 6f72 2061 206d 656d 6d61  emory or a memma
+0001ccb0: 7020 2220 2274 656e 736f 7264 6963 742e  p " "tensordict.
+0001ccc0: 220d 0a20 2020 2020 2020 2020 2020 2029  "..            )
+0001ccd0: 0d0a 2020 2020 2020 2020 6966 2073 6861  ..        if sha
+0001cce0: 7265 645f 7464 2069 7320 6e6f 7420 4e6f  red_td is not No
+0001ccf0: 6e65 3a0d 0a20 2020 2020 2020 2020 2020  ne:..           
+0001cd00: 2066 6f72 206b 6579 2069 6e20 696e 5f6b   for key in in_k
+0001cd10: 6579 733a 0d0a 2020 2020 2020 2020 2020  eys:..          
+0001cd20: 2020 2020 2020 6966 2028 0d0a 2020 2020        if (..    
+0001cd30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001cd40: 286b 6579 202b 2022 5f73 756d 2220 6e6f  (key + "_sum" no
+0001cd50: 7420 696e 2073 6861 7265 645f 7464 2e6b  t in shared_td.k
+0001cd60: 6579 7328 2929 0d0a 2020 2020 2020 2020  eys())..        
+0001cd70: 2020 2020 2020 2020 2020 2020 6f72 2028              or (
+0001cd80: 6b65 7920 2b20 225f 7373 7122 206e 6f74  key + "_ssq" not
+0001cd90: 2069 6e20 7368 6172 6564 5f74 642e 6b65   in shared_td.ke
+0001cda0: 7973 2829 290d 0a20 2020 2020 2020 2020  ys())..         
+0001cdb0: 2020 2020 2020 2020 2020 206f 7220 286b             or (k
+0001cdc0: 6579 202b 2022 5f63 6f75 6e74 2220 6e6f  ey + "_count" no
+0001cdd0: 7420 696e 2073 6861 7265 645f 7464 2e6b  t in shared_td.k
+0001cde0: 6579 7328 2929 0d0a 2020 2020 2020 2020  eys())..        
+0001cdf0: 2020 2020 2020 2020 293a 0d0a 2020 2020          ):..    
+0001ce00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ce10: 7261 6973 6520 4b65 7945 7272 6f72 280d  raise KeyError(.
+0001ce20: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001ce30: 2020 2020 2020 2020 2066 226b 6579 207b           f"key {
+0001ce40: 6b65 797d 206e 6f74 2070 7265 7365 6e74  key} not present
+0001ce50: 2069 6e20 7468 6520 7368 6172 6564 2074   in the shared t
+0001ce60: 656e 736f 7264 6963 7420 220d 0a20 2020  ensordict "..   
+0001ce70: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001ce80: 2020 2020 2066 2277 6974 6820 6b65 7973       f"with keys
+0001ce90: 207b 7368 6172 6564 5f74 642e 6b65 7973   {shared_td.keys
+0001cea0: 2829 7d22 0d0a 2020 2020 2020 2020 2020  ()}"..          
+0001ceb0: 2020 2020 2020 2020 2020 290d 0a0d 0a20            ).... 
+0001cec0: 2020 2020 2020 2073 656c 662e 6c6f 636b         self.lock
+0001ced0: 203d 206c 6f63 6b0d 0a20 2020 2020 2020   = lock..       
+0001cee0: 2073 656c 662e 6465 6361 7920 3d20 6465   self.decay = de
+0001cef0: 6361 790d 0a20 2020 2020 2020 2073 656c  cay..        sel
+0001cf00: 662e 7368 6170 6573 203d 2073 6861 7065  f.shapes = shape
+0001cf10: 730d 0a20 2020 2020 2020 2073 656c 662e  s..        self.
+0001cf20: 6570 7320 3d20 6570 730d 0a0d 0a20 2020  eps = eps....   
+0001cf30: 2064 6566 205f 6b65 795f 7374 7228 7365   def _key_str(se
+0001cf40: 6c66 2c20 6b65 7929 3a0d 0a20 2020 2020  lf, key):..     
+0001cf50: 2020 2069 6620 6e6f 7420 6973 696e 7374     if not isinst
+0001cf60: 616e 6365 286b 6579 2c20 7374 7229 3a0d  ance(key, str):.
+0001cf70: 0a20 2020 2020 2020 2020 2020 206b 6579  .            key
+0001cf80: 203d 2022 5f22 2e6a 6f69 6e28 6b65 7929   = "_".join(key)
+0001cf90: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
+0001cfa0: 206b 6579 0d0a 0d0a 2020 2020 6465 6620   key....    def 
+0001cfb0: 5f63 616c 6c28 7365 6c66 2c20 7465 6e73  _call(self, tens
+0001cfc0: 6f72 6469 6374 3a20 5465 6e73 6f72 4469  ordict: TensorDi
+0001cfd0: 6374 4261 7365 2920 2d3e 2054 656e 736f  ctBase) -> Tenso
+0001cfe0: 7244 6963 7442 6173 653a 0d0a 2020 2020  rDictBase:..    
+0001cff0: 2020 2020 6966 2073 656c 662e 6c6f 636b      if self.lock
+0001d000: 2069 7320 6e6f 7420 4e6f 6e65 3a0d 0a20   is not None:.. 
+0001d010: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+0001d020: 6c6f 636b 2e61 6371 7569 7265 2829 0d0a  lock.acquire()..
+0001d030: 0d0a 2020 2020 2020 2020 666f 7220 6b65  ..        for ke
+0001d040: 7920 696e 2073 656c 662e 696e 5f6b 6579  y in self.in_key
+0001d050: 733a 0d0a 2020 2020 2020 2020 2020 2020  s:..            
+0001d060: 6966 206b 6579 206e 6f74 2069 6e20 7465  if key not in te
+0001d070: 6e73 6f72 6469 6374 2e6b 6579 7328 696e  nsordict.keys(in
+0001d080: 636c 7564 655f 6e65 7374 6564 3d54 7275  clude_nested=Tru
+0001d090: 6529 3a0d 0a20 2020 2020 2020 2020 2020  e):..           
+0001d0a0: 2020 2020 2063 6f6e 7469 6e75 650d 0a20       continue.. 
+0001d0b0: 2020 2020 2020 2020 2020 2073 656c 662e             self.
+0001d0c0: 5f69 6e69 7428 7465 6e73 6f72 6469 6374  _init(tensordict
+0001d0d0: 2c20 6b65 7929 0d0a 2020 2020 2020 2020  , key)..        
+0001d0e0: 2020 2020 2320 7570 6461 7465 2061 6e64      # update and
+0001d0f0: 2073 7461 6e64 6172 6469 7a65 0d0a 2020   standardize..  
+0001d100: 2020 2020 2020 2020 2020 6e65 775f 7661            new_va
+0001d110: 6c20 3d20 7365 6c66 2e5f 7570 6461 7465  l = self._update
+0001d120: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
+0001d130: 2020 206b 6579 2c20 7465 6e73 6f72 6469     key, tensordi
+0001d140: 6374 2e67 6574 286b 6579 292c 204e 3d6d  ct.get(key), N=m
+0001d150: 6178 2831 2c20 7465 6e73 6f72 6469 6374  ax(1, tensordict
+0001d160: 2e6e 756d 656c 2829 290d 0a20 2020 2020  .numel())..     
+0001d170: 2020 2020 2020 2029 0d0a 0d0a 2020 2020         )....    
+0001d180: 2020 2020 2020 2020 7465 6e73 6f72 6469          tensordi
+0001d190: 6374 2e73 6574 286b 6579 2c20 6e65 775f  ct.set(key, new_
+0001d1a0: 7661 6c29 0d0a 0d0a 2020 2020 2020 2020  val)....        
+0001d1b0: 6966 2073 656c 662e 6c6f 636b 2069 7320  if self.lock is 
+0001d1c0: 6e6f 7420 4e6f 6e65 3a0d 0a20 2020 2020  not None:..     
+0001d1d0: 2020 2020 2020 2073 656c 662e 6c6f 636b         self.lock
+0001d1e0: 2e72 656c 6561 7365 2829 0d0a 0d0a 2020  .release()....  
+0001d1f0: 2020 2020 2020 7265 7475 726e 2074 656e        return ten
+0001d200: 736f 7264 6963 740d 0a0d 0a20 2020 2066  sordict....    f
+0001d210: 6f72 7761 7264 203d 205f 6361 6c6c 0d0a  orward = _call..
+0001d220: 0d0a 2020 2020 6465 6620 5f69 6e69 7428  ..    def _init(
+0001d230: 7365 6c66 2c20 7465 6e73 6f72 6469 6374  self, tensordict
+0001d240: 3a20 5465 6e73 6f72 4469 6374 4261 7365  : TensorDictBase
+0001d250: 2c20 6b65 793a 2073 7472 2920 2d3e 204e  , key: str) -> N
+0001d260: 6f6e 653a 0d0a 2020 2020 2020 2020 6b65  one:..        ke
+0001d270: 795f 7374 7220 3d20 7365 6c66 2e5f 6b65  y_str = self._ke
+0001d280: 795f 7374 7228 6b65 7929 0d0a 2020 2020  y_str(key)..    
+0001d290: 2020 2020 6966 2073 656c 662e 5f74 6420      if self._td 
+0001d2a0: 6973 204e 6f6e 6520 6f72 206b 6579 5f73  is None or key_s
+0001d2b0: 7472 202b 2022 5f73 756d 2220 6e6f 7420  tr + "_sum" not 
+0001d2c0: 696e 2073 656c 662e 5f74 642e 6b65 7973  in self._td.keys
+0001d2d0: 2829 3a0d 0a20 2020 2020 2020 2020 2020  ():..           
+0001d2e0: 2069 6620 6b65 7920 6973 206e 6f74 206b   if key is not k
+0001d2f0: 6579 5f73 7472 2061 6e64 206b 6579 5f73  ey_str and key_s
+0001d300: 7472 2069 6e20 7465 6e73 6f72 6469 6374  tr in tensordict
+0001d310: 2e6b 6579 7328 293a 0d0a 2020 2020 2020  .keys():..      
+0001d320: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
+0001d330: 5275 6e74 696d 6545 7272 6f72 280d 0a20  RuntimeError(.. 
+0001d340: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d350: 2020 2066 2243 6f6e 666c 6963 7469 6e67     f"Conflicting
+0001d360: 206b 6579 206e 616d 6573 3a20 7b6b 6579   key names: {key
+0001d370: 5f73 7472 7d20 6672 6f6d 2056 6563 4e6f  _str} from VecNo
+0001d380: 726d 2061 6e64 2069 6e70 7574 2074 656e  rm and input ten
+0001d390: 736f 7264 6963 7420 6b65 7973 2e22 0d0a  sordict keys."..
+0001d3a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d3b0: 290d 0a20 2020 2020 2020 2020 2020 2069  )..            i
+0001d3c0: 6620 7365 6c66 2e73 6861 7065 7320 6973  f self.shapes is
+0001d3d0: 204e 6f6e 653a 0d0a 2020 2020 2020 2020   None:..        
+0001d3e0: 2020 2020 2020 2020 7464 5f76 6965 7720          td_view 
+0001d3f0: 3d20 7465 6e73 6f72 6469 6374 2e76 6965  = tensordict.vie
+0001d400: 7728 2d31 290d 0a20 2020 2020 2020 2020  w(-1)..         
+0001d410: 2020 2020 2020 2074 645f 7365 6c65 6374         td_select
+0001d420: 203d 2074 645f 7669 6577 5b30 5d0d 0a20   = td_view[0].. 
+0001d430: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+0001d440: 7465 6d20 3d20 7464 5f73 656c 6563 742e  tem = td_select.
+0001d450: 6765 7428 6b65 7929 0d0a 2020 2020 2020  get(key)..      
+0001d460: 2020 2020 2020 2020 2020 6420 3d20 7b6b            d = {k
+0001d470: 6579 5f73 7472 202b 2022 5f73 756d 223a  ey_str + "_sum":
+0001d480: 2074 6f72 6368 2e7a 6572 6f73 5f6c 696b   torch.zeros_lik
+0001d490: 6528 6974 656d 297d 0d0a 2020 2020 2020  e(item)}..      
+0001d4a0: 2020 2020 2020 2020 2020 642e 7570 6461            d.upda
+0001d4b0: 7465 287b 6b65 795f 7374 7220 2b20 225f  te({key_str + "_
+0001d4c0: 7373 7122 3a20 746f 7263 682e 7a65 726f  ssq": torch.zero
+0001d4d0: 735f 6c69 6b65 2869 7465 6d29 7d29 0d0a  s_like(item)})..
+0001d4e0: 2020 2020 2020 2020 2020 2020 656c 7365              else
+0001d4f0: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
+0001d500: 2020 2069 6478 203d 2030 0d0a 2020 2020     idx = 0..    
+0001d510: 2020 2020 2020 2020 2020 2020 666f 7220              for 
+0001d520: 696e 5f6b 6579 2069 6e20 7365 6c66 2e69  in_key in self.i
+0001d530: 6e5f 6b65 7973 3a0d 0a20 2020 2020 2020  n_keys:..       
+0001d540: 2020 2020 2020 2020 2020 2020 2069 6620               if 
+0001d550: 696e 5f6b 6579 2021 3d20 6b65 793a 0d0a  in_key != key:..
+0001d560: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d570: 2020 2020 2020 2020 6964 7820 2b3d 2031          idx += 1
+0001d580: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+0001d590: 2020 2020 2020 656c 7365 3a0d 0a20 2020        else:..   
+0001d5a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d5b0: 2020 2020 2062 7265 616b 0d0a 2020 2020       break..    
+0001d5c0: 2020 2020 2020 2020 2020 2020 7368 6170              shap
+0001d5d0: 6520 3d20 7365 6c66 2e73 6861 7065 735b  e = self.shapes[
+0001d5e0: 6964 785d 0d0a 2020 2020 2020 2020 2020  idx]..          
+0001d5f0: 2020 2020 2020 6974 656d 203d 2074 656e        item = ten
+0001d600: 736f 7264 6963 742e 6765 7428 6b65 7929  sordict.get(key)
+0001d610: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+0001d620: 2020 6420 3d20 7b0d 0a20 2020 2020 2020    d = {..       
+0001d630: 2020 2020 2020 2020 2020 2020 206b 6579               key
+0001d640: 5f73 7472 0d0a 2020 2020 2020 2020 2020  _str..          
+0001d650: 2020 2020 2020 2020 2020 2b20 225f 7375            + "_su
+0001d660: 6d22 3a20 746f 7263 682e 7a65 726f 7328  m": torch.zeros(
+0001d670: 7368 6170 652c 2064 6576 6963 653d 6974  shape, device=it
+0001d680: 656d 2e64 6576 6963 652c 2064 7479 7065  em.device, dtype
+0001d690: 3d69 7465 6d2e 6474 7970 6529 0d0a 2020  =item.dtype)..  
+0001d6a0: 2020 2020 2020 2020 2020 2020 2020 7d0d                }.
+0001d6b0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001d6c0: 2064 2e75 7064 6174 6528 0d0a 2020 2020   d.update(..    
+0001d6d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d6e0: 7b0d 0a20 2020 2020 2020 2020 2020 2020  {..             
+0001d6f0: 2020 2020 2020 2020 2020 206b 6579 5f73             key_s
+0001d700: 7472 0d0a 2020 2020 2020 2020 2020 2020  tr..            
+0001d710: 2020 2020 2020 2020 2020 2020 2b20 225f              + "_
+0001d720: 7373 7122 3a20 746f 7263 682e 7a65 726f  ssq": torch.zero
+0001d730: 7328 0d0a 2020 2020 2020 2020 2020 2020  s(..            
+0001d740: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d750: 7368 6170 652c 2064 6576 6963 653d 6974  shape, device=it
+0001d760: 656d 2e64 6576 6963 652c 2064 7479 7065  em.device, dtype
+0001d770: 3d69 7465 6d2e 6474 7970 650d 0a20 2020  =item.dtype..   
+0001d780: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d790: 2020 2020 2029 0d0a 2020 2020 2020 2020       )..        
+0001d7a0: 2020 2020 2020 2020 2020 2020 7d0d 0a20              }.. 
+0001d7b0: 2020 2020 2020 2020 2020 2020 2020 2029                 )
+0001d7c0: 0d0a 0d0a 2020 2020 2020 2020 2020 2020  ....            
+0001d7d0: 642e 7570 6461 7465 280d 0a20 2020 2020  d.update(..     
+0001d7e0: 2020 2020 2020 2020 2020 207b 0d0a 2020             {..  
+0001d7f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001d800: 2020 6b65 795f 7374 720d 0a20 2020 2020    key_str..     
+0001d810: 2020 2020 2020 2020 2020 2020 2020 202b                 +
+0001d820: 2022 5f63 6f75 6e74 223a 2074 6f72 6368   "_count": torch
+0001d830: 2e7a 6572 6f73 2831 2c20 6465 7669 6365  .zeros(1, device
+0001d840: 3d69 7465 6d2e 6465 7669 6365 2c20 6474  =item.device, dt
+0001d850: 7970 653d 746f 7263 682e 666c 6f61 7429  ype=torch.float)
+0001d860: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+0001d870: 2020 7d0d 0a20 2020 2020 2020 2020 2020    }..           
+0001d880: 2029 0d0a 2020 2020 2020 2020 2020 2020   )..            
+0001d890: 6966 2073 656c 662e 5f74 6420 6973 204e  if self._td is N
+0001d8a0: 6f6e 653a 0d0a 2020 2020 2020 2020 2020  one:..          
+0001d8b0: 2020 2020 2020 7365 6c66 2e5f 7464 203d        self._td =
+0001d8c0: 2054 656e 736f 7244 6963 7428 642c 2062   TensorDict(d, b
+0001d8d0: 6174 6368 5f73 697a 653d 5b5d 290d 0a20  atch_size=[]).. 
+0001d8e0: 2020 2020 2020 2020 2020 2065 6c73 653a             else:
+0001d8f0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+0001d900: 2020 7365 6c66 2e5f 7464 2e75 7064 6174    self._td.updat
+0001d910: 6528 6429 0d0a 2020 2020 2020 2020 656c  e(d)..        el
+0001d920: 7365 3a0d 0a20 2020 2020 2020 2020 2020  se:..           
+0001d930: 2070 6173 730d 0a0d 0a20 2020 2064 6566   pass....    def
+0001d940: 205f 7570 6461 7465 2873 656c 662c 206b   _update(self, k
+0001d950: 6579 2c20 7661 6c75 652c 204e 2920 2d3e  ey, value, N) ->
+0001d960: 2074 6f72 6368 2e54 656e 736f 723a 0d0a   torch.Tensor:..
+0001d970: 2020 2020 2020 2020 6b65 7920 3d20 7365          key = se
+0001d980: 6c66 2e5f 6b65 795f 7374 7228 6b65 7929  lf._key_str(key)
+0001d990: 0d0a 2020 2020 2020 2020 5f73 756d 203d  ..        _sum =
+0001d9a0: 2073 656c 662e 5f74 642e 6765 7428 6b65   self._td.get(ke
+0001d9b0: 7920 2b20 225f 7375 6d22 290d 0a20 2020  y + "_sum")..   
+0001d9c0: 2020 2020 205f 7373 7120 3d20 7365 6c66       _ssq = self
+0001d9d0: 2e5f 7464 2e67 6574 286b 6579 202b 2022  ._td.get(key + "
+0001d9e0: 5f73 7371 2229 0d0a 2020 2020 2020 2020  _ssq")..        
+0001d9f0: 5f63 6f75 6e74 203d 2073 656c 662e 5f74  _count = self._t
+0001da00: 642e 6765 7428 6b65 7920 2b20 225f 636f  d.get(key + "_co
+0001da10: 756e 7422 290d 0a0d 0a20 2020 2020 2020  unt")....       
+0001da20: 205f 7375 6d20 3d20 7365 6c66 2e5f 7464   _sum = self._td
+0001da30: 2e67 6574 286b 6579 202b 2022 5f73 756d  .get(key + "_sum
+0001da40: 2229 0d0a 2020 2020 2020 2020 7661 6c75  ")..        valu
+0001da50: 655f 7375 6d20 3d20 5f73 756d 5f6c 6566  e_sum = _sum_lef
+0001da60: 7428 7661 6c75 652c 205f 7375 6d29 0d0a  t(value, _sum)..
+0001da70: 2020 2020 2020 2020 5f73 756d 202a 3d20          _sum *= 
+0001da80: 7365 6c66 2e64 6563 6179 0d0a 2020 2020  self.decay..    
+0001da90: 2020 2020 5f73 756d 202b 3d20 7661 6c75      _sum += valu
+0001daa0: 655f 7375 6d0d 0a20 2020 2020 2020 2073  e_sum..        s
+0001dab0: 656c 662e 5f74 642e 7365 745f 280d 0a20  elf._td.set_(.. 
+0001dac0: 2020 2020 2020 2020 2020 206b 6579 202b             key +
+0001dad0: 2022 5f73 756d 222c 0d0a 2020 2020 2020   "_sum",..      
+0001dae0: 2020 2020 2020 5f73 756d 2c0d 0a20 2020        _sum,..   
+0001daf0: 2020 2020 2029 0d0a 0d0a 2020 2020 2020       )....      
+0001db00: 2020 5f73 7371 203d 2073 656c 662e 5f74    _ssq = self._t
+0001db10: 642e 6765 7428 6b65 7920 2b20 225f 7373  d.get(key + "_ss
+0001db20: 7122 290d 0a20 2020 2020 2020 2076 616c  q")..        val
+0001db30: 7565 5f73 7371 203d 205f 7375 6d5f 6c65  ue_ssq = _sum_le
+0001db40: 6674 2876 616c 7565 2e70 6f77 2832 292c  ft(value.pow(2),
+0001db50: 205f 7373 7129 0d0a 2020 2020 2020 2020   _ssq)..        
+0001db60: 5f73 7371 202a 3d20 7365 6c66 2e64 6563  _ssq *= self.dec
+0001db70: 6179 0d0a 2020 2020 2020 2020 5f73 7371  ay..        _ssq
+0001db80: 202b 3d20 7661 6c75 655f 7373 710d 0a20   += value_ssq.. 
+0001db90: 2020 2020 2020 2073 656c 662e 5f74 642e         self._td.
+0001dba0: 7365 745f 280d 0a20 2020 2020 2020 2020  set_(..         
+0001dbb0: 2020 206b 6579 202b 2022 5f73 7371 222c     key + "_ssq",
+0001dbc0: 0d0a 2020 2020 2020 2020 2020 2020 5f73  ..            _s
+0001dbd0: 7371 2c0d 0a20 2020 2020 2020 2029 0d0a  sq,..        )..
+0001dbe0: 0d0a 2020 2020 2020 2020 5f63 6f75 6e74  ..        _count
+0001dbf0: 203d 2073 656c 662e 5f74 642e 6765 7428   = self._td.get(
+0001dc00: 6b65 7920 2b20 225f 636f 756e 7422 290d  key + "_count").
+0001dc10: 0a20 2020 2020 2020 205f 636f 756e 7420  .        _count 
+0001dc20: 2a3d 2073 656c 662e 6465 6361 790d 0a20  *= self.decay.. 
+0001dc30: 2020 2020 2020 205f 636f 756e 7420 2b3d         _count +=
+0001dc40: 204e 0d0a 2020 2020 2020 2020 7365 6c66   N..        self
+0001dc50: 2e5f 7464 2e73 6574 5f28 0d0a 2020 2020  ._td.set_(..    
+0001dc60: 2020 2020 2020 2020 6b65 7920 2b20 225f          key + "_
+0001dc70: 636f 756e 7422 2c0d 0a20 2020 2020 2020  count",..       
+0001dc80: 2020 2020 205f 636f 756e 742c 0d0a 2020       _count,..  
+0001dc90: 2020 2020 2020 290d 0a0d 0a20 2020 2020        )....     
+0001dca0: 2020 206d 6561 6e20 3d20 5f73 756d 202f     mean = _sum /
+0001dcb0: 205f 636f 756e 740d 0a20 2020 2020 2020   _count..       
+0001dcc0: 2073 7464 203d 2028 5f73 7371 202f 205f   std = (_ssq / _
+0001dcd0: 636f 756e 7420 2d20 6d65 616e 2e70 6f77  count - mean.pow
+0001dce0: 2832 2929 2e63 6c61 6d70 5f6d 696e 2873  (2)).clamp_min(s
+0001dcf0: 656c 662e 6570 7329 2e73 7172 7428 290d  elf.eps).sqrt().
+0001dd00: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+0001dd10: 2876 616c 7565 202d 206d 6561 6e29 202f  (value - mean) /
+0001dd20: 2073 7464 2e63 6c61 6d70 5f6d 696e 2873   std.clamp_min(s
+0001dd30: 656c 662e 6570 7329 0d0a 0d0a 2020 2020  elf.eps)....    
+0001dd40: 6465 6620 746f 5f6f 6273 6572 7661 7469  def to_observati
+0001dd50: 6f6e 5f6e 6f72 6d28 7365 6c66 2920 2d3e  on_norm(self) ->
+0001dd60: 2055 6e69 6f6e 5b43 6f6d 706f 7365 2c20   Union[Compose, 
+0001dd70: 4f62 7365 7276 6174 696f 6e4e 6f72 6d5d  ObservationNorm]
+0001dd80: 3a0d 0a20 2020 2020 2020 2022 2222 436f  :..        """Co
+0001dd90: 6e76 6572 7473 2056 6563 4e6f 726d 2069  nverts VecNorm i
+0001dda0: 6e74 6f20 616e 204f 6273 6572 7661 7469  nto an Observati
+0001ddb0: 6f6e 4e6f 726d 2063 6c61 7373 2074 6861  onNorm class tha
+0001ddc0: 7420 6361 6e20 6265 2075 7365 6420 6174  t can be used at
+0001ddd0: 2069 6e66 6572 656e 6365 2074 696d 652e   inference time.
+0001dde0: 2222 220d 0a20 2020 2020 2020 206f 7574  """..        out
+0001ddf0: 203d 205b 5d0d 0a20 2020 2020 2020 2066   = []..        f
+0001de00: 6f72 206b 6579 2069 6e20 7365 6c66 2e69  or key in self.i
+0001de10: 6e5f 6b65 7973 3a0d 0a20 2020 2020 2020  n_keys:..       
+0001de20: 2020 2020 205f 7375 6d20 3d20 7365 6c66       _sum = self
+0001de30: 2e5f 7464 2e67 6574 286b 6579 202b 2022  ._td.get(key + "
+0001de40: 5f73 756d 2229 0d0a 2020 2020 2020 2020  _sum")..        
+0001de50: 2020 2020 5f73 7371 203d 2073 656c 662e      _ssq = self.
+0001de60: 5f74 642e 6765 7428 6b65 7920 2b20 225f  _td.get(key + "_
+0001de70: 7373 7122 290d 0a20 2020 2020 2020 2020  ssq")..         
+0001de80: 2020 205f 636f 756e 7420 3d20 7365 6c66     _count = self
+0001de90: 2e5f 7464 2e67 6574 286b 6579 202b 2022  ._td.get(key + "
+0001dea0: 5f63 6f75 6e74 2229 0d0a 2020 2020 2020  _count")..      
+0001deb0: 2020 2020 2020 6d65 616e 203d 205f 7375        mean = _su
+0001dec0: 6d20 2f20 5f63 6f75 6e74 0d0a 2020 2020  m / _count..    
+0001ded0: 2020 2020 2020 2020 7374 6420 3d20 285f          std = (_
+0001dee0: 7373 7120 2f20 5f63 6f75 6e74 202d 206d  ssq / _count - m
+0001def0: 6561 6e2e 706f 7728 3229 292e 636c 616d  ean.pow(2)).clam
+0001df00: 705f 6d69 6e28 7365 6c66 2e65 7073 292e  p_min(self.eps).
+0001df10: 7371 7274 2829 0d0a 0d0a 2020 2020 2020  sqrt()....      
+0001df20: 2020 2020 2020 5f6f 7574 203d 204f 6273        _out = Obs
+0001df30: 6572 7661 7469 6f6e 4e6f 726d 280d 0a20  ervationNorm(.. 
+0001df40: 2020 2020 2020 2020 2020 2020 2020 206c                 l
+0001df50: 6f63 3d6d 6561 6e2c 0d0a 2020 2020 2020  oc=mean,..      
+0001df60: 2020 2020 2020 2020 2020 7363 616c 653d            scale=
+0001df70: 7374 642c 0d0a 2020 2020 2020 2020 2020  std,..          
+0001df80: 2020 2020 2020 7374 616e 6461 7264 5f6e        standard_n
+0001df90: 6f72 6d61 6c3d 5472 7565 2c0d 0a20 2020  ormal=True,..   
+0001dfa0: 2020 2020 2020 2020 2020 2020 2069 6e5f               in_
+0001dfb0: 6b65 7973 3d73 656c 662e 696e 5f6b 6579  keys=self.in_key
+0001dfc0: 732c 0d0a 2020 2020 2020 2020 2020 2020  s,..            
+0001dfd0: 290d 0a20 2020 2020 2020 2020 2020 2069  )..            i
+0001dfe0: 6620 6c65 6e28 7365 6c66 2e69 6e5f 6b65  f len(self.in_ke
+0001dff0: 7973 2920 3d3d 2031 3a0d 0a20 2020 2020  ys) == 1:..     
+0001e000: 2020 2020 2020 2020 2020 2072 6574 7572             retur
+0001e010: 6e20 5f6f 7574 0d0a 2020 2020 2020 2020  n _out..        
+0001e020: 2020 2020 656c 7365 3a0d 0a20 2020 2020      else:..     
+0001e030: 2020 2020 2020 2020 2020 206f 7574 202b             out +
+0001e040: 3d20 4f62 7365 7276 6174 696f 6e4e 6f72  = ObservationNor
+0001e050: 6d0d 0a20 2020 2020 2020 2072 6574 7572  m..        retur
+0001e060: 6e20 436f 6d70 6f73 6528 2a6f 7574 290d  n Compose(*out).
+0001e070: 0a0d 0a20 2020 2040 7374 6174 6963 6d65  ...    @staticme
+0001e080: 7468 6f64 0d0a 2020 2020 6465 6620 6275  thod..    def bu
+0001e090: 696c 645f 7464 5f66 6f72 5f73 6861 7265  ild_td_for_share
+0001e0a0: 645f 7665 636e 6f72 6d28 0d0a 2020 2020  d_vecnorm(..    
+0001e0b0: 2020 2020 656e 763a 2045 6e76 4261 7365      env: EnvBase
+0001e0c0: 2c0d 0a20 2020 2020 2020 206b 6579 733a  ,..        keys:
+0001e0d0: 204f 7074 696f 6e61 6c5b 5365 7175 656e   Optional[Sequen
+0001e0e0: 6365 5b73 7472 5d5d 203d 204e 6f6e 652c  ce[str]] = None,
+0001e0f0: 0d0a 2020 2020 2020 2020 6d65 6d6d 6170  ..        memmap
+0001e100: 3a20 626f 6f6c 203d 2046 616c 7365 2c0d  : bool = False,.
+0001e110: 0a20 2020 2029 202d 3e20 5465 6e73 6f72  .    ) -> Tensor
+0001e120: 4469 6374 4261 7365 3a0d 0a20 2020 2020  DictBase:..     
+0001e130: 2020 2022 2222 4372 6561 7465 7320 6120     """Creates a 
+0001e140: 7368 6172 6564 2074 656e 736f 7264 6963  shared tensordic
+0001e150: 7420 666f 7220 6e6f 726d 616c 697a 6174  t for normalizat
+0001e160: 696f 6e20 6163 726f 7373 2070 726f 6365  ion across proce
+0001e170: 7373 6573 2e0d 0a0d 0a20 2020 2020 2020  sses.....       
+0001e180: 2041 7267 733a 0d0a 2020 2020 2020 2020   Args:..        
+0001e190: 2020 2020 656e 7620 2845 6e76 4261 7365      env (EnvBase
+0001e1a0: 293a 2065 7861 6d70 6c65 2065 6e76 6972  ): example envir
+0001e1b0: 6f6e 6d65 6e74 2074 6f20 6265 2075 7365  onment to be use
+0001e1c0: 6420 746f 2063 7265 6174 6520 7468 650d  d to create the.
+0001e1d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001e1e0: 2074 656e 736f 7264 6963 740d 0a20 2020   tensordict..   
+0001e1f0: 2020 2020 2020 2020 206b 6579 7320 2869           keys (i
+0001e200: 7465 7261 626c 6520 6f66 2073 7472 2c20  terable of str, 
+0001e210: 6f70 7469 6f6e 616c 293a 206b 6579 7320  optional): keys 
+0001e220: 7468 6174 0d0a 2020 2020 2020 2020 2020  that..          
+0001e230: 2020 2020 2020 6861 7665 2074 6f20 6265        have to be
+0001e240: 206e 6f72 6d61 6c69 7a65 642e 2044 6566   normalized. Def
+0001e250: 6175 6c74 2069 7320 605b 226e 6578 7422  ault is `["next"
+0001e260: 2c20 2272 6577 6172 6422 5d60 0d0a 2020  , "reward"]`..  
+0001e270: 2020 2020 2020 2020 2020 6d65 6d6d 6170            memmap
+0001e280: 2028 626f 6f6c 293a 2069 6620 6060 5472   (bool): if ``Tr
+0001e290: 7565 6060 2c20 7468 6520 7265 7375 6c74  ue``, the result
+0001e2a0: 696e 6720 7465 6e73 6f72 6469 6374 2077  ing tensordict w
+0001e2b0: 696c 6c20 6265 2063 6173 7420 696e 746f  ill be cast into
+0001e2c0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+0001e2d0: 2020 6d65 6d6d 6f72 7920 6d61 7020 2875    memmory map (u
+0001e2e0: 7369 6e67 2060 6d65 6d6d 6170 5f28 2960  sing `memmap_()`
+0001e2f0: 292e 204f 7468 6572 7769 7365 2c20 7468  ). Otherwise, th
+0001e300: 6520 7465 6e73 6f72 6469 6374 0d0a 2020  e tensordict..  
+0001e310: 2020 2020 2020 2020 2020 2020 2020 7769                wi
+0001e320: 6c6c 2062 6520 706c 6163 6564 2069 6e20  ll be placed in 
+0001e330: 7368 6172 6564 206d 656d 6f72 792e 0d0a  shared memory...
+0001e340: 0d0a 2020 2020 2020 2020 5265 7475 726e  ..        Return
+0001e350: 733a 0d0a 2020 2020 2020 2020 2020 2020  s:..            
+0001e360: 4120 6d65 6d6f 7279 2069 6e20 7368 6172  A memory in shar
+0001e370: 6564 206d 656d 6f72 7920 746f 2062 6520  ed memory to be 
+0001e380: 7365 6e74 2074 6f20 6561 6368 2070 726f  sent to each pro
+0001e390: 6365 7373 2e0d 0a0d 0a20 2020 2020 2020  cess.....       
+0001e3a0: 2045 7861 6d70 6c65 733a 0d0a 2020 2020   Examples:..    
+0001e3b0: 2020 2020 2020 2020 3e3e 3e20 6672 6f6d          >>> from
+0001e3c0: 2074 6f72 6368 2069 6d70 6f72 7420 6d75   torch import mu
+0001e3d0: 6c74 6970 726f 6365 7373 696e 6720 6173  ltiprocessing as
+0001e3e0: 206d 700d 0a20 2020 2020 2020 2020 2020   mp..           
+0001e3f0: 203e 3e3e 2071 7565 7565 203d 206d 702e   >>> queue = mp.
+0001e400: 5175 6575 6528 290d 0a20 2020 2020 2020  Queue()..       
+0001e410: 2020 2020 203e 3e3e 2065 6e76 203d 206d       >>> env = m
+0001e420: 616b 655f 656e 7628 290d 0a20 2020 2020  ake_env()..     
+0001e430: 2020 2020 2020 203e 3e3e 2074 645f 7368         >>> td_sh
+0001e440: 6172 6564 203d 2056 6563 4e6f 726d 2e62  ared = VecNorm.b
+0001e450: 7569 6c64 5f74 645f 666f 725f 7368 6172  uild_td_for_shar
+0001e460: 6564 5f76 6563 6e6f 726d 2865 6e76 2c0d  ed_vecnorm(env,.
+0001e470: 0a20 2020 2020 2020 2020 2020 202e 2e2e  .            ...
+0001e480: 2020 2020 205b 226e 6578 7422 2c20 2272       ["next", "r
+0001e490: 6577 6172 6422 5d29 0d0a 2020 2020 2020  eward"])..      
+0001e4a0: 2020 2020 2020 3e3e 3e20 6173 7365 7274        >>> assert
+0001e4b0: 2074 645f 7368 6172 6564 2e69 735f 7368   td_shared.is_sh
+0001e4c0: 6172 6564 2829 0d0a 2020 2020 2020 2020  ared()..        
+0001e4d0: 2020 2020 3e3e 3e20 7175 6575 652e 7075      >>> queue.pu
+0001e4e0: 7428 7464 5f73 6861 7265 6429 0d0a 2020  t(td_shared)..  
+0001e4f0: 2020 2020 2020 2020 2020 3e3e 3e20 2320            >>> # 
+0001e500: 6f6e 2077 6f72 6b65 7273 0d0a 2020 2020  on workers..    
+0001e510: 2020 2020 2020 2020 3e3e 3e20 7620 3d20          >>> v = 
+0001e520: 5665 634e 6f72 6d28 7368 6172 6564 5f74  VecNorm(shared_t
+0001e530: 643d 7175 6575 652e 6765 7428 2929 0d0a  d=queue.get())..
+0001e540: 2020 2020 2020 2020 2020 2020 3e3e 3e20              >>> 
+0001e550: 656e 7620 3d20 5472 616e 7366 6f72 6d65  env = Transforme
+0001e560: 6445 6e76 286d 616b 655f 656e 7628 292c  dEnv(make_env(),
+0001e570: 2076 290d 0a0d 0a20 2020 2020 2020 2022   v)....        "
+0001e580: 2222 0d0a 2020 2020 2020 2020 7261 6973  ""..        rais
+0001e590: 6520 4e6f 7449 6d70 6c65 6d65 6e74 6564  e NotImplemented
+0001e5a0: 4572 726f 7228 2274 6869 7320 6665 6174  Error("this feat
+0001e5b0: 7572 6520 6973 2063 7572 7265 6e74 6c79  ure is currently
+0001e5c0: 2070 7574 206f 6e20 686f 6c64 2e22 290d   put on hold.").
+0001e5d0: 0a20 2020 2020 2020 2073 6570 203d 2022  .        sep = "
+0001e5e0: 2e2d 7c2d 2e22 0d0a 2020 2020 2020 2020  .-|-."..        
+0001e5f0: 6966 206b 6579 7320 6973 204e 6f6e 653a  if keys is None:
+0001e600: 0d0a 2020 2020 2020 2020 2020 2020 6b65  ..            ke
+0001e610: 7973 203d 205b 226e 6578 7422 2c20 2272  ys = ["next", "r
+0001e620: 6577 6172 6422 5d0d 0a20 2020 2020 2020  eward"]..       
+0001e630: 2074 6420 3d20 6d61 6b65 5f74 656e 736f   td = make_tenso
+0001e640: 7264 6963 7428 656e 7629 0d0a 2020 2020  rdict(env)..    
+0001e650: 2020 2020 6b65 7973 203d 207b 6b65 7920      keys = {key 
+0001e660: 666f 7220 6b65 7920 696e 2074 642e 6b65  for key in td.ke
+0001e670: 7973 2829 2069 6620 6b65 7920 696e 206b  ys() if key in k
+0001e680: 6579 737d 0d0a 2020 2020 2020 2020 7464  eys}..        td
+0001e690: 5f73 656c 6563 7420 3d20 7464 2e73 656c  _select = td.sel
+0001e6a0: 6563 7428 2a6b 6579 7329 0d0a 2020 2020  ect(*keys)..    
+0001e6b0: 2020 2020 7464 5f73 656c 6563 7420 3d20      td_select = 
+0001e6c0: 7464 5f73 656c 6563 742e 666c 6174 7465  td_select.flatte
+0001e6d0: 6e5f 6b65 7973 2873 6570 290d 0a20 2020  n_keys(sep)..   
+0001e6e0: 2020 2020 2069 6620 7464 2e62 6174 6368       if td.batch
+0001e6f0: 5f64 696d 733a 0d0a 2020 2020 2020 2020  _dims:..        
+0001e700: 2020 2020 7261 6973 6520 5275 6e74 696d      raise Runtim
+0001e710: 6545 7272 6f72 280d 0a20 2020 2020 2020  eError(..       
+0001e720: 2020 2020 2020 2020 2066 2256 6563 4e6f           f"VecNo
+0001e730: 726d 2073 686f 756c 6420 6265 2075 7365  rm should be use
+0001e740: 6420 7769 7468 206e 6f6e 2d62 6174 6368  d with non-batch
+0001e750: 6564 2065 6e76 6972 6f6e 6d65 6e74 732e  ed environments.
+0001e760: 2022 0d0a 2020 2020 2020 2020 2020 2020   "..            
+0001e770: 2020 2020 6622 476f 7420 6261 7463 685f      f"Got batch_
+0001e780: 7369 7a65 3d7b 7464 2e62 6174 6368 5f73  size={td.batch_s
+0001e790: 697a 657d 220d 0a20 2020 2020 2020 2020  ize}"..         
+0001e7a0: 2020 2029 0d0a 2020 2020 2020 2020 6b65     )..        ke
+0001e7b0: 7973 203d 206c 6973 7428 7464 5f73 656c  ys = list(td_sel
+0001e7c0: 6563 742e 6b65 7973 2829 290d 0a20 2020  ect.keys())..   
+0001e7d0: 2020 2020 2066 6f72 206b 6579 2069 6e20       for key in 
+0001e7e0: 6b65 7973 3a0d 0a20 2020 2020 2020 2020  keys:..         
+0001e7f0: 2020 2074 645f 7365 6c65 6374 2e73 6574     td_select.set
+0001e800: 286b 6579 202b 2022 5f73 7371 222c 2074  (key + "_ssq", t
+0001e810: 645f 7365 6c65 6374 2e67 6574 286b 6579  d_select.get(key
+0001e820: 292e 636c 6f6e 6528 2929 0d0a 2020 2020  ).clone())..    
+0001e830: 2020 2020 2020 2020 7464 5f73 656c 6563          td_selec
+0001e840: 742e 7365 7428 0d0a 2020 2020 2020 2020  t.set(..        
+0001e850: 2020 2020 2020 2020 6b65 7920 2b20 225f          key + "_
+0001e860: 636f 756e 7422 2c0d 0a20 2020 2020 2020  count",..       
+0001e870: 2020 2020 2020 2020 2074 6f72 6368 2e7a           torch.z
+0001e880: 6572 6f73 280d 0a20 2020 2020 2020 2020  eros(..         
+0001e890: 2020 2020 2020 2020 2020 202a 7464 2e62             *td.b
+0001e8a0: 6174 6368 5f73 697a 652c 0d0a 2020 2020  atch_size,..    
+0001e8b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001e8c0: 312c 0d0a 2020 2020 2020 2020 2020 2020  1,..            
+0001e8d0: 2020 2020 2020 2020 6465 7669 6365 3d74          device=t
+0001e8e0: 645f 7365 6c65 6374 2e64 6576 6963 652c  d_select.device,
+0001e8f0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+0001e900: 2020 2020 2020 6474 7970 653d 746f 7263        dtype=torc
+0001e910: 682e 666c 6f61 742c 0d0a 2020 2020 2020  h.float,..      
+0001e920: 2020 2020 2020 2020 2020 292c 0d0a 2020            ),..  
+0001e930: 2020 2020 2020 2020 2020 290d 0a20 2020            )..   
+0001e940: 2020 2020 2020 2020 2074 645f 7365 6c65           td_sele
+0001e950: 6374 2e72 656e 616d 655f 6b65 795f 286b  ct.rename_key_(k
+0001e960: 6579 2c20 6b65 7920 2b20 225f 7375 6d22  ey, key + "_sum"
+0001e970: 290d 0a20 2020 2020 2020 2074 645f 7365  )..        td_se
+0001e980: 6c65 6374 2e65 7863 6c75 6465 282a 6b65  lect.exclude(*ke
+0001e990: 7973 292e 7a65 726f 5f28 290d 0a20 2020  ys).zero_()..   
+0001e9a0: 2020 2020 2074 645f 7365 6c65 6374 203d       td_select =
+0001e9b0: 2074 645f 7365 6c65 6374 2e75 6e66 6c61   td_select.unfla
+0001e9c0: 7474 656e 5f6b 6579 7328 7365 7029 0d0a  tten_keys(sep)..
+0001e9d0: 2020 2020 2020 2020 6966 206d 656d 6d61          if memma
+0001e9e0: 703a 0d0a 2020 2020 2020 2020 2020 2020  p:..            
+0001e9f0: 7265 7475 726e 2074 645f 7365 6c65 6374  return td_select
+0001ea00: 2e6d 656d 6d61 705f 2829 0d0a 2020 2020  .memmap_()..    
+0001ea10: 2020 2020 7265 7475 726e 2074 645f 7365      return td_se
+0001ea20: 6c65 6374 2e73 6861 7265 5f6d 656d 6f72  lect.share_memor
+0001ea30: 795f 2829 0d0a 0d0a 2020 2020 6465 6620  y_()....    def 
+0001ea40: 6765 745f 6578 7472 615f 7374 6174 6528  get_extra_state(
+0001ea50: 7365 6c66 2920 2d3e 204f 7264 6572 6564  self) -> Ordered
+0001ea60: 4469 6374 3a0d 0a20 2020 2020 2020 2072  Dict:..        r
+0001ea70: 6574 7572 6e20 636f 6c6c 6563 7469 6f6e  eturn collection
+0001ea80: 732e 4f72 6465 7265 6444 6963 7428 7b22  s.OrderedDict({"
+0001ea90: 6c6f 636b 223a 2073 656c 662e 6c6f 636b  lock": self.lock
+0001eaa0: 2c20 2274 6422 3a20 7365 6c66 2e5f 7464  , "td": self._td
+0001eab0: 7d29 0d0a 0d0a 2020 2020 6465 6620 7365  })....    def se
+0001eac0: 745f 6578 7472 615f 7374 6174 6528 7365  t_extra_state(se
+0001ead0: 6c66 2c20 7374 6174 653a 204f 7264 6572  lf, state: Order
+0001eae0: 6564 4469 6374 2920 2d3e 204e 6f6e 653a  edDict) -> None:
+0001eaf0: 0d0a 2020 2020 2020 2020 6c6f 636b 203d  ..        lock =
+0001eb00: 2073 7461 7465 5b22 6c6f 636b 225d 0d0a   state["lock"]..
+0001eb10: 2020 2020 2020 2020 6966 206c 6f63 6b20          if lock 
+0001eb20: 6973 206e 6f74 204e 6f6e 653a 0d0a 2020  is not None:..  
+0001eb30: 2020 2020 2020 2020 2020 2222 220d 0a20            """.. 
+0001eb40: 2020 2020 2020 2020 2020 2073 696e 6365             since
+0001eb50: 206c 6f63 6b73 2063 616e 2774 2062 6520   locks can't be 
+0001eb60: 7365 7269 616c 697a 6564 2c20 7765 2068  serialized, we h
+0001eb70: 6176 6520 7573 6520 6361 7365 7320 666f  ave use cases fo
+0001eb80: 7220 7374 7269 7070 696e 6720 7468 656d  r stripping them
+0001eb90: 0d0a 2020 2020 2020 2020 2020 2020 666f  ..            fo
+0001eba0: 7220 6578 616d 706c 6520 696e 2050 6172  r example in Par
+0001ebb0: 616c 6c65 6c45 6e76 2c20 696e 2077 6869  allelEnv, in whi
+0001ebc0: 6368 2063 6173 6520 6b65 6570 2074 6865  ch case keep the
+0001ebd0: 206c 6f63 6b20 7765 2061 6c72 6561 6479   lock we already
+0001ebe0: 2068 6176 650d 0a20 2020 2020 2020 2020   have..         
+0001ebf0: 2020 2074 6f20 6176 6f69 6420 616e 2075     to avoid an u
+0001ec00: 7064 6174 6564 2074 656e 736f 7220 6469  pdated tensor di
+0001ec10: 6374 2062 6569 6e67 2073 656e 7420 6265  ct being sent be
+0001ec20: 7477 6565 6e20 7072 6f63 6573 7365 7320  tween processes 
+0001ec30: 746f 2065 7261 7365 206c 6f63 6b73 0d0a  to erase locks..
+0001ec40: 2020 2020 2020 2020 2020 2020 2222 220d              """.
+0001ec50: 0a20 2020 2020 2020 2020 2020 2073 656c  .            sel
+0001ec60: 662e 6c6f 636b 203d 206c 6f63 6b0d 0a20  f.lock = lock.. 
+0001ec70: 2020 2020 2020 2074 6420 3d20 7374 6174         td = stat
+0001ec80: 655b 2274 6422 5d0d 0a20 2020 2020 2020  e["td"]..       
+0001ec90: 2069 6620 7464 2069 7320 6e6f 7420 4e6f   if td is not No
+0001eca0: 6e65 2061 6e64 206e 6f74 2074 642e 6973  ne and not td.is
+0001ecb0: 5f73 6861 7265 6428 293a 0d0a 2020 2020  _shared():..    
+0001ecc0: 2020 2020 2020 2020 7261 6973 6520 5275          raise Ru
+0001ecd0: 6e74 696d 6545 7272 6f72 280d 0a20 2020  ntimeError(..   
+0001ece0: 2020 2020 2020 2020 2020 2020 2022 4f6e               "On
+0001ecf0: 6c79 2073 6861 7265 6420 7465 6e73 6f72  ly shared tensor
+0001ed00: 6469 6374 7320 6361 6e20 6265 2073 6574  dicts can be set
+0001ed10: 2069 6e20 5665 634e 6f72 6d20 7472 616e   in VecNorm tran
+0001ed20: 7366 6f72 6d73 220d 0a20 2020 2020 2020  sforms"..       
+0001ed30: 2020 2020 2029 0d0a 2020 2020 2020 2020       )..        
+0001ed40: 7365 6c66 2e5f 7464 203d 2074 640d 0a0d  self._td = td...
+0001ed50: 0a20 2020 2064 6566 205f 5f72 6570 725f  .    def __repr_
+0001ed60: 5f28 7365 6c66 2920 2d3e 2073 7472 3a0d  _(self) -> str:.
+0001ed70: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+0001ed80: 280d 0a20 2020 2020 2020 2020 2020 2066  (..            f
+0001ed90: 227b 7365 6c66 2e5f 5f63 6c61 7373 5f5f  "{self.__class__
+0001eda0: 2e5f 5f6e 616d 655f 5f7d 2864 6563 6179  .__name__}(decay
+0001edb0: 3d7b 7365 6c66 2e64 6563 6179 3a34 2e34  ={self.decay:4.4
+0001edc0: 667d 2c22 0d0a 2020 2020 2020 2020 2020  f},"..          
+0001edd0: 2020 6622 6570 733d 7b73 656c 662e 6570    f"eps={self.ep
+0001ede0: 733a 342e 3466 7d2c 206b 6579 733d 7b73  s:4.4f}, keys={s
+0001edf0: 656c 662e 696e 5f6b 6579 737d 2922 0d0a  elf.in_keys})"..
+0001ee00: 2020 2020 2020 2020 290d 0a0d 0a0d 0a63          )......c
+0001ee10: 6c61 7373 2052 6577 6172 6453 756d 2854  lass RewardSum(T
+0001ee20: 7261 6e73 666f 726d 293a 0d0a 2020 2020  ransform):..    
+0001ee30: 2222 2254 7261 636b 7320 6570 6973 6f64  """Tracks episod
+0001ee40: 6520 6375 6d75 6c61 7469 7665 2072 6577  e cumulative rew
+0001ee50: 6172 6473 2e0d 0a0d 0a20 2020 2054 6869  ards.....    Thi
+0001ee60: 7320 7472 616e 7366 6f72 6d20 6163 6365  s transform acce
+0001ee70: 7074 7320 6120 6c69 7374 206f 6620 7465  pts a list of te
+0001ee80: 6e73 6f72 6469 6374 2072 6577 6172 6420  nsordict reward 
+0001ee90: 6b65 7973 2028 692e 652e 20c2 b469 6e5f  keys (i.e. ..in_
+0001eea0: 6b65 7973 c2b4 2920 616e 6420 7472 6163  keys..) and trac
+0001eeb0: 6b73 2074 6865 6972 2063 756d 756c 6174  ks their cumulat
+0001eec0: 6976 650d 0a20 2020 2076 616c 7565 2061  ive..    value a
+0001eed0: 6c6f 6e67 2065 6163 6820 6570 6973 6f64  long each episod
+0001eee0: 652e 2057 6865 6e20 6361 6c6c 6564 2c20  e. When called, 
+0001eef0: 7468 6520 7472 616e 7366 6f72 6d20 6372  the transform cr
+0001ef00: 6561 7465 7320 6120 6e65 7720 7465 6e73  eates a new tens
+0001ef10: 6f72 6469 6374 206b 6579 2066 6f72 2065  ordict key for e
+0001ef20: 6163 6820 696e 5f6b 6579 206e 616d 6564  ach in_key named
+0001ef30: 0d0a 2020 2020 c2b4 6570 6973 6f64 655f  ..    ..episode_
+0001ef40: 7b69 6e5f 6b65 797d c2b4 2077 6865 7265  {in_key}.. where
+0001ef50: 2020 7468 6520 6375 6d75 6c61 7469 7665    the cumulative
+0001ef60: 2076 616c 7565 7320 6172 6520 7772 6974   values are writ
+0001ef70: 7465 6e2e 2041 6c6c 20c2 b469 6e5f 6b65  ten. All ..in_ke
+0001ef80: 7973 c2b4 2073 686f 756c 6420 6265 2070  ys.. should be p
+0001ef90: 6172 7420 6f66 2074 6865 2065 6e76 0d0a  art of the env..
+0001efa0: 2020 2020 7265 7761 7264 2061 6e64 2062      reward and b
+0001efb0: 6520 7072 6573 656e 7420 696e 2074 6865  e present in the
+0001efc0: 2065 6e76 2072 6577 6172 645f 7370 6563   env reward_spec
+0001efd0: 2e0d 0a0d 0a20 2020 2049 6620 6e6f 2069  .....    If no i
+0001efe0: 6e5f 6b65 7973 2061 7265 2073 7065 6369  n_keys are speci
+0001eff0: 6669 6564 2c20 7468 6973 2074 7261 6e73  fied, this trans
+0001f000: 666f 726d 2061 7373 756d 6573 20c2 b472  form assumes ..r
+0001f010: 6577 6172 64c2 b420 746f 2062 6520 7468  eward.. to be th
+0001f020: 6520 696e 7075 7420 6b65 792e 2048 6f77  e input key. How
+0001f030: 6576 6572 2c20 6d75 6c74 6970 6c65 2072  ever, multiple r
+0001f040: 6577 6172 6473 0d0a 2020 2020 2865 2e67  ewards..    (e.g
+0001f050: 2e20 7265 7761 7264 3120 616e 6420 7265  . reward1 and re
+0001f060: 7761 7264 3229 2063 616e 2061 6c73 6f20  ward2) can also 
+0001f070: 6265 2073 7065 6369 6669 6564 2e20 4966  be specified. If
+0001f080: 20c2 b469 6e5f 6b65 7973 c2b4 2061 7265   ..in_keys.. are
+0001f090: 206e 6f74 2070 7265 7365 6e74 2069 6e20   not present in 
+0001f0a0: 7468 6520 7072 6f76 6964 6564 2074 656e  the provided ten
+0001f0b0: 736f 7264 6963 742c 0d0a 2020 2020 7468  sordict,..    th
+0001f0c0: 6973 2074 7261 6e73 666f 726d 2068 6f73  is transform hos
+0001f0d0: 206e 6f20 6566 6665 6374 2e0d 0a20 2020   no effect...   
+0001f0e0: 2022 2222 0d0a 0d0a 2020 2020 6465 6620   """....    def 
+0001f0f0: 5f5f 696e 6974 5f5f 280d 0a20 2020 2020  __init__(..     
+0001f100: 2020 2073 656c 662c 0d0a 2020 2020 2020     self,..      
+0001f110: 2020 696e 5f6b 6579 733a 204f 7074 696f    in_keys: Optio
+0001f120: 6e61 6c5b 5365 7175 656e 6365 5b73 7472  nal[Sequence[str
+0001f130: 5d5d 203d 204e 6f6e 652c 0d0a 2020 2020  ]] = None,..    
+0001f140: 2020 2020 6f75 745f 6b65 7973 3a20 4f70      out_keys: Op
+0001f150: 7469 6f6e 616c 5b53 6571 7565 6e63 655b  tional[Sequence[
+0001f160: 7374 725d 5d20 3d20 4e6f 6e65 2c0d 0a20  str]] = None,.. 
+0001f170: 2020 2029 3a0d 0a20 2020 2020 2020 2022     ):..        "
+0001f180: 2222 496e 6974 6961 6c69 7365 7320 7468  ""Initialises th
+0001f190: 6520 7472 616e 7366 6f72 6d2e 2046 696c  e transform. Fil
+0001f1a0: 7465 7273 206f 7574 206e 6f6e 2d72 6577  ters out non-rew
+0001f1b0: 6172 6420 696e 7075 7420 6b65 7973 2061  ard input keys a
+0001f1c0: 6e64 2064 6566 696e 6573 206f 7574 7075  nd defines outpu
+0001f1d0: 7420 6b65 7973 2e22 2222 0d0a 2020 2020  t keys."""..    
+0001f1e0: 2020 2020 6966 2069 6e5f 6b65 7973 2069      if in_keys i
+0001f1f0: 7320 4e6f 6e65 3a0d 0a20 2020 2020 2020  s None:..       
+0001f200: 2020 2020 2069 6e5f 6b65 7973 203d 205b       in_keys = [
+0001f210: 2272 6577 6172 6422 5d0d 0a20 2020 2020  "reward"]..     
+0001f220: 2020 2069 6620 6f75 745f 6b65 7973 2069     if out_keys i
+0001f230: 7320 4e6f 6e65 2061 6e64 2069 6e5f 6b65  s None and in_ke
+0001f240: 7973 203d 3d20 5b22 7265 7761 7264 225d  ys == ["reward"]
+0001f250: 3a0d 0a20 2020 2020 2020 2020 2020 206f  :..            o
+0001f260: 7574 5f6b 6579 7320 3d20 5b22 6570 6973  ut_keys = ["epis
+0001f270: 6f64 655f 7265 7761 7264 225d 0d0a 2020  ode_reward"]..  
+0001f280: 2020 2020 2020 656c 6966 206f 7574 5f6b        elif out_k
+0001f290: 6579 7320 6973 204e 6f6e 653a 0d0a 2020  eys is None:..  
+0001f2a0: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
+0001f2b0: 5275 6e74 696d 6545 7272 6f72 280d 0a20  RuntimeError(.. 
+0001f2c0: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+0001f2d0: 7468 6520 6f75 745f 6b65 7973 206d 7573  the out_keys mus
+0001f2e0: 7420 6265 2073 7065 6369 6669 6564 2066  t be specified f
+0001f2f0: 6f72 206e 6f6e 2d63 6f6e 7665 6e74 696f  or non-conventio
+0001f300: 6e61 6c20 696e 2d6b 6579 7320 696e 2052  nal in-keys in R
+0001f310: 6577 6172 6453 756d 2e22 0d0a 2020 2020  ewardSum."..    
+0001f320: 2020 2020 2020 2020 290d 0a0d 0a20 2020          )....   
+0001f330: 2020 2020 2073 7570 6572 2829 2e5f 5f69       super().__i
+0001f340: 6e69 745f 5f28 696e 5f6b 6579 733d 696e  nit__(in_keys=in
+0001f350: 5f6b 6579 732c 206f 7574 5f6b 6579 733d  _keys, out_keys=
+0001f360: 6f75 745f 6b65 7973 290d 0a0d 0a20 2020  out_keys)....   
+0001f370: 2064 6566 2072 6573 6574 2873 656c 662c   def reset(self,
+0001f380: 2074 656e 736f 7264 6963 743a 2054 656e   tensordict: Ten
+0001f390: 736f 7244 6963 7442 6173 6529 202d 3e20  sorDictBase) -> 
+0001f3a0: 5465 6e73 6f72 4469 6374 4261 7365 3a0d  TensorDictBase:.
+0001f3b0: 0a20 2020 2020 2020 2022 2222 5265 7365  .        """Rese
+0001f3c0: 7473 2065 7069 736f 6465 2072 6577 6172  ts episode rewar
+0001f3d0: 6473 2e22 2222 0d0a 2020 2020 2020 2020  ds."""..        
+0001f3e0: 2320 4e6f 6e2d 6261 7463 6865 6420 656e  # Non-batched en
+0001f3f0: 7669 726f 6e6d 656e 7473 0d0a 2020 2020  vironments..    
+0001f400: 2020 2020 5f72 6573 6574 203d 2074 656e      _reset = ten
+0001f410: 736f 7264 6963 742e 6765 7428 0d0a 2020  sordict.get(..  
+0001f420: 2020 2020 2020 2020 2020 225f 7265 7365            "_rese
+0001f430: 7422 2c0d 0a20 2020 2020 2020 2020 2020  t",..           
+0001f440: 2074 6f72 6368 2e6f 6e65 7328 0d0a 2020   torch.ones(..  
+0001f450: 2020 2020 2020 2020 2020 2020 2020 7365                se
+0001f460: 6c66 2e70 6172 656e 742e 646f 6e65 5f73  lf.parent.done_s
+0001f470: 7065 632e 7368 6170 6520 6966 2073 656c  pec.shape if sel
+0001f480: 662e 7061 7265 6e74 2065 6c73 6520 7465  f.parent else te
+0001f490: 6e73 6f72 6469 6374 2e62 6174 6368 5f73  nsordict.batch_s
+0001f4a0: 697a 652c 0d0a 2020 2020 2020 2020 2020  ize,..          
+0001f4b0: 2020 2020 2020 6474 7970 653d 746f 7263        dtype=torc
+0001f4c0: 682e 626f 6f6c 2c0d 0a20 2020 2020 2020  h.bool,..       
+0001f4d0: 2020 2020 2020 2020 2064 6576 6963 653d           device=
+0001f4e0: 7465 6e73 6f72 6469 6374 2e64 6576 6963  tensordict.devic
+0001f4f0: 652c 0d0a 2020 2020 2020 2020 2020 2020  e,..            
+0001f500: 292c 0d0a 2020 2020 2020 2020 290d 0a20  ),..        ).. 
+0001f510: 2020 2020 2020 2069 6620 5f72 6573 6574         if _reset
+0001f520: 2e61 6e79 2829 3a0d 0a20 2020 2020 2020  .any():..       
+0001f530: 2020 2020 2066 6f72 2069 6e5f 6b65 792c       for in_key,
+0001f540: 206f 7574 5f6b 6579 2069 6e20 7a69 7028   out_key in zip(
+0001f550: 7365 6c66 2e69 6e5f 6b65 7973 2c20 7365  self.in_keys, se
+0001f560: 6c66 2e6f 7574 5f6b 6579 7329 3a0d 0a20  lf.out_keys):.. 
+0001f570: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+0001f580: 6620 6f75 745f 6b65 7920 696e 2074 656e  f out_key in ten
+0001f590: 736f 7264 6963 742e 6b65 7973 2829 3a0d  sordict.keys():.
+0001f5a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001f5b0: 2020 2020 2076 616c 7565 203d 2074 656e       value = ten
+0001f5c0: 736f 7264 6963 745b 6f75 745f 6b65 795d  sordict[out_key]
+0001f5d0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+0001f5e0: 2020 2020 2020 7465 6e73 6f72 6469 6374        tensordict
+0001f5f0: 5b6f 7574 5f6b 6579 5d20 3d20 7661 6c75  [out_key] = valu
+0001f600: 652e 6d61 736b 6564 5f66 696c 6c28 0d0a  e.masked_fill(..
+0001f610: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f620: 2020 2020 2020 2020 6578 7061 6e64 5f61          expand_a
+0001f630: 735f 7269 6768 7428 5f72 6573 6574 2c20  s_right(_reset, 
+0001f640: 7661 6c75 6529 2c20 302e 300d 0a20 2020  value), 0.0..   
+0001f650: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f660: 2029 0d0a 2020 2020 2020 2020 2020 2020   )..            
+0001f670: 2020 2020 656c 6966 2069 6e5f 6b65 7920      elif in_key 
+0001f680: 696e 2028 2272 6577 6172 6422 2c20 2822  in ("reward", ("
+0001f690: 7265 7761 7264 222c 2929 3a0d 0a20 2020  reward",)):..   
+0001f6a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f6b0: 2023 2053 696e 6365 2074 6865 2065 7069   # Since the epi
+0001f6c0: 736f 6465 2072 6577 6172 6420 6973 206e  sode reward is n
+0001f6d0: 6f74 2069 6e20 7468 6520 7465 6e73 6f72  ot in the tensor
+0001f6e0: 6469 6374 2c20 7765 206e 6565 6420 746f  dict, we need to
+0001f6f0: 2061 6c6c 6f63 6174 6520 6974 0d0a 2020   allocate it..  
+0001f700: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f710: 2020 2320 7769 7468 207a 6572 6f73 2065    # with zeros e
+0001f720: 6e74 6972 656c 7920 2872 6567 6172 646c  ntirely (regardl
+0001f730: 6573 7320 6f66 2074 6865 205f 7265 7365  ess of the _rese
+0001f740: 7420 6d61 736b 290d 0a20 2020 2020 2020  t mask)..       
+0001f750: 2020 2020 2020 2020 2020 2020 2074 656e               ten
+0001f760: 736f 7264 6963 745b 6f75 745f 6b65 795d  sordict[out_key]
+0001f770: 203d 2073 656c 662e 7061 7265 6e74 2e72   = self.parent.r
+0001f780: 6577 6172 645f 7370 6563 2e7a 6572 6f28  eward_spec.zero(
+0001f790: 290d 0a20 2020 2020 2020 2020 2020 2020  )..             
+0001f7a0: 2020 2065 6c73 653a 0d0a 2020 2020 2020     else:..      
+0001f7b0: 2020 2020 2020 2020 2020 2020 2020 7472                tr
+0001f7c0: 793a 0d0a 2020 2020 2020 2020 2020 2020  y:..            
+0001f7d0: 2020 2020 2020 2020 2020 2020 7465 6e73              tens
+0001f7e0: 6f72 6469 6374 5b6f 7574 5f6b 6579 5d20  ordict[out_key] 
+0001f7f0: 3d20 7365 6c66 2e70 6172 656e 742e 6f62  = self.parent.ob
+0001f800: 7365 7276 6174 696f 6e5f 7370 6563 5b0d  servation_spec[.
+0001f810: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001f820: 2020 2020 2020 2020 2020 2020 2069 6e5f               in_
+0001f830: 6b65 790d 0a20 2020 2020 2020 2020 2020  key..           
+0001f840: 2020 2020 2020 2020 2020 2020 205d 2e7a               ].z
+0001f850: 6572 6f28 290d 0a20 2020 2020 2020 2020  ero()..         
+0001f860: 2020 2020 2020 2020 2020 2065 7863 6570             excep
+0001f870: 7420 4b65 7945 7272 6f72 2061 7320 6572  t KeyError as er
+0001f880: 723a 0d0a 2020 2020 2020 2020 2020 2020  r:..            
+0001f890: 2020 2020 2020 2020 2020 2020 7261 6973              rais
+0001f8a0: 6520 4b65 7945 7272 6f72 280d 0a20 2020  e KeyError(..   
+0001f8b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f8c0: 2020 2020 2020 2020 2066 2254 6865 206b           f"The k
+0001f8d0: 6579 207b 696e 5f6b 6579 7d20 7761 7320  ey {in_key} was 
+0001f8e0: 6e6f 7420 666f 756e 6420 696e 2074 6865  not found in the
+0001f8f0: 2070 6172 656e 7420 220d 0a20 2020 2020   parent "..     
+0001f900: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f910: 2020 2020 2020 2066 226f 6273 6572 7661         f"observa
+0001f920: 7469 6f6e 5f73 7065 6320 7769 7468 206b  tion_spec with k
+0001f930: 6579 7320 220d 0a20 2020 2020 2020 2020  eys "..         
+0001f940: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f950: 2020 2066 227b 6c69 7374 2873 656c 662e     f"{list(self.
+0001f960: 7061 7265 6e74 2e6f 6273 6572 7661 7469  parent.observati
+0001f970: 6f6e 5f73 7065 632e 6b65 7973 2854 7275  on_spec.keys(Tru
+0001f980: 6529 297d 2e20 220d 0a20 2020 2020 2020  e))}. "..       
+0001f990: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001f9a0: 2029 2066 726f 6d20 6572 720d 0a20 2020   ) from err..   
+0001f9b0: 2020 2020 2072 6574 7572 6e20 7465 6e73       return tens
+0001f9c0: 6f72 6469 6374 0d0a 0d0a 2020 2020 6465  ordict....    de
+0001f9d0: 6620 5f73 7465 7028 7365 6c66 2c20 7465  f _step(self, te
+0001f9e0: 6e73 6f72 6469 6374 3a20 5465 6e73 6f72  nsordict: Tensor
+0001f9f0: 4469 6374 4261 7365 2920 2d3e 2054 656e  DictBase) -> Ten
+0001fa00: 736f 7244 6963 7442 6173 653a 0d0a 2020  sorDictBase:..  
+0001fa10: 2020 2020 2020 2222 2255 7064 6174 6573        """Updates
+0001fa20: 2074 6865 2065 7069 736f 6465 2072 6577   the episode rew
+0001fa30: 6172 6473 2077 6974 6820 7468 6520 7374  ards with the st
+0001fa40: 6570 2072 6577 6172 6473 2e22 2222 0d0a  ep rewards."""..
+0001fa50: 2020 2020 2020 2020 2320 5570 6461 7465          # Update
+0001fa60: 2065 7069 736f 6465 2072 6577 6172 6473   episode rewards
+0001fa70: 0d0a 2020 2020 2020 2020 6e65 7874 5f74  ..        next_t
+0001fa80: 656e 736f 7264 6963 7420 3d20 7465 6e73  ensordict = tens
+0001fa90: 6f72 6469 6374 2e67 6574 2822 6e65 7874  ordict.get("next
+0001faa0: 2229 0d0a 2020 2020 2020 2020 666f 7220  ")..        for 
+0001fab0: 696e 5f6b 6579 2c20 6f75 745f 6b65 7920  in_key, out_key 
+0001fac0: 696e 207a 6970 2873 656c 662e 696e 5f6b  in zip(self.in_k
+0001fad0: 6579 732c 2073 656c 662e 6f75 745f 6b65  eys, self.out_ke
+0001fae0: 7973 293a 0d0a 2020 2020 2020 2020 2020  ys):..          
+0001faf0: 2020 6966 2069 6e5f 6b65 7920 696e 206e    if in_key in n
+0001fb00: 6578 745f 7465 6e73 6f72 6469 6374 2e6b  ext_tensordict.k
+0001fb10: 6579 7328 696e 636c 7564 655f 6e65 7374  eys(include_nest
+0001fb20: 6564 3d54 7275 6529 3a0d 0a20 2020 2020  ed=True):..     
+0001fb30: 2020 2020 2020 2020 2020 2072 6577 6172             rewar
+0001fb40: 6420 3d20 6e65 7874 5f74 656e 736f 7264  d = next_tensord
+0001fb50: 6963 742e 6765 7428 696e 5f6b 6579 290d  ict.get(in_key).
+0001fb60: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0001fb70: 2069 6620 6f75 745f 6b65 7920 6e6f 7420   if out_key not 
+0001fb80: 696e 2074 656e 736f 7264 6963 742e 6b65  in tensordict.ke
+0001fb90: 7973 2854 7275 6529 3a0d 0a20 2020 2020  ys(True):..     
+0001fba0: 2020 2020 2020 2020 2020 2020 2020 2074                 t
+0001fbb0: 656e 736f 7264 6963 742e 7365 7428 6f75  ensordict.set(ou
+0001fbc0: 745f 6b65 792c 2074 6f72 6368 2e7a 6572  t_key, torch.zer
+0001fbd0: 6f73 5f6c 696b 6528 7265 7761 7264 2929  os_like(reward))
+0001fbe0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+0001fbf0: 2020 6e65 7874 5f74 656e 736f 7264 6963    next_tensordic
+0001fc00: 742e 7365 7428 6f75 745f 6b65 792c 2074  t.set(out_key, t
+0001fc10: 656e 736f 7264 6963 742e 6765 7428 6f75  ensordict.get(ou
+0001fc20: 745f 6b65 7929 202b 2072 6577 6172 6429  t_key) + reward)
+0001fc30: 0d0a 2020 2020 2020 2020 2020 2020 656c  ..            el
+0001fc40: 6966 206e 6f74 2073 656c 662e 6d69 7373  if not self.miss
+0001fc50: 696e 675f 746f 6c65 7261 6e63 653a 0d0a  ing_tolerance:..
+0001fc60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001fc70: 7261 6973 6520 4b65 7945 7272 6f72 2866  raise KeyError(f
+0001fc80: 2227 7b69 6e5f 6b65 797d 2720 6e6f 7420  "'{in_key}' not 
+0001fc90: 666f 756e 6420 696e 2074 656e 736f 7264  found in tensord
+0001fca0: 6963 7420 7b74 656e 736f 7264 6963 747d  ict {tensordict}
+0001fcb0: 2229 0d0a 2020 2020 2020 2020 7465 6e73  ")..        tens
+0001fcc0: 6f72 6469 6374 2e73 6574 2822 6e65 7874  ordict.set("next
+0001fcd0: 222c 206e 6578 745f 7465 6e73 6f72 6469  ", next_tensordi
+0001fce0: 6374 290d 0a20 2020 2020 2020 2072 6574  ct)..        ret
+0001fcf0: 7572 6e20 7465 6e73 6f72 6469 6374 0d0a  urn tensordict..
+0001fd00: 0d0a 2020 2020 6465 6620 7472 616e 7366  ..    def transf
+0001fd10: 6f72 6d5f 6f62 7365 7276 6174 696f 6e5f  orm_observation_
+0001fd20: 7370 6563 2873 656c 662c 206f 6273 6572  spec(self, obser
+0001fd30: 7661 7469 6f6e 5f73 7065 633a 2054 656e  vation_spec: Ten
+0001fd40: 736f 7253 7065 6329 202d 3e20 5465 6e73  sorSpec) -> Tens
+0001fd50: 6f72 5370 6563 3a0d 0a20 2020 2020 2020  orSpec:..       
+0001fd60: 2022 2222 5472 616e 7366 6f72 6d73 2074   """Transforms t
+0001fd70: 6865 206f 6273 6572 7661 7469 6f6e 2073  he observation s
+0001fd80: 7065 632c 2061 6464 696e 6720 7468 6520  pec, adding the 
+0001fd90: 6e65 7720 6b65 7973 2067 656e 6572 6174  new keys generat
+0001fda0: 6564 2062 7920 5265 7761 7264 5375 6d2e  ed by RewardSum.
+0001fdb0: 2222 220d 0a20 2020 2020 2020 2023 2052  """..        # R
+0001fdc0: 6574 7269 6576 6520 7061 7265 6e74 2072  etrieve parent r
+0001fdd0: 6577 6172 6420 7370 6563 0d0a 2020 2020  eward spec..    
+0001fde0: 2020 2020 7265 7761 7264 5f73 7065 6320      reward_spec 
+0001fdf0: 3d20 7365 6c66 2e70 6172 656e 742e 7265  = self.parent.re
+0001fe00: 7761 7264 5f73 7065 630d 0a0d 0a20 2020  ward_spec....   
+0001fe10: 2020 2020 2065 7069 736f 6465 5f73 7065       episode_spe
+0001fe20: 6373 203d 207b 7d0d 0a20 2020 2020 2020  cs = {}..       
+0001fe30: 2069 6620 6973 696e 7374 616e 6365 2872   if isinstance(r
+0001fe40: 6577 6172 645f 7370 6563 2c20 436f 6d70  eward_spec, Comp
+0001fe50: 6f73 6974 6553 7065 6329 3a0d 0a20 2020  ositeSpec):..   
+0001fe60: 2020 2020 2020 2020 2023 2049 6620 7265           # If re
+0001fe70: 7761 7264 5f73 7065 6320 6973 2061 2043  ward_spec is a C
+0001fe80: 6f6d 706f 7369 7465 5370 6563 2c20 616c  ompositeSpec, al
+0001fe90: 6c20 696e 5f6b 6579 7320 7368 6f75 6c64  l in_keys should
+0001fea0: 2062 6520 6b65 7973 206f 6620 7265 7761   be keys of rewa
+0001feb0: 7264 5f73 7065 630d 0a20 2020 2020 2020  rd_spec..       
+0001fec0: 2020 2020 2069 6620 6e6f 7420 616c 6c28       if not all(
+0001fed0: 6b20 696e 2072 6577 6172 645f 7370 6563  k in reward_spec
+0001fee0: 2e6b 6579 7328 5472 7565 2c20 5472 7565  .keys(True, True
+0001fef0: 2920 666f 7220 6b20 696e 2073 656c 662e  ) for k in self.
+0001ff00: 696e 5f6b 6579 7329 3a0d 0a20 2020 2020  in_keys):..     
+0001ff10: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+0001ff20: 204b 6579 4572 726f 7228 224e 6f74 2061   KeyError("Not a
+0001ff30: 6c6c 2069 6e5f 6b65 7973 2061 7265 2070  ll in_keys are p
+0001ff40: 7265 7365 6e74 2069 6e20 c2b4 7265 7761  resent in ..rewa
+0001ff50: 7264 5f73 7065 63c2 b422 290d 0a0d 0a20  rd_spec..").... 
+0001ff60: 2020 2020 2020 2020 2020 2023 2044 6566             # Def
+0001ff70: 696e 6520 6570 6973 6f64 6520 7370 6563  ine episode spec
+0001ff80: 7320 666f 7220 616c 6c20 6f75 745f 6b65  s for all out_ke
+0001ff90: 7973 0d0a 2020 2020 2020 2020 2020 2020  ys..            
+0001ffa0: 666f 7220 6f75 745f 6b65 7920 696e 2073  for out_key in s
+0001ffb0: 656c 662e 6f75 745f 6b65 7973 3a0d 0a20  elf.out_keys:.. 
+0001ffc0: 2020 2020 2020 2020 2020 2020 2020 2065                 e
+0001ffd0: 7069 736f 6465 5f73 7065 6320 3d20 556e  pisode_spec = Un
+0001ffe0: 626f 756e 6465 6443 6f6e 7469 6e75 6f75  boundedContinuou
+0001fff0: 7354 656e 736f 7253 7065 6328 0d0a 2020  sTensorSpec(..  
+00020000: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00020010: 2020 7368 6170 653d 7265 7761 7264 5f73    shape=reward_s
+00020020: 7065 632e 7368 6170 652c 0d0a 2020 2020  pec.shape,..    
+00020030: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00020040: 6465 7669 6365 3d72 6577 6172 645f 7370  device=reward_sp
+00020050: 6563 2e64 6576 6963 652c 0d0a 2020 2020  ec.device,..    
+00020060: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00020070: 6474 7970 653d 7265 7761 7264 5f73 7065  dtype=reward_spe
+00020080: 632e 6474 7970 652c 0d0a 2020 2020 2020  c.dtype,..      
+00020090: 2020 2020 2020 2020 2020 290d 0a20 2020            )..   
+000200a0: 2020 2020 2020 2020 2020 2020 2065 7069               epi
+000200b0: 736f 6465 5f73 7065 6373 2e75 7064 6174  sode_specs.updat
+000200c0: 6528 7b6f 7574 5f6b 6579 3a20 6570 6973  e({out_key: epis
+000200d0: 6f64 655f 7370 6563 7d29 0d0a 0d0a 2020  ode_spec})....  
+000200e0: 2020 2020 2020 656c 7365 3a0d 0a20 2020        else:..   
+000200f0: 2020 2020 2020 2020 2023 2049 6620 7265           # If re
+00020100: 7761 7264 5f73 7065 6320 6973 206e 6f74  ward_spec is not
+00020110: 2061 2043 6f6d 706f 7369 7465 5370 6563   a CompositeSpec
+00020120: 2c20 7468 6520 6f6e 6c79 2069 6e5f 6b65  , the only in_ke
+00020130: 7920 7368 6f75 6c64 2062 6520 c2b4 7265  y should be ..re
+00020140: 7761 7264 c2b4 0d0a 2020 2020 2020 2020  ward....        
+00020150: 2020 2020 6966 2073 6574 2873 656c 662e      if set(self.
+00020160: 696e 5f6b 6579 7329 2021 3d20 7b22 7265  in_keys) != {"re
+00020170: 7761 7264 227d 3a0d 0a20 2020 2020 2020  ward"}:..       
+00020180: 2020 2020 2020 2020 2072 6169 7365 204b           raise K
+00020190: 6579 4572 726f 7228 0d0a 2020 2020 2020  eyError(..      
+000201a0: 2020 2020 2020 2020 2020 2020 2020 2272                "r
+000201b0: 6577 6172 645f 7370 6563 2069 7320 6e6f  eward_spec is no
+000201c0: 7420 6120 436f 6d70 6f73 6974 6553 7065  t a CompositeSpe
+000201d0: 6320 636c 6173 732c 2069 6e5f 6b65 7973  c class, in_keys
+000201e0: 2073 686f 756c 6420 6f6e 6c79 2069 6e63   should only inc
+000201f0: 6c75 6465 20c2 b472 6577 6172 64c2 b422  lude ..reward.."
+00020200: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00020210: 2020 290d 0a0d 0a20 2020 2020 2020 2020    )....         
+00020220: 2020 2023 2044 6566 696e 6520 6570 6973     # Define epis
+00020230: 6f64 6520 7370 6563 0d0a 2020 2020 2020  ode spec..      
+00020240: 2020 2020 2020 6570 6973 6f64 655f 7370        episode_sp
+00020250: 6563 203d 2055 6e62 6f75 6e64 6564 436f  ec = UnboundedCo
+00020260: 6e74 696e 756f 7573 5465 6e73 6f72 5370  ntinuousTensorSp
+00020270: 6563 280d 0a20 2020 2020 2020 2020 2020  ec(..           
+00020280: 2020 2020 2064 6576 6963 653d 7265 7761       device=rewa
+00020290: 7264 5f73 7065 632e 6465 7669 6365 2c0d  rd_spec.device,.
+000202a0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000202b0: 2064 7479 7065 3d72 6577 6172 645f 7370   dtype=reward_sp
+000202c0: 6563 2e64 7479 7065 2c0d 0a20 2020 2020  ec.dtype,..     
+000202d0: 2020 2020 2020 2020 2020 2073 6861 7065             shape
+000202e0: 3d72 6577 6172 645f 7370 6563 2e73 6861  =reward_spec.sha
+000202f0: 7065 2c0d 0a20 2020 2020 2020 2020 2020  pe,..           
+00020300: 2029 0d0a 2020 2020 2020 2020 2020 2020   )..            
+00020310: 6570 6973 6f64 655f 7370 6563 732e 7570  episode_specs.up
+00020320: 6461 7465 287b 2265 7069 736f 6465 5f72  date({"episode_r
+00020330: 6577 6172 6422 3a20 6570 6973 6f64 655f  eward": episode_
+00020340: 7370 6563 7d29 0d0a 0d0a 2020 2020 2020  spec})....      
+00020350: 2020 2320 5570 6461 7465 206f 6273 6572    # Update obser
+00020360: 7661 7469 6f6e 5f73 7065 6320 7769 7468  vation_spec with
+00020370: 2065 7069 736f 6465 5f73 7065 6373 0d0a   episode_specs..
+00020380: 2020 2020 2020 2020 6966 206e 6f74 2069          if not i
+00020390: 7369 6e73 7461 6e63 6528 6f62 7365 7276  sinstance(observ
+000203a0: 6174 696f 6e5f 7370 6563 2c20 436f 6d70  ation_spec, Comp
+000203b0: 6f73 6974 6553 7065 6329 3a0d 0a20 2020  ositeSpec):..   
+000203c0: 2020 2020 2020 2020 206f 6273 6572 7661           observa
+000203d0: 7469 6f6e 5f73 7065 6320 3d20 436f 6d70  tion_spec = Comp
+000203e0: 6f73 6974 6553 7065 6328 0d0a 2020 2020  ositeSpec(..    
+000203f0: 2020 2020 2020 2020 2020 2020 6f62 7365              obse
+00020400: 7276 6174 696f 6e3d 6f62 7365 7276 6174  rvation=observat
+00020410: 696f 6e5f 7370 6563 2c20 7368 6170 653d  ion_spec, shape=
+00020420: 7365 6c66 2e70 6172 656e 742e 6261 7463  self.parent.batc
+00020430: 685f 7369 7a65 0d0a 2020 2020 2020 2020  h_size..        
+00020440: 2020 2020 290d 0a20 2020 2020 2020 206f      )..        o
+00020450: 6273 6572 7661 7469 6f6e 5f73 7065 632e  bservation_spec.
+00020460: 7570 6461 7465 2865 7069 736f 6465 5f73  update(episode_s
+00020470: 7065 6373 290d 0a20 2020 2020 2020 2072  pecs)..        r
+00020480: 6574 7572 6e20 6f62 7365 7276 6174 696f  eturn observatio
+00020490: 6e5f 7370 6563 0d0a 0d0a 2020 2020 6465  n_spec....    de
+000204a0: 6620 666f 7277 6172 6428 7365 6c66 2c20  f forward(self, 
+000204b0: 7465 6e73 6f72 6469 6374 3a20 5465 6e73  tensordict: Tens
+000204c0: 6f72 4469 6374 4261 7365 2920 2d3e 2054  orDictBase) -> T
+000204d0: 656e 736f 7244 6963 7442 6173 653a 0d0a  ensorDictBase:..
+000204e0: 2020 2020 2020 2020 7261 6973 6520 4e6f          raise No
+000204f0: 7449 6d70 6c65 6d65 6e74 6564 4572 726f  tImplementedErro
+00020500: 7228 0d0a 2020 2020 2020 2020 2020 2020  r(..            
+00020510: 464f 5257 4152 445f 4e4f 545f 494d 504c  FORWARD_NOT_IMPL
+00020520: 454d 454e 5445 442e 666f 726d 6174 2873  EMENTED.format(s
+00020530: 656c 662e 5f5f 636c 6173 735f 5f2e 5f5f  elf.__class__.__
+00020540: 6e61 6d65 5f5f 290d 0a20 2020 2020 2020  name__)..       
+00020550: 2029 0d0a 0d0a 0d0a 636c 6173 7320 5374   )......class St
+00020560: 6570 436f 756e 7465 7228 5472 616e 7366  epCounter(Transf
+00020570: 6f72 6d29 3a0d 0a20 2020 2022 2222 436f  orm):..    """Co
+00020580: 756e 7473 2074 6865 2073 7465 7073 2066  unts the steps f
+00020590: 726f 6d20 6120 7265 7365 7420 616e 6420  rom a reset and 
+000205a0: 7365 7473 2074 6865 2064 6f6e 6520 7374  sets the done st
+000205b0: 6174 6520 746f 2054 7275 6520 6166 7465  ate to True afte
+000205c0: 7220 6120 6365 7274 6169 6e20 6e75 6d62  r a certain numb
+000205d0: 6572 206f 6620 7374 6570 732e 0d0a 0d0a  er of steps.....
+000205e0: 2020 2020 4172 6773 3a0d 0a20 2020 2020      Args:..     
+000205f0: 2020 206d 6178 5f73 7465 7073 2028 696e     max_steps (in
+00020600: 742c 206f 7074 696f 6e61 6c29 3a20 6120  t, optional): a 
+00020610: 706f 7369 7469 7665 2069 6e74 6567 6572  positive integer
+00020620: 2074 6861 7420 696e 6469 6361 7465 7320   that indicates 
+00020630: 7468 650d 0a20 2020 2020 2020 2020 2020  the..           
+00020640: 206d 6178 696d 756d 206e 756d 6265 7220   maximum number 
+00020650: 6f66 2073 7465 7073 2074 6f20 7461 6b65  of steps to take
+00020660: 2062 6566 6f72 6520 7365 7474 696e 6720   before setting 
+00020670: 7468 6520 6060 7472 756e 6361 7465 645f  the ``truncated_
+00020680: 6b65 7960 600d 0a20 2020 2020 2020 2020  key``..         
+00020690: 2020 2065 6e74 7279 2074 6f20 6060 5472     entry to ``Tr
+000206a0: 7565 6060 2e0d 0a20 2020 2020 2020 2020  ue``...         
+000206b0: 2020 2048 6f77 6576 6572 2c20 7468 6520     However, the 
+000206c0: 7374 6570 2063 6f75 6e74 2077 696c 6c20  step count will 
+000206d0: 7374 696c 6c20 6265 0d0a 2020 2020 2020  still be..      
+000206e0: 2020 2020 2020 696e 6372 656d 656e 7465        incremente
+000206f0: 6420 6f6e 2065 6163 6820 6361 6c6c 2074  d on each call t
+00020700: 6f20 7374 6570 2829 2069 6e74 6f20 7468  o step() into th
+00020710: 6520 6073 7465 705f 636f 756e 7460 2061  e `step_count` a
+00020720: 7474 7269 6275 7465 2e0d 0a20 2020 2020  ttribute...     
+00020730: 2020 2074 7275 6e63 6174 6564 5f6b 6579     truncated_key
+00020740: 2028 7374 722c 206f 7074 696f 6e61 6c29   (str, optional)
+00020750: 3a20 7468 6520 6b65 7920 7768 6572 6520  : the key where 
+00020760: 7468 6520 7472 756e 6361 7465 6420 6b65  the truncated ke
+00020770: 7920 7368 6f75 6c64 0d0a 2020 2020 2020  y should..      
+00020780: 2020 2020 2020 6265 2077 7269 7474 656e        be written
+00020790: 2e20 4465 6661 756c 7473 2074 6f20 6060  . Defaults to ``
+000207a0: 2274 7275 6e63 6174 6564 2260 602c 2077  "truncated"``, w
+000207b0: 6869 6368 2069 7320 7265 636f 676e 6973  hich is recognis
+000207c0: 6564 2062 790d 0a20 2020 2020 2020 2020  ed by..         
+000207d0: 2020 2064 6174 6120 636f 6c6c 6563 746f     data collecto
+000207e0: 7273 2061 7320 6120 7265 7365 7420 7369  rs as a reset si
+000207f0: 676e 616c 2e0d 0a20 2020 2022 2222 0d0a  gnal...    """..
+00020800: 0d0a 2020 2020 696e 7665 7274 6962 6c65  ..    invertible
+00020810: 203d 2046 616c 7365 0d0a 0d0a 2020 2020   = False....    
+00020820: 6465 6620 5f5f 696e 6974 5f5f 280d 0a20  def __init__(.. 
+00020830: 2020 2020 2020 2073 656c 662c 206d 6178         self, max
+00020840: 5f73 7465 7073 3a20 4f70 7469 6f6e 616c  _steps: Optional
+00020850: 5b69 6e74 5d20 3d20 4e6f 6e65 2c20 7472  [int] = None, tr
+00020860: 756e 6361 7465 645f 6b65 793a 2073 7472  uncated_key: str
+00020870: 203d 2022 7472 756e 6361 7465 6422 0d0a   = "truncated"..
+00020880: 2020 2020 293a 0d0a 2020 2020 2020 2020      ):..        
+00020890: 6966 206d 6178 5f73 7465 7073 2069 7320  if max_steps is 
+000208a0: 6e6f 7420 4e6f 6e65 2061 6e64 206d 6178  not None and max
+000208b0: 5f73 7465 7073 203c 2031 3a0d 0a20 2020  _steps < 1:..   
+000208c0: 2020 2020 2020 2020 2072 6169 7365 2056           raise V
+000208d0: 616c 7565 4572 726f 7228 226d 6178 5f73  alueError("max_s
+000208e0: 7465 7073 2073 686f 756c 6420 6861 7665  teps should have
+000208f0: 2061 2076 616c 7565 2067 7265 6174 6572   a value greater
+00020900: 206f 7220 6571 7561 6c20 746f 206f 6e65   or equal to one
+00020910: 2e22 290d 0a20 2020 2020 2020 2073 656c  .")..        sel
+00020920: 662e 6d61 785f 7374 6570 7320 3d20 6d61  f.max_steps = ma
+00020930: 785f 7374 6570 730d 0a20 2020 2020 2020  x_steps..       
+00020940: 2073 656c 662e 7472 756e 6361 7465 645f   self.truncated_
+00020950: 6b65 7920 3d20 7472 756e 6361 7465 645f  key = truncated_
+00020960: 6b65 790d 0a20 2020 2020 2020 2073 7570  key..        sup
+00020970: 6572 2829 2e5f 5f69 6e69 745f 5f28 5b5d  er().__init__([]
+00020980: 290d 0a0d 0a20 2020 2064 6566 2072 6573  )....    def res
+00020990: 6574 2873 656c 662c 2074 656e 736f 7264  et(self, tensord
+000209a0: 6963 743a 2054 656e 736f 7244 6963 7442  ict: TensorDictB
+000209b0: 6173 6529 202d 3e20 5465 6e73 6f72 4469  ase) -> TensorDi
+000209c0: 6374 4261 7365 3a0d 0a20 2020 2020 2020  ctBase:..       
+000209d0: 2064 6f6e 6520 3d20 7465 6e73 6f72 6469   done = tensordi
+000209e0: 6374 2e67 6574 2822 646f 6e65 222c 204e  ct.get("done", N
+000209f0: 6f6e 6529 0d0a 2020 2020 2020 2020 6966  one)..        if
+00020a00: 2064 6f6e 6520 6973 204e 6f6e 653a 0d0a   done is None:..
+00020a10: 2020 2020 2020 2020 2020 2020 646f 6e65              done
+00020a20: 203d 2074 6f72 6368 2e6f 6e65 7328 0d0a   = torch.ones(..
+00020a30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00020a40: 7365 6c66 2e70 6172 656e 742e 646f 6e65  self.parent.done
+00020a50: 5f73 7065 632e 7368 6170 652c 0d0a 2020  _spec.shape,..  
+00020a60: 2020 2020 2020 2020 2020 2020 2020 6474                dt
+00020a70: 7970 653d 7365 6c66 2e70 6172 656e 742e  ype=self.parent.
+00020a80: 646f 6e65 5f73 7065 632e 6474 7970 652c  done_spec.dtype,
+00020a90: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00020aa0: 2020 6465 7669 6365 3d73 656c 662e 7061    device=self.pa
+00020ab0: 7265 6e74 2e64 6f6e 655f 7370 6563 2e64  rent.done_spec.d
+00020ac0: 6576 6963 652c 0d0a 2020 2020 2020 2020  evice,..        
+00020ad0: 2020 2020 290d 0a20 2020 2020 2020 205f      )..        _
+00020ae0: 7265 7365 7420 3d20 7465 6e73 6f72 6469  reset = tensordi
+00020af0: 6374 2e67 6574 280d 0a20 2020 2020 2020  ct.get(..       
+00020b00: 2020 2020 2022 5f72 6573 6574 222c 0d0a       "_reset",..
+00020b10: 2020 2020 2020 2020 2020 2020 2320 544f              # TO
+00020b20: 444f 3a20 6465 6369 6465 2069 6620 7573  DO: decide if us
+00020b30: 696e 6720 646f 6e65 2068 6572 652c 206f  ing done here, o
+00020b40: 7220 7573 696e 6720 6120 6465 6661 756c  r using a defaul
+00020b50: 7420 6054 7275 6560 2074 656e 736f 720d  t `True` tensor.
+00020b60: 0a20 2020 2020 2020 2020 2020 2064 6566  .            def
+00020b70: 6175 6c74 3d4e 6f6e 652c 0d0a 2020 2020  ault=None,..    
+00020b80: 2020 2020 290d 0a20 2020 2020 2020 2069      )..        i
+00020b90: 6620 5f72 6573 6574 2069 7320 4e6f 6e65  f _reset is None
+00020ba0: 3a0d 0a20 2020 2020 2020 2020 2020 205f  :..            _
+00020bb0: 7265 7365 7420 3d20 746f 7263 682e 6f6e  reset = torch.on
+00020bc0: 6573 5f6c 696b 6528 646f 6e65 290d 0a20  es_like(done).. 
+00020bd0: 2020 2020 2020 2073 7465 705f 636f 756e         step_coun
+00020be0: 7420 3d20 7465 6e73 6f72 6469 6374 2e67  t = tensordict.g
+00020bf0: 6574 280d 0a20 2020 2020 2020 2020 2020  et(..           
+00020c00: 2022 7374 6570 5f63 6f75 6e74 222c 0d0a   "step_count",..
+00020c10: 2020 2020 2020 2020 2020 2020 6465 6661              defa
+00020c20: 756c 743d 4e6f 6e65 2c0d 0a20 2020 2020  ult=None,..     
+00020c30: 2020 2029 0d0a 2020 2020 2020 2020 6966     )..        if
+00020c40: 2073 7465 705f 636f 756e 7420 6973 204e   step_count is N
+00020c50: 6f6e 653a 0d0a 2020 2020 2020 2020 2020  one:..          
+00020c60: 2020 7374 6570 5f63 6f75 6e74 203d 2074    step_count = t
+00020c70: 6f72 6368 2e7a 6572 6f73 5f6c 696b 6528  orch.zeros_like(
+00020c80: 646f 6e65 2c20 6474 7970 653d 746f 7263  done, dtype=torc
+00020c90: 682e 696e 7436 3429 0d0a 0d0a 2020 2020  h.int64)....    
+00020ca0: 2020 2020 7374 6570 5f63 6f75 6e74 5b5f      step_count[_
+00020cb0: 7265 7365 745d 203d 2030 0d0a 2020 2020  reset] = 0..    
+00020cc0: 2020 2020 7465 6e73 6f72 6469 6374 2e73      tensordict.s
+00020cd0: 6574 280d 0a20 2020 2020 2020 2020 2020  et(..           
+00020ce0: 2022 7374 6570 5f63 6f75 6e74 222c 0d0a   "step_count",..
+00020cf0: 2020 2020 2020 2020 2020 2020 7374 6570              step
+00020d00: 5f63 6f75 6e74 2c0d 0a20 2020 2020 2020  _count,..       
+00020d10: 2029 0d0a 2020 2020 2020 2020 6966 2073   )..        if s
+00020d20: 656c 662e 6d61 785f 7374 6570 7320 6973  elf.max_steps is
+00020d30: 206e 6f74 204e 6f6e 653a 0d0a 2020 2020   not None:..    
+00020d40: 2020 2020 2020 2020 7472 756e 6361 7465          truncate
+00020d50: 6420 3d20 7374 6570 5f63 6f75 6e74 203e  d = step_count >
+00020d60: 3d20 7365 6c66 2e6d 6178 5f73 7465 7073  = self.max_steps
+00020d70: 0d0a 2020 2020 2020 2020 2020 2020 7465  ..            te
+00020d80: 6e73 6f72 6469 6374 2e73 6574 2873 656c  nsordict.set(sel
+00020d90: 662e 7472 756e 6361 7465 645f 6b65 792c  f.truncated_key,
+00020da0: 2074 7275 6e63 6174 6564 290d 0a20 2020   truncated)..   
+00020db0: 2020 2020 2072 6574 7572 6e20 7465 6e73       return tens
+00020dc0: 6f72 6469 6374 0d0a 0d0a 2020 2020 6465  ordict....    de
+00020dd0: 6620 5f73 7465 7028 7365 6c66 2c20 7465  f _step(self, te
+00020de0: 6e73 6f72 6469 6374 3a20 5465 6e73 6f72  nsordict: Tensor
+00020df0: 4469 6374 4261 7365 2920 2d3e 2054 656e  DictBase) -> Ten
+00020e00: 736f 7244 6963 7442 6173 653a 0d0a 2020  sorDictBase:..  
+00020e10: 2020 2020 2020 7465 6e73 6f72 6469 6374        tensordict
+00020e20: 203d 2074 656e 736f 7264 6963 742e 636c   = tensordict.cl
+00020e30: 6f6e 6528 4661 6c73 6529 0d0a 2020 2020  one(False)..    
+00020e40: 2020 2020 7374 6570 5f63 6f75 6e74 203d      step_count =
+00020e50: 2074 656e 736f 7264 6963 742e 6765 7428   tensordict.get(
+00020e60: 0d0a 2020 2020 2020 2020 2020 2020 2273  ..            "s
+00020e70: 7465 705f 636f 756e 7422 2c0d 0a20 2020  tep_count",..   
+00020e80: 2020 2020 2029 0d0a 2020 2020 2020 2020       )..        
+00020e90: 6e65 7874 5f73 7465 705f 636f 756e 7420  next_step_count 
+00020ea0: 3d20 7374 6570 5f63 6f75 6e74 202b 2031  = step_count + 1
+00020eb0: 0d0a 2020 2020 2020 2020 7465 6e73 6f72  ..        tensor
+00020ec0: 6469 6374 2e73 6574 2828 226e 6578 7422  dict.set(("next"
+00020ed0: 2c20 2273 7465 705f 636f 756e 7422 292c  , "step_count"),
+00020ee0: 206e 6578 745f 7374 6570 5f63 6f75 6e74   next_step_count
+00020ef0: 290d 0a20 2020 2020 2020 2069 6620 7365  )..        if se
+00020f00: 6c66 2e6d 6178 5f73 7465 7073 2069 7320  lf.max_steps is 
+00020f10: 6e6f 7420 4e6f 6e65 3a0d 0a20 2020 2020  not None:..     
+00020f20: 2020 2020 2020 2074 7275 6e63 6174 6564         truncated
+00020f30: 203d 206e 6578 745f 7374 6570 5f63 6f75   = next_step_cou
+00020f40: 6e74 203e 3d20 7365 6c66 2e6d 6178 5f73  nt >= self.max_s
+00020f50: 7465 7073 0d0a 2020 2020 2020 2020 2020  teps..          
+00020f60: 2020 7465 6e73 6f72 6469 6374 2e73 6574    tensordict.set
+00020f70: 2828 226e 6578 7422 2c20 7365 6c66 2e74  (("next", self.t
+00020f80: 7275 6e63 6174 6564 5f6b 6579 292c 2074  runcated_key), t
+00020f90: 7275 6e63 6174 6564 290d 0a20 2020 2020  runcated)..     
+00020fa0: 2020 2072 6574 7572 6e20 7465 6e73 6f72     return tensor
+00020fb0: 6469 6374 0d0a 0d0a 2020 2020 6465 6620  dict....    def 
+00020fc0: 7472 616e 7366 6f72 6d5f 6f62 7365 7276  transform_observ
+00020fd0: 6174 696f 6e5f 7370 6563 280d 0a20 2020  ation_spec(..   
+00020fe0: 2020 2020 2073 656c 662c 206f 6273 6572       self, obser
+00020ff0: 7661 7469 6f6e 5f73 7065 633a 2043 6f6d  vation_spec: Com
+00021000: 706f 7369 7465 5370 6563 0d0a 2020 2020  positeSpec..    
+00021010: 2920 2d3e 2043 6f6d 706f 7369 7465 5370  ) -> CompositeSp
+00021020: 6563 3a0d 0a20 2020 2020 2020 2069 6620  ec:..        if 
+00021030: 6e6f 7420 6973 696e 7374 616e 6365 286f  not isinstance(o
+00021040: 6273 6572 7661 7469 6f6e 5f73 7065 632c  bservation_spec,
+00021050: 2043 6f6d 706f 7369 7465 5370 6563 293a   CompositeSpec):
+00021060: 0d0a 2020 2020 2020 2020 2020 2020 7261  ..            ra
+00021070: 6973 6520 5661 6c75 6545 7272 6f72 280d  ise ValueError(.
+00021080: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00021090: 2066 226f 6273 6572 7661 7469 6f6e 5f73   f"observation_s
+000210a0: 7065 6320 7761 7320 6578 7065 6374 6564  pec was expected
+000210b0: 2074 6f20 6265 206f 6620 7479 7065 2043   to be of type C
+000210c0: 6f6d 706f 7369 7465 5370 6563 2e20 476f  ompositeSpec. Go
+000210d0: 7420 7b74 7970 6528 6f62 7365 7276 6174  t {type(observat
+000210e0: 696f 6e5f 7370 6563 297d 2069 6e73 7465  ion_spec)} inste
+000210f0: 6164 2e22 0d0a 2020 2020 2020 2020 2020  ad."..          
+00021100: 2020 290d 0a20 2020 2020 2020 206f 6273    )..        obs
+00021110: 6572 7661 7469 6f6e 5f73 7065 635b 2273  ervation_spec["s
+00021120: 7465 705f 636f 756e 7422 5d20 3d20 556e  tep_count"] = Un
+00021130: 626f 756e 6465 6444 6973 6372 6574 6554  boundedDiscreteT
+00021140: 656e 736f 7253 7065 6328 0d0a 2020 2020  ensorSpec(..    
+00021150: 2020 2020 2020 2020 7368 6170 653d 7365          shape=se
+00021160: 6c66 2e70 6172 656e 742e 646f 6e65 5f73  lf.parent.done_s
+00021170: 7065 632e 7368 6170 650d 0a20 2020 2020  pec.shape..     
+00021180: 2020 2020 2020 2069 6620 7365 6c66 2e70         if self.p
+00021190: 6172 656e 740d 0a20 2020 2020 2020 2020  arent..         
+000211a0: 2020 2065 6c73 6520 6f62 7365 7276 6174     else observat
+000211b0: 696f 6e5f 7370 6563 2e73 6861 7065 2c0d  ion_spec.shape,.
+000211c0: 0a20 2020 2020 2020 2020 2020 2064 7479  .            dty
+000211d0: 7065 3d74 6f72 6368 2e69 6e74 3634 2c0d  pe=torch.int64,.
+000211e0: 0a20 2020 2020 2020 2020 2020 2064 6576  .            dev
+000211f0: 6963 653d 6f62 7365 7276 6174 696f 6e5f  ice=observation_
+00021200: 7370 6563 2e64 6576 6963 652c 0d0a 2020  spec.device,..  
+00021210: 2020 2020 2020 290d 0a20 2020 2020 2020        )..       
+00021220: 206f 6273 6572 7661 7469 6f6e 5f73 7065   observation_spe
+00021230: 635b 2273 7465 705f 636f 756e 7422 5d2e  c["step_count"].
+00021240: 7370 6163 652e 6d69 6e69 6d75 6d20 3d20  space.minimum = 
+00021250: 280d 0a20 2020 2020 2020 2020 2020 206f  (..            o
+00021260: 6273 6572 7661 7469 6f6e 5f73 7065 635b  bservation_spec[
+00021270: 2273 7465 705f 636f 756e 7422 5d2e 7370  "step_count"].sp
+00021280: 6163 652e 6d69 6e69 6d75 6d20 2a20 300d  ace.minimum * 0.
+00021290: 0a20 2020 2020 2020 2029 0d0a 2020 2020  .        )..    
+000212a0: 2020 2020 6966 2073 656c 662e 6d61 785f      if self.max_
+000212b0: 7374 6570 7320 6973 206e 6f74 204e 6f6e  steps is not Non
+000212c0: 6520 616e 6420 7365 6c66 2e74 7275 6e63  e and self.trunc
+000212d0: 6174 6564 5f6b 6579 2021 3d20 2264 6f6e  ated_key != "don
+000212e0: 6522 3a0d 0a20 2020 2020 2020 2020 2020  e":..           
+000212f0: 206f 6273 6572 7661 7469 6f6e 5f73 7065   observation_spe
+00021300: 635b 7365 6c66 2e74 7275 6e63 6174 6564  c[self.truncated
+00021310: 5f6b 6579 5d20 3d20 7365 6c66 2e70 6172  _key] = self.par
+00021320: 656e 742e 646f 6e65 5f73 7065 632e 636c  ent.done_spec.cl
+00021330: 6f6e 6528 290d 0a20 2020 2020 2020 2072  one()..        r
+00021340: 6574 7572 6e20 6f62 7365 7276 6174 696f  eturn observatio
+00021350: 6e5f 7370 6563 0d0a 0d0a 2020 2020 6465  n_spec....    de
+00021360: 6620 7472 616e 7366 6f72 6d5f 696e 7075  f transform_inpu
+00021370: 745f 7370 6563 2873 656c 662c 2069 6e70  t_spec(self, inp
+00021380: 7574 5f73 7065 633a 2043 6f6d 706f 7369  ut_spec: Composi
+00021390: 7465 5370 6563 2920 2d3e 2043 6f6d 706f  teSpec) -> Compo
+000213a0: 7369 7465 5370 6563 3a0d 0a20 2020 2020  siteSpec:..     
+000213b0: 2020 2069 6620 6e6f 7420 6973 696e 7374     if not isinst
+000213c0: 616e 6365 2869 6e70 7574 5f73 7065 632c  ance(input_spec,
+000213d0: 2043 6f6d 706f 7369 7465 5370 6563 293a   CompositeSpec):
+000213e0: 0d0a 2020 2020 2020 2020 2020 2020 7261  ..            ra
+000213f0: 6973 6520 5661 6c75 6545 7272 6f72 280d  ise ValueError(.
+00021400: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00021410: 2066 2269 6e70 7574 5f73 7065 6320 7761   f"input_spec wa
+00021420: 7320 6578 7065 6374 6564 2074 6f20 6265  s expected to be
+00021430: 206f 6620 7479 7065 2043 6f6d 706f 7369   of type Composi
+00021440: 7465 5370 6563 2e20 476f 7420 7b74 7970  teSpec. Got {typ
+00021450: 6528 696e 7075 745f 7370 6563 297d 2069  e(input_spec)} i
+00021460: 6e73 7465 6164 2e22 0d0a 2020 2020 2020  nstead."..      
+00021470: 2020 2020 2020 290d 0a20 2020 2020 2020        )..       
+00021480: 2069 6e70 7574 5f73 7065 635b 2273 7465   input_spec["ste
+00021490: 705f 636f 756e 7422 5d20 3d20 556e 626f  p_count"] = Unbo
+000214a0: 756e 6465 6444 6973 6372 6574 6554 656e  undedDiscreteTen
+000214b0: 736f 7253 7065 6328 0d0a 2020 2020 2020  sorSpec(..      
+000214c0: 2020 2020 2020 7368 6170 653d 7365 6c66        shape=self
+000214d0: 2e70 6172 656e 742e 646f 6e65 5f73 7065  .parent.done_spe
+000214e0: 632e 7368 6170 6520 6966 2073 656c 662e  c.shape if self.
+000214f0: 7061 7265 6e74 2065 6c73 6520 696e 7075  parent else inpu
+00021500: 745f 7370 6563 2e73 6861 7065 2c0d 0a20  t_spec.shape,.. 
+00021510: 2020 2020 2020 2020 2020 2064 7479 7065             dtype
+00021520: 3d74 6f72 6368 2e69 6e74 3634 2c0d 0a20  =torch.int64,.. 
+00021530: 2020 2020 2020 2020 2020 2064 6576 6963             devic
+00021540: 653d 696e 7075 745f 7370 6563 2e64 6576  e=input_spec.dev
+00021550: 6963 652c 0d0a 2020 2020 2020 2020 290d  ice,..        ).
+00021560: 0a20 2020 2020 2020 2069 6e70 7574 5f73  .        input_s
+00021570: 7065 635b 2273 7465 705f 636f 756e 7422  pec["step_count"
+00021580: 5d2e 7370 6163 652e 6d69 6e69 6d75 6d20  ].space.minimum 
+00021590: 3d20 280d 0a20 2020 2020 2020 2020 2020  = (..           
+000215a0: 2069 6e70 7574 5f73 7065 635b 2273 7465   input_spec["ste
+000215b0: 705f 636f 756e 7422 5d2e 7370 6163 652e  p_count"].space.
+000215c0: 6d69 6e69 6d75 6d20 2a20 300d 0a20 2020  minimum * 0..   
+000215d0: 2020 2020 2029 0d0a 2020 2020 2020 2020       )..        
+000215e0: 7265 7475 726e 2069 6e70 7574 5f73 7065  return input_spe
+000215f0: 630d 0a0d 0a20 2020 2064 6566 2066 6f72  c....    def for
+00021600: 7761 7264 2873 656c 662c 2074 656e 736f  ward(self, tenso
+00021610: 7264 6963 743a 2054 656e 736f 7244 6963  rdict: TensorDic
+00021620: 7442 6173 6529 202d 3e20 5465 6e73 6f72  tBase) -> Tensor
+00021630: 4469 6374 4261 7365 3a0d 0a20 2020 2020  DictBase:..     
+00021640: 2020 2072 6169 7365 204e 6f74 496d 706c     raise NotImpl
+00021650: 656d 656e 7465 6445 7272 6f72 280d 0a20  ementedError(.. 
+00021660: 2020 2020 2020 2020 2020 2022 5374 6570             "Step
+00021670: 436f 756e 7465 7220 6361 6e6e 6f74 2062  Counter cannot b
+00021680: 6520 6361 6c6c 6564 2069 6e64 6570 656e  e called indepen
+00021690: 6465 6e74 6c79 2c20 6f6e 6c79 2069 7473  dently, only its
+000216a0: 2073 7465 7020 616e 6420 7265 7365 7420   step and reset 
+000216b0: 6d65 7468 6f64 7320 220d 0a20 2020 2020  methods "..     
+000216c0: 2020 2020 2020 2022 6172 6520 6675 6e63         "are func
+000216d0: 7469 6f6e 616c 2e20 5468 6520 7265 6173  tional. The reas
+000216e0: 6f6e 2066 6f72 2074 6869 7320 6973 2074  on for this is t
+000216f0: 6861 7420 6974 2069 7320 6861 7264 2074  hat it is hard t
+00021700: 6f20 636f 6e73 6964 6572 2075 7369 6e67  o consider using
+00021710: 2022 0d0a 2020 2020 2020 2020 2020 2020   "..            
+00021720: 2253 7465 7043 6f75 6e74 6572 2077 6974  "StepCounter wit
+00021730: 6820 6e6f 6e2d 7365 7175 656e 7469 616c  h non-sequential
+00021740: 2064 6174 612c 2073 7563 6820 6173 2074   data, such as t
+00021750: 686f 7365 2063 6f6c 6c65 6374 6564 2062  hose collected b
+00021760: 7920 6120 7265 706c 6179 2062 7566 6665  y a replay buffe
+00021770: 7220 220d 0a20 2020 2020 2020 2020 2020  r "..           
+00021780: 2022 6f72 2061 2064 6174 6173 6574 2e20   "or a dataset. 
+00021790: 4966 2079 6f75 206e 6565 6420 5374 6570  If you need Step
+000217a0: 436f 756e 7465 7220 746f 2077 6f72 6b20  Counter to work 
+000217b0: 6f6e 2061 2062 6174 6368 206f 6620 7365  on a batch of se
+000217c0: 7175 656e 7469 616c 2064 6174 6120 220d  quential data ".
+000217d0: 0a20 2020 2020 2020 2020 2020 2022 2869  .            "(i
+000217e0: 6520 6173 204c 5354 4d20 776f 756c 6420  e as LSTM would 
+000217f0: 776f 726b 206f 7665 7220 6120 7768 6f6c  work over a whol
+00021800: 6520 7365 7175 656e 6365 206f 6620 6461  e sequence of da
+00021810: 7461 292c 2066 696c 6520 616e 2069 7373  ta), file an iss
+00021820: 7565 206f 6e20 220d 0a20 2020 2020 2020  ue on "..       
+00021830: 2020 2020 2022 546f 7263 6852 4c20 7265       "TorchRL re
+00021840: 7175 6573 7469 6e67 2074 6861 7420 6665  questing that fe
+00021850: 6174 7572 652e 220d 0a20 2020 2020 2020  ature."..       
+00021860: 2029 0d0a 0d0a 0d0a 636c 6173 7320 4578   )......class Ex
+00021870: 636c 7564 6554 7261 6e73 666f 726d 2854  cludeTransform(T
+00021880: 7261 6e73 666f 726d 293a 0d0a 2020 2020  ransform):..    
+00021890: 2222 2245 7863 6c75 6465 7320 6b65 7973  """Excludes keys
+000218a0: 2066 726f 6d20 7468 6520 696e 7075 7420   from the input 
+000218b0: 7465 6e73 6f72 6469 6374 2e0d 0a0d 0a20  tensordict..... 
+000218c0: 2020 2041 7267 733a 0d0a 2020 2020 2020     Args:..      
+000218d0: 2020 2a65 7863 6c75 6465 645f 6b65 7973    *excluded_keys
+000218e0: 2028 6974 6572 6162 6c65 206f 6620 7374   (iterable of st
+000218f0: 7229 3a20 5468 6520 6e61 6d65 206f 6620  r): The name of 
+00021900: 7468 6520 6b65 7973 2074 6f20 6578 636c  the keys to excl
+00021910: 7564 652e 2049 6620 7468 6520 6b65 7920  ude. If the key 
+00021920: 6973 0d0a 2020 2020 2020 2020 2020 2020  is..            
+00021930: 6e6f 7420 7072 6573 656e 742c 2069 7420  not present, it 
+00021940: 6973 2073 696d 706c 7920 6967 6e6f 7265  is simply ignore
+00021950: 642e 0d0a 0d0a 2020 2020 2222 220d 0a0d  d.....    """...
+00021960: 0a20 2020 2064 6566 205f 5f69 6e69 745f  .    def __init_
+00021970: 5f28 7365 6c66 2c20 2a65 7863 6c75 6465  _(self, *exclude
+00021980: 645f 6b65 7973 293a 0d0a 2020 2020 2020  d_keys):..      
+00021990: 2020 7375 7065 7228 292e 5f5f 696e 6974    super().__init
+000219a0: 5f5f 2869 6e5f 6b65 7973 3d5b 5d2c 2069  __(in_keys=[], i
+000219b0: 6e5f 6b65 7973 5f69 6e76 3d5b 5d2c 206f  n_keys_inv=[], o
+000219c0: 7574 5f6b 6579 733d 5b5d 2c20 6f75 745f  ut_keys=[], out_
+000219d0: 6b65 7973 5f69 6e76 3d5b 5d29 0d0a 2020  keys_inv=[])..  
+000219e0: 2020 2020 2020 7472 793a 0d0a 2020 2020        try:..    
+000219f0: 2020 2020 2020 2020 5f73 6571 5f6f 665f          _seq_of_
+00021a00: 6e65 7374 6564 5f6b 6579 5f63 6865 636b  nested_key_check
+00021a10: 2865 7863 6c75 6465 645f 6b65 7973 290d  (excluded_keys).
+00021a20: 0a20 2020 2020 2020 2065 7863 6570 7420  .        except 
+00021a30: 5661 6c75 6545 7272 6f72 3a0d 0a20 2020  ValueError:..   
+00021a40: 2020 2020 2020 2020 2072 6169 7365 2056           raise V
+00021a50: 616c 7565 4572 726f 7228 0d0a 2020 2020  alueError(..    
+00021a60: 2020 2020 2020 2020 2020 2020 2265 7863              "exc
+00021a70: 6c75 6465 6420 6b65 7973 206d 7573 7420  luded keys must 
+00021a80: 6265 2061 206c 6973 7420 6f72 2074 7570  be a list or tup
+00021a90: 6c65 206f 6620 7374 7269 6e67 7320 6f72  le of strings or
+00021aa0: 2074 7570 6c65 7320 6f66 2073 7472 696e   tuples of strin
+00021ab0: 6773 2e22 0d0a 2020 2020 2020 2020 2020  gs."..          
+00021ac0: 2020 290d 0a20 2020 2020 2020 2073 656c    )..        sel
+00021ad0: 662e 6578 636c 7564 6564 5f6b 6579 7320  f.excluded_keys 
+00021ae0: 3d20 6578 636c 7564 6564 5f6b 6579 730d  = excluded_keys.
+00021af0: 0a20 2020 2020 2020 2069 6620 2272 6577  .        if "rew
+00021b00: 6172 6422 2069 6e20 6578 636c 7564 6564  ard" in excluded
+00021b10: 5f6b 6579 733a 0d0a 2020 2020 2020 2020  _keys:..        
+00021b20: 2020 2020 7261 6973 6520 5275 6e74 696d      raise Runtim
+00021b30: 6545 7272 6f72 2822 2772 6577 6172 6427  eError("'reward'
+00021b40: 2063 616e 6e6f 7420 6265 2065 7863 6c75   cannot be exclu
+00021b50: 6465 6420 6672 6f6d 2074 6865 206b 6579  ded from the key
+00021b60: 732e 2229 0d0a 0d0a 2020 2020 6465 6620  s.")....    def 
+00021b70: 5f63 616c 6c28 7365 6c66 2c20 7465 6e73  _call(self, tens
+00021b80: 6f72 6469 6374 3a20 5465 6e73 6f72 4469  ordict: TensorDi
+00021b90: 6374 4261 7365 2920 2d3e 2054 656e 736f  ctBase) -> Tenso
+00021ba0: 7244 6963 7442 6173 653a 0d0a 2020 2020  rDictBase:..    
+00021bb0: 2020 2020 7265 7475 726e 2074 656e 736f      return tenso
+00021bc0: 7264 6963 742e 6578 636c 7564 6528 2a73  rdict.exclude(*s
+00021bd0: 656c 662e 6578 636c 7564 6564 5f6b 6579  elf.excluded_key
+00021be0: 7329 0d0a 0d0a 2020 2020 666f 7277 6172  s)....    forwar
+00021bf0: 6420 3d20 5f63 616c 6c0d 0a0d 0a20 2020  d = _call....   
+00021c00: 2064 6566 2072 6573 6574 2873 656c 662c   def reset(self,
+00021c10: 2074 656e 736f 7264 6963 743a 2054 656e   tensordict: Ten
+00021c20: 736f 7244 6963 7442 6173 6529 202d 3e20  sorDictBase) -> 
+00021c30: 5465 6e73 6f72 4469 6374 4261 7365 3a0d  TensorDictBase:.
+00021c40: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00021c50: 7465 6e73 6f72 6469 6374 2e65 7863 6c75  tensordict.exclu
+00021c60: 6465 282a 7365 6c66 2e65 7863 6c75 6465  de(*self.exclude
+00021c70: 645f 6b65 7973 290d 0a0d 0a20 2020 2064  d_keys)....    d
+00021c80: 6566 2074 7261 6e73 666f 726d 5f6f 6273  ef transform_obs
+00021c90: 6572 7661 7469 6f6e 5f73 7065 6328 7365  ervation_spec(se
+00021ca0: 6c66 2c20 6f62 7365 7276 6174 696f 6e5f  lf, observation_
+00021cb0: 7370 6563 3a20 5465 6e73 6f72 5370 6563  spec: TensorSpec
+00021cc0: 2920 2d3e 2054 656e 736f 7253 7065 633a  ) -> TensorSpec:
+00021cd0: 0d0a 2020 2020 2020 2020 6966 2061 6e79  ..        if any
+00021ce0: 286b 6579 2069 6e20 6f62 7365 7276 6174  (key in observat
+00021cf0: 696f 6e5f 7370 6563 2e6b 6579 7328 5472  ion_spec.keys(Tr
+00021d00: 7565 2c20 5472 7565 2920 666f 7220 6b65  ue, True) for ke
+00021d10: 7920 696e 2073 656c 662e 6578 636c 7564  y in self.exclud
+00021d20: 6564 5f6b 6579 7329 3a0d 0a20 2020 2020  ed_keys):..     
+00021d30: 2020 2020 2020 2072 6574 7572 6e20 436f         return Co
+00021d40: 6d70 6f73 6974 6553 7065 6328 0d0a 2020  mpositeSpec(..  
+00021d50: 2020 2020 2020 2020 2020 2020 2020 2a2a                **
+00021d60: 7b0d 0a20 2020 2020 2020 2020 2020 2020  {..             
+00021d70: 2020 2020 2020 206b 6579 3a20 7661 6c75         key: valu
+00021d80: 650d 0a20 2020 2020 2020 2020 2020 2020  e..             
+00021d90: 2020 2020 2020 2066 6f72 206b 6579 2c20         for key, 
+00021da0: 7661 6c75 6520 696e 206f 6273 6572 7661  value in observa
+00021db0: 7469 6f6e 5f73 7065 632e 6974 656d 7328  tion_spec.items(
+00021dc0: 290d 0a20 2020 2020 2020 2020 2020 2020  )..             
+00021dd0: 2020 2020 2020 2069 6620 6b65 7920 6e6f         if key no
+00021de0: 7420 696e 2073 656c 662e 6578 636c 7564  t in self.exclud
+00021df0: 6564 5f6b 6579 730d 0a20 2020 2020 2020  ed_keys..       
+00021e00: 2020 2020 2020 2020 207d 2c0d 0a20 2020           },..   
+00021e10: 2020 2020 2020 2020 2020 2020 2073 6861               sha
+00021e20: 7065 3d6f 6273 6572 7661 7469 6f6e 5f73  pe=observation_s
+00021e30: 7065 632e 7368 6170 652c 0d0a 2020 2020  pec.shape,..    
+00021e40: 2020 2020 2020 2020 290d 0a20 2020 2020          )..     
+00021e50: 2020 2072 6574 7572 6e20 6f62 7365 7276     return observ
+00021e60: 6174 696f 6e5f 7370 6563 0d0a 0d0a 0d0a  ation_spec......
+00021e70: 636c 6173 7320 5365 6c65 6374 5472 616e  class SelectTran
+00021e80: 7366 6f72 6d28 5472 616e 7366 6f72 6d29  sform(Transform)
+00021e90: 3a0d 0a20 2020 2022 2222 5365 6c65 6374  :..    """Select
+00021ea0: 206b 6579 7320 6672 6f6d 2074 6865 2069   keys from the i
+00021eb0: 6e70 7574 2074 656e 736f 7264 6963 742e  nput tensordict.
+00021ec0: 0d0a 0d0a 2020 2020 496e 2067 656e 6572  ....    In gener
+00021ed0: 616c 2c20 7468 6520 3a6f 626a 3a60 4578  al, the :obj:`Ex
+00021ee0: 636c 7564 6554 7261 6e73 666f 726d 6020  cludeTransform` 
+00021ef0: 7368 6f75 6c64 2062 6520 7072 6566 6572  should be prefer
+00021f00: 7265 643a 2074 6869 7320 7472 616e 7366  red: this transf
+00021f10: 6f72 6d73 2061 6c73 6f0d 0a20 2020 2020  orms also..     
+00021f20: 2020 2073 656c 6563 7473 2074 6865 2022     selects the "
+00021f30: 6163 7469 6f6e 2220 286f 7220 6f74 6865  action" (or othe
+00021f40: 7220 6b65 7973 2066 726f 6d20 696e 7075  r keys from inpu
+00021f50: 745f 7370 6563 292c 2022 646f 6e65 2220  t_spec), "done" 
+00021f60: 616e 6420 2272 6577 6172 6422 0d0a 2020  and "reward"..  
+00021f70: 2020 2020 2020 6b65 7973 2062 7574 206f        keys but o
+00021f80: 7468 6572 206d 6179 2062 6520 6e65 6365  ther may be nece
+00021f90: 7373 6172 792e 0d0a 0d0a 2020 2020 4172  ssary.....    Ar
+00021fa0: 6773 3a0d 0a20 2020 2020 2020 202a 7365  gs:..        *se
+00021fb0: 6c65 6374 6564 5f6b 6579 7320 2869 7465  lected_keys (ite
+00021fc0: 7261 626c 6520 6f66 2073 7472 293a 2054  rable of str): T
+00021fd0: 6865 206e 616d 6520 6f66 2074 6865 206b  he name of the k
+00021fe0: 6579 7320 746f 2073 656c 6563 742e 2049  eys to select. I
+00021ff0: 6620 7468 6520 6b65 7920 6973 0d0a 2020  f the key is..  
+00022000: 2020 2020 2020 2020 2020 6e6f 7420 7072            not pr
+00022010: 6573 656e 742c 2069 7420 6973 2073 696d  esent, it is sim
+00022020: 706c 7920 6967 6e6f 7265 642e 0d0a 0d0a  ply ignored.....
+00022030: 2020 2020 2222 220d 0a0d 0a20 2020 2064      """....    d
+00022040: 6566 205f 5f69 6e69 745f 5f28 7365 6c66  ef __init__(self
+00022050: 2c20 2a73 656c 6563 7465 645f 6b65 7973  , *selected_keys
+00022060: 293a 0d0a 2020 2020 2020 2020 7375 7065  ):..        supe
+00022070: 7228 292e 5f5f 696e 6974 5f5f 2869 6e5f  r().__init__(in_
+00022080: 6b65 7973 3d5b 5d2c 2069 6e5f 6b65 7973  keys=[], in_keys
+00022090: 5f69 6e76 3d5b 5d2c 206f 7574 5f6b 6579  _inv=[], out_key
+000220a0: 733d 5b5d 2c20 6f75 745f 6b65 7973 5f69  s=[], out_keys_i
+000220b0: 6e76 3d5b 5d29 0d0a 2020 2020 2020 2020  nv=[])..        
+000220c0: 7472 793a 0d0a 2020 2020 2020 2020 2020  try:..          
+000220d0: 2020 5f73 6571 5f6f 665f 6e65 7374 6564    _seq_of_nested
+000220e0: 5f6b 6579 5f63 6865 636b 2873 656c 6563  _key_check(selec
+000220f0: 7465 645f 6b65 7973 290d 0a20 2020 2020  ted_keys)..     
+00022100: 2020 2065 7863 6570 7420 5661 6c75 6545     except ValueE
+00022110: 7272 6f72 3a0d 0a20 2020 2020 2020 2020  rror:..         
+00022120: 2020 2072 6169 7365 2056 616c 7565 4572     raise ValueEr
+00022130: 726f 7228 0d0a 2020 2020 2020 2020 2020  ror(..          
+00022140: 2020 2020 2020 2273 656c 6563 7465 6420        "selected 
+00022150: 6b65 7973 206d 7573 7420 6265 2061 206c  keys must be a l
+00022160: 6973 7420 6f72 2074 7570 6c65 206f 6620  ist or tuple of 
+00022170: 7374 7269 6e67 7320 6f72 2074 7570 6c65  strings or tuple
+00022180: 7320 6f66 2073 7472 696e 6773 2e22 0d0a  s of strings."..
+00022190: 2020 2020 2020 2020 2020 2020 290d 0a20              ).. 
+000221a0: 2020 2020 2020 2073 656c 662e 7365 6c65         self.sele
+000221b0: 6374 6564 5f6b 6579 7320 3d20 7365 6c65  cted_keys = sele
+000221c0: 6374 6564 5f6b 6579 730d 0a0d 0a20 2020  cted_keys....   
+000221d0: 2064 6566 205f 6361 6c6c 2873 656c 662c   def _call(self,
+000221e0: 2074 656e 736f 7264 6963 743a 2054 656e   tensordict: Ten
+000221f0: 736f 7244 6963 7442 6173 6529 202d 3e20  sorDictBase) -> 
+00022200: 5465 6e73 6f72 4469 6374 4261 7365 3a0d  TensorDictBase:.
+00022210: 0a20 2020 2020 2020 2069 6620 7365 6c66  .        if self
+00022220: 2e70 6172 656e 743a 0d0a 2020 2020 2020  .parent:..      
+00022230: 2020 2020 2020 696e 7075 745f 6b65 7973        input_keys
+00022240: 203d 2073 656c 662e 7061 7265 6e74 2e69   = self.parent.i
+00022250: 6e70 7574 5f73 7065 632e 6b65 7973 2854  nput_spec.keys(T
+00022260: 7275 652c 2054 7275 6529 0d0a 2020 2020  rue, True)..    
+00022270: 2020 2020 656c 7365 3a0d 0a20 2020 2020      else:..     
+00022280: 2020 2020 2020 2069 6e70 7574 5f6b 6579         input_key
+00022290: 7320 3d20 5b5d 0d0a 2020 2020 2020 2020  s = []..        
+000222a0: 7265 7475 726e 2074 656e 736f 7264 6963  return tensordic
+000222b0: 742e 7365 6c65 6374 280d 0a20 2020 2020  t.select(..     
+000222c0: 2020 2020 2020 202a 7365 6c66 2e73 656c         *self.sel
+000222d0: 6563 7465 645f 6b65 7973 2c20 2272 6577  ected_keys, "rew
+000222e0: 6172 6422 2c20 2264 6f6e 6522 2c20 2a69  ard", "done", *i
+000222f0: 6e70 7574 5f6b 6579 732c 2073 7472 6963  nput_keys, stric
+00022300: 743d 4661 6c73 650d 0a20 2020 2020 2020  t=False..       
+00022310: 2029 0d0a 0d0a 2020 2020 666f 7277 6172   )....    forwar
+00022320: 6420 3d20 5f63 616c 6c0d 0a0d 0a20 2020  d = _call....   
+00022330: 2064 6566 2072 6573 6574 2873 656c 662c   def reset(self,
+00022340: 2074 656e 736f 7264 6963 743a 2054 656e   tensordict: Ten
+00022350: 736f 7244 6963 7442 6173 6529 202d 3e20  sorDictBase) -> 
+00022360: 5465 6e73 6f72 4469 6374 4261 7365 3a0d  TensorDictBase:.
+00022370: 0a20 2020 2020 2020 2069 6620 7365 6c66  .        if self
+00022380: 2e70 6172 656e 743a 0d0a 2020 2020 2020  .parent:..      
+00022390: 2020 2020 2020 696e 7075 745f 6b65 7973        input_keys
+000223a0: 203d 2073 656c 662e 7061 7265 6e74 2e69   = self.parent.i
+000223b0: 6e70 7574 5f73 7065 632e 6b65 7973 2854  nput_spec.keys(T
+000223c0: 7275 652c 2054 7275 6529 0d0a 2020 2020  rue, True)..    
+000223d0: 2020 2020 656c 7365 3a0d 0a20 2020 2020      else:..     
+000223e0: 2020 2020 2020 2069 6e70 7574 5f6b 6579         input_key
+000223f0: 7320 3d20 5b5d 0d0a 2020 2020 2020 2020  s = []..        
+00022400: 7265 7475 726e 2074 656e 736f 7264 6963  return tensordic
+00022410: 742e 7365 6c65 6374 280d 0a20 2020 2020  t.select(..     
+00022420: 2020 2020 2020 202a 7365 6c66 2e73 656c         *self.sel
+00022430: 6563 7465 645f 6b65 7973 2c20 2272 6577  ected_keys, "rew
+00022440: 6172 6422 2c20 2264 6f6e 6522 2c20 2a69  ard", "done", *i
+00022450: 6e70 7574 5f6b 6579 732c 2073 7472 6963  nput_keys, stric
+00022460: 743d 4661 6c73 650d 0a20 2020 2020 2020  t=False..       
+00022470: 2029 0d0a 0d0a 2020 2020 6465 6620 7472   )....    def tr
+00022480: 616e 7366 6f72 6d5f 6f62 7365 7276 6174  ansform_observat
+00022490: 696f 6e5f 7370 6563 2873 656c 662c 206f  ion_spec(self, o
+000224a0: 6273 6572 7661 7469 6f6e 5f73 7065 633a  bservation_spec:
+000224b0: 2054 656e 736f 7253 7065 6329 202d 3e20   TensorSpec) -> 
+000224c0: 5465 6e73 6f72 5370 6563 3a0d 0a20 2020  TensorSpec:..   
+000224d0: 2020 2020 2072 6574 7572 6e20 436f 6d70       return Comp
+000224e0: 6f73 6974 6553 7065 6328 0d0a 2020 2020  ositeSpec(..    
+000224f0: 2020 2020 2020 2020 2a2a 7b0d 0a20 2020          **{..   
+00022500: 2020 2020 2020 2020 2020 2020 206b 6579               key
+00022510: 3a20 7661 6c75 650d 0a20 2020 2020 2020  : value..       
+00022520: 2020 2020 2020 2020 2066 6f72 206b 6579           for key
+00022530: 2c20 7661 6c75 6520 696e 206f 6273 6572  , value in obser
+00022540: 7661 7469 6f6e 5f73 7065 632e 6974 656d  vation_spec.item
+00022550: 7328 290d 0a20 2020 2020 2020 2020 2020  s()..           
+00022560: 2020 2020 2069 6620 6b65 7920 696e 2073       if key in s
+00022570: 656c 662e 7365 6c65 6374 6564 5f6b 6579  elf.selected_key
+00022580: 730d 0a20 2020 2020 2020 2020 2020 207d  s..            }
+00022590: 2c0d 0a20 2020 2020 2020 2020 2020 2073  ,..            s
+000225a0: 6861 7065 3d6f 6273 6572 7661 7469 6f6e  hape=observation
+000225b0: 5f73 7065 632e 7368 6170 652c 0d0a 2020  _spec.shape,..  
+000225c0: 2020 2020 2020 290d 0a0d 0a0d 0a63 6c61        )......cla
+000225d0: 7373 2054 696d 654d 6178 506f 6f6c 2854  ss TimeMaxPool(T
+000225e0: 7261 6e73 666f 726d 293a 0d0a 2020 2020  ransform):..    
+000225f0: 2222 2254 616b 6520 7468 6520 6d61 7869  """Take the maxi
+00022600: 6d75 6d20 7661 6c75 6520 696e 2065 6163  mum value in eac
+00022610: 6820 706f 7369 7469 6f6e 206f 7665 7220  h position over 
+00022620: 7468 6520 6c61 7374 2054 206f 6273 6572  the last T obser
+00022630: 7661 7469 6f6e 732e 0d0a 0d0a 2020 2020  vations.....    
+00022640: 5468 6973 2074 7261 6e73 666f 726d 2074  This transform t
+00022650: 616b 6520 7468 6520 6d61 7869 6d75 6d20  ake the maximum 
+00022660: 7661 6c75 6520 696e 2065 6163 6820 706f  value in each po
+00022670: 7369 7469 6f6e 2066 6f72 2061 6c6c 2069  sition for all i
+00022680: 6e5f 6b65 7973 2074 656e 736f 7273 206f  n_keys tensors o
+00022690: 7665 7220 7468 6520 6c61 7374 2054 2074  ver the last T t
+000226a0: 696d 6520 7374 6570 732e 0d0a 0d0a 2020  ime steps.....  
+000226b0: 2020 4172 6773 3a0d 0a20 2020 2020 2020    Args:..       
+000226c0: 2069 6e5f 6b65 7973 2028 7365 7175 656e   in_keys (sequen
+000226d0: 6365 206f 6620 7374 722c 206f 7074 696f  ce of str, optio
+000226e0: 6e61 6c29 3a20 696e 7075 7420 6b65 7973  nal): input keys
+000226f0: 206f 6e20 7768 6963 6820 7468 6520 6d61   on which the ma
+00022700: 7820 706f 6f6c 2077 696c 6c20 6265 2061  x pool will be a
+00022710: 7070 6c69 6564 2e20 4465 6661 756c 7473  pplied. Defaults
+00022720: 2074 6f20 226f 6273 6572 7661 7469 6f6e   to "observation
+00022730: 2220 6966 206c 6566 7420 656d 7074 792e  " if left empty.
+00022740: 0d0a 2020 2020 2020 2020 6f75 745f 6b65  ..        out_ke
+00022750: 7973 2028 7365 7175 656e 6365 206f 6620  ys (sequence of 
+00022760: 7374 722c 206f 7074 696f 6e61 6c29 3a20  str, optional): 
+00022770: 6f75 7470 7574 206b 6579 7320 7768 6572  output keys wher
+00022780: 6520 7468 6520 6f75 7470 7574 2077 696c  e the output wil
+00022790: 6c20 6265 2077 7269 7474 656e 2e20 4465  l be written. De
+000227a0: 6661 756c 7473 2074 6f20 6069 6e5f 6b65  faults to `in_ke
+000227b0: 7973 6020 6966 206c 6566 7420 656d 7074  ys` if left empt
+000227c0: 792e 0d0a 2020 2020 2020 2020 5420 2869  y...        T (i
+000227d0: 6e74 2c20 6f70 7469 6f6e 616c 293a 204e  nt, optional): N
+000227e0: 756d 6265 7220 6f66 2074 696d 6520 7374  umber of time st
+000227f0: 6570 7320 6f76 6572 2077 6869 6368 2074  eps over which t
+00022800: 6f20 6170 706c 7920 6d61 7820 706f 6f6c  o apply max pool
+00022810: 696e 672e 0d0a 2020 2020 2222 220d 0a0d  ing...    """...
+00022820: 0a20 2020 2069 6e76 6572 7469 626c 6520  .    invertible 
+00022830: 3d20 4661 6c73 650d 0a0d 0a20 2020 2064  = False....    d
+00022840: 6566 205f 5f69 6e69 745f 5f28 0d0a 2020  ef __init__(..  
+00022850: 2020 2020 2020 7365 6c66 2c0d 0a20 2020        self,..   
+00022860: 2020 2020 2069 6e5f 6b65 7973 3a20 4f70       in_keys: Op
+00022870: 7469 6f6e 616c 5b53 6571 7565 6e63 655b  tional[Sequence[
+00022880: 7374 725d 5d20 3d20 4e6f 6e65 2c0d 0a20  str]] = None,.. 
+00022890: 2020 2020 2020 206f 7574 5f6b 6579 733a         out_keys:
+000228a0: 204f 7074 696f 6e61 6c5b 5365 7175 656e   Optional[Sequen
+000228b0: 6365 5b73 7472 5d5d 203d 204e 6f6e 652c  ce[str]] = None,
+000228c0: 0d0a 2020 2020 2020 2020 543a 2069 6e74  ..        T: int
+000228d0: 203d 2031 2c0d 0a20 2020 2029 3a0d 0a20   = 1,..    ):.. 
+000228e0: 2020 2020 2020 2069 6620 696e 5f6b 6579         if in_key
+000228f0: 7320 6973 204e 6f6e 653a 0d0a 2020 2020  s is None:..    
+00022900: 2020 2020 2020 2020 696e 5f6b 6579 7320          in_keys 
+00022910: 3d20 5b22 6f62 7365 7276 6174 696f 6e22  = ["observation"
+00022920: 5d0d 0a20 2020 2020 2020 2073 7570 6572  ]..        super
+00022930: 2829 2e5f 5f69 6e69 745f 5f28 696e 5f6b  ().__init__(in_k
+00022940: 6579 733d 696e 5f6b 6579 732c 206f 7574  eys=in_keys, out
+00022950: 5f6b 6579 733d 6f75 745f 6b65 7973 290d  _keys=out_keys).
+00022960: 0a20 2020 2020 2020 2069 6620 5420 3c20  .        if T < 
+00022970: 313a 0d0a 2020 2020 2020 2020 2020 2020  1:..            
+00022980: 7261 6973 6520 5661 6c75 6545 7272 6f72  raise ValueError
+00022990: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
+000229a0: 2020 2022 5469 6d65 4d61 7850 6f6f 6c54     "TimeMaxPoolT
+000229b0: 7261 6e66 6f72 6d20 5420 7061 7261 6d65  ranform T parame
+000229c0: 7465 7220 7368 6f75 6c64 2068 6176 6520  ter should have 
+000229d0: 6120 7661 6c75 6520 6772 6561 7465 7220  a value greater 
+000229e0: 6f72 2065 7175 616c 2074 6f20 6f6e 652e  or equal to one.
+000229f0: 220d 0a20 2020 2020 2020 2020 2020 2029  "..            )
+00022a00: 0d0a 2020 2020 2020 2020 6966 206c 656e  ..        if len
+00022a10: 2873 656c 662e 696e 5f6b 6579 7329 2021  (self.in_keys) !
+00022a20: 3d20 6c65 6e28 7365 6c66 2e6f 7574 5f6b  = len(self.out_k
+00022a30: 6579 7329 3a0d 0a20 2020 2020 2020 2020  eys):..         
+00022a40: 2020 2072 6169 7365 2056 616c 7565 4572     raise ValueEr
+00022a50: 726f 7228 0d0a 2020 2020 2020 2020 2020  ror(..          
+00022a60: 2020 2020 2020 2254 696d 654d 6178 506f        "TimeMaxPo
+00022a70: 6f6c 5472 616e 666f 726d 2069 6e5f 6b65  olTranform in_ke
+00022a80: 7973 2061 6e64 206f 7574 5f6b 6579 7320  ys and out_keys 
+00022a90: 646f 6e27 7420 6861 7665 2074 6865 2073  don't have the s
+00022aa0: 616d 6520 6e75 6d62 6572 206f 6620 656c  ame number of el
+00022ab0: 656d 656e 7473 220d 0a20 2020 2020 2020  ements"..       
+00022ac0: 2020 2020 2029 0d0a 2020 2020 2020 2020       )..        
+00022ad0: 7365 6c66 2e62 7566 6665 725f 7369 7a65  self.buffer_size
+00022ae0: 203d 2054 0d0a 2020 2020 2020 2020 666f   = T..        fo
+00022af0: 7220 696e 5f6b 6579 2069 6e20 7365 6c66  r in_key in self
+00022b00: 2e69 6e5f 6b65 7973 3a0d 0a20 2020 2020  .in_keys:..     
+00022b10: 2020 2020 2020 2062 7566 6665 725f 6e61         buffer_na
+00022b20: 6d65 203d 2066 225f 6d61 7870 6f6f 6c5f  me = f"_maxpool_
+00022b30: 6275 6666 6572 5f7b 696e 5f6b 6579 7d22  buffer_{in_key}"
+00022b40: 0d0a 2020 2020 2020 2020 2020 2020 7365  ..            se
+00022b50: 7461 7474 7228 0d0a 2020 2020 2020 2020  tattr(..        
+00022b60: 2020 2020 2020 2020 7365 6c66 2c0d 0a20          self,.. 
+00022b70: 2020 2020 2020 2020 2020 2020 2020 2062                 b
+00022b80: 7566 6665 725f 6e61 6d65 2c0d 0a20 2020  uffer_name,..   
+00022b90: 2020 2020 2020 2020 2020 2020 2074 6f72               tor
+00022ba0: 6368 2e6e 6e2e 7061 7261 6d65 7465 722e  ch.nn.parameter.
+00022bb0: 556e 696e 6974 6961 6c69 7a65 6442 7566  UninitializedBuf
+00022bc0: 6665 7228 0d0a 2020 2020 2020 2020 2020  fer(..          
+00022bd0: 2020 2020 2020 2020 2020 6465 7669 6365            device
+00022be0: 3d74 6f72 6368 2e64 6576 6963 6528 2263  =torch.device("c
+00022bf0: 7075 2229 2c20 6474 7970 653d 746f 7263  pu"), dtype=torc
+00022c00: 682e 6765 745f 6465 6661 756c 745f 6474  h.get_default_dt
+00022c10: 7970 6528 290d 0a20 2020 2020 2020 2020  ype()..         
+00022c20: 2020 2020 2020 2029 2c0d 0a20 2020 2020         ),..     
+00022c30: 2020 2020 2020 2029 0d0a 0d0a 2020 2020         )....    
+00022c40: 6465 6620 7265 7365 7428 7365 6c66 2c20  def reset(self, 
+00022c50: 7465 6e73 6f72 6469 6374 3a20 5465 6e73  tensordict: Tens
+00022c60: 6f72 4469 6374 4261 7365 2920 2d3e 2054  orDictBase) -> T
+00022c70: 656e 736f 7244 6963 7442 6173 653a 0d0a  ensorDictBase:..
+00022c80: 2020 2020 2020 2020 2222 2252 6573 6574          """Reset
+00022c90: 7320 5f62 7566 6665 7273 2e22 2222 0d0a  s _buffers."""..
+00022ca0: 2020 2020 2020 2020 2320 4e6f 6e2d 6261          # Non-ba
+00022cb0: 7463 6865 6420 656e 7669 726f 6e6d 656e  tched environmen
+00022cc0: 7473 0d0a 2020 2020 2020 2020 6966 206c  ts..        if l
+00022cd0: 656e 2874 656e 736f 7264 6963 742e 6261  en(tensordict.ba
+00022ce0: 7463 685f 7369 7a65 2920 3c20 3120 6f72  tch_size) < 1 or
+00022cf0: 2074 656e 736f 7264 6963 742e 6261 7463   tensordict.batc
+00022d00: 685f 7369 7a65 5b30 5d20 3d3d 2031 3a0d  h_size[0] == 1:.
+00022d10: 0a20 2020 2020 2020 2020 2020 2066 6f72  .            for
+00022d20: 2069 6e5f 6b65 7920 696e 2073 656c 662e   in_key in self.
+00022d30: 696e 5f6b 6579 733a 0d0a 2020 2020 2020  in_keys:..      
+00022d40: 2020 2020 2020 2020 2020 6275 6666 6572            buffer
+00022d50: 5f6e 616d 6520 3d20 6622 5f6d 6178 706f  _name = f"_maxpo
+00022d60: 6f6c 5f62 7566 6665 725f 7b69 6e5f 6b65  ol_buffer_{in_ke
+00022d70: 797d 220d 0a20 2020 2020 2020 2020 2020  y}"..           
+00022d80: 2020 2020 2062 7566 6665 7220 3d20 6765       buffer = ge
+00022d90: 7461 7474 7228 7365 6c66 2c20 6275 6666  tattr(self, buff
+00022da0: 6572 5f6e 616d 6529 0d0a 2020 2020 2020  er_name)..      
+00022db0: 2020 2020 2020 2020 2020 6966 2069 7369            if isi
+00022dc0: 6e73 7461 6e63 6528 6275 6666 6572 2c20  nstance(buffer, 
+00022dd0: 746f 7263 682e 6e6e 2e70 6172 616d 6574  torch.nn.paramet
+00022de0: 6572 2e55 6e69 6e69 7469 616c 697a 6564  er.Uninitialized
+00022df0: 4275 6666 6572 293a 0d0a 2020 2020 2020  Buffer):..      
+00022e00: 2020 2020 2020 2020 2020 2020 2020 636f                co
+00022e10: 6e74 696e 7565 0d0a 2020 2020 2020 2020  ntinue..        
+00022e20: 2020 2020 2020 2020 6275 6666 6572 2e66          buffer.f
+00022e30: 696c 6c5f 2830 2e30 290d 0a0d 0a20 2020  ill_(0.0)....   
+00022e40: 2020 2020 2023 2042 6174 6368 6564 2065       # Batched e
+00022e50: 6e76 6972 6f6e 6d65 6e74 730d 0a20 2020  nvironments..   
+00022e60: 2020 2020 2065 6c73 653a 0d0a 2020 2020       else:..    
+00022e70: 2020 2020 2020 2020 5f72 6573 6574 203d          _reset =
+00022e80: 2074 656e 736f 7264 6963 742e 6765 7428   tensordict.get(
+00022e90: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00022ea0: 2020 225f 7265 7365 7422 2c0d 0a20 2020    "_reset",..   
+00022eb0: 2020 2020 2020 2020 2020 2020 2074 6f72               tor
+00022ec0: 6368 2e6f 6e65 7328 0d0a 2020 2020 2020  ch.ones(..      
+00022ed0: 2020 2020 2020 2020 2020 2020 2020 7365                se
+00022ee0: 6c66 2e70 6172 656e 742e 646f 6e65 5f73  lf.parent.done_s
+00022ef0: 7065 632e 7368 6170 650d 0a20 2020 2020  pec.shape..     
+00022f00: 2020 2020 2020 2020 2020 2020 2020 2069                 i
+00022f10: 6620 7365 6c66 2e70 6172 656e 740d 0a20  f self.parent.. 
+00022f20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00022f30: 2020 2065 6c73 6520 7465 6e73 6f72 6469     else tensordi
+00022f40: 6374 2e62 6174 6368 5f73 697a 652c 0d0a  ct.batch_size,..
+00022f50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00022f60: 2020 2020 6474 7970 653d 746f 7263 682e      dtype=torch.
+00022f70: 626f 6f6c 2c0d 0a20 2020 2020 2020 2020  bool,..         
+00022f80: 2020 2020 2020 2020 2020 2064 6576 6963             devic
+00022f90: 653d 7465 6e73 6f72 6469 6374 2e64 6576  e=tensordict.dev
+00022fa0: 6963 652c 0d0a 2020 2020 2020 2020 2020  ice,..          
+00022fb0: 2020 2020 2020 292c 0d0a 2020 2020 2020        ),..      
+00022fc0: 2020 2020 2020 290d 0a20 2020 2020 2020        )..       
+00022fd0: 2020 2020 2066 6f72 2069 6e5f 6b65 7920       for in_key 
+00022fe0: 696e 2073 656c 662e 696e 5f6b 6579 733a  in self.in_keys:
+00022ff0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00023000: 2020 6275 6666 6572 5f6e 616d 6520 3d20    buffer_name = 
+00023010: 6622 5f6d 6178 706f 6f6c 5f62 7566 6665  f"_maxpool_buffe
+00023020: 725f 7b69 6e5f 6b65 797d 220d 0a20 2020  r_{in_key}"..   
+00023030: 2020 2020 2020 2020 2020 2020 2062 7566               buf
+00023040: 6665 7220 3d20 6765 7461 7474 7228 7365  fer = getattr(se
+00023050: 6c66 2c20 6275 6666 6572 5f6e 616d 6529  lf, buffer_name)
+00023060: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00023070: 2020 6966 2069 7369 6e73 7461 6e63 6528    if isinstance(
+00023080: 6275 6666 6572 2c20 746f 7263 682e 6e6e  buffer, torch.nn
+00023090: 2e70 6172 616d 6574 6572 2e55 6e69 6e69  .parameter.Unini
+000230a0: 7469 616c 697a 6564 4275 6666 6572 293a  tializedBuffer):
+000230b0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+000230c0: 2020 2020 2020 636f 6e74 696e 7565 0d0a        continue..
+000230d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000230e0: 5f72 6573 6574 203d 205f 7265 7365 742e  _reset = _reset.
+000230f0: 7375 6d28 0d0a 2020 2020 2020 2020 2020  sum(..          
+00023100: 2020 2020 2020 2020 2020 7475 706c 6528            tuple(
+00023110: 7261 6e67 6528 7465 6e73 6f72 6469 6374  range(tensordict
+00023120: 2e62 6174 6368 5f64 696d 732c 205f 7265  .batch_dims, _re
+00023130: 7365 742e 6e64 696d 2929 2c20 6474 7970  set.ndim)), dtyp
+00023140: 653d 746f 7263 682e 626f 6f6c 0d0a 2020  e=torch.bool..  
+00023150: 2020 2020 2020 2020 2020 2020 2020 290d                ).
+00023160: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00023170: 2062 7566 6665 725b 3a2c 205f 7265 7365   buffer[:, _rese
+00023180: 745d 203d 2030 2e30 0d0a 0d0a 2020 2020  t] = 0.0....    
+00023190: 2020 2020 7265 7475 726e 2074 656e 736f      return tenso
+000231a0: 7264 6963 740d 0a0d 0a20 2020 2064 6566  rdict....    def
+000231b0: 205f 6d61 6b65 5f6d 6973 7369 6e67 5f62   _make_missing_b
+000231c0: 7566 6665 7228 7365 6c66 2c20 6461 7461  uffer(self, data
+000231d0: 2c20 6275 6666 6572 5f6e 616d 6529 3a0d  , buffer_name):.
+000231e0: 0a20 2020 2020 2020 2062 7566 6665 7220  .        buffer 
+000231f0: 3d20 6765 7461 7474 7228 7365 6c66 2c20  = getattr(self, 
+00023200: 6275 6666 6572 5f6e 616d 6529 0d0a 2020  buffer_name)..  
+00023210: 2020 2020 2020 6275 6666 6572 2e6d 6174        buffer.mat
+00023220: 6572 6961 6c69 7a65 2828 7365 6c66 2e62  erialize((self.b
+00023230: 7566 6665 725f 7369 7a65 2c29 202b 2064  uffer_size,) + d
+00023240: 6174 612e 7368 6170 6529 0d0a 2020 2020  ata.shape)..    
+00023250: 2020 2020 6275 6666 6572 203d 2062 7566      buffer = buf
+00023260: 6665 722e 746f 2864 6174 612e 6474 7970  fer.to(data.dtyp
+00023270: 6529 2e74 6f28 6461 7461 2e64 6576 6963  e).to(data.devic
+00023280: 6529 2e7a 6572 6f5f 2829 0d0a 2020 2020  e).zero_()..    
+00023290: 2020 2020 7365 7461 7474 7228 7365 6c66      setattr(self
+000232a0: 2c20 6275 6666 6572 5f6e 616d 652c 2062  , buffer_name, b
+000232b0: 7566 6665 7229 0d0a 0d0a 2020 2020 6465  uffer)....    de
+000232c0: 6620 5f63 616c 6c28 7365 6c66 2c20 7465  f _call(self, te
+000232d0: 6e73 6f72 6469 6374 3a20 5465 6e73 6f72  nsordict: Tensor
+000232e0: 4469 6374 4261 7365 2920 2d3e 2054 656e  DictBase) -> Ten
+000232f0: 736f 7244 6963 7442 6173 653a 0d0a 2020  sorDictBase:..  
+00023300: 2020 2020 2020 2222 2255 7064 6174 6520        """Update 
+00023310: 7468 6520 6570 6973 6f64 6520 7465 6e73  the episode tens
+00023320: 6f72 6469 6374 2077 6974 6820 6d61 7820  ordict with max 
+00023330: 706f 6f6c 6564 206b 6579 732e 2222 220d  pooled keys.""".
+00023340: 0a20 2020 2020 2020 2066 6f72 2069 6e5f  .        for in_
+00023350: 6b65 792c 206f 7574 5f6b 6579 2069 6e20  key, out_key in 
+00023360: 7a69 7028 7365 6c66 2e69 6e5f 6b65 7973  zip(self.in_keys
+00023370: 2c20 7365 6c66 2e6f 7574 5f6b 6579 7329  , self.out_keys)
+00023380: 3a0d 0a20 2020 2020 2020 2020 2020 2023  :..            #
+00023390: 204c 617a 7920 696e 6974 206f 6620 6275   Lazy init of bu
+000233a0: 6666 6572 730d 0a20 2020 2020 2020 2020  ffers..         
+000233b0: 2020 2062 7566 6665 725f 6e61 6d65 203d     buffer_name =
+000233c0: 2066 225f 6d61 7870 6f6f 6c5f 6275 6666   f"_maxpool_buff
+000233d0: 6572 5f7b 696e 5f6b 6579 7d22 0d0a 2020  er_{in_key}"..  
+000233e0: 2020 2020 2020 2020 2020 6275 6666 6572            buffer
+000233f0: 203d 2067 6574 6174 7472 2873 656c 662c   = getattr(self,
+00023400: 2062 7566 6665 725f 6e61 6d65 290d 0a20   buffer_name).. 
+00023410: 2020 2020 2020 2020 2020 2069 6620 6973             if is
+00023420: 696e 7374 616e 6365 2862 7566 6665 722c  instance(buffer,
+00023430: 2074 6f72 6368 2e6e 6e2e 7061 7261 6d65   torch.nn.parame
+00023440: 7465 722e 556e 696e 6974 6961 6c69 7a65  ter.Uninitialize
+00023450: 6442 7566 6665 7229 3a0d 0a20 2020 2020  dBuffer):..     
+00023460: 2020 2020 2020 2020 2020 2064 6174 6120             data 
+00023470: 3d20 7465 6e73 6f72 6469 6374 5b69 6e5f  = tensordict[in_
+00023480: 6b65 795d 0d0a 2020 2020 2020 2020 2020  key]..          
+00023490: 2020 2020 2020 7365 6c66 2e5f 6d61 6b65        self._make
+000234a0: 5f6d 6973 7369 6e67 5f62 7566 6665 7228  _missing_buffer(
+000234b0: 6461 7461 2c20 6275 6666 6572 5f6e 616d  data, buffer_nam
+000234c0: 6529 0d0a 2020 2020 2020 2020 2020 2020  e)..            
+000234d0: 2320 7368 6966 7420 6f62 7320 3120 706f  # shift obs 1 po
+000234e0: 7369 7469 6f6e 2074 6f20 7468 6520 7269  sition to the ri
+000234f0: 6768 740d 0a20 2020 2020 2020 2020 2020  ght..           
+00023500: 2062 7566 6665 722e 636f 7079 5f28 746f   buffer.copy_(to
+00023510: 7263 682e 726f 6c6c 2862 7566 6665 722c  rch.roll(buffer,
+00023520: 2073 6869 6674 733d 312c 2064 696d 733d   shifts=1, dims=
+00023530: 3029 290d 0a20 2020 2020 2020 2020 2020  0))..           
+00023540: 2023 2061 6464 206e 6577 206f 6273 0d0a   # add new obs..
+00023550: 2020 2020 2020 2020 2020 2020 6275 6666              buff
+00023560: 6572 5b30 5d2e 636f 7079 5f28 7465 6e73  er[0].copy_(tens
+00023570: 6f72 6469 6374 5b69 6e5f 6b65 795d 290d  ordict[in_key]).
+00023580: 0a20 2020 2020 2020 2020 2020 2023 2061  .            # a
+00023590: 7070 6c79 206d 6178 2070 6f6f 6c69 6e67  pply max pooling
+000235a0: 0d0a 2020 2020 2020 2020 2020 2020 706f  ..            po
+000235b0: 6f6c 6564 5f74 656e 736f 722c 205f 203d  oled_tensor, _ =
+000235c0: 2062 7566 6665 722e 6d61 7828 6469 6d3d   buffer.max(dim=
+000235d0: 3029 0d0a 2020 2020 2020 2020 2020 2020  0)..            
+000235e0: 2320 6164 6420 746f 2074 656e 736f 7264  # add to tensord
+000235f0: 6963 740d 0a20 2020 2020 2020 2020 2020  ict..           
+00023600: 2074 656e 736f 7264 6963 742e 7365 7428   tensordict.set(
+00023610: 6f75 745f 6b65 792c 2070 6f6f 6c65 645f  out_key, pooled_
+00023620: 7465 6e73 6f72 290d 0a0d 0a20 2020 2020  tensor)....     
+00023630: 2020 2072 6574 7572 6e20 7465 6e73 6f72     return tensor
+00023640: 6469 6374 0d0a 0d0a 2020 2020 405f 6170  dict....    @_ap
+00023650: 706c 795f 746f 5f63 6f6d 706f 7369 7465  ply_to_composite
+00023660: 0d0a 2020 2020 6465 6620 7472 616e 7366  ..    def transf
+00023670: 6f72 6d5f 6f62 7365 7276 6174 696f 6e5f  orm_observation_
+00023680: 7370 6563 2873 656c 662c 206f 6273 6572  spec(self, obser
+00023690: 7661 7469 6f6e 5f73 7065 633a 2054 656e  vation_spec: Ten
+000236a0: 736f 7253 7065 6329 202d 3e20 5465 6e73  sorSpec) -> Tens
+000236b0: 6f72 5370 6563 3a0d 0a20 2020 2020 2020  orSpec:..       
+000236c0: 2072 6574 7572 6e20 6f62 7365 7276 6174   return observat
+000236d0: 696f 6e5f 7370 6563 0d0a 0d0a 2020 2020  ion_spec....    
+000236e0: 6465 6620 666f 7277 6172 6428 7365 6c66  def forward(self
+000236f0: 2c20 7465 6e73 6f72 6469 6374 3a20 5465  , tensordict: Te
+00023700: 6e73 6f72 4469 6374 4261 7365 2920 2d3e  nsorDictBase) ->
+00023710: 2054 656e 736f 7244 6963 7442 6173 653a   TensorDictBase:
+00023720: 0d0a 2020 2020 2020 2020 7261 6973 6520  ..        raise 
+00023730: 4e6f 7449 6d70 6c65 6d65 6e74 6564 4572  NotImplementedEr
+00023740: 726f 7228 0d0a 2020 2020 2020 2020 2020  ror(..          
+00023750: 2020 2254 696d 654d 6178 506f 6f6c 2063    "TimeMaxPool c
+00023760: 616e 6e6f 7420 6265 2063 616c 6c65 6420  annot be called 
+00023770: 696e 6465 7065 6e64 656e 746c 792c 206f  independently, o
+00023780: 6e6c 7920 6974 7320 7374 6570 2061 6e64  nly its step and
+00023790: 2072 6573 6574 206d 6574 686f 6473 2022   reset methods "
+000237a0: 0d0a 2020 2020 2020 2020 2020 2020 2261  ..            "a
+000237b0: 7265 2066 756e 6374 696f 6e61 6c2e 2054  re functional. T
+000237c0: 6865 2072 6561 736f 6e20 666f 7220 7468  he reason for th
+000237d0: 6973 2069 7320 7468 6174 2069 7420 6973  is is that it is
+000237e0: 2068 6172 6420 746f 2063 6f6e 7369 6465   hard to conside
+000237f0: 7220 7573 696e 6720 220d 0a20 2020 2020  r using "..     
+00023800: 2020 2020 2020 2022 5469 6d65 4d61 7850         "TimeMaxP
+00023810: 6f6f 6c20 7769 7468 206e 6f6e 2d73 6571  ool with non-seq
+00023820: 7565 6e74 6961 6c20 6461 7461 2c20 7375  uential data, su
+00023830: 6368 2061 7320 7468 6f73 6520 636f 6c6c  ch as those coll
+00023840: 6563 7465 6420 6279 2061 2072 6570 6c61  ected by a repla
+00023850: 7920 6275 6666 6572 2022 0d0a 2020 2020  y buffer "..    
+00023860: 2020 2020 2020 2020 226f 7220 6120 6461          "or a da
+00023870: 7461 7365 742e 2049 6620 796f 7520 6e65  taset. If you ne
+00023880: 6564 2054 696d 654d 6178 506f 6f6c 2074  ed TimeMaxPool t
+00023890: 6f20 776f 726b 206f 6e20 6120 6261 7463  o work on a batc
+000238a0: 6820 6f66 2073 6571 7565 6e74 6961 6c20  h of sequential 
+000238b0: 6461 7461 2022 0d0a 2020 2020 2020 2020  data "..        
+000238c0: 2020 2020 2228 6965 2061 7320 4c53 544d      "(ie as LSTM
+000238d0: 2077 6f75 6c64 2077 6f72 6b20 6f76 6572   would work over
+000238e0: 2061 2077 686f 6c65 2073 6571 7565 6e63   a whole sequenc
+000238f0: 6520 6f66 2064 6174 6129 2c20 6669 6c65  e of data), file
+00023900: 2061 6e20 6973 7375 6520 6f6e 2022 0d0a   an issue on "..
+00023910: 2020 2020 2020 2020 2020 2020 2254 6f72              "Tor
+00023920: 6368 524c 2072 6571 7565 7374 696e 6720  chRL requesting 
+00023930: 7468 6174 2066 6561 7475 7265 2e22 0d0a  that feature."..
+00023940: 2020 2020 2020 2020 290d 0a0d 0a0d 0a63          )......c
+00023950: 6c61 7373 2052 616e 646f 6d43 726f 7054  lass RandomCropT
+00023960: 656e 736f 7244 6963 7428 5472 616e 7366  ensorDict(Transf
+00023970: 6f72 6d29 3a0d 0a20 2020 2022 2222 4120  orm):..    """A 
+00023980: 7472 616a 6563 746f 7279 2073 7562 2d73  trajectory sub-s
+00023990: 616d 706c 6572 2066 6f72 2052 6570 6c61  ampler for Repla
+000239a0: 7942 7566 6665 7220 616e 6420 6d6f 6475  yBuffer and modu
+000239b0: 6c65 732e 0d0a 0d0a 2020 2020 4761 7468  les.....    Gath
+000239c0: 6572 7320 6120 7375 622d 7365 7175 656e  ers a sub-sequen
+000239d0: 6365 206f 6620 6120 6465 6669 6e65 6420  ce of a defined 
+000239e0: 6c65 6e67 7468 2061 6c6f 6e67 2074 6865  length along the
+000239f0: 206c 6173 7420 6469 6d65 6e73 696f 6e20   last dimension 
+00023a00: 6f66 2074 6865 2069 6e70 7574 0d0a 2020  of the input..  
+00023a10: 2020 7465 6e73 6f72 6469 6374 2e0d 0a20    tensordict... 
+00023a20: 2020 2054 6869 7320 6361 6e20 6265 2075     This can be u
+00023a30: 7365 6420 746f 2067 6574 2063 726f 7070  sed to get cropp
+00023a40: 6564 2074 7261 6a65 6374 6f72 6965 7320  ed trajectories 
+00023a50: 6672 6f6d 2074 7261 6a65 6374 6f72 6965  from trajectorie
+00023a60: 7320 7361 6d70 6c65 640d 0a20 2020 2066  s sampled..    f
+00023a70: 726f 6d20 6120 5265 706c 6179 4275 6666  rom a ReplayBuff
+00023a80: 6572 2e0d 0a0d 0a20 2020 2054 6869 7320  er.....    This 
+00023a90: 7472 616e 7366 6f72 6d20 6973 2070 7269  transform is pri
+00023aa0: 6d61 7269 6c79 2064 6573 6967 6e65 6420  marily designed 
+00023ab0: 746f 2062 6520 7573 6564 2077 6974 6820  to be used with 
+00023ac0: 7265 706c 6179 2062 7566 6665 7273 2061  replay buffers a
+00023ad0: 6e64 206d 6f64 756c 6573 2e0d 0a20 2020  nd modules...   
+00023ae0: 2043 7572 7265 6e74 6c79 2c20 6974 2063   Currently, it c
+00023af0: 616e 6e6f 7420 6265 2075 7365 6420 6173  annot be used as
+00023b00: 2061 6e20 656e 7669 726f 6e6d 656e 7420   an environment 
+00023b10: 7472 616e 7366 6f72 6d2e 0d0a 2020 2020  transform...    
+00023b20: 446f 206e 6f74 2068 6573 6974 6174 6520  Do not hesitate 
+00023b30: 746f 2072 6571 7565 7374 2066 6f72 2074  to request for t
+00023b40: 6869 7320 6265 6861 7669 6f75 7220 7468  his behaviour th
+00023b50: 726f 7567 6820 616e 2069 7373 7565 2069  rough an issue i
+00023b60: 6620 7468 6973 2069 730d 0a20 2020 2064  f this is..    d
+00023b70: 6573 6972 6564 2e0d 0a0d 0a20 2020 2041  esired.....    A
+00023b80: 7267 733a 0d0a 2020 2020 2020 2020 7375  rgs:..        su
+00023b90: 625f 7365 715f 6c65 6e20 2869 6e74 293a  b_seq_len (int):
+00023ba0: 2074 6865 206c 656e 6774 6820 6f66 2074   the length of t
+00023bb0: 6865 2073 7562 2d74 7261 6a65 6374 6f72  he sub-trajector
+00023bc0: 7920 746f 2073 616d 706c 650d 0a20 2020  y to sample..   
+00023bd0: 2020 2020 2073 616d 706c 655f 6469 6d20       sample_dim 
+00023be0: 2869 6e74 2c20 6f70 7469 6f6e 616c 293a  (int, optional):
+00023bf0: 2074 6865 2064 696d 656e 7369 6f6e 2061   the dimension a
+00023c00: 6c6f 6e67 2077 6869 6368 2074 6865 2063  long which the c
+00023c10: 726f 7070 696e 670d 0a20 2020 2020 2020  ropping..       
+00023c20: 2020 2020 2073 686f 756c 6420 6f63 6375       should occu
+00023c30: 722e 204e 6567 6174 6976 6520 6469 6d65  r. Negative dime
+00023c40: 6e73 696f 6e73 2073 686f 756c 6420 6265  nsions should be
+00023c50: 2070 7265 6665 7272 6564 2074 6f20 6d61   preferred to ma
+00023c60: 6b65 0d0a 2020 2020 2020 2020 2020 2020  ke..            
+00023c70: 7468 6520 7472 616e 7366 6f72 6d20 726f  the transform ro
+00023c80: 6275 7374 2074 6f20 7465 6e73 6f72 6469  bust to tensordi
+00023c90: 6374 7320 6f66 2076 6172 7969 6e67 2062  cts of varying b
+00023ca0: 6174 6368 2064 696d 656e 7369 6f6e 732e  atch dimensions.
+00023cb0: 0d0a 2020 2020 2020 2020 2020 2020 4465  ..            De
+00023cc0: 6661 756c 7473 2074 6f20 2d31 2028 7468  faults to -1 (th
+00023cd0: 6520 6465 6661 756c 7420 7469 6d65 2064  e default time d
+00023ce0: 696d 656e 7369 6f6e 2069 6e20 546f 7263  imension in Torc
+00023cf0: 6852 4c29 2e0d 0a20 2020 2020 2020 206d  hRL)...        m
+00023d00: 6173 6b5f 6b65 7920 2873 7472 293a 2049  ask_key (str): I
+00023d10: 6620 7072 6f76 6964 6564 2c20 7468 6973  f provided, this
+00023d20: 2072 6570 7265 7365 6e74 7320 7468 6520   represents the 
+00023d30: 6d61 736b 206b 6579 2074 6f20 6265 206c  mask key to be l
+00023d40: 6f6f 6b65 640d 0a20 2020 2020 2020 2020  ooked..         
+00023d50: 2020 2066 6f72 2077 6865 6e20 646f 696e     for when doin
+00023d60: 6720 7468 6520 7361 6d70 6c69 6e67 2e20  g the sampling. 
+00023d70: 4966 2070 726f 7669 6465 642c 2069 7420  If provided, it 
+00023d80: 6f6e 6c79 2076 616c 6964 2065 6c65 6d65  only valid eleme
+00023d90: 6e74 7320 7769 6c6c 0d0a 2020 2020 2020  nts will..      
+00023da0: 2020 2020 2020 6265 2072 6574 7572 6e65        be returne
+00023db0: 642e 2049 7420 6973 2061 7373 756d 6564  d. It is assumed
+00023dc0: 2074 6861 7420 7468 6520 6d61 736b 2069   that the mask i
+00023dd0: 7320 6120 626f 6f6c 6561 6e20 7465 6e73  s a boolean tens
+00023de0: 6f72 2077 6974 680d 0a20 2020 2020 2020  or with..       
+00023df0: 2020 2020 2066 6972 7374 2054 7275 6520       first True 
+00023e00: 7661 6c75 6573 2061 6e64 2074 6865 6e20  values and then 
+00023e10: 4661 6c73 6520 7661 6c75 6573 2c20 6e6f  False values, no
+00023e20: 7420 6d69 7865 6420 746f 6765 7468 6572  t mixed together
+00023e30: 2e0d 0a20 2020 2020 2020 2020 2020 203a  ...            :
+00023e40: 636c 6173 733a 6052 616e 646f 6d43 726f  class:`RandomCro
+00023e50: 7054 656e 736f 7244 6963 7460 2077 696c  pTensorDict` wil
+00023e60: 6c20 4e4f 5420 6368 6563 6b20 7468 6174  l NOT check that
+00023e70: 2074 6869 7320 6973 2072 6573 7065 6374   this is respect
+00023e80: 6564 0d0a 2020 2020 2020 2020 2020 2020  ed..            
+00023e90: 6865 6e63 6520 616e 7920 6572 726f 7220  hence any error 
+00023ea0: 6361 7573 6564 2062 7920 616e 2069 6d70  caused by an imp
+00023eb0: 726f 7065 7220 6d61 736b 2072 6973 6b73  roper mask risks
+00023ec0: 2074 6f20 676f 2075 6e6e 6f74 6963 6564   to go unnoticed
+00023ed0: 2e0d 0a20 2020 2020 2020 2020 2020 2044  ...            D
+00023ee0: 6566 6175 6c74 733a 204e 6f6e 6520 286e  efaults: None (n
+00023ef0: 6f20 6d61 736b 206b 6579 292e 0d0a 2020  o mask key)...  
+00023f00: 2020 2222 220d 0a0d 0a20 2020 2064 6566    """....    def
+00023f10: 205f 5f69 6e69 745f 5f28 0d0a 2020 2020   __init__(..    
+00023f20: 2020 2020 7365 6c66 2c20 7375 625f 7365      self, sub_se
+00023f30: 715f 6c65 6e3a 2069 6e74 2c20 7361 6d70  q_len: int, samp
+00023f40: 6c65 5f64 696d 3a20 696e 7420 3d20 2d31  le_dim: int = -1
+00023f50: 2c20 6d61 736b 5f6b 6579 3a20 4f70 7469  , mask_key: Opti
+00023f60: 6f6e 616c 5b73 7472 5d20 3d20 4e6f 6e65  onal[str] = None
+00023f70: 0d0a 2020 2020 293a 0d0a 2020 2020 2020  ..    ):..      
+00023f80: 2020 7365 6c66 2e73 7562 5f73 6571 5f6c    self.sub_seq_l
+00023f90: 656e 203d 2073 7562 5f73 6571 5f6c 656e  en = sub_seq_len
+00023fa0: 0d0a 2020 2020 2020 2020 6966 2073 616d  ..        if sam
+00023fb0: 706c 655f 6469 6d20 3e20 303a 0d0a 2020  ple_dim > 0:..  
+00023fc0: 2020 2020 2020 2020 2020 7761 726e 696e            warnin
+00023fd0: 6773 2e77 6172 6e28 0d0a 2020 2020 2020  gs.warn(..      
+00023fe0: 2020 2020 2020 2020 2020 2241 2070 6f73            "A pos
+00023ff0: 6974 6976 6520 7368 6170 6520 6861 7320  itive shape has 
+00024000: 6265 656e 2070 6173 7365 6420 746f 2074  been passed to t
+00024010: 6865 2052 616e 646f 6d43 726f 7054 656e  he RandomCropTen
+00024020: 736f 7244 6963 7420 220d 0a20 2020 2020  sorDict "..     
+00024030: 2020 2020 2020 2020 2020 2022 636f 6e73             "cons
+00024040: 7472 7563 746f 722e 2054 6869 7320 6d61  tructor. This ma
+00024050: 7920 6861 7665 2075 6e65 7870 6563 7465  y have unexpecte
+00024060: 6420 6265 6861 7669 6f75 7273 2077 6865  d behaviours whe
+00024070: 6e20 7468 6520 220d 0a20 2020 2020 2020  n the "..       
+00024080: 2020 2020 2020 2020 2022 7061 7373 6564           "passed
+00024090: 2074 656e 736f 7264 6963 7473 2068 6176   tensordicts hav
+000240a0: 6520 696e 636f 6e73 6973 7465 6e74 2062  e inconsistent b
+000240b0: 6174 6368 2064 696d 656e 7369 6f6e 732e  atch dimensions.
+000240c0: 2022 0d0a 2020 2020 2020 2020 2020 2020   "..            
+000240d0: 2020 2020 2246 6f72 2063 6f6e 7465 7874      "For context
+000240e0: 2c20 6279 2063 6f6e 7665 6e74 696f 6e2c  , by convention,
+000240f0: 2054 6f72 6368 524c 2063 6f6e 6361 7465   TorchRL concate
+00024100: 6e61 7465 7320 7469 6d65 2073 7465 7073  nates time steps
+00024110: 2022 0d0a 2020 2020 2020 2020 2020 2020   "..            
+00024120: 2020 2020 2261 6c6f 6e67 2074 6865 206c      "along the l
+00024130: 6173 7420 6469 6d65 6e73 696f 6e20 6f66  ast dimension of
+00024140: 2074 6865 2074 656e 736f 7264 6963 742e   the tensordict.
+00024150: 220d 0a20 2020 2020 2020 2020 2020 2029  "..            )
+00024160: 0d0a 2020 2020 2020 2020 7365 6c66 2e73  ..        self.s
+00024170: 616d 706c 655f 6469 6d20 3d20 7361 6d70  ample_dim = samp
+00024180: 6c65 5f64 696d 0d0a 2020 2020 2020 2020  le_dim..        
+00024190: 7365 6c66 2e6d 6173 6b5f 6b65 7920 3d20  self.mask_key = 
+000241a0: 6d61 736b 5f6b 6579 0d0a 2020 2020 2020  mask_key..      
+000241b0: 2020 7375 7065 7228 292e 5f5f 696e 6974    super().__init
+000241c0: 5f5f 285b 5d29 0d0a 0d0a 2020 2020 6465  __([])....    de
+000241d0: 6620 666f 7277 6172 6428 7365 6c66 2c20  f forward(self, 
+000241e0: 7465 6e73 6f72 6469 6374 3a20 5465 6e73  tensordict: Tens
+000241f0: 6f72 4469 6374 4261 7365 2920 2d3e 2054  orDictBase) -> T
+00024200: 656e 736f 7244 6963 7442 6173 653a 0d0a  ensorDictBase:..
+00024210: 2020 2020 2020 2020 7368 6170 6520 3d20          shape = 
+00024220: 7465 6e73 6f72 6469 6374 2e73 6861 7065  tensordict.shape
+00024230: 0d0a 2020 2020 2020 2020 6469 6d20 3d20  ..        dim = 
+00024240: 7365 6c66 2e73 616d 706c 655f 6469 6d0d  self.sample_dim.
+00024250: 0a20 2020 2020 2020 2023 2073 6861 7065  .        # shape
+00024260: 206d 7573 7420 6861 7665 2061 7420 6c65   must have at le
+00024270: 6173 7420 6f6e 6520 6469 6d65 6e73 696f  ast one dimensio
+00024280: 6e0d 0a20 2020 2020 2020 2069 6620 6e6f  n..        if no
+00024290: 7420 6c65 6e28 7368 6170 6529 3a0d 0a20  t len(shape):.. 
+000242a0: 2020 2020 2020 2020 2020 2072 6169 7365             raise
+000242b0: 2052 756e 7469 6d65 4572 726f 7228 0d0a   RuntimeError(..
+000242c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000242d0: 2243 616e 6e6f 7420 7375 622d 7361 6d70  "Cannot sub-samp
+000242e0: 6c65 2066 726f 6d20 6120 7465 6e73 6f72  le from a tensor
+000242f0: 6469 6374 2077 6974 6820 616e 2065 6d70  dict with an emp
+00024300: 7479 2073 6861 7065 2e22 0d0a 2020 2020  ty shape."..    
+00024310: 2020 2020 2020 2020 290d 0a20 2020 2020          )..     
+00024320: 2020 2069 6620 7368 6170 655b 6469 6d5d     if shape[dim]
+00024330: 203c 2073 656c 662e 7375 625f 7365 715f   < self.sub_seq_
+00024340: 6c65 6e3a 0d0a 2020 2020 2020 2020 2020  len:..          
+00024350: 2020 7261 6973 6520 5275 6e74 696d 6545    raise RuntimeE
+00024360: 7272 6f72 280d 0a20 2020 2020 2020 2020  rror(..         
+00024370: 2020 2020 2020 2066 2243 616e 6e6f 7420         f"Cannot 
+00024380: 7361 6d70 6c65 2074 7261 6a65 6374 6f72  sample trajector
+00024390: 6965 7320 6f66 206c 656e 6774 6820 7b73  ies of length {s
+000243a0: 656c 662e 7375 625f 7365 715f 6c65 6e7d  elf.sub_seq_len}
+000243b0: 2061 6c6f 6e67 220d 0a20 2020 2020 2020   along"..       
+000243c0: 2020 2020 2020 2020 2066 2220 6469 6d65           f" dime
+000243d0: 6e73 696f 6e20 7b64 696d 7d20 6769 7665  nsion {dim} give
+000243e0: 6e20 6120 7465 6e73 6f72 6469 6374 206f  n a tensordict o
+000243f0: 6620 7368 6170 6520 220d 0a20 2020 2020  f shape "..     
+00024400: 2020 2020 2020 2020 2020 2066 227b 7465             f"{te
+00024410: 6e73 6f72 6469 6374 2e73 6861 7065 7d2e  nsordict.shape}.
+00024420: 2043 6f6e 7369 6465 7220 7265 6475 6369   Consider reduci
+00024430: 6e67 2074 6865 2073 7562 5f73 6571 5f6c  ng the sub_seq_l
+00024440: 656e 2022 0d0a 2020 2020 2020 2020 2020  en "..          
+00024450: 2020 2020 2020 6622 7061 7261 6d65 7465        f"paramete
+00024460: 7220 6f72 2069 6e63 7265 6173 6520 7361  r or increase sa
+00024470: 6d70 6c65 206c 656e 6774 682e 220d 0a20  mple length.".. 
+00024480: 2020 2020 2020 2020 2020 2029 0d0a 2020             )..  
+00024490: 2020 2020 2020 6d61 785f 6964 785f 3020        max_idx_0 
+000244a0: 3d20 7368 6170 655b 6469 6d5d 202d 2073  = shape[dim] - s
+000244b0: 656c 662e 7375 625f 7365 715f 6c65 6e0d  elf.sub_seq_len.
+000244c0: 0a20 2020 2020 2020 2069 6478 5f73 6861  .        idx_sha
+000244d0: 7065 203d 206c 6973 7428 7465 6e73 6f72  pe = list(tensor
+000244e0: 6469 6374 2e73 6861 7065 290d 0a20 2020  dict.shape)..   
+000244f0: 2020 2020 2069 6478 5f73 6861 7065 5b64       idx_shape[d
+00024500: 696d 5d20 3d20 310d 0a20 2020 2020 2020  im] = 1..       
+00024510: 2064 6576 6963 6520 3d20 7465 6e73 6f72   device = tensor
+00024520: 6469 6374 2e64 6576 6963 650d 0a20 2020  dict.device..   
+00024530: 2020 2020 2069 6620 6465 7669 6365 2069       if device i
+00024540: 7320 4e6f 6e65 3a0d 0a20 2020 2020 2020  s None:..       
+00024550: 2020 2020 2064 6576 6963 6520 3d20 746f       device = to
+00024560: 7263 682e 6465 7669 6365 2822 6370 7522  rch.device("cpu"
+00024570: 290d 0a20 2020 2020 2020 2069 6620 7365  )..        if se
+00024580: 6c66 2e6d 6173 6b5f 6b65 7920 6973 204e  lf.mask_key is N
+00024590: 6f6e 6520 6f72 2073 656c 662e 6d61 736b  one or self.mask
+000245a0: 5f6b 6579 206e 6f74 2069 6e20 7465 6e73  _key not in tens
+000245b0: 6f72 6469 6374 2e6b 6579 7328 0d0a 2020  ordict.keys(..  
+000245c0: 2020 2020 2020 2020 2020 6973 696e 7374            isinst
+000245d0: 616e 6365 2873 656c 662e 6d61 736b 5f6b  ance(self.mask_k
+000245e0: 6579 2c20 7475 706c 6529 0d0a 2020 2020  ey, tuple)..    
+000245f0: 2020 2020 293a 0d0a 2020 2020 2020 2020      ):..        
+00024600: 2020 2020 6964 785f 3020 3d20 746f 7263      idx_0 = torc
+00024610: 682e 7261 6e64 696e 7428 6d61 785f 6964  h.randint(max_id
+00024620: 785f 302c 2069 6478 5f73 6861 7065 2c20  x_0, idx_shape, 
+00024630: 6465 7669 6365 3d64 6576 6963 6529 0d0a  device=device)..
+00024640: 2020 2020 2020 2020 656c 7365 3a0d 0a20          else:.. 
+00024650: 2020 2020 2020 2020 2020 2023 2067 6574             # get
+00024660: 2074 6865 2074 7261 6a20 6c65 6e67 7468   the traj length
+00024670: 2066 6f72 2065 6163 6820 656e 7472 790d   for each entry.
+00024680: 0a20 2020 2020 2020 2020 2020 206d 6173  .            mas
+00024690: 6b20 3d20 7465 6e73 6f72 6469 6374 2e67  k = tensordict.g
+000246a0: 6574 2873 656c 662e 6d61 736b 5f6b 6579  et(self.mask_key
+000246b0: 290d 0a20 2020 2020 2020 2020 2020 2069  )..            i
+000246c0: 6620 6d61 736b 2e73 6861 7065 2021 3d20  f mask.shape != 
+000246d0: 7465 6e73 6f72 6469 6374 2e73 6861 7065  tensordict.shape
+000246e0: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
+000246f0: 2020 2072 6169 7365 2056 616c 7565 4572     raise ValueEr
+00024700: 726f 7228 0d0a 2020 2020 2020 2020 2020  ror(..          
+00024710: 2020 2020 2020 2020 2020 2245 7870 6563            "Expec
+00024720: 7465 6420 6120 6d61 736b 206f 6620 7468  ted a mask of th
+00024730: 6520 7361 6d65 2073 6861 7065 2061 7320  e same shape as 
+00024740: 7468 6520 7465 6e73 6f72 6469 6374 2e20  the tensordict. 
+00024750: 476f 7420 220d 0a20 2020 2020 2020 2020  Got "..         
+00024760: 2020 2020 2020 2020 2020 2066 226d 6173             f"mas
+00024770: 6b2e 7368 6170 653d 7b6d 6173 6b2e 7368  k.shape={mask.sh
+00024780: 6170 657d 2061 6e64 2074 656e 736f 7264  ape} and tensord
+00024790: 6963 742e 7368 6170 653d 220d 0a20 2020  ict.shape="..   
+000247a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000247b0: 2066 227b 7465 6e73 6f72 6469 6374 2e73   f"{tensordict.s
+000247c0: 6861 7065 7d20 696e 7374 6561 642e 220d  hape} instead.".
+000247d0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000247e0: 2029 0d0a 2020 2020 2020 2020 2020 2020   )..            
+000247f0: 7472 616a 5f6c 656e 6774 6873 203d 206d  traj_lengths = m
+00024800: 6173 6b2e 6375 6d73 756d 2873 656c 662e  ask.cumsum(self.
+00024810: 7361 6d70 6c65 5f64 696d 292e 6d61 7828  sample_dim).max(
+00024820: 7365 6c66 2e73 616d 706c 655f 6469 6d2c  self.sample_dim,
+00024830: 2054 7275 6529 5b30 5d0d 0a20 2020 2020   True)[0]..     
+00024840: 2020 2020 2020 2069 6620 2874 7261 6a5f         if (traj_
+00024850: 6c65 6e67 7468 7320 3c20 7365 6c66 2e73  lengths < self.s
+00024860: 7562 5f73 6571 5f6c 656e 292e 616e 7928  ub_seq_len).any(
+00024870: 293a 0d0a 2020 2020 2020 2020 2020 2020  ):..            
+00024880: 2020 2020 7261 6973 6520 5275 6e74 696d      raise Runtim
+00024890: 6545 7272 6f72 280d 0a20 2020 2020 2020  eError(..       
+000248a0: 2020 2020 2020 2020 2020 2020 2066 2243               f"C
+000248b0: 616e 6e6f 7420 7361 6d70 6c65 2074 7261  annot sample tra
+000248c0: 6a65 6374 6f72 6965 7320 6f66 206c 656e  jectories of len
+000248d0: 6774 6820 7b73 656c 662e 7375 625f 7365  gth {self.sub_se
+000248e0: 715f 6c65 6e7d 2077 6865 6e20 7468 6520  q_len} when the 
+000248f0: 6d69 6e69 6d75 6d20 220d 0a20 2020 2020  minimum "..     
+00024900: 2020 2020 2020 2020 2020 2020 2020 2066                 f
+00024910: 2274 7261 6a65 6374 6f72 7920 6c65 6e67  "trajectory leng
+00024920: 7468 2069 7320 7b74 7261 6a5f 6c65 6e67  th is {traj_leng
+00024930: 7468 732e 6d69 6e28 297d 2e22 0d0a 2020  ths.min()}."..  
+00024940: 2020 2020 2020 2020 2020 2020 2020 290d                ).
+00024950: 0a20 2020 2020 2020 2020 2020 2023 2074  .            # t
+00024960: 616b 6520 6120 7261 6e64 6f6d 206e 756d  ake a random num
+00024970: 6265 7220 6265 7477 6565 6e20 3020 616e  ber between 0 an
+00024980: 6420 7472 616a 5f6c 656e 6774 6873 202d  d traj_lengths -
+00024990: 2073 656c 662e 7375 625f 7365 715f 6c65   self.sub_seq_le
+000249a0: 6e0d 0a20 2020 2020 2020 2020 2020 2069  n..            i
+000249b0: 6478 5f30 203d 2028 0d0a 2020 2020 2020  dx_0 = (..      
+000249c0: 2020 2020 2020 2020 2020 746f 7263 682e            torch.
+000249d0: 7261 6e64 2869 6478 5f73 6861 7065 2c20  rand(idx_shape, 
+000249e0: 6465 7669 6365 3d64 6576 6963 6529 202a  device=device) *
+000249f0: 2028 7472 616a 5f6c 656e 6774 6873 202d   (traj_lengths -
+00024a00: 2073 656c 662e 7375 625f 7365 715f 6c65   self.sub_seq_le
+00024a10: 6e29 0d0a 2020 2020 2020 2020 2020 2020  n)..            
+00024a20: 292e 746f 2874 6f72 6368 2e6c 6f6e 6729  ).to(torch.long)
+00024a30: 0d0a 2020 2020 2020 2020 6172 616e 6765  ..        arange
+00024a40: 203d 2074 6f72 6368 2e61 7261 6e67 6528   = torch.arange(
+00024a50: 7365 6c66 2e73 7562 5f73 6571 5f6c 656e  self.sub_seq_len
+00024a60: 2c20 6465 7669 6365 3d69 6478 5f30 2e64  , device=idx_0.d
+00024a70: 6576 6963 6529 0d0a 2020 2020 2020 2020  evice)..        
+00024a80: 6172 616e 6765 5f73 6861 7065 203d 205b  arange_shape = [
+00024a90: 3120 666f 7220 5f20 696e 2072 616e 6765  1 for _ in range
+00024aa0: 2874 656e 736f 7264 6963 742e 6e64 696d  (tensordict.ndim
+00024ab0: 656e 7369 6f6e 2829 295d 0d0a 2020 2020  ension())]..    
+00024ac0: 2020 2020 6172 616e 6765 5f73 6861 7065      arange_shape
+00024ad0: 5b64 696d 5d20 3d20 6c65 6e28 6172 616e  [dim] = len(aran
+00024ae0: 6765 290d 0a20 2020 2020 2020 2061 7261  ge)..        ara
+00024af0: 6e67 6520 3d20 6172 616e 6765 2e76 6965  nge = arange.vie
+00024b00: 7728 6172 616e 6765 5f73 6861 7065 290d  w(arange_shape).
+00024b10: 0a20 2020 2020 2020 2069 6478 203d 2069  .        idx = i
+00024b20: 6478 5f30 202b 2061 7261 6e67 650d 0a20  dx_0 + arange.. 
+00024b30: 2020 2020 2020 2072 6574 7572 6e20 7465         return te
+00024b40: 6e73 6f72 6469 6374 2e67 6174 6865 7228  nsordict.gather(
+00024b50: 6469 6d3d 7365 6c66 2e73 616d 706c 655f  dim=self.sample_
+00024b60: 6469 6d2c 2069 6e64 6578 3d69 6478 290d  dim, index=idx).
+00024b70: 0a0d 0a0d 0a63 6c61 7373 2049 6e69 7454  .....class InitT
+00024b80: 7261 636b 6572 2854 7261 6e73 666f 726d  racker(Transform
+00024b90: 293a 0d0a 2020 2020 2222 2252 6573 6574  ):..    """Reset
+00024ba0: 2074 7261 636b 6572 2e0d 0a0d 0a20 2020   tracker.....   
+00024bb0: 2054 6869 7320 7472 616e 7366 6f72 6d20   This transform 
+00024bc0: 706f 7075 6c61 7465 7320 7468 6520 7374  populates the st
+00024bd0: 6570 2f72 6573 6574 2074 656e 736f 7264  ep/reset tensord
+00024be0: 6963 7420 7769 7468 2061 2072 6573 6574  ict with a reset
+00024bf0: 2074 7261 636b 6572 2065 6e74 7279 0d0a   tracker entry..
+00024c00: 2020 2020 7468 6174 2069 7320 7365 7420      that is set 
+00024c10: 746f 2060 6054 7275 6560 6020 7768 656e  to ``True`` when
+00024c20: 6576 6572 203a 6d65 7468 3a60 7e2e 7265  ever :meth:`~.re
+00024c30: 7365 7460 2069 7320 6361 6c6c 6564 2e0d  set` is called..
+00024c40: 0a0d 0a20 2020 2041 7267 733a 0d0a 2020  ...    Args:..  
+00024c50: 2020 2020 2020 2069 6e69 745f 6b65 7920         init_key 
+00024c60: 2873 7472 2c20 6f70 7469 6f6e 616c 293a  (str, optional):
+00024c70: 2074 6865 206b 6579 2074 6f20 6265 2075   the key to be u
+00024c80: 7365 6420 666f 7220 7468 6520 7472 6163  sed for the trac
+00024c90: 6b65 7220 656e 7472 792e 0d0a 0d0a 2020  ker entry.....  
+00024ca0: 2020 4578 616d 706c 6573 3a0d 0a20 2020    Examples:..   
+00024cb0: 2020 2020 203e 3e3e 2066 726f 6d20 746f       >>> from to
+00024cc0: 7263 6872 6c2e 656e 7673 2e6c 6962 732e  rchrl.envs.libs.
+00024cd0: 6779 6d20 696d 706f 7274 2047 796d 456e  gym import GymEn
+00024ce0: 760d 0a20 2020 2020 2020 203e 3e3e 2065  v..        >>> e
+00024cf0: 6e76 203d 2054 7261 6e73 666f 726d 6564  nv = Transformed
+00024d00: 456e 7628 4779 6d45 6e76 2822 5065 6e64  Env(GymEnv("Pend
+00024d10: 756c 756d 2d76 3122 292c 2049 6e69 7454  ulum-v1"), InitT
+00024d20: 7261 636b 6572 2829 290d 0a20 2020 2020  racker())..     
+00024d30: 2020 203e 3e3e 2074 6420 3d20 656e 762e     >>> td = env.
+00024d40: 7265 7365 7428 290d 0a20 2020 2020 2020  reset()..       
+00024d50: 203e 3e3e 2070 7269 6e74 2874 645b 2269   >>> print(td["i
+00024d60: 735f 696e 6974 225d 290d 0a20 2020 2020  s_init"])..     
+00024d70: 2020 2074 656e 736f 7228 5472 7565 290d     tensor(True).
+00024d80: 0a20 2020 2020 2020 203e 3e3e 2074 6420  .        >>> td 
+00024d90: 3d20 656e 762e 7261 6e64 5f73 7465 7028  = env.rand_step(
+00024da0: 7464 290d 0a20 2020 2020 2020 203e 3e3e  td)..        >>>
+00024db0: 2070 7269 6e74 2874 645b 226e 6578 7422   print(td["next"
+00024dc0: 2c20 2269 735f 696e 6974 225d 290d 0a20  , "is_init"]).. 
+00024dd0: 2020 2020 2020 2074 656e 736f 7228 4661         tensor(Fa
+00024de0: 6c73 6529 0d0a 0d0a 2020 2020 2222 220d  lse)....    """.
+00024df0: 0a0d 0a20 2020 2064 6566 205f 5f69 6e69  ...    def __ini
+00024e00: 745f 5f28 7365 6c66 2c20 696e 6974 5f6b  t__(self, init_k
+00024e10: 6579 3a20 626f 6f6c 203d 2022 6973 5f69  ey: bool = "is_i
+00024e20: 6e69 7422 293a 0d0a 2020 2020 2020 2020  nit"):..        
+00024e30: 7375 7065 7228 292e 5f5f 696e 6974 5f5f  super().__init__
+00024e40: 2869 6e5f 6b65 7973 3d5b 5d2c 206f 7574  (in_keys=[], out
+00024e50: 5f6b 6579 733d 5b69 6e69 745f 6b65 795d  _keys=[init_key]
+00024e60: 290d 0a0d 0a20 2020 2064 6566 205f 6361  )....    def _ca
+00024e70: 6c6c 2873 656c 662c 2074 656e 736f 7264  ll(self, tensord
+00024e80: 6963 743a 2054 656e 736f 7244 6963 7442  ict: TensorDictB
+00024e90: 6173 6529 202d 3e20 5465 6e73 6f72 4469  ase) -> TensorDi
+00024ea0: 6374 4261 7365 3a0d 0a20 2020 2020 2020  ctBase:..       
+00024eb0: 2069 6620 7365 6c66 2e6f 7574 5f6b 6579   if self.out_key
+00024ec0: 735b 305d 206e 6f74 2069 6e20 7465 6e73  s[0] not in tens
+00024ed0: 6f72 6469 6374 2e6b 6579 7328 293a 0d0a  ordict.keys():..
+00024ee0: 2020 2020 2020 2020 2020 2020 6465 7669              devi
+00024ef0: 6365 203d 2074 656e 736f 7264 6963 742e  ce = tensordict.
+00024f00: 6465 7669 6365 0d0a 2020 2020 2020 2020  device..        
+00024f10: 2020 2020 6966 2064 6576 6963 6520 6973      if device is
+00024f20: 204e 6f6e 653a 0d0a 2020 2020 2020 2020   None:..        
+00024f30: 2020 2020 2020 2020 6465 7669 6365 203d          device =
+00024f40: 2074 6f72 6368 2e64 6576 6963 6528 2263   torch.device("c
+00024f50: 7075 2229 0d0a 2020 2020 2020 2020 2020  pu")..          
+00024f60: 2020 7465 6e73 6f72 6469 6374 2e73 6574    tensordict.set
+00024f70: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
+00024f80: 2020 2073 656c 662e 6f75 745f 6b65 7973     self.out_keys
+00024f90: 5b30 5d2c 0d0a 2020 2020 2020 2020 2020  [0],..          
+00024fa0: 2020 2020 2020 746f 7263 682e 7a65 726f        torch.zero
+00024fb0: 7328 0d0a 2020 2020 2020 2020 2020 2020  s(..            
+00024fc0: 2020 2020 2020 2020 7365 6c66 2e70 6172          self.par
+00024fd0: 656e 742e 646f 6e65 5f73 7065 632e 7368  ent.done_spec.sh
+00024fe0: 6170 652c 2064 6576 6963 653d 6465 7669  ape, device=devi
+00024ff0: 6365 2c20 6474 7970 653d 746f 7263 682e  ce, dtype=torch.
+00025000: 626f 6f6c 0d0a 2020 2020 2020 2020 2020  bool..          
+00025010: 2020 2020 2020 292c 0d0a 2020 2020 2020        ),..      
+00025020: 2020 2020 2020 290d 0a20 2020 2020 2020        )..       
+00025030: 2072 6574 7572 6e20 7465 6e73 6f72 6469   return tensordi
+00025040: 6374 0d0a 0d0a 2020 2020 6465 6620 7265  ct....    def re
+00025050: 7365 7428 7365 6c66 2c20 7465 6e73 6f72  set(self, tensor
+00025060: 6469 6374 3a20 5465 6e73 6f72 4469 6374  dict: TensorDict
+00025070: 4261 7365 2920 2d3e 2054 656e 736f 7244  Base) -> TensorD
+00025080: 6963 7442 6173 653a 0d0a 2020 2020 2020  ictBase:..      
+00025090: 2020 6465 7669 6365 203d 2074 656e 736f    device = tenso
+000250a0: 7264 6963 742e 6465 7669 6365 0d0a 2020  rdict.device..  
+000250b0: 2020 2020 2020 6966 2064 6576 6963 6520        if device 
+000250c0: 6973 204e 6f6e 653a 0d0a 2020 2020 2020  is None:..      
+000250d0: 2020 2020 2020 6465 7669 6365 203d 2074        device = t
+000250e0: 6f72 6368 2e64 6576 6963 6528 2263 7075  orch.device("cpu
+000250f0: 2229 0d0a 2020 2020 2020 2020 5f72 6573  ")..        _res
+00025100: 6574 203d 2074 656e 736f 7264 6963 742e  et = tensordict.
+00025110: 6765 7428 225f 7265 7365 7422 2c20 4e6f  get("_reset", No
+00025120: 6e65 290d 0a20 2020 2020 2020 2069 6620  ne)..        if 
+00025130: 5f72 6573 6574 2069 7320 4e6f 6e65 3a0d  _reset is None:.
+00025140: 0a20 2020 2020 2020 2020 2020 205f 7265  .            _re
+00025150: 7365 7420 3d20 746f 7263 682e 6f6e 6573  set = torch.ones
+00025160: 280d 0a20 2020 2020 2020 2020 2020 2020  (..             
+00025170: 2020 2073 656c 662e 7061 7265 6e74 2e64     self.parent.d
+00025180: 6f6e 655f 7370 6563 2e73 6861 7065 2c0d  one_spec.shape,.
+00025190: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000251a0: 2064 6576 6963 653d 6465 7669 6365 2c0d   device=device,.
+000251b0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+000251c0: 2064 7479 7065 3d74 6f72 6368 2e62 6f6f   dtype=torch.boo
+000251d0: 6c2c 0d0a 2020 2020 2020 2020 2020 2020  l,..            
+000251e0: 290d 0a20 2020 2020 2020 2074 656e 736f  )..        tenso
+000251f0: 7264 6963 742e 7365 7428 7365 6c66 2e6f  rdict.set(self.o
+00025200: 7574 5f6b 6579 735b 305d 2c20 5f72 6573  ut_keys[0], _res
+00025210: 6574 2e63 6c6f 6e65 2829 290d 0a20 2020  et.clone())..   
+00025220: 2020 2020 2072 6574 7572 6e20 7465 6e73       return tens
+00025230: 6f72 6469 6374 0d0a 0d0a 2020 2020 6465  ordict....    de
+00025240: 6620 7472 616e 7366 6f72 6d5f 6f62 7365  f transform_obse
+00025250: 7276 6174 696f 6e5f 7370 6563 2873 656c  rvation_spec(sel
+00025260: 662c 206f 6273 6572 7661 7469 6f6e 5f73  f, observation_s
+00025270: 7065 633a 2054 656e 736f 7253 7065 6329  pec: TensorSpec)
+00025280: 202d 3e20 5465 6e73 6f72 5370 6563 3a0d   -> TensorSpec:.
+00025290: 0a20 2020 2020 2020 206f 6273 6572 7661  .        observa
+000252a0: 7469 6f6e 5f73 7065 635b 7365 6c66 2e6f  tion_spec[self.o
+000252b0: 7574 5f6b 6579 735b 305d 5d20 3d20 4469  ut_keys[0]] = Di
+000252c0: 7363 7265 7465 5465 6e73 6f72 5370 6563  screteTensorSpec
+000252d0: 280d 0a20 2020 2020 2020 2020 2020 2032  (..            2
+000252e0: 2c0d 0a20 2020 2020 2020 2020 2020 2064  ,..            d
+000252f0: 7479 7065 3d74 6f72 6368 2e62 6f6f 6c2c  type=torch.bool,
+00025300: 0d0a 2020 2020 2020 2020 2020 2020 6465  ..            de
+00025310: 7669 6365 3d73 656c 662e 7061 7265 6e74  vice=self.parent
+00025320: 2e64 6576 6963 652c 0d0a 2020 2020 2020  .device,..      
+00025330: 2020 2020 2020 7368 6170 653d 7365 6c66        shape=self
+00025340: 2e70 6172 656e 742e 646f 6e65 5f73 7065  .parent.done_spe
+00025350: 632e 7368 6170 652c 0d0a 2020 2020 2020  c.shape,..      
+00025360: 2020 290d 0a20 2020 2020 2020 2072 6574    )..        ret
+00025370: 7572 6e20 6f62 7365 7276 6174 696f 6e5f  urn observation_
+00025380: 7370 6563 0d0a 0d0a 2020 2020 6465 6620  spec....    def 
+00025390: 666f 7277 6172 6428 7365 6c66 2c20 7465  forward(self, te
+000253a0: 6e73 6f72 6469 6374 3a20 5465 6e73 6f72  nsordict: Tensor
+000253b0: 4469 6374 4261 7365 2920 2d3e 2054 656e  DictBase) -> Ten
+000253c0: 736f 7244 6963 7442 6173 653a 0d0a 2020  sorDictBase:..  
+000253d0: 2020 2020 2020 7261 6973 6520 4e6f 7449        raise NotI
+000253e0: 6d70 6c65 6d65 6e74 6564 4572 726f 7228  mplementedError(
+000253f0: 0d0a 2020 2020 2020 2020 2020 2020 464f  ..            FO
+00025400: 5257 4152 445f 4e4f 545f 494d 504c 454d  RWARD_NOT_IMPLEM
+00025410: 454e 5445 442e 666f 726d 6174 2873 656c  ENTED.format(sel
+00025420: 662e 5f5f 636c 6173 735f 5f2e 5f5f 6e61  f.__class__.__na
+00025430: 6d65 5f5f 290d 0a20 2020 2020 2020 2029  me__)..        )
+00025440: 0d0a 0d0a 0d0a 636c 6173 7320 5265 6e61  ......class Rena
+00025450: 6d65 5472 616e 7366 6f72 6d28 5472 616e  meTransform(Tran
+00025460: 7366 6f72 6d29 3a0d 0a20 2020 2022 2222  sform):..    """
+00025470: 4120 7472 616e 7366 6f72 6d20 746f 2072  A transform to r
+00025480: 656e 616d 6520 656e 7472 6965 7320 696e  ename entries in
+00025490: 2074 6865 206f 7574 7075 7420 7465 6e73   the output tens
+000254a0: 6f72 6469 6374 2e0d 0a0d 0a20 2020 2041  ordict.....    A
+000254b0: 7267 733a 0d0a 2020 2020 2020 2020 696e  rgs:..        in
+000254c0: 5f6b 6579 7320 286c 6973 7420 6f66 2073  _keys (list of s
+000254d0: 7472 2f74 7570 6c65 7320 6f66 2073 7472  tr/tuples of str
+000254e0: 293a 2074 6865 2065 6e74 7269 6573 2074  ): the entries t
+000254f0: 6f20 7265 6e61 6d65 0d0a 2020 2020 2020  o rename..      
+00025500: 2020 6f75 745f 6b65 7973 2028 6c69 7374    out_keys (list
+00025510: 206f 6620 7374 722f 7475 706c 6573 206f   of str/tuples o
+00025520: 6620 7374 7229 3a20 7468 6520 6e61 6d65  f str): the name
+00025530: 206f 6620 7468 6520 656e 7472 6965 7320   of the entries 
+00025540: 6166 7465 7220 7265 6e61 6d69 6e67 2e0d  after renaming..
+00025550: 0a20 2020 2020 2020 2069 6e5f 6b65 7973  .        in_keys
+00025560: 5f69 6e76 2028 6c69 7374 206f 6620 7374  _inv (list of st
+00025570: 722f 7475 706c 6573 206f 6620 7374 7229  r/tuples of str)
+00025580: 3a20 7468 6520 656e 7472 6965 7320 746f  : the entries to
+00025590: 2072 656e 616d 6520 6265 666f 7265 0d0a   rename before..
+000255a0: 2020 2020 2020 2020 2020 2020 7061 7373              pass
+000255b0: 696e 6720 7468 6520 696e 7075 7420 7465  ing the input te
+000255c0: 6e73 6f72 6469 6374 2074 6f20 3a6d 6574  nsordict to :met
+000255d0: 683a 6045 6e76 4261 7365 2e5f 7374 6570  h:`EnvBase._step
+000255e0: 602e 0d0a 2020 2020 2020 2020 6f75 745f  `...        out_
+000255f0: 6b65 7973 5f69 6e76 2028 6c69 7374 206f  keys_inv (list o
+00025600: 6620 7374 722f 7475 706c 6573 206f 6620  f str/tuples of 
+00025610: 7374 7229 3a20 7468 6520 6e61 6d65 7320  str): the names 
+00025620: 6f66 2074 6865 2072 656e 616d 6564 0d0a  of the renamed..
+00025630: 2020 2020 2020 2020 2020 2020 656e 7472              entr
+00025640: 6965 7320 7061 7373 6564 2074 6f20 3a6d  ies passed to :m
+00025650: 6574 683a 6045 6e76 4261 7365 2e5f 7374  eth:`EnvBase._st
+00025660: 6570 602e 0d0a 2020 2020 2020 2020 6372  ep`...        cr
+00025670: 6561 7465 5f63 6f70 7920 2862 6f6f 6c2c  eate_copy (bool,
+00025680: 206f 7074 696f 6e61 6c29 3a20 6966 2060   optional): if `
+00025690: 6054 7275 6560 602c 2074 6865 2065 6e74  `True``, the ent
+000256a0: 7269 6573 2077 696c 6c20 6265 2063 6f70  ries will be cop
+000256b0: 6965 640d 0a20 2020 2020 2020 2020 2020  ied..           
+000256c0: 2077 6974 6820 6120 6469 6666 6572 656e   with a differen
+000256d0: 7420 6e61 6d65 2072 6174 6865 7220 7468  t name rather th
+000256e0: 616e 2062 6569 6e67 2072 656e 616d 6564  an being renamed
+000256f0: 2e20 5468 6973 2061 6c6c 6f77 7320 666f  . This allows fo
+00025700: 720d 0a20 2020 2020 2020 2020 2020 2072  r..            r
+00025710: 656e 616d 696e 6720 696d 6d75 7461 626c  enaming immutabl
+00025720: 6520 656e 7472 6965 7320 7375 6368 2061  e entries such a
+00025730: 7320 6060 2272 6577 6172 6422 6060 2061  s ``"reward"`` a
+00025740: 6e64 2060 6022 646f 6e65 2260 602e 0d0a  nd ``"done"``...
+00025750: 0d0a 2020 2020 4578 616d 706c 6573 3a0d  ..    Examples:.
+00025760: 0a20 2020 2020 2020 203e 3e3e 2066 726f  .        >>> fro
+00025770: 6d20 746f 7263 6872 6c2e 656e 7673 2e6c  m torchrl.envs.l
+00025780: 6962 732e 6779 6d20 696d 706f 7274 2047  ibs.gym import G
+00025790: 796d 456e 760d 0a20 2020 2020 2020 203e  ymEnv..        >
+000257a0: 3e3e 2065 6e76 203d 2054 7261 6e73 666f  >> env = Transfo
+000257b0: 726d 6564 456e 7628 0d0a 2020 2020 2020  rmedEnv(..      
+000257c0: 2020 2e2e 2e20 2020 2020 4779 6d45 6e76    ...     GymEnv
+000257d0: 2822 5065 6e64 756c 756d 2d76 3122 292c  ("Pendulum-v1"),
+000257e0: 0d0a 2020 2020 2020 2020 2e2e 2e20 2020  ..        ...   
+000257f0: 2020 5265 6e61 6d65 5472 616e 7366 6f72    RenameTransfor
+00025800: 6d28 5b22 6f62 7365 7276 6174 696f 6e22  m(["observation"
+00025810: 2c20 5d2c 205b 2273 7475 6666 222c 5d2c  , ], ["stuff",],
+00025820: 2063 7265 6174 655f 636f 7079 3d46 616c   create_copy=Fal
+00025830: 7365 292c 0d0a 2020 2020 2020 2020 2e2e  se),..        ..
+00025840: 2e20 290d 0a20 2020 2020 2020 203e 3e3e  . )..        >>>
+00025850: 2074 656e 736f 7264 6963 7420 3d20 656e   tensordict = en
+00025860: 762e 726f 6c6c 6f75 7428 3329 0d0a 2020  v.rollout(3)..  
+00025870: 2020 2020 2020 3e3e 3e20 7072 696e 7428        >>> print(
+00025880: 7465 6e73 6f72 6469 6374 290d 0a20 2020  tensordict)..   
+00025890: 2020 2020 2054 656e 736f 7244 6963 7428       TensorDict(
+000258a0: 0d0a 2020 2020 2020 2020 2020 2020 6669  ..            fi
+000258b0: 656c 6473 3d7b 0d0a 2020 2020 2020 2020  elds={..        
+000258c0: 2020 2020 2020 2020 6163 7469 6f6e 3a20          action: 
+000258d0: 5465 6e73 6f72 2873 6861 7065 3d74 6f72  Tensor(shape=tor
+000258e0: 6368 2e53 697a 6528 5b33 2c20 315d 292c  ch.Size([3, 1]),
+000258f0: 2064 6576 6963 653d 6370 752c 2064 7479   device=cpu, dty
+00025900: 7065 3d74 6f72 6368 2e66 6c6f 6174 3332  pe=torch.float32
+00025910: 2c20 6973 5f73 6861 7265 643d 4661 6c73  , is_shared=Fals
+00025920: 6529 2c0d 0a20 2020 2020 2020 2020 2020  e),..           
+00025930: 2020 2020 2064 6f6e 653a 2054 656e 736f       done: Tenso
+00025940: 7228 7368 6170 653d 746f 7263 682e 5369  r(shape=torch.Si
+00025950: 7a65 285b 332c 2031 5d29 2c20 6465 7669  ze([3, 1]), devi
+00025960: 6365 3d63 7075 2c20 6474 7970 653d 746f  ce=cpu, dtype=to
+00025970: 7263 682e 626f 6f6c 2c20 6973 5f73 6861  rch.bool, is_sha
+00025980: 7265 643d 4661 6c73 6529 2c0d 0a20 2020  red=False),..   
+00025990: 2020 2020 2020 2020 2020 2020 206e 6578               nex
+000259a0: 743a 2054 656e 736f 7244 6963 7428 0d0a  t: TensorDict(..
+000259b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000259c0: 2020 2020 6669 656c 6473 3d7b 0d0a 2020      fields={..  
+000259d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000259e0: 2020 2020 2020 646f 6e65 3a20 5465 6e73        done: Tens
+000259f0: 6f72 2873 6861 7065 3d74 6f72 6368 2e53  or(shape=torch.S
+00025a00: 697a 6528 5b33 2c20 315d 292c 2064 6576  ize([3, 1]), dev
+00025a10: 6963 653d 6370 752c 2064 7479 7065 3d74  ice=cpu, dtype=t
+00025a20: 6f72 6368 2e62 6f6f 6c2c 2069 735f 7368  orch.bool, is_sh
+00025a30: 6172 6564 3d46 616c 7365 292c 0d0a 2020  ared=False),..  
+00025a40: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00025a50: 2020 2020 2020 7265 7761 7264 3a20 5465        reward: Te
+00025a60: 6e73 6f72 2873 6861 7065 3d74 6f72 6368  nsor(shape=torch
+00025a70: 2e53 697a 6528 5b33 2c20 315d 292c 2064  .Size([3, 1]), d
+00025a80: 6576 6963 653d 6370 752c 2064 7479 7065  evice=cpu, dtype
+00025a90: 3d74 6f72 6368 2e66 6c6f 6174 3332 2c20  =torch.float32, 
+00025aa0: 6973 5f73 6861 7265 643d 4661 6c73 6529  is_shared=False)
+00025ab0: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
+00025ac0: 2020 2020 2020 2020 2020 2073 7475 6666             stuff
+00025ad0: 3a20 5465 6e73 6f72 2873 6861 7065 3d74  : Tensor(shape=t
+00025ae0: 6f72 6368 2e53 697a 6528 5b33 2c20 335d  orch.Size([3, 3]
+00025af0: 292c 2064 6576 6963 653d 6370 752c 2064  ), device=cpu, d
+00025b00: 7479 7065 3d74 6f72 6368 2e66 6c6f 6174  type=torch.float
+00025b10: 3332 2c20 6973 5f73 6861 7265 643d 4661  32, is_shared=Fa
+00025b20: 6c73 6529 7d2c 0d0a 2020 2020 2020 2020  lse)},..        
+00025b30: 2020 2020 2020 2020 2020 2020 6261 7463              batc
+00025b40: 685f 7369 7a65 3d74 6f72 6368 2e53 697a  h_size=torch.Siz
+00025b50: 6528 5b33 5d29 2c0d 0a20 2020 2020 2020  e([3]),..       
+00025b60: 2020 2020 2020 2020 2020 2020 2064 6576               dev
+00025b70: 6963 653d 6370 752c 0d0a 2020 2020 2020  ice=cpu,..      
+00025b80: 2020 2020 2020 2020 2020 2020 2020 6973                is
+00025b90: 5f73 6861 7265 643d 4661 6c73 6529 2c0d  _shared=False),.
+00025ba0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00025bb0: 2073 7475 6666 3a20 5465 6e73 6f72 2873   stuff: Tensor(s
+00025bc0: 6861 7065 3d74 6f72 6368 2e53 697a 6528  hape=torch.Size(
+00025bd0: 5b33 2c20 335d 292c 2064 6576 6963 653d  [3, 3]), device=
+00025be0: 6370 752c 2064 7479 7065 3d74 6f72 6368  cpu, dtype=torch
+00025bf0: 2e66 6c6f 6174 3332 2c20 6973 5f73 6861  .float32, is_sha
+00025c00: 7265 643d 4661 6c73 6529 7d2c 0d0a 2020  red=False)},..  
+00025c10: 2020 2020 2020 2020 2020 6261 7463 685f            batch_
+00025c20: 7369 7a65 3d74 6f72 6368 2e53 697a 6528  size=torch.Size(
+00025c30: 5b33 5d29 2c0d 0a20 2020 2020 2020 2020  [3]),..         
+00025c40: 2020 2064 6576 6963 653d 6370 752c 0d0a     device=cpu,..
+00025c50: 2020 2020 2020 2020 2020 2020 6973 5f73              is_s
+00025c60: 6861 7265 643d 4661 6c73 6529 0d0a 2020  hared=False)..  
+00025c70: 2020 2020 2020 3e3e 3e20 2320 6966 2074        >>> # if t
+00025c80: 6865 206f 7574 7075 7420 6973 2061 6c73  he output is als
+00025c90: 6f20 616e 2069 6e70 7574 2c20 7765 206e  o an input, we n
+00025ca0: 6565 6420 746f 2072 656e 616d 6520 6966  eed to rename if
+00025cb0: 2062 6f74 6820 7761 7973 3a0d 0a20 2020   both ways:..   
+00025cc0: 2020 2020 203e 3e3e 2066 726f 6d20 746f       >>> from to
+00025cd0: 7263 6872 6c2e 656e 7673 2e6c 6962 732e  rchrl.envs.libs.
+00025ce0: 6272 6178 2069 6d70 6f72 7420 4272 6178  brax import Brax
+00025cf0: 456e 760d 0a20 2020 2020 2020 203e 3e3e  Env..        >>>
+00025d00: 2065 6e76 203d 2054 7261 6e73 666f 726d   env = Transform
+00025d10: 6564 456e 7628 0d0a 2020 2020 2020 2020  edEnv(..        
+00025d20: 2e2e 2e20 2020 2020 4272 6178 456e 7628  ...     BraxEnv(
+00025d30: 2266 6173 7422 292c 0d0a 2020 2020 2020  "fast"),..      
+00025d40: 2020 2e2e 2e20 2020 2020 5265 6e61 6d65    ...     Rename
+00025d50: 5472 616e 7366 6f72 6d28 5b22 7374 6174  Transform(["stat
+00025d60: 6522 5d2c 205b 226e 6577 6e61 6d65 225d  e"], ["newname"]
+00025d70: 2c20 5b22 7374 6174 6522 5d2c 205b 226e  , ["state"], ["n
+00025d80: 6577 6e61 6d65 225d 290d 0a20 2020 2020  ewname"])..     
+00025d90: 2020 202e 2e2e 2029 0d0a 2020 2020 2020     ... )..      
+00025da0: 2020 3e3e 3e20 5f20 3d20 656e 762e 7365    >>> _ = env.se
+00025db0: 745f 7365 6564 2831 290d 0a20 2020 2020  t_seed(1)..     
+00025dc0: 2020 203e 3e3e 2074 656e 736f 7264 6963     >>> tensordic
+00025dd0: 7420 3d20 656e 762e 726f 6c6c 6f75 7428  t = env.rollout(
+00025de0: 3329 0d0a 2020 2020 2020 2020 3e3e 3e20  3)..        >>> 
+00025df0: 6173 7365 7274 2022 6e65 776e 616d 6522  assert "newname"
+00025e00: 2069 6e20 7465 6e73 6f72 6469 6374 2e6b   in tensordict.k
+00025e10: 6579 7328 290d 0a20 2020 2020 2020 203e  eys()..        >
+00025e20: 3e3e 2061 7373 6572 7420 2273 7461 7465  >> assert "state
+00025e30: 2220 6e6f 7420 696e 2074 656e 736f 7264  " not in tensord
+00025e40: 6963 742e 6b65 7973 2829 0d0a 0d0a 2020  ict.keys()....  
+00025e50: 2020 2222 220d 0a0d 0a20 2020 2064 6566    """....    def
+00025e60: 205f 5f69 6e69 745f 5f28 0d0a 2020 2020   __init__(..    
+00025e70: 2020 2020 7365 6c66 2c20 696e 5f6b 6579      self, in_key
+00025e80: 732c 206f 7574 5f6b 6579 732c 2069 6e5f  s, out_keys, in_
+00025e90: 6b65 7973 5f69 6e76 3d4e 6f6e 652c 206f  keys_inv=None, o
+00025ea0: 7574 5f6b 6579 735f 696e 763d 4e6f 6e65  ut_keys_inv=None
+00025eb0: 2c20 6372 6561 7465 5f63 6f70 793d 4661  , create_copy=Fa
+00025ec0: 6c73 650d 0a20 2020 2029 3a0d 0a20 2020  lse..    ):..   
+00025ed0: 2020 2020 2069 6620 2264 6f6e 6522 2069       if "done" i
+00025ee0: 6e20 696e 5f6b 6579 7320 616e 6420 6e6f  n in_keys and no
+00025ef0: 7420 6372 6561 7465 5f63 6f70 793a 0d0a  t create_copy:..
+00025f00: 2020 2020 2020 2020 2020 2020 7261 6973              rais
+00025f10: 6520 5661 6c75 6545 7272 6f72 280d 0a20  e ValueError(.. 
+00025f20: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00025f30: 5265 6e61 6d69 6e67 2027 646f 6e65 2720  Renaming 'done' 
+00025f40: 6973 206e 6f74 2061 6c6c 6f77 6564 2e20  is not allowed. 
+00025f50: 5365 7420 6063 7265 6174 655f 636f 7079  Set `create_copy
+00025f60: 6020 746f 2060 5472 7565 6020 220d 0a20  ` to `True` ".. 
+00025f70: 2020 2020 2020 2020 2020 2020 2020 2022                 "
+00025f80: 746f 2063 7265 6174 6520 6120 636f 7079  to create a copy
+00025f90: 206f 6620 7468 6520 646f 6e65 2073 7461   of the done sta
+00025fa0: 7465 2e22 0d0a 2020 2020 2020 2020 2020  te."..          
+00025fb0: 2020 290d 0a20 2020 2020 2020 2069 6620    )..        if 
+00025fc0: 2272 6577 6172 6422 2069 6e20 696e 5f6b  "reward" in in_k
+00025fd0: 6579 7320 616e 6420 6e6f 7420 6372 6561  eys and not crea
+00025fe0: 7465 5f63 6f70 793a 0d0a 2020 2020 2020  te_copy:..      
+00025ff0: 2020 2020 2020 7261 6973 6520 5661 6c75        raise Valu
+00026000: 6545 7272 6f72 280d 0a20 2020 2020 2020  eError(..       
+00026010: 2020 2020 2020 2020 2022 5265 6e61 6d69           "Renami
+00026020: 6e67 2027 7265 7761 7264 2720 6973 206e  ng 'reward' is n
+00026030: 6f74 2061 6c6c 6f77 6564 2e20 5365 7420  ot allowed. Set 
+00026040: 6063 7265 6174 655f 636f 7079 6020 746f  `create_copy` to
+00026050: 2060 5472 7565 6020 220d 0a20 2020 2020   `True` "..     
+00026060: 2020 2020 2020 2020 2020 2022 746f 2063             "to c
+00026070: 7265 6174 6520 6120 636f 7079 206f 6620  reate a copy of 
+00026080: 7468 6520 7265 7761 7264 2065 6e74 7279  the reward entry
+00026090: 2e22 0d0a 2020 2020 2020 2020 2020 2020  ."..            
+000260a0: 290d 0a20 2020 2020 2020 2069 6620 696e  )..        if in
+000260b0: 5f6b 6579 735f 696e 7620 6973 204e 6f6e  _keys_inv is Non
+000260c0: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
+000260d0: 696e 5f6b 6579 735f 696e 7620 3d20 5b5d  in_keys_inv = []
+000260e0: 0d0a 2020 2020 2020 2020 6966 206f 7574  ..        if out
+000260f0: 5f6b 6579 735f 696e 7620 6973 204e 6f6e  _keys_inv is Non
+00026100: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
+00026110: 6f75 745f 6b65 7973 5f69 6e76 203d 2063  out_keys_inv = c
+00026120: 6f70 7928 696e 5f6b 6579 735f 696e 7629  opy(in_keys_inv)
+00026130: 0d0a 2020 2020 2020 2020 7365 6c66 2e63  ..        self.c
+00026140: 7265 6174 655f 636f 7079 203d 2063 7265  reate_copy = cre
+00026150: 6174 655f 636f 7079 0d0a 2020 2020 2020  ate_copy..      
+00026160: 2020 7375 7065 7228 292e 5f5f 696e 6974    super().__init
+00026170: 5f5f 2869 6e5f 6b65 7973 2c20 6f75 745f  __(in_keys, out_
+00026180: 6b65 7973 2c20 696e 5f6b 6579 735f 696e  keys, in_keys_in
+00026190: 762c 206f 7574 5f6b 6579 735f 696e 7629  v, out_keys_inv)
+000261a0: 0d0a 2020 2020 2020 2020 6966 206c 656e  ..        if len
+000261b0: 2873 656c 662e 696e 5f6b 6579 7329 2021  (self.in_keys) !
+000261c0: 3d20 6c65 6e28 7365 6c66 2e6f 7574 5f6b  = len(self.out_k
+000261d0: 6579 7329 3a0d 0a20 2020 2020 2020 2020  eys):..         
+000261e0: 2020 2072 6169 7365 2056 616c 7565 4572     raise ValueEr
+000261f0: 726f 7228 0d0a 2020 2020 2020 2020 2020  ror(..          
+00026200: 2020 2020 2020 6622 5468 6520 6e75 6d62        f"The numb
+00026210: 6572 206f 6620 696e 5f6b 6579 7320 287b  er of in_keys ({
+00026220: 6c65 6e28 7365 6c66 2e69 6e5f 6b65 7973  len(self.in_keys
+00026230: 297d 2920 7368 6f75 6c64 206d 6174 6368  )}) should match
+00026240: 2074 6865 206e 756d 6265 7220 6f66 206f   the number of o
+00026250: 7574 5f6b 6579 7320 287b 6c65 6e28 7365  ut_keys ({len(se
+00026260: 6c66 2e6f 7574 5f6b 6579 7329 7d29 2e22  lf.out_keys)})."
+00026270: 0d0a 2020 2020 2020 2020 2020 2020 290d  ..            ).
+00026280: 0a20 2020 2020 2020 2069 6620 6c65 6e28  .        if len(
+00026290: 7365 6c66 2e69 6e5f 6b65 7973 5f69 6e76  self.in_keys_inv
+000262a0: 2920 213d 206c 656e 2873 656c 662e 6f75  ) != len(self.ou
+000262b0: 745f 6b65 7973 5f69 6e76 293a 0d0a 2020  t_keys_inv):..  
+000262c0: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
+000262d0: 5661 6c75 6545 7272 6f72 280d 0a20 2020  ValueError(..   
+000262e0: 2020 2020 2020 2020 2020 2020 2066 2254               f"T
+000262f0: 6865 206e 756d 6265 7220 6f66 2069 6e5f  he number of in_
+00026300: 6b65 7973 5f69 6e76 2028 7b6c 656e 2873  keys_inv ({len(s
+00026310: 656c 662e 696e 5f6b 6579 735f 696e 7629  elf.in_keys_inv)
+00026320: 7d29 2073 686f 756c 6420 6d61 7463 6820  }) should match 
+00026330: 7468 6520 6e75 6d62 6572 206f 6620 6f75  the number of ou
+00026340: 745f 6b65 7973 5f69 6e76 2028 7b6c 656e  t_keys_inv ({len
+00026350: 2873 656c 662e 6f75 745f 6b65 7973 297d  (self.out_keys)}
+00026360: 292e 220d 0a20 2020 2020 2020 2020 2020  )."..           
+00026370: 2029 0d0a 2020 2020 2020 2020 6966 206c   )..        if l
+00026380: 656e 2873 6574 286f 7574 5f6b 6579 7329  en(set(out_keys)
+00026390: 2e69 6e74 6572 7365 6374 696f 6e28 696e  .intersection(in
+000263a0: 5f6b 6579 7329 293a 0d0a 2020 2020 2020  _keys)):..      
+000263b0: 2020 2020 2020 7261 6973 6520 5661 6c75        raise Valu
+000263c0: 6545 7272 6f72 280d 0a20 2020 2020 2020  eError(..       
+000263d0: 2020 2020 2020 2020 2066 2243 616e 6e6f           f"Canno
+000263e0: 7420 6861 7665 206d 6174 6368 696e 6720  t have matching 
+000263f0: 696e 2061 6e64 206f 7574 5f6b 6579 7320  in and out_keys 
+00026400: 6265 6361 7573 6520 6f72 6465 7220 6973  because order is
+00026410: 2075 6e63 6c65 6172 2e20 220d 0a20 2020   unclear. "..   
+00026420: 2020 2020 2020 2020 2020 2020 2066 2250               f"P
+00026430: 6c65 6173 6520 7573 6520 7365 7061 7261  lease use separa
+00026440: 7465 6420 7472 616e 7366 6f72 6d73 2e20  ted transforms. 
+00026450: 220d 0a20 2020 2020 2020 2020 2020 2020  "..             
+00026460: 2020 2066 2247 6f74 2069 6e5f 6b65 7973     f"Got in_keys
+00026470: 3d7b 696e 5f6b 6579 737d 2061 6e64 206f  ={in_keys} and o
+00026480: 7574 5f6b 6579 733d 7b6f 7574 5f6b 6579  ut_keys={out_key
+00026490: 737d 2e22 0d0a 2020 2020 2020 2020 2020  s}."..          
+000264a0: 2020 290d 0a0d 0a20 2020 2064 6566 205f    )....    def _
+000264b0: 6361 6c6c 2873 656c 662c 2074 656e 736f  call(self, tenso
+000264c0: 7264 6963 743a 2054 656e 736f 7244 6963  rdict: TensorDic
+000264d0: 7442 6173 6529 202d 3e20 5465 6e73 6f72  tBase) -> Tensor
+000264e0: 4469 6374 4261 7365 3a0d 0a20 2020 2020  DictBase:..     
+000264f0: 2020 2069 6620 7365 6c66 2e63 7265 6174     if self.creat
+00026500: 655f 636f 7079 3a0d 0a20 2020 2020 2020  e_copy:..       
+00026510: 2020 2020 206f 7574 203d 2074 656e 736f       out = tenso
+00026520: 7264 6963 742e 7365 6c65 6374 282a 7365  rdict.select(*se
+00026530: 6c66 2e69 6e5f 6b65 7973 290d 0a20 2020  lf.in_keys)..   
+00026540: 2020 2020 2020 2020 2066 6f72 2069 6e5f           for in_
+00026550: 6b65 792c 206f 7574 5f6b 6579 2069 6e20  key, out_key in 
+00026560: 7a69 7028 7365 6c66 2e69 6e5f 6b65 7973  zip(self.in_keys
+00026570: 2c20 7365 6c66 2e6f 7574 5f6b 6579 7329  , self.out_keys)
+00026580: 3a0d 0a20 2020 2020 2020 2020 2020 2020  :..             
+00026590: 2020 206f 7574 2e72 656e 616d 655f 6b65     out.rename_ke
+000265a0: 795f 2869 6e5f 6b65 792c 206f 7574 5f6b  y_(in_key, out_k
+000265b0: 6579 290d 0a20 2020 2020 2020 2020 2020  ey)..           
+000265c0: 2074 656e 736f 7264 6963 7420 3d20 7465   tensordict = te
+000265d0: 6e73 6f72 6469 6374 2e75 7064 6174 6528  nsordict.update(
+000265e0: 6f75 7429 0d0a 2020 2020 2020 2020 656c  out)..        el
+000265f0: 7365 3a0d 0a20 2020 2020 2020 2020 2020  se:..           
+00026600: 2066 6f72 2069 6e5f 6b65 792c 206f 7574   for in_key, out
+00026610: 5f6b 6579 2069 6e20 7a69 7028 7365 6c66  _key in zip(self
+00026620: 2e69 6e5f 6b65 7973 2c20 7365 6c66 2e6f  .in_keys, self.o
+00026630: 7574 5f6b 6579 7329 3a0d 0a20 2020 2020  ut_keys):..     
+00026640: 2020 2020 2020 2020 2020 2074 656e 736f             tenso
+00026650: 7264 6963 742e 7265 6e61 6d65 5f6b 6579  rdict.rename_key
+00026660: 5f28 696e 5f6b 6579 2c20 6f75 745f 6b65  _(in_key, out_ke
+00026670: 7929 0d0a 2020 2020 2020 2020 7265 7475  y)..        retu
+00026680: 726e 2074 656e 736f 7264 6963 740d 0a0d  rn tensordict...
+00026690: 0a20 2020 2066 6f72 7761 7264 203d 205f  .    forward = _
+000266a0: 6361 6c6c 0d0a 0d0a 2020 2020 6465 6620  call....    def 
+000266b0: 5f69 6e76 5f63 616c 6c28 7365 6c66 2c20  _inv_call(self, 
+000266c0: 7465 6e73 6f72 6469 6374 3a20 5465 6e73  tensordict: Tens
+000266d0: 6f72 4469 6374 4261 7365 2920 2d3e 2054  orDictBase) -> T
+000266e0: 656e 736f 7244 6963 7442 6173 653a 0d0a  ensorDictBase:..
+000266f0: 2020 2020 2020 2020 2320 6e6f 2069 6e2d          # no in-
+00026700: 706c 6163 6520 6d6f 6469 660d 0a20 2020  place modif..   
+00026710: 2020 2020 2069 6620 7365 6c66 2e63 7265       if self.cre
+00026720: 6174 655f 636f 7079 3a0d 0a20 2020 2020  ate_copy:..     
+00026730: 2020 2020 2020 206f 7574 203d 2074 656e         out = ten
+00026740: 736f 7264 6963 742e 7365 6c65 6374 282a  sordict.select(*
+00026750: 7365 6c66 2e6f 7574 5f6b 6579 735f 696e  self.out_keys_in
+00026760: 7629 0d0a 2020 2020 2020 2020 2020 2020  v)..            
+00026770: 666f 7220 696e 5f6b 6579 2c20 6f75 745f  for in_key, out_
+00026780: 6b65 7920 696e 207a 6970 2873 656c 662e  key in zip(self.
+00026790: 696e 5f6b 6579 735f 696e 762c 2073 656c  in_keys_inv, sel
+000267a0: 662e 6f75 745f 6b65 7973 5f69 6e76 293a  f.out_keys_inv):
+000267b0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+000267c0: 2020 6f75 742e 7265 6e61 6d65 5f6b 6579    out.rename_key
+000267d0: 5f28 6f75 745f 6b65 792c 2069 6e5f 6b65  _(out_key, in_ke
+000267e0: 7929 0d0a 2020 2020 2020 2020 2020 2020  y)..            
+000267f0: 7465 6e73 6f72 6469 6374 203d 2074 656e  tensordict = ten
+00026800: 736f 7264 6963 742e 7570 6461 7465 286f  sordict.update(o
+00026810: 7574 290d 0a20 2020 2020 2020 2065 6c73  ut)..        els
+00026820: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
+00026830: 666f 7220 696e 5f6b 6579 2c20 6f75 745f  for in_key, out_
+00026840: 6b65 7920 696e 207a 6970 2873 656c 662e  key in zip(self.
+00026850: 696e 5f6b 6579 735f 696e 762c 2073 656c  in_keys_inv, sel
+00026860: 662e 6f75 745f 6b65 7973 5f69 6e76 293a  f.out_keys_inv):
+00026870: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00026880: 2020 7465 6e73 6f72 6469 6374 2e72 656e    tensordict.ren
+00026890: 616d 655f 6b65 795f 286f 7574 5f6b 6579  ame_key_(out_key
+000268a0: 2c20 696e 5f6b 6579 290d 0a20 2020 2020  , in_key)..     
+000268b0: 2020 2072 6574 7572 6e20 7465 6e73 6f72     return tensor
+000268c0: 6469 6374 0d0a 0d0a 2020 2020 6465 6620  dict....    def 
+000268d0: 7472 616e 7366 6f72 6d5f 6f75 7470 7574  transform_output
+000268e0: 5f73 7065 6328 7365 6c66 2c20 6f75 7470  _spec(self, outp
+000268f0: 7574 5f73 7065 633a 2043 6f6d 706f 7369  ut_spec: Composi
+00026900: 7465 5370 6563 2920 2d3e 2043 6f6d 706f  teSpec) -> Compo
+00026910: 7369 7465 5370 6563 3a0d 0a20 2020 2020  siteSpec:..     
+00026920: 2020 2023 2077 6520 6e65 6564 2074 6f20     # we need to 
+00026930: 6368 6563 6b20 7768 6574 6865 7220 7468  check whether th
+00026940: 6572 6520 6172 6520 7370 6563 6961 6c20  ere are special 
+00026950: 6b65 7973 0d0a 2020 2020 2020 2020 6f75  keys..        ou
+00026960: 7470 7574 5f73 7065 6320 3d20 6f75 7470  tput_spec = outp
+00026970: 7574 5f73 7065 632e 636c 6f6e 6528 290d  ut_spec.clone().
+00026980: 0a20 2020 2020 2020 2069 6620 2264 6f6e  .        if "don
+00026990: 6522 2069 6e20 7365 6c66 2e69 6e5f 6b65  e" in self.in_ke
+000269a0: 7973 3a0d 0a20 2020 2020 2020 2020 2020  ys:..           
+000269b0: 2066 6f72 2069 2c20 6f75 745f 6b65 7920   for i, out_key 
+000269c0: 696e 2065 6e75 6d65 7261 7465 2873 656c  in enumerate(sel
+000269d0: 662e 6f75 745f 6b65 7973 293a 2020 2320  f.out_keys):  # 
+000269e0: 6e6f 7161 3a20 4230 3037 0d0a 2020 2020  noqa: B007..    
+000269f0: 2020 2020 2020 2020 2020 2020 6966 2073              if s
+00026a00: 656c 662e 696e 5f6b 6579 735b 695d 203d  elf.in_keys[i] =
+00026a10: 3d20 2264 6f6e 6522 3a0d 0a20 2020 2020  = "done":..     
+00026a20: 2020 2020 2020 2020 2020 2020 2020 2062                 b
+00026a30: 7265 616b 0d0a 2020 2020 2020 2020 2020  reak..          
+00026a40: 2020 656c 7365 3a0d 0a20 2020 2020 2020    else:..       
+00026a50: 2020 2020 2020 2020 2072 6169 7365 2052           raise R
+00026a60: 756e 7469 6d65 4572 726f 7228 2245 7870  untimeError("Exp
+00026a70: 6563 7465 6420 6f6e 6520 6b65 7920 746f  ected one key to
+00026a80: 2062 6520 2764 6f6e 6527 2229 0d0a 2020   be 'done'")..  
+00026a90: 2020 2020 2020 2020 2020 6f75 7470 7574            output
+00026aa0: 5f73 7065 635b 226f 6273 6572 7661 7469  _spec["observati
+00026ab0: 6f6e 225d 5b6f 7574 5f6b 6579 5d20 3d20  on"][out_key] = 
+00026ac0: 6f75 7470 7574 5f73 7065 635b 2264 6f6e  output_spec["don
+00026ad0: 6522 5d2e 636c 6f6e 6528 290d 0a20 2020  e"].clone()..   
+00026ae0: 2020 2020 2069 6620 2272 6577 6172 6422       if "reward"
+00026af0: 2069 6e20 7365 6c66 2e69 6e5f 6b65 7973   in self.in_keys
+00026b00: 3a0d 0a20 2020 2020 2020 2020 2020 2066  :..            f
+00026b10: 6f72 2069 2c20 6f75 745f 6b65 7920 696e  or i, out_key in
+00026b20: 2065 6e75 6d65 7261 7465 2873 656c 662e   enumerate(self.
+00026b30: 6f75 745f 6b65 7973 293a 2020 2320 6e6f  out_keys):  # no
+00026b40: 7161 3a20 4230 3037 0d0a 2020 2020 2020  qa: B007..      
+00026b50: 2020 2020 2020 2020 2020 6966 2073 656c            if sel
+00026b60: 662e 696e 5f6b 6579 735b 695d 203d 3d20  f.in_keys[i] == 
+00026b70: 2272 6577 6172 6422 3a0d 0a20 2020 2020  "reward":..     
+00026b80: 2020 2020 2020 2020 2020 2020 2020 2062                 b
+00026b90: 7265 616b 0d0a 2020 2020 2020 2020 2020  reak..          
+00026ba0: 2020 656c 7365 3a0d 0a20 2020 2020 2020    else:..       
+00026bb0: 2020 2020 2020 2020 2072 6169 7365 2052           raise R
+00026bc0: 756e 7469 6d65 4572 726f 7228 2245 7870  untimeError("Exp
+00026bd0: 6563 7465 6420 6f6e 6520 6b65 7920 746f  ected one key to
+00026be0: 2062 6520 2772 6577 6172 6427 2229 0d0a   be 'reward'")..
+00026bf0: 2020 2020 2020 2020 2020 2020 6f75 7470              outp
+00026c00: 7574 5f73 7065 635b 226f 6273 6572 7661  ut_spec["observa
+00026c10: 7469 6f6e 225d 5b6f 7574 5f6b 6579 5d20  tion"][out_key] 
+00026c20: 3d20 6f75 7470 7574 5f73 7065 635b 2272  = output_spec["r
+00026c30: 6577 6172 6422 5d2e 636c 6f6e 6528 290d  eward"].clone().
+00026c40: 0a20 2020 2020 2020 2066 6f72 2069 6e5f  .        for in_
+00026c50: 6b65 792c 206f 7574 5f6b 6579 2069 6e20  key, out_key in 
+00026c60: 7a69 7028 7365 6c66 2e69 6e5f 6b65 7973  zip(self.in_keys
+00026c70: 2c20 7365 6c66 2e6f 7574 5f6b 6579 7329  , self.out_keys)
+00026c80: 3a0d 0a20 2020 2020 2020 2020 2020 2069  :..            i
+00026c90: 6620 696e 5f6b 6579 2069 6e20 2822 7265  f in_key in ("re
+00026ca0: 7761 7264 222c 2022 646f 6e65 2229 3a0d  ward", "done"):.
+00026cb0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00026cc0: 2063 6f6e 7469 6e75 650d 0a20 2020 2020   continue..     
+00026cd0: 2020 2020 2020 2069 6620 6f75 745f 6b65         if out_ke
+00026ce0: 7920 696e 2028 2264 6f6e 6522 2c20 2272  y in ("done", "r
+00026cf0: 6577 6172 6422 293a 0d0a 2020 2020 2020  eward"):..      
+00026d00: 2020 2020 2020 2020 2020 6f75 7470 7574            output
+00026d10: 5f73 7065 635b 6f75 745f 6b65 795d 203d  _spec[out_key] =
+00026d20: 206f 7574 7075 745f 7370 6563 5b22 6f62   output_spec["ob
+00026d30: 7365 7276 6174 696f 6e22 5d5b 696e 5f6b  servation"][in_k
+00026d40: 6579 5d2e 636c 6f6e 6528 290d 0a20 2020  ey].clone()..   
+00026d50: 2020 2020 2020 2020 2065 6c73 653a 0d0a           else:..
+00026d60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00026d70: 6f75 7470 7574 5f73 7065 635b 226f 6273  output_spec["obs
+00026d80: 6572 7661 7469 6f6e 225d 5b6f 7574 5f6b  ervation"][out_k
+00026d90: 6579 5d20 3d20 6f75 7470 7574 5f73 7065  ey] = output_spe
+00026da0: 635b 226f 6273 6572 7661 7469 6f6e 225d  c["observation"]
+00026db0: 5b0d 0a20 2020 2020 2020 2020 2020 2020  [..             
+00026dc0: 2020 2020 2020 2069 6e5f 6b65 790d 0a20         in_key.. 
+00026dd0: 2020 2020 2020 2020 2020 2020 2020 205d                 ]
+00026de0: 2e63 6c6f 6e65 2829 0d0a 2020 2020 2020  .clone()..      
+00026df0: 2020 2020 2020 6966 206e 6f74 2073 656c        if not sel
+00026e00: 662e 6372 6561 7465 5f63 6f70 793a 0d0a  f.create_copy:..
+00026e10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00026e20: 6465 6c20 6f75 7470 7574 5f73 7065 635b  del output_spec[
+00026e30: 226f 6273 6572 7661 7469 6f6e 225d 5b69  "observation"][i
+00026e40: 6e5f 6b65 795d 0d0a 2020 2020 2020 2020  n_key]..        
+00026e50: 7265 7475 726e 206f 7574 7075 745f 7370  return output_sp
+00026e60: 6563 0d0a 0d0a 2020 2020 6465 6620 7472  ec....    def tr
+00026e70: 616e 7366 6f72 6d5f 696e 7075 745f 7370  ansform_input_sp
+00026e80: 6563 2873 656c 662c 2069 6e70 7574 5f73  ec(self, input_s
+00026e90: 7065 633a 2043 6f6d 706f 7369 7465 5370  pec: CompositeSp
+00026ea0: 6563 2920 2d3e 2043 6f6d 706f 7369 7465  ec) -> Composite
+00026eb0: 5370 6563 3a0d 0a20 2020 2020 2020 2023  Spec:..        #
+00026ec0: 2077 6520 6e65 6564 2074 6f20 6368 6563   we need to chec
+00026ed0: 6b20 7768 6574 6865 7220 7468 6572 6520  k whether there 
+00026ee0: 6172 6520 7370 6563 6961 6c20 6b65 7973  are special keys
+00026ef0: 0d0a 2020 2020 2020 2020 696e 7075 745f  ..        input_
+00026f00: 7370 6563 203d 2069 6e70 7574 5f73 7065  spec = input_spe
+00026f10: 632e 636c 6f6e 6528 290d 0a20 2020 2020  c.clone()..     
+00026f20: 2020 2066 6f72 2069 6e5f 6b65 792c 206f     for in_key, o
+00026f30: 7574 5f6b 6579 2069 6e20 7a69 7028 7365  ut_key in zip(se
+00026f40: 6c66 2e69 6e5f 6b65 7973 5f69 6e76 2c20  lf.in_keys_inv, 
+00026f50: 7365 6c66 2e6f 7574 5f6b 6579 735f 696e  self.out_keys_in
+00026f60: 7629 3a0d 0a20 2020 2020 2020 2020 2020  v):..           
+00026f70: 2069 6e70 7574 5f73 7065 635b 6f75 745f   input_spec[out_
+00026f80: 6b65 795d 203d 2069 6e70 7574 5f73 7065  key] = input_spe
+00026f90: 635b 696e 5f6b 6579 5d2e 636c 6f6e 6528  c[in_key].clone(
+00026fa0: 290d 0a20 2020 2020 2020 2020 2020 2069  )..            i
+00026fb0: 6620 6e6f 7420 7365 6c66 2e63 7265 6174  f not self.creat
+00026fc0: 655f 636f 7079 3a0d 0a20 2020 2020 2020  e_copy:..       
+00026fd0: 2020 2020 2020 2020 2064 656c 2069 6e70           del inp
+00026fe0: 7574 5f73 7065 635b 696e 5f6b 6579 5d0d  ut_spec[in_key].
+00026ff0: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
+00027000: 696e 7075 745f 7370 6563 0d0a 0d0a 0d0a  input_spec......
+00027010: 636c 6173 7320 5265 7761 7264 3247 6f54  class Reward2GoT
+00027020: 7261 6e73 666f 726d 2854 7261 6e73 666f  ransform(Transfo
+00027030: 726d 293a 0d0a 2020 2020 2222 2243 616c  rm):..    """Cal
+00027040: 6375 6c61 7465 7320 7468 6520 7265 7761  culates the rewa
+00027050: 7264 2074 6f20 676f 2062 6173 6564 206f  rd to go based o
+00027060: 6e20 7468 6520 6570 6973 6f64 6520 7265  n the episode re
+00027070: 7761 7264 2061 6e64 2061 2064 6973 636f  ward and a disco
+00027080: 756e 7420 6661 6374 6f72 2e0d 0a0d 0a20  unt factor..... 
+00027090: 2020 2041 7320 7468 6520 3a63 6c61 7373     As the :class
+000270a0: 3a60 7e2e 5265 7761 7264 3247 6f54 7261  :`~.Reward2GoTra
+000270b0: 6e73 666f 726d 6020 6973 206f 6e6c 7920  nsform` is only 
+000270c0: 616e 2069 6e76 6572 7365 2074 7261 6e73  an inverse trans
+000270d0: 666f 726d 2074 6865 2060 6069 6e5f 6b65  form the ``in_ke
+000270e0: 7973 6060 2077 696c 6c20 6265 2064 6972  ys`` will be dir
+000270f0: 6563 746c 7920 7573 6564 2066 6f72 2074  ectly used for t
+00027100: 6865 2060 6069 6e5f 6b65 7973 5f69 6e76  he ``in_keys_inv
+00027110: 6060 2e0d 0a20 2020 2054 6865 2072 6577  ``...    The rew
+00027120: 6172 642d 746f 2d67 6f20 6361 6e20 6265  ard-to-go can be
+00027130: 206f 6e6c 7920 6361 6c63 756c 6174 6564   only calculated
+00027140: 206f 6e63 6520 7468 6520 6570 6973 6f64   once the episod
+00027150: 6520 6973 2066 696e 6973 6865 642e 2054  e is finished. T
+00027160: 6865 7265 666f 7265 2c20 7468 6520 7472  herefore, the tr
+00027170: 616e 7366 6f72 6d20 7368 6f75 6c64 2062  ansform should b
+00027180: 6520 6170 706c 6965 6420 746f 2074 6865  e applied to the
+00027190: 2072 6570 6c61 7920 6275 6666 6572 0d0a   replay buffer..
+000271a0: 2020 2020 616e 6420 6e6f 7420 746f 2074      and not to t
+000271b0: 6865 2063 6f6c 6c65 6374 6f72 2e0d 0a0d  he collector....
+000271c0: 0a20 2020 2041 7267 733a 0d0a 2020 2020  .    Args:..    
+000271d0: 2020 2020 696e 5f6b 6579 7320 286c 6973      in_keys (lis
+000271e0: 7420 6f66 2073 7472 2f74 7570 6c65 7320  t of str/tuples 
+000271f0: 6f66 2073 7472 293a 2074 6865 2065 6e74  of str): the ent
+00027200: 7269 6573 2074 6f20 7265 6e61 6d65 2e20  ries to rename. 
+00027210: 4465 6661 756c 7473 2074 6f0d 0a20 2020  Defaults to..   
+00027220: 2020 2020 2020 2020 2060 6028 226e 6578           ``("nex
+00027230: 7422 2c20 2272 6577 6172 6422 2960 6020  t", "reward")`` 
+00027240: 6966 206e 6f6e 6520 6973 2070 726f 7669  if none is provi
+00027250: 6465 642e 0d0a 2020 2020 2020 2020 6f75  ded...        ou
+00027260: 745f 6b65 7973 2028 6c69 7374 206f 6620  t_keys (list of 
+00027270: 7374 722f 7475 706c 6573 206f 6620 7374  str/tuples of st
+00027280: 7229 3a20 7468 6520 656e 7472 6965 7320  r): the entries 
+00027290: 746f 2072 656e 616d 652e 2044 6566 6175  to rename. Defau
+000272a0: 6c74 7320 746f 0d0a 2020 2020 2020 2020  lts to..        
+000272b0: 2020 2020 7468 6520 7661 6c75 6573 206f      the values o
+000272c0: 6620 6060 696e 5f6b 6579 7360 6020 6966  f ``in_keys`` if
+000272d0: 206e 6f6e 6520 6973 2070 726f 7669 6465   none is provide
+000272e0: 642e 0d0a 2020 2020 2020 2020 6761 6d6d  d...        gamm
+000272f0: 6120 2866 6c6f 6174 206f 7220 746f 7263  a (float or torc
+00027300: 682e 5465 6e73 6f72 293a 2074 6865 2064  h.Tensor): the d
+00027310: 6973 636f 756e 7420 6661 6374 6f72 2e20  iscount factor. 
+00027320: 4465 6661 756c 7473 2074 6f20 312e 302e  Defaults to 1.0.
+00027330: 0d0a 0d0a 2020 2020 4578 616d 706c 6573  ....    Examples
+00027340: 3a0d 0a20 2020 2020 2020 203e 3e3e 2023  :..        >>> #
+00027350: 2055 7369 6e67 2074 6869 7320 7472 616e   Using this tran
+00027360: 7366 6f72 6d20 6173 2070 6172 7420 6f66  sform as part of
+00027370: 2061 2072 6570 6c61 7920 6275 6666 6572   a replay buffer
+00027380: 0d0a 2020 2020 2020 2020 3e3e 3e20 6672  ..        >>> fr
+00027390: 6f6d 2074 6f72 6368 726c 2e64 6174 6120  om torchrl.data 
+000273a0: 696d 706f 7274 2052 6570 6c61 7942 7566  import ReplayBuf
+000273b0: 6665 722c 204c 617a 7954 656e 736f 7253  fer, LazyTensorS
+000273c0: 746f 7261 6765 0d0a 2020 2020 2020 2020  torage..        
+000273d0: 3e3e 3e20 746f 7263 682e 6d61 6e75 616c  >>> torch.manual
+000273e0: 5f73 6565 6428 3029 0d0a 2020 2020 2020  _seed(0)..      
+000273f0: 2020 3e3e 3e20 7232 6720 3d20 5265 7761    >>> r2g = Rewa
+00027400: 7264 3247 6f54 7261 6e73 666f 726d 2867  rd2GoTransform(g
+00027410: 616d 6d61 3d30 2e39 392c 206f 7574 5f6b  amma=0.99, out_k
+00027420: 6579 733d 5b22 7265 7761 7264 5f74 6f5f  eys=["reward_to_
+00027430: 676f 225d 290d 0a20 2020 2020 2020 203e  go"])..        >
+00027440: 3e3e 2072 6220 3d20 5265 706c 6179 4275  >> rb = ReplayBu
+00027450: 6666 6572 2873 746f 7261 6765 3d4c 617a  ffer(storage=Laz
+00027460: 7954 656e 736f 7253 746f 7261 6765 2831  yTensorStorage(1
+00027470: 3030 292c 2074 7261 6e73 666f 726d 3d72  00), transform=r
+00027480: 3267 290d 0a20 2020 2020 2020 203e 3e3e  2g)..        >>>
+00027490: 2062 6174 6368 2c20 7469 6d65 7374 6570   batch, timestep
+000274a0: 7320 3d20 342c 2035 0d0a 2020 2020 2020  s = 4, 5..      
+000274b0: 2020 3e3e 3e20 646f 6e65 203d 2074 6f72    >>> done = tor
+000274c0: 6368 2e7a 6572 6f73 2862 6174 6368 2c20  ch.zeros(batch, 
+000274d0: 7469 6d65 7374 6570 732c 2031 2c20 6474  timesteps, 1, dt
+000274e0: 7970 653d 746f 7263 682e 626f 6f6c 290d  ype=torch.bool).
+000274f0: 0a20 2020 2020 2020 203e 3e3e 2066 6f72  .        >>> for
+00027500: 2069 2069 6e20 7261 6e67 6528 6261 7463   i in range(batc
+00027510: 6829 3a0d 0a20 2020 2020 2020 202e 2e2e  h):..        ...
+00027520: 2020 2020 2077 6869 6c65 206e 6f74 2064       while not d
+00027530: 6f6e 655b 695d 2e61 6e79 2829 3a0d 0a20  one[i].any():.. 
+00027540: 2020 2020 2020 202e 2e2e 2020 2020 2020         ...      
+00027550: 2020 2064 6f6e 655b 695d 203d 2064 6f6e     done[i] = don
+00027560: 655b 695d 2e62 6572 6e6f 756c 6c69 5f28  e[i].bernoulli_(
+00027570: 302e 3129 0d0a 2020 2020 2020 2020 3e3e  0.1)..        >>
+00027580: 3e20 7265 7761 7264 203d 2074 6f72 6368  > reward = torch
+00027590: 2e6f 6e65 7328 6261 7463 682c 2074 696d  .ones(batch, tim
+000275a0: 6573 7465 7073 2c20 3129 0d0a 2020 2020  esteps, 1)..    
+000275b0: 2020 2020 3e3e 3e20 7464 203d 2054 656e      >>> td = Ten
+000275c0: 736f 7244 6963 7428 0d0a 2020 2020 2020  sorDict(..      
+000275d0: 2020 2e2e 2e20 2020 2020 7b22 6e65 7874    ...     {"next
+000275e0: 223a 207b 2264 6f6e 6522 3a20 646f 6e65  ": {"done": done
+000275f0: 2c20 2272 6577 6172 6422 3a20 7265 7761  , "reward": rewa
+00027600: 7264 7d7d 2c0d 0a20 2020 2020 2020 202e  rd}},..        .
+00027610: 2e2e 2020 2020 205b 6261 7463 682c 2074  ..     [batch, t
+00027620: 696d 6573 7465 7073 5d2c 0d0a 2020 2020  imesteps],..    
+00027630: 2020 2020 2e2e 2e20 290d 0a20 2020 2020      ... )..     
+00027640: 2020 203e 3e3e 2072 622e 6578 7465 6e64     >>> rb.extend
+00027650: 2874 6429 0d0a 2020 2020 2020 2020 3e3e  (td)..        >>
+00027660: 3e20 7361 6d70 6c65 203d 2072 622e 7361  > sample = rb.sa
+00027670: 6d70 6c65 2831 290d 0a20 2020 2020 2020  mple(1)..       
+00027680: 203e 3e3e 2070 7269 6e74 2873 616d 706c   >>> print(sampl
+00027690: 655b 226e 6578 7422 2c20 2272 6577 6172  e["next", "rewar
+000276a0: 6422 5d29 0d0a 2020 2020 2020 2020 7465  d"])..        te
+000276b0: 6e73 6f72 285b 5b5b 312e 5d2c 0d0a 2020  nsor([[[1.],..  
+000276c0: 2020 2020 2020 2020 2020 2020 2020 205b                 [
+000276d0: 312e 5d2c 0d0a 2020 2020 2020 2020 2020  1.],..          
+000276e0: 2020 2020 2020 205b 312e 5d2c 0d0a 2020         [1.],..  
+000276f0: 2020 2020 2020 2020 2020 2020 2020 205b                 [
+00027700: 312e 5d2c 0d0a 2020 2020 2020 2020 2020  1.],..          
+00027710: 2020 2020 2020 205b 312e 5d5d 5d29 0d0a         [1.]]])..
+00027720: 2020 2020 2020 2020 3e3e 3e20 7072 696e          >>> prin
+00027730: 7428 7361 6d70 6c65 5b22 7265 7761 7264  t(sample["reward
+00027740: 5f74 6f5f 676f 225d 290d 0a20 2020 2020  _to_go"])..     
+00027750: 2020 2074 656e 736f 7228 5b5b 5b34 2e39     tensor([[[4.9
+00027760: 3031 305d 2c0d 0a20 2020 2020 2020 2020  010],..         
+00027770: 2020 2020 2020 2020 5b33 2e39 3430 345d          [3.9404]
+00027780: 2c0d 0a20 2020 2020 2020 2020 2020 2020  ,..             
+00027790: 2020 2020 5b32 2e39 3730 315d 2c0d 0a20      [2.9701],.. 
+000277a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000277b0: 5b31 2e39 3930 305d 2c0d 0a20 2020 2020  [1.9900],..     
+000277c0: 2020 2020 2020 2020 2020 2020 5b31 2e30              [1.0
+000277d0: 3030 305d 5d5d 290d 0a0d 0a20 2020 204f  000]]])....    O
+000277e0: 6e65 2063 616e 2061 6c73 6f20 7573 6520  ne can also use 
+000277f0: 7468 6973 2074 7261 6e73 666f 726d 2064  this transform d
+00027800: 6972 6563 746c 7920 7769 7468 2061 2063  irectly with a c
+00027810: 6f6c 6c65 6374 6f72 3a20 6d61 6b65 2073  ollector: make s
+00027820: 7572 6520 746f 0d0a 2020 2020 6170 7065  ure to..    appe
+00027830: 6e64 2074 6865 2060 696e 7660 206d 6574  nd the `inv` met
+00027840: 686f 6420 6f66 2074 6865 2074 7261 6e73  hod of the trans
+00027850: 666f 726d 2e0d 0a0d 0a20 2020 2045 7861  form.....    Exa
+00027860: 6d70 6c65 733a 0d0a 2020 2020 2020 2020  mples:..        
+00027870: 3e3e 3e20 6672 6f6d 2074 6f72 6368 726c  >>> from torchrl
+00027880: 2e63 6f6c 6c65 6374 6f72 7320 696d 706f  .collectors impo
+00027890: 7274 2053 796e 6344 6174 6143 6f6c 6c65  rt SyncDataColle
+000278a0: 6374 6f72 2c20 5261 6e64 6f6d 506f 6c69  ctor, RandomPoli
+000278b0: 6379 0d0a 2020 2020 2020 2020 3e3e 3e20  cy..        >>> 
+000278c0: 6672 6f6d 2074 6f72 6368 726c 2e65 6e76  from torchrl.env
+000278d0: 732e 6c69 6273 2e67 796d 2069 6d70 6f72  s.libs.gym impor
+000278e0: 7420 4779 6d45 6e76 0d0a 2020 2020 2020  t GymEnv..      
+000278f0: 2020 3e3e 3e20 7420 3d20 5265 7761 7264    >>> t = Reward
+00027900: 3247 6f54 7261 6e73 666f 726d 2867 616d  2GoTransform(gam
+00027910: 6d61 3d30 2e39 392c 206f 7574 5f6b 6579  ma=0.99, out_key
+00027920: 733d 5b22 7265 7761 7264 5f74 6f5f 676f  s=["reward_to_go
+00027930: 225d 290d 0a20 2020 2020 2020 203e 3e3e  "])..        >>>
+00027940: 2065 6e76 203d 2047 796d 456e 7628 2250   env = GymEnv("P
+00027950: 656e 6475 6c75 6d2d 7631 2229 0d0a 2020  endulum-v1")..  
+00027960: 2020 2020 2020 3e3e 3e20 636f 6c6c 6563        >>> collec
+00027970: 746f 7220 3d20 5379 6e63 4461 7461 436f  tor = SyncDataCo
+00027980: 6c6c 6563 746f 7228 0d0a 2020 2020 2020  llector(..      
+00027990: 2020 2e2e 2e20 2020 2020 656e 762c 0d0a    ...     env,..
+000279a0: 2020 2020 2020 2020 2e2e 2e20 2020 2020          ...     
+000279b0: 5261 6e64 6f6d 506f 6c69 6379 2865 6e76  RandomPolicy(env
+000279c0: 2e61 6374 696f 6e5f 7370 6563 292c 0d0a  .action_spec),..
+000279d0: 2020 2020 2020 2020 2e2e 2e20 2020 2020          ...     
+000279e0: 6672 616d 6573 5f70 6572 5f62 6174 6368  frames_per_batch
+000279f0: 3d32 3030 2c0d 0a20 2020 2020 2020 202e  =200,..        .
+00027a00: 2e2e 2020 2020 2074 6f74 616c 5f66 7261  ..     total_fra
+00027a10: 6d65 733d 2d31 2c0d 0a20 2020 2020 2020  mes=-1,..       
+00027a20: 202e 2e2e 2020 2020 2070 6f73 7470 726f   ...     postpro
+00027a30: 633d 742e 696e 760d 0a20 2020 2020 2020  c=t.inv..       
+00027a40: 202e 2e2e 2029 0d0a 2020 2020 2020 2020   ... )..        
+00027a50: 3e3e 3e20 666f 7220 6461 7461 2069 6e20  >>> for data in 
+00027a60: 636f 6c6c 6563 746f 723a 0d0a 2020 2020  collector:..    
+00027a70: 2020 2020 2e2e 2e20 2020 2020 6272 6561      ...     brea
+00027a80: 6b0d 0a20 2020 2020 2020 203e 3e3e 2070  k..        >>> p
+00027a90: 7269 6e74 2864 6174 6129 0d0a 2020 2020  rint(data)..    
+00027aa0: 2020 2020 5465 6e73 6f72 4469 6374 280d      TensorDict(.
+00027ab0: 0a20 2020 2020 2020 2020 2020 2066 6965  .            fie
+00027ac0: 6c64 733d 7b0d 0a20 2020 2020 2020 2020  lds={..         
+00027ad0: 2020 2020 2020 2061 6374 696f 6e3a 2054         action: T
+00027ae0: 656e 736f 7228 7368 6170 653d 746f 7263  ensor(shape=torc
+00027af0: 682e 5369 7a65 285b 3230 302c 2031 5d29  h.Size([200, 1])
+00027b00: 2c20 6465 7669 6365 3d63 7075 2c20 6474  , device=cpu, dt
+00027b10: 7970 653d 746f 7263 682e 666c 6f61 7433  ype=torch.float3
+00027b20: 322c 2069 735f 7368 6172 6564 3d46 616c  2, is_shared=Fal
+00027b30: 7365 292c 0d0a 2020 2020 2020 2020 2020  se),..          
+00027b40: 2020 2020 2020 636f 6c6c 6563 746f 723a        collector:
+00027b50: 2054 656e 736f 7244 6963 7428 0d0a 2020   TensorDict(..  
+00027b60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00027b70: 2020 6669 656c 6473 3d7b 0d0a 2020 2020    fields={..    
+00027b80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00027b90: 2020 2020 7472 616a 5f69 6473 3a20 5465      traj_ids: Te
+00027ba0: 6e73 6f72 2873 6861 7065 3d74 6f72 6368  nsor(shape=torch
+00027bb0: 2e53 697a 6528 5b32 3030 5d29 2c20 6465  .Size([200]), de
+00027bc0: 7669 6365 3d63 7075 2c20 6474 7970 653d  vice=cpu, dtype=
+00027bd0: 746f 7263 682e 696e 7436 342c 2069 735f  torch.int64, is_
+00027be0: 7368 6172 6564 3d46 616c 7365 297d 2c0d  shared=False)},.
+00027bf0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00027c00: 2020 2020 2062 6174 6368 5f73 697a 653d       batch_size=
+00027c10: 746f 7263 682e 5369 7a65 285b 3230 305d  torch.Size([200]
+00027c20: 292c 0d0a 2020 2020 2020 2020 2020 2020  ),..            
+00027c30: 2020 2020 2020 2020 6465 7669 6365 3d63          device=c
+00027c40: 7075 2c0d 0a20 2020 2020 2020 2020 2020  pu,..           
+00027c50: 2020 2020 2020 2020 2069 735f 7368 6172           is_shar
+00027c60: 6564 3d46 616c 7365 292c 0d0a 2020 2020  ed=False),..    
+00027c70: 2020 2020 2020 2020 2020 2020 646f 6e65              done
+00027c80: 3a20 5465 6e73 6f72 2873 6861 7065 3d74  : Tensor(shape=t
+00027c90: 6f72 6368 2e53 697a 6528 5b32 3030 2c20  orch.Size([200, 
+00027ca0: 315d 292c 2064 6576 6963 653d 6370 752c  1]), device=cpu,
+00027cb0: 2064 7479 7065 3d74 6f72 6368 2e62 6f6f   dtype=torch.boo
+00027cc0: 6c2c 2069 735f 7368 6172 6564 3d46 616c  l, is_shared=Fal
+00027cd0: 7365 292c 0d0a 2020 2020 2020 2020 2020  se),..          
+00027ce0: 2020 2020 2020 6e65 7874 3a20 5465 6e73        next: Tens
+00027cf0: 6f72 4469 6374 280d 0a20 2020 2020 2020  orDict(..       
+00027d00: 2020 2020 2020 2020 2020 2020 2066 6965               fie
+00027d10: 6c64 733d 7b0d 0a20 2020 2020 2020 2020  lds={..         
+00027d20: 2020 2020 2020 2020 2020 2020 2020 2064                 d
+00027d30: 6f6e 653a 2054 656e 736f 7228 7368 6170  one: Tensor(shap
+00027d40: 653d 746f 7263 682e 5369 7a65 285b 3230  e=torch.Size([20
+00027d50: 302c 2031 5d29 2c20 6465 7669 6365 3d63  0, 1]), device=c
+00027d60: 7075 2c20 6474 7970 653d 746f 7263 682e  pu, dtype=torch.
+00027d70: 626f 6f6c 2c20 6973 5f73 6861 7265 643d  bool, is_shared=
+00027d80: 4661 6c73 6529 2c0d 0a20 2020 2020 2020  False),..       
+00027d90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00027da0: 206f 6273 6572 7661 7469 6f6e 3a20 5465   observation: Te
+00027db0: 6e73 6f72 2873 6861 7065 3d74 6f72 6368  nsor(shape=torch
+00027dc0: 2e53 697a 6528 5b32 3030 2c20 335d 292c  .Size([200, 3]),
+00027dd0: 2064 6576 6963 653d 6370 752c 2064 7479   device=cpu, dty
+00027de0: 7065 3d74 6f72 6368 2e66 6c6f 6174 3332  pe=torch.float32
+00027df0: 2c20 6973 5f73 6861 7265 643d 4661 6c73  , is_shared=Fals
+00027e00: 6529 2c0d 0a20 2020 2020 2020 2020 2020  e),..           
+00027e10: 2020 2020 2020 2020 2020 2020 2072 6577               rew
+00027e20: 6172 643a 2054 656e 736f 7228 7368 6170  ard: Tensor(shap
+00027e30: 653d 746f 7263 682e 5369 7a65 285b 3230  e=torch.Size([20
+00027e40: 302c 2031 5d29 2c20 6465 7669 6365 3d63  0, 1]), device=c
+00027e50: 7075 2c20 6474 7970 653d 746f 7263 682e  pu, dtype=torch.
+00027e60: 666c 6f61 7433 322c 2069 735f 7368 6172  float32, is_shar
+00027e70: 6564 3d46 616c 7365 297d 2c0d 0a20 2020  ed=False)},..   
+00027e80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00027e90: 2062 6174 6368 5f73 697a 653d 746f 7263   batch_size=torc
+00027ea0: 682e 5369 7a65 285b 3230 305d 292c 0d0a  h.Size([200]),..
+00027eb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00027ec0: 2020 2020 6465 7669 6365 3d63 7075 2c0d      device=cpu,.
+00027ed0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00027ee0: 2020 2020 2069 735f 7368 6172 6564 3d46       is_shared=F
+00027ef0: 616c 7365 292c 0d0a 2020 2020 2020 2020  alse),..        
+00027f00: 2020 2020 2020 2020 6f62 7365 7276 6174          observat
+00027f10: 696f 6e3a 2054 656e 736f 7228 7368 6170  ion: Tensor(shap
+00027f20: 653d 746f 7263 682e 5369 7a65 285b 3230  e=torch.Size([20
+00027f30: 302c 2033 5d29 2c20 6465 7669 6365 3d63  0, 3]), device=c
+00027f40: 7075 2c20 6474 7970 653d 746f 7263 682e  pu, dtype=torch.
+00027f50: 666c 6f61 7433 322c 2069 735f 7368 6172  float32, is_shar
+00027f60: 6564 3d46 616c 7365 292c 0d0a 2020 2020  ed=False),..    
+00027f70: 2020 2020 2020 2020 2020 2020 7265 7761              rewa
+00027f80: 7264 3a20 5465 6e73 6f72 2873 6861 7065  rd: Tensor(shape
+00027f90: 3d74 6f72 6368 2e53 697a 6528 5b32 3030  =torch.Size([200
+00027fa0: 2c20 315d 292c 2064 6576 6963 653d 6370  , 1]), device=cp
+00027fb0: 752c 2064 7479 7065 3d74 6f72 6368 2e66  u, dtype=torch.f
+00027fc0: 6c6f 6174 3332 2c20 6973 5f73 6861 7265  loat32, is_share
+00027fd0: 643d 4661 6c73 6529 2c0d 0a20 2020 2020  d=False),..     
+00027fe0: 2020 2020 2020 2020 2020 2072 6577 6172             rewar
+00027ff0: 645f 746f 5f67 6f3a 2054 656e 736f 7228  d_to_go: Tensor(
+00028000: 7368 6170 653d 746f 7263 682e 5369 7a65  shape=torch.Size
+00028010: 285b 3230 302c 2031 5d29 2c20 6465 7669  ([200, 1]), devi
+00028020: 6365 3d63 7075 2c20 6474 7970 653d 746f  ce=cpu, dtype=to
+00028030: 7263 682e 666c 6f61 7433 322c 2069 735f  rch.float32, is_
+00028040: 7368 6172 6564 3d46 616c 7365 297d 2c0d  shared=False)},.
+00028050: 0a20 2020 2020 2020 2020 2020 2062 6174  .            bat
+00028060: 6368 5f73 697a 653d 746f 7263 682e 5369  ch_size=torch.Si
+00028070: 7a65 285b 3230 305d 292c 0d0a 2020 2020  ze([200]),..    
+00028080: 2020 2020 2020 2020 6465 7669 6365 3d63          device=c
+00028090: 7075 2c0d 0a20 2020 2020 2020 2020 2020  pu,..           
+000280a0: 2069 735f 7368 6172 6564 3d46 616c 7365   is_shared=False
+000280b0: 290d 0a0d 0a20 2020 2055 7369 6e67 2074  )....    Using t
+000280c0: 6869 7320 7472 616e 7366 6f72 6d20 6173  his transform as
+000280d0: 2070 6172 7420 6f66 2061 6e20 656e 7620   part of an env 
+000280e0: 7769 6c6c 2072 6169 7365 2061 6e20 6578  will raise an ex
+000280f0: 6365 7074 696f 6e0d 0a0d 0a20 2020 2045  ception....    E
+00028100: 7861 6d70 6c65 733a 0d0a 2020 2020 2020  xamples:..      
+00028110: 2020 3e3e 3e20 7420 3d20 5265 7761 7264    >>> t = Reward
+00028120: 3247 6f54 7261 6e73 666f 726d 2867 616d  2GoTransform(gam
+00028130: 6d61 3d30 2e39 3929 0d0a 2020 2020 2020  ma=0.99)..      
+00028140: 2020 3e3e 3e20 5472 616e 7366 6f72 6d65    >>> Transforme
+00028150: 6445 6e76 2847 796d 456e 7628 2250 656e  dEnv(GymEnv("Pen
+00028160: 6475 6c75 6d2d 7631 2229 2c20 7429 2020  dulum-v1"), t)  
+00028170: 2320 6372 6173 6865 730d 0a0d 0a20 2020  # crashes....   
+00028180: 2022 2222 0d0a 0d0a 2020 2020 454e 565f   """....    ENV_
+00028190: 4552 5220 3d20 280d 0a20 2020 2020 2020  ERR = (..       
+000281a0: 2022 5468 6520 5265 7761 7264 3247 6f54   "The Reward2GoT
+000281b0: 7261 6e73 666f 726d 2069 7320 6f6e 6c79  ransform is only
+000281c0: 2061 6e20 696e 7665 7273 6520 7472 616e   an inverse tran
+000281d0: 7366 6f72 6d20 616e 6420 6361 6e20 220d  sform and can ".
+000281e0: 0a20 2020 2020 2020 2022 6f6e 6c79 2062  .        "only b
+000281f0: 6520 6170 706c 6965 6420 746f 2074 6865  e applied to the
+00028200: 2072 6570 6c61 7920 6275 6666 6572 2061   replay buffer a
+00028210: 6e64 206e 6f74 2074 6f20 7468 6520 636f  nd not to the co
+00028220: 6c6c 6563 746f 7220 6f72 2074 6865 2065  llector or the e
+00028230: 6e76 6972 6f6e 6d65 6e74 2e22 0d0a 2020  nvironment."..  
+00028240: 2020 290d 0a0d 0a20 2020 2064 6566 205f    )....    def _
+00028250: 5f69 6e69 745f 5f28 0d0a 2020 2020 2020  _init__(..      
+00028260: 2020 7365 6c66 2c0d 0a20 2020 2020 2020    self,..       
+00028270: 2067 616d 6d61 3a20 4f70 7469 6f6e 616c   gamma: Optional
+00028280: 5b55 6e69 6f6e 5b66 6c6f 6174 2c20 746f  [Union[float, to
+00028290: 7263 682e 5465 6e73 6f72 5d5d 203d 2031  rch.Tensor]] = 1
+000282a0: 2e30 2c0d 0a20 2020 2020 2020 2069 6e5f  .0,..        in_
+000282b0: 6b65 7973 3a20 4f70 7469 6f6e 616c 5b53  keys: Optional[S
+000282c0: 6571 7565 6e63 655b 7374 725d 5d20 3d20  equence[str]] = 
+000282d0: 4e6f 6e65 2c0d 0a20 2020 2020 2020 206f  None,..        o
+000282e0: 7574 5f6b 6579 733a 204f 7074 696f 6e61  ut_keys: Optiona
+000282f0: 6c5b 5365 7175 656e 6365 5b73 7472 5d5d  l[Sequence[str]]
+00028300: 203d 204e 6f6e 652c 0d0a 2020 2020 293a   = None,..    ):
+00028310: 0d0a 2020 2020 2020 2020 6966 2069 6e5f  ..        if in_
+00028320: 6b65 7973 2069 7320 4e6f 6e65 3a0d 0a20  keys is None:.. 
+00028330: 2020 2020 2020 2020 2020 2069 6e5f 6b65             in_ke
+00028340: 7973 203d 205b 2822 6e65 7874 222c 2022  ys = [("next", "
+00028350: 7265 7761 7264 2229 5d0d 0a20 2020 2020  reward")]..     
+00028360: 2020 2069 6620 6f75 745f 6b65 7973 2069     if out_keys i
+00028370: 7320 4e6f 6e65 3a0d 0a20 2020 2020 2020  s None:..       
+00028380: 2020 2020 206f 7574 5f6b 6579 7320 3d20       out_keys = 
+00028390: 6465 6570 636f 7079 2869 6e5f 6b65 7973  deepcopy(in_keys
+000283a0: 290d 0a20 2020 2020 2020 2023 206f 7574  )..        # out
+000283b0: 5f6b 6579 7320 3d20 5b22 7265 7761 7264  _keys = ["reward
+000283c0: 5f74 6f5f 676f 225d 0d0a 2020 2020 2020  _to_go"]..      
+000283d0: 2020 7375 7065 7228 292e 5f5f 696e 6974    super().__init
+000283e0: 5f5f 280d 0a20 2020 2020 2020 2020 2020  __(..           
+000283f0: 2069 6e5f 6b65 7973 3d69 6e5f 6b65 7973   in_keys=in_keys
+00028400: 2c0d 0a20 2020 2020 2020 2020 2020 2069  ,..            i
+00028410: 6e5f 6b65 7973 5f69 6e76 3d69 6e5f 6b65  n_keys_inv=in_ke
+00028420: 7973 2c0d 0a20 2020 2020 2020 2020 2020  ys,..           
+00028430: 206f 7574 5f6b 6579 735f 696e 763d 6f75   out_keys_inv=ou
+00028440: 745f 6b65 7973 2c0d 0a20 2020 2020 2020  t_keys,..       
+00028450: 2029 0d0a 0d0a 2020 2020 2020 2020 6966   )....        if
+00028460: 206e 6f74 2069 7369 6e73 7461 6e63 6528   not isinstance(
+00028470: 6761 6d6d 612c 2074 6f72 6368 2e54 656e  gamma, torch.Ten
+00028480: 736f 7229 3a0d 0a20 2020 2020 2020 2020  sor):..         
+00028490: 2020 2067 616d 6d61 203d 2074 6f72 6368     gamma = torch
+000284a0: 2e74 656e 736f 7228 6761 6d6d 6129 0d0a  .tensor(gamma)..
+000284b0: 0d0a 2020 2020 2020 2020 7365 6c66 2e72  ..        self.r
+000284c0: 6567 6973 7465 725f 6275 6666 6572 2822  egister_buffer("
+000284d0: 6761 6d6d 6122 2c20 6761 6d6d 6129 0d0a  gamma", gamma)..
+000284e0: 0d0a 2020 2020 6465 6620 5f69 6e76 5f63  ..    def _inv_c
+000284f0: 616c 6c28 7365 6c66 2c20 7465 6e73 6f72  all(self, tensor
+00028500: 6469 6374 3a20 5465 6e73 6f72 4469 6374  dict: TensorDict
+00028510: 4261 7365 2920 2d3e 2054 656e 736f 7244  Base) -> TensorD
+00028520: 6963 7442 6173 653a 0d0a 2020 2020 2020  ictBase:..      
+00028530: 2020 646f 6e65 203d 2074 656e 736f 7264    done = tensord
+00028540: 6963 742e 6765 7428 2822 6e65 7874 222c  ict.get(("next",
+00028550: 2022 646f 6e65 2229 290d 0a20 2020 2020   "done"))..     
+00028560: 2020 2074 7275 6e63 6174 6564 203d 2074     truncated = t
+00028570: 656e 736f 7264 6963 742e 6765 7428 2822  ensordict.get(("
+00028580: 6e65 7874 222c 2022 7472 756e 6361 7465  next", "truncate
+00028590: 6422 292c 204e 6f6e 6529 0d0a 2020 2020  d"), None)..    
+000285a0: 2020 2020 6966 2074 7275 6e63 6174 6564      if truncated
+000285b0: 2069 7320 6e6f 7420 4e6f 6e65 3a0d 0a20   is not None:.. 
+000285c0: 2020 2020 2020 2020 2020 2064 6f6e 655f             done_
+000285d0: 6f72 5f74 7275 6e63 6174 6564 203d 2064  or_truncated = d
+000285e0: 6f6e 6520 7c20 7472 756e 6361 7465 640d  one | truncated.
+000285f0: 0a20 2020 2020 2020 2065 6c73 653a 0d0a  .        else:..
+00028600: 2020 2020 2020 2020 2020 2020 646f 6e65              done
+00028610: 5f6f 725f 7472 756e 6361 7465 6420 3d20  _or_truncated = 
+00028620: 646f 6e65 0d0a 2020 2020 2020 2020 6966  done..        if
+00028630: 206e 6f74 2064 6f6e 655f 6f72 5f74 7275   not done_or_tru
+00028640: 6e63 6174 6564 2e61 6e79 282d 3229 2e61  ncated.any(-2).a
+00028650: 6c6c 2829 3a0d 0a20 2020 2020 2020 2020  ll():..         
+00028660: 2020 2072 6169 7365 2052 756e 7469 6d65     raise Runtime
+00028670: 4572 726f 7228 0d0a 2020 2020 2020 2020  Error(..        
+00028680: 2020 2020 2020 2020 224e 6f20 6570 6973          "No epis
+00028690: 6f64 6520 656e 6473 2066 6f75 6e64 2074  ode ends found t
+000286a0: 6f20 6361 6c63 756c 6174 6520 7468 6520  o calculate the 
+000286b0: 7265 7761 7264 2074 6f20 676f 2e20 4d61  reward to go. Ma
+000286c0: 6b65 2073 7572 6520 7468 6174 2074 6865  ke sure that the
+000286d0: 206e 756d 6265 7220 6f66 2066 7261 6d65   number of frame
+000286e0: 735f 7065 725f 6261 7463 6820 6973 206c  s_per_batch is l
+000286f0: 6172 6765 7220 7468 616e 206e 756d 6265  arger than numbe
+00028700: 7220 6f66 2073 7465 7073 2070 6572 2065  r of steps per e
+00028710: 7069 736f 6465 2e22 0d0a 2020 2020 2020  pisode."..      
+00028720: 2020 2020 2020 290d 0a20 2020 2020 2020        )..       
+00028730: 2066 6f75 6e64 203d 2046 616c 7365 0d0a   found = False..
+00028740: 2020 2020 2020 2020 666f 7220 696e 5f6b          for in_k
+00028750: 6579 2c20 6f75 745f 6b65 7920 696e 207a  ey, out_key in z
+00028760: 6970 2873 656c 662e 696e 5f6b 6579 735f  ip(self.in_keys_
+00028770: 696e 762c 2073 656c 662e 6f75 745f 6b65  inv, self.out_ke
+00028780: 7973 5f69 6e76 293a 0d0a 2020 2020 2020  ys_inv):..      
+00028790: 2020 2020 2020 6966 2069 6e5f 6b65 7920        if in_key 
+000287a0: 696e 2074 656e 736f 7264 6963 742e 6b65  in tensordict.ke
+000287b0: 7973 2869 6e63 6c75 6465 5f6e 6573 7465  ys(include_neste
+000287c0: 643d 5472 7565 293a 0d0a 2020 2020 2020  d=True):..      
+000287d0: 2020 2020 2020 2020 2020 666f 756e 6420            found 
+000287e0: 3d20 5472 7565 0d0a 2020 2020 2020 2020  = True..        
+000287f0: 2020 2020 2020 2020 6974 656d 203d 2073          item = s
+00028800: 656c 662e 5f69 6e76 5f61 7070 6c79 5f74  elf._inv_apply_t
+00028810: 7261 6e73 666f 726d 280d 0a20 2020 2020  ransform(..     
+00028820: 2020 2020 2020 2020 2020 2020 2020 2074                 t
+00028830: 656e 736f 7264 6963 742e 6765 7428 696e  ensordict.get(in
+00028840: 5f6b 6579 292c 2064 6f6e 655f 6f72 5f74  _key), done_or_t
+00028850: 7275 6e63 6174 6564 0d0a 2020 2020 2020  runcated..      
+00028860: 2020 2020 2020 2020 2020 290d 0a20 2020            )..   
+00028870: 2020 2020 2020 2020 2020 2020 2074 656e               ten
+00028880: 736f 7264 6963 742e 7365 7428 0d0a 2020  sordict.set(..  
+00028890: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000288a0: 2020 6f75 745f 6b65 792c 0d0a 2020 2020    out_key,..    
+000288b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000288c0: 6974 656d 2c0d 0a20 2020 2020 2020 2020  item,..         
+000288d0: 2020 2020 2020 2029 0d0a 2020 2020 2020         )..      
+000288e0: 2020 6966 206e 6f74 2066 6f75 6e64 3a0d    if not found:.
+000288f0: 0a20 2020 2020 2020 2020 2020 2072 6169  .            rai
+00028900: 7365 204b 6579 4572 726f 7228 6622 436f  se KeyError(f"Co
+00028910: 756c 6420 6e6f 7420 6669 6e64 2061 6e79  uld not find any
+00028920: 206f 6620 7468 6520 696e 7075 7420 6b65   of the input ke
+00028930: 7973 207b 7365 6c66 2e69 6e5f 6b65 7973  ys {self.in_keys
+00028940: 7d2e 2229 0d0a 2020 2020 2020 2020 7265  }.")..        re
+00028950: 7475 726e 2074 656e 736f 7264 6963 740d  turn tensordict.
+00028960: 0a0d 0a20 2020 2064 6566 2066 6f72 7761  ...    def forwa
+00028970: 7264 2873 656c 662c 2074 656e 736f 7264  rd(self, tensord
+00028980: 6963 743a 2054 656e 736f 7244 6963 7442  ict: TensorDictB
+00028990: 6173 6529 202d 3e20 5465 6e73 6f72 4469  ase) -> TensorDi
+000289a0: 6374 4261 7365 3a0d 0a20 2020 2020 2020  ctBase:..       
+000289b0: 2072 6574 7572 6e20 7465 6e73 6f72 6469   return tensordi
+000289c0: 6374 0d0a 0d0a 2020 2020 6465 6620 5f63  ct....    def _c
+000289d0: 616c 6c28 7365 6c66 2c20 7465 6e73 6f72  all(self, tensor
+000289e0: 6469 6374 3a20 5465 6e73 6f72 4469 6374  dict: TensorDict
+000289f0: 4261 7365 2920 2d3e 2054 656e 736f 7244  Base) -> TensorD
+00028a00: 6963 7442 6173 653a 0d0a 2020 2020 2020  ictBase:..      
+00028a10: 2020 7261 6973 6520 5661 6c75 6545 7272    raise ValueErr
+00028a20: 6f72 2873 656c 662e 454e 565f 4552 5229  or(self.ENV_ERR)
+00028a30: 0d0a 0d0a 2020 2020 6465 6620 5f69 6e76  ....    def _inv
+00028a40: 5f61 7070 6c79 5f74 7261 6e73 666f 726d  _apply_transform
+00028a50: 280d 0a20 2020 2020 2020 2073 656c 662c  (..        self,
+00028a60: 2072 6577 6172 643a 2074 6f72 6368 2e54   reward: torch.T
+00028a70: 656e 736f 722c 2064 6f6e 653a 2074 6f72  ensor, done: tor
+00028a80: 6368 2e54 656e 736f 720d 0a20 2020 2029  ch.Tensor..    )
+00028a90: 202d 3e20 746f 7263 682e 5465 6e73 6f72   -> torch.Tensor
+00028aa0: 3a0d 0a20 2020 2020 2020 2072 6574 7572  :..        retur
+00028ab0: 6e20 7265 7761 7264 3267 6f28 7265 7761  n reward2go(rewa
+00028ac0: 7264 2c20 646f 6e65 2c20 7365 6c66 2e67  rd, done, self.g
+00028ad0: 616d 6d61 290d 0a0d 0a20 2020 2064 6566  amma)....    def
+00028ae0: 2073 6574 5f63 6f6e 7461 696e 6572 2873   set_container(s
+00028af0: 656c 662c 2063 6f6e 7461 696e 6572 293a  elf, container):
+00028b00: 0d0a 2020 2020 2020 2020 6966 2069 7369  ..        if isi
+00028b10: 6e73 7461 6e63 6528 636f 6e74 6169 6e65  nstance(containe
+00028b20: 722c 2045 6e76 4261 7365 2920 6f72 2063  r, EnvBase) or c
+00028b30: 6f6e 7461 696e 6572 2e70 6172 656e 7420  ontainer.parent 
+00028b40: 6973 206e 6f74 204e 6f6e 653a 0d0a 2020  is not None:..  
+00028b50: 2020 2020 2020 2020 2020 7261 6973 6520            raise 
+00028b60: 5661 6c75 6545 7272 6f72 2873 656c 662e  ValueError(self.
+00028b70: 454e 565f 4552 5229 0d0a                 ENV_ERR)..
```

## torchrl/envs/transforms/vip.py

```diff
@@ -177,15 +177,15 @@
              "vip_vec" is assumed.
         size (int, optional): Size of the image to feed to resnet.
             Defaults to 244.
         stack_images (bool, optional): if False, the images given in the :obj:`in_keys`
              argument will be treaded separetely and each will be given a single,
              separated entry in the output tensordict. Defaults to :obj:`True`.
         download (bool, torchvision Weights config or corresponding string):
-            if True, the weights will be downloaded using the torch.hub download
+            if ``True``, the weights will be downloaded using the torch.hub download
             API (i.e. weights will be cached for future use).
             These weights are the original weights from the VIP publication.
             If the torchvision weights are needed, there are two ways they can be
             obtained: :obj:`download=ResNet50_Weights.IMAGENET1K_V1` or :obj:`download="IMAGENET1K_V1"`
             where :obj:`ResNet50_Weights` can be imported via :obj:`from torchvision.models import resnet50, ResNet50_Weights`.
             Defaults to False.
         download_path (str, optional): path where to download the models.
```

## torchrl/modules/__init__.py

```diff
@@ -3,14 +3,15 @@
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
 
 from .distributions import (
     Delta,
     distributions_maps,
     IndependentNormal,
+    MaskedCategorical,
     NormalParamWrapper,
     OneHotCategorical,
     TanhDelta,
     TanhNormal,
     TruncatedNormal,
 )
 from .models import (
@@ -37,19 +38,24 @@
 from .tensordict_module import (
     Actor,
     ActorCriticOperator,
     ActorCriticWrapper,
     ActorValueOperator,
     AdditiveGaussianWrapper,
     DistributionalQValueActor,
+    DistributionalQValueHook,
+    DistributionalQValueModule,
     EGreedyWrapper,
+    LSTMModule,
     OrnsteinUhlenbeckProcessWrapper,
     ProbabilisticActor,
     QValueActor,
+    QValueHook,
+    QValueModule,
     SafeModule,
     SafeProbabilisticModule,
-    SafeProbabilisticSequential,
+    SafeProbabilisticTensorDictSequential,
     SafeSequential,
     ValueOperator,
     WorldModelWrapper,
 )
 from .planners import CEMPlanner, MPCPlannerBase, MPPIPlanner  # usort:skip
```

## torchrl/modules/distributions/__init__.py

```diff
@@ -8,13 +8,13 @@
     Delta,
     IndependentNormal,
     NormalParamWrapper,
     TanhDelta,
     TanhNormal,
     TruncatedNormal,
 )
-from .discrete import __all__ as _all_discrete, OneHotCategorical
+from .discrete import __all__ as _all_discrete, MaskedCategorical, OneHotCategorical
 
 distributions_maps = {
     distribution_class.lower(): eval(distribution_class)
     for distribution_class in _all_continuous + _all_discrete
 }
```

## torchrl/modules/distributions/continuous.py

```diff
@@ -11,15 +11,18 @@
 from torch import distributions as D, nn
 from torch.distributions import constraints
 
 from torchrl._torchrl import safetanh
 from torchrl.modules.distributions.truncated_normal import (
     TruncatedNormal as _TruncatedNormal,
 )
-from torchrl.modules.distributions.utils import _cast_device
+from torchrl.modules.distributions.utils import (
+    _cast_device,
+    FasterTransformedDistribution,
+)
 from torchrl.modules.utils import mappings
 
 __all__ = [
     "NormalParamWrapper",
     "TanhNormal",
     "Delta",
     "TanhDelta",
@@ -50,15 +53,15 @@
         upscale (torch.Tensor or number, optional): 'a' scaling factor in the formula:
 
             .. math::
                 loc = tanh(loc / upscale) * upscale.
 
             Default is 5.0
 
-        tanh_loc (bool, optional): if True, the above formula is used for the location scaling, otherwise the raw value
+        tanh_loc (bool, optional): if ``True``, the above formula is used for the location scaling, otherwise the raw value
             is kept.
             Default is :obj:`True`;
     """
 
     num_params: int = 2
 
     def __init__(
@@ -176,15 +179,15 @@
             .. math::
                 loc = tanh(loc / upscale) * upscale.
 
             Default is 5.0
 
         min (torch.Tensor or number, optional): minimum value of the distribution. Default = -1.0;
         max (torch.Tensor or number, optional): maximum value of the distribution. Default = 1.0;
-        tanh_loc (bool, optional): if True, the above formula is used for the location scaling, otherwise the raw value
+        tanh_loc (bool, optional): if ``True``, the above formula is used for the location scaling, otherwise the raw value
             is kept.
             Default is :obj:`True`;
     """
 
     num_params: int = 2
 
     arg_constraints = {
@@ -269,15 +272,15 @@
         b = self.base_dist._non_std_b - self.base_dist._dtype_min_gt_0
         b = b.expand_as(value)
         value = torch.min(torch.stack([value, b], -1), dim=-1)[0]
         value = torch.max(torch.stack([value, a], -1), dim=-1)[0]
         return super().log_prob(value, **kwargs)
 
 
-class TanhNormal(D.TransformedDistribution):
+class TanhNormal(FasterTransformedDistribution):
     """Implements a TanhNormal distribution with location scaling.
 
     Location scaling prevents the location to be "too far" from 0 when a TanhTransform is applied, which ultimately
     leads to numerically unstable samples and poor gradient computation (e.g. gradient explosion).
     In practice, the location is computed according to
 
         .. math::
@@ -294,15 +297,15 @@
             .. math::
                 loc = tanh(loc / upscale) * upscale.
 
         min (torch.Tensor or number, optional): minimum value of the distribution. Default is -1.0;
         max (torch.Tensor or number, optional): maximum value of the distribution. Default is 1.0;
         event_dims (int, optional): number of dimensions describing the action.
             Default is 1;
-        tanh_loc (bool, optional): if True, the above formula is used for the location scaling, otherwise the raw
+        tanh_loc (bool, optional): if ``True``, the above formula is used for the location scaling, otherwise the raw
             value is kept. Default is :obj:`True`;
     """
 
     arg_constraints = {
         "loc": constraints.real,
         "scale": constraints.greater_than(1e-6),
     }
@@ -481,15 +484,15 @@
         return self.param
 
     @property
     def mean(self) -> torch.Tensor:
         return self.param
 
 
-class TanhDelta(D.TransformedDistribution):
+class TanhDelta(FasterTransformedDistribution):
     """Implements a Tanh transformed_in Delta distribution.
 
     Args:
         param (torch.Tensor): parameter of the delta distribution;
                 min (torch.Tensor or number): minimum value of the distribution. Default is -1.0;
         min (torch.Tensor or number, optional): minimum value of the distribution. Default is 1.0;
         max (torch.Tensor or number, optional): maximum value of the distribution. Default is 1.0;
```

## torchrl/modules/distributions/discrete.py

```diff
@@ -2,18 +2,19 @@
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
 
 from typing import Optional, Sequence, Union
 
 import torch
-from torch import distributions as D
+import torch.distributions as D
 
 __all__ = [
     "OneHotCategorical",
+    "MaskedCategorical",
 ]
 
 
 def _treat_categorical_params(
     params: Optional[torch.Tensor] = None,
 ) -> Optional[torch.Tensor]:
     if params is None:
@@ -33,23 +34,36 @@
 
 class OneHotCategorical(D.Categorical):
     """One-hot categorical distribution.
 
     This class behaves excacly as torch.distributions.Categorical except that it reads and produces one-hot encodings
     of the discrete tensors.
 
+    Args:
+        logits (torch.Tensor): event log probabilities (unnormalized)
+        probs (torch.Tensor): event probabilities
+
+    Examples:
+        >>> torch.manual_seed(0)
+        >>> logits = torch.randn(4)
+        >>> dist = OneHotCategorical(logits=logits)
+        >>> print(dist.rsample((3,)))
+        tensor([[1., 0., 0., 0.],
+                [0., 0., 0., 1.],
+                [1., 0., 0., 0.]])
+
     """
 
     num_params: int = 1
 
     def __init__(
         self,
         logits: Optional[torch.Tensor] = None,
         probs: Optional[torch.Tensor] = None,
-        **kwargs
+        **kwargs,
     ) -> None:
         logits = _treat_categorical_params(logits)
         probs = _treat_categorical_params(probs)
         super().__init__(probs=probs, logits=logits, **kwargs)
 
     def log_prob(self, value: torch.Tensor) -> torch.Tensor:
         return super().log_prob(value.argmax(dim=-1))
@@ -69,13 +83,167 @@
         out = super().sample(sample_shape=sample_shape)
         out = torch.nn.functional.one_hot(out, self.logits.shape[-1]).to(torch.long)
         return out
 
     def rsample(self, sample_shape: Union[torch.Size, Sequence] = None) -> torch.Tensor:
         if sample_shape is None:
             sample_shape = torch.Size([])
+        if hasattr(self, "logits") and self.logits is not None:
+            logits = self.logits
+            probs = None
+        else:
+            logits = None
+            probs = self.probs
         d = D.relaxed_categorical.RelaxedOneHotCategorical(
-            1.0, probs=self.probs, logits=self.logits
+            1.0, probs=probs, logits=logits
         )
         out = d.rsample(sample_shape)
         out.data.copy_((out == out.max(-1)[0].unsqueeze(-1)).to(out.dtype))
         return out
+
+
+class MaskedCategorical(D.Categorical):
+    """MaskedCategorical distribution.
+
+    Reference:
+    https://www.tensorflow.org/agents/api_docs/python/tf_agents/distributions/masked/MaskedCategorical
+
+    Args:
+        logits (torch.Tensor): event log probabilities (unnormalized)
+        probs (torch.Tensor): event probabilities. If provided, the probabilities
+            corresponding to to masked items will be zeroed and the probability
+            re-normalized along its last dimension.
+        mask (torch.Tensor): A boolean mask of the same shape as ``logits``/``probs``
+            where ``False`` entries are the ones to be masked. Alternatively,
+            if ``sparse_mask`` is True, it represents the list of valid indices
+            in the distribution. Exclusive with ``indices``.
+        indices (torch.Tensor): A dense index tensor representing which actions
+            must be taken into account. Exclusive with ``mask``.
+        neg_inf (float, optional): The log-probability value allocated to
+            invalid (out-of-mask) indices. Defaults to -inf.
+        padding_value: The padding value in the then mask tensor when
+            sparse_mask == True, the padding_value will be ignored.
+
+        >>> torch.manual_seed(0)
+        >>> logits = torch.randn(4) / 100  # almost equal probabilities
+        >>> mask = torch.tensor([True, False, True, True])
+        >>> dist = MaskedCategorical(logits=logits, mask=mask)
+        >>> sample = dist.sample((10,))
+        >>> print(sample)  # no `1` in the sample
+        tensor([2, 3, 0, 2, 2, 0, 2, 0, 2, 2])
+        >>> print(dist.log_prob(sample))
+        tensor([-1.1203, -1.0928, -1.0831, -1.1203, -1.1203, -1.0831, -1.1203, -1.0831,
+                -1.1203, -1.1203])
+        >>> print(dist.log_prob(torch.ones_like(sample)))
+        tensor([-inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf])
+        >>> # with probabilities
+        >>> prob = torch.ones(10)
+        >>> prob = prob / prob.sum()
+        >>> mask = torch.tensor([False] + 9 * [True])  # first outcome is masked
+        >>> dist = MaskedCategorical(probs=prob, mask=mask)
+        >>> print(dist.log_prob(torch.arange(10)))
+        tensor([   -inf, -2.1972, -2.1972, -2.1972, -2.1972, -2.1972, -2.1972, -2.1972,
+                -2.1972, -2.1972])
+    """
+
+    def __init__(
+        self,
+        logits: Optional[torch.Tensor] = None,
+        probs: Optional[torch.Tensor] = None,
+        mask: torch.Tensor = None,
+        indices: torch.Tensor = None,
+        neg_inf: float = float("-inf"),
+        padding_value: Optional[int] = None,
+    ) -> None:
+        if not ((mask is None) ^ (indices is None)):
+            raise ValueError(
+                f"A ``mask`` or some ``indices`` must be provided for {type(self)}, but not both."
+            )
+        if mask is None:
+            mask = indices
+            sparse_mask = True
+        else:
+            sparse_mask = False
+
+        if probs is not None:
+            if logits is not None:
+                raise ValueError(
+                    "Either `probs` or `logits` must be specified, but not both."
+                )
+            # unnormalized logits
+            probs = probs.clone()
+            probs[~mask] = 0
+            probs = probs / probs.sum(-1, keepdim=True)
+            logits = probs.log()
+        logits = self._mask_logits(
+            logits,
+            mask,
+            neg_inf=neg_inf,
+            sparse_mask=sparse_mask,
+            padding_value=padding_value,
+        )
+        self.neg_inf = neg_inf
+        self._mask = mask
+        self._sparse_mask = sparse_mask
+        self._padding_value = padding_value
+        super().__init__(logits=logits)
+
+    def sample(
+        self, sample_shape: Optional[Union[torch.Size, Sequence[int]]] = None
+    ) -> torch.Tensor:
+        if sample_shape is None:
+            sample_shape = torch.Size()
+
+        ret = super().sample(sample_shape)
+        if not self._sparse_mask:
+            return ret
+
+        size = ret.size()
+        # Python 3.7 doesn't support math.prod
+        # outer_dim = prod(sample_shape)
+        # inner_dim = prod(self._mask.size()[:-1])
+        outer_dim = torch.empty(sample_shape, device="meta").numel()
+        inner_dim = self._mask.numel() // self._mask.size(-1)
+        idx_3d = self._mask.expand(outer_dim, inner_dim, -1)
+        ret = idx_3d.gather(dim=-1, index=ret.view(outer_dim, inner_dim, 1))
+        return ret.view(size)
+
+    # # # TODO: Improve performance here.
+    def log_prob(self, value: torch.Tensor) -> torch.Tensor:
+        if not self._sparse_mask:
+            return super().log_prob(value)
+
+        idx_3d = self._mask.view(1, -1, self._num_events)
+        val_3d = value.view(-1, idx_3d.size(1), 1)
+        mask = idx_3d == val_3d
+        idx = mask.int().argmax(dim=-1, keepdim=True)
+        ret = super().log_prob(idx.view_as(value))
+        # Fill masked values with neg_inf.
+        ret = ret.view_as(val_3d)
+        ret = ret.masked_fill(
+            torch.logical_not(mask.any(dim=-1, keepdim=True)), self.neg_inf
+        )
+        return ret.resize_as(value)
+
+    @staticmethod
+    def _mask_logits(
+        logits: torch.Tensor,
+        mask: Optional[torch.Tensor] = None,
+        neg_inf: float = float("-inf"),
+        sparse_mask: bool = False,
+        padding_value: Optional[int] = None,
+    ) -> torch.Tensor:
+        if mask is None:
+            return logits
+
+        if not sparse_mask:
+            return logits.masked_fill(~mask, neg_inf)
+
+        if padding_value is not None:
+            padding_mask = mask == padding_value
+            if padding_value != 0:
+                # Avoid invalid indices in mask.
+                mask = mask.masked_fill(padding_mask, 0)
+        logits = logits.gather(dim=-1, index=mask)
+        if padding_value is not None:
+            logits.masked_fill_(padding_mask, neg_inf)
+        return logits
```

## torchrl/modules/distributions/utils.py

```diff
@@ -3,14 +3,15 @@
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
 
 from typing import Union
 
 import torch
 from torch import distributions as d
+from torch.distributions import Independent, Transform, TransformedDistribution
 
 
 def _cast_device(elt: Union[torch.Tensor, float], device) -> Union[torch.Tensor, float]:
     if isinstance(elt, torch.Tensor):
         return elt.to(device)
     return elt
 
@@ -27,7 +28,64 @@
             if isinstance(value, torch.Tensor):
                 setattr(transform, attribute, value.to(device))
         return transform
     else:
         raise TypeError(
             f"Cannot perform device casting for transform of type {type(transform)}"
         )
+
+
+class FasterTransformedDistribution(TransformedDistribution):
+    """A faster implementation of TransformedDistribution."""
+
+    __doc__ = __doc__ + TransformedDistribution.__doc__
+
+    def __init__(self, base_distribution, transforms, validate_args=None):
+        if isinstance(transforms, Transform):
+            self.transforms = [
+                transforms,
+            ]
+        elif isinstance(transforms, list):
+            raise ValueError("Mae a ComposeTransform first.")
+        else:
+            raise ValueError(
+                "transforms must be a Transform or list, but was {}".format(transforms)
+            )
+        transform = self.transforms[0]
+        # Reshape base_distribution according to transforms.
+        base_shape = base_distribution.batch_shape + base_distribution.event_shape
+        base_event_dim = len(base_distribution.event_shape)
+        # transform = ComposeTransform(self.transforms)
+        # if len(base_shape) < transform.domain.event_dim:
+        #     raise ValueError("base_distribution needs to have shape with size at least {}, but got {}."
+        #                      .format(transform.domain.event_dim, base_shape))
+        transform_codomain_event_dim = transform.codomain.event_dim
+        transform_domain_event_dim = transform.domain.event_dim
+
+        forward_shape = transform.forward_shape(base_shape)
+        expanded_base_shape = transform.inverse_shape(forward_shape)
+        if base_shape != expanded_base_shape:
+            base_batch_shape = expanded_base_shape[
+                : len(expanded_base_shape) - base_event_dim
+            ]
+            base_distribution = base_distribution.expand(base_batch_shape)
+        reinterpreted_batch_ndims = transform_domain_event_dim - base_event_dim
+        if reinterpreted_batch_ndims > 0:
+            base_distribution = Independent(
+                base_distribution, reinterpreted_batch_ndims
+            )
+        self.base_dist = base_distribution
+
+        # Compute shapes.
+        transform_change_in_event_dim = (
+            transform_codomain_event_dim - transform_domain_event_dim
+        )
+        event_dim = max(
+            transform_codomain_event_dim,  # the transform is coupled
+            base_event_dim + transform_change_in_event_dim,  # the base dist is coupled
+        )
+        cut = len(forward_shape) - event_dim
+        batch_shape = forward_shape[:cut]
+        event_shape = forward_shape[cut:]
+        super(TransformedDistribution, self).__init__(
+            batch_shape, event_shape, validate_args=validate_args
+        )
```

## torchrl/modules/models/exploration.py

```diff
@@ -9,15 +9,15 @@
 import torch
 from torch import distributions as d, nn
 from torch.nn.modules.lazy import LazyModuleMixin
 from torch.nn.parameter import UninitializedBuffer, UninitializedParameter
 
 from torchrl._utils import prod
 from torchrl.data.utils import DEVICE_TYPING, DEVICE_TYPING_ARGS
-from torchrl.envs.utils import exploration_mode
+from torchrl.envs.utils import exploration_type, ExplorationType
 from torchrl.modules.distributions.utils import _cast_transform_device
 from torchrl.modules.utils import inv_softplus
 
 
 class NoisyLinear(nn.Linear):
     """Noisy Linear Layer.
 
@@ -28,15 +28,15 @@
     with gradient descent along with any other remaining network weights. Factorized Gaussian
     noise is the type of noise usually employed.
 
 
     Args:
         in_features (int): input features dimension
         out_features (int): out features dimension
-        bias (bool): if True, a bias term will be added to the matrix multiplication: Ax + b.
+        bias (bool): if ``True``, a bias term will be added to the matrix multiplication: Ax + b.
             default: True
         device (DEVICE_TYPING, optional): device of the layer.
             default: "cpu"
         dtype (torch.dtype, optional): dtype of the parameters.
             default: None
         std_init (scalar): initial value of the Gaussian standard deviation before optimization.
             default: 1.0
@@ -150,15 +150,15 @@
     This class makes the Noisy Linear layer lazy, in that the in_feature argument does not need to be passed at
     initialization (but is inferred after the first call to the layer).
 
     For more context on noisy layers, see the NoisyLinear class.
 
     Args:
         out_features (int): out features dimension
-        bias (bool): if True, a bias term will be added to the matrix multiplication: Ax + b.
+        bias (bool): if ``True``, a bias term will be added to the matrix multiplication: Ax + b.
             default: True
         device (DEVICE_TYPING, optional): device of the layer.
         dtype (torch.dtype, optional): dtype of the parameters.
             default: None
         std_init (scalar): initial value of the Gaussian standard deviation before optimization.
             default: 1.0
 
@@ -260,45 +260,46 @@
         scale_max (float, optional): max value of the scale.
         transform (torch.distribution.Transform, optional): a transform to apply
             to the sampled action.
         device (DEVICE_TYPING, optional): device to create the model on.
 
     Examples:
         >>> from tensordict import TensorDict
-        >>> from torchrl.modules import SafeModule, SafeSequential, ProbabilisticActor, TanhNormal
+        >>> from torchrl.modules import ProbabilisticActor, TanhNormal
+        >>> from tensordict.nn import TensorDictModule, ProbabilisticTensorDictSequential
         >>> batch, state_dim, action_dim = 3, 7, 5
         >>> model = nn.Linear(state_dim, action_dim)
-        >>> deterministic_policy = SafeModule(model, in_keys=["obs"], out_keys=["action"])
-        >>> stochatstic_part = SafeModule(
+        >>> deterministic_policy = TensorDictModule(model, in_keys=["obs"], out_keys=["action"])
+        >>> stochastic_part = TensorDictModule(
         ...     gSDEModule(action_dim, state_dim),
         ...     in_keys=["action", "obs", "_eps_gSDE"],
         ...     out_keys=["loc", "scale", "action", "_eps_gSDE"])
-        >>> stochatstic_part = ProbabilisticActor(stochatstic_part,
-        ...      dist_in_keys=["loc", "scale"],
+        >>> stochastic_part = ProbabilisticActor(stochastic_part,
+        ...      in_keys=["loc", "scale"],
         ...      distribution_class=TanhNormal)
-        >>> stochatstic_policy = SafeSequential(deterministic_policy, stochatstic_part)
+        >>> stochastic_policy = ProbabilisticTensorDictSequential(deterministic_policy, *stochastic_part)
         >>> tensordict = TensorDict({'obs': torch.randn(state_dim), '_epx_gSDE': torch.zeros(1)}, [])
-        >>> _ = stochatstic_policy(tensordict)
+        >>> _ = stochastic_policy(tensordict)
         >>> print(tensordict)
         TensorDict(
             fields={
-                obs: Tensor(torch.Size([7]), dtype=torch.float32),
-                _epx_gSDE: Tensor(torch.Size([1]), dtype=torch.float32),
-                action: Tensor(torch.Size([5]), dtype=torch.float32),
-                loc: Tensor(torch.Size([5]), dtype=torch.float32),
-                scale: Tensor(torch.Size([5]), dtype=torch.float32),
-                _eps_gSDE: Tensor(torch.Size([5, 7]), dtype=torch.float32)},
+                _eps_gSDE: Tensor(shape=torch.Size([5, 7]), device=cpu, dtype=torch.float32, is_shared=False),
+                _epx_gSDE: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),
+                action: Tensor(shape=torch.Size([5]), device=cpu, dtype=torch.float32, is_shared=False),
+                loc: Tensor(shape=torch.Size([5]), device=cpu, dtype=torch.float32, is_shared=False),
+                obs: Tensor(shape=torch.Size([7]), device=cpu, dtype=torch.float32, is_shared=False),
+                scale: Tensor(shape=torch.Size([5]), device=cpu, dtype=torch.float32, is_shared=False)},
             batch_size=torch.Size([]),
-            device=cpu,
+            device=None,
             is_shared=False)
         >>> action_first_call = tensordict.get("action").clone()
-        >>> dist, *_ = stochatstic_policy.get_dist(tensordict)
+        >>> dist = stochastic_policy.get_dist(tensordict)
         >>> print(dist)
         TanhNormal(loc: torch.Size([5]), scale: torch.Size([5]))
-        >>> _ = stochatstic_policy(tensordict)
+        >>> _ = stochastic_policy(tensordict)
         >>> action_second_call = tensordict.get("action").clone()
         >>> assert (action_second_call == action_first_call).all()  # actions are the same
         >>> assert (action_first_call != dist.base_dist.base_dist.loc).all()  # actions are truly stochastic
 
     """
 
     def __init__(
@@ -347,47 +348,47 @@
             sigma = torch.nn.functional.softplus(self.log_sigma)
             return sigma.clamp_min(self.scale_min)
         else:
             return self._sigma.clamp_min(self.scale_min)
 
     def forward(self, mu, state, _eps_gSDE):
         sigma = self.sigma.clamp_max(self.scale_max)
-        _err_explo = f"gSDE behaviour for exploration mode {exploration_mode()} is not defined. Choose from 'random' or 'mode'."
+        _err_explo = f"gSDE behaviour for exploration mode {exploration_type()} is not defined. Choose from 'random' or 'mode'."
 
         if state.shape[:-1] != mu.shape[:-1]:
             _err_msg = f"mu and state are expected to have matching batch size, got shapes {mu.shape} and {state.shape}"
             raise RuntimeError(_err_msg)
         if _eps_gSDE is not None and (
             _eps_gSDE.shape[: state.ndimension() - 1] != state.shape[:-1]
         ):
             _err_msg = f"noise and state are expected to have matching batch size, got shapes {_eps_gSDE.shape} and {state.shape}"
             raise RuntimeError(_err_msg)
 
-        if _eps_gSDE is None and exploration_mode() == "mode":
+        if _eps_gSDE is None and exploration_type() == ExplorationType.MODE:
             # noise is irrelevant in with no exploration
             _eps_gSDE = torch.zeros(
                 *state.shape[:-1], *sigma.shape, device=sigma.device, dtype=sigma.dtype
             )
-        elif (_eps_gSDE is None and exploration_mode() == "random") or (
+        elif (_eps_gSDE is None and exploration_type() == ExplorationType.RANDOM) or (
             _eps_gSDE is not None
             and _eps_gSDE.numel() == prod(state.shape[:-1])
             and (_eps_gSDE == 0).all()
         ):
             _eps_gSDE = torch.randn(
                 *state.shape[:-1], *sigma.shape, device=sigma.device, dtype=sigma.dtype
             )
         elif _eps_gSDE is None:
             raise RuntimeError(_err_explo)
 
         gSDE_noise = sigma * _eps_gSDE
         eps = (gSDE_noise @ state.unsqueeze(-1)).squeeze(-1)
 
-        if exploration_mode() in ("random",):
+        if exploration_type() in (ExplorationType.RANDOM,):
             action = mu + eps
-        elif exploration_mode() in ("mode",):
+        elif exploration_type() in (ExplorationType.MODE,):
             action = mu
         else:
             raise RuntimeError(_err_explo)
 
         sigma = (sigma * state.unsqueeze(-2)).pow(2).sum(-1).clamp_min(1e-5).sqrt()
         if not torch.isfinite(sigma).all():
             warnings.warn("inf sigma")
```

## torchrl/modules/models/model_based.py

```diff
@@ -2,20 +2,20 @@
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
 
 
 import torch
 from packaging import version
+from tensordict.nn import TensorDictModule
 from torch import nn
 
 from torchrl.envs.utils import step_mdp
 from torchrl.modules.distributions import NormalParamWrapper
 from torchrl.modules.models.models import MLP
-from torchrl.modules.tensordict_module.common import SafeModule
 from torchrl.modules.tensordict_module.sequence import SafeSequential
 
 
 class DreamerActor(nn.Module):
     """Dreamer actor network.
 
     This network is used to predict the action distribution given the
@@ -147,21 +147,21 @@
     states and beliefs.
     The previous posterior is used as the prior for the next time step.
     The forward method returns a stack of all intermediate states and beliefs.
 
     Reference: https://arxiv.org/abs/1811.04551
 
     Args:
-        rssm_prior (SafeModule): Prior network.
-        rssm_posterior (SafeModule): Posterior network.
+        rssm_prior (TensorDictModule): Prior network.
+        rssm_posterior (TensorDictModule): Posterior network.
 
 
     """
 
-    def __init__(self, rssm_prior: SafeModule, rssm_posterior: SafeModule):
+    def __init__(self, rssm_prior: TensorDictModule, rssm_posterior: TensorDictModule):
         super().__init__()
         _module = SafeSequential(rssm_prior, rssm_posterior)
         self.in_keys = _module.in_keys
         self.out_keys = _module.out_keys
         self.rssm_prior = rssm_prior
         self.rssm_posterior = rssm_posterior
```

## torchrl/modules/models/models.py

```diff
@@ -1,16 +1,17 @@
 # Copyright (c) Meta Platforms, Inc. and affiliates.
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
-
+import warnings
 from numbers import Number
 from typing import Dict, List, Optional, Sequence, Tuple, Type, Union
 
 import torch
+from tensordict.nn import dispatch, TensorDictModuleBase
 from torch import nn
 from torch.nn import functional as F
 
 from torchrl._utils import prod
 from torchrl.data.utils import DEVICE_TYPING
 from torchrl.modules.models.utils import (
     _find_depth,
@@ -45,17 +46,19 @@
             the linear layers out_features will match the content of num_cells.
             default: 32;
         activation_class (Type[nn.Module]): activation class to be used.
             default: nn.Tanh
         activation_kwargs (dict, optional): kwargs to be used with the activation class;
         norm_class (Type, optional): normalization class, if any.
         norm_kwargs (dict, optional): kwargs to be used with the normalization layers;
-        bias_last_layer (bool): if True, the last Linear layer will have a bias parameter.
+        dropout (float, optional): dropout probability. Defaults to ``None`` (no
+            dropout);
+        bias_last_layer (bool): if ``True``, the last Linear layer will have a bias parameter.
             default: True;
-        single_bias_last_layer (bool): if True, the last dimension of the bias of the last layer will be a singleton
+        single_bias_last_layer (bool): if ``True``, the last dimension of the bias of the last layer will be a singleton
             dimension.
             default: True;
         layer_class (Type[nn.Module]): class to be used for the linear layers;
         layer_kwargs (dict, optional): kwargs for the linear layers;
         activate_last_layer (bool): whether the MLP output should be activated. This is useful when the MLP output
             is used as the input for another module.
             default: False.
@@ -143,14 +146,15 @@
         out_features: Union[int, Sequence[int]] = None,
         depth: Optional[int] = None,
         num_cells: Optional[Union[Sequence, int]] = None,
         activation_class: Type[nn.Module] = nn.Tanh,
         activation_kwargs: Optional[dict] = None,
         norm_class: Optional[Type[nn.Module]] = None,
         norm_kwargs: Optional[dict] = None,
+        dropout: Optional[float] = None,
         bias_last_layer: bool = True,
         single_bias_last_layer: bool = False,
         layer_class: Type[nn.Module] = nn.Linear,
         layer_kwargs: Optional[dict] = None,
         activate_last_layer: bool = False,
         device: Optional[DEVICE_TYPING] = None,
     ):
@@ -174,14 +178,15 @@
         self._out_features_num = _out_features_num
         self.activation_class = activation_class
         self.activation_kwargs = (
             activation_kwargs if activation_kwargs is not None else {}
         )
         self.norm_class = norm_class
         self.norm_kwargs = norm_kwargs if norm_kwargs is not None else {}
+        self.dropout = dropout
         self.bias_last_layer = bias_last_layer
         self.single_bias_last_layer = single_bias_last_layer
         self.layer_class = layer_class
         self.layer_kwargs = layer_kwargs if layer_kwargs is not None else {}
         self.activate_last_layer = activate_last_layer
         if single_bias_last_layer:
             raise NotImplementedError
@@ -231,23 +236,26 @@
                 layers.append(
                     create_on_device(
                         lazy_version, device, _out, bias=_bias, **self.layer_kwargs
                     )
                 )
 
             if i < self.depth or self.activate_last_layer:
+                if self.dropout is not None:
+                    layers.append(create_on_device(nn.Dropout, device, p=self.dropout))
+                if self.norm_class is not None:
+                    layers.append(
+                        create_on_device(self.norm_class, device, **self.norm_kwargs)
+                    )
                 layers.append(
                     create_on_device(
                         self.activation_class, device, **self.activation_kwargs
                     )
                 )
-                if self.norm_class is not None:
-                    layers.append(
-                        create_on_device(self.norm_class, device, **self.norm_kwargs)
-                    )
+
         return layers
 
     def forward(self, *inputs: Tuple[torch.Tensor]) -> torch.Tensor:
         if len(inputs) > 1:
             inputs = (torch.cat([*inputs], -1),)
 
         out = super().forward(*inputs)
@@ -275,21 +283,21 @@
         strides (int or Sequence[int]): Stride(s) of the conv network. If iterable, the length must match the
             depth, defined by the num_cells or depth arguments.
         activation_class (Type[nn.Module]): activation class to be used.
             default: nn.Tanh
         activation_kwargs (dict, optional): kwargs to be used with the activation class;
         norm_class (Type, optional): normalization class, if any;
         norm_kwargs (dict, optional): kwargs to be used with the normalization layers;
-        bias_last_layer (bool): if True, the last Linear layer will have a bias parameter.
+        bias_last_layer (bool): if ``True``, the last Linear layer will have a bias parameter.
             default: True;
         aggregator_class (Type[nn.Module]): aggregator to use at the end of the chain.
             default:  SquashDims;
         aggregator_kwargs (dict, optional): kwargs for the aggregator_class;
         squeeze_output (bool): whether the output should be squeezed of its singleton dimensions.
-            default: True.
+            default: False.
         device (Optional[DEVICE_TYPING]): device to create the module on.
 
     Examples:
         >>> # All of the following examples provide valid, working MLPs
         >>> cnet = ConvNet(in_features=3, depth=1, num_cells=[32,]) # MLP consisting of a single 3 x 6 linear layer
         >>> print(cnet)
         ConvNet(
@@ -626,57 +634,85 @@
     def forward(self, x: torch.Tensor) -> torch.Tensor:
         x = self.features(x)
         advantage = self.advantage(x)
         value = self.value(x)
         return value + advantage - advantage.mean(dim=-1, keepdim=True)
 
 
-class DistributionalDQNnet(nn.Module):
+class DistributionalDQNnet(TensorDictModuleBase):
     """Distributional Deep Q-Network.
 
     Args:
-        DQNet (nn.Module): Q-Network with output length equal to the number of atoms:
+        DQNet (nn.Module): (deprecated) Q-Network with output length equal
+            to the number of atoms:
             output.shape = [*batch, atoms, actions].
+        in_keys (list of str or tuples of str): input keys to the log-softmax
+            operation. Defaults to ``["action_value"]``.
+        out_keys (list of str or tuples of str): output keys to the log-softmax
+            operation. Defaults to ``["action_value"]``.
 
     """
 
     _wrong_out_feature_dims_error = (
         "DistributionalDQNnet requires dqn output to be at least "
         "2-dimensional, with dimensions *Batch x #Atoms x #Actions. Got {0} "
         "instead."
     )
 
-    def __init__(self, DQNet: nn.Module):
+    def __init__(self, DQNet: nn.Module = None, in_keys=None, out_keys=None):
         super().__init__()
-        if not (
-            not isinstance(DQNet.out_features, Number) and len(DQNet.out_features) > 1
-        ):
-            raise RuntimeError(self._wrong_out_feature_dims_error)
-        self.dqn = DQNet
-
-    def forward(self, x: torch.Tensor) -> torch.Tensor:
-        q_values = self.dqn(x)
-        if q_values.ndimension() < 2:
-            raise RuntimeError(
-                self._wrong_out_feature_dims_error.format(q_values.shape)
+        if DQNet is not None:
+            warnings.warn(
+                f"Passing a network to {type(self)} is going to be deprecated.",
+                category=DeprecationWarning,
             )
-        return F.log_softmax(q_values, dim=-2)
+            if not (
+                not isinstance(DQNet.out_features, Number)
+                and len(DQNet.out_features) > 1
+            ):
+                raise RuntimeError(self._wrong_out_feature_dims_error)
+        self.dqn = DQNet
+        if in_keys is None:
+            in_keys = ["action_value"]
+        if out_keys is None:
+            out_keys = ["action_value"]
+        self.in_keys = in_keys
+        self.out_keys = out_keys
+
+    @dispatch(auto_batch_size=False)
+    def forward(self, tensordict):
+        for in_key, out_key in zip(self.in_keys, self.out_keys):
+            q_values = tensordict.get(in_key)
+            if self.dqn is not None:
+                q_values = self.dqn(q_values)
+            if q_values.ndimension() < 2:
+                raise RuntimeError(
+                    self._wrong_out_feature_dims_error.format(q_values.shape)
+                )
+            tensordict.set(out_key, F.log_softmax(q_values, dim=-2))
+        return tensordict
 
 
 def ddpg_init_last_layer(
-    last_layer: nn.Module,
+    module: nn.Sequential,
     scale: float = 6e-4,
     device: Optional[DEVICE_TYPING] = None,
 ) -> None:
     """Initializer for the last layer of DDPG.
 
     Presented in "CONTINUOUS CONTROL WITH DEEP REINFORCEMENT LEARNING",
     https://arxiv.org/pdf/1509.02971.pdf
 
     """
+    for last_layer in reversed(module):
+        if isinstance(last_layer, (nn.Linear, nn.Conv2d)):
+            break
+    else:
+        raise RuntimeError("Could not find a nn.Linear / nn.Conv2d to initialize.")
+
     last_layer.weight.data.copy_(
         torch.rand_like(last_layer.weight.data, device=device) * scale - scale / 2
     )
     if last_layer.bias is not None:
         last_layer.bias.data.copy_(
             torch.rand_like(last_layer.bias.data, device=device) * scale - scale / 2
         )
@@ -712,16 +748,16 @@
             'in_features': None,
             'out_features': action_dim,
             'depth': 2,
             'num_cells': 200,
             'activation_class': nn.ELU,
             'bias_last_layer': True,
         }
-        use_avg_pooling (bool, optional): if True, a nn.AvgPooling layer is
-            used to aggregate the output. Default is :obj:`False`.
+        use_avg_pooling (bool, optional): if ``True``, a nn.AvgPooling layer is
+            used to aggregate the output. Default is ``False``.
         device (Optional[DEVICE_TYPING]): device to create the module on.
     """
 
     def __init__(
         self,
         action_dim: int,
         conv_net_kwargs: Optional[dict] = None,
@@ -756,15 +792,15 @@
             "activation_class": nn.ELU,
             "bias_last_layer": True,
         }
         mlp_net_kwargs = mlp_net_kwargs if mlp_net_kwargs is not None else {}
         mlp_net_default_kwargs.update(mlp_net_kwargs)
         self.convnet = ConvNet(device=device, **conv_net_default_kwargs)
         self.mlp = MLP(device=device, **mlp_net_default_kwargs)
-        ddpg_init_last_layer(self.mlp[-1], 6e-4, device=device)
+        ddpg_init_last_layer(self.mlp, 6e-4, device=device)
 
     def forward(self, observation: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
         hidden = self.convnet(observation)
         action = self.mlp(hidden)
         return action, hidden
 
 
@@ -805,15 +841,15 @@
             "num_cells": [400, 300],
             "activation_class": nn.ELU,
             "bias_last_layer": True,
         }
         mlp_net_kwargs = mlp_net_kwargs if mlp_net_kwargs is not None else {}
         mlp_net_default_kwargs.update(mlp_net_kwargs)
         self.mlp = MLP(device=device, **mlp_net_default_kwargs)
-        ddpg_init_last_layer(self.mlp[-1], 6e-3, device=device)
+        ddpg_init_last_layer(self.mlp, 6e-3, device=device)
 
     def forward(self, observation: torch.Tensor) -> torch.Tensor:
         action = self.mlp(observation)
         return action
 
 
 class DdpgCnnQNet(nn.Module):
@@ -843,15 +879,15 @@
             'in_features': None,
             'out_features': 1,
             'depth': 2,
             'num_cells': 200,
             'activation_class': nn.ELU,
             'bias_last_layer': True,
         }
-        use_avg_pooling (bool, optional): if True, a nn.AvgPooling layer is
+        use_avg_pooling (bool, optional): if ``True``, a nn.AvgPooling layer is
             used to aggregate the output. Default is :obj:`True`.
         device (Optional[DEVICE_TYPING]): device to create the module on.
     """
 
     def __init__(
         self,
         conv_net_kwargs: Optional[dict] = None,
@@ -886,15 +922,15 @@
             "activation_class": nn.ELU,
             "bias_last_layer": True,
         }
         mlp_net_kwargs = mlp_net_kwargs if mlp_net_kwargs is not None else {}
         mlp_net_default_kwargs.update(mlp_net_kwargs)
         self.convnet = ConvNet(device=device, **conv_net_default_kwargs)
         self.mlp = MLP(device=device, **mlp_net_default_kwargs)
-        ddpg_init_last_layer(self.mlp[-1], 6e-4, device=device)
+        ddpg_init_last_layer(self.mlp, 6e-4, device=device)
 
     def forward(self, observation: torch.Tensor, action: torch.Tensor) -> torch.Tensor:
         hidden = torch.cat([self.convnet(observation), action], -1)
         value = self.mlp(hidden)
         return value
 
 
@@ -906,31 +942,31 @@
 
     The DDPG Q-value network takes as input an observation and an action, and returns a scalar from it.
     Because actions are integrated later than observations, two networks are created.
 
     Args:
         mlp_net_kwargs_net1 (dict, optional): kwargs for MLP.
             Default: {
-            'in_features': None,
-            'out_features': 400,
-            'depth': 0,
-            'num_cells': [],
-            'activation_class': nn.ELU,
-            'bias_last_layer': True,
-            'activate_last_layer': True,
-        }
+                'in_features': None,
+                'out_features': 400,
+                'depth': 0,
+                'num_cells': [],
+                'activation_class': nn.ELU,
+                'bias_last_layer': True,
+                'activate_last_layer': True,
+            }
         mlp_net_kwargs_net2
             Default: {
-            'in_features': None,
-            'out_features': 1,
-            'depth': 1,
-            'num_cells': [300, ],
-            'activation_class': nn.ELU,
-            'bias_last_layer': True,
-        }
+                'in_features': None,
+                'out_features': 1,
+                'depth': 1,
+                'num_cells': [300, ],
+                'activation_class': nn.ELU,
+                'bias_last_layer': True,
+            }
         device (Optional[DEVICE_TYPING]): device to create the module on.
     """
 
     def __init__(
         self,
         mlp_net_kwargs_net1: Optional[dict] = None,
         mlp_net_kwargs_net2: Optional[dict] = None,
@@ -962,15 +998,15 @@
             "bias_last_layer": True,
         }
         mlp_net_kwargs_net2 = (
             mlp_net_kwargs_net2 if mlp_net_kwargs_net2 is not None else {}
         )
         mlp2_net_default_kwargs.update(mlp_net_kwargs_net2)
         self.mlp2 = MLP(device=device, **mlp2_net_default_kwargs)
-        ddpg_init_last_layer(self.mlp2[-1], 6e-3, device=device)
+        ddpg_init_last_layer(self.mlp2, 6e-3, device=device)
 
     def forward(self, observation: torch.Tensor, action: torch.Tensor) -> torch.Tensor:
         value = self.mlp2(torch.cat([self.mlp1(observation), action], -1))
         return value
 
 
 class LSTMNet(nn.Module):
@@ -1009,14 +1045,18 @@
     def __init__(
         self,
         out_features: int,
         lstm_kwargs: Dict,
         mlp_kwargs: Dict,
         device: Optional[DEVICE_TYPING] = None,
     ) -> None:
+        warnings.warn(
+            "LSTMNet is being deprecated in favour of torchrl.modules.LSTMModule, and will be removed soon.",
+            category=DeprecationWarning,
+        )
         super().__init__()
         lstm_kwargs.update({"batch_first": True})
         self.mlp = MLP(device=device, **mlp_kwargs)
         self.lstm = nn.LSTM(device=device, **lstm_kwargs)
         self.linear = nn.LazyLinear(out_features, device=device)
 
     def _lstm(
```

## torchrl/modules/planners/cem.py

```diff
@@ -88,37 +88,39 @@
         ... )
         >>> env = MyMBEnv(world_model)
         >>> # Build a planner and use it as actor
         >>> planner = CEMPlanner(env, 10, 11, 7, 3)
         >>> env.rollout(5, planner)
         TensorDict(
             fields={
-                action: Tensor(torch.Size([5, 1]), dtype=torch.float32),
-                done: Tensor(torch.Size([5, 1]), dtype=torch.bool),
-                hidden_observation: Tensor(torch.Size([5, 4]), dtype=torch.float32),
-                next: LazyStackedTensorDict(
+                action: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.float32, is_shared=False),
+                done: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False),
+                hidden_observation: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                next: TensorDict(
                     fields={
-                        hidden_observation: Tensor(torch.Size([5, 4]), dtype=torch.float32)},
+                        done: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False),
+                        next_hidden_observation: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                        reward: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.float32, is_shared=False)},
                     batch_size=torch.Size([5]),
                     device=cpu,
                     is_shared=False),
-                reward: Tensor(torch.Size([5, 1]), dtype=torch.float32)},
+                next_hidden_observation: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.float32, is_shared=False)},
             batch_size=torch.Size([5]),
             device=cpu,
             is_shared=False)
     """
 
     def __init__(
         self,
         env: EnvBase,
         planning_horizon: int,
         optim_steps: int,
         num_candidates: int,
         top_k: int,
-        reward_key: str = "reward",
+        reward_key: str = ("next", "reward"),
         action_key: str = "action",
     ):
         super().__init__(env=env, action_key=action_key)
         self.planning_horizon = planning_horizon
         self.optim_steps = optim_steps
         self.num_candidates = num_candidates
         self.top_k = top_k
```

## torchrl/modules/planners/mppi.py

```diff
@@ -39,29 +39,30 @@
         reward_key (str, optional): The key in the TensorDict to use to
             retrieve the reward. Defaults to "reward".
         action_key (str, optional): The key in the TensorDict to use to store
             the action. Defaults to "action"
 
     Examples:
         >>> from tensordict import TensorDict
-        >>> from torchrl.data import CompositeSpec, NdUnboundedContinuousTensorSpec
+        >>> from torchrl.data import CompositeSpec, UnboundedContinuousTensorSpec
         >>> from torchrl.envs.model_based import ModelBasedEnvBase
-        >>> from torchrl.modules import TensorDictModule, ValueOperator
-        >>> from torchrl.objectives.value import TDLambdaEstimate
+        >>> from tensordict.nn import TensorDictModule
+        >>> from torchrl.modules import ValueOperator
+        >>> from torchrl.objectives.value import TDLambdaEstimator
         >>> class MyMBEnv(ModelBasedEnvBase):
         ...     def __init__(self, world_model, device="cpu", dtype=None, batch_size=None):
         ...         super().__init__(world_model, device=device, dtype=dtype, batch_size=batch_size)
         ...         self.observation_spec = CompositeSpec(
-        ...             hidden_observation=NdUnboundedContinuousTensorSpec((4,))
+        ...             hidden_observation=UnboundedContinuousTensorSpec((4,))
         ...         )
         ...         self.input_spec = CompositeSpec(
-        ...             hidden_observation=NdUnboundedContinuousTensorSpec((4,)),
-        ...             action=NdUnboundedContinuousTensorSpec((1,)),
+        ...             hidden_observation=UnboundedContinuousTensorSpec((4,)),
+        ...             action=UnboundedContinuousTensorSpec((1,)),
         ...         )
-        ...         self.reward_spec = NdUnboundedContinuousTensorSpec((1,))
+        ...         self.reward_spec = UnboundedContinuousTensorSpec((1,))
         ...
         ...     def _reset(self, tensordict: TensorDict) -> TensorDict:
         ...         tensordict = TensorDict(
         ...             {},
         ...             batch_size=self.batch_size,
         ...             device=self.device,
         ...         )
@@ -83,56 +84,57 @@
         ...         in_keys=["hidden_observation"],
         ...         out_keys=["reward"],
         ...     ),
         ... )
         >>> env = MyMBEnv(world_model)
         >>> value_net = nn.Linear(4, 1)
         >>> value_net = ValueOperator(value_net, in_keys=["hidden_observation"])
-        >>> adv = TDLambdaEstimate(
-        ...     0.99,
-        ...     0.95,
-        ...     value_net,
+        >>> adv = TDLambdaEstimator(
+        ...     gamma=0.99,
+        ...     lmbda=0.95,
+        ...     value_network=value_net,
         ... )
         >>> # Build a planner and use it as actor
         >>> planner = MPPIPlanner(
         ...     env,
         ...     adv,
         ...     temperature=1.0,
         ...     planning_horizon=10,
         ...     optim_steps=11,
         ...     num_candidates=7,
         ...     top_k=3)
         >>> env.rollout(5, planner)
         TensorDict(
             fields={
-                action: Tensor(torch.Size([5, 1]), dtype=torch.float32),
-                done: Tensor(torch.Size([5, 1]), dtype=torch.bool),
-                hidden_observation: Tensor(torch.Size([5, 4]), dtype=torch.float32),
-                next: LazyStackedTensorDict(
+                action: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.float32, is_shared=False),
+                done: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False),
+                hidden_observation: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                next: TensorDict(
                     fields={
-                        hidden_observation: Tensor(torch.Size([5, 4]), dtype=torch.float32)},
+                        done: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.bool, is_shared=False),
+                        hidden_observation: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                        reward: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.float32, is_shared=False)},
                     batch_size=torch.Size([5]),
                     device=cpu,
-                    is_shared=False),
-                reward: Tensor(torch.Size([5, 1]), dtype=torch.float32)},
+                    is_shared=False)},
             batch_size=torch.Size([5]),
             device=cpu,
             is_shared=False)
     """
 
     def __init__(
         self,
         env: EnvBase,
         advantage_module: nn.Module,
         temperature: float,
         planning_horizon: int,
         optim_steps: int,
         num_candidates: int,
         top_k: int,
-        reward_key: str = "reward",
+        reward_key: str = ("next", "reward"),
         action_key: str = "action",
     ):
         super().__init__(env=env, action_key=action_key)
         self.advantage_module = advantage_module
         self.planning_horizon = planning_horizon
         self.optim_steps = optim_steps
         self.num_candidates = num_candidates
```

## torchrl/modules/tensordict_module/__init__.py

```diff
@@ -5,20 +5,28 @@
 
 from .actors import (
     Actor,
     ActorCriticOperator,
     ActorCriticWrapper,
     ActorValueOperator,
     DistributionalQValueActor,
+    DistributionalQValueHook,
+    DistributionalQValueModule,
     ProbabilisticActor,
     QValueActor,
+    QValueHook,
+    QValueModule,
     ValueOperator,
 )
 from .common import SafeModule
 from .exploration import (
     AdditiveGaussianWrapper,
     EGreedyWrapper,
     OrnsteinUhlenbeckProcessWrapper,
 )
-from .probabilistic import SafeProbabilisticModule, SafeProbabilisticSequential
+from .probabilistic import (
+    SafeProbabilisticModule,
+    SafeProbabilisticTensorDictSequential,
+)
+from .rnn import LSTMModule
 from .sequence import SafeSequential
 from .world_models import WorldModelWrapper
```

## torchrl/modules/tensordict_module/actors.py

```diff
@@ -1,61 +1,101 @@
 # Copyright (c) Meta Platforms, Inc. and affiliates.
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
 
-from typing import Optional, Sequence, Tuple, Union
+from typing import List, Optional, Sequence, Tuple, Union
 
 import torch
-from tensordict.nn import TensorDictModuleWrapper
+from tensordict import TensorDictBase
+from tensordict.nn import (
+    dispatch,
+    TensorDictModule,
+    TensorDictModuleBase,
+    TensorDictModuleWrapper,
+)
 from torch import nn
 
-from torchrl.data.tensor_specs import (
-    CompositeSpec,
-    TensorSpec,
-    UnboundedContinuousTensorSpec,
-)
+from torchrl.data.tensor_specs import CompositeSpec, TensorSpec
 from torchrl.modules.models.models import DistributionalDQNnet
 from torchrl.modules.tensordict_module.common import SafeModule
 from torchrl.modules.tensordict_module.probabilistic import (
     SafeProbabilisticModule,
-    SafeProbabilisticSequential,
+    SafeProbabilisticTensorDictSequential,
 )
 from torchrl.modules.tensordict_module.sequence import SafeSequential
+from torchrl.modules.utils.utils import _find_action_space
 
 
 class Actor(SafeModule):
     """General class for deterministic actors in RL.
 
     The Actor class comes with default values for the out_keys (["action"])
     and if the spec is provided but not as a CompositeSpec object, it will be
     automatically translated into :obj:`spec = CompositeSpec(action=spec)`
 
+    Args:
+        module (nn.Module): a :class:`torch.nn.Module` used to map the input to
+            the output parameter space.
+        in_keys (iterable of str, optional): keys to be read from input
+            tensordict and passed to the module. If it
+            contains more than one element, the values will be passed in the
+            order given by the in_keys iterable.
+            Defaults to ``["observation"]``.
+        out_keys (iterable of str): keys to be written to the input tensordict.
+            The length of out_keys must match the
+            number of tensors returned by the embedded module. Using "_" as a
+            key avoid writing tensor to output.
+            Defaults to ``["action"]``.
+        spec (TensorSpec, optional): Keyword-only argument.
+            Specs of the output tensor. If the module
+            outputs multiple output tensors,
+            spec characterize the space of the first output tensor.
+        safe (bool): Keyword-only argument.
+            If ``True``, the value of the output is checked against the
+            input spec. Out-of-domain sampling can
+            occur because of exploration policies or numerical under/overflow
+            issues. If this value is out of bounds, it is projected back onto the
+            desired space using the :obj:`TensorSpec.project`
+            method. Default is ``False``.
+
     Examples:
         >>> import torch
         >>> from tensordict import TensorDict
         >>> from torchrl.data import UnboundedContinuousTensorSpec
         >>> from torchrl.modules import Actor
+        >>> torch.manual_seed(0)
         >>> td = TensorDict({"observation": torch.randn(3, 4)}, [3,])
         >>> action_spec = UnboundedContinuousTensorSpec(4)
         >>> module = torch.nn.Linear(4, 4)
         >>> td_module = Actor(
         ...    module=module,
         ...    spec=action_spec,
         ...    )
         >>> td_module(td)
+        TensorDict(
+            fields={
+                action: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False)},
+            batch_size=torch.Size([3]),
+            device=None,
+            is_shared=False)
         >>> print(td.get("action"))
+        tensor([[-1.3635, -0.0340,  0.1476, -1.3911],
+                [-0.1664,  0.5455,  0.2247, -0.4583],
+                [-0.2916,  0.2160,  0.5337, -0.5193]], grad_fn=<AddmmBackward0>)
 
     """
 
     def __init__(
         self,
-        *args,
+        module: nn.Module,
         in_keys: Optional[Sequence[str]] = None,
         out_keys: Optional[Sequence[str]] = None,
+        *,
         spec: Optional[TensorSpec] = None,
         **kwargs,
     ):
         if in_keys is None:
             in_keys = ["observation"]
         if out_keys is None:
             out_keys = ["action"]
@@ -63,66 +103,121 @@
             "action" in out_keys
             and spec is not None
             and not isinstance(spec, CompositeSpec)
         ):
             spec = CompositeSpec(action=spec)
 
         super().__init__(
-            *args,
+            module,
             in_keys=in_keys,
             out_keys=out_keys,
             spec=spec,
             **kwargs,
         )
 
 
-class ProbabilisticActor(SafeProbabilisticSequential):
+class ProbabilisticActor(SafeProbabilisticTensorDictSequential):
     """General class for probabilistic actors in RL.
 
     The Actor class comes with default values for the out_keys (["action"])
     and if the spec is provided but not as a CompositeSpec object, it will be
     automatically translated into :obj:`spec = CompositeSpec(action=spec)`
 
+    Args:
+        module (nn.Module): a :class:`torch.nn.Module` used to map the input to
+            the output parameter space.
+        in_keys (str or iterable of str or dict): key(s) that will be read from the
+            input TensorDict and used to build the distribution. Importantly, if it's an
+            iterable of string or a string, those keys must match the keywords used by
+            the distribution class of interest, e.g. :obj:`"loc"` and :obj:`"scale"` for
+            the Normal distribution and similar. If in_keys is a dictionary,, the keys
+            are the keys of the distribution and the values are the keys in the
+            tensordict that will get match to the corresponding distribution keys.
+        out_keys (str or iterable of str): keys where the sampled values will be
+            written. Importantly, if these keys are found in the input TensorDict, the
+            sampling step will be skipped.
+        spec (TensorSpec, optional): keyword-only argument containing the specs
+            of the output tensor. If the module outputs multiple output tensors,
+            spec characterize the space of the first output tensor.
+        safe (bool): keyword-only argument. if ``True``, the value of the output is checked against the
+            input spec. Out-of-domain sampling can
+            occur because of exploration policies or numerical under/overflow
+            issues. If this value is out of bounds, it is projected back onto the
+            desired space using the :obj:`TensorSpec.project`
+            method. Default is ``False``.
+        default_interaction_type=InteractionType.RANDOM (str, optional): keyword-only argument.
+            Default method to be used to retrieve
+            the output value. Should be one of: 'mode', 'median', 'mean' or 'random'
+            (in which case the value is sampled randomly from the distribution). Default
+            is 'mode'.
+            Note: When a sample is drawn, the :obj:`ProbabilisticTDModule` instance will
+            first look for the interaction mode dictated by the `interaction_typ()`
+            global function. If this returns `None` (its default value), then the
+            `default_interaction_type` of the `ProbabilisticTDModule` instance will be
+            used. Note that DataCollector instances will use `set_interaction_type` to
+            :class:`tensordict.nn.InteractionType.RANDOM` by default.
+        distribution_class (Type, optional): keyword-only argument.
+            A :class:`torch.distributions.Distribution` class to
+            be used for sampling.
+            Default is :class:`tensordict.nn.distributions.Delta`.
+        distribution_kwargs (dict, optional): keyword-only argument.
+            Keyword-argument pairs to be passed to the distribution.
+        return_log_prob (bool, optional): keyword-only argument.
+            If ``True``, the log-probability of the
+            distribution sample will be written in the tensordict with the key
+            `'sample_log_prob'`. Default is ``False``.
+        cache_dist (bool, optional): keyword-only argument.
+            EXPERIMENTAL: if ``True``, the parameters of the
+            distribution (i.e. the output of the module) will be written to the
+            tensordict along with the sample. Those parameters can be used to re-compute
+            the original distribution later on (e.g. to compute the divergence between
+            the distribution used to sample the action and the updated distribution in
+            PPO). Default is ``False``.
+        n_empirical_estimate (int, optional): keyword-only argument.
+            Number of samples to compute the empirical
+            mean when it is not available. Defaults to 1000.
+
     Examples:
         >>> import torch
         >>> from tensordict import TensorDict
-        >>> from tensordict.nn.functional_modules import make_functional
+        >>> from tensordict.nn import TensorDictModule, make_functional
         >>> from torchrl.data import BoundedTensorSpec
-        >>> from torchrl.modules import ProbabilisticActor, NormalParamWrapper, SafeModule, TanhNormal
+        >>> from torchrl.modules import ProbabilisticActor, NormalParamWrapper, TanhNormal
         >>> td = TensorDict({"observation": torch.randn(3, 4)}, [3,])
         >>> action_spec = BoundedTensorSpec(shape=torch.Size([4]),
         ...    minimum=-1, maximum=1)
         >>> module = NormalParamWrapper(torch.nn.Linear(4, 8))
-        >>> tensordict_module = SafeModule(module, in_keys=["observation"], out_keys=["loc", "scale"])
+        >>> tensordict_module = TensorDictModule(module, in_keys=["observation"], out_keys=["loc", "scale"])
         >>> td_module = ProbabilisticActor(
         ...    module=tensordict_module,
         ...    spec=action_spec,
-        ...    dist_in_keys=["loc", "scale"],
+        ...    in_keys=["loc", "scale"],
         ...    distribution_class=TanhNormal,
         ...    )
         >>> params = make_functional(td_module)
         >>> td = td_module(td, params=params)
         >>> td
         TensorDict(
             fields={
-                observation: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                loc: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                scale: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                action: Tensor(torch.Size([3, 4]), dtype=torch.float32)},
+                action: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                loc: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                scale: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False)},
             batch_size=torch.Size([3]),
-            device=cpu,
+            device=None,
             is_shared=False)
 
     """
 
     def __init__(
         self,
-        module: SafeModule,
+        module: TensorDictModule,
         in_keys: Union[str, Sequence[str]],
         out_keys: Optional[Sequence[str]] = None,
+        *,
         spec: Optional[TensorSpec] = None,
         **kwargs,
     ):
         if out_keys is None:
             out_keys = ["action"]
         if (
             "action" in out_keys
@@ -135,26 +230,40 @@
             module,
             SafeProbabilisticModule(
                 in_keys=in_keys, out_keys=out_keys, spec=spec, **kwargs
             ),
         )
 
 
-class ValueOperator(SafeModule):
+class ValueOperator(TensorDictModule):
     """General class for value functions in RL.
 
     The ValueOperator class comes with default values for the in_keys and
     out_keys arguments (["observation"] and ["state_value"] or
     ["state_action_value"], respectively and depending on whether the "action"
     key is part of the in_keys list).
 
+    Args:
+        module (nn.Module): a :class:`torch.nn.Module` used to map the input to
+            the output parameter space.
+        in_keys (iterable of str, optional): keys to be read from input
+            tensordict and passed to the module. If it
+            contains more than one element, the values will be passed in the
+            order given by the in_keys iterable.
+            Defaults to ``["observation"]``.
+        out_keys (iterable of str): keys to be written to the input tensordict.
+            The length of out_keys must match the
+            number of tensors returned by the embedded module. Using "_" as a
+            key avoid writing tensor to output.
+            Defaults to ``["action"]``.
+
     Examples:
         >>> import torch
         >>> from tensordict import TensorDict
-        >>> from tensordict.nn.functional_modules import make_functional
+        >>> from tensordict.nn import make_functional
         >>> from torch import nn
         >>> from torchrl.data import UnboundedContinuousTensorSpec
         >>> from torchrl.modules import ValueOperator
         >>> td = TensorDict({"observation": torch.randn(3, 4), "action": torch.randn(3, 2)}, [3,])
         >>> class CustomModule(nn.Module):
         ...     def __init__(self):
         ...         super().__init__()
@@ -162,21 +271,21 @@
         ...     def forward(self, obs, action):
         ...         return self.linear(torch.cat([obs, action], -1))
         >>> module = CustomModule()
         >>> td_module = ValueOperator(
         ...    in_keys=["observation", "action"], module=module
         ... )
         >>> params = make_functional(td_module)
-        >>> td_module(td, params=params)
+        >>> td = td_module(td, params=params)
         >>> print(td)
         TensorDict(
             fields={
-                action: Tensor(torch.Size([3, 2]), dtype=torch.float32),
-                observation: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                state_action_value: Tensor(torch.Size([3, 1]), dtype=torch.float32)},
+                action: Tensor(shape=torch.Size([3, 2]), device=cpu, dtype=torch.float32, is_shared=False),
+                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                state_action_value: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},
             batch_size=torch.Size([3]),
             device=None,
             is_shared=False)
 
 
     """
 
@@ -189,95 +298,163 @@
 
         if in_keys is None:
             in_keys = ["observation"]
         if out_keys is None:
             out_keys = (
                 ["state_value"] if "action" not in in_keys else ["state_action_value"]
             )
-        value_spec = UnboundedContinuousTensorSpec()
         super().__init__(
-            spec=value_spec,
             module=module,
             in_keys=in_keys,
             out_keys=out_keys,
         )
 
 
-class QValueHook:
-    """Q-Value hook for Q-value policies.
+class QValueModule(TensorDictModuleBase):
+    """Q-Value TensorDictModule for Q-value policies.
 
-    Given a the output of a regular nn.Module, representing the values of the different discrete actions available,
-    a QValueHook will transform these values into their argmax component (i.e. the resulting greedy action).
-    Currently, this is returned as a one-hot encoding.
+    This module processes a tensor containing action value into is argmax
+    component (i.e. the resulting greedy action), following a given
+    action space (one-hot, binary or categorical).
+    It works with both tensordict and regular tensors.
 
     Args:
-        action_space (str): Action space. Must be one of "one-hot", "mult_one_hot", "binary" or "categorical".
-        var_nums (int, optional): if action_space == "mult_one_hot", this value represents the cardinality of each
+        action_space (str or TensorSpec, optional): Action space. Must be one of
+            ``"one-hot"``, ``"mult-one-hot"``, ``"binary"`` or ``"categorical"``,
+            or an instance of the corresponding specs (:class:`torchrl.data.OneHotDiscreteTensorSpec`,
+            :class:`torchrl.data.MultiOneHotDiscreteTensorSpec`,
+            :class:`torchrl.data.BinaryDiscreteTensorSpec` or :class:`torchrl.data.DiscreteTensorSpec`).
+            This is argumets is exclusive with ``spec``, since the ``action_spec``
+            conditions the action spec.
+        action_value_key (str or tuple of str, optional): The input key
+            representing the action value. Defaults to ``"action_value"``.
+        out_keys (list of str or tuple of str, optional): The output keys
+            representing the actions, action values and chosen action value.
+            Defaults to ``["action", "action_value", "chosen_action_value"]``.
+        var_nums (int, optional): if ``action_space = "mult-one-hot"``,
+            this value represents the cardinality of each
             action component.
+        spec (TensorSpec, optional): if provided, the specs of the action (and/or
+            other outputs). This is exclusive with ``action_space``, as the spec
+            conditions the action space.
+        safe (bool): if ``True``, the value of the output is checked against the
+            input spec. Out-of-domain sampling can
+            occur because of exploration policies or numerical under/overflow issues.
+            If this value is out of bounds, it is projected back onto the
+            desired space using the :obj:`TensorSpec.project`
+            method. Default is ``False``.
+
+    Returns:
+        if the input is a single tensor, a triplet containing the chosen action,
+        the values and the value of the chose action is returned. If a tensordict
+        is provided, it is updated with these entries at the keys indicated by the
+        ``out_keys`` field.
 
     Examples:
-        >>> import torch
         >>> from tensordict import TensorDict
-        >>> from tensordict.nn.functional_modules import make_functional
-        >>> from torch import nn
-        >>> from torchrl.data import OneHotDiscreteTensorSpec
-        >>> from torchrl.modules.tensordict_module.actors import QValueHook, Actor
-        >>> td = TensorDict({'observation': torch.randn(5, 4)}, [5])
-        >>> module = nn.Linear(4, 4)
-        >>> params = make_functional(module)
-        >>> hook = QValueHook("one_hot")
-        >>> module.register_forward_hook(hook)
-        >>> action_spec = OneHotDiscreteTensorSpec(4)
-        >>> qvalue_actor = Actor(module=module, spec=action_spec, out_keys=["action", "action_value"])
-        >>> qvalue_actor(td, params=params)
-        >>> print(td)
+        >>> action_space = "categorical"
+        >>> action_value_key = "my_action_value"
+        >>> actor = QValueModule(action_space, action_value_key=action_value_key)
+        >>> # This module works with both tensordict and regular tensors:
+        >>> value = torch.zeros(4)
+        >>> value[-1] = 1
+        >>> actor(my_action_value=value)
+        (tensor(3), tensor([0., 0., 0., 1.]), tensor([1.]))
+        >>> actor(value)
+        (tensor(3), tensor([0., 0., 0., 1.]), tensor([1.]))
+        >>> actor(TensorDict({action_value_key: value}, []))
         TensorDict(
             fields={
-                action: Tensor(torch.Size([5, 4]), dtype=torch.int64),
-                action_value: Tensor(torch.Size([5, 4]), dtype=torch.float32),
-                observation: Tensor(torch.Size([5, 4]), dtype=torch.float32)},
-            batch_size=torch.Size([5]),
+                action: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False),
+                action_value: Tensor(shape=torch.Size([4]), device=cpu, dtype=torch.float32, is_shared=False),
+                chosen_action_value: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),
+                my_action_value: Tensor(shape=torch.Size([4]), device=cpu, dtype=torch.float32, is_shared=False)},
+            batch_size=torch.Size([]),
             device=None,
             is_shared=False)
 
     """
 
     def __init__(
         self,
-        action_space: str,
+        action_space: Optional[Union[str, TensorSpec]],
+        action_value_key: Union[List[str], List[Tuple[str]]] = None,
+        out_keys: Union[List[str], List[Tuple[str]]] = None,
         var_nums: Optional[int] = None,
+        spec: Optional[TensorSpec] = None,
+        safe: bool = False,
     ):
+        action_space, spec = _process_action_space_spec(action_space, spec)
         self.action_space = action_space
         self.var_nums = var_nums
         self.action_func_mapping = {
             "one_hot": self._one_hot,
             "mult_one_hot": self._mult_one_hot,
             "binary": self._binary,
             "categorical": self._categorical,
         }
         self.action_value_func_mapping = {
             "categorical": self._categorical_action_value,
         }
         if action_space not in self.action_func_mapping:
             raise ValueError(
-                f"action_space must be one of {list(self.action_func_mapping.keys())}"
+                f"action_space must be one of {list(self.action_func_mapping.keys())}, got {action_space}"
+            )
+        if action_value_key is None:
+            action_value_key = "action_value"
+        self.in_keys = [action_value_key]
+        if out_keys is None:
+            out_keys = ["action", action_value_key, "chosen_action_value"]
+        elif action_value_key not in out_keys:
+            raise RuntimeError(
+                f"Expected the action-value key to be '{action_value_key}' but got {out_keys[1]} instead."
+            )
+        self.out_keys = out_keys
+        action_key = out_keys[0]
+        if not isinstance(spec, CompositeSpec):
+            spec = CompositeSpec({action_key: spec})
+        super().__init__()
+        self.register_spec(safe=safe, spec=spec)
+
+    register_spec = SafeModule.register_spec
+
+    @property
+    def spec(self) -> CompositeSpec:
+        return self._spec
+
+    @spec.setter
+    def spec(self, spec: CompositeSpec) -> None:
+        if not isinstance(spec, CompositeSpec):
+            raise RuntimeError(
+                f"Trying to set an object of type {type(spec)} as a tensorspec but expected a CompositeSpec instance."
             )
+        self._spec = spec
 
-    def __call__(
-        self, net: nn.Module, observation: torch.Tensor, values: torch.Tensor
-    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
-        if isinstance(values, tuple):
-            values = values[0]
-        action = self.action_func_mapping[self.action_space](values)
+    @property
+    def action_value_key(self):
+        return self.in_keys[0]
+
+    @dispatch(auto_batch_size=False)
+    def forward(self, tensordict: torch.Tensor) -> TensorDictBase:
+        action_values = tensordict.get(self.action_value_key, None)
+        if action_values is None:
+            raise KeyError(
+                f"Action value key {self.action_value_key} not found in {tensordict}."
+            )
+
+        action = self.action_func_mapping[self.action_space](action_values)
 
         action_value_func = self.action_value_func_mapping.get(
             self.action_space, self._default_action_value
         )
-        chosen_action_value = action_value_func(values, action)
-        return action, values, chosen_action_value
+        chosen_action_value = action_value_func(action_values, action)
+        tensordict.update(
+            dict(zip(self.out_keys, (action, action_values, chosen_action_value)))
+        )
+        return tensordict
 
     @staticmethod
     def _one_hot(value: torch.Tensor) -> torch.Tensor:
         out = (value == value.max(dim=-1, keepdim=True)[0]).to(torch.long)
         return out
 
     @staticmethod
@@ -306,429 +483,894 @@
     ) -> torch.Tensor:
         return (action * values).sum(-1, True)
 
     @staticmethod
     def _categorical_action_value(
         values: torch.Tensor, action: torch.Tensor
     ) -> torch.Tensor:
-        if len(values.shape) == 1:
-            return values[action].unsqueeze(-1)
-        batch_size = values.size(0)
-        return values[range(batch_size), action].unsqueeze(-1)
+        return values.gather(-1, action.unsqueeze(-1))
+        # if values.ndim == 1:
+        #     return values[action].unsqueeze(-1)
+        # batch_size = values.size(0)
+        # return values[range(batch_size), action].unsqueeze(-1)
 
 
-class DistributionalQValueHook(QValueHook):
+class DistributionalQValueModule(QValueModule):
     """Distributional Q-Value hook for Q-value policies.
 
-    Given a the output of a mapping operator, representing the values of the different discrete actions available,
-    a DistributionalQValueHook will transform these values into their argmax component using the provided support.
-    Currently, this is returned as a one-hot encoding.
+    This module processes a tensor containing action value logits into is argmax
+    component (i.e. the resulting greedy action), following a given
+    action space (one-hot, binary or categorical).
+    It works with both tensordict and regular tensors.
+
+    The input action value is expected to be the result of a log-softmax
+    operation.
+
     For more details regarding Distributional DQN, refer to "A Distributional Perspective on Reinforcement Learning",
     https://arxiv.org/pdf/1707.06887.pdf
 
     Args:
-        action_space (str): Action space. Must be one of "one_hot", "mult_one_hot", "binary" or "categorical".
+        action_space (str or TensorSpec, optional): Action space. Must be one of
+            ``"one-hot"``, ``"mult-one-hot"``, ``"binary"`` or ``"categorical"``,
+            or an instance of the corresponding specs (:class:`torchrl.data.OneHotDiscreteTensorSpec`,
+            :class:`torchrl.data.MultiOneHotDiscreteTensorSpec`,
+            :class:`torchrl.data.BinaryDiscreteTensorSpec` or :class:`torchrl.data.DiscreteTensorSpec`).
+            This is argumets is exclusive with ``spec``, since the ``action_spec``
+            conditions the action spec.
         support (torch.Tensor): support of the action values.
-        var_nums (int, optional): if action_space == "mult_one_hot", this value represents the cardinality of each
+        action_value_key (str or tuple of str, optional): The input key
+            representing the action value. Defaults to ``"action_value"``.
+        out_keys (list of str or tuple of str, optional): The output keys
+            representing the actions and action values.
+            Defaults to ``["action", "action_value"]``.
+        var_nums (int, optional): if ``action_space = "mult-one-hot"``,
+            this value represents the cardinality of each
             action component.
+        spec (TensorSpec, optional): if provided, the specs of the action (and/or
+            other outputs). This is exclusive with ``action_space``, as the spec
+            conditions the action space.
+        safe (bool): if ``True``, the value of the output is checked against the
+            input spec. Out-of-domain sampling can
+            occur because of exploration policies or numerical under/overflow issues.
+            If this value is out of bounds, it is projected back onto the
+            desired space using the :obj:`TensorSpec.project`
+            method. Default is ``False``.
 
     Examples:
-        >>> import torch
         >>> from tensordict import TensorDict
-        >>> from tensordict.nn.functional_modules import make_functional
-        >>> from torch import nn
-        >>> from torchrl.data import OneHotDiscreteTensorSpec
-        >>> from torchrl.modules.tensordict_module.actors import DistributionalQValueHook, Actor
-        >>> td = TensorDict({'observation': torch.randn(5, 4)}, [5])
-        >>> nbins = 3
-        >>> class CustomDistributionalQval(nn.Module):
-        ...     def __init__(self):
-        ...         super().__init__()
-        ...         self.linear = nn.Linear(4, nbins*4)
-        ...
-        ...     def forward(self, x):
-        ...         return self.linear(x).view(-1, nbins, 4).log_softmax(-2)
-        ...
-        >>> module = CustomDistributionalQval()
-        >>> params = make_functional(module)
-        >>> action_spec = OneHotDiscreteTensorSpec(4)
-        >>> hook = DistributionalQValueHook("one_hot", support = torch.arange(nbins))
-        >>> module.register_forward_hook(hook)
-        >>> qvalue_actor = Actor(module=module, spec=action_spec, out_keys=["action", "action_value"])
-        >>> qvalue_actor(td, params=params)
-        >>> print(td)
+        >>> torch.manual_seed(0)
+        >>> action_space = "categorical"
+        >>> action_value_key = "my_action_value"
+        >>> support = torch.tensor([-1, 0.0, 1.0]) # the action value is between -1 and 1
+        >>> actor = DistributionalQValueModule(action_space, support=support, action_value_key=action_value_key)
+        >>> # This module works with both tensordict and regular tensors:
+        >>> value = torch.full((3, 4), -100)
+        >>> # the first bin (-1) of the first action is high: there's a high chance that it has a low value
+        >>> value[0, 0] = 0
+        >>> # the second bin (0) of the second action is high: there's a high chance that it has an intermediate value
+        >>> value[1, 1] = 0
+        >>> # the third bin (0) of the thid action is high: there's a high chance that it has an high value
+        >>> value[2, 2] = 0
+        >>> actor(my_action_value=value)
+        (tensor(2), tensor([[   0, -100, -100, -100],
+                [-100,    0, -100, -100],
+                [-100, -100,    0, -100]]))
+        >>> actor(value)
+        (tensor(2), tensor([[   0, -100, -100, -100],
+                [-100,    0, -100, -100],
+                [-100, -100,    0, -100]]))
+        >>> actor(TensorDict({action_value_key: value}, []))
         TensorDict(
             fields={
-                action: Tensor(torch.Size([5, 4]), dtype=torch.int64),
-                action_value: Tensor(torch.Size([5, 3, 4]), dtype=torch.float32),
-                observation: Tensor(torch.Size([5, 4]), dtype=torch.float32)},
-            batch_size=torch.Size([5]),
+                action: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False),
+                my_action_value: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.int64, is_shared=False)},
+            batch_size=torch.Size([]),
             device=None,
             is_shared=False)
 
     """
 
     def __init__(
         self,
         action_space: str,
         support: torch.Tensor,
+        action_value_key: Union[List[str], List[Tuple[str]]] = None,
+        out_keys: Union[List[str], List[Tuple[str]]] = None,
         var_nums: Optional[int] = None,
+        spec: TensorSpec = None,
+        safe: bool = False,
     ):
-        self.action_space = action_space
-        self.support = support
-        self.var_nums = var_nums
-        self.action_func_mapping = {
-            "one_hot": self._one_hot,
-            "mult_one_hot": self._mult_one_hot,
-            "binary": self._binary,
-            "categorical": self._categorical,
-        }
-        if action_space not in self.action_func_mapping:
-            raise ValueError(
-                f"action_space must be one of {list(self.action_func_mapping.keys())}"
+        if action_value_key is None:
+            action_value_key = "action_value"
+        if out_keys is None:
+            out_keys = ["action", action_value_key]
+        super().__init__(
+            action_space=action_space,
+            action_value_key=action_value_key,
+            out_keys=out_keys,
+            var_nums=var_nums,
+            spec=spec,
+            safe=safe,
+        )
+        self.register_buffer("support", support)
+
+    @dispatch(auto_batch_size=False)
+    def forward(self, tensordict: torch.Tensor) -> TensorDictBase:
+        action_values = tensordict.get(self.action_value_key, None)
+        if action_values is None:
+            raise KeyError(
+                f"Action value key {self.action_value_key} not found in {tensordict}."
             )
 
-    def __call__(
-        self, net: nn.Module, observation: torch.Tensor, values: torch.Tensor
-    ) -> Tuple[torch.Tensor, torch.Tensor]:
-        if isinstance(values, tuple):
-            values = values[0]
-        action = self.action_func_mapping[self.action_space](values, self.support)
-        return action, values
+        action = self.action_func_mapping[self.action_space](action_values)
+
+        tensordict.update(
+            dict(
+                zip(
+                    self.out_keys,
+                    (
+                        action,
+                        action_values,
+                    ),
+                )
+            )
+        )
+        return tensordict
 
     def _support_expected(
-        self, log_softmax_values: torch.Tensor, support: torch.Tensor
+        self, log_softmax_values: torch.Tensor, support=None
     ) -> torch.Tensor:
+        if support is None:
+            support = self.support
         support = support.to(log_softmax_values.device)
         if log_softmax_values.shape[-2] != support.shape[-1]:
             raise RuntimeError(
                 "Support length and number of atoms in module output should match, "
                 f"got self.support.shape={support.shape} and module(...).shape={log_softmax_values.shape}"
             )
         if (log_softmax_values > 0).any():
             raise ValueError(
                 f"input to QValueHook must be log-softmax values (which are expected to be non-positive numbers). "
                 f"got a maximum value of {log_softmax_values.max():4.4f}"
             )
         return (log_softmax_values.exp() * support.unsqueeze(-1)).sum(-2)
 
-    def _one_hot(self, value: torch.Tensor, support: torch.Tensor) -> torch.Tensor:
+    def _one_hot(self, value: torch.Tensor, support=None) -> torch.Tensor:
+        if support is None:
+            support = self.support
         if not isinstance(value, torch.Tensor):
             raise TypeError(f"got value of type {value.__class__.__name__}")
         if not isinstance(support, torch.Tensor):
             raise TypeError(f"got support of type {support.__class__.__name__}")
-        value = self._support_expected(value, support)
+        value = self._support_expected(value)
         out = (value == value.max(dim=-1, keepdim=True)[0]).to(torch.long)
         return out
 
-    def _mult_one_hot(self, value: torch.Tensor, support: torch.Tensor) -> torch.Tensor:
+    def _mult_one_hot(self, value: torch.Tensor, support=None) -> torch.Tensor:
+        if support is None:
+            support = self.support
         values = value.split(self.var_nums, dim=-1)
         return torch.cat(
             [
                 self._one_hot(_value, _support)
                 for _value, _support in zip(values, support)
             ],
             -1,
         )
 
-    def _categorical(self, value: torch.Tensor, support: torch.Tensor) -> torch.Tensor:
-        value = value = self._support_expected(value, support)
+    def _categorical(
+        self,
+        value: torch.Tensor,
+    ) -> torch.Tensor:
+        value = self._support_expected(
+            value,
+        )
         return torch.argmax(value, dim=-1).to(torch.long)
 
-    @staticmethod
-    def _binary(value: torch.Tensor, support: torch.Tensor) -> torch.Tensor:
-        raise NotImplementedError
+    def _binary(self, value: torch.Tensor) -> torch.Tensor:
+        raise NotImplementedError(
+            "'binary' is currently not supported for DistributionalQValueModule."
+        )
+
+
+def _process_action_space_spec(action_space, spec):
+    nest_action = False
+    if isinstance(spec, CompositeSpec):
+        try:
+            # this will break whenever our action is more complex than a single tensor
+            spec = spec["action"]
+            nest_action = True
+        except KeyError:
+            raise KeyError(
+                "action could not be found in the spec. Make sure "
+                "you pass a spec that is either a native action spec or a composite action spec "
+                "with an 'action' entry. Otherwise, simply remove the spec and use the action_space only."
+            )
+    if action_space is not None:
+        if isinstance(action_space, CompositeSpec):
+            raise ValueError("action_space cannot be of type CompositeSpec.")
+        if (
+            spec is not None
+            and isinstance(action_space, TensorSpec)
+            and action_space is not spec
+        ):
+            raise ValueError(
+                "Passing an action_space as a TensorSpec and a spec isn't allowed, unless they match."
+            )
+        if isinstance(action_space, TensorSpec):
+            spec = action_space
+        action_space = _find_action_space(action_space)
+        # check that the spec and action_space match
+        if spec is not None and _find_action_space(spec) != action_space:
+            raise ValueError(
+                f"The action spec and the action space do not match: got action_space={action_space} and spec={spec}."
+            )
+    elif spec is not None:
+        action_space = _find_action_space(spec)
+    else:
+        raise ValueError(
+            "Neither action_space nor spec was defined. The action space cannot be inferred."
+        )
+    if nest_action:
+        spec = CompositeSpec(action=spec)
+    return action_space, spec
 
 
-class QValueActor(Actor):
-    """DQN Actor subclass.
+class QValueHook:
+    """Q-Value hook for Q-value policies.
 
-    This class hooks the module such that it returns a one-hot encoding of the argmax value.
+    Given the output of a regular nn.Module, representing the values of the
+    different discrete actions available,
+    a QValueHook will transform these values into their argmax component (i.e.
+    the resulting greedy action).
+
+    Args:
+        action_space (str): Action space. Must be one of
+            ``"one-hot"``, ``"mult-one-hot"``, ``"binary"`` or ``"categorical"``.
+        var_nums (int, optional): if ``action_space = "mult-one-hot"``,
+            this value represents the cardinality of each
+            action component.
+        action_value_key (str or tuple of str, optional): to be used when hooked on
+            a TensorDictModule. The input key representing the action value. Defaults
+            to ``"action_value"``.
+        out_keys (list of str or tuple of str, optional): to be used when hooked on
+            a TensorDictModule. The output keys representing the actions, action values
+            and chosen action value. Defaults to ``["action", "action_value", "chosen_action_value"]``.
 
     Examples:
         >>> import torch
         >>> from tensordict import TensorDict
         >>> from tensordict.nn.functional_modules import make_functional
         >>> from torch import nn
         >>> from torchrl.data import OneHotDiscreteTensorSpec
-        >>> from torchrl.modules.tensordict_module.actors import QValueActor
+        >>> from torchrl.modules.tensordict_module.actors import QValueHook, Actor
         >>> td = TensorDict({'observation': torch.randn(5, 4)}, [5])
         >>> module = nn.Linear(4, 4)
-        >>> params= make_functional(module)
+        >>> hook = QValueHook("one_hot")
+        >>> module.register_forward_hook(hook)
         >>> action_spec = OneHotDiscreteTensorSpec(4)
-        >>> qvalue_actor = QValueActor(module=module, spec=action_spec)
+        >>> qvalue_actor = Actor(module=module, spec=action_spec, out_keys=["action", "action_value"])
+        >>> td = qvalue_actor(td)
+        >>> print(td)
+        TensorDict(
+            fields={
+                action: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.int64, is_shared=False),
+                action_value: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                observation: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.float32, is_shared=False)},
+            batch_size=torch.Size([5]),
+            device=None,
+            is_shared=False)
+
+    """
+
+    def __init__(
+        self,
+        action_space: str,
+        var_nums: Optional[int] = None,
+        action_value_key: Union[str, Tuple[str]] = None,
+        out_keys: Union[List[str], List[Tuple[str]]] = None,
+    ):
+        action_space, _ = _process_action_space_spec(action_space, None)
+
+        self.qvalue_model = QValueModule(
+            action_space=action_space,
+            var_nums=var_nums,
+            action_value_key=action_value_key,
+            out_keys=out_keys,
+        )
+        action_value_key = self.qvalue_model.in_keys[0]
+        if isinstance(action_value_key, tuple):
+            action_value_key = "_".join(action_value_key)
+        # uses "dispatch" to get and return tensors
+        self.action_value_key = action_value_key
+
+    def __call__(
+        self, net: nn.Module, observation: torch.Tensor, values: torch.Tensor
+    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
+        kwargs = {self.action_value_key: values}
+        return self.qvalue_model(**kwargs)
+
+
+class DistributionalQValueHook(QValueHook):
+    """Distributional Q-Value hook for Q-value policies.
+
+    Given the output of a mapping operator, representing the log-probability of the
+    different action value bin available,
+    a DistributionalQValueHook will transform these values into their argmax
+    component using the provided support.
+
+    For more details regarding Distributional DQN, refer to "A Distributional Perspective on Reinforcement Learning",
+    https://arxiv.org/pdf/1707.06887.pdf
+
+    Args:
+        action_space (str): Action space. Must be one of
+            ``"one-hot"``, ``"mult-one-hot"``, ``"binary"`` or ``"categorical"``.
+        support (torch.Tensor): support of the action values.
+        var_nums (int, optional): if ``action_space = "mult-one-hot"``, this
+            value represents the cardinality of each
+            action component.
+
+    Examples:
+        >>> import torch
+        >>> from tensordict import TensorDict
+        >>> from tensordict.nn.functional_modules import make_functional
+        >>> from torch import nn
+        >>> from torchrl.data import OneHotDiscreteTensorSpec
+        >>> from torchrl.modules.tensordict_module.actors import DistributionalQValueHook, Actor
+        >>> td = TensorDict({'observation': torch.randn(5, 4)}, [5])
+        >>> nbins = 3
+        >>> class CustomDistributionalQval(nn.Module):
+        ...     def __init__(self):
+        ...         super().__init__()
+        ...         self.linear = nn.Linear(4, nbins*4)
+        ...
+        ...     def forward(self, x):
+        ...         return self.linear(x).view(-1, nbins, 4).log_softmax(-2)
+        ...
+        >>> module = CustomDistributionalQval()
+        >>> params = make_functional(module)
+        >>> action_spec = OneHotDiscreteTensorSpec(4)
+        >>> hook = DistributionalQValueHook("one_hot", support = torch.arange(nbins))
+        >>> module.register_forward_hook(hook)
+        >>> qvalue_actor = Actor(module=module, spec=action_spec, out_keys=["action", "action_value"])
         >>> qvalue_actor(td, params=params)
         >>> print(td)
         TensorDict(
             fields={
                 action: Tensor(torch.Size([5, 4]), dtype=torch.int64),
-                action_value: Tensor(torch.Size([5, 4]), dtype=torch.float32),
-                chosen_action_value: Tensor(torch.Size([5, 1]), dtype=torch.float32),
+                action_value: Tensor(torch.Size([5, 3, 4]), dtype=torch.float32),
                 observation: Tensor(torch.Size([5, 4]), dtype=torch.float32)},
             batch_size=torch.Size([5]),
             device=None,
             is_shared=False)
 
     """
 
-    def __init__(self, *args, action_space: int = "one_hot", **kwargs):
+    def __init__(
+        self,
+        action_space: str,
+        support: torch.Tensor,
+        var_nums: Optional[int] = None,
+        action_value_key: Union[str, Tuple[str]] = None,
+        out_keys: Union[List[str], List[Tuple[str]]] = None,
+    ):
+        action_space, _ = _process_action_space_spec(action_space, None)
+        self.qvalue_model = DistributionalQValueModule(
+            action_space=action_space,
+            var_nums=var_nums,
+            support=support,
+            action_value_key=action_value_key,
+            out_keys=out_keys,
+        )
+        action_value_key = self.qvalue_model.in_keys[0]
+        if isinstance(action_value_key, tuple):
+            action_value_key = "_".join(action_value_key)
+        # uses "dispatch" to get and return tensors
+        self.action_value_key = action_value_key
+
+
+class QValueActor(SafeSequential):
+    """A Q-Value actor class.
+
+    This class appends a :class:`~.QValueModule` after the input module
+    such that the action values are used to select an action.
+
+    Args:
+        module (nn.Module): a :class:`torch.nn.Module` used to map the input to
+            the output parameter space. If the class provided is not compatible
+            with :class:`tensordict.nn.TensorDictModuleBase`, it will be
+            wrapped in a :class:`tensordict.nn.TensorDictModule` with
+            ``in_keys`` indicated by the following keyword argument.
+
+    Keyword Args:
+        in_keys (iterable of str, optional): If the class provided is not
+            compatible with :class:`tensordict.nn.TensorDictModuleBase`, this
+            list of keys indicates what observations need to be passed to the
+            wrapped module to get the action values.
+            Defaults to ``["observation"]``.
+        spec (TensorSpec, optional): Keyword-only argument.
+            Specs of the output tensor. If the module
+            outputs multiple output tensors,
+            spec characterize the space of the first output tensor.
+        safe (bool): Keyword-only argument.
+            If ``True``, the value of the output is checked against the
+            input spec. Out-of-domain sampling can
+            occur because of exploration policies or numerical under/overflow
+            issues. If this value is out of bounds, it is projected back onto the
+            desired space using the :obj:`TensorSpec.project`
+            method. Default is ``False``.
+        action_space (str or TensorSpec, optional): Action space. Must be one of
+            ``"one-hot"``, ``"mult-one-hot"``, ``"binary"`` or ``"categorical"``,
+            or an instance of the corresponding specs (:class:`torchrl.data.OneHotDiscreteTensorSpec`,
+            :class:`torchrl.data.MultiOneHotDiscreteTensorSpec`,
+            :class:`torchrl.data.BinaryDiscreteTensorSpec` or :class:`torchrl.data.DiscreteTensorSpec`).
+            This is argumets is exclusive with ``spec``, since the ``action_spec``
+            conditions the action spec.
+        action_value_key (str or tuple of str, optional): if the input module
+            is a :class:`tensordict.nn.TensorDictModuleBase` instance, it must
+            match one of its output keys. Otherwise, this string represents
+            the name of the action-value entry in the output tensordict.
+
+    .. note::
+        ``out_keys`` cannot be passed. If the module is a :class:`tensordict.nn.TensorDictModule`
+        instance, the out_keys will be updated accordingly. For regular
+        :class:`torch.nn.Module` instance, the triplet ``["action", action_value_key, "chosen_action_value"]``
+        will be used.
+
+    Examples:
+        >>> import torch
+        >>> from tensordict import TensorDict
+        >>> from tensordict.nn.functional_modules import make_functional
+        >>> from torch import nn
+        >>> from torchrl.data import OneHotDiscreteTensorSpec
+        >>> from torchrl.modules.tensordict_module.actors import QValueActor
+        >>> td = TensorDict({'observation': torch.randn(5, 4)}, [5])
+        >>> # with a regular nn.Module
+        >>> module = nn.Linear(4, 4)
+        >>> action_spec = OneHotDiscreteTensorSpec(4)
+        >>> qvalue_actor = QValueActor(module=module, spec=action_spec)
+        >>> td = qvalue_actor(td)
+        >>> print(td)
+        TensorDict(
+            fields={
+                action: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.int64, is_shared=False),
+                action_value: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                chosen_action_value: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.float32, is_shared=False),
+                observation: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.float32, is_shared=False)},
+            batch_size=torch.Size([5]),
+            device=None,
+            is_shared=False)
+        >>> # with a TensorDictModule
+        >>> td = TensorDict({'obs': torch.randn(5, 4)}, [5])
+        >>> module = TensorDictModule(lambda x: x, in_keys=["obs"], out_keys=["action_value"])
+        >>> action_spec = OneHotDiscreteTensorSpec(4)
+        >>> qvalue_actor = QValueActor(module=module, spec=action_spec)
+        >>> td = qvalue_actor(td)
+        >>> print(td)
+        TensorDict(
+            fields={
+                action: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.int64, is_shared=False),
+                action_value: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                chosen_action_value: Tensor(shape=torch.Size([5, 1]), device=cpu, dtype=torch.float32, is_shared=False),
+                obs: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.float32, is_shared=False)},
+            batch_size=torch.Size([5]),
+            device=None,
+            is_shared=False)
+
+    """
+
+    def __init__(
+        self,
+        module,
+        *,
+        in_keys=None,
+        spec=None,
+        safe=False,
+        action_space: str = None,
+        action_value_key=None,
+    ):
+        action_space, spec = _process_action_space_spec(action_space, spec)
+
+        self.action_space = action_space
+        self.action_value_key = action_value_key
+        if action_value_key is None:
+            action_value_key = "action_value"
         out_keys = [
             "action",
-            "action_value",
+            action_value_key,
             "chosen_action_value",
         ]
-        super().__init__(*args, out_keys=out_keys, **kwargs)
-        self.action_space = action_space
-        self.module.register_forward_hook(QValueHook(self.action_space))
+        if isinstance(module, TensorDictModuleBase):
+            if action_value_key not in module.out_keys:
+                raise KeyError(
+                    f"The key '{action_value_key}' is not part of the module out-keys."
+                )
+        else:
+            if in_keys is None:
+                in_keys = ["observation"]
+            module = TensorDictModule(
+                module, in_keys=in_keys, out_keys=[action_value_key]
+            )
+        if spec is None:
+            spec = CompositeSpec()
+        if isinstance(spec, CompositeSpec):
+            spec = spec.clone()
+            if "action" not in spec.keys():
+                spec["action"] = None
+        else:
+            spec = CompositeSpec(action=spec, shape=spec.shape[:-1])
+        spec[action_value_key] = None
+        spec["chosen_action_value"] = None
+        qvalue = QValueModule(
+            action_value_key=action_value_key,
+            out_keys=out_keys,
+            spec=spec,
+            safe=safe,
+            action_space=action_space,
+        )
+
+        super().__init__(module, qvalue)
 
 
 class DistributionalQValueActor(QValueActor):
-    """Distributional DQN Actor subclass.
+    """A Distributional DQN actor class.
 
-    This class hooks the module such that it returns a one-hot encoding of the argmax value on its support.
+    This class appends a :class:`~.QValueModule` after the input module
+    such that the action values are used to select an action.
+
+    Args:
+        module (nn.Module): a :class:`torch.nn.Module` used to map the input to
+            the output parameter space.
+            If the module isn't of type :class:`torchrl.modules.DistributionalDQNnet`,
+            :class:`~.DistributionalQValueActor` will ensure that a log-softmax
+            operation is applied to the action value tensor along dimension ``-2``.
+            This can be deactivated by turning off the ``make_log_softmax``
+            keyword argument.
+
+    Keyword Args:
+        in_keys (iterable of str, optional): keys to be read from input
+            tensordict and passed to the module. If it
+            contains more than one element, the values will be passed in the
+            order given by the in_keys iterable.
+            Defaults to ``["observation"]``.
+        spec (TensorSpec, optional): Keyword-only argument.
+            Specs of the output tensor. If the module
+            outputs multiple output tensors,
+            spec characterize the space of the first output tensor.
+        safe (bool): Keyword-only argument.
+            If ``True``, the value of the output is checked against the
+            input spec. Out-of-domain sampling can
+            occur because of exploration policies or numerical under/overflow
+            issues. If this value is out of bounds, it is projected back onto the
+            desired space using the :obj:`TensorSpec.project`
+            method. Default is ``False``.
+        var_nums (int, optional): if ``action_space = "mult-one-hot"``,
+            this value represents the cardinality of each
+            action component.
+        support (torch.Tensor): support of the action values.
+        action_space (str or TensorSpec, optional): Action space. Must be one of
+            ``"one-hot"``, ``"mult-one-hot"``, ``"binary"`` or ``"categorical"``,
+            or an instance of the corresponding specs (:class:`torchrl.data.OneHotDiscreteTensorSpec`,
+            :class:`torchrl.data.MultiOneHotDiscreteTensorSpec`,
+            :class:`torchrl.data.BinaryDiscreteTensorSpec` or :class:`torchrl.data.DiscreteTensorSpec`).
+            This is argumets is exclusive with ``spec``, since the ``action_spec``
+            conditions the action spec.
+        make_log_softmax (bool, optional): if ``True`` and if the module is not
+            of type :class:`torchrl.modules.DistributionalDQNnet`, a log-softmax
+            operation will be applied along dimension -2 of the action value tensor.
 
     Examples:
         >>> import torch
         >>> from tensordict import TensorDict
+        >>> from tensordict.nn import TensorDictModule, TensorDictSequential
         >>> from torch import nn
         >>> from torchrl.data import OneHotDiscreteTensorSpec
         >>> from torchrl.modules import DistributionalQValueActor, MLP
         >>> td = TensorDict({'observation': torch.randn(5, 4)}, [5])
         >>> nbins = 3
         >>> module = MLP(out_features=(nbins, 4), depth=2)
+        >>> # let us make sure that the output is a log-softmax
+        >>> module = TensorDictSequential(
+        ...     TensorDictModule(module, ["observation"], ["action_value"]),
+        ...     TensorDictModule(lambda x: x.log_softmax(-2), ["action_value"], ["action_value"]),
+        ... )
         >>> action_spec = OneHotDiscreteTensorSpec(4)
-        >>> qvalue_actor = DistributionalQValueActor(module=module, spec=action_spec, support=torch.arange(nbins))
-        >>> qvalue_actor(td)
+        >>> qvalue_actor = DistributionalQValueActor(
+        ...     module=module,
+        ...     spec=action_spec,
+        ...     support=torch.arange(nbins))
+        >>> td = qvalue_actor(td)
         >>> print(td)
         TensorDict(
             fields={
-                action: Tensor(torch.Size([5, 4]), dtype=torch.int64),
-                action_value: Tensor(torch.Size([5, 3, 4]), dtype=torch.float32),
-                observation: Tensor(torch.Size([5, 4]), dtype=torch.float32)},
+                action: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.int64, is_shared=False),
+                action_value: Tensor(shape=torch.Size([5, 3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                observation: Tensor(shape=torch.Size([5, 4]), device=cpu, dtype=torch.float32, is_shared=False)},
             batch_size=torch.Size([5]),
             device=None,
             is_shared=False)
 
     """
 
     def __init__(
         self,
-        *args,
+        module,
         support: torch.Tensor,
-        action_space: str = "one_hot",
-        **kwargs,
+        in_keys=None,
+        spec=None,
+        safe=False,
+        var_nums: Optional[int] = None,
+        action_space: str = None,
+        action_value_key: str = "action_value",
+        make_log_softmax: bool = True,
     ):
+
+        action_space, spec = _process_action_space_spec(action_space, spec)
+        self.action_space = action_space
+        self.action_value_key = action_value_key
         out_keys = [
             "action",
-            "action_value",
+            action_value_key,
         ]
-        super(QValueActor, self).__init__(*args, out_keys=out_keys, **kwargs)
-        self.action_space = action_space
+        if isinstance(module, TensorDictModuleBase):
+            if action_value_key not in module.out_keys:
+                raise KeyError(
+                    f"The key '{action_value_key}' is not part of the module out-keys."
+                )
+        else:
+            if in_keys is None:
+                in_keys = ["observation"]
+            module = TensorDictModule(
+                module, in_keys=in_keys, out_keys=[action_value_key]
+            )
+        if spec is None:
+            spec = CompositeSpec()
+        if isinstance(spec, CompositeSpec):
+            spec = spec.clone()
+            if "action" not in spec.keys():
+                spec["action"] = None
+        else:
+            spec = CompositeSpec(action=spec, shape=spec.shape[:-1])
+        spec[action_value_key] = None
 
-        self.register_buffer("support", support)
-        self.action_space = action_space
-        if not isinstance(self.module, DistributionalDQNnet):
-            self.module = DistributionalDQNnet(self.module)
-        self.module.register_forward_hook(
-            DistributionalQValueHook(self.action_space, self.support)
+        qvalue = DistributionalQValueModule(
+            action_value_key=action_value_key,
+            out_keys=out_keys,
+            spec=spec,
+            safe=safe,
+            action_space=action_space,
+            support=support,
+            var_nums=var_nums,
         )
+        self.make_log_softmax = make_log_softmax
+        if make_log_softmax and not isinstance(module, DistributionalDQNnet):
+            log_softmax_module = DistributionalDQNnet(
+                in_keys=qvalue.in_keys, out_keys=qvalue.in_keys
+            )
+            super(QValueActor, self).__init__(module, log_softmax_module, qvalue)
+        else:
+            super(QValueActor, self).__init__(module, qvalue)
+        self.register_buffer("support", support)
 
 
 class ActorValueOperator(SafeSequential):
     """Actor-value operator.
 
-    This class wraps together an actor and a value model that share a common observation embedding network:
+    This class wraps together an actor and a value model that share a common
+    observation embedding network:
 
     .. aafig::
         :aspect: 60
         :scale: 120
         :proportional:
         :textual:
 
-            +-------------+
-            |"Observation"|
-            +-------------+
-                   |
-                   v
-            +--------------+
-            |"hidden state"|
-            +--------------+
-            |      |       |
-            v      |       v
-            actor  |       critic
-            |      |       |
-            v      |       v
-         +--------+|+-------+
-         |"action"|||"value"|
-         +--------+|+-------+
+               +---------------+
+               |Observation (s)|
+               +---------------+
+                        |
+                       "common"
+                        |
+                        v
+                 +------------+
+                 |Hidden state|
+                 +------------+
+                   |         |
+                  actor     critic
+                   |         |
+                   v         v
+        +-------------+ +------------+
+        |Action (a(s))| |Value (V(s))|
+        +-------------+ +------------+
+
+    .. note::
+      For a similar class that returns an action and a Quality value :math:`Q(s, a)`
+      see :class:`~.ActorCriticOperator`. For a version without common embeddig
+      refet to :class:`~.ActorCriticWrapper`.
 
     To facilitate the workflow, this  class comes with a get_policy_operator() and get_value_operator() methods, which
-    will both return a stand-alone TDModule with the dedicated functionality.
+    will both return a standalone TDModule with the dedicated functionality.
 
     Args:
-        common_operator (SafeModule): a common operator that reads observations and produces a hidden variable
-        policy_operator (SafeModule): a policy operator that reads the hidden variable and returns an action
-        value_operator (SafeModule): a value operator, that reads the hidden variable and returns a value
+        common_operator (TensorDictModule): a common operator that reads
+            observations and produces a hidden variable
+        policy_operator (TensorDictModule): a policy operator that reads the
+            hidden variable and returns an action
+        value_operator (TensorDictModule): a value operator, that reads the
+            hidden variable and returns a value
 
     Examples:
         >>> import torch
         >>> from tensordict import TensorDict
         >>> from torchrl.modules import ProbabilisticActor, SafeModule
-        >>> from torchrl.data import UnboundedContinuousTensorSpec, BoundedTensorSpec
         >>> from torchrl.modules import ValueOperator, TanhNormal, ActorValueOperator, NormalParamWrapper
-        >>> spec_hidden = UnboundedContinuousTensorSpec(4)
         >>> module_hidden = torch.nn.Linear(4, 4)
         >>> td_module_hidden = SafeModule(
         ...    module=module_hidden,
-        ...    spec=spec_hidden,
         ...    in_keys=["observation"],
         ...    out_keys=["hidden"],
         ...    )
-        >>> spec_action = BoundedTensorSpec(-1, 1, torch.Size([8]))
-        >>> module_action = SafeModule(
+        >>> module_action = TensorDictModule(
         ...     NormalParamWrapper(torch.nn.Linear(4, 8)),
         ...     in_keys=["hidden"],
         ...     out_keys=["loc", "scale"],
         ...     )
         >>> td_module_action = ProbabilisticActor(
         ...    module=module_action,
-        ...    spec=spec_action,
-        ...    dist_in_keys=["loc", "scale"],
-        ...    sample_out_key=["action"],
+        ...    in_keys=["loc", "scale"],
+        ...    out_keys=["action"],
         ...    distribution_class=TanhNormal,
         ...    return_log_prob=True,
         ...    )
         >>> module_value = torch.nn.Linear(4, 1)
         >>> td_module_value = ValueOperator(
         ...    module=module_value,
         ...    in_keys=["hidden"],
         ...    )
         >>> td_module = ActorValueOperator(td_module_hidden, td_module_action, td_module_value)
         >>> td = TensorDict({"observation": torch.randn(3, 4)}, [3,])
         >>> td_clone = td_module(td.clone())
         >>> print(td_clone)
         TensorDict(
             fields={
-                action: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                hidden: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                loc: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                observation: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                sample_log_prob: Tensor(torch.Size([3, 1]), dtype=torch.float32),
-                scale: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                state_value: Tensor(torch.Size([3, 1]), dtype=torch.float32)},
+                action: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                hidden: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                loc: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                sample_log_prob: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),
+                scale: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                state_value: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},
             batch_size=torch.Size([3]),
             device=None,
             is_shared=False)
         >>> td_clone = td_module.get_policy_operator()(td.clone())
         >>> print(td_clone)  # no value
         TensorDict(
             fields={
-                action: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                hidden: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                loc: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                observation: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                sample_log_prob: Tensor(torch.Size([3, 1]), dtype=torch.float32),
-                scale: Tensor(torch.Size([3, 4]), dtype=torch.float32)},
+                action: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                hidden: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                loc: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                sample_log_prob: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),
+                scale: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False)},
             batch_size=torch.Size([3]),
             device=None,
             is_shared=False)
         >>> td_clone = td_module.get_value_operator()(td.clone())
         >>> print(td_clone)  # no action
         TensorDict(
             fields={
-                hidden: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                observation: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                state_value: Tensor(torch.Size([3, 1]), dtype=torch.float32)},
+                hidden: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                state_value: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},
             batch_size=torch.Size([3]),
             device=None,
             is_shared=False)
 
     """
 
     def __init__(
         self,
-        common_operator: SafeModule,
-        policy_operator: SafeModule,
-        value_operator: SafeModule,
+        common_operator: TensorDictModule,
+        policy_operator: TensorDictModule,
+        value_operator: TensorDictModule,
     ):
         super().__init__(
             common_operator,
             policy_operator,
             value_operator,
         )
 
     def get_policy_operator(self) -> SafeSequential:
-        """Returns a stand-alone policy operator that maps an observation to an action."""
-        if isinstance(self.module[1], SafeProbabilisticSequential):
-            return SafeProbabilisticSequential(self.module[0], *self.module[1].module)
+        """Returns a standalone policy operator that maps an observation to an action."""
+        if isinstance(self.module[1], SafeProbabilisticTensorDictSequential):
+            return SafeProbabilisticTensorDictSequential(
+                self.module[0], *self.module[1].module
+            )
         return SafeSequential(self.module[0], self.module[1])
 
     def get_value_operator(self) -> SafeSequential:
-        """Returns a stand-alone value network operator that maps an observation to a value estimate."""
+        """Returns a standalone value network operator that maps an observation to a value estimate."""
         return SafeSequential(self.module[0], self.module[2])
 
+    def get_policy_head(self) -> SafeSequential:
+        """Returns the policy head."""
+        return self.module[1]
+
+    def get_value_head(self) -> SafeSequential:
+        """Returns the value head."""
+        return self.module[2]
+
 
 class ActorCriticOperator(ActorValueOperator):
     """Actor-critic operator.
 
-    This class wraps together an actor and a value model that share a common observation embedding network:
+    This class wraps together an actor and a value model that share a common
+    observation embedding network:
 
     .. aafig::
         :aspect: 60
         :scale: 120
         :proportional:
         :textual:
 
-          +-----------+
-          |Observation|
-          +-----------+
-            |
-            v
-            actor
-            |
-            v
-        +------+
-        |action| --> critic
-        +------+      |
-                      v
-                   +-----+
-                   |value|
-                   +-----+
+                 +---------------+
+                 |Observation (s)|
+                 +---------------+
+                         |
+                         v
+                        "common"
+                         |
+                         v
+                  +------------+
+                  |Hidden state|
+                  +------------+
+                    |        |
+                    v        v
+                   actor --> critic
+                    |        |
+                    v        v
+            +-------------+ +----------------+
+            |Action (a(s))| |Quality (Q(s,a))|
+            +-------------+ +----------------+
+
+    .. note::
+      For a similar class that returns an action and a state-value :math:`V(s)`
+      see :class:`~.ActorValueOperator`.
+
 
     To facilitate the workflow, this  class comes with a get_policy_operator() method, which
-    will both return a stand-alone TDModule with the dedicated functionality. The get_critic_operator will return the
+    will both return a standalone TDModule with the dedicated functionality. The get_critic_operator will return the
     parent object, as the value is computed based on the policy output.
 
     Args:
-        common_operator (SafeModule): a common operator that reads observations and produces a hidden variable
-        policy_operator (SafeModule): a policy operator that reads the hidden variable and returns an action
-        value_operator (SafeModule): a value operator, that reads the hidden variable and returns a value
+        common_operator (TensorDictModule): a common operator that reads
+            observations and produces a hidden variable
+        policy_operator (TensorDictModule): a policy operator that reads the
+            hidden variable and returns an action
+        value_operator (TensorDictModule): a value operator, that reads the
+            hidden variable and returns a value
 
     Examples:
         >>> import torch
         >>> from tensordict import TensorDict
-        >>> from torchrl.modules import ProbabilisticActor, SafeModule
-        >>> from torchrl.data import UnboundedContinuousTensorSpec, BoundedTensorSpec
+        >>> from torchrl.modules import ProbabilisticActor
         >>> from torchrl.modules import  ValueOperator, TanhNormal, ActorCriticOperator, NormalParamWrapper, MLP
-        >>> spec_hidden = UnboundedContinuousTensorSpec(4)
         >>> module_hidden = torch.nn.Linear(4, 4)
         >>> td_module_hidden = SafeModule(
         ...    module=module_hidden,
-        ...    spec=spec_hidden,
         ...    in_keys=["observation"],
         ...    out_keys=["hidden"],
         ...    )
-        >>> spec_action = BoundedTensorSpec(-1, 1, torch.Size([8]))
         >>> module_action = NormalParamWrapper(torch.nn.Linear(4, 8))
-        >>> module_action = SafeModule(module_action, in_keys=["hidden"], out_keys=["loc", "scale"])
+        >>> module_action = TensorDictModule(module_action, in_keys=["hidden"], out_keys=["loc", "scale"])
         >>> td_module_action = ProbabilisticActor(
         ...    module=module_action,
-        ...    spec=spec_action,
-        ...    dist_in_keys=["loc", "scale"],
-        ...    sample_out_key=["action"],
+        ...    in_keys=["loc", "scale"],
+        ...    out_keys=["action"],
         ...    distribution_class=TanhNormal,
         ...    return_log_prob=True,
         ...    )
         >>> module_value = MLP(in_features=8, out_features=1, num_cells=[])
         >>> td_module_value = ValueOperator(
         ...    module=module_value,
         ...    in_keys=["hidden", "action"],
@@ -736,186 +1378,204 @@
         ...    )
         >>> td_module = ActorCriticOperator(td_module_hidden, td_module_action, td_module_value)
         >>> td = TensorDict({"observation": torch.randn(3, 4)}, [3,])
         >>> td_clone = td_module(td.clone())
         >>> print(td_clone)
         TensorDict(
             fields={
-                action: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                hidden: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                loc: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                observation: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                sample_log_prob: Tensor(torch.Size([3, 1]), dtype=torch.float32),
-                scale: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                state_action_value: Tensor(torch.Size([3, 1]), dtype=torch.float32)},
+                action: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                hidden: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                loc: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                sample_log_prob: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),
+                scale: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                state_action_value: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},
             batch_size=torch.Size([3]),
             device=None,
             is_shared=False)
         >>> td_clone = td_module.get_policy_operator()(td.clone())
         >>> print(td_clone)  # no value
         TensorDict(
             fields={
-                action: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                hidden: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                loc: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                observation: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                sample_log_prob: Tensor(torch.Size([3, 1]), dtype=torch.float32),
-                scale: Tensor(torch.Size([3, 4]), dtype=torch.float32)},
+                action: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                hidden: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                loc: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                sample_log_prob: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),
+                scale: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False)},
             batch_size=torch.Size([3]),
             device=None,
             is_shared=False)
         >>> td_clone = td_module.get_critic_operator()(td.clone())
         >>> print(td_clone)  # no action
         TensorDict(
             fields={
-                action: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                hidden: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                loc: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                observation: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                sample_log_prob: Tensor(torch.Size([3, 1]), dtype=torch.float32),
-                scale: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                state_action_value: Tensor(torch.Size([3, 1]), dtype=torch.float32)},
+                action: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                hidden: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                loc: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                sample_log_prob: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),
+                scale: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                state_action_value: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},
             batch_size=torch.Size([3]),
             device=None,
             is_shared=False)
 
     """
 
-    def __init__(self, *args, **kwargs):
-        super().__init__(*args, **kwargs)
+    def __init__(
+        self,
+        common_operator: TensorDictModule,
+        policy_operator: TensorDictModule,
+        value_operator: TensorDictModule,
+    ):
+        super().__init__(
+            common_operator,
+            policy_operator,
+            value_operator,
+        )
         if self[2].out_keys[0] == "state_value":
             raise RuntimeError(
                 "Value out_key is state_value, which may lead to errors in downstream usages"
                 "of that module. Consider setting `'state_action_value'` instead."
                 "Make also sure that `'action'` is amongst the input keys of the value network."
                 "If you are confident that action should not be used to compute the value, please"
                 "user `ActorValueOperator` instead."
             )
 
     def get_critic_operator(self) -> TensorDictModuleWrapper:
-        """Returns a stand-alone critic network operator that maps a state-action pair to a critic estimate."""
+        """Returns a standalone critic network operator that maps a state-action pair to a critic estimate."""
         return self
 
     def get_value_operator(self) -> TensorDictModuleWrapper:
         raise RuntimeError(
             "value_operator is the term used for operators that associate a value with a "
             "state/observation. This class computes the value of a state-action pair: to get the "
             "network computing this value, please call td_sequence.get_critic_operator()"
         )
 
+    def get_policy_head(self) -> SafeSequential:
+        """Returns the policy head."""
+        return self.module[1]
+
+    def get_value_head(self) -> SafeSequential:
+        """Returns the value head."""
+        return self.module[2]
+
 
 class ActorCriticWrapper(SafeSequential):
     """Actor-value operator without common module.
 
     This class wraps together an actor and a value model that do not share a common observation embedding network:
 
     .. aafig::
         :aspect: 60
         :scale: 120
         :proportional:
         :textual:
 
-          +-----------+
-          |Observation|
-          +-----------+
-          |     |   |
-          v     |   v
-          actor |   critic
-          |     |   |
-          v     |   v
-        +------+|+-------+
-        |action||| value |
-        +------+|+-------+
+                 +---------------+
+                 |Observation (s)|
+                 +---------------+
+                    |    |    |
+                    v    |    v
+                   actor |    critic
+                    |    |    |
+                    v    |    v
+        +-------------+  |  +------------+
+        |Action (a(s))|  |  |Value (V(s))|
+        +-------------+  |  +------------+
+
 
     To facilitate the workflow, this  class comes with a get_policy_operator() and get_value_operator() methods, which
-    will both return a stand-alone TDModule with the dedicated functionality.
+    will both return a standalone TDModule with the dedicated functionality.
 
     Args:
-        policy_operator (SafeModule): a policy operator that reads the hidden variable and returns an action
-        value_operator (SafeModule): a value operator, that reads the hidden variable and returns a value
+        policy_operator (TensorDictModule): a policy operator that reads the hidden variable and returns an action
+        value_operator (TensorDictModule): a value operator, that reads the hidden variable and returns a value
 
     Examples:
         >>> import torch
         >>> from tensordict import TensorDict
-        >>> from torchrl.data import UnboundedContinuousTensorSpec, BoundedTensorSpec
+        >>> from tensordict.nn import TensorDictModule
         >>> from torchrl.modules import (
-                ActorCriticWrapper,
-                ProbabilisticActor,
-                NormalParamWrapper,
-                SafeModule,
-                TanhNormal,
-                ValueOperator,
-            )
-        >>> action_spec = BoundedTensorSpec(-1, 1, torch.Size([8]))
-        >>> action_module = SafeModule(
-                NormalParamWrapper(torch.nn.Linear(4, 8)),
-                in_keys=["observation"],
-                out_keys=["loc", "scale"],
-            )
+        ...      ActorCriticWrapper,
+        ...      ProbabilisticActor,
+        ...      NormalParamWrapper,
+        ...      TanhNormal,
+        ...      ValueOperator,
+        ...  )
+        >>> action_module = TensorDictModule(
+        ...        NormalParamWrapper(torch.nn.Linear(4, 8)),
+        ...        in_keys=["observation"],
+        ...        out_keys=["loc", "scale"],
+        ...    )
         >>> td_module_action = ProbabilisticActor(
         ...    module=action_module,
-        ...    spec=action_spec,
-        ...    dist_in_keys=["loc", "scale"],
+        ...    in_keys=["loc", "scale"],
         ...    distribution_class=TanhNormal,
         ...    return_log_prob=True,
         ...    )
         >>> module_value = torch.nn.Linear(4, 1)
         >>> td_module_value = ValueOperator(
         ...    module=module_value,
         ...    in_keys=["observation"],
         ...    )
         >>> td_module = ActorCriticWrapper(td_module_action, td_module_value)
         >>> td = TensorDict({"observation": torch.randn(3, 4)}, [3,])
         >>> td_clone = td_module(td.clone())
         >>> print(td_clone)
         TensorDict(
             fields={
-                action: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                loc: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                observation: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                sample_log_prob: Tensor(torch.Size([3, 1]), dtype=torch.float32),
-                scale: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                state_value: Tensor(torch.Size([3, 1]), dtype=torch.float32)},
+                action: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                loc: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                sample_log_prob: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),
+                scale: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                state_value: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},
             batch_size=torch.Size([3]),
             device=None,
             is_shared=False)
         >>> td_clone = td_module.get_policy_operator()(td.clone())
         >>> print(td_clone)  # no value
         TensorDict(
             fields={
-                action: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                loc: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                observation: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                sample_log_prob: Tensor(torch.Size([3, 1]), dtype=torch.float32),
-                scale: Tensor(torch.Size([3, 4]), dtype=torch.float32)},
+                action: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                loc: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                sample_log_prob: Tensor(shape=torch.Size([3]), device=cpu, dtype=torch.float32, is_shared=False),
+                scale: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False)},
             batch_size=torch.Size([3]),
             device=None,
             is_shared=False)
         >>> td_clone = td_module.get_value_operator()(td.clone())
         >>> print(td_clone)  # no action
         TensorDict(
             fields={
-                observation: Tensor(torch.Size([3, 4]), dtype=torch.float32),
-                state_value: Tensor(torch.Size([3, 1]), dtype=torch.float32)},
+                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),
+                state_value: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False)},
             batch_size=torch.Size([3]),
             device=None,
             is_shared=False)
 
     """
 
     def __init__(
         self,
-        policy_operator: SafeModule,
-        value_operator: SafeModule,
+        policy_operator: TensorDictModule,
+        value_operator: TensorDictModule,
     ):
         super().__init__(
             policy_operator,
             value_operator,
         )
 
     def get_policy_operator(self) -> SafeSequential:
-        """Returns a stand-alone policy operator that maps an observation to an action."""
+        """Returns a standalone policy operator that maps an observation to an action."""
         return self.module[0]
 
     def get_value_operator(self) -> SafeSequential:
-        """Returns a stand-alone value network operator that maps an observation to a value estimate."""
+        """Returns a standalone value network operator that maps an observation to a value estimate."""
         return self.module[1]
+
+    get_policy_head = get_policy_operator
+    get_value_head = get_value_operator
```

## torchrl/modules/tensordict_module/common.py

```diff
@@ -8,14 +8,20 @@
 import inspect
 import re
 import warnings
 from typing import Iterable, Optional, Type, Union
 
 import torch
 
+from tensordict.nn import TensorDictModule
+from tensordict.tensordict import TensorDictBase
+from torch import nn
+
+from torchrl.data.tensor_specs import CompositeSpec, TensorSpec
+
 from torchrl.data.utils import DEVICE_TYPING
 
 _has_functorch = False
 try:
     from functorch import FunctionalModule, FunctionalModuleWithBuffers
 
     _has_functorch = True
@@ -29,21 +35,14 @@
     class FunctionalModule:  # noqa: D101
         pass
 
     class FunctionalModuleWithBuffers:  # noqa: D101
         pass
 
 
-from tensordict.nn import TensorDictModule
-from tensordict.tensordict import TensorDictBase
-from torch import nn
-
-from torchrl.data.tensor_specs import CompositeSpec, TensorSpec
-
-
 def _check_all_str(list_of_str, first_level=True):
     if isinstance(list_of_str, str) and first_level:
         raise RuntimeError(
             f"Expected a list of strings but got a string: {list_of_str}"
         )
     elif not isinstance(list_of_str, str):
         try:
@@ -55,28 +54,35 @@
 
 
 def _forward_hook_safe_action(module, tensordict_in, tensordict_out):
     try:
         spec = module.spec
         if len(module.out_keys) > 1 and not isinstance(spec, CompositeSpec):
             raise RuntimeError(
-                "safe SafeModules with multiple out_keys require a CompositeSpec with matching keys. Got "
+                "safe TensorDictModules with multiple out_keys require a CompositeSpec with matching keys. Got "
                 f"keys {module.out_keys}."
             )
         elif not isinstance(spec, CompositeSpec):
             out_key = module.out_keys[0]
             keys = [out_key]
             values = [spec]
         else:
             keys = list(spec.keys(True, True))
             values = [spec[key] for key in keys]
         for _spec, _key in zip(values, keys):
             if _spec is None:
                 continue
-            if not _spec.is_in(tensordict_out.get(_key)):
+            item = tensordict_out.get(_key, None)
+            if item is None:
+                # this will happen when an exploration (e.g. OU) writes a key only
+                # during exploration, but is missing otherwise.
+                # it's fine since what we want here it to make sure that a key
+                # is within bounds if it is present
+                continue
+            if not _spec.is_in(item):
                 try:
                     tensordict_out.set_(
                         _key,
                         _spec.project(tensordict_out.get(_key)),
                     )
                 except RuntimeError:
                     tensordict_out.set(
@@ -92,45 +98,54 @@
                 "vmap cannot be used with safe=True, consider turning the safe mode off."
             ) from err
         else:
             raise err
 
 
 class SafeModule(TensorDictModule):
-    """An :obj:``SafeModule`` is a :obj:``tensordict.nn.TensorDictModule`` subclass that accepts a :obj:``TensorSpec`` as argument to control the output domain.
+    """:class:`tensordict.nn.TensorDictModule` subclass that accepts a :class:`~torchrl.data.TensorSpec` as argument to control the output domain.
 
     Args:
-        module (nn.Module): a nn.Module used to map the input to the output parameter space. Can be a functional
-            module (FunctionalModule or FunctionalModuleWithBuffers), in which case the :obj:`forward` method will expect
+        module (nn.Module): a nn.Module used to map the input to the output
+            parameter space. Can be a functional
+            module (FunctionalModule or FunctionalModuleWithBuffers), in which
+            case the :obj:`forward` method will expect
             the params (and possibly) buffers keyword arguments.
-        in_keys (iterable of str): keys to be read from input tensordict and passed to the module. If it
-            contains more than one element, the values will be passed in the order given by the in_keys iterable.
-        out_keys (iterable of str): keys to be written to the input tensordict. The length of out_keys must match the
-            number of tensors returned by the embedded module. Using "_" as a key avoid writing tensor to output.
-        spec (TensorSpec): specs of the output tensor. If the module outputs multiple output tensors,
+        in_keys (iterable of str): keys to be read from input tensordict and
+            passed to the module. If it
+            contains more than one element, the values will be passed in the
+            order given by the in_keys iterable.
+        out_keys (iterable of str): keys to be written to the input tensordict.
+            The length of out_keys must match the
+            number of tensors returned by the embedded module. Using "_" as a
+            key avoid writing tensor to output.
+        spec (TensorSpec, optional): specs of the output tensor. If the module
+            outputs multiple output tensors,
             spec characterize the space of the first output tensor.
-        safe (bool): if True, the value of the output is checked against the input spec. Out-of-domain sampling can
+        safe (bool): if ``True``, the value of the output is checked against the
+            input spec. Out-of-domain sampling can
             occur because of exploration policies or numerical under/overflow issues.
-            If this value is out of bounds, it is projected back onto the desired space using the :obj:`TensorSpec.project`
-            method. Default is :obj:`False`.
+            If this value is out of bounds, it is projected back onto the
+            desired space using the :obj:`TensorSpec.project`
+            method. Default is ``False``.
 
-    Embedding a neural network in a SafeModule only requires to specify the input and output keys. The domain spec can
-        be passed along if needed. SafeModule support functional and regular :obj:`nn.Module` objects. In the functional
+    Embedding a neural network in a TensorDictModule only requires to specify the input and output keys. The domain spec can
+        be passed along if needed. TensorDictModule support functional and regular :obj:`nn.Module` objects. In the functional
         case, the 'params' (and 'buffers') keyword argument must be specified:
 
     Examples:
         >>> import torch
         >>> from tensordict import TensorDict
         >>> from tensordict.nn.functional_modules import make_functional
         >>> from torchrl.data import UnboundedContinuousTensorSpec
-        >>> from torchrl.modules import SafeModule
+        >>> from torchrl.modules import TensorDictModule
         >>> td = TensorDict({"input": torch.randn(3, 4), "hidden": torch.randn(3, 8)}, [3,])
         >>> spec = UnboundedContinuousTensorSpec(8)
         >>> module = torch.nn.GRUCell(4, 8)
-        >>> td_fmodule = SafeModule(
+        >>> td_fmodule = TensorDictModule(
         ...    module=module,
         ...    spec=spec,
         ...    in_keys=["input", "hidden"],
         ...    out_keys=["output"],
         ...    )
         >>> params = make_functional(td_fmodule)
         >>> td_functional = td_fmodule(td.clone(), params=params)
@@ -141,15 +156,15 @@
                 input: Tensor(torch.Size([3, 4]), dtype=torch.float32),
                 output: Tensor(torch.Size([3, 8]), dtype=torch.float32)},
             batch_size=torch.Size([3]),
             device=None,
             is_shared=False)
 
     In the stateful case:
-        >>> td_module = SafeModule(
+        >>> td_module = TensorDictModule(
         ...    module=torch.nn.GRUCell(4, 8),
         ...    spec=spec,
         ...    in_keys=["input", "hidden"],
         ...    out_keys=["output"],
         ...    )
         >>> td_stateful = td_module(td.clone())
         >>> print(td_stateful)
@@ -161,15 +176,15 @@
             batch_size=torch.Size([3]),
             device=None,
             is_shared=False)
 
     One can use a vmap operator to call the functional module. In this case the tensordict is expanded to match the
     batch size (i.e. the tensordict isn't modified in-place anymore):
         >>> # Model ensemble using vmap
-        >>> from functorch import vmap
+        >>> from torch import vmap
         >>> params_repeat = params.expand(4, *params.shape)
         >>> td_vmap = vmap(td_fmodule, (None, 0))(td.clone(), params_repeat)
         >>> print(td_vmap)
         TensorDict(
             fields={
                 hidden: Tensor(torch.Size([4, 3, 8]), dtype=torch.float32),
                 input: Tensor(torch.Size([4, 3, 4]), dtype=torch.float32),
@@ -179,29 +194,31 @@
             is_shared=False)
 
     """
 
     def __init__(
         self,
         module: Union[
-            FunctionalModule, FunctionalModuleWithBuffers, SafeModule, nn.Module
+            FunctionalModule, FunctionalModuleWithBuffers, TensorDictModule, nn.Module
         ],
         in_keys: Iterable[str],
         out_keys: Iterable[str],
         spec: Optional[TensorSpec] = None,
         safe: bool = False,
     ):
         super().__init__(module, in_keys, out_keys)
+        self.register_spec(safe=safe, spec=spec)
 
+    def register_spec(self, safe, spec):
         if spec is not None and not isinstance(spec, TensorSpec):
             raise TypeError("spec must be a TensorSpec subclass")
         elif spec is not None and not isinstance(spec, CompositeSpec):
             if len(self.out_keys) > 1:
                 raise RuntimeError(
-                    f"got more than one out_key for the SafeModule: {self.out_keys},\nbut only one spec. "
+                    f"got more than one out_key for the TensorDictModule: {self.out_keys},\nbut only one spec. "
                     "Consider using a CompositeSpec object or no spec at all."
                 )
             spec = CompositeSpec(**{self.out_keys[0]: spec})
         elif spec is not None and isinstance(spec, CompositeSpec):
             if "_" in spec.keys():
                 warnings.warn('got a spec with key "_": it will be ignored')
         elif spec is None:
@@ -222,15 +239,15 @@
         self.safe = safe
         if safe:
             if spec is None or (
                 isinstance(spec, CompositeSpec)
                 and all(_spec is None for _spec in spec.values())
             ):
                 raise RuntimeError(
-                    "`SafeModule(spec=None, safe=True)` is not a valid configuration as the tensor "
+                    "`TensorDictModule(spec=None, safe=True)` is not a valid configuration as the tensor "
                     "specs are not specified"
                 )
             self.register_forward_hook(_forward_hook_safe_action)
 
     @property
     def spec(self) -> CompositeSpec:
         return self._spec
@@ -256,26 +273,26 @@
 
         """
         key0 = self.out_keys[0]
         tensordict.set(key0, self.spec.rand(tensordict.batch_size))
         return tensordict
 
     def random_sample(self, tensordict: TensorDictBase) -> TensorDictBase:
-        """See :obj:`SafeModule.random(...)`."""
+        """See :obj:`TensorDictModule.random(...)`."""
         return self.random(tensordict)
 
-    def to(self, dest: Union[torch.dtype, DEVICE_TYPING]) -> SafeModule:
+    def to(self, dest: Union[torch.dtype, DEVICE_TYPING]) -> TensorDictModule:
         if hasattr(self, "spec") and self.spec is not None:
             self.spec = self.spec.to(dest)
         out = super().to(dest)
         return out
 
 
-def is_tensordict_compatible(module: Union[SafeModule, nn.Module]):
-    """Returns `True` if a module can be used as a SafeModule, and False if it can't.
+def is_tensordict_compatible(module: Union[TensorDictModule, nn.Module]):
+    """Returns `True` if a module can be used as a TensorDictModule, and False if it can't.
 
     If the signature is misleading an error is raised.
 
     Examples:
         >>> module = nn.Linear(3, 4)
         >>> is_tensordict_compatible(module)
         False
@@ -305,47 +322,50 @@
         ...     is_tensordict_compatible(tensordict_module)
         ... except TypeError:
         ...     print("passing")
         passing
     """
     sig = inspect.signature(module.forward)
 
-    if isinstance(module, SafeModule) or (
+    if isinstance(module, TensorDictModule) or (
         len(sig.parameters) == 1
         and hasattr(module, "in_keys")
         and hasattr(module, "out_keys")
     ):
-        # if the module is a SafeModule or takes a single argument and defines
+        # if the module is a TensorDictModule or takes a single argument and defines
         # in_keys and out_keys then we assume it can already deal with TensorDict input
         # to forward and we return True
         return True
     elif not hasattr(module, "in_keys") and not hasattr(module, "out_keys"):
-        # if it's not a SafeModule, and in_keys and out_keys are not defined then
+        # if it's not a TensorDictModule, and in_keys and out_keys are not defined then
         # we assume no TensorDict compatibility and will try to wrap it.
         return False
 
-    # if in_keys or out_keys were defined but module is not a SafeModule or
+    # if in_keys or out_keys were defined but module is not a TensorDictModule or
     # accepts multiple arguments then it's likely the user is trying to do something
     # that will have undetermined behaviour, we raise an error
     raise TypeError(
         "Received a module that defines in_keys or out_keys and also expects multiple "
         "arguments to module.forward. If the module is compatible with TensorDict, it "
         "should take a single argument of type TensorDict to module.forward and define "
         "both in_keys and out_keys. Alternatively, module.forward can accept "
         "arbitrarily many tensor inputs and leave in_keys and out_keys undefined and "
-        "TorchRL will attempt to automatically wrap the module with a SafeModule."
+        "TorchRL will attempt to automatically wrap the module with a TensorDictModule."
     )
 
 
 def ensure_tensordict_compatible(
-    module: Union[FunctionalModule, FunctionalModuleWithBuffers, SafeModule, nn.Module],
+    module: Union[
+        FunctionalModule, FunctionalModuleWithBuffers, TensorDictModule, nn.Module
+    ],
     in_keys: Optional[Iterable[str]] = None,
     out_keys: Optional[Iterable[str]] = None,
     safe: bool = False,
-    wrapper_type: Optional[Type] = SafeModule,
+    wrapper_type: Optional[Type] = TensorDictModule,
+    **kwargs,
 ):
     """Checks and ensures an object with forward method is TensorDict compatible."""
     if is_tensordict_compatible(module):
         if in_keys is not None and set(in_keys) != set(module.in_keys):
             raise TypeError(
                 f"Arguments to module.forward ({set(module.in_keys)}) doesn't match "
                 f"with the expected TensorDict in_keys ({set(in_keys)})."
@@ -357,28 +377,27 @@
             )
         # return module itself if it's already tensordict compatible
         return module
 
     if not isinstance(module, nn.Module):
         raise TypeError(
             "Argument to ensure_tensordict_compatible should be either "
-            "a SafeModule or an nn.Module"
+            "a TensorDictModule or an nn.Module"
         )
 
     sig = inspect.signature(module.forward)
     if in_keys is not None and set(sig.parameters) != set(in_keys):
         raise TypeError(
             "Arguments to module.forward are incompatible with entries in "
             "env.observation_spec. If you want TorchRL to automatically "
-            "wrap your module with a SafeModule then the arguments "
+            "wrap your module with a TensorDictModule then the arguments "
             "to module must correspond one-to-one with entries in "
             "in_keys. For more complex behaviour and more control you can "
-            "consider writing your own SafeModule."
+            "consider writing your own TensorDictModule."
         )
 
     # TODO: Check whether out_keys match (at least in number) if they are provided.
-    kwargs = {}
     if in_keys is not None:
         kwargs["in_keys"] = in_keys
     if out_keys is not None:
         kwargs["out_keys"] = out_keys
     return wrapper_type(module, **kwargs)
```

## torchrl/modules/tensordict_module/exploration.py

```diff
@@ -1,102 +1,123 @@
 # Copyright (c) Meta Platforms, Inc. and affiliates.
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
-
+import warnings
 from typing import Optional, Union
 
 import numpy as np
 import torch
-from tensordict.nn import TensorDictModuleWrapper
+from tensordict.nn import TensorDictModule, TensorDictModuleWrapper
 from tensordict.tensordict import TensorDictBase
 from tensordict.utils import expand_as_right
 
-from torchrl.data.tensor_specs import CompositeSpec, TensorSpec
-from torchrl.envs.utils import exploration_mode
-from torchrl.modules.tensordict_module.common import (
-    _forward_hook_safe_action,
-    SafeModule,
+from torchrl.data.tensor_specs import (
+    CompositeSpec,
+    TensorSpec,
+    UnboundedContinuousTensorSpec,
 )
-
+from torchrl.envs.utils import exploration_type, ExplorationType
+from torchrl.modules.tensordict_module.common import _forward_hook_safe_action
 
 __all__ = [
     "EGreedyWrapper",
     "AdditiveGaussianWrapper",
     "OrnsteinUhlenbeckProcessWrapper",
 ]
 
 
 class EGreedyWrapper(TensorDictModuleWrapper):
     """Epsilon-Greedy PO wrapper.
 
     Args:
-        policy (SafeModule): a deterministic policy.
+        policy (TensorDictModule): a deterministic policy.
+
+    Keyword Args:
         eps_init (scalar, optional): initial epsilon value.
             default: 1.0
         eps_end (scalar, optional): final epsilon value.
             default: 0.1
         annealing_num_steps (int, optional): number of steps it will take for epsilon to reach the eps_end value
         action_key (str, optional): if the policy module has more than one output key,
             its output spec will be of type CompositeSpec. One needs to know where to
             find the action spec.
             Default is "action".
         spec (TensorSpec, optional): if provided, the sampled action will be
             projected onto the valid action space once explored. If not provided,
             the exploration wrapper will attempt to recover it from the policy.
 
+    .. note::
+        Once an environment has been wrapped in :class:`EGreedyWrapper`, it is
+        crucial to incorporate a call to :meth:`~.step` in the training loop
+        to update the exploration factor.
+        Since it is not easy to capture this omission no warning or exception
+        will be raised if this is ommitted!
+
     Examples:
         >>> import torch
         >>> from tensordict import TensorDict
         >>> from torchrl.modules import EGreedyWrapper, Actor
         >>> from torchrl.data import BoundedTensorSpec
         >>> torch.manual_seed(0)
         >>> spec = BoundedTensorSpec(-1, 1, torch.Size([4]))
         >>> module = torch.nn.Linear(4, 4, bias=False)
         >>> policy = Actor(spec=spec, module=module)
         >>> explorative_policy = EGreedyWrapper(policy, eps_init=0.2)
         >>> td = TensorDict({"observation": torch.zeros(10, 4)}, batch_size=[10])
         >>> print(explorative_policy(td).get("action"))
         tensor([[ 0.0000,  0.0000,  0.0000,  0.0000],
                 [ 0.0000,  0.0000,  0.0000,  0.0000],
-                [-0.6986, -0.9366, -0.5837,  0.8596],
+                [ 0.9055, -0.9277, -0.6295, -0.2532],
                 [ 0.0000,  0.0000,  0.0000,  0.0000],
                 [ 0.0000,  0.0000,  0.0000,  0.0000],
                 [ 0.0000,  0.0000,  0.0000,  0.0000],
                 [ 0.0000,  0.0000,  0.0000,  0.0000],
                 [ 0.0000,  0.0000,  0.0000,  0.0000],
                 [ 0.0000,  0.0000,  0.0000,  0.0000],
                 [ 0.0000,  0.0000,  0.0000,  0.0000]], grad_fn=<AddBackward0>)
 
     """
 
     def __init__(
         self,
-        policy: SafeModule,
+        policy: TensorDictModule,
+        *,
         eps_init: float = 1.0,
         eps_end: float = 0.1,
         annealing_num_steps: int = 1000,
         action_key: str = "action",
         spec: Optional[TensorSpec] = None,
     ):
         super().__init__(policy)
         self.register_buffer("eps_init", torch.tensor([eps_init]))
         self.register_buffer("eps_end", torch.tensor([eps_end]))
         if self.eps_end > self.eps_init:
             raise RuntimeError("eps should decrease over time or be constant")
         self.annealing_num_steps = annealing_num_steps
         self.register_buffer("eps", torch.tensor([eps_init]))
         self.action_key = action_key
-        self.spec = (
-            spec
-            if spec is not None
-            else policy.spec
-            if hasattr(policy, "spec")
-            else None
-        )
+        if spec is not None:
+            if not isinstance(spec, CompositeSpec) and len(self.out_keys) >= 1:
+                spec = CompositeSpec({action_key: spec}, shape=spec.shape[:-1])
+            self._spec = spec
+        elif hasattr(self.td_module, "_spec"):
+            self._spec = self.td_module._spec.clone()
+            if action_key not in self._spec.keys():
+                self._spec[action_key] = None
+        elif hasattr(self.td_module, "spec"):
+            self._spec = self.td_module.spec.clone()
+            if action_key not in self._spec.keys():
+                self._spec[action_key] = None
+        else:
+            self._spec = CompositeSpec({key: None for key in policy.out_keys})
+
+    @property
+    def spec(self):
+        return self._spec
 
     def step(self, frames: int = 1) -> None:
         """A step of epsilon decay.
 
         After self.annealing_num_steps, this function is a no-op.
 
         Args:
@@ -109,41 +130,41 @@
                 (
                     self.eps - (self.eps_init - self.eps_end) / self.annealing_num_steps
                 ).item(),
             )
 
     def forward(self, tensordict: TensorDictBase) -> TensorDictBase:
         tensordict = self.td_module.forward(tensordict)
-        if exploration_mode() == "random" or exploration_mode() is None:
-            out = tensordict.get(self.td_module.out_keys[0])
+        if exploration_type() == ExplorationType.RANDOM or exploration_type() is None:
+            out = tensordict.get(self.action_key)
             eps = self.eps.item()
             cond = (torch.rand(tensordict.shape, device=tensordict.device) < eps).to(
                 out.dtype
             )
             cond = expand_as_right(cond, out)
             spec = self.spec
             if spec is not None:
                 if isinstance(spec, CompositeSpec):
                     spec = spec[self.action_key]
-                out = (
-                    cond * spec.rand(tensordict.shape).to(out.device) + (1 - cond) * out
-                )
+                out = cond * spec.rand().to(out.device) + (1 - cond) * out
             else:
                 raise RuntimeError(
                     "spec must be provided by the policy or directly to the exploration wrapper."
                 )
-            tensordict.set(self.td_module.out_keys[0], out)
+            tensordict.set(self.action_key, out)
         return tensordict
 
 
 class AdditiveGaussianWrapper(TensorDictModuleWrapper):
     """Additive Gaussian PO wrapper.
 
     Args:
-        policy (SafeModule): a policy.
+        policy (TensorDictModule): a policy.
+
+    Keyword Args:
         sigma_init (scalar, optional): initial epsilon value.
             default: 1.0
         sigma_end (scalar, optional): final epsilon value.
             default: 0.1
         annealing_num_steps (int, optional): number of steps it will take for
             sigma to reach the :obj:`sigma_end` value.
         mean (float, optional): mean of each output element’s normal distribution.
@@ -156,19 +177,28 @@
             projected onto the valid action space once explored. If not provided,
             the exploration wrapper will attempt to recover it from the policy.
         safe (boolean, optional): if False, the TensorSpec can be None. If it
             is set to False but the spec is passed, the projection will still
             happen.
             Default is True.
 
+    .. note::
+        Once an environment has been wrapped in :class:`AdditiveGaussianWrapper`, it is
+        crucial to incorporate a call to :meth:`~.step` in the training loop
+        to update the exploration factor.
+        Since it is not easy to capture this omission no warning or exception
+        will be raised if this is ommitted!
+
+
     """
 
     def __init__(
         self,
-        policy: SafeModule,
+        policy: TensorDictModule,
+        *,
         sigma_init: float = 1.0,
         sigma_end: float = 0.1,
         annealing_num_steps: int = 1000,
         mean: float = 0.0,
         std: float = 1.0,
         action_key: str = "action",
         spec: Optional[TensorSpec] = None,
@@ -180,22 +210,41 @@
         self.register_buffer("sigma_init", torch.tensor([sigma_init]))
         self.register_buffer("sigma_end", torch.tensor([sigma_end]))
         self.annealing_num_steps = annealing_num_steps
         self.register_buffer("mean", torch.tensor([mean]))
         self.register_buffer("std", torch.tensor([std]))
         self.register_buffer("sigma", torch.tensor([sigma_init]))
         self.action_key = action_key
-        self.spec = (
-            spec
-            if spec is not None
-            else policy.spec
-            if hasattr(policy, "spec")
-            else None
-        )
+        self.out_keys = list(self.td_module.out_keys)
+        if action_key not in self.out_keys:
+            raise RuntimeError(
+                f"The action key {action_key} was not found in the td_module out_keys {self.td_module.out_keys}."
+            )
+        if spec is not None:
+            if not isinstance(spec, CompositeSpec) and len(self.out_keys) >= 1:
+                spec = CompositeSpec({action_key: spec}, shape=spec.shape[:-1])
+            self._spec = spec
+        elif hasattr(self.td_module, "_spec"):
+            self._spec = self.td_module._spec.clone()
+            if action_key not in self._spec.keys():
+                self._spec[action_key] = None
+        elif hasattr(self.td_module, "spec"):
+            self._spec = self.td_module.spec.clone()
+            if action_key not in self._spec.keys():
+                self._spec[action_key] = None
+        else:
+            self._spec = CompositeSpec({key: None for key in policy.out_keys})
+
         self.safe = safe
+        if self.safe:
+            self.register_forward_hook(_forward_hook_safe_action)
+
+    @property
+    def spec(self):
+        return self._spec
 
     def step(self, frames: int = 1) -> None:
         """A step of sigma decay.
 
         After self.annealing_num_steps, this function is a no-op.
 
         Args:
@@ -215,55 +264,68 @@
         sigma = self.sigma.item()
         noise = torch.normal(
             mean=torch.ones(action.shape) * self.mean.item(),
             std=torch.ones(action.shape) * self.std.item(),
         ).to(action.device)
         action = action + noise * sigma
         spec = self.spec
-        if isinstance(spec, CompositeSpec):
-            spec = spec[self.action_key]
+        spec = spec[self.action_key]
         if spec is not None:
             action = spec.project(action)
         elif self.safe:
             raise RuntimeError(
                 "the action spec must be provided to AdditiveGaussianWrapper unless "
                 "the `safe` keyword argument is turned off at initialization."
             )
         return action
 
     def forward(self, tensordict: TensorDictBase) -> TensorDictBase:
         tensordict = self.td_module.forward(tensordict)
-        if exploration_mode() == "random" or exploration_mode() is None:
+        if exploration_type() is ExplorationType.RANDOM or exploration_type() is None:
             out = tensordict.get(self.action_key)
             out = self._add_noise(out)
             tensordict.set(self.action_key, out)
         return tensordict
 
 
 class OrnsteinUhlenbeckProcessWrapper(TensorDictModuleWrapper):
-    """Ornstein-Uhlenbeck exploration policy wrapper.
+    r"""Ornstein-Uhlenbeck exploration policy wrapper.
 
     Presented in "CONTINUOUS CONTROL WITH DEEP REINFORCEMENT LEARNING", https://arxiv.org/pdf/1509.02971.pdf.
 
     The OU exploration is to be used with continuous control policies and introduces a auto-correlated exploration
     noise. This enables a sort of 'structured' exploration.
 
-        Noise equation:
-            noise = prev_noise + theta * (mu - prev_noise) * dt + current_sigma * sqrt(dt) * W
-        Sigma equation:
-            current_sigma = (-(sigma - sigma_min) / (n_steps_annealing) * n_steps + sigma).clamp_min(sigma_min)
+    Noise equation:
+
+    .. math::
+        noise_t = noise_{t-1} + \theta * (mu - noise_{t-1}) * dt + \sigma_t * \sqrt{dt} * W
+
+    Sigma equation:
+
+    .. math::
+        \sigma_t = max(\sigma^{min, (-(\sigma_{t-1} - \sigma^{min}) / (n^{\text{steps annealing}}) * n^{\text{steps}} + \sigma))
 
     To keep track of the steps and noise from sample to sample, an :obj:`"ou_prev_noise{id}"` and :obj:`"ou_steps{id}"` keys
     will be written in the input/output tensordict. It is expected that the tensordict will be zeroed at reset,
     indicating that a new trajectory is being collected. If not, and is the same tensordict is used for consecutive
     trajectories, the step count will keep on increasing across rollouts. Note that the collector classes take care of
     zeroing the tensordict at reset time.
 
+    .. note::
+        Once an environment has been wrapped in :class:`OrnsteinUhlenbeckProcessWrapper`, it is
+        crucial to incorporate a call to :meth:`~.step` in the training loop
+        to update the exploration factor.
+        Since it is not easy to capture this omission no warning or exception
+        will be raised if this is ommitted!
+
     Args:
-        policy (SafeModule): a policy
+        policy (TensorDictModule): a policy
+
+    Keyword Args:
         eps_init (scalar): initial epsilon value, determining the amount of noise to be added.
             default: 1.0
         eps_end (scalar): final epsilon value, determining the amount of noise to be added.
             default: 0.1
         annealing_num_steps (int): number of steps it will take for epsilon to reach the eps_end value.
             default: 1000
         theta (scalar): theta factor in the noise equation
@@ -276,17 +338,20 @@
             default: 0.01
         x0 (Tensor, ndarray, optional): initial value of the process.
             default: 0.0
         sigma_min (number, optional): sigma_min in the sigma equation.
             default: None
         n_steps_annealing (int): number of steps for the sigma annealing.
             default: 1000
-        key (str): key of the action to be modified.
+        action_key (str): key of the action to be modified.
             default: "action"
-        safe (bool): if True, actions that are out of bounds given the action specs will be projected in the space
+        spec (TensorSpec, optional): if provided, the sampled action will be
+            projected onto the valid action space once explored. If not provided,
+            the exploration wrapper will attempt to recover it from the policy.
+        safe (bool): if ``True``, actions that are out of bounds given the action specs will be projected in the space
             given the :obj:`TensorSpec.project` heuristic.
             default: True
 
     Examples:
         >>> import torch
         >>> from tensordict import TensorDict
         >>> from torchrl.data import BoundedTensorSpec
@@ -307,58 +372,93 @@
             batch_size=torch.Size([10]),
             device=None,
             is_shared=False)
     """
 
     def __init__(
         self,
-        policy: SafeModule,
+        policy: TensorDictModule,
+        *,
         eps_init: float = 1.0,
         eps_end: float = 0.1,
         annealing_num_steps: int = 1000,
         theta: float = 0.15,
         mu: float = 0.0,
         sigma: float = 0.2,
         dt: float = 1e-2,
         x0: Optional[Union[torch.Tensor, np.ndarray]] = None,
         sigma_min: Optional[float] = None,
         n_steps_annealing: int = 1000,
-        key: str = "action",
+        action_key: str = "action",
+        spec: TensorSpec = None,
         safe: bool = True,
+        key: str = None,
     ):
+        if key is not None:
+            action_key = key
+            warnings.warn(
+                f"the 'key' keyword argument of {type(self)} has been renamed 'action_key'. The 'key' entry will be deprecated soon."
+            )
         super().__init__(policy)
         self.ou = _OrnsteinUhlenbeckProcess(
             theta=theta,
             mu=mu,
             sigma=sigma,
             dt=dt,
             x0=x0,
             sigma_min=sigma_min,
             n_steps_annealing=n_steps_annealing,
-            key=key,
+            key=action_key,
         )
         self.register_buffer("eps_init", torch.tensor([eps_init]))
         self.register_buffer("eps_end", torch.tensor([eps_end]))
         if self.eps_end > self.eps_init:
             raise ValueError(
                 "eps should decrease over time or be constant, "
                 f"got eps_init={eps_init} and eps_end={eps_end}"
             )
         self.annealing_num_steps = annealing_num_steps
         self.register_buffer("eps", torch.tensor([eps_init]))
         self.out_keys = list(self.td_module.out_keys) + self.ou.out_keys
-        self._spec = CompositeSpec(
-            **self.td_module._spec, **{key: None for key in self.ou.out_keys}
-        )
+        noise_key = self.ou.noise_key
+        steps_key = self.ou.steps_key
+
+        ou_specs = {
+            noise_key: None,
+            steps_key: UnboundedContinuousTensorSpec(
+                shape=(*self.td_module._spec.shape, 1),
+                device=self.td_module._spec.device,
+                dtype=torch.int64,
+            ),
+        }
+        if spec is not None:
+            if not isinstance(spec, CompositeSpec) and len(self.out_keys) >= 1:
+                spec = CompositeSpec({action_key: spec}, shape=spec.shape[:-1])
+            self._spec = spec
+        elif hasattr(self.td_module, "_spec"):
+            self._spec = self.td_module._spec.clone()
+            if action_key not in self._spec.keys():
+                self._spec[action_key] = None
+        elif hasattr(self.td_module, "spec"):
+            self._spec = self.td_module.spec.clone()
+            if action_key not in self._spec.keys():
+                self._spec[action_key] = None
+        else:
+            self._spec = CompositeSpec({key: None for key in policy.out_keys})
+        self._spec.update(ou_specs)
         if len(set(self.out_keys)) != len(self.out_keys):
             raise RuntimeError(f"Got multiple identical output keys: {self.out_keys}")
         self.safe = safe
         if self.safe:
             self.register_forward_hook(_forward_hook_safe_action)
 
+    @property
+    def spec(self):
+        return self._spec
+
     def step(self, frames: int = 1) -> None:
         """Updates the eps noise factor.
 
         Args:
             frames (int): number of frames of the current batch (corresponding to the number of updates to be made).
 
         """
@@ -376,15 +476,28 @@
                     f"{self.__class__.__name__}.step() called when "
                     f"self.annealing_num_steps={self.annealing_num_steps}. Expected a strictly positive "
                     f"number of frames."
                 )
 
     def forward(self, tensordict: TensorDictBase) -> TensorDictBase:
         tensordict = super().forward(tensordict)
-        if exploration_mode() == "random" or exploration_mode() is None:
+        if exploration_type() == ExplorationType.RANDOM or exploration_type() is None:
+            if "is_init" not in tensordict.keys():
+                warnings.warn(
+                    f"The tensordict passed to {self.__class__.__name__} appears to be "
+                    f"missing the 'is_init' entry. This entry is used to "
+                    f"reset the noise at the beginning of a trajectory, without it "
+                    f"the behaviour of this exploration method is undefined. "
+                    f"This is allowed for BC compatibility purposes but it will be deprecated soon! "
+                    f"To create a 'is_init' entry, simply append an torchrl.envs.InitTracker "
+                    f"transform to your environment with `env = TransformedEnv(env, InitTracker())`."
+                )
+                tensordict.set(
+                    "is_init", torch.zeros(*tensordict.shape, 1, dtype=torch.bool)
+                )
             tensordict = self.ou.add_sample(tensordict, self.eps.item())
         return tensordict
 
 
 # Based on http://math.stackexchange.com/questions/1287634/implementing-ornstein-uhlenbeck-in-matlab
 class _OrnsteinUhlenbeckProcess:
     def __init__(
@@ -423,34 +536,41 @@
     def noise_key(self):
         return self._noise_key  # + str(id(self))
 
     @property
     def steps_key(self):
         return self._steps_key  # + str(id(self))
 
-    def _make_noise_pair(self, tensordict: TensorDictBase) -> None:
+    def _make_noise_pair(self, tensordict: TensorDictBase, is_init=None) -> None:
+        if is_init is not None:
+            tensordict = tensordict.get_sub_tensordict(is_init.view(tensordict.shape))
         tensordict.set(
             self.noise_key,
             torch.zeros(tensordict.get(self.key).shape, device=tensordict.device),
+            inplace=is_init is not None,
         )
         tensordict.set(
             self.steps_key,
             torch.zeros(
                 torch.Size([*tensordict.batch_size, 1]),
                 dtype=torch.long,
                 device=tensordict.device,
             ),
+            inplace=is_init is not None,
         )
 
     def add_sample(
         self, tensordict: TensorDictBase, eps: float = 1.0
     ) -> TensorDictBase:
 
         if self.noise_key not in tensordict.keys():
             self._make_noise_pair(tensordict)
+        is_init = tensordict.get("is_init", None)
+        if is_init is not None and is_init.any():
+            self._make_noise_pair(tensordict, is_init.view(tensordict.shape))
 
         prev_noise = tensordict.get(self.noise_key)
         prev_noise = prev_noise + self.x0
 
         n_steps = tensordict.get(self.steps_key)
 
         noise = (
```

## torchrl/modules/tensordict_module/probabilistic.py

```diff
@@ -3,34 +3,35 @@
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
 
 import warnings
 from typing import Optional, Sequence, Type, Union
 
 from tensordict.nn import (
+    InteractionType,
     ProbabilisticTensorDictModule,
     ProbabilisticTensorDictSequential,
     TensorDictModule,
 )
 from tensordict.tensordict import TensorDictBase
 
 from torchrl.data.tensor_specs import CompositeSpec, TensorSpec
 from torchrl.modules.distributions import Delta
 from torchrl.modules.tensordict_module.common import _forward_hook_safe_action
 from torchrl.modules.tensordict_module.sequence import SafeSequential
 
 
 class SafeProbabilisticModule(ProbabilisticTensorDictModule):
-    """A :obj:``SafeProbabilisticModule`` is an :obj:``tensordict.nn.ProbabilisticTensorDictModule`` subclass that accepts a :obj:``TensorSpec`` as argument to control the output domain.
+    """:class:`tensordict.nn.ProbabilisticTensorDictModule` subclass that accepts a :class:`~torchrl.envs.TensorSpec` as argument to control the output domain.
 
     `SafeProbabilisticModule` is a non-parametric module representing a
     probability distribution. It reads the distribution parameters from an input
     TensorDict using the specified `in_keys`. The output is sampled given some rule,
-    specified by the input :obj:`default_interaction_mode` argument and the
-    :obj:`interaction_mode()` global function.
+    specified by the input ``default_interaction_type`` argument and the
+    ``interaction_type()`` global function.
 
     :obj:`SafeProbabilisticModule` can be used to construct the distribution
     (through the :obj:`get_dist()` method) and/or sampling from this distribution
     (through a regular :obj:`__call__()` to the module).
 
     A :obj:`SafeProbabilisticModule` instance has two main features:
     - It reads and writes TensorDict objects
@@ -55,64 +56,67 @@
             are the keys of the distribution and the values are the keys in the
             tensordict that will get match to the corresponding distribution keys.
         out_keys (str or iterable of str): keys where the sampled values will be
             written. Importantly, if these keys are found in the input TensorDict, the
             sampling step will be skipped.
         spec (TensorSpec): specs of the first output tensor. Used when calling
             td_module.random() to generate random values in the target space.
-        safe (bool, optional): if True, the value of the sample is checked against the
+        safe (bool, optional): if ``True``, the value of the sample is checked against the
             input spec. Out-of-domain sampling can occur because of exploration policies
             or numerical under/overflow issues. As for the :obj:`spec` argument, this
             check will only occur for the distribution sample, but not the other tensors
             returned by the input module. If the sample is out of bounds, it is
             projected back onto the desired space using the `TensorSpec.project` method.
-            Default is :obj:`False`.
-        default_interaction_mode (str, optional): default method to be used to retrieve
+            Default is ``False``.
+        default_interaction_type (str, optional): default method to be used to retrieve
             the output value. Should be one of: 'mode', 'median', 'mean' or 'random'
             (in which case the value is sampled randomly from the distribution). Default
             is 'mode'.
             Note: When a sample is drawn, the :obj:`ProbabilisticTDModule` instance will
-            fist look for the interaction mode dictated by the `interaction_mode()`
+            fist look for the interaction mode dictated by the `interaction_typ()`
             global function. If this returns `None` (its default value), then the
-            `default_interaction_mode` of the `ProbabilisticTDModule` instance will be
-            used. Note that DataCollector instances will use `set_interaction_mode` to
-            `"random"` by default.
+            `default_interaction_type` of the :class:`~.ProbabilisticTDModule`
+            instance will be used. Note that DataCollector instances will use
+            :func:`tensordict.nn.set_interaction_type` to
+            :class:`tensordict.nn.InteractionType.RANDOM` by default.
         distribution_class (Type, optional): a torch.distributions.Distribution class to
             be used for sampling. Default is Delta.
         distribution_kwargs (dict, optional): kwargs to be passed to the distribution.
-        return_log_prob (bool, optional): if True, the log-probability of the
+        return_log_prob (bool, optional): if ``True``, the log-probability of the
             distribution sample will be written in the tensordict with the key
-            `'sample_log_prob'`. Default is `False`.
-        cache_dist (bool, optional): EXPERIMENTAL: if True, the parameters of the
+            `'sample_log_prob'`. Default is ``False``.
+        cache_dist (bool, optional): EXPERIMENTAL: if ``True``, the parameters of the
             distribution (i.e. the output of the module) will be written to the
             tensordict along with the sample. Those parameters can be used to re-compute
             the original distribution later on (e.g. to compute the divergence between
             the distribution used to sample the action and the updated distribution in
-            PPO). Default is `False`.
+            PPO). Default is ``False``.
         n_empirical_estimate (int, optional): number of samples to compute the empirical
             mean when it is not available. Default is 1000
 
     """
 
     def __init__(
         self,
         in_keys: Union[str, Sequence[str], dict],
         out_keys: Union[str, Sequence[str]],
         spec: Optional[TensorSpec] = None,
         safe: bool = False,
-        default_interaction_mode: str = "mode",
+        default_interaction_mode: str = None,
+        default_interaction_type: str = InteractionType.MODE,
         distribution_class: Type = Delta,
         distribution_kwargs: Optional[dict] = None,
         return_log_prob: bool = False,
         cache_dist: bool = False,
         n_empirical_estimate: int = 1000,
     ):
         super().__init__(
             in_keys=in_keys,
             out_keys=out_keys,
+            default_interaction_type=default_interaction_type,
             default_interaction_mode=default_interaction_mode,
             distribution_class=distribution_class,
             distribution_kwargs=distribution_kwargs,
             return_log_prob=return_log_prob,
             cache_dist=cache_dist,
             n_empirical_estimate=n_empirical_estimate,
         )
@@ -185,26 +189,28 @@
         return tensordict
 
     def random_sample(self, tensordict: TensorDictBase) -> TensorDictBase:
         """See :obj:`SafeModule.random(...)`."""
         return self.random(tensordict)
 
 
-class SafeProbabilisticSequential(ProbabilisticTensorDictSequential, SafeSequential):
-    """A :obj:``SafeProbabilisticSequential`` is an :obj:``tensordict.nn.ProbabilisticTensorDictSequential`` subclass that accepts a :obj:``TensorSpec`` as argument to control the output domain.
+class SafeProbabilisticTensorDictSequential(
+    ProbabilisticTensorDictSequential, SafeSequential
+):
+    """:class:`tensordict.nn.ProbabilisticTensorDictSequential` subclass that accepts a :class:`~torchrl.envs.TensorSpec` as argument to control the output domain.
 
     Similarly to :obj:`TensorDictSequential`, but enforces that the final module in the
     sequence is an :obj:`ProbabilisticTensorDictModule` and also exposes ``get_dist``
     method to recover the distribution object from the ``ProbabilisticTensorDictModule``
 
     Args:
          modules (iterable of TensorDictModules): ordered sequence of TensorDictModule
             instances, terminating in ProbabilisticTensorDictModule, to be run
             sequentially.
-         partial_tolerant (bool, optional): if True, the input tensordict can miss some
+         partial_tolerant (bool, optional): if ``True``, the input tensordict can miss some
             of the input keys. If so, the only module that will be executed are those
             who can be executed given the keys that are present. Also, if the input
             tensordict is a lazy stack of tensordicts AND if partial_tolerant is
             :obj:`True` AND if the stack does not have the required keys, then
             TensorDictSequential will scan through the sub-tensordicts looking for those
             that have the required keys, if any.
```

## torchrl/modules/tensordict_module/sequence.py

```diff
@@ -1,61 +1,61 @@
 # Copyright (c) Meta Platforms, Inc. and affiliates.
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
 
 from __future__ import annotations
 
-from tensordict.nn import TensorDictSequential
+from tensordict.nn import TensorDictModule, TensorDictSequential
 from torch import nn
 
 from torchrl.data.tensor_specs import CompositeSpec
 from torchrl.modules.tensordict_module.common import SafeModule
 
 
 class SafeSequential(TensorDictSequential, SafeModule):
-    """A sequence of SafeModules.
+    """A safe sequence of TensorDictModules.
 
     Similarly to :obj:`nn.Sequence` which passes a tensor through a chain of mappings that read and write a single tensor
     each, this module will read and write over a tensordict by querying each of the input modules.
     When calling a :obj:`TensorDictSequencial` instance with a functional module, it is expected that the parameter lists (and
     buffers) will be concatenated in a single list.
 
     Args:
-         modules (iterable of SafeModules): ordered sequence of SafeModule instances to be run sequentially.
-         partial_tolerant (bool, optional): if True, the input tensordict can miss some of the input keys.
+         modules (iterable of TensorDictModules): ordered sequence of TensorDictModule instances to be run sequentially.
+         partial_tolerant (bool, optional): if ``True``, the input tensordict can miss some of the input keys.
             If so, the only module that will be executed are those who can be executed given the keys that
             are present.
             Also, if the input tensordict is a lazy stack of tensordicts AND if partial_tolerant is :obj:`True` AND if the
             stack does not have the required keys, then SafeSequential will scan through the sub-tensordicts
             looking for those that have the required keys, if any.
 
     TensorDictSequence supports functional, modular and vmap coding:
     Examples:
         >>> import torch
         >>> from tensordict import TensorDict
         >>> from tensordict.nn.functional_modules import make_functional
         >>> from torchrl.data import CompositeSpec, UnboundedContinuousTensorSpec
-        >>> from torchrl.modules import TanhNormal, SafeSequential, SafeModule, NormalParamWrapper
+        >>> from torchrl.modules import TanhNormal, SafeSequential, TensorDictModule, NormalParamWrapper
         >>> from torchrl.modules.tensordict_module import SafeProbabilisticModule
         >>> td = TensorDict({"input": torch.randn(3, 4)}, [3,])
         >>> spec1 = CompositeSpec(hidden=UnboundedContinuousTensorSpec(4), loc=None, scale=None)
         >>> net1 = NormalParamWrapper(torch.nn.Linear(4, 8))
-        >>> module1 = SafeModule(net1, in_keys=["input"], out_keys=["loc", "scale"])
+        >>> module1 = TensorDictModule(net1, in_keys=["input"], out_keys=["loc", "scale"])
         >>> td_module1 = SafeProbabilisticModule(
         ...     module=module1,
         ...     spec=spec1,
-        ...     dist_in_keys=["loc", "scale"],
-        ...     sample_out_key=["hidden"],
+        ...     in_keys=["loc", "scale"],
+        ...     out_keys=["hidden"],
         ...     distribution_class=TanhNormal,
         ...     return_log_prob=True,
         ... )
         >>> spec2 = UnboundedContinuousTensorSpec(8)
         >>> module2 = torch.nn.Linear(4, 8)
-        >>> td_module2 = SafeModule(
+        >>> td_module2 = TensorDictModule(
         ...    module=module2,
         ...    spec=spec2,
         ...    in_keys=["hidden"],
         ...    out_keys=["output"],
         ...    )
         >>> td_module = SafeSequential(td_module1, td_module2)
         >>> params = make_functional(td_module)
@@ -71,23 +71,23 @@
                 scale: Tensor(torch.Size([3, 4]), dtype=torch.float32)},
             batch_size=torch.Size([3]),
             device=None,
             is_shared=False)
         >>> # The module spec aggregates all the input specs:
         >>> print(td_module.spec)
         CompositeSpec(
-            hidden: NdUnboundedContinuousTensorSpec(
+            hidden: UnboundedContinuousTensorSpec(
                 shape=torch.Size([4]), space=None, device=cpu, dtype=torch.float32, domain=continuous),
             loc: None,
             scale: None,
-            output: NdUnboundedContinuousTensorSpec(
+            output: UnboundedContinuousTensorSpec(
                 shape=torch.Size([8]), space=None, device=cpu, dtype=torch.float32, domain=continuous))
 
     In the vmap case:
-        >>> from functorch import vmap
+        >>> from torch import vmap
         >>> params = params.expand(4, *params.shape)
         >>> td_vmap = vmap(td_module, (None, 0))(td, params)
         >>> print(td_vmap)
         TensorDict(
             fields={
                 hidden: Tensor(torch.Size([4, 3, 4]), dtype=torch.float32),
                 input: Tensor(torch.Size([4, 3, 4]), dtype=torch.float32),
@@ -101,26 +101,26 @@
 
     """
 
     module: nn.ModuleList
 
     def __init__(
         self,
-        *modules: SafeModule,
+        *modules: TensorDictModule,
         partial_tolerant: bool = False,
     ):
         self.partial_tolerant = partial_tolerant
 
         in_keys, out_keys = self._compute_in_and_out_keys(modules)
 
         spec = CompositeSpec()
         for module in modules:
-            if isinstance(module, SafeModule) or hasattr(module, "spec"):
+            try:
                 spec.update(module.spec)
-            else:
+            except AttributeError:
                 spec.update(CompositeSpec({key: None for key in module.out_keys}))
 
         super(TensorDictSequential, self).__init__(
             spec=spec,
             module=nn.ModuleList(list(modules)),
             in_keys=in_keys,
             out_keys=out_keys,
```

## torchrl/modules/tensordict_module/world_models.py

```diff
@@ -1,32 +1,34 @@
 # Copyright (c) Meta Platforms, Inc. and affiliates.
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
 
 
-from torchrl.modules.tensordict_module import SafeModule, SafeSequential
+from tensordict.nn import TensorDictModule, TensorDictSequential
 
 
-class WorldModelWrapper(SafeSequential):
+class WorldModelWrapper(TensorDictSequential):
     """World model wrapper.
 
     This module wraps together a transition model and a reward model.
     The transition model is used to predict an imaginary world state.
     The reward model is used to predict the reward of the imagined transition.
 
     Args:
-        transition_model (SafeModule): a transition model that generates a new world states.
-        reward_model (SafeModule): a reward model, that reads the world state and returns a reward.
+        transition_model (TensorDictModule): a transition model that generates a new world states.
+        reward_model (TensorDictModule): a reward model, that reads the world state and returns a reward.
 
     """
 
-    def __init__(self, transition_model: SafeModule, reward_model: SafeModule):
+    def __init__(
+        self, transition_model: TensorDictModule, reward_model: TensorDictModule
+    ):
         super().__init__(transition_model, reward_model)
 
-    def get_transition_model_operator(self) -> SafeSequential:
+    def get_transition_model_operator(self) -> TensorDictModule:
         """Returns a transition operator that maps either an observation to a world state or a world state to the next world state."""
         return self.module[0]
 
-    def get_reward_operator(self) -> SafeSequential:
+    def get_reward_operator(self) -> TensorDictModule:
         """Returns a reward operator that maps a world state to a reward."""
         return self.module[1]
```

## torchrl/modules/utils/__init__.py

```diff
@@ -4,14 +4,15 @@
 # LICENSE file in the root directory of this source tree.
 
 from collections import OrderedDict
 
 import torch
 from packaging import version
 
+
 if version.parse(torch.__version__) >= version.parse("1.12.0"):
     from torch.nn.parameter import _disabled_torch_function_impl, _ParameterMeta
 else:
     from torch.nn.parameter import _disabled_torch_function_impl
 
     # Metaclass to combine _TensorMeta and the instance check override for Parameter.
     class _ParameterMeta(torch._C._TensorMeta):
```

## torchrl/objectives/__init__.py

```diff
@@ -8,19 +8,21 @@
 from .ddpg import DDPGLoss
 from .dqn import DistributionalDQNLoss, DQNLoss
 from .dreamer import DreamerActorLoss, DreamerModelLoss, DreamerValueLoss
 from .iql import IQLLoss
 from .ppo import ClipPPOLoss, KLPENPPOLoss, PPOLoss
 from .redq import REDQLoss
 from .reinforce import ReinforceLoss
-from .sac import SACLoss
+from .sac import DiscreteSACLoss, SACLoss
 from .td3 import TD3Loss
 from .utils import (
+    default_value_kwargs,
     distance_loss,
     HardUpdate,
     hold_out_net,
     hold_out_params,
     next_state_value,
     SoftUpdate,
+    ValueEstimators,
 )
 
 # from .value import bellman_max, c_val, dv_val, vtrace, GAE, TDLambdaEstimate, TDEstimate
```

## torchrl/objectives/a2c.py

```diff
@@ -1,77 +1,117 @@
 # Copyright (c) Meta Platforms, Inc. and affiliates.
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
-
+import warnings
 from typing import Tuple
 
 import torch
+from tensordict.nn import ProbabilisticTensorDictSequential, TensorDictModule
 from tensordict.tensordict import TensorDict, TensorDictBase
 from torch import distributions as d
 
-from torchrl.modules import SafeModule
-from torchrl.modules.tensordict_module import SafeProbabilisticSequential
 from torchrl.objectives.common import LossModule
-from torchrl.objectives.utils import distance_loss
+from torchrl.objectives.utils import (
+    _GAMMA_LMBDA_DEPREC_WARNING,
+    default_value_kwargs,
+    distance_loss,
+    ValueEstimators,
+)
+from torchrl.objectives.value import GAE, TD0Estimator, TD1Estimator, TDLambdaEstimator
 
 
 class A2CLoss(LossModule):
     """TorchRL implementation of the A2C loss.
 
     A2C (Advantage Actor Critic) is a model-free, online RL algorithm that uses parallel rollouts of n steps to
     update the policy, relying on the REINFORCE estimator to compute the gradient. It also adds an entropy term to the
     objective function to improve exploration.
 
     For more details regarding A2C, refer to: "Asynchronous Methods for Deep Reinforcment Learning",
     https://arxiv.org/abs/1602.01783v2
 
     Args:
-        actor (SafeProbabilisticSequential): policy operator.
+        actor (ProbabilisticTensorDictSequential): policy operator.
         critic (ValueOperator): value operator.
         advantage_key (str): the input tensordict key where the advantage is expected to be written.
             default: "advantage"
-        advantage_diff_key (str): the input tensordict key where advantage_diff is expected to be written.
-            default: "value_error"
+        value_target_key (str): the input tensordict key where the target state
+            value is expected to be written. Defaults to ``"value_target"``.
+        entropy_bonus (bool): if ``True``, an entropy bonus will be added to the
+            loss to favour exploratory policies.
+        samples_mc_entropy (int): if the distribution retrieved from the policy
+            operator does not have a closed form
+            formula for the entropy, a Monte-Carlo estimate will be used.
+            ``samples_mc_entropy`` will control how many
+            samples will be used to compute this estimate.
+            Defaults to ``1``.
         entropy_coef (float): the weight of the entropy loss.
         critic_coef (float): the weight of the critic loss.
-        gamma (scalar): a discount factor for return computation.
-        loss_function_type (str): loss function for the value discrepancy. Can be one of "l1", "l2" or "smooth_l1".
-        advantage_module (nn.Module): SafeModule used to compute tha advantage function.
+        loss_critic_type (str): loss function for the value discrepancy.
+            Can be one of "l1", "l2" or "smooth_l1". Defaults to ``"smooth_l1"``.
+        separate_losses (bool, optional): if ``True``, shared parameters between
+            policy and critic will only be trained on the policy loss.
+            Defaults to ``False``, ie. gradients are propagated to shared
+            parameters for both policy and critic losses.
+
+    .. note:
+      The advantage (typically GAE) can be computed by the loss function or
+      in the training loop. The latter option is usually preferred, but this is
+      up to the user to choose which option is to be preferred.
+      If the advantage key (``"advantage`` by default) is not present in the
+      input tensordict, the advantage will be computed by the :meth:`~.forward`
+      method.
+      A custom advantage module can be built using :meth:`~.make_value_estimator`.
+      The default is :class:`~torchrl.objectives.value.GAE` with hyperparameters
+      dictated by :func:`~torchrl.objectives.utils.default_value_kwargs`.
+
     """
 
+    default_value_estimator: ValueEstimators = ValueEstimators.GAE
+
     def __init__(
         self,
-        actor: SafeProbabilisticSequential,
-        critic: SafeModule,
+        actor: ProbabilisticTensorDictSequential,
+        critic: TensorDictModule,
+        *,
         advantage_key: str = "advantage",
         value_target_key: str = "value_target",
         entropy_bonus: bool = True,
         samples_mc_entropy: int = 1,
         entropy_coef: float = 0.01,
         critic_coef: float = 1.0,
-        gamma: float = 0.99,
         loss_critic_type: str = "smooth_l1",
+        gamma: float = None,
+        separate_losses: bool = False,
     ):
         super().__init__()
         self.convert_to_functional(
             actor, "actor", funs_to_decorate=["forward", "get_dist"]
         )
-        self.convert_to_functional(critic, "critic", compare_against=self.actor_params)
+        if separate_losses:
+            # we want to make sure there are no duplicates in the params: the
+            # params of critic must be refs to actor if they're shared
+            policy_params = list(actor.parameters())
+        else:
+            policy_params = None
+        self.convert_to_functional(critic, "critic", compare_against=policy_params)
         self.advantage_key = advantage_key
         self.value_target_key = value_target_key
         self.samples_mc_entropy = samples_mc_entropy
         self.entropy_bonus = entropy_bonus and entropy_coef
         self.register_buffer(
             "entropy_coef", torch.tensor(entropy_coef, device=self.device)
         )
         self.register_buffer(
             "critic_coef", torch.tensor(critic_coef, device=self.device)
         )
-        self.register_buffer("gamma", torch.tensor(gamma, device=self.device))
+        if gamma is not None:
+            warnings.warn(_GAMMA_LMBDA_DEPREC_WARNING, category=DeprecationWarning)
+            self.gamma = gamma
         self.loss_critic_type = loss_critic_type
 
     def reset(self) -> None:
         pass
 
     def get_entropy_bonus(self, dist: d.Distribution) -> torch.Tensor:
         try:
@@ -93,14 +133,16 @@
         dist = self.actor.get_dist(tensordict_clone, params=self.actor_params)
         log_prob = dist.log_prob(action)
         log_prob = log_prob.unsqueeze(-1)
         return log_prob, dist
 
     def loss_critic(self, tensordict: TensorDictBase) -> torch.Tensor:
         try:
+            # TODO: if the advantage is gathered by forward, this introduces an
+            # overhead that we could easily reduce.
             target_return = tensordict.get(self.value_target_key)
             tensordict_select = tensordict.select(*self.critic.in_keys)
             state_value = self.critic(
                 tensordict_select,
                 params=self.critic_params,
             ).get("state_value")
             loss_value = distance_loss(
@@ -115,20 +157,55 @@
                 f"return) has been retrieved accordingly. Advantage classes such as GAE, "
                 f"TDLambdaEstimate and TDEstimate all return a 'value_target' entry that "
                 f"can be used for the value loss."
             )
         return self.critic_coef * loss_value
 
     def forward(self, tensordict: TensorDictBase) -> TensorDictBase:
-        tensordict = tensordict.clone()
-        advantage = tensordict.get(self.advantage_key)
+        tensordict = tensordict.clone(False)
+        advantage = tensordict.get(self.advantage_key, None)
+        if advantage is None:
+            self.value_estimator(
+                tensordict,
+                params=self.critic_params.detach(),
+                target_params=self.target_critic_params,
+            )
+            advantage = tensordict.get(self.advantage_key)
         log_probs, dist = self._log_probs(tensordict)
         loss = -(log_probs * advantage)
         td_out = TensorDict({"loss_objective": loss.mean()}, [])
         if self.entropy_bonus:
             entropy = self.get_entropy_bonus(dist)
             td_out.set("entropy", entropy.mean().detach())  # for logging
             td_out.set("loss_entropy", -self.entropy_coef * entropy.mean())
         if self.critic_coef:
             loss_critic = self.loss_critic(tensordict).mean()
             td_out.set("loss_critic", loss_critic.mean())
         return td_out
+
+    def make_value_estimator(self, value_type: ValueEstimators = None, **hyperparams):
+        if value_type is None:
+            value_type = self.default_value_estimator
+        self.value_type = value_type
+        hp = dict(default_value_kwargs(value_type))
+        hp.update(hyperparams)
+        if hasattr(self, "gamma"):
+            hp["gamma"] = self.gamma
+        value_key = "state_value"
+        if value_type == ValueEstimators.TD1:
+            self._value_estimator = TD1Estimator(
+                value_network=self.critic, value_key=value_key, **hp
+            )
+        elif value_type == ValueEstimators.TD0:
+            self._value_estimator = TD0Estimator(
+                value_network=self.critic, value_key=value_key, **hp
+            )
+        elif value_type == ValueEstimators.GAE:
+            self._value_estimator = GAE(
+                value_network=self.critic, value_key=value_key, **hp
+            )
+        elif value_type == ValueEstimators.TDLambda:
+            self._value_estimator = TDLambdaEstimator(
+                value_network=self.critic, value_key=value_key, **hp
+            )
+        else:
+            raise NotImplementedError(f"Unknown value type {value_type}")
```

## torchrl/objectives/common.py

```diff
@@ -1,28 +1,31 @@
 # Copyright (c) Meta Platforms, Inc. and affiliates.
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
 
 from __future__ import annotations
 
-import itertools
+import warnings
 from copy import deepcopy
 from typing import Iterator, List, Optional, Tuple, Union
 
 import torch
 
-from tensordict.nn import make_functional, repopulate_module
+from tensordict.nn import make_functional, repopulate_module, TensorDictModule
 
 from tensordict.tensordict import TensorDictBase
 from torch import nn, Tensor
 from torch.nn import Parameter
 
-from torchrl.modules import SafeModule
+from torchrl._utils import RL_WARNINGS
+from torchrl.envs.utils import ExplorationType, set_exploration_type
 from torchrl.modules.utils import Buffer
+from torchrl.objectives.utils import ValueEstimators
+from torchrl.objectives.value import ValueEstimatorBase
 
 _has_functorch = False
 try:
     import functorch as ft  # noqa
 
     _has_functorch = True
     FUNCTORCH_ERR = ""
@@ -34,24 +37,45 @@
     )
     FUNCTORCH_ERROR = "functorch not installed. Consider installing functorch to use this functionality."
 
 
 class LossModule(nn.Module):
     """A parent class for RL losses.
 
-    LossModule inherits from nn.Module. It is designed to read an input TensorDict and return another tensordict
-    with loss keys named "loss_*".
-    Splitting the loss in its component can then be used by the trainer to log the various loss values throughout
+    LossModule inherits from nn.Module. It is designed to read an input
+    TensorDict and return another tensordict
+    with loss keys named ``"loss_*"``.
+
+    Splitting the loss in its component can then be used by the trainer to log
+    the various loss values throughout
     training. Other scalars present in the output tensordict will be logged too.
 
+    :cvar default_value_estimator: The default value type of the class.
+        Losses that require a value estimation are equipped with a default value
+        pointer. This class attribute indicates which value estimator will be
+        used if none other is specified.
+        The value estimator can be changed using the :meth:`~.make_value_estimator` method.
+
+    By default, the forward method is always decorated with a
+    gh :class:`torchrl.envs.ExplorationType.MODE`
     """
 
+    default_value_estimator: ValueEstimators = None
+    SEP = "_sep_"
+
+    def __new__(cls, *args, **kwargs):
+        cls.forward = set_exploration_type(ExplorationType.MODE)(cls.forward)
+        return super().__new__(cls)
+
     def __init__(self):
         super().__init__()
         self._param_maps = {}
+        self._value_estimator = None
+        self._has_update_associated = False
+        self.value_type = self.default_value_estimator
         # self.register_forward_pre_hook(_parameters_to_tensordict)
 
     def forward(self, tensordict: TensorDictBase) -> TensorDictBase:
         """It is designed to read an input TensorDict and return another tensordict with loss keys named "loss*".
 
         Splitting the loss in its component can then be used by the trainer to log the various loss values throughout
         training. Other scalars present in the output tensordict will be logged too.
@@ -65,32 +89,85 @@
             backpropagation.
 
         """
         raise NotImplementedError
 
     def convert_to_functional(
         self,
-        module: SafeModule,
+        module: TensorDictModule,
         module_name: str,
         expand_dim: Optional[int] = None,
         create_target_params: bool = False,
         compare_against: Optional[List[Parameter]] = None,
         funs_to_decorate=None,
     ) -> None:
+        """Converts a module to functional to be used in the loss.
+
+        Args:
+            module (TensorDictModule or compatible): a stateful tensordict module.
+                This module will be made functional, yet still stateful, meaning
+                that it will be callable with the following alternative signatures:
+
+                >>> module(tensordict)
+                >>> module(tensordict, params=params)
+
+                ``params`` is a :class:`tensordict.TensorDict` instance with parameters
+                stuctured as the output of :func:`tensordict.nn.make_functional`
+                is.
+            module_name (str): name where the module will be found.
+                The parameters of the module will be found under ``loss_module.<module_name>_params``
+                whereas the module will be found under ``loss_module.<module_name>``.
+            expand_dim (int, optional): if provided, the parameters of the module
+                will be expanded ``N`` times, where ``N = expand_dim`` along the
+                first dimension. This option is to be used whenever a target
+                network with more than one configuration is to be used.
+
+                .. note::
+                  If a ``compare_against`` list of values is provided, the
+                  resulting parameters will simply be a detached expansion
+                  of the original parameters. If ``compare_against`` is not
+                  provided, the value of the parameters will be resampled uniformly
+                  between the minimum and maximum value of the parameter content.
+
+             create_target_params (bool, optional): if ``True``, a detached
+                copy of the parameter will be available to feed a target network
+                under the name ``loss_module.<module_name>_target_params``.
+                If ``False`` (default), this attribute will still be available
+                but it will be a detached instance of the parameters, not a copy.
+                In other words, any modification of the parameter value
+                will directly be reflected in the target parameters.
+            compare_against (iterable of parameters, optional): if provided,
+                this list of parameters will be used as a comparison set for
+                the parameters of the module. If the parameters are expanded
+                (``expand_dim > 0``), the resulting parameters for the module
+                will be a simple expansion of the original parameter. Otherwise,
+                the resulting parameters will be a detached version of the
+                original parameters. If ``None``, the resulting parameters
+                will carry gradients as expected.
+            funs_to_decorate (list of str, optional): if provided, the list of
+                methods of ``module`` to make functional, ie the list of
+                methods that will accept the ``params`` keyword argument.
+
+        """
         if funs_to_decorate is None:
             funs_to_decorate = ["forward"]
         # To make it robust to device casting, we must register list of
         # tensors as lazy calls to `getattr(self, name_of_tensor)`.
         # Otherwise, casting the module to a device will keep old references
         # to uncast tensors
-        try:
-            buffer_names = next(itertools.islice(zip(*module.named_buffers()), 1))
-        except StopIteration:
-            buffer_names = ()
+        sep = self.SEP
         params = make_functional(module, funs_to_decorate=funs_to_decorate)
+        # buffer_names = next(itertools.islice(zip(*module.named_buffers()), 1))
+        buffer_names = []
+        for key, value in params.items(True, True):
+            # we just consider all that is not param as a buffer, but if the module has been made
+            # functional and the params have been replaced this may break
+            if not isinstance(value, nn.Parameter):
+                key = sep.join(key) if not isinstance(key, str) else key
+                buffer_names.append(key)
         functional_module = deepcopy(module)
         repopulate_module(module, params)
 
         params_and_buffers = params
         # we transform the buffers in params to make sure they follow the device
         # as tensor = nn.Parameter(tensor) keeps its identity when moved to another device
 
@@ -101,36 +178,35 @@
             ):
                 return Buffer(tensor, requires_grad=tensor.requires_grad)
             return tensor
 
         # separate params and buffers
         params_and_buffers = params_and_buffers.apply(create_buffers)
         for key in params_and_buffers.keys(True):
-            if "_sep_" in key:
+            if sep in key:
                 raise KeyError(
                     f"The key {key} contains the '_sep_' pattern which is prohibited. Consider renaming the parameter / buffer."
                 )
-        params_and_buffers_flat = params_and_buffers.flatten_keys("_sep_")
+        params_and_buffers_flat = params_and_buffers.flatten_keys(sep)
         buffers = params_and_buffers_flat.select(*buffer_names)
         params = params_and_buffers_flat.exclude(*buffer_names)
-
         if expand_dim and not _has_functorch:
             raise ImportError(
                 "expanding params is only possible when functorch is installed,"
                 "as this feature requires calls to the vmap operator."
             )
+        if compare_against is not None:
+            compare_against = set(compare_against)
+        else:
+            compare_against = set()
         if expand_dim:
             # Expands the dims of params and buffers.
             # If the param already exist in the module, we return a simple expansion of the
             # original one. Otherwise, we expand and resample it.
             # For buffers, a cloned expansion (or equivalently a repeat) is returned.
-            if compare_against is not None:
-                compare_against = set(compare_against)
-            else:
-                compare_against = set()
 
             def _compare_and_expand(param):
 
                 if param in compare_against:
                     expanded_param = param.data.expand(expand_dim, *param.shape)
                     # the expanded parameter must be sent to device when to()
                     # is called:
@@ -150,46 +226,51 @@
 
             params = params_udpated
             buffers = buffers.apply(
                 lambda buffer: Buffer(buffer.expand(expand_dim, *buffer.shape).clone()),
                 batch_size=[expand_dim, *buffers.shape],
             )
 
-            params_and_buffers.update(params.unflatten_keys("_sep_"))
-            params_and_buffers.update(buffers.unflatten_keys("_sep_"))
+            params_and_buffers.update(params.unflatten_keys(sep))
+            params_and_buffers.update(buffers.unflatten_keys(sep))
             params_and_buffers.batch_size = params.batch_size
 
             # self.params_to_map = params_to_map
 
         param_name = module_name + "_params"
 
         prev_set_params = set(self.parameters())
 
         # register parameters and buffers
         for key, parameter in params.items():
             if parameter not in prev_set_params:
-                setattr(self, "_sep_".join([module_name, key]), parameter)
+                setattr(self, sep.join([module_name, key]), parameter)
             else:
+                # if the parameter is already present, we register a string pointing
+                # to is instead. If the string ends with a '_detached' suffix, the
+                # value will be detached
                 for _param_name, p in self.named_parameters():
                     if parameter is p:
                         break
                 else:
                     raise RuntimeError("parameter not found")
-                setattr(self, "_sep_".join([module_name, key]), _param_name)
+                if compare_against is not None and p in compare_against:
+                    _param_name = _param_name + "_detached"
+                setattr(self, sep.join([module_name, key]), _param_name)
         prev_set_buffers = set(self.buffers())
         for key, buffer in buffers.items():
             if buffer not in prev_set_buffers:
-                self.register_buffer("_sep_".join([module_name, key]), buffer)
+                self.register_buffer(sep.join([module_name, key]), buffer)
             else:
                 for _buffer_name, b in self.named_buffers():
                     if buffer is b:
                         break
                 else:
                     raise RuntimeError("buffer not found")
-                setattr(self, "_sep_".join([module_name, key]), _buffer_name)
+                setattr(self, sep.join([module_name, key]), _buffer_name)
 
         setattr(self, "_" + param_name, params_and_buffers)
         setattr(
             self.__class__,
             param_name,
             property(lambda _self=self: _self._param_getter(module_name)),
         )
@@ -201,28 +282,28 @@
         for key, value in params.items(True, True):
             if not isinstance(key, tuple):
                 key = (key,)
             if not isinstance(value, nn.Parameter):
                 # find the param name
                 for name, param in self.named_parameters():
                     if param.data.data_ptr() == value.data_ptr() and param is not value:
-                        self._param_maps[name] = "_sep_".join([module_name, *key])
+                        self._param_maps[name] = sep.join([module_name, *key])
                         break
                 else:
-                    raise RuntimeError("did not find matching param.")
+                    raise RuntimeError(f"key {key} did not find matching param.")
 
         name_params_target = "_target_" + module_name
         if create_target_params:
             target_params = params_and_buffers.detach().clone()
             target_params_items = target_params.items(True, True)
             target_params_list = []
             for (key, val) in target_params_items:
                 if not isinstance(key, tuple):
                     key = (key,)
-                name = "_sep_".join([name_params_target, *key])
+                name = sep.join([name_params_target, *key])
                 self.register_buffer(name, Buffer(val))
                 target_params_list.append((name, key))
             setattr(self, name_params_target + "_params", target_params)
         else:
             setattr(self, name_params_target + "_params", None)
         setattr(
             self.__class__,
@@ -236,18 +317,22 @@
         if name in self.__dict__:
             params = getattr(self, name)
             if params is not None:
                 # get targets and update
                 for key in params.keys(True, True):
                     if not isinstance(key, tuple):
                         key = (key,)
-                    value_to_set = getattr(self, "_sep_".join([network_name, *key]))
+                    value_to_set = getattr(self, self.SEP.join([network_name, *key]))
                     if isinstance(value_to_set, str):
-                        value_to_set = getattr(self, value_to_set).detach()
-                    params.set(key, value_to_set)
+                        if value_to_set.endswith("_detached"):
+                            value_to_set = value_to_set[:-9]
+                            value_to_set = getattr(self, value_to_set).detach()
+                        else:
+                            value_to_set = getattr(self, value_to_set)
+                    params._set(key, value_to_set)
                 return params
             else:
                 params = getattr(self, param_name)
                 return params.detach()
 
         else:
             raise RuntimeError(
@@ -256,22 +341,32 @@
 
     def _target_param_getter(self, network_name):
         target_name = "_target_" + network_name + "_params"
         param_name = network_name + "_params"
         if target_name in self.__dict__:
             target_params = getattr(self, target_name)
             if target_params is not None:
+                if not self._has_update_associated and RL_WARNINGS:
+                    warnings.warn(
+                        "No target network updater has been associated "
+                        "with this loss module, but target parameters have been found."
+                        "While this is supported, it is expected that the target network "
+                        "updates will be manually performed. You can deactivate this warning "
+                        "by turning the RL_WARNINGS env variable to False.",
+                        category=UserWarning,
+                    )
                 # get targets and update
                 for key in target_params.keys(True, True):
                     if not isinstance(key, tuple):
                         key = (key,)
                     value_to_set = getattr(
-                        self, "_sep_".join(["_target_" + network_name, *key])
+                        self, self.SEP.join(["_target_" + network_name, *key])
                     )
-                    target_params.set(key, value_to_set)
+                    # _set is faster bc is bypasses the checks
+                    target_params._set(key, value_to_set)
                 return target_params
             else:
                 params = getattr(self, param_name)
                 return params.detach()
 
         else:
             raise RuntimeError(
@@ -345,7 +440,83 @@
         return self.to(torch.float)
 
     def half(self) -> LossModule:
         return self.to(torch.half)
 
     def cpu(self) -> LossModule:
         return self.to(torch.device("cpu"))
+
+    @property
+    def value_estimator(self) -> ValueEstimatorBase:
+        """The value function blends in the reward and value estimate(s) from upcoming state(s)/state-action pair(s) into a target value estimate for the value network."""
+        out = self._value_estimator
+        if out is None:
+            self._default_value_estimator()
+            return self._value_estimator
+        return out
+
+    @value_estimator.setter
+    def value_estimator(self, value):
+        self._value_estimator = value
+
+    def _default_value_estimator(self):
+        """A value-function constructor when none is provided.
+
+        No kwarg should be present as default parameters should be retrieved
+        from :obj:`torchrl.objectives.utils.DEFAULT_VALUE_FUN_PARAMS`.
+
+        """
+        self.make_value_estimator(self.default_value_estimator)
+
+    def make_value_estimator(self, value_type: ValueEstimators = None, **hyperparams):
+        """Value-function constructor.
+
+        If the non-default value function is wanted, it must be built using
+        this method.
+
+        Args:
+            value_type (ValueEstimators): A :class:`~torchrl.objectives.utils.ValueEstimators`
+                enum type indicating the value function to use. If none is provided,
+                the default stored in the ``default_value_estimator``
+                attribute will be used. The resulting value estimator class
+                will be registered in ``self.value_type``, allowing
+                future refinements.
+            **hyperparams: hyperparameters to use for the value function.
+                If not provided, the value indicated by
+                :func:`~torchrl.objectives.utils.default_value_kwargs` will be
+                used.
+
+        Examples:
+            >>> from torchrl.objectives import DQNLoss
+            >>> # initialize the DQN loss
+            >>> actor = torch.nn.Linear(3, 4)
+            >>> dqn_loss = DQNLoss(actor, action_space="one-hot")
+            >>> # updating the parameters of the default value estimator
+            >>> dqn_loss.make_value_estimator(gamma=0.9)
+            >>> dqn_loss.make_value_estimator(
+            ...     ValueEstimators.TD1,
+            ...     gamma=0.9)
+            >>> # if we want to change the gamma value
+            >>> dqn_loss.make_value_estimator(dqn_loss.value_type, gamma=0.9)
+
+        """
+        if value_type is None:
+            value_type = self.default_value_estimator
+        self.value_type = value_type
+        if value_type == ValueEstimators.TD1:
+            raise NotImplementedError(
+                f"Value type {value_type} it not implemented for loss {type(self)}."
+            )
+        elif value_type == ValueEstimators.TD0:
+            raise NotImplementedError(
+                f"Value type {value_type} it not implemented for loss {type(self)}."
+            )
+        elif value_type == ValueEstimators.GAE:
+            raise NotImplementedError(
+                f"Value type {value_type} it not implemented for loss {type(self)}."
+            )
+        elif value_type == ValueEstimators.TDLambda:
+            raise NotImplementedError(
+                f"Value type {value_type} it not implemented for loss {type(self)}."
+            )
+        else:
+            raise NotImplementedError(f"Unknown value type {value_type}")
```

## torchrl/objectives/ddpg.py

```diff
@@ -1,54 +1,59 @@
 # Copyright (c) Meta Platforms, Inc. and affiliates.
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
 
 from __future__ import annotations
 
+import warnings
 from copy import deepcopy
 
 from typing import Tuple
 
 import torch
-from tensordict.nn import make_functional, repopulate_module
+from tensordict.nn import make_functional, repopulate_module, TensorDictModule
 from tensordict.tensordict import TensorDict, TensorDictBase
 
-from torchrl.modules import SafeModule
 from torchrl.modules.tensordict_module.actors import ActorCriticWrapper
-from torchrl.objectives.utils import distance_loss, hold_out_params, next_state_value
-
-from ..envs.utils import set_exploration_mode
-from .common import LossModule
+from torchrl.objectives.common import LossModule
+from torchrl.objectives.utils import (
+    _GAMMA_LMBDA_DEPREC_WARNING,
+    default_value_kwargs,
+    distance_loss,
+    hold_out_params,
+    ValueEstimators,
+)
+from torchrl.objectives.value import TD0Estimator, TD1Estimator, TDLambdaEstimator
 
 
 class DDPGLoss(LossModule):
     """The DDPG Loss class.
 
     Args:
-        actor_network (SafeModule): a policy operator.
-        value_network (SafeModule): a Q value operator.
-        gamma (scalar): a discount factor for return computation.
-        device (str, int or torch.device, optional): a device where the losses will be computed, if it can't be found
-            via the value operator.
+        actor_network (TensorDictModule): a policy operator.
+        value_network (TensorDictModule): a Q value operator.
         loss_function (str): loss function for the value discrepancy. Can be one of "l1", "l2" or "smooth_l1".
         delay_actor (bool, optional): whether to separate the target actor networks from the actor networks used for
-            data collection. Default is :obj:`False`.
+            data collection. Default is ``False``.
         delay_value (bool, optional): whether to separate the target value networks from the value networks used for
-            data collection. Default is :obj:`False`.
+            data collection. Default is ``False``.
     """
 
+    default_value_estimator: ValueEstimators = ValueEstimators.TD0
+
     def __init__(
         self,
-        actor_network: SafeModule,
-        value_network: SafeModule,
-        gamma: float,
+        actor_network: TensorDictModule,
+        value_network: TensorDictModule,
+        *,
         loss_function: str = "l2",
         delay_actor: bool = False,
         delay_value: bool = False,
+        gamma: float = None,
     ) -> None:
         super().__init__()
         self.delay_actor = delay_actor
         self.delay_value = delay_value
 
         actor_critic = ActorCriticWrapper(actor_network, value_network)
         params = make_functional(actor_critic)
@@ -68,37 +73,34 @@
             compare_against=list(actor_network.parameters()),
         )
         self.actor_critic.module[0] = self.actor_network
         self.actor_critic.module[1] = self.value_network
 
         self.actor_in_keys = actor_network.in_keys
 
-        self.register_buffer("gamma", torch.tensor(gamma))
         self.loss_funtion = loss_function
 
+        if gamma is not None:
+            warnings.warn(_GAMMA_LMBDA_DEPREC_WARNING, category=DeprecationWarning)
+            self.gamma = gamma
+
     def forward(self, input_tensordict: TensorDictBase) -> TensorDict:
         """Computes the DDPG losses given a tensordict sampled from the replay buffer.
 
         This function will also write a "td_error" key that can be used by prioritized replay buffers to assign
             a priority to items in the tensordict.
 
         Args:
             input_tensordict (TensorDictBase): a tensordict with keys ["done", "reward"] and the in_keys of the actor
                 and value networks.
 
         Returns:
             a tuple of 2 tensors containing the DDPG loss.
 
         """
-        if not input_tensordict.device == self.device:
-            raise RuntimeError(
-                f"Got device={input_tensordict.device} but "
-                f"actor_network.device={self.device} (self.device={self.device})"
-            )
-
         loss_value, td_error, pred_val, target_value = self._loss_value(
             input_tensordict,
         )
         td_error = td_error.detach()
         td_error = td_error.unsqueeze(input_tensordict.ndimension())
         if input_tensordict.device is not None:
             td_error = td_error.to(input_tensordict.device)
@@ -144,32 +146,55 @@
         td_copy = tensordict.select(*self.value_network.in_keys).detach()
         self.value_network(
             td_copy,
             params=self.value_network_params,
         )
         pred_val = td_copy.get("state_action_value").squeeze(-1)
 
-        actor_critic = self.actor_critic
         target_params = TensorDict(
             {
                 "module": {
                     "0": self.target_actor_network_params,
                     "1": self.target_value_network_params,
                 }
             },
             batch_size=self.target_actor_network_params.batch_size,
             device=self.target_actor_network_params.device,
         )
-        with set_exploration_mode("mode"):
-            target_value = next_state_value(
-                tensordict,
-                actor_critic,
-                gamma=self.gamma,
-                params=target_params,
-            )
+        target_value = self.value_estimator.value_estimate(
+            tensordict, target_params=target_params
+        ).squeeze(-1)
 
         # td_error = pred_val - target_value
         loss_value = distance_loss(
             pred_val, target_value, loss_function=self.loss_funtion
         )
 
         return loss_value, (pred_val - target_value).pow(2), pred_val, target_value
+
+    def make_value_estimator(self, value_type: ValueEstimators = None, **hyperparams):
+        if value_type is None:
+            value_type = self.default_value_estimator
+        self.value_type = value_type
+        hp = dict(default_value_kwargs(value_type))
+        if hasattr(self, "gamma"):
+            hp["gamma"] = self.gamma
+        hp.update(hyperparams)
+        value_key = "state_action_value"
+        if value_type == ValueEstimators.TD1:
+            self._value_estimator = TD1Estimator(
+                value_network=self.actor_critic, value_key=value_key, **hp
+            )
+        elif value_type == ValueEstimators.TD0:
+            self._value_estimator = TD0Estimator(
+                value_network=self.actor_critic, value_key=value_key, **hp
+            )
+        elif value_type == ValueEstimators.GAE:
+            raise NotImplementedError(
+                f"Value type {value_type} it not implemented for loss {type(self)}."
+            )
+        elif value_type == ValueEstimators.TDLambda:
+            self._value_estimator = TDLambdaEstimator(
+                value_network=self.actor_critic, value_key=value_key, **hp
+            )
+        else:
+            raise NotImplementedError(f"Unknown value type {value_type}")
```

## torchrl/objectives/deprecated.py

```diff
@@ -1,33 +1,39 @@
 # Copyright (c) Meta Platforms, Inc. and affiliates.
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
-
 import math
+import warnings
 from numbers import Number
 from typing import Tuple, Union
 
 import numpy as np
 import torch
 
 from tensordict import TensorDict
+from tensordict.nn import TensorDictModule
 from tensordict.tensordict import TensorDictBase
 from torch import Tensor
-from torchrl.envs.utils import set_exploration_mode, step_mdp
-from torchrl.modules import SafeModule
+from torchrl.envs.utils import ExplorationType, set_exploration_type, step_mdp
 from torchrl.objectives import (
+    default_value_kwargs,
     distance_loss,
     hold_out_params,
-    next_state_value as get_next_state_value,
+    ValueEstimators,
 )
 from torchrl.objectives.common import LossModule
+from torchrl.objectives.utils import _GAMMA_LMBDA_DEPREC_WARNING
+from torchrl.objectives.value import TD0Estimator, TD1Estimator, TDLambdaEstimator
 
 try:
-    from functorch import vmap
+    try:
+        from torch import vmap
+    except ImportError:
+        from functorch import vmap
 
     FUNCTORCH_ERR = ""
     _has_functorch = True
 except ImportError as err:
     FUNCTORCH_ERR = str(err)
     _has_functorch = False
 
@@ -36,53 +42,67 @@
     """REDQ Loss module.
 
     REDQ (RANDOMIZED ENSEMBLED DOUBLE Q-LEARNING: LEARNING FAST WITHOUT A MODEL
     https://openreview.net/pdf?id=AY8zfZm0tDd) generalizes the idea of using an ensemble of Q-value functions to
     train a SAC-like algorithm.
 
     Args:
-        actor_network (SafeModule): the actor to be trained
-        qvalue_network (SafeModule): a single Q-value network that will be multiplicated as many times as needed.
-        num_qvalue_nets (int, optional): Number of Q-value networks to be trained. Default is 10.
-        sub_sample_len (int, optional): number of Q-value networks to be subsampled to evaluate the next state value
-            Default is 2.
-        gamma (Number, optional): gamma decay factor. Default is 0.99.
-        priotity_key (str, optional): Key where to write the priority value for prioritized replay buffers. Default is
-            `"td_error"`.
-        loss_function (str, optional): loss function to be used for the Q-value. Can be one of  `"smooth_l1"`, "l2",
-            "l1", Default is "smooth_l1".
+        actor_network (TensorDictModule): the actor to be trained
+        qvalue_network (TensorDictModule): a single Q-value network that will
+            be multiplicated as many times as needed.
+        num_qvalue_nets (int, optional): Number of Q-value networks to be trained.
+            Default is ``10``.
+        sub_sample_len (int, optional): number of Q-value networks to be
+            subsampled to evaluate the next state value
+            Default is ``2``.
+        priority_key (str, optional): Key where to write the priority value
+            for prioritized replay buffers. Default is
+            ``"td_error"``.
+        loss_function (str, optional): loss function to be used for the Q-value.
+            Can be one of  ``"smooth_l1"``, ``"l2"``,
+            ``"l1"``, Default is ``"smooth_l1"``.
         alpha_init (float, optional): initial entropy multiplier.
-            Default is 1.0.
+            Default is ``1.0``.
         min_alpha (float, optional): min value of alpha.
-            Default is 0.1.
+            Default is ``0.1``.
         max_alpha (float, optional): max value of alpha.
-            Default is 10.0.
-        fixed_alpha (bool, optional): whether alpha should be trained to match a target entropy. Default is :obj:`False`.
-        target_entropy (Union[str, Number], optional): Target entropy for the stochastic policy. Default is "auto".
+            Default is ``10.0``.
+        fixed_alpha (bool, optional): whether alpha should be trained to match
+            a target entropy. Default is ``False``.
+        target_entropy (Union[str, Number], optional): Target entropy for the
+            stochastic policy. Default is "auto".
+        delay_qvalue (bool, optional): Whether to separate the target Q value
+            networks from the Q value networks used
+            for data collection. Default is ``False``.
+        gSDE (bool, optional): Knowing if gSDE is used is necessary to create
+            random noise variables.
+            Default is ``False``.
 
     """
 
     delay_actor: bool = False
+    default_value_estimator = ValueEstimators.TD0
 
     def __init__(
         self,
-        actor_network: SafeModule,
-        qvalue_network: SafeModule,
+        actor_network: TensorDictModule,
+        qvalue_network: TensorDictModule,
+        *,
         num_qvalue_nets: int = 10,
         sub_sample_len: int = 2,
-        gamma: Number = 0.99,
-        priotity_key: str = "td_error",
+        priority_key: str = "td_error",
         loss_function: str = "smooth_l1",
         alpha_init: float = 1.0,
         min_alpha: float = 0.1,
         max_alpha: float = 10.0,
         fixed_alpha: bool = False,
         target_entropy: Union[str, Number] = "auto",
         delay_qvalue: bool = True,
         gSDE: bool = False,
+        gamma: float = None,
     ):
         if not _has_functorch:
             raise ImportError("Failed to import functorch.") from FUNCTORCH_ERR
         super().__init__()
         self.convert_to_functional(
             actor_network,
             "actor_network",
@@ -98,16 +118,15 @@
             "qvalue_network",
             expand_dim=num_qvalue_nets,
             create_target_params=self.delay_qvalue,
             compare_against=actor_network.parameters(),
         )
         self.num_qvalue_nets = num_qvalue_nets
         self.sub_sample_len = max(1, min(sub_sample_len, num_qvalue_nets - 1))
-        self.register_buffer("gamma", torch.tensor(gamma))
-        self.priority_key = priotity_key
+        self.priority_key = priority_key
         self.loss_function = loss_function
 
         try:
             device = next(self.parameters()).device
         except AttributeError:
             device = torch.device("cpu")
 
@@ -138,14 +157,18 @@
                 )
             target_entropy = -float(np.prod(actor_network.spec["action"].shape))
         self.register_buffer(
             "target_entropy", torch.tensor(target_entropy, device=device)
         )
         self.gSDE = gSDE
 
+        if gamma is not None:
+            warnings.warn(_GAMMA_LMBDA_DEPREC_WARNING, category=DeprecationWarning)
+            self.gamma = gamma
+
     @property
     def alpha(self):
         # keep alpha is a reasonable range
         self.log_alpha.data.clamp_(self.min_log_alpha, self.max_log_alpha)
         with torch.no_grad():
             alpha = self.log_alpha.exp()
         return alpha
@@ -171,15 +194,15 @@
         )
 
         return td_out
 
     def _actor_loss(self, tensordict: TensorDictBase) -> Tuple[Tensor, Tensor]:
         obs_keys = self.actor_network.in_keys
         tensordict_clone = tensordict.select(*obs_keys)  # to avoid overwriting keys
-        with set_exploration_mode("random"):
+        with set_exploration_type(ExplorationType.RANDOM):
             self.actor_network(
                 tensordict_clone,
                 params=self.actor_network_params,
             )
 
         with hold_out_params(self.qvalue_network_params) as params:
             tensordict_expand = vmap(self.qvalue_network, (None, 0))(
@@ -193,28 +216,28 @@
         ).mean(0)
         return loss_actor, tensordict_clone.get("sample_log_prob")
 
     def _qvalue_loss(self, tensordict: TensorDictBase) -> Tensor:
         tensordict_save = tensordict
 
         obs_keys = self.actor_network.in_keys
-        tensordict = tensordict.select("next", *obs_keys, "action")
+        tensordict = tensordict.clone(False).select("next", *obs_keys, "action")
 
         selected_models_idx = torch.randperm(self.num_qvalue_nets)[
             : self.sub_sample_len
         ].sort()[0]
         with torch.no_grad():
             selected_q_params = self.target_qvalue_network_params[selected_models_idx]
 
             next_td = step_mdp(tensordict).select(
                 *self.actor_network.in_keys
             )  # next_observation ->
             # observation
             # select pseudo-action
-            with set_exploration_mode("random"):
+            with set_exploration_type(ExplorationType.RANDOM):
                 self.actor_network(
                     next_td,
                     params=self.target_actor_network_params,
                 )
             sample_log_prob = next_td.get("sample_log_prob")
             # get q-values
             next_td = vmap(self.qvalue_network, (None, 0))(
@@ -223,25 +246,21 @@
             )
             state_action_value = next_td.get("state_action_value")
             if (
                 state_action_value.shape[-len(sample_log_prob.shape) :]
                 != sample_log_prob.shape
             ):
                 sample_log_prob = sample_log_prob.unsqueeze(-1)
-            state_value = (
+            next_state_value = (
                 next_td.get("state_action_value") - self.alpha * sample_log_prob
             )
-            state_value = state_value.min(0)[0]
+            next_state_value = next_state_value.min(0)[0]
 
-        tensordict.set("next.state_value", state_value)
-        target_value = get_next_state_value(
-            tensordict,
-            gamma=self.gamma,
-            pred_next_val=state_value,
-        )
+        tensordict.set(("next", "state_value"), next_state_value)
+        target_value = self.value_estimator.value_estimate(tensordict).squeeze(-1)
         tensordict_expand = vmap(self.qvalue_network, (None, 0))(
             tensordict.select(*self.qvalue_network.in_keys),
             self.qvalue_network_params,
         )
         pred_val = tensordict_expand.get("state_action_value").squeeze(-1)
         td_error = abs(pred_val - target_value)
         loss_qval = distance_loss(
@@ -261,12 +280,41 @@
             # we can compute this loss even if log_alpha is not a parameter
             alpha_loss = -self.log_alpha.exp() * (log_pi.detach() + self.target_entropy)
         else:
             # placeholder
             alpha_loss = torch.zeros_like(log_pi)
         return alpha_loss
 
+    def make_value_estimator(self, value_type: ValueEstimators = None, **hyperparams):
+        if value_type is None:
+            value_type = self.default_value_estimator
+        self.value_type = value_type
+        hp = dict(default_value_kwargs(value_type))
+        if hasattr(self, "gamma"):
+            hp["gamma"] = self.gamma
+        hp.update(hyperparams)
+        value_key = "state_value"
+        # we do not need a value network bc the next state value is already passed
+        if value_type == ValueEstimators.TD1:
+            self._value_estimator = TD1Estimator(
+                value_network=None, value_key=value_key, **hp
+            )
+        elif value_type == ValueEstimators.TD0:
+            self._value_estimator = TD0Estimator(
+                value_network=None, value_key=value_key, **hp
+            )
+        elif value_type == ValueEstimators.GAE:
+            raise NotImplementedError(
+                f"Value type {value_type} it not implemented for loss {type(self)}."
+            )
+        elif value_type == ValueEstimators.TDLambda:
+            self._value_estimator = TDLambdaEstimator(
+                value_network=None, value_key=value_key, **hp
+            )
+        else:
+            raise NotImplementedError(f"Unknown value type {value_type}")
+
 
 class DoubleREDQLoss_deprecated(REDQLoss_deprecated):
     """[Deprecated] Class for delayed target-REDQ (which should be the default behaviour)."""
 
     delay_qvalue: bool = True
```

## torchrl/objectives/dqn.py

```diff
@@ -1,67 +1,157 @@
 # Copyright (c) Meta Platforms, Inc. and affiliates.
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
-
+import warnings
 from typing import Union
 
 import torch
-from tensordict import TensorDict
-from tensordict.tensordict import TensorDictBase
+from tensordict import TensorDict, TensorDictBase
 from torch import nn
+from torchrl.data.tensor_specs import TensorSpec
 
 from torchrl.envs.utils import step_mdp
-from torchrl.modules import DistributionalQValueActor, QValueActor
+from torchrl.modules.tensordict_module.actors import (
+    DistributionalQValueActor,
+    QValueActor,
+)
 from torchrl.modules.tensordict_module.common import ensure_tensordict_compatible
 
+from ..modules.utils.utils import _find_action_space
+
 from .common import LossModule
-from .utils import distance_loss, next_state_value
+from .utils import (
+    _GAMMA_LMBDA_DEPREC_WARNING,
+    default_value_kwargs,
+    distance_loss,
+    ValueEstimators,
+)
+from .value import TDLambdaEstimator
+from .value.advantages import TD0Estimator, TD1Estimator
 
 
 class DQNLoss(LossModule):
     """The DQN Loss class.
 
     Args:
         value_network (QValueActor or nn.Module): a Q value operator.
-        gamma (scalar): a discount factor for return computation.
+
+    Keyword Args:
         loss_function (str): loss function for the value discrepancy. Can be one of "l1", "l2" or "smooth_l1".
-        delay_value (bool, optional): whether to duplicate the value network into a new target value network to
-            create a double DQN. Default is :obj:`False`.
+        priority_key (str, optional): the key at which priority is assumed to
+            be stored within TensorDicts added to this ReplayBuffer.
+            This is to be used when the sampler is of type
+            :class:`~torchrl.data.PrioritizedSampler`.
+            Defaults to ``"td_error"``.
+        delay_value (bool, optional): whether to duplicate the value network
+            into a new target value network to
+            create a double DQN. Default is ``False``.
+        action_space (str or TensorSpec, optional): Action space. Must be one of
+            ``"one-hot"``, ``"mult_one_hot"``, ``"binary"`` or ``"categorical"``,
+            or an instance of the corresponding specs (:class:`torchrl.data.OneHotDiscreteTensorSpec`,
+            :class:`torchrl.data.MultiOneHotDiscreteTensorSpec`,
+            :class:`torchrl.data.BinaryDiscreteTensorSpec` or :class:`torchrl.data.DiscreteTensorSpec`).
+            If not provided, an attempt to retrieve it from the value network
+            will be made.
 
     """
 
+    default_value_estimator = ValueEstimators.TDLambda
+
     def __init__(
         self,
         value_network: Union[QValueActor, nn.Module],
-        gamma: float,
+        *,
         loss_function: str = "l2",
         priority_key: str = "td_error",
         delay_value: bool = False,
+        gamma: float = None,
+        action_space: Union[str, TensorSpec] = None,
     ) -> None:
 
         super().__init__()
         self.delay_value = delay_value
-
         value_network = ensure_tensordict_compatible(
-            module=value_network, wrapper_type=QValueActor
+            module=value_network,
+            wrapper_type=QValueActor,
+            action_space=action_space,
         )
 
         self.convert_to_functional(
             value_network,
             "value_network",
             create_target_params=self.delay_value,
         )
 
         self.value_network_in_keys = value_network.in_keys
 
-        self.register_buffer("gamma", torch.tensor(gamma))
         self.loss_function = loss_function
         self.priority_key = priority_key
-        self.action_space = self.value_network.action_space
+        if action_space is None:
+            # infer from value net
+            try:
+                action_space = value_network.spec
+            except AttributeError:
+                # let's try with action_space then
+                try:
+                    action_space = value_network.action_space
+                except AttributeError:
+                    raise ValueError(self.ACTION_SPEC_ERROR)
+        if action_space is None:
+            warnings.warn(
+                "action_space was not specified. DQNLoss will default to 'one-hot'."
+                "This behaviour will be deprecated soon and a space will have to be passed."
+                "Check the DQNLoss documentation to see how to pass the action space. "
+            )
+            action_space = "one-hot"
+        self.action_space = _find_action_space(action_space)
+
+        if gamma is not None:
+            warnings.warn(_GAMMA_LMBDA_DEPREC_WARNING, category=DeprecationWarning)
+            self.gamma = gamma
+
+    def make_value_estimator(self, value_type: ValueEstimators = None, **hyperparams):
+        if value_type is None:
+            value_type = self.default_value_estimator
+        self.value_type = value_type
+        hp = dict(default_value_kwargs(value_type))
+        if hasattr(self, "gamma"):
+            hp["gamma"] = self.gamma
+        hp.update(hyperparams)
+        if value_type is ValueEstimators.TD1:
+            self._value_estimator = TD1Estimator(
+                **hp,
+                value_network=self.value_network,
+                advantage_key="advantage",
+                value_target_key="value_target",
+                value_key="chosen_action_value",
+            )
+        elif value_type is ValueEstimators.TD0:
+            self._value_estimator = TD0Estimator(
+                **hp,
+                value_network=self.value_network,
+                advantage_key="advantage",
+                value_target_key="value_target",
+                value_key="chosen_action_value",
+            )
+        elif value_type is ValueEstimators.GAE:
+            raise NotImplementedError(
+                f"Value type {value_type} it not implemented for loss {type(self)}."
+            )
+        elif value_type is ValueEstimators.TDLambda:
+            self._value_estimator = TDLambdaEstimator(
+                **hp,
+                value_network=self.value_network,
+                advantage_key="advantage",
+                value_target_key="value_target",
+                value_key="chosen_action_value",
+            )
+        else:
+            raise NotImplementedError(f"Unknown value type {value_type}")
 
     def forward(self, input_tensordict: TensorDictBase) -> TensorDict:
         """Computes the DQN loss given a tensordict sampled from the replay buffer.
 
         This function will also write a "td_error" key that can be used by prioritized replay buffers to assign
             a priority to items in the tensordict.
 
@@ -87,37 +177,35 @@
                     f"found key value pair {k}-{t.shape} "
                     f"with device {t.device} when {device} was required"
                 )
 
         td_copy = tensordict.clone()
         if td_copy.device != tensordict.device:
             raise RuntimeError(f"{tensordict} and {td_copy} have different devices")
-        assert hasattr(self.value_network, "_is_stateless")
         self.value_network(
             td_copy,
             params=self.value_network_params,
         )
 
         action = tensordict.get("action")
         pred_val = td_copy.get("action_value")
 
         if self.action_space == "categorical":
+            if action.shape != pred_val.shape:
+                # unsqueeze the action if it lacks on trailing singleton dim
+                action = action.unsqueeze(-1)
             pred_val_index = torch.gather(pred_val, -1, index=action).squeeze(-1)
         else:
             action = action.to(torch.float)
             pred_val_index = (pred_val * action).sum(-1)
 
-        with torch.no_grad():
-            target_value = next_state_value(
-                tensordict,
-                self.value_network,
-                gamma=self.gamma,
-                params=self.target_value_network_params,
-                next_val_key="chosen_action_value",
-            )
+        target_value = self.value_estimator.value_estimate(
+            tensordict.clone(False), target_params=self.target_value_network_params
+        ).squeeze(-1)
+
         priority_tensor = (pred_val_index - target_value).pow(2)
         priority_tensor = priority_tensor.detach().unsqueeze(-1)
         if input_tensordict.device is not None:
             priority_tensor = priority_tensor.to(input_tensordict.device)
 
         input_tensordict.set(
             self.priority_key,
@@ -140,15 +228,22 @@
     Perspective on Reinforcement Learning",
     https://arxiv.org/pdf/1707.06887.pdf
 
     Args:
         value_network (DistributionalQValueActor or nn.Module): the distributional Q
             value operator.
         gamma (scalar): a discount factor for return computation.
-        delay_value (bool): whether to duplicate the value network into a new target value network to create double DQN
+
+            .. note::
+              Unlike :class:`DQNLoss`, this class does not currently support
+              custom value functions. The next value estimation is always
+              bootstrapped.
+
+        delay_value (bool): whether to duplicate the value network into a new
+            target value network to create double DQN
     """
 
     def __init__(
         self,
         value_network: Union[DistributionalQValueActor, nn.Module],
         gamma: float,
         priority_key: str = "td_error",
@@ -176,19 +271,20 @@
         log_ps_a = action_log_softmax.masked_select(action_expand.to(torch.bool))
         log_ps_a = log_ps_a.view(batch_size, atoms)  # log p(s_t, a_t; θonline)
         return log_ps_a
 
     @staticmethod
     def _log_ps_a_categorical(action, action_log_softmax):
         # Reshaping action of shape `[*batch_sizes, 1]` to `[*batch_sizes, atoms, 1]` for gather.
+        if action.shape[-1] != 1:
+            action = action.unsqueeze(-1)
         action = action.unsqueeze(-2)
         new_shape = [-1] * len(action.shape)
         new_shape[-2] = action_log_softmax.shape[-2]  # calculating atoms
         action = action.expand(new_shape)
-
         return torch.gather(action_log_softmax, -1, index=action).squeeze(-1)
 
     def forward(self, input_tensordict: TensorDictBase) -> TensorDict:
         # from https://github.com/Kaixhin/Rainbow/blob/9ff5567ad1234ae0ed30d8471e8f13ae07119395/agent.py
         device = self.device
         tensordict = TensorDict(
             source=input_tensordict, batch_size=input_tensordict.batch_size
@@ -256,14 +352,15 @@
             # Tz = R^n + (γ^n)z (accounting for terminal states)
             if isinstance(discount, torch.Tensor):
                 discount = discount.to("cpu")
             done = done.to("cpu")
             reward = reward.to("cpu")
             support = support.to("cpu")
             pns_a = pns_a.to("cpu")
+
             Tz = reward + (1 - done.to(reward.dtype)) * discount * support
             if Tz.shape != torch.Size([batch_size, atoms]):
                 raise RuntimeError(
                     "Tz shape must be torch.Size([batch_size, atoms]), "
                     f"got Tz.shape={Tz.shape} and batch_size={batch_size}, "
                     f"atoms={atoms}"
                 )
@@ -302,7 +399,32 @@
         input_tensordict.set(
             self.priority_key,
             loss.detach().unsqueeze(1).to(input_tensordict.device),
             inplace=True,
         )
         loss_td = TensorDict({"loss": loss.mean()}, [])
         return loss_td
+
+    def make_value_estimator(self, value_type: ValueEstimators = None, **hyperparams):
+        if value_type is None:
+            value_type = self.default_value_estimator
+        self.value_type = value_type
+        if value_type is ValueEstimators.TD1:
+            raise NotImplementedError(
+                f"value type {value_type} is not implemented for {self.__class__.__name__}."
+            )
+        elif value_type is ValueEstimators.TD0:
+            # see forward call
+            pass
+        elif value_type is ValueEstimators.GAE:
+            raise NotImplementedError(
+                f"value type {value_type} is not implemented for {self.__class__.__name__}."
+            )
+        elif value_type is ValueEstimators.TDLambda:
+            raise NotImplementedError(
+                f"value type {value_type} is not implemented for {self.__class__.__name__}."
+            )
+        else:
+            raise NotImplementedError(f"Unknown value type {value_type}")
+
+    def _default_value_estimator(self):
+        self.make_value_estimator(ValueEstimators.TD0)
```

## torchrl/objectives/dreamer.py

```diff
@@ -1,52 +1,62 @@
 # Copyright (c) Meta Platforms, Inc. and affiliates.
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
+import warnings
 from typing import Optional, Tuple
 
 import torch
 from tensordict import TensorDict
+from tensordict.nn import TensorDictModule
 
 from torchrl.envs.model_based.dreamer import DreamerEnv
-from torchrl.envs.utils import set_exploration_mode, step_mdp
-from torchrl.modules import SafeModule
+from torchrl.envs.utils import ExplorationType, set_exploration_type, step_mdp
 from torchrl.objectives.common import LossModule
-from torchrl.objectives.utils import distance_loss, hold_out_net
-from torchrl.objectives.value.functional import vec_td_lambda_return_estimate
+from torchrl.objectives.utils import (
+    _GAMMA_LMBDA_DEPREC_WARNING,
+    default_value_kwargs,
+    distance_loss,
+    hold_out_net,
+    ValueEstimators,
+)
+from torchrl.objectives.value import TD0Estimator, TD1Estimator, TDLambdaEstimator
 
 
 class DreamerModelLoss(LossModule):
     """Dreamer Model Loss.
 
-    Computes the loss of the dreamer world model. The loss is composed of the kl divergence between the prior and posterior of the RSSM,
-    the reconstruction loss over the reconstructed observation and the reward loss over the predicted reward.
+    Computes the loss of the dreamer world model. The loss is composed of the
+    kl divergence between the prior and posterior of the RSSM,
+    the reconstruction loss over the reconstructed observation and the reward
+    loss over the predicted reward.
 
     Reference: https://arxiv.org/abs/1912.01603.
 
     Args:
-        world_model (SafeModule): the world model.
+        world_model (TensorDictModule): the world model.
         lambda_kl (float, optional): the weight of the kl divergence loss. Default: 1.0.
         lambda_reco (float, optional): the weight of the reconstruction loss. Default: 1.0.
         lambda_reward (float, optional): the weight of the reward loss. Default: 1.0.
         reco_loss (str, optional): the reconstruction loss. Default: "l2".
         reward_loss (str, optional): the reward loss. Default: "l2".
         free_nats (int, optional): the free nats. Default: 3.
-        delayed_clamp (bool, optional): if True, the KL clamping occurs after
+        delayed_clamp (bool, optional): if ``True``, the KL clamping occurs after
             averaging. If False (default), the kl divergence is clamped to the
             free nats value first and then averaged.
-        global_average (bool, optional): if True, the losses will be averaged
+        global_average (bool, optional): if ``True``, the losses will be averaged
             over all dimensions. Otherwise, a sum will be performed over all
             non-batch/time dimensions and an average over batch and time.
             Default: False.
     """
 
     def __init__(
         self,
-        world_model: SafeModule,
+        world_model: TensorDictModule,
+        *,
         lambda_kl: float = 1.0,
         lambda_reco: float = 1.0,
         lambda_reward: float = 1.0,
         reco_loss: Optional[str] = None,
         reward_loss: Optional[str] = None,
         free_nats: int = 3,
         delayed_clamp: bool = False,
@@ -125,56 +135,64 @@
             kl = kl.clamp_min(self.free_nats).mean()
         return kl
 
 
 class DreamerActorLoss(LossModule):
     """Dreamer Actor Loss.
 
-    Computes the loss of the dreamer actor. The actor loss is computed as the negative average lambda return.
+    Computes the loss of the dreamer actor. The actor loss is computed as the
+    negative average lambda return.
 
     Reference: https://arxiv.org/abs/1912.01603.
 
     Args:
-        actor_model (SafeModule): the actor model.
-        value_model (SafeModule): the value model.
+        actor_model (TensorDictModule): the actor model.
+        value_model (TensorDictModule): the value model.
         model_based_env (DreamerEnv): the model based environment.
         imagination_horizon (int, optional): The number of steps to unroll the
-            model. Default: 15.
-        gamma (float, optional): the gamma discount factor. Default: 0.99.
-        lmbda (float, optional): the lambda discount factor factor. Default: 0.95.
-        discount_loss (bool, optional): if True, the loss is discounted with a
-            gamma discount factor. Default: False.
+            model. Defaults to ``15``.
+        discount_loss (bool, optional): if ``True``, the loss is discounted with a
+            gamma discount factor. Default to ``False``.
 
     """
 
+    default_value_estimator = ValueEstimators.TDLambda
+
     def __init__(
         self,
-        actor_model: SafeModule,
-        value_model: SafeModule,
+        actor_model: TensorDictModule,
+        value_model: TensorDictModule,
         model_based_env: DreamerEnv,
+        *,
         imagination_horizon: int = 15,
-        gamma: int = 0.99,
-        lmbda: int = 0.95,
         discount_loss: bool = False,  # for consistency with paper
+        gamma: int = None,
+        lmbda: int = None,
     ):
         super().__init__()
         self.actor_model = actor_model
         self.value_model = value_model
         self.model_based_env = model_based_env
         self.imagination_horizon = imagination_horizon
-        self.gamma = gamma
-        self.lmbda = lmbda
         self.discount_loss = discount_loss
+        if gamma is not None:
+            warnings.warn(_GAMMA_LMBDA_DEPREC_WARNING, category=DeprecationWarning)
+            self.gamma = gamma
+        if lmbda is not None:
+            warnings.warn(_GAMMA_LMBDA_DEPREC_WARNING, category=DeprecationWarning)
+            self.lmbda = lmbda
 
     def forward(self, tensordict: TensorDict) -> Tuple[TensorDict, TensorDict]:
         with torch.no_grad():
             tensordict = tensordict.select("state", "belief")
             tensordict = tensordict.reshape(-1)
 
-        with hold_out_net(self.model_based_env), set_exploration_mode("random"):
+        with hold_out_net(self.model_based_env), set_exploration_type(
+            ExplorationType.RANDOM
+        ):
             tensordict = self.model_based_env.reset(tensordict.clone(recurse=False))
             fake_data = self.model_based_env.rollout(
                 max_steps=self.imagination_horizon,
                 policy=self.actor_model,
                 auto_reset=False,
                 tensordict=tensordict,
             )
@@ -188,54 +206,103 @@
 
         reward = fake_data.get(("next", "reward"))
         next_value = next_tensordict.get("state_value")
         lambda_target = self.lambda_target(reward, next_value)
         fake_data.set("lambda_target", lambda_target)
 
         if self.discount_loss:
-            discount = self.gamma * torch.ones_like(
-                lambda_target, device=tensordict.device
-            )
+            gamma = self.value_estimator.gamma.to(tensordict.device)
+            discount = gamma.expand(lambda_target.shape)
             discount[..., 0, :] = 1
             discount = discount.cumprod(dim=-2)
             actor_loss = -(lambda_target * discount).sum((-2, -1)).mean()
         else:
             actor_loss = -lambda_target.sum((-2, -1)).mean()
         loss_tensordict = TensorDict({"loss_actor": actor_loss}, [])
         return loss_tensordict, fake_data.detach()
 
     def lambda_target(self, reward: torch.Tensor, value: torch.Tensor) -> torch.Tensor:
         done = torch.zeros(reward.shape, dtype=torch.bool, device=reward.device)
-        return vec_td_lambda_return_estimate(
-            self.gamma, self.lmbda, value, reward, done
+        input_tensordict = TensorDict(
+            {
+                ("next", "reward"): reward,
+                ("next", "state_value"): value,
+                ("next", "done"): done,
+            },
+            [],
         )
+        return self.value_estimator.value_estimate(input_tensordict)
+
+    def make_value_estimator(self, value_type: ValueEstimators = None, **hyperparams):
+        if value_type is None:
+            value_type = self.default_value_estimator
+        self.value_type = value_type
+        value_net = None
+        value_key = "state_value"
+        hp = dict(default_value_kwargs(value_type))
+        if hasattr(self, "gamma"):
+            hp["gamma"] = self.gamma
+        hp.update(hyperparams)
+        if value_type is ValueEstimators.TD1:
+            self._value_estimator = TD1Estimator(
+                **hp,
+                value_network=value_net,
+                value_target_key="value_target",
+                value_key=value_key,
+            )
+        elif value_type is ValueEstimators.TD0:
+            self._value_estimator = TD0Estimator(
+                **hp,
+                value_network=value_net,
+                value_target_key="value_target",
+                value_key=value_key,
+            )
+        elif value_type is ValueEstimators.GAE:
+            if hasattr(self, "lmbda"):
+                hp["lmbda"] = self.lmbda
+            raise NotImplementedError(
+                f"Value type {value_type} it not implemented for loss {type(self)}."
+            )
+        elif value_type is ValueEstimators.TDLambda:
+            if hasattr(self, "lmbda"):
+                hp["lmbda"] = self.lmbda
+            self._value_estimator = TDLambdaEstimator(
+                **hp,
+                value_network=value_net,
+                value_target_key="value_target",
+                value_key=value_key,
+            )
+        else:
+            raise NotImplementedError(f"Unknown value type {value_type}")
 
 
 class DreamerValueLoss(LossModule):
     """Dreamer Value Loss.
 
-    Computes the loss of the dreamer value model. The value loss is computed between the predicted value and the lambda target.
+    Computes the loss of the dreamer value model. The value loss is computed
+    between the predicted value and the lambda target.
 
     Reference: https://arxiv.org/abs/1912.01603.
 
     Args:
-        value_model (SafeModule): the value model.
-        value_loss (str, optional): the loss to use for the value loss. Default: "l2".
-        gamma (float, optional): the gamma discount factor. Default: 0.99.
-        discount_loss (bool, optional): if True, the loss is discounted with a
+        value_model (TensorDictModule): the value model.
+        value_loss (str, optional): the loss to use for the value loss.
+            Default: ``"l2"``.
+        discount_loss (bool, optional): if ``True``, the loss is discounted with a
             gamma discount factor. Default: False.
+        gamma (float, optional): the gamma discount factor. Default: ``0.99``.
 
     """
 
     def __init__(
         self,
-        value_model: SafeModule,
+        value_model: TensorDictModule,
         value_loss: Optional[str] = None,
-        gamma: int = 0.99,
         discount_loss: bool = False,  # for consistency with paper
+        gamma: int = 0.99,
     ):
         super().__init__()
         self.value_model = value_model
         self.value_loss = value_loss if value_loss is not None else "l2"
         self.gamma = gamma
         self.discount_loss = discount_loss
```

## torchrl/objectives/iql.py

```diff
@@ -1,27 +1,34 @@
 # Copyright (c) Meta Platforms, Inc. and affiliates.
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
-
-from numbers import Number
+import warnings
 from typing import Optional, Tuple
 
 import torch
+from tensordict.nn import TensorDictModule
 from tensordict.tensordict import TensorDict, TensorDictBase
 from torch import Tensor
 
-from torchrl.modules import ProbabilisticActor, SafeModule
-from torchrl.objectives.utils import distance_loss, next_state_value
-
-from ..envs.utils import set_exploration_mode, step_mdp
-from .common import LossModule
+from torchrl.modules import ProbabilisticActor
+from torchrl.objectives.common import LossModule
+from torchrl.objectives.utils import (
+    _GAMMA_LMBDA_DEPREC_WARNING,
+    default_value_kwargs,
+    distance_loss,
+    ValueEstimators,
+)
+from torchrl.objectives.value import TD0Estimator, TD1Estimator, TDLambdaEstimator
 
 try:
-    from functorch import vmap
+    try:
+        from torch import vmap
+    except ImportError:
+        from functorch import vmap
 
     _has_functorch = True
     err = ""
 except ImportError as err:
     _has_functorch = False
     FUNCTORCH_ERROR = err
 
@@ -29,48 +36,46 @@
 class IQLLoss(LossModule):
     r"""TorchRL implementation of the IQL loss.
 
     Presented in "Offline Reinforcement Learning with Implicit Q-Learning" https://arxiv.org/abs/2110.06169
 
     Args:
         actor_network (ProbabilisticActor): stochastic actor
-        qvalue_network (SafeModule): Q(s, a) parametric model
-        value_network (SafeModule, optional): V(s) parametric model. If not
-            provided, the second version of SAC is assumed.
-        qvalue_network_bis (ProbabilisticTDModule, optional): if required, the
-            Q-value can be computed twice independently using two separate
-            networks. The minimum predicted value will then be used for
-            inference.
-        gamma (number, optional): discount for return computation
-            Default is 0.99
+        qvalue_network (TensorDictModule): Q(s, a) parametric model
+        value_network (TensorDictModule, optional): V(s) parametric model.
+        num_qvalue_nets (integer, optional): number of Q-Value networks used.
+            Defaults to ``2``.
         priority_key (str, optional): tensordict key where to write the
             priority (for prioritized replay buffer usage). Default is
             `"td_error"`.
         loss_function (str, optional): loss function to be used with
             the value function loss. Default is `"smooth_l1"`.
         temperature (float, optional):  Inverse temperature (beta).
             For smaller hyperparameter values, the objective behaves similarly to
             behavioral cloning, while for larger values, it attempts to recover the
             maximum of the Q-function.
         expectile (float, optional): expectile :math:`\tau`. A larger value of :math:`\tau` is crucial
             for antmaze tasks that require dynamical programming ("stichting").
 
     """
 
+    default_value_estimator = ValueEstimators.TD0
+
     def __init__(
         self,
         actor_network: ProbabilisticActor,
-        qvalue_network: SafeModule,
-        value_network: Optional[SafeModule] = None,
+        qvalue_network: TensorDictModule,
+        value_network: Optional[TensorDictModule],
+        *,
         num_qvalue_nets: int = 2,
-        gamma: Number = 0.99,
-        priotity_key: str = "td_error",
+        priority_key: str = "td_error",
         loss_function: str = "smooth_l1",
         temperature: float = 1.0,
         expectile: float = 0.5,
+        gamma: float = None,
     ) -> None:
         if not _has_functorch:
             raise ImportError("Failed to import functorch.") from FUNCTORCH_ERROR
         super().__init__()
 
         # IQL parameter
         self.temperature = temperature
@@ -101,17 +106,19 @@
             "qvalue_network",
             num_qvalue_nets,
             create_target_params=True,
             compare_against=list(actor_network.parameters())
             + list(value_network.parameters()),
         )
 
-        self.register_buffer("gamma", torch.tensor(gamma))
-        self.priority_key = priotity_key
+        self.priority_key = priority_key
         self.loss_function = loss_function
+        if gamma is not None:
+            warnings.warn(_GAMMA_LMBDA_DEPREC_WARNING, category=DeprecationWarning)
+            self.gamma = gamma
 
     @property
     def device(self) -> torch.device:
         for p in self.parameters():
             return p.device
         raise RuntimeError(
             "At least one of the networks of SACLoss must have trainable " "parameters."
@@ -157,19 +164,18 @@
         return TensorDict(
             out,
             [],
         )
 
     def _loss_actor(self, tensordict: TensorDictBase) -> Tensor:
         # KL loss
-        with set_exploration_mode("mode"):
-            dist = self.actor_network.get_dist(
-                tensordict,
-                params=self.actor_network_params,
-            )
+        dist = self.actor_network.get_dist(
+            tensordict,
+            params=self.actor_network_params,
+        )
 
         log_prob = dist.log_prob(tensordict["action"])
 
         # Min Q value
         td_q = tensordict.select(*self.qvalue_network.in_keys)
         td_q = vmap(self.qvalue_network, (None, 0))(
             td_q, self.target_qvalue_network_params
@@ -213,34 +219,17 @@
         value_loss = self.loss_value_diff(min_q - value, self.expectile).mean()
         return value_loss
 
     def _loss_qvalue(self, tensordict: TensorDictBase) -> Tuple[Tensor, Tensor]:
         obs_keys = self.actor_network.in_keys
         tensordict = tensordict.select("next", *obs_keys, "action")
 
-        with torch.no_grad():
-            next_td = step_mdp(tensordict).select(
-                *self.actor_network.in_keys
-            )  # next_observation ->
-            # observation
-            # select pseudo-action
-            # get state values
-            next_td = self.value_network(
-                next_td,
-                params=self.value_network_params,
-            )
-
-            state_value = next_td.get("state_value")
-
-        tensordict.set("next.state_value", state_value)
-        target_value = next_state_value(
-            tensordict,
-            gamma=self.gamma,
-            pred_next_val=state_value,
-        )
+        target_value = self.value_estimator.value_estimate(
+            tensordict, target_params=self.target_value_network_params
+        ).squeeze(-1)
         tensordict_expand = vmap(self.qvalue_network, (None, 0))(
             tensordict.select(*self.qvalue_network.in_keys),
             self.qvalue_network_params,
         )
         pred_val = tensordict_expand.get("state_action_value").squeeze(-1)
         td_error = abs(pred_val - target_value)
         loss_qval = (
@@ -249,7 +238,46 @@
                 target_value.expand_as(pred_val),
                 loss_function=self.loss_function,
             )
             .sum(0)
             .mean()
         )
         return loss_qval, td_error.detach().max(0)[0]
+
+    def make_value_estimator(self, value_type: ValueEstimators = None, **hyperparams):
+        if value_type is None:
+            value_type = self.default_value_estimator
+        self.value_type = value_type
+        value_net = self.value_network
+
+        value_key = "state_value"
+        hp = dict(default_value_kwargs(value_type))
+        if hasattr(self, "gamma"):
+            hp["gamma"] = self.gamma
+        hp.update(hyperparams)
+        if value_type is ValueEstimators.TD1:
+            self._value_estimator = TD1Estimator(
+                **hp,
+                value_network=value_net,
+                value_target_key="value_target",
+                value_key=value_key,
+            )
+        elif value_type is ValueEstimators.TD0:
+            self._value_estimator = TD0Estimator(
+                **hp,
+                value_network=value_net,
+                value_target_key="value_target",
+                value_key=value_key,
+            )
+        elif value_type is ValueEstimators.GAE:
+            raise NotImplementedError(
+                f"Value type {value_type} it not implemented for loss {type(self)}."
+            )
+        elif value_type is ValueEstimators.TDLambda:
+            self._value_estimator = TDLambdaEstimator(
+                **hp,
+                value_network=value_net,
+                value_target_key="value_target",
+                value_key=value_key,
+            )
+        else:
+            raise NotImplementedError(f"Unknown value type {value_type}")
```

## torchrl/objectives/ppo.py

```diff
@@ -1,95 +1,171 @@
 # Copyright (c) Meta Platforms, Inc. and affiliates.
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
-
 import math
+import warnings
 from typing import Tuple
 
 import torch
+from tensordict.nn import ProbabilisticTensorDictSequential, TensorDictModule
 from tensordict.tensordict import TensorDict, TensorDictBase
 from torch import distributions as d
 
-from torchrl.modules import SafeModule
-from torchrl.objectives.utils import distance_loss
+from torchrl.objectives.utils import (
+    _GAMMA_LMBDA_DEPREC_WARNING,
+    default_value_kwargs,
+    distance_loss,
+    ValueEstimators,
+)
 
-from ..modules.tensordict_module import SafeProbabilisticSequential
 from .common import LossModule
+from .value import GAE, TD0Estimator, TD1Estimator, TDLambdaEstimator
 
 
 class PPOLoss(LossModule):
     """A parent PPO loss class.
 
-    PPO (Proximal Policy Optimisation) is a model-free, online RL algorithm that makes use of a recorded (batch of)
-    trajectories to perform several optimization steps, while actively preventing the updated policy to deviate too
+    PPO (Proximal Policy Optimisation) is a model-free, online RL algorithm
+    that makes use of a recorded (batch of)
+    trajectories to perform several optimization steps, while actively
+    preventing the updated policy to deviate too
     much from its original parameter configuration.
 
-    PPO loss can be found in different flavours, depending on the way the constrained optimisation is implemented:
-        ClipPPOLoss and KLPENPPOLoss.
-    Unlike its subclasses, this class does not implement any regularisation and should therefore be used cautiously.
+    PPO loss can be found in different flavours, depending on the way the
+    constrained optimisation is implemented: ClipPPOLoss and KLPENPPOLoss.
+    Unlike its subclasses, this class does not implement any regularisation
+    and should therefore be used cautiously.
 
     For more details regarding PPO, refer to: "Proximal Policy Optimization Algorithms",
     https://arxiv.org/abs/1707.06347
 
     Args:
-        actor (SafeProbabilisticSequential): policy operator.
+        actor (ProbabilisticTensorDictSequential): policy operator.
         critic (ValueOperator): value operator.
-        advantage_key (str): the input tensordict key where the advantage is expected to be written.
-            default: "advantage"
-        entropy_bonus (bool): if True, an entropy bonus will be added to the loss to favour exploratory policies.
-        samples_mc_entropy (int): if the distribution retrieved from the policy operator does not have a closed form
-            formula for the entropy, a Monte-Carlo estimate will be used. samples_mc_entropy will control how many
+
+    Keyword Args:
+        advantage_key (str, optional): the input tensordict key where the advantage is
+            expected to be written.
+            Defaults to ``"advantage"``.
+        value_target_key (str, optional): the input tensordict key where the target state
+            value is expected to be written. Defaults to ``"value_target"``.
+        value_key (str, optional): the input tensordict key where the state
+            value is expected to be written. Defaults to ``"state_value"``.
+        entropy_bonus (bool, optional): if ``True``, an entropy bonus will be added to the
+            loss to favour exploratory policies.
+        samples_mc_entropy (int, optional): if the distribution retrieved from the policy
+            operator does not have a closed form
+            formula for the entropy, a Monte-Carlo estimate will be used.
+            ``samples_mc_entropy`` will control how many
             samples will be used to compute this estimate.
-            default: 1
-        entropy_coef (scalar): entropy multiplier when computing the total loss.
-            default: 0.01
-        critic_coef (scalar): critic loss multiplier when computing the total loss.
-            default: 1.0
-        gamma (scalar): a discount factor for return computation.
-        loss_function (str): loss function for the value discrepancy. Can be one of "l1", "l2" or "smooth_l1".
-        normalize_advantage (bool): if True, the advantage will be normalized before being used.
-            Defaults to False.
+            Defaults to ``1``.
+        entropy_coef (scalar, optional): entropy multiplier when computing the total loss.
+            Defaults to ``0.01``.
+        critic_coef (scalar, optional): critic loss multiplier when computing the total
+            loss. Defaults to ``1.0``.
+        loss_critic_type (str, optional): loss function for the value discrepancy.
+            Can be one of "l1", "l2" or "smooth_l1". Defaults to ``"smooth_l1"``.
+        normalize_advantage (bool, optional): if ``True``, the advantage will be normalized
+            before being used. Defaults to ``False``.
+        separate_losses (bool, optional): if ``True``, shared parameters between
+            policy and critic will only be trained on the policy loss.
+            Defaults to ``False``, ie. gradients are propagated to shared
+            parameters for both policy and critic losses.
+
+    .. note::
+      The advantage (typically GAE) can be computed by the loss function or
+      in the training loop. The latter option is usually preferred, but this is
+      up to the user to choose which option is to be preferred.
+      If the advantage key (``"advantage`` by default) is not present in the
+      input tensordict, the advantage will be computed by the :meth:`~.forward`
+      method.
+
+        >>> ppo_loss = PPOLoss(actor, critic)
+        >>> advantage = GAE(critic)
+        >>> data = next(datacollector)
+        >>> losses = ppo_loss(data)
+        >>> # equivalent
+        >>> advantage(data)
+        >>> losses = ppo_loss(data)
+
+      A custom advantage module can be built using :meth:`~.make_value_estimator`.
+      The default is :class:`~torchrl.objectives.value.GAE` with hyperparameters
+      dictated by :func:`~torchrl.objectives.utils.default_value_kwargs`.
+
+        >>> ppo_loss = PPOLoss(actor, critic)
+        >>> ppo_loss.make_value_estimator(ValueEstimators.TDLambda)
+        >>> data = next(datacollector)
+        >>> losses = ppo_loss(data)
+
+    .. note::
+      If the actor and the value function share parameters, one can avoid
+      calling the common module multiple times by passing only the head of the
+      value network to the PPO loss module:
+
+        >>> common = SomeModule(in_keys=["observation"], out_keys=["hidden"])
+        >>> actor_head = SomeActor(in_keys=["hidden"])
+        >>> value_head = SomeValue(in_keys=["hidden"])
+        >>> # first option, with 2 calls on the common module
+        >>> model = ActorCriticOperator(common, actor_head, value_head)
+        >>> loss_module = PPOLoss(model.get_policy_operator(), model.get_value_operator())
+        >>> # second option, with a single call to the common module
+        >>> loss_module = PPOLoss(ProbabilisticTensorDictSequential(model, actor_head), value_head)
+
+      This will work regardless of whether separate_losses is activated or not.
 
     """
 
+    default_value_estimator = ValueEstimators.GAE
+
     def __init__(
         self,
-        actor: SafeProbabilisticSequential,
-        critic: SafeModule,
+        actor: ProbabilisticTensorDictSequential,
+        critic: TensorDictModule,
+        *,
         advantage_key: str = "advantage",
         value_target_key: str = "value_target",
+        value_key: str = "state_value",
         entropy_bonus: bool = True,
         samples_mc_entropy: int = 1,
         entropy_coef: float = 0.01,
         critic_coef: float = 1.0,
-        gamma: float = 0.99,
         loss_critic_type: str = "smooth_l1",
         normalize_advantage: bool = False,
+        gamma: float = None,
+        separate_losses: bool = False,
     ):
         super().__init__()
         self.convert_to_functional(
             actor, "actor", funs_to_decorate=["forward", "get_dist"]
         )
-        # we want to make sure there are no duplicates in the params: the
-        # params of critic must be refs to actor if they're shared
-        self.convert_to_functional(critic, "critic", compare_against=self.actor_params)
+        if separate_losses:
+            # we want to make sure there are no duplicates in the params: the
+            # params of critic must be refs to actor if they're shared
+            policy_params = list(actor.parameters())
+        else:
+            policy_params = None
+        self.convert_to_functional(critic, "critic", compare_against=policy_params)
         self.advantage_key = advantage_key
         self.value_target_key = value_target_key
+        self.value_key = value_key
         self.samples_mc_entropy = samples_mc_entropy
-        self.entropy_bonus = entropy_bonus and entropy_coef
+        self.entropy_bonus = entropy_bonus
+        self.separate_losses = separate_losses
         self.register_buffer(
             "entropy_coef", torch.tensor(entropy_coef, device=self.device)
         )
         self.register_buffer(
             "critic_coef", torch.tensor(critic_coef, device=self.device)
         )
-        self.register_buffer("gamma", torch.tensor(gamma, device=self.device))
         self.loss_critic_type = loss_critic_type
         self.normalize_advantage = normalize_advantage
+        if gamma is not None:
+            warnings.warn(_GAMMA_LMBDA_DEPREC_WARNING, category=DeprecationWarning)
+            self.gamma = gamma
 
     def reset(self) -> None:
         pass
 
     def get_entropy_bonus(self, dist: d.Distribution) -> torch.Tensor:
         try:
             entropy = dist.entropy()
@@ -101,52 +177,71 @@
     def _log_weight(
         self, tensordict: TensorDictBase
     ) -> Tuple[torch.Tensor, d.Distribution]:
         # current log_prob of actions
         action = tensordict.get("action")
         if action.requires_grad:
             raise RuntimeError("tensordict stored action requires grad.")
-        tensordict_clone = tensordict.select(*self.actor.in_keys).clone()
 
-        dist = self.actor.get_dist(tensordict_clone, params=self.actor_params)
+        dist = self.actor.get_dist(tensordict, params=self.actor_params)
         log_prob = dist.log_prob(action)
 
         prev_log_prob = tensordict.get("sample_log_prob")
         if prev_log_prob.requires_grad:
             raise RuntimeError("tensordict prev_log_prob requires grad.")
 
         log_weight = (log_prob - prev_log_prob).unsqueeze(-1)
         return log_weight, dist
 
     def loss_critic(self, tensordict: TensorDictBase) -> torch.Tensor:
+        # TODO: if the advantage is gathered by forward, this introduces an
+        # overhead that we could easily reduce.
+        if self.separate_losses:
+            tensordict = tensordict.detach()
         try:
             target_return = tensordict.get(self.value_target_key)
-            tensordict_select = tensordict.select(*self.critic.in_keys)
-            state_value = self.critic(
-                tensordict_select,
-                params=self.critic_params,
-            ).get("state_value")
-            loss_value = distance_loss(
-                target_return,
-                state_value,
-                loss_function=self.loss_critic_type,
-            )
         except KeyError:
             raise KeyError(
                 f"the key {self.value_target_key} was not found in the input tensordict. "
                 f"Make sure you provided the right key and the value_target (i.e. the target "
                 f"return) has been retrieved accordingly. Advantage classes such as GAE, "
                 f"TDLambdaEstimate and TDEstimate all return a 'value_target' entry that "
                 f"can be used for the value loss."
             )
+
+        state_value_td = self.critic(
+            tensordict,
+            params=self.critic_params,
+        )
+
+        try:
+            state_value = state_value_td.get(self.value_key)
+        except KeyError:
+            raise KeyError(
+                f"the key {self.value_key} was not found in the input tensordict. "
+                f"Make sure that the value_key passed to PPO is accurate."
+            )
+
+        loss_value = distance_loss(
+            target_return,
+            state_value,
+            loss_function=self.loss_critic_type,
+        )
         return self.critic_coef * loss_value
 
     def forward(self, tensordict: TensorDictBase) -> TensorDictBase:
         tensordict = tensordict.clone(False)
-        advantage = tensordict.get(self.advantage_key)
+        advantage = tensordict.get(self.advantage_key, None)
+        if advantage is None:
+            self.value_estimator(
+                tensordict,
+                params=self.critic_params.detach(),
+                target_params=self.target_critic_params,
+            )
+            advantage = tensordict.get(self.advantage_key)
         if self.normalize_advantage and advantage.numel() > 1:
             loc = advantage.mean().item()
             scale = advantage.std().clamp_min(1e-6).item()
             advantage = (advantage - loc) / scale
 
         log_weight, dist = self._log_weight(tensordict)
         neg_loss = (log_weight.exp() * advantage).mean()
@@ -156,84 +251,183 @@
             td_out.set("entropy", entropy.mean().detach())  # for logging
             td_out.set("loss_entropy", -self.entropy_coef * entropy.mean())
         if self.critic_coef:
             loss_critic = self.loss_critic(tensordict).mean()
             td_out.set("loss_critic", loss_critic.mean())
         return td_out
 
+    def make_value_estimator(self, value_type: ValueEstimators = None, **hyperparams):
+        if value_type is None:
+            value_type = self.default_value_estimator
+        self.value_type = value_type
+        hp = dict(default_value_kwargs(value_type))
+        if hasattr(self, "gamma"):
+            hp["gamma"] = self.gamma
+        hp.update(hyperparams)
+        value_key = "state_value"
+        if value_type == ValueEstimators.TD1:
+            self._value_estimator = TD1Estimator(
+                value_network=self.critic, value_key=value_key, **hp
+            )
+        elif value_type == ValueEstimators.TD0:
+            self._value_estimator = TD0Estimator(
+                value_network=self.critic, value_key=value_key, **hp
+            )
+        elif value_type == ValueEstimators.GAE:
+            self._value_estimator = GAE(
+                value_network=self.critic, value_key=value_key, **hp
+            )
+        elif value_type == ValueEstimators.TDLambda:
+            self._value_estimator = TDLambdaEstimator(
+                value_network=self.critic, value_key=value_key, **hp
+            )
+        else:
+            raise NotImplementedError(f"Unknown value type {value_type}")
+
 
 class ClipPPOLoss(PPOLoss):
     """Clipped PPO loss.
 
     The clipped importance weighted loss is computed as follows:
         loss = -min( weight * advantage, min(max(weight, 1-eps), 1+eps) * advantage)
 
     Args:
-        actor (SafeProbabilisticSequential): policy operator.
+        actor (ProbabilisticTensorDictSequential): policy operator.
         critic (ValueOperator): value operator.
-        advantage_key (str): the input tensordict key where the advantage is expected to be written.
-            default: "advantage"
-        clip_epsilon (scalar): weight clipping threshold in the clipped PPO loss equation.
+
+    Keyword Args:
+        advantage_key (str, optional): the input tensordict key where the advantage is expected to be written.
+            Defaults to ``"advantage"``.
+        value_target_key (str, optional): the input tensordict key where the target state
+            value is expected to be written. Defaults to ``"value_target"``.
+        value_key (str, optional): the input tensordict key where the state
+            value is expected to be written. Defaults to ``"state_value"``.
+        clip_epsilon (scalar, optional): weight clipping threshold in the clipped PPO loss equation.
             default: 0.2
-        entropy_bonus (bool): if True, an entropy bonus will be added to the loss to favour exploratory policies.
-        samples_mc_entropy (int): if the distribution retrieved from the policy operator does not have a closed form
-            formula for the entropy, a Monte-Carlo estimate will be used. samples_mc_entropy will control how many
+        entropy_bonus (bool, optional): if ``True``, an entropy bonus will be added to the
+            loss to favour exploratory policies.
+        samples_mc_entropy (int, optional): if the distribution retrieved from the policy
+            operator does not have a closed form
+            formula for the entropy, a Monte-Carlo estimate will be used.
+            ``samples_mc_entropy`` will control how many
             samples will be used to compute this estimate.
-            default: 1
-        entropy_coef (scalar): entropy multiplier when computing the total loss.
-            default: 0.01
-        critic_coef (scalar): critic loss multiplier when computing the total loss.
-            default: 1.0
-        gamma (scalar): a discount factor for return computation.
-        loss_function (str): loss function for the value discrepancy. Can be one of "l1", "l2" or "smooth_l1".
-        normalize_advantage (bool): if True, the advantage will be normalized before being used.
-            Defaults to True.
+            Defaults to ``1``.
+        entropy_coef (scalar, optional): entropy multiplier when computing the total loss.
+            Defaults to ``0.01``.
+        critic_coef (scalar, optional): critic loss multiplier when computing the total
+            loss. Defaults to ``1.0``.
+        loss_critic_type (str, optional): loss function for the value discrepancy.
+            Can be one of "l1", "l2" or "smooth_l1". Defaults to ``"smooth_l1"``.
+        normalize_advantage (bool, optional): if ``True``, the advantage will be normalized
+            before being used. Defaults to ``False``.
+        separate_losses (bool, optional): if ``True``, shared parameters between
+            policy and critic will only be trained on the policy loss.
+            Defaults to ``False``, ie. gradients are propagated to shared
+            parameters for both policy and critic losses.
+
+    .. note:
+      The advantage (typically GAE) can be computed by the loss function or
+      in the training loop. The latter option is usually preferred, but this is
+      up to the user to choose which option is to be preferred.
+      If the advantage key (``"advantage`` by default) is not present in the
+      input tensordict, the advantage will be computed by the :meth:`~.forward`
+      method.
+
+        >>> ppo_loss = ClipPPOLoss(actor, critic)
+        >>> advantage = GAE(critic)
+        >>> data = next(datacollector)
+        >>> losses = ppo_loss(data)
+        >>> # equivalent
+        >>> advantage(data)
+        >>> losses = ppo_loss(data)
+
+      A custom advantage module can be built using :meth:`~.make_value_estimator`.
+      The default is :class:`~torchrl.objectives.value.GAE` with hyperparameters
+      dictated by :func:`~torchrl.objectives.utils.default_value_kwargs`.
+
+        >>> ppo_loss = ClipPPOLoss(actor, critic)
+        >>> ppo_loss.make_value_estimator(ValueEstimators.TDLambda)
+        >>> data = next(datacollector)
+        >>> losses = ppo_loss(data)
+
+    .. note::
+      If the actor and the value function share parameters, one can avoid
+      calling the common module multiple times by passing only the head of the
+      value network to the PPO loss module:
+
+        >>> common = SomeModule(in_keys=["observation"], out_keys=["hidden"])
+        >>> actor_head = SomeActor(in_keys=["hidden"])
+        >>> value_head = SomeValue(in_keys=["hidden"])
+        >>> # first option, with 2 calls on the common module
+        >>> model = ActorCriticOperator(common, actor_head, value_head)
+        >>> loss_module = PPOLoss(model.get_policy_operator(), model.get_value_operator())
+        >>> # second option, with a single call to the common module
+        >>> loss_module = PPOLoss(ProbabilisticTensorDictSequential(model, actor_head), value_head)
+
+      This will work regardless of whether separate_losses is activated or not.
 
     """
 
     def __init__(
         self,
-        actor: SafeProbabilisticSequential,
-        critic: SafeModule,
+        actor: ProbabilisticTensorDictSequential,
+        critic: TensorDictModule,
+        *,
         advantage_key: str = "advantage",
+        value_key: str = "state_value",
         clip_epsilon: float = 0.2,
         entropy_bonus: bool = True,
         samples_mc_entropy: int = 1,
         entropy_coef: float = 0.01,
         critic_coef: float = 1.0,
-        gamma: float = 0.99,
         loss_critic_type: str = "smooth_l1",
         normalize_advantage: bool = True,
+        gamma: float = None,
+        separate_losses: bool = False,
         **kwargs,
     ):
         super(ClipPPOLoss, self).__init__(
             actor,
             critic,
-            advantage_key,
+            advantage_key=advantage_key,
             entropy_bonus=entropy_bonus,
+            value_key=value_key,
             samples_mc_entropy=samples_mc_entropy,
             entropy_coef=entropy_coef,
             critic_coef=critic_coef,
-            gamma=gamma,
             loss_critic_type=loss_critic_type,
             normalize_advantage=normalize_advantage,
+            gamma=gamma,
+            separate_losses=separate_losses,
             **kwargs,
         )
         self.register_buffer("clip_epsilon", torch.tensor(clip_epsilon))
 
     @property
     def _clip_bounds(self):
         return (
             math.log1p(-self.clip_epsilon),
             math.log1p(self.clip_epsilon),
         )
 
     def forward(self, tensordict: TensorDictBase) -> TensorDictBase:
         tensordict = tensordict.clone(False)
-        advantage = tensordict.get(self.advantage_key)
+        advantage = tensordict.get(self.advantage_key, None)
+        if advantage is None:
+            self.value_estimator(
+                tensordict,
+                params=self.critic_params.detach(),
+                target_params=self.target_critic_params,
+            )
+            advantage = tensordict.get(self.advantage_key)
+        if self.normalize_advantage and advantage.numel() > 1:
+            loc = advantage.mean().item()
+            scale = advantage.std().clamp_min(1e-6).item()
+            advantage = (advantage - loc) / scale
+
         log_weight, dist = self._log_weight(tensordict)
         # ESS for logging
         with torch.no_grad():
             # In theory, ESS should be computed on particles sampled from the same source. Here we sample according
             # to different, unrelated trajectories, which is not standard. Still it can give a idea of the dispersion
             # of the weights.
             lw = log_weight.squeeze()
@@ -244,18 +438,14 @@
             raise RuntimeError(
                 f"advantage.shape and log_weight.shape do not match (got {advantage.shape} "
                 f"and {log_weight.shape})"
             )
         gain1 = log_weight.exp() * advantage
 
         log_weight_clip = log_weight.clamp(*self._clip_bounds)
-        if self.normalize_advantage and advantage.numel() > 1:
-            loc = advantage.mean().item()
-            scale = advantage.std().clamp_min(1e-6).item()
-            advantage = (advantage - loc) / scale
         gain2 = log_weight_clip.exp() * advantage
 
         gain = torch.stack([gain1, gain2], -1).min(dim=-1)[0]
         td_out = TensorDict({"loss_objective": -gain.mean()}, [])
 
         if self.entropy_bonus:
             entropy = self.get_entropy_bonus(dist)
@@ -273,71 +463,133 @@
 
     The KL penalty loss has the following formula:
         loss = loss - beta * KL(old_policy, new_policy)
     The "beta" parameter is adapted on-the-fly to match a target KL divergence between the new and old policy, thus
     favouring a certain level of distancing between the two while still preventing them to be too much apart.
 
     Args:
-        actor (SafeProbabilisticSequential): policy operator.
+        actor (ProbabilisticTensorDictSequential): policy operator.
         critic (ValueOperator): value operator.
-        advantage_key (str): the input tensordict key where the advantage is expected to be written.
-            default: "advantage"
-        dtarg (scalar): target KL divergence.
-        beta (scalar): initial KL divergence multiplier.
-            default: 1.0
-        increment (scalar): how much beta should be incremented if KL > dtarg. Valid range: increment >= 1.0
-            default: 2.0
-        decrement (scalar): how much beta should be decremented if KL < dtarg. Valid range: decrement <= 1.0
-            default: 0.5
-        entropy_bonus (bool): if True, an entropy bonus will be added to the loss to favour exploratory policies.
-        samples_mc_entropy (int): if the distribution retrieved from the policy operator does not have a closed form
-            formula for the entropy, a Monte-Carlo estimate will be used. samples_mc_entropy will control how many
+
+    Keyword Args:
+        advantage_key (str, optional): the input tensordict key where the advantage is expected to be written.
+            Defaults to ``"advantage"``.
+        value_target_key (str, optional): the input tensordict key where the target state
+            value is expected to be written. Defaults to ``"value_target"``.
+        value_key (str, optional): the input tensordict key where the state
+            value is expected to be written. Defaults to ``"state_value"``.
+        dtarg (scalar, optional): target KL divergence. Defaults to ``0.01``.
+        samples_mc_kl (int, optional): number of samples used to compute the KL divergence
+            if no analytical formula can be found. Defaults to ``1``.
+        beta (scalar, optional): initial KL divergence multiplier.
+            Defaults to ``1.0``.
+        decrement (scalar, optional): how much beta should be decremented if KL < dtarg. Valid range: decrement <= 1.0
+            default: ``0.5``.
+        increment (scalar, optional): how much beta should be incremented if KL > dtarg. Valid range: increment >= 1.0
+            default: ``2.0``.
+        entropy_bonus (bool, optional): if ``True``, an entropy bonus will be added to the
+            loss to favour exploratory policies. Defaults to ``True``.
+        samples_mc_entropy (int, optional): if the distribution retrieved from the policy
+            operator does not have a closed form
+            formula for the entropy, a Monte-Carlo estimate will be used.
+            ``samples_mc_entropy`` will control how many
             samples will be used to compute this estimate.
-            default: 1
-        entropy_coef (scalar): entropy multiplier when computing the total loss.
-            default: 0.01
-        critic_coef (scalar): critic loss multiplier when computing the total loss.
-            default: 1.0
-        gamma (scalar): a discount factor for return computation.
-        loss_critic_type (str): loss function for the value discrepancy. Can be one of "l1", "l2" or "smooth_l1".
-        normalize_advantage (bool): if True, the advantage will be normalized before being used.
-            Defaults to True.
+            Defaults to ``1``.
+        entropy_coef (scalar, optional): entropy multiplier when computing the total loss.
+            Defaults to ``0.01``.
+        critic_coef (scalar, optional): critic loss multiplier when computing the total
+            loss. Defaults to ``1.0``.
+        loss_critic_type (str, optional): loss function for the value discrepancy.
+            Can be one of "l1", "l2" or "smooth_l1". Defaults to ``"smooth_l1"``.
+        normalize_advantage (bool, optional): if ``True``, the advantage will be normalized
+            before being used. Defaults to ``False``.
+        separate_losses (bool, optional): if ``True``, shared parameters between
+            policy and critic will only be trained on the policy loss.
+            Defaults to ``False``, ie. gradients are propagated to shared
+            parameters for both policy and critic losses.
+
+
+    .. note:
+      The advantage (typically GAE) can be computed by the loss function or
+      in the training loop. The latter option is usually preferred, but this is
+      up to the user to choose which option is to be preferred.
+      If the advantage key (``"advantage`` by default) is not present in the
+      input tensordict, the advantage will be computed by the :meth:`~.forward`
+      method.
+
+        >>> ppo_loss = KLPENPPOLoss(actor, critic)
+        >>> advantage = GAE(critic)
+        >>> data = next(datacollector)
+        >>> losses = ppo_loss(data)
+        >>> # equivalent
+        >>> advantage(data)
+        >>> losses = ppo_loss(data)
+
+      A custom advantage module can be built using :meth:`~.make_value_estimator`.
+      The default is :class:`~torchrl.objectives.value.GAE` with hyperparameters
+      dictated by :func:`~torchrl.objectives.utils.default_value_kwargs`.
+
+        >>> ppo_loss = KLPENPPOLoss(actor, critic)
+        >>> ppo_loss.make_value_estimator(ValueEstimators.TDLambda)
+        >>> data = next(datacollector)
+        >>> losses = ppo_loss(data)
+
+    .. note::
+      If the actor and the value function share parameters, one can avoid
+      calling the common module multiple times by passing only the head of the
+      value network to the PPO loss module:
+
+        >>> common = SomeModule(in_keys=["observation"], out_keys=["hidden"])
+        >>> actor_head = SomeActor(in_keys=["hidden"])
+        >>> value_head = SomeValue(in_keys=["hidden"])
+        >>> # first option, with 2 calls on the common module
+        >>> model = ActorCriticOperator(common, actor_head, value_head)
+        >>> loss_module = PPOLoss(model.get_policy_operator(), model.get_value_operator())
+        >>> # second option, with a single call to the common module
+        >>> loss_module = PPOLoss(ProbabilisticTensorDictSequential(model, actor_head), value_head)
+
+      This will work regardless of whether separate_losses is activated or not.
 
     """
 
     def __init__(
         self,
-        actor: SafeProbabilisticSequential,
-        critic: SafeModule,
+        actor: ProbabilisticTensorDictSequential,
+        critic: TensorDictModule,
+        *,
         advantage_key="advantage",
         dtarg: float = 0.01,
+        value_key: str = "state_value",
         beta: float = 1.0,
         increment: float = 2,
         decrement: float = 0.5,
         samples_mc_kl: int = 1,
         entropy_bonus: bool = True,
         samples_mc_entropy: int = 1,
         entropy_coef: float = 0.01,
         critic_coef: float = 1.0,
-        gamma: float = 0.99,
         loss_critic_type: str = "smooth_l1",
         normalize_advantage: bool = True,
+        gamma: float = None,
+        separate_losses: bool = False,
         **kwargs,
     ):
         super(KLPENPPOLoss, self).__init__(
             actor,
             critic,
-            advantage_key,
+            advantage_key=advantage_key,
             entropy_bonus=entropy_bonus,
             samples_mc_entropy=samples_mc_entropy,
             entropy_coef=entropy_coef,
             critic_coef=critic_coef,
-            gamma=gamma,
             loss_critic_type=loss_critic_type,
             normalize_advantage=normalize_advantage,
+            gamma=gamma,
+            separate_losses=separate_losses,
+            value_key=value_key,
             **kwargs,
         )
 
         self.dtarg = dtarg
         self._beta_init = beta
         self.register_buffer("beta", torch.tensor(beta))
 
@@ -351,28 +603,31 @@
                 f"decrement should be <= 1.0 in KLPENPPOLoss, got {decrement:4.4f}"
             )
         self.decrement = decrement
         self.samples_mc_kl = samples_mc_kl
 
     def forward(self, tensordict: TensorDictBase) -> TensorDict:
         tensordict = tensordict.clone(False)
-        advantage = tensordict.get(self.advantage_key)
+        advantage = tensordict.get(self.advantage_key, None)
+        if advantage is None:
+            self.value_estimator(
+                tensordict,
+                params=self.critic_params.detach(),
+                target_params=self.target_critic_params,
+            )
+            advantage = tensordict.get(self.advantage_key)
         if self.normalize_advantage and advantage.numel() > 1:
             loc = advantage.mean().item()
             scale = advantage.std().clamp_min(1e-6).item()
             advantage = (advantage - loc) / scale
         log_weight, dist = self._log_weight(tensordict)
         neg_loss = log_weight.exp() * advantage
 
-        tensordict_clone = tensordict.select(
-            *self.actor.in_keys, *self.actor.out_keys
-        ).clone()
-
-        previous_dist = self.actor.build_dist_from_params(tensordict_clone)
-        current_dist = self.actor.get_dist(tensordict_clone, params=self.actor_params)
+        previous_dist = self.actor.build_dist_from_params(tensordict)
+        current_dist = self.actor.get_dist(tensordict, params=self.actor_params)
         try:
             kl = torch.distributions.kl.kl_divergence(previous_dist, current_dist)
         except NotImplementedError:
             x = previous_dist.sample((self.samples_mc_kl,))
             kl = (previous_dist.log_prob(x) - current_dist.log_prob(x)).mean(0)
         kl = kl.unsqueeze(-1)
         neg_loss = neg_loss - self.beta * kl
```

## torchrl/objectives/redq.py

```diff
@@ -1,33 +1,38 @@
 # Copyright (c) Meta Platforms, Inc. and affiliates.
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
-
 import math
+import warnings
 from numbers import Number
 from typing import Union
 
 import numpy as np
 import torch
 
-from tensordict.nn import TensorDictSequential
+from tensordict.nn import TensorDictModule, TensorDictSequential
 from tensordict.tensordict import TensorDict, TensorDictBase
 from torch import Tensor
 
-from torchrl.envs.utils import set_exploration_mode, step_mdp
-from torchrl.modules import SafeModule
+from torchrl.envs.utils import ExplorationType, set_exploration_type, step_mdp
 from torchrl.objectives.common import LossModule
 from torchrl.objectives.utils import (
+    _GAMMA_LMBDA_DEPREC_WARNING,
+    default_value_kwargs,
     distance_loss,
-    next_state_value as get_next_state_value,
+    ValueEstimators,
 )
+from torchrl.objectives.value import TD0Estimator, TD1Estimator, TDLambdaEstimator
 
 try:
-    from functorch import vmap
+    try:
+        from torch import vmap
+    except ImportError:
+        from functorch import vmap
 
     FUNCTORCH_ERR = ""
     _has_functorch = True
 except ImportError as err:
     FUNCTORCH_ERR = str(err)
     _has_functorch = False
 
@@ -36,57 +41,67 @@
     """REDQ Loss module.
 
     REDQ (RANDOMIZED ENSEMBLED DOUBLE Q-LEARNING: LEARNING FAST WITHOUT A MODEL
     https://openreview.net/pdf?id=AY8zfZm0tDd) generalizes the idea of using an ensemble of Q-value functions to
     train a SAC-like algorithm.
 
     Args:
-        actor_network (SafeModule): the actor to be trained
-        qvalue_network (SafeModule): a single Q-value network that will be multiplicated as many times as needed.
-        num_qvalue_nets (int, optional): Number of Q-value networks to be trained. Default is 10.
-        sub_sample_len (int, optional): number of Q-value networks to be subsampled to evaluate the next state value
-            Default is 2.
-        gamma (Number, optional): gamma decay factor. Default is 0.99.
-        priotity_key (str, optional): Key where to write the priority value for prioritized replay buffers. Default is
-            `"td_error"`.
-        loss_function (str, optional): loss function to be used for the Q-value. Can be one of  `"smooth_l1"`, "l2",
-            "l1", Default is "smooth_l1".
+        actor_network (TensorDictModule): the actor to be trained
+        qvalue_network (TensorDictModule): a single Q-value network that will
+            be multiplicated as many times as needed.
+        num_qvalue_nets (int, optional): Number of Q-value networks to be trained.
+            Default is ``10``.
+        sub_sample_len (int, optional): number of Q-value networks to be
+            subsampled to evaluate the next state value
+            Default is ``2``.
+        priority_key (str, optional): Key where to write the priority value
+            for prioritized replay buffers. Default is
+            ``"td_error"``.
+        loss_function (str, optional): loss function to be used for the Q-value.
+            Can be one of  ``"smooth_l1"``, ``"l2"``,
+            ``"l1"``, Default is ``"smooth_l1"``.
         alpha_init (float, optional): initial entropy multiplier.
-            Default is 1.0.
+            Default is ``1.0``.
         min_alpha (float, optional): min value of alpha.
-            Default is 0.1.
+            Default is ``0.1``.
         max_alpha (float, optional): max value of alpha.
-            Default is 10.0.
-        fixed_alpha (bool, optional): whether alpha should be trained to match a target entropy. Default is :obj:`False`.
-        target_entropy (Union[str, Number], optional): Target entropy for the stochastic policy. Default is "auto".
-        delay_qvalue (bool, optional): Whether to separate the target Q value networks from the Q value networks used
-            for data collection. Default is :obj:`False`.
-        gSDE (bool, optional): Knowing if gSDE is used is necessary to create random noise variables.
-            Default is False
+            Default is ``10.0``.
+        fixed_alpha (bool, optional): whether alpha should be trained to match
+            a target entropy. Default is ``False``.
+        target_entropy (Union[str, Number], optional): Target entropy for the
+            stochastic policy. Default is "auto".
+        delay_qvalue (bool, optional): Whether to separate the target Q value
+            networks from the Q value networks used
+            for data collection. Default is ``False``.
+        gSDE (bool, optional): Knowing if gSDE is used is necessary to create
+            random noise variables.
+            Default is ``False``.
 
     """
 
     delay_actor: bool = False
+    default_value_estimator = ValueEstimators.TD0
 
     def __init__(
         self,
-        actor_network: SafeModule,
-        qvalue_network: SafeModule,
+        actor_network: TensorDictModule,
+        qvalue_network: TensorDictModule,
+        *,
         num_qvalue_nets: int = 10,
         sub_sample_len: int = 2,
-        gamma: Number = 0.99,
-        priotity_key: str = "td_error",
+        priority_key: str = "td_error",
         loss_function: str = "smooth_l1",
         alpha_init: float = 1.0,
         min_alpha: float = 0.1,
         max_alpha: float = 10.0,
         fixed_alpha: bool = False,
         target_entropy: Union[str, Number] = "auto",
         delay_qvalue: bool = True,
         gSDE: bool = False,
+        gamma: float = None,
     ):
         if not _has_functorch:
             raise ImportError("Failed to import functorch.") from FUNCTORCH_ERR
 
         super().__init__()
         self.convert_to_functional(
             actor_network,
@@ -104,16 +119,15 @@
             "qvalue_network",
             num_qvalue_nets,
             create_target_params=self.delay_qvalue,
             compare_against=list(actor_network.parameters()),
         )
         self.num_qvalue_nets = num_qvalue_nets
         self.sub_sample_len = max(1, min(sub_sample_len, num_qvalue_nets - 1))
-        self.register_buffer("gamma", torch.tensor(gamma))
-        self.priority_key = priotity_key
+        self.priority_key = priority_key
         self.loss_function = loss_function
 
         try:
             device = next(self.parameters()).device
         except AttributeError:
             device = torch.device("cpu")
 
@@ -143,25 +157,28 @@
                     "action tensor in the actor network."
                 )
             target_entropy = -float(np.prod(actor_network.spec["action"].shape))
         self.register_buffer(
             "target_entropy", torch.tensor(target_entropy, device=device)
         )
         self.gSDE = gSDE
+        if gamma is not None:
+            warnings.warn(_GAMMA_LMBDA_DEPREC_WARNING, category=DeprecationWarning)
+            self.gamma = gamma
 
     @property
     def alpha(self):
         self.log_alpha.data.clamp_(self.min_log_alpha, self.max_log_alpha)
         with torch.no_grad():
             alpha = self.log_alpha.exp()
         return alpha
 
     def forward(self, tensordict: TensorDictBase) -> TensorDictBase:
         obs_keys = self.actor_network.in_keys
-        tensordict_select = tensordict.select("next", *obs_keys, "action")
+        tensordict_select = tensordict.clone(False).select("next", *obs_keys, "action")
         selected_models_idx = torch.randperm(self.num_qvalue_nets)[
             : self.sub_sample_len
         ].sort()[0]
         selected_q_params = self.target_qvalue_network_params[selected_models_idx]
 
         actor_params = torch.stack(
             [self.actor_network_params, self.target_actor_network_params], 0
@@ -172,32 +189,32 @@
         )  # to avoid overwriting keys
         next_td_actor = step_mdp(tensordict_select).select(
             *self.actor_network.in_keys
         )  # next_observation ->
         tensordict_actor = torch.stack([tensordict_actor_grad, next_td_actor], 0)
         tensordict_actor = tensordict_actor.contiguous()
 
-        with set_exploration_mode("random"):
+        with set_exploration_type(ExplorationType.RANDOM):
             if self.gSDE:
                 tensordict_actor.set(
                     "_eps_gSDE",
                     torch.zeros(tensordict_actor.shape, device=tensordict_actor.device),
                 )
             # vmap doesn't support sampling, so we take it out from the vmap
             td_params = vmap(self.actor_network.get_dist_params)(
                 tensordict_actor,
                 actor_params,
             )
             if isinstance(self.actor_network, TensorDictSequential):
-                sample_key = self.actor_network[-1].out_keys[0]
+                sample_key = "action"
                 tensordict_actor_dist = self.actor_network.build_dist_from_params(
                     td_params
                 )
             else:
-                sample_key = self.actor_network.out_keys[0]
+                sample_key = "action"
                 tensordict_actor_dist = self.actor_network.build_dist_from_params(
                     td_params
                 )
             tensordict_actor[sample_key] = tensordict_actor_dist.rsample()
             tensordict_actor["sample_log_prob"] = tensordict_actor_dist.log_prob(
                 tensordict_actor[sample_key]
             )
@@ -256,19 +273,19 @@
         ).mean(0)
 
         next_state_value = (
             next_state_action_value_qvalue - self.alpha * next_action_log_prob_qvalue
         )
         next_state_value = next_state_value.min(0)[0]
 
-        target_value = get_next_state_value(
-            tensordict,
-            gamma=self.gamma,
-            pred_next_val=next_state_value,
+        tensordict_select.set(("next", "state_value"), next_state_value.unsqueeze(-1))
+        target_value = self.value_estimator.value_estimate(tensordict_select).squeeze(
+            -1
         )
+
         pred_val = state_action_value_qvalue
         td_error = (pred_val - target_value).pow(2)
         loss_qval = distance_loss(
             pred_val,
             target_value.expand_as(pred_val),
             loss_function=self.loss_function,
         ).mean(0)
@@ -305,7 +322,36 @@
         if self.target_entropy is not None:
             # we can compute this loss even if log_alpha is not a parameter
             alpha_loss = -self.log_alpha.exp() * (log_pi.detach() + self.target_entropy)
         else:
             # placeholder
             alpha_loss = torch.zeros_like(log_pi)
         return alpha_loss
+
+    def make_value_estimator(self, value_type: ValueEstimators = None, **hyperparams):
+        if value_type is None:
+            value_type = self.default_value_estimator
+        self.value_type = value_type
+        hp = dict(default_value_kwargs(value_type))
+        if hasattr(self, "gamma"):
+            hp["gamma"] = self.gamma
+        hp.update(hyperparams)
+        value_key = "state_value"
+        # we do not need a value network bc the next state value is already passed
+        if value_type == ValueEstimators.TD1:
+            self._value_estimator = TD1Estimator(
+                value_network=None, value_key=value_key, **hp
+            )
+        elif value_type == ValueEstimators.TD0:
+            self._value_estimator = TD0Estimator(
+                value_network=None, value_key=value_key, **hp
+            )
+        elif value_type == ValueEstimators.GAE:
+            raise NotImplementedError(
+                f"Value type {value_type} it not implemented for loss {type(self)}."
+            )
+        elif value_type == ValueEstimators.TDLambda:
+            self._value_estimator = TDLambdaEstimator(
+                value_network=None, value_key=value_key, **hp
+            )
+        else:
+            raise NotImplementedError(f"Unknown value type {value_type}")
```

## torchrl/objectives/reinforce.py

```diff
@@ -1,66 +1,123 @@
 # Copyright (c) Meta Platforms, Inc. and affiliates.
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
-
+import warnings
 from typing import Optional
 
 import torch
-from tensordict.tensordict import TensorDict, TensorDictBase
 
-from torchrl.modules.tensordict_module import SafeModule, SafeProbabilisticSequential
+from tensordict.nn import ProbabilisticTensorDictSequential, TensorDictModule
+from tensordict.tensordict import TensorDict, TensorDictBase
 from torchrl.objectives.common import LossModule
-from torchrl.objectives.utils import distance_loss
+from torchrl.objectives.utils import (
+    _GAMMA_LMBDA_DEPREC_WARNING,
+    default_value_kwargs,
+    distance_loss,
+    ValueEstimators,
+)
+from torchrl.objectives.value import GAE, TD0Estimator, TD1Estimator, TDLambdaEstimator
 
 
 class ReinforceLoss(LossModule):
     """Reinforce loss module.
 
     Presented in "Simple statistical gradient-following algorithms for connectionist reinforcement learning", Williams, 1992
     https://doi.org/10.1007/BF00992696
 
+
+    Args:
+        actor (ProbabilisticTensorDictSequential): policy operator.
+        critic (ValueOperator): value operator.
+        delay_value (bool, optional): if ``True``, a target network is needed
+            for the critic. Defaults to ``False``.
+        advantage_key (str): the input tensordict key where the advantage is
+            expected to be written.
+            Defaults to ``"advantage"``.
+        value_target_key (str): the input tensordict key where the target state
+            value is expected to be written. Defaults to ``"value_target"``.
+        loss_critic_type (str): loss function for the value discrepancy.
+            Can be one of "l1", "l2" or "smooth_l1". Defaults to ``"smooth_l1"``.
+
+    .. note:
+      The advantage (typically GAE) can be computed by the loss function or
+      in the training loop. The latter option is usually preferred, but this is
+      up to the user to choose which option is to be preferred.
+      If the advantage key (``"advantage`` by default) is not present in the
+      input tensordict, the advantage will be computed by the :meth:`~.forward`
+      method.
+
+        >>> reinforce_loss = ReinforceLoss(actor, critic)
+        >>> advantage = GAE(critic)
+        >>> data = next(datacollector)
+        >>> losses = reinforce_loss(data)
+        >>> # equivalent
+        >>> advantage(data)
+        >>> losses = reinforce_loss(data)
+
+      A custom advantage module can be built using :meth:`~.make_value_estimator`.
+      The default is :class:`~torchrl.objectives.value.GAE` with hyperparameters
+      dictated by :func:`~torchrl.objectives.utils.default_value_kwargs`.
+
+        >>> reinforce_loss = ReinforceLoss(actor, critic)
+        >>> reinforce_loss.make_value_estimator(ValueEstimators.TDLambda)
+        >>> data = next(datacollector)
+        >>> losses = reinforce_loss(data)
+
     """
 
+    default_value_estimator = ValueEstimators.GAE
+
     def __init__(
         self,
-        actor_network: SafeProbabilisticSequential,
-        critic: Optional[SafeModule] = None,
+        actor: ProbabilisticTensorDictSequential,
+        critic: Optional[TensorDictModule] = None,
+        *,
         delay_value: bool = False,
-        gamma: float = 0.99,
         advantage_key: str = "advantage",
         value_target_key: str = "value_target",
         loss_critic_type: str = "smooth_l1",
+        gamma: float = None,
     ) -> None:
         super().__init__()
 
         self.delay_value = delay_value
         self.advantage_key = advantage_key
         self.value_target_key = value_target_key
         self.loss_critic_type = loss_critic_type
-        self.register_buffer("gamma", torch.tensor(gamma))
 
         # Actor
         self.convert_to_functional(
-            actor_network,
+            actor,
             "actor_network",
             create_target_params=False,
         )
 
         # Value
         if critic is not None:
             self.convert_to_functional(
                 critic,
                 "critic",
                 create_target_params=self.delay_value,
-                compare_against=list(actor_network.parameters()),
+                compare_against=list(actor.parameters()),
             )
+        if gamma is not None:
+            warnings.warn(_GAMMA_LMBDA_DEPREC_WARNING, category=DeprecationWarning)
+            self.gamma = gamma
 
     def forward(self, tensordict: TensorDictBase) -> TensorDictBase:
-        advantage = tensordict.get(self.advantage_key)
+        advantage = tensordict.get(self.advantage_key, None)
+        if advantage is None:
+            self.value_estimator(
+                tensordict,
+                params=self.critic_params.detach(),
+                target_params=self.target_critic_params,
+            )
+            advantage = tensordict.get(self.advantage_key)
 
         # compute log-prob
         tensordict = self.actor_network(
             tensordict,
             params=self.actor_network_params,
         )
 
@@ -91,7 +148,35 @@
                 f"the key {self.value_target_key} was not found in the input tensordict. "
                 f"Make sure you provided the right key and the value_target (i.e. the target "
                 f"return) has been retrieved accordingly. Advantage classes such as GAE, "
                 f"TDLambdaEstimate and TDEstimate all return a 'value_target' entry that "
                 f"can be used for the value loss."
             )
         return loss_value
+
+    def make_value_estimator(self, value_type: ValueEstimators = None, **hyperparams):
+        if value_type is None:
+            value_type = self.default_value_estimator
+        self.value_type = value_type
+        hp = dict(default_value_kwargs(value_type))
+        if hasattr(self, "gamma"):
+            hp["gamma"] = self.gamma
+        hp.update(hyperparams)
+        value_key = "state_value"
+        if value_type == ValueEstimators.TD1:
+            self._value_estimator = TD1Estimator(
+                value_network=self.critic, value_key=value_key, **hp
+            )
+        elif value_type == ValueEstimators.TD0:
+            self._value_estimator = TD0Estimator(
+                value_network=self.critic, value_key=value_key, **hp
+            )
+        elif value_type == ValueEstimators.GAE:
+            self._value_estimator = GAE(
+                value_network=self.critic, value_key=value_key, **hp
+            )
+        elif value_type == ValueEstimators.TDLambda:
+            self._value_estimator = TDLambdaEstimator(
+                value_network=self.critic, value_key=value_key, **hp
+            )
+        else:
+            raise NotImplementedError(f"Unknown value type {value_type}")
```

## torchrl/objectives/sac.py

```diff
@@ -1,31 +1,40 @@
 # Copyright (c) Meta Platforms, Inc. and affiliates.
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
-
 import math
+import warnings
 from numbers import Number
 from typing import Optional, Tuple, Union
 
 import numpy as np
 import torch
-from tensordict.nn import make_functional
+from tensordict.nn import make_functional, TensorDictModule
 from tensordict.tensordict import TensorDict, TensorDictBase
 from torch import Tensor
 
-from torchrl.modules import ProbabilisticActor, SafeModule
-from torchrl.modules.tensordict_module.actors import ActorCriticWrapper
-from torchrl.objectives.utils import distance_loss, next_state_value
+from torchrl.envs.utils import ExplorationType, set_exploration_type, step_mdp
 
-from ..envs.utils import set_exploration_mode, step_mdp
-from .common import LossModule
+from torchrl.modules import ProbabilisticActor
+from torchrl.modules.tensordict_module.actors import ActorCriticWrapper
+from torchrl.objectives.common import LossModule
+from torchrl.objectives.utils import (
+    _GAMMA_LMBDA_DEPREC_WARNING,
+    default_value_kwargs,
+    distance_loss,
+    ValueEstimators,
+)
+from torchrl.objectives.value import TD0Estimator, TD1Estimator, TDLambdaEstimator
 
 try:
-    from functorch import vmap
+    try:
+        from torch import vmap
+    except ImportError:
+        from functorch import vmap
 
     _has_functorch = True
     err = ""
 except ImportError as err:
     _has_functorch = False
     FUNCTORCH_ERROR = err
 
@@ -35,69 +44,74 @@
 
     Presented in "Soft Actor-Critic: Off-Policy Maximum Entropy Deep
     Reinforcement Learning with a Stochastic Actor" https://arxiv.org/abs/1801.01290
     and "Soft Actor-Critic Algorithms and Applications" https://arxiv.org/abs/1812.05905
 
     Args:
         actor_network (ProbabilisticActor): stochastic actor
-        qvalue_network (SafeModule): Q(s, a) parametric model
-        value_network (SafeModule, optional): V(s) parametric model. If not
-            provided, the second version of SAC is assumed.
-        qvalue_network_bis (ProbabilisticTDModule, optional): if required, the
-            Q-value can be computed twice independently using two separate
-            networks. The minimum predicted value will then be used for
-            inference.
-        gamma (number, optional): discount for return computation
-            Default is 0.99
+        qvalue_network (TensorDictModule): Q(s, a) parametric model.
+            This module typically outputs a ``"state_action_value"`` entry.
+        value_network (TensorDictModule, optional): V(s) parametric model.
+            This module typically outputs a ``"state_value"`` entry.
+
+            .. note::
+              If not provided, the second version of SAC is assumed, where
+              only the Q-Value network is needed.
+
+        num_qvalue_nets (integer, optional): number of Q-Value networks used.
+            Defaults to ``2``.
         priority_key (str, optional): tensordict key where to write the
-            priority (for prioritized replay buffer usage). Default is
-            `"td_error"`.
+            priority (for prioritized replay buffer usage). Defaults to
+            ``"td_error"``.
         loss_function (str, optional): loss function to be used with
             the value function loss. Default is `"smooth_l1"`.
         alpha_init (float, optional): initial entropy multiplier.
             Default is 1.0.
         min_alpha (float, optional): min value of alpha.
             Default is 0.1.
         max_alpha (float, optional): max value of alpha.
             Default is 10.0.
-        fixed_alpha (bool, optional): if True, alpha will be fixed to its
+        fixed_alpha (bool, optional): if ``True``, alpha will be fixed to its
             initial value. Otherwise, alpha will be optimized to
             match the 'target_entropy' value.
-            Default is :obj:`False`.
+            Default is ``False``.
         target_entropy (float or str, optional): Target entropy for the
             stochastic policy. Default is "auto", where target entropy is
             computed as :obj:`-prod(n_actions)`.
         delay_actor (bool, optional): Whether to separate the target actor
             networks from the actor networks used for data collection.
-            Default is :obj:`False`.
+            Default is ``False``.
         delay_qvalue (bool, optional): Whether to separate the target Q value
             networks from the Q value networks used for data collection.
-            Default is :obj:`False`.
+            Default is ``False``.
         delay_value (bool, optional): Whether to separate the target value
             networks from the value networks used for data collection.
-            Default is :obj:`False`.
+            Default is ``False``.
     """
 
+    default_value_estimator = ValueEstimators.TD0
+
     def __init__(
         self,
         actor_network: ProbabilisticActor,
-        qvalue_network: SafeModule,
-        value_network: Optional[SafeModule] = None,
+        qvalue_network: TensorDictModule,
+        value_network: Optional[TensorDictModule] = None,
+        *,
         num_qvalue_nets: int = 2,
-        gamma: Number = 0.99,
-        priotity_key: str = "td_error",
+        priority_key: str = "td_error",
         loss_function: str = "smooth_l1",
         alpha_init: float = 1.0,
         min_alpha: float = 0.1,
         max_alpha: float = 10.0,
         fixed_alpha: bool = False,
         target_entropy: Union[str, float] = "auto",
         delay_actor: bool = False,
         delay_qvalue: bool = False,
         delay_value: bool = False,
+        gamma: float = None,
     ) -> None:
         if not _has_functorch:
             raise ImportError("Failed to import functorch.") from FUNCTORCH_ERROR
         super().__init__()
 
         # Actor
         self.delay_actor = delay_actor
@@ -132,16 +146,15 @@
             qvalue_network,
             "qvalue_network",
             num_qvalue_nets,
             create_target_params=self.delay_qvalue,
             compare_against=list(actor_network.parameters()) + value_params,
         )
 
-        self.register_buffer("gamma", torch.tensor(gamma))
-        self.priority_key = priotity_key
+        self.priority_key = priority_key
         self.loss_function = loss_function
         try:
             device = next(self.parameters()).device
         except AttributeError:
             device = torch.device("cpu")
         self.register_buffer("alpha_init", torch.tensor(alpha_init, device=device))
         self.register_buffer(
@@ -173,14 +186,61 @@
             "target_entropy", torch.tensor(target_entropy, device=device)
         )
         if self._version == 1:
             self.actor_critic = ActorCriticWrapper(
                 self.actor_network, self.value_network
             )
             make_functional(self.actor_critic)
+        if gamma is not None:
+            warnings.warn(_GAMMA_LMBDA_DEPREC_WARNING, category=DeprecationWarning)
+            self.gamma = gamma
+
+    def make_value_estimator(self, value_type: ValueEstimators = None, **hyperparams):
+        if value_type is None:
+            value_type = self.default_value_estimator
+        self.value_type = value_type
+        if self._version == 1:
+            value_net = self.actor_critic
+        elif self._version == 2:
+            # we will take care of computing the next value inside this module
+            value_net = None
+        else:
+            # unreachable
+            raise NotImplementedError
+
+        value_key = "state_value"
+        hp = dict(default_value_kwargs(value_type))
+        hp.update(hyperparams)
+        if value_type is ValueEstimators.TD1:
+            self._value_estimator = TD1Estimator(
+                **hp,
+                value_network=value_net,
+                value_target_key="value_target",
+                value_key=value_key,
+            )
+        elif value_type is ValueEstimators.TD0:
+            self._value_estimator = TD0Estimator(
+                **hp,
+                value_network=value_net,
+                value_target_key="value_target",
+                value_key=value_key,
+            )
+        elif value_type is ValueEstimators.GAE:
+            raise NotImplementedError(
+                f"Value type {value_type} it not implemented for loss {type(self)}."
+            )
+        elif value_type is ValueEstimators.TDLambda:
+            self._value_estimator = TDLambdaEstimator(
+                **hp,
+                value_network=value_net,
+                value_target_key="value_target",
+                value_key=value_key,
+            )
+        else:
+            raise NotImplementedError(f"Unknown value type {value_type}")
 
     @property
     def device(self) -> torch.device:
         for p in self.parameters():
             return p.device
         raise RuntimeError(
             "At least one of the networks of SACLoss must have trainable " "parameters."
@@ -219,22 +279,19 @@
             "loss_qvalue": loss_qvalue.mean(),
             "loss_alpha": loss_alpha.mean(),
             "alpha": self._alpha,
             "entropy": -td_device.get("_log_prob").mean().detach(),
         }
         if self._version == 1:
             out["loss_value"] = loss_value.mean()
-        return TensorDict(
-            out,
-            [],
-        )
+        return TensorDict(out, [])
 
     def _loss_actor(self, tensordict: TensorDictBase) -> Tensor:
         # KL lossa
-        with set_exploration_mode("random"):
+        with set_exploration_type(ExplorationType.RANDOM):
             dist = self.actor_network.get_dist(
                 tensordict,
                 params=self.actor_network_params,
             )
             a_reparm = dist.rsample()
         # if not self.actor_network.spec.is_in(a_reparm):
         #     a_reparm.data.copy_(self.actor_network.spec.project(a_reparm.data))
@@ -253,39 +310,34 @@
             )
 
         # write log_prob in tensordict for alpha loss
         tensordict.set("_log_prob", log_prob.detach())
         return self._alpha * log_prob - min_q_logprob
 
     def _loss_qvalue_v1(self, tensordict: TensorDictBase) -> Tuple[Tensor, Tensor]:
-        actor_critic = self.actor_critic
-        params = TensorDict(
+        target_params = TensorDict(
             {
                 "module": {
                     "0": self.target_actor_network_params,
                     "1": self.target_value_network_params,
                 }
             },
-            [],
+            torch.Size([]),
             _run_checks=False,
         )
-        with set_exploration_mode("mode"):
-            target_value = next_state_value(
-                tensordict,
-                actor_critic,
-                gamma=self.gamma,
-                next_val_key="state_value",
-                params=params,
-            )
+        with set_exploration_type(ExplorationType.MODE):
+            target_value = self.value_estimator.value_estimate(
+                tensordict, target_params=target_params
+            ).squeeze(-1)
 
         # value loss
         qvalue_network = self.qvalue_network
 
-        # Q-nets must be trained independently: as such, we split the data in 2 if required and train each q-net on
-        # one half of the data.
+        # Q-nets must be trained independently: as such, we split the data in 2
+        # if required and train each q-net on one half of the data.
         shape = tensordict.shape
         if shape[0] % self.num_qvalue_nets != 0:
             raise RuntimeError(
                 f"Batch size={tensordict.shape} is incompatible "
                 f"with num_qvqlue_nets={self.num_qvalue_nets}."
             )
         tensordict_chunks = torch.stack(
@@ -301,54 +353,66 @@
         loss_value = distance_loss(
             pred_val, target_chunks, loss_function=self.loss_function
         ).view(*shape)
         priority_value = torch.cat((pred_val - target_chunks).pow(2).unbind(0), 0)
 
         return loss_value, priority_value
 
-    def _loss_qvalue_v2(self, tensordict: TensorDictBase) -> Tuple[Tensor, Tensor]:
-        obs_keys = self.actor_network.in_keys
-        tensordict = tensordict.select("next", *obs_keys, "action")
+    def _get_value_v2(self, tensordict, _alpha, actor_params, qval_params):
+        r"""Value network for SAC v2.
+
+        SAC v2 is based on a value estimate of the form:
 
+        .. math::
+
+          V = Q(s,a) - \alpha * \log p(a | s)
+
+        This class computes this value given the actor and qvalue network
+
+        """
+        tensordict = tensordict.clone(False)
+        # get actions and log-probs
         with torch.no_grad():
-            next_td = step_mdp(tensordict).select(
-                *self.actor_network.in_keys
-            )  # next_observation ->
-            # observation
-            # select pseudo-action
-            with set_exploration_mode("random"):
-                dist = self.actor_network.get_dist(
-                    next_td,
-                    params=self.target_actor_network_params,
-                )
-                next_td["action"] = dist.rsample()
-                next_td["sample_log_prob"] = dist.log_prob(next_td["action"])
-            sample_log_prob = next_td.get("sample_log_prob")
+            with set_exploration_type(ExplorationType.RANDOM):
+                dist = self.actor_network.get_dist(tensordict, params=actor_params)
+                tensordict.set("action", dist.rsample())
+                log_prob = dist.log_prob(tensordict.get("action"))
+                tensordict.set("sample_log_prob", log_prob)
+            sample_log_prob = tensordict.get("sample_log_prob")
+
             # get q-values
-            next_td = vmap(self.qvalue_network, (None, 0))(
-                next_td,
-                self.target_qvalue_network_params,
+            tensordict_expand = vmap(self.qvalue_network, (None, 0))(
+                tensordict, qval_params
             )
-            state_action_value = next_td.get("state_action_value")
+            state_action_value = tensordict_expand.get("state_action_value")
             if (
                 state_action_value.shape[-len(sample_log_prob.shape) :]
                 != sample_log_prob.shape
             ):
                 sample_log_prob = sample_log_prob.unsqueeze(-1)
-            state_value = (
-                next_td.get("state_action_value") - self._alpha * sample_log_prob
-            )
+            state_value = state_action_value - _alpha * sample_log_prob
             state_value = state_value.min(0)[0]
+            tensordict.set(("next", self.value_estimator.value_key), state_value)
+            target_value = self.value_estimator.value_estimate(
+                tensordict,
+                _alpha=self._alpha,
+                actor_params=self.target_actor_network_params,
+                qval_params=self.target_qvalue_network_params,
+            ).squeeze(-1)
+            return target_value
 
-        tensordict.set("next.state_value", state_value)
-        target_value = next_state_value(
+    def _loss_qvalue_v2(self, tensordict: TensorDictBase) -> Tuple[Tensor, Tensor]:
+        # we pass the alpha value to the tensordict. Since it's a scalar, we must erase the batch-size first.
+        target_value = self._get_value_v2(
             tensordict,
-            gamma=self.gamma,
-            pred_next_val=state_value,
+            self._alpha,
+            self.target_actor_network_params,
+            self.target_qvalue_network_params,
         )
+
         tensordict_expand = vmap(self.qvalue_network, (None, 0))(
             tensordict.select(*self.qvalue_network.in_keys),
             self.qvalue_network_params,
         )
         pred_val = tensordict_expand.get("state_action_value").squeeze(-1)
         td_error = abs(pred_val - target_value)
         loss_qval = distance_loss(
@@ -368,16 +432,14 @@
         pred_val = td_copy.get("state_value").squeeze(-1)
 
         action_dist = self.actor_network.get_dist(
             td_copy,
             params=self.target_actor_network_params,
         )  # resample an action
         action = action_dist.rsample()
-        # if not self.actor_network.spec.is_in(action):
-        #     action.data.copy_(self.actor_network.spec.project(action.data))
 
         td_copy.set("action", action, inplace=False)
 
         qval_net = self.qvalue_network
         td_copy = vmap(qval_net, (None, 0))(
             td_copy,
             self.target_qvalue_network_params,
@@ -409,7 +471,308 @@
 
     @property
     def _alpha(self):
         self.log_alpha.data.clamp_(self.min_log_alpha, self.max_log_alpha)
         with torch.no_grad():
             alpha = self.log_alpha.exp()
         return alpha
+
+
+class DiscreteSACLoss(LossModule):
+    """Discrete SAC Loss module.
+
+    Args:
+        actor_network (ProbabilisticActor): the actor to be trained
+        qvalue_network (TensorDictModule): a single Q-value network that will be multiplicated as many times as needed.
+        num_actions (int): number of actions in the action space.
+        num_qvalue_nets (int, optional): Number of Q-value networks to be trained. Default is 10.
+        priority_key (str, optional): Key where to write the priority value for prioritized replay buffers. Default is
+            `"td_error"`.
+        loss_function (str, optional): loss function to be used for the Q-value. Can be one of  `"smooth_l1"`, "l2",
+            "l1", Default is "smooth_l1".
+        alpha_init (float, optional): initial entropy multiplier.
+            Default is 1.0.
+        min_alpha (float, optional): min value of alpha.
+            Default is 0.1.
+        max_alpha (float, optional): max value of alpha.
+            Default is 10.0.
+        fixed_alpha (bool, optional): whether alpha should be trained to match a target entropy. Default is ``False``.
+        target_entropy_weight (float, optional): weight for the target entropy term.
+        target_entropy (Union[str, Number], optional): Target entropy for the stochastic policy. Default is "auto".
+        delay_qvalue (bool, optional): Whether to separate the target Q value networks from the Q value networks used
+            for data collection. Default is ``False``.
+
+    """
+
+    default_value_estimator = ValueEstimators.TD0
+    delay_actor: bool = False
+
+    def __init__(
+        self,
+        actor_network: ProbabilisticActor,
+        qvalue_network: TensorDictModule,
+        num_actions: int,
+        *,
+        num_qvalue_nets: int = 2,
+        priority_key: str = "td_error",
+        loss_function: str = "smooth_l1",
+        alpha_init: float = 1.0,
+        min_alpha: float = 0.1,
+        max_alpha: float = 10.0,
+        fixed_alpha: bool = False,
+        target_entropy_weight: float = 0.98,
+        target_entropy: Union[str, Number] = "auto",
+        delay_qvalue: bool = True,
+    ):
+        if not _has_functorch:
+            raise ImportError("Failed to import functorch.") from FUNCTORCH_ERROR
+        super().__init__()
+        self.convert_to_functional(
+            actor_network,
+            "actor_network",
+            create_target_params=self.delay_actor,
+            funs_to_decorate=["forward", "get_dist_params"],
+        )
+
+        self.delay_qvalue = delay_qvalue
+        self.convert_to_functional(
+            qvalue_network,
+            "qvalue_network",
+            num_qvalue_nets,
+            create_target_params=self.delay_qvalue,
+            compare_against=list(actor_network.parameters()),
+        )
+        self.num_qvalue_nets = num_qvalue_nets
+        self.priority_key = priority_key
+        self.loss_function = loss_function
+
+        try:
+            device = next(self.parameters()).device
+        except AttributeError:
+            device = torch.device("cpu")
+
+        self.register_buffer("alpha_init", torch.tensor(alpha_init, device=device))
+        self.register_buffer(
+            "min_log_alpha", torch.tensor(min_alpha, device=device).log()
+        )
+        self.register_buffer(
+            "max_log_alpha", torch.tensor(max_alpha, device=device).log()
+        )
+        self.fixed_alpha = fixed_alpha
+        if fixed_alpha:
+            self.register_buffer(
+                "log_alpha", torch.tensor(math.log(alpha_init), device=device)
+            )
+        else:
+            self.register_parameter(
+                "log_alpha",
+                torch.nn.Parameter(torch.tensor(math.log(alpha_init), device=device)),
+            )
+
+        if target_entropy == "auto":
+            target_entropy = -float(np.log(1.0 / num_actions) * target_entropy_weight)
+        self.register_buffer(
+            "target_entropy", torch.tensor(target_entropy, device=device)
+        )
+
+    @property
+    def alpha(self):
+        self.log_alpha.data.clamp_(self.min_log_alpha, self.max_log_alpha)
+        with torch.no_grad():
+            alpha = self.log_alpha.exp()
+        return alpha
+
+    def forward(self, tensordict: TensorDictBase) -> TensorDictBase:
+        obs_keys = self.actor_network.in_keys
+        tensordict_select = tensordict.clone(False).select("next", *obs_keys, "action")
+
+        actor_params = torch.stack(
+            [self.actor_network_params, self.target_actor_network_params], 0
+        )
+
+        tensordict_actor_grad = tensordict_select.select(
+            *obs_keys
+        )  # to avoid overwriting keys
+        next_td_actor = step_mdp(tensordict_select).select(
+            *self.actor_network.in_keys
+        )  # next_observation ->
+        tensordict_actor = torch.stack([tensordict_actor_grad, next_td_actor], 0)
+        tensordict_actor = tensordict_actor.contiguous()
+
+        with set_exploration_type(ExplorationType.RANDOM):
+            # vmap doesn't support sampling, so we take it out from the vmap
+            td_params = vmap(self.actor_network.get_dist_params)(
+                tensordict_actor,
+                actor_params,
+            )
+            if isinstance(self.actor_network, ProbabilisticActor):
+                tensordict_actor_dist = self.actor_network.build_dist_from_params(
+                    td_params
+                )
+            else:
+                tensordict_actor_dist = self.actor_network.build_dist_from_params(
+                    td_params
+                )
+            probs = tensordict_actor_dist.probs
+            z = (probs == 0.0).float() * 1e-8
+            logp_pi = torch.log(probs + z)
+            logp_pi_pol = torch.sum(probs * logp_pi, dim=-1, keepdim=True)
+
+        # repeat tensordict_actor to match the qvalue size
+        _actor_loss_td = (
+            tensordict_actor[0]
+            .select(*self.qvalue_network.in_keys)
+            .expand(self.num_qvalue_nets, *tensordict_actor[0].batch_size)
+        )  # for actor loss
+        _qval_td = tensordict_select.select(*self.qvalue_network.in_keys).expand(
+            self.num_qvalue_nets,
+            *tensordict_select.select(*self.qvalue_network.in_keys).batch_size,
+        )  # for qvalue loss
+        _next_val_td = (
+            tensordict_actor[1]
+            .select(*self.qvalue_network.in_keys)
+            .expand(self.num_qvalue_nets, *tensordict_actor[1].batch_size)
+        )  # for next value estimation
+        tensordict_qval = torch.cat(
+            [
+                _actor_loss_td,
+                _next_val_td,
+                _qval_td,
+            ],
+            0,
+        )
+
+        # cat params
+        q_params_detach = self.qvalue_network_params.detach()
+        qvalue_params = torch.cat(
+            [
+                q_params_detach,
+                self.target_qvalue_network_params,
+                self.qvalue_network_params,
+            ],
+            0,
+        )
+        tensordict_qval = vmap(self.qvalue_network)(
+            tensordict_qval,
+            qvalue_params,
+        )
+
+        state_action_value = tensordict_qval.get("state_value").squeeze(-1)
+        (
+            state_action_value_actor,
+            next_state_action_value_qvalue,
+            state_action_value_qvalue,
+        ) = state_action_value.split(
+            [self.num_qvalue_nets, self.num_qvalue_nets, self.num_qvalue_nets],
+            dim=0,
+        )
+
+        loss_actor = -(
+            (state_action_value_actor.min(0)[0] * probs[0]).sum(-1, keepdim=True)
+            - self.alpha * logp_pi_pol[0]
+        ).mean()
+
+        pred_next_val = (
+            probs[1]
+            * (next_state_action_value_qvalue.min(0)[0] - self.alpha * logp_pi[1])
+        ).sum(dim=-1, keepdim=True)
+
+        tensordict_select.set(("next", self.value_estimator.value_key), pred_next_val)
+        target_value = self.value_estimator.value_estimate(tensordict_select).squeeze(
+            -1
+        )
+
+        actions = torch.argmax(tensordict_select["action"], dim=-1)
+
+        pred_val_1 = (
+            state_action_value_qvalue[0].gather(-1, actions.unsqueeze(-1)).unsqueeze(0)
+        )
+        pred_val_2 = (
+            state_action_value_qvalue[1].gather(-1, actions.unsqueeze(-1)).unsqueeze(0)
+        )
+        pred_val = torch.cat([pred_val_1, pred_val_2], dim=0).squeeze()
+        td_error = (pred_val - target_value.expand_as(pred_val)).pow(2)
+        loss_qval = (
+            distance_loss(
+                pred_val,
+                target_value.expand_as(pred_val),
+                loss_function=self.loss_function,
+            )
+            .mean(-1)
+            .sum()
+            * 0.5
+        )
+
+        tensordict.set("td_error", td_error.detach().max(0)[0])
+
+        loss_alpha = self._loss_alpha(logp_pi_pol)
+        if not loss_qval.shape == loss_actor.shape:
+            raise RuntimeError(
+                f"QVal and actor loss have different shape: {loss_qval.shape} and {loss_actor.shape}"
+            )
+        td_out = TensorDict(
+            {
+                "loss_actor": loss_actor.mean(),
+                "loss_qvalue": loss_qval.mean(),
+                "loss_alpha": loss_alpha.mean(),
+                "alpha": self.alpha.detach(),
+                "entropy": -logp_pi.mean().detach(),
+                "state_action_value_actor": state_action_value_actor.mean().detach(),
+                "action_log_prob_actor": logp_pi.mean().detach(),
+                "next.state_value": pred_next_val.mean().detach(),
+                "target_value": target_value.mean().detach(),
+            },
+            [],
+        )
+
+        return td_out
+
+    def _loss_alpha(self, log_pi: Tensor) -> Tensor:
+        if torch.is_grad_enabled() and not log_pi.requires_grad:
+            raise RuntimeError(
+                "expected log_pi to require gradient for the alpha loss)"
+            )
+        if self.target_entropy is not None:
+            # we can compute this loss even if log_alpha is not a parameter
+            alpha_loss = -self.log_alpha.exp() * (log_pi.detach() + self.target_entropy)
+        else:
+            # placeholder
+            alpha_loss = torch.zeros_like(log_pi)
+        return alpha_loss
+
+    def make_value_estimator(self, value_type: ValueEstimators = None, **hyperparams):
+        if value_type is None:
+            value_type = self.default_value_estimator
+        self.value_type = value_type
+        value_net = None
+        value_key = "state_value"
+        hp = dict(default_value_kwargs(value_type))
+        hp.update(hyperparams)
+        if hasattr(self, "gamma"):
+            hp["gamma"] = self.gamma
+        if value_type is ValueEstimators.TD1:
+            self._value_estimator = TD1Estimator(
+                **hp,
+                value_network=value_net,
+                value_target_key="value_target",
+                value_key=value_key,
+            )
+        elif value_type is ValueEstimators.TD0:
+            self._value_estimator = TD0Estimator(
+                **hp,
+                value_network=value_net,
+                value_target_key="value_target",
+                value_key=value_key,
+            )
+        elif value_type is ValueEstimators.GAE:
+            raise NotImplementedError(
+                f"Value type {value_type} it not implemented for loss {type(self)}."
+            )
+        elif value_type is ValueEstimators.TDLambda:
+            self._value_estimator = TDLambdaEstimator(
+                **hp,
+                value_network=value_net,
+                value_target_key="value_target",
+                value_key=value_key,
+            )
+        else:
+            raise NotImplementedError(f"Unknown value type {value_type}")
```

## torchrl/objectives/td3.py

```diff
@@ -1,69 +1,83 @@
 # Copyright (c) Meta Platforms, Inc. and affiliates.
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
-
-from numbers import Number
+import warnings
 
 import torch
+from tensordict.nn import TensorDictModule
 
 from tensordict.tensordict import TensorDict, TensorDictBase
 
-from torchrl.envs.utils import set_exploration_mode, step_mdp
-from torchrl.modules import SafeModule
+from torchrl.envs.utils import step_mdp
 from torchrl.objectives.common import LossModule
 from torchrl.objectives.utils import (
+    _GAMMA_LMBDA_DEPREC_WARNING,
+    default_value_kwargs,
     distance_loss,
-    next_state_value as get_next_state_value,
+    ValueEstimators,
 )
+from torchrl.objectives.value import TD0Estimator, TD1Estimator, TDLambdaEstimator
 
 try:
-    from functorch import vmap
+    try:
+        from torch import vmap
+    except ImportError:
+        from functorch import vmap
 
     FUNCTORCH_ERR = ""
     _has_functorch = True
 except ImportError as err:
     FUNCTORCH_ERR = str(err)
     _has_functorch = False
 
 
 class TD3Loss(LossModule):
     """TD3 Loss module.
 
     Args:
-        actor_network (SafeModule): the actor to be trained
-        qvalue_network (SafeModule): a single Q-value network that will be multiplicated as many times as needed.
-        num_qvalue_nets (int, optional): Number of Q-value networks to be trained. Default is 10.
-        gamma (Number, optional): gamma decay factor. Default is 0.99.
-        max_action (float, optional): Maximum action, in MuJoCo environments typically 1.0.
-        policy_noise (float, optional): Standard deviation for the target policy action noise. Default is 0.2.
-        noise_clip (float, optional): Clipping range value for the sampled target policy action noise. Default is 0.5.
-        priotity_key (str, optional): Key where to write the priority value for prioritized replay buffers. Default is
+        actor_network (TensorDictModule): the actor to be trained
+        qvalue_network (TensorDictModule): a single Q-value network that will
+            be multiplicated as many times as needed.
+        num_qvalue_nets (int, optional): Number of Q-value networks to be
+            trained. Default is ``10``.
+        policy_noise (float, optional): Standard deviation for the target
+            policy action noise. Default is ``0.2``.
+        noise_clip (float, optional): Clipping range value for the sampled
+            target policy action noise. Default is ``0.5``.
+        priority_key (str, optional): Key where to write the priority value
+            for prioritized replay buffers. Default is
             `"td_error"`.
-        loss_function (str, optional): loss function to be used for the Q-value. Can be one of  `"smooth_l1"`, "l2",
-            "l1", Default is "smooth_l1".
-        delay_actor (bool, optional): whether to separate the target actor networks from the actor networks used for
-            data collection. Default is :obj:`False`.
-        delay_qvalue (bool, optional): Whether to separate the target Q value networks from the Q value networks used
-            for data collection. Default is :obj:`False`.
+        loss_function (str, optional): loss function to be used for the Q-value.
+            Can be one of  ``"smooth_l1"``, ``"l2"``,
+            ``"l1"``, Default is ``"smooth_l1"``.
+        delay_actor (bool, optional): whether to separate the target actor
+            networks from the actor networks used for
+            data collection. Default is ``False``.
+        delay_qvalue (bool, optional): Whether to separate the target Q value
+            networks from the Q value networks used
+            for data collection. Default is ``False``.
     """
 
+    default_value_estimator = ValueEstimators.TD0
+
     def __init__(
         self,
-        actor_network: SafeModule,
-        qvalue_network: SafeModule,
+        actor_network: TensorDictModule,
+        qvalue_network: TensorDictModule,
+        *,
         num_qvalue_nets: int = 2,
-        gamma: Number = 0.99,
         policy_noise: float = 0.2,
         noise_clip: float = 0.5,
-        priotity_key: str = "td_error",
+        priority_key: str = "td_error",
         loss_function: str = "smooth_l1",
         delay_actor: bool = False,
         delay_qvalue: bool = False,
+        gamma: float = None,
     ) -> None:
         if not _has_functorch:
             raise ImportError(
                 f"Failed to import functorch with error message:\n{FUNCTORCH_ERR}"
             )
 
         super().__init__()
@@ -82,43 +96,45 @@
             "qvalue_network",
             num_qvalue_nets,
             create_target_params=self.delay_qvalue,
             compare_against=list(actor_network.parameters()),
         )
 
         self.num_qvalue_nets = num_qvalue_nets
-        self.register_buffer("gamma", torch.tensor(gamma))
-        self.priority_key = priotity_key
+        self.priority_key = priority_key
         self.loss_function = loss_function
         self.policy_noise = policy_noise
         self.noise_clip = noise_clip
         self.max_action = actor_network.spec["action"].space.maximum.max().item()
+        if gamma is not None:
+            warnings.warn(_GAMMA_LMBDA_DEPREC_WARNING, category=DeprecationWarning)
+            self.gamma = gamma
 
     def forward(self, tensordict: TensorDictBase) -> TensorDictBase:
         obs_keys = self.actor_network.in_keys
-        tensordict_select = tensordict.select("next", *obs_keys, "action")
+        tensordict_save = tensordict
+        tensordict = tensordict.clone(False)
 
         actor_params = torch.stack(
             [self.actor_network_params, self.target_actor_network_params], 0
         )
 
-        tensordict_actor_grad = tensordict_select.select(
+        tensordict_actor_grad = tensordict.select(
             *obs_keys
         )  # to avoid overwriting keys
-        next_td_actor = step_mdp(tensordict_select).select(
+        next_td_actor = step_mdp(tensordict).select(
             *self.actor_network.in_keys
         )  # next_observation ->
         tensordict_actor = torch.stack([tensordict_actor_grad, next_td_actor], 0)
         tensordict_actor = tensordict_actor.contiguous()
 
-        with set_exploration_mode("mode"):
-            actor_output_td = vmap(self.actor_network)(
-                tensordict_actor,
-                actor_params,
-            )
+        actor_output_td = vmap(self.actor_network)(
+            tensordict_actor,
+            actor_params,
+        )
         # add noise to target policy
         noise = torch.normal(
             mean=torch.zeros(actor_output_td[1]["action"].shape),
             std=torch.ones(actor_output_td[1]["action"].shape) * self.policy_noise,
         ).to(actor_output_td[1].device)
         noise = noise.clamp(-self.noise_clip, self.noise_clip)
 
@@ -130,17 +146,17 @@
 
         # repeat tensordict_actor to match the qvalue size
         _actor_loss_td = (
             tensordict_actor[0]
             .select(*self.qvalue_network.in_keys)
             .expand(self.num_qvalue_nets, *tensordict_actor[0].batch_size)
         )  # for actor loss
-        _qval_td = tensordict_select.select(*self.qvalue_network.in_keys).expand(
+        _qval_td = tensordict.select(*self.qvalue_network.in_keys).expand(
             self.num_qvalue_nets,
-            *tensordict_select.select(*self.qvalue_network.in_keys).batch_size,
+            *tensordict.select(*self.qvalue_network.in_keys).batch_size,
         )  # for qvalue loss
         _next_val_td = (
             tensordict_actor[1]
             .select(*self.qvalue_network.in_keys)
             .expand(self.num_qvalue_nets, *tensordict_actor[1].batch_size)
         )  # for next value estimation
         tensordict_qval = torch.cat(
@@ -176,34 +192,30 @@
             [self.num_qvalue_nets, self.num_qvalue_nets, self.num_qvalue_nets],
             dim=0,
         )
 
         loss_actor = -(state_action_value_actor.min(0)[0]).mean()
 
         next_state_value = next_state_action_value_qvalue.min(0)[0]
-
-        target_value = get_next_state_value(
-            tensordict,
-            gamma=self.gamma,
-            pred_next_val=next_state_value,
-        )
+        tensordict.set(("next", "state_action_value"), next_state_value.unsqueeze(-1))
+        target_value = self.value_estimator.value_estimate(tensordict).squeeze(-1)
         pred_val = state_action_value_qvalue
         td_error = (pred_val - target_value).pow(2)
         loss_qval = (
             distance_loss(
                 pred_val,
                 target_value.expand_as(pred_val),
                 loss_function=self.loss_function,
             )
             .mean(-1)
             .sum()
             * 0.5
         )
 
-        tensordict.set("td_error", td_error.detach().max(0)[0])
+        tensordict_save.set("td_error", td_error.detach().max(0)[0])
 
         if not loss_qval.shape == loss_actor.shape:
             raise RuntimeError(
                 f"QVal and actor loss have different shape: {loss_qval.shape} and {loss_actor.shape}"
             )
         td_out = TensorDict(
             source={
@@ -214,7 +226,36 @@
                 "next_state_value": next_state_value.mean().detach(),
                 "target_value": target_value.mean().detach(),
             },
             batch_size=[],
         )
 
         return td_out
+
+    def make_value_estimator(self, value_type: ValueEstimators = None, **hyperparams):
+        if value_type is None:
+            value_type = self.default_value_estimator
+        self.value_type = value_type
+        hp = dict(default_value_kwargs(value_type))
+        if hasattr(self, "gamma"):
+            hp["gamma"] = self.gamma
+        hp.update(hyperparams)
+        value_key = "state_action_value"
+        # we do not need a value network bc the next state value is already passed
+        if value_type == ValueEstimators.TD1:
+            self._value_estimator = TD1Estimator(
+                value_network=None, value_key=value_key, **hp
+            )
+        elif value_type == ValueEstimators.TD0:
+            self._value_estimator = TD0Estimator(
+                value_network=None, value_key=value_key, **hp
+            )
+        elif value_type == ValueEstimators.GAE:
+            raise NotImplementedError(
+                f"Value type {value_type} it not implemented for loss {type(self)}."
+            )
+        elif value_type == ValueEstimators.TDLambda:
+            self._value_estimator = TDLambdaEstimator(
+                value_network=None, value_key=value_key, **hp
+            )
+        else:
+            raise NotImplementedError(f"Unknown value type {value_type}")
```

## torchrl/objectives/utils.py

```diff
@@ -1,22 +1,72 @@
 # Copyright (c) Meta Platforms, Inc. and affiliates.
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
 
 import functools
+import warnings
+from enum import Enum
 from typing import Iterable, Optional, Union
 
 import torch
+from tensordict.nn import TensorDictModule
 from tensordict.tensordict import TensorDict, TensorDictBase
 from torch import nn, Tensor
 from torch.nn import functional as F
 
 from torchrl.envs.utils import step_mdp
-from torchrl.modules import SafeModule
+
+_GAMMA_LMBDA_DEPREC_WARNING = (
+    "Passing gamma / lambda parameters through the loss constructor "
+    "is deprecated and will be removed soon. To customize your value function, "
+    "run `loss_module.make_value_estimator(ValueEstimators.<value_fun>, gamma=val)`."
+)
+
+
+class ValueEstimators(Enum):
+    """Value function enumerator for custom-built estimators.
+
+    Allows for a flexible usage of various value functions when the loss module
+    allows it.
+
+    Examples:
+        >>> dqn_loss = DQNLoss(actor)
+        >>> dqn_loss.make_value_estimator(ValueEstimators.TD0, gamma=0.9)
+
+    """
+
+    TD0 = "Bootstrapped TD (1-step return)"
+    TD1 = "TD(1) (infinity-step return)"
+    TDLambda = "TD(lambda)"
+    GAE = "Generalized advantage estimate"
+
+
+def default_value_kwargs(value_type: ValueEstimators):
+    """Default value function keyword argument generator.
+
+    Args:
+        value_type (Enum.value): the value function type, from the
+        :class:`~torchrl.objectives.utils.ValueEstimators` class.
+
+    Examples:
+        >>> kwargs = default_value_kwargs(ValueEstimators.TDLambda)
+        {"gamma": 0.99, "lmbda": 0.95}
+
+    """
+    if value_type == ValueEstimators.TD1:
+        return {"gamma": 0.99, "differentiable": True}
+    elif value_type == ValueEstimators.TD0:
+        return {"gamma": 0.99, "differentiable": True}
+    elif value_type == ValueEstimators.GAE:
+        return {"gamma": 0.99, "lmbda": 0.95, "differentiable": True}
+    elif value_type == ValueEstimators.TDLambda:
+        return {"gamma": 0.99, "lmbda": 0.95, "differentiable": True}
+    else:
+        raise NotImplementedError(f"Unknown value type {value_type}.")
 
 
 class _context_manager:
     def __init__(self, value=True):
         self.value = value
         self.prev = []
 
@@ -85,61 +135,67 @@
     Args:
         loss_module (DQNLoss or DDPGLoss): loss module where the target network should be updated.
 
     """
 
     def __init__(
         self,
-        loss_module: Union["DQNLoss", "DDPGLoss", "SACLoss", "TD3Loss"],  # noqa: F821
+        loss_module: "LossModule",  # noqa: F821
     ):
+        _has_update_associated = getattr(loss_module, "_has_update_associated", None)
+        loss_module._has_update_associated = True
+        try:
+            _target_names = []
+            # for properties
+            for name in loss_module.__class__.__dict__:
+                if (
+                    name.startswith("target_")
+                    and (name.endswith("params") or name.endswith("buffers"))
+                    and (getattr(loss_module, name) is not None)
+                ):
+                    _target_names.append(name)
+
+            # for regular lists: raise an exception
+            for name in loss_module.__dict__:
+                if (
+                    name.startswith("target_")
+                    and (name.endswith("params") or name.endswith("buffers"))
+                    and (getattr(loss_module, name) is not None)
+                ):
+                    raise RuntimeError(
+                        "Your module seems to have a target tensor list contained "
+                        "in a non-dynamic structure (such as a list). If the "
+                        "module is cast onto a device, the reference to these "
+                        "tensors will be lost."
+                    )
 
-        _target_names = []
-        # for properties
-        for name in loss_module.__class__.__dict__:
-            if (
-                name.startswith("target_")
-                and (name.endswith("params") or name.endswith("buffers"))
-                and (getattr(loss_module, name) is not None)
-            ):
-                _target_names.append(name)
-
-        # for regular lists: raise an exception
-        for name in loss_module.__dict__:
-            if (
-                name.startswith("target_")
-                and (name.endswith("params") or name.endswith("buffers"))
-                and (getattr(loss_module, name) is not None)
-            ):
+            if len(_target_names) == 0:
                 raise RuntimeError(
-                    "Your module seems to have a target tensor list contained "
-                    "in a non-dynamic structure (such as a list). If the "
-                    "module is cast onto a device, the reference to these "
-                    "tensors will be lost."
+                    "Did not find any target parameters or buffers in the loss module."
                 )
 
-        if len(_target_names) == 0:
-            raise RuntimeError(
-                "Did not find any target parameters or buffers in the loss module."
-            )
-
-        _source_names = ["".join(name.split("target_")) for name in _target_names]
+            _source_names = ["".join(name.split("target_")) for name in _target_names]
 
-        for _source in _source_names:
-            try:
-                getattr(loss_module, _source)
-            except AttributeError:
-                raise RuntimeError(
-                    f"Incongruent target and source parameter lists: "
-                    f"{_source} is not an attribute of the loss_module"
-                )
-
-        self._target_names = _target_names
-        self._source_names = _source_names
-        self.loss_module = loss_module
-        self.initialized = False
+            for _source in _source_names:
+                try:
+                    getattr(loss_module, _source)
+                except AttributeError:
+                    raise RuntimeError(
+                        f"Incongruent target and source parameter lists: "
+                        f"{_source} is not an attribute of the loss_module"
+                    )
+
+            self._target_names = _target_names
+            self._source_names = _source_names
+            self.loss_module = loss_module
+            self.initialized = False
+            self.init_()
+            _has_update_associated = True
+        finally:
+            loss_module._has_update_associated = _has_update_associated
 
     @property
     def _targets(self):
         return TensorDict(
             {name: getattr(self.loss_module, name) for name in self._target_names},
             [],
         )
@@ -148,14 +204,16 @@
     def _sources(self):
         return TensorDict(
             {name: getattr(self.loss_module, name) for name in self._source_names},
             [],
         )
 
     def init_(self) -> None:
+        if self.initialized:
+            warnings.warn("Updated already initialized.")
         for key, source in self._sources.items(True, True):
             if not isinstance(key, tuple):
                 key = (key,)
             key = ("target_" + key[0], *key[1:])
             target = self._targets[key]
             # for p_source, p_target in zip(source, target):
             if target.requires_grad:
@@ -189,37 +247,40 @@
             f"{self.__class__.__name__}(sources={self._sources}, targets="
             f"{self._targets})"
         )
         return string
 
 
 class SoftUpdate(TargetNetUpdater):
-    """A soft-update class for target network update in Double DQN/DDPG.
+    r"""A soft-update class for target network update in Double DQN/DDPG.
 
     This was proposed in "CONTINUOUS CONTROL WITH DEEP REINFORCEMENT LEARNING", https://arxiv.org/pdf/1509.02971.pdf
 
     Args:
         loss_module (DQNLoss or DDPGLoss): loss module where the target network should be updated.
         eps (scalar): epsilon in the update equation:
-            param = prev_param * eps + new_param * (1-eps)
-            default: 0.999
+            .. math::
+
+                \theta_t = \theta_{t-1} * \epsilon + \theta_t * (1-\epsilon)
+
+            Defaults to 0.999
     """
 
     def __init__(
         self,
         loss_module: Union[
             "DQNLoss",  # noqa: F821
             "DDPGLoss",  # noqa: F821
             "SACLoss",  # noqa: F821
             "REDQLoss",  # noqa: F821
             "TD3Loss",  # noqa: F821
         ],
         eps: float = 0.999,
     ):
-        if not (eps < 1.0 and eps > 0.0):
+        if not (eps <= 1.0 and eps >= 0.0):
             raise ValueError(
                 f"Got eps = {eps} when it was supposed to be between 0 and 1."
             )
         super(SoftUpdate, self).__init__(loss_module)
         self.eps = eps
 
     def _step(self, p_source: Tensor, p_target: Tensor) -> None:
@@ -262,15 +323,15 @@
 class hold_out_net(_context_manager):
     """Context manager to hold a network out of a computational graph."""
 
     def __init__(self, network: nn.Module) -> None:
         self.network = network
         try:
             self.p_example = next(network.parameters())
-        except StopIteration:
+        except (AttributeError, StopIteration):
             self.p_example = torch.tensor([])
         self._prev_state = []
 
     def __enter__(self) -> None:
         self._prev_state.append(self.p_example.requires_grad)
         self.network.requires_grad_(False)
 
@@ -293,15 +354,15 @@
     def __exit__(self, exc_type, exc_val, exc_tb) -> None:
         pass
 
 
 @torch.no_grad()
 def next_state_value(
     tensordict: TensorDictBase,
-    operator: Optional[SafeModule] = None,
+    operator: Optional[TensorDictModule] = None,
     next_val_key: str = "state_action_value",
     gamma: float = 0.99,
     pred_next_val: Optional[Tensor] = None,
     **kwargs,
 ) -> torch.Tensor:
     """Computes the next state value (without gradient) to compute a target value.
 
@@ -330,14 +391,16 @@
     if "steps_to_next_obs" in tensordict.keys():
         steps_to_next_obs = tensordict.get("steps_to_next_obs").squeeze(-1)
     else:
         steps_to_next_obs = 1
 
     rewards = tensordict.get(("next", "reward")).squeeze(-1)
     done = tensordict.get(("next", "done")).squeeze(-1)
+    if done.all() or gamma == 0:
+        return rewards
 
     if pred_next_val is None:
         next_td = step_mdp(tensordict)  # next_observation -> observation
         next_td = next_td.select(*operator.in_keys)
         operator(next_td, **kwargs)
         pred_next_val_detach = next_td.get(next_val_key).squeeze(-1)
     else:
```

## torchrl/objectives/value/__init__.py

```diff
@@ -1,6 +1,15 @@
 # Copyright (c) Meta Platforms, Inc. and affiliates.
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
 
-from .advantages import GAE, TDEstimate, TDLambdaEstimate
+from .advantages import (
+    GAE,
+    TD0Estimate,
+    TD0Estimator,
+    TD1Estimate,
+    TD1Estimator,
+    TDLambdaEstimate,
+    TDLambdaEstimator,
+    ValueEstimatorBase,
+)
```

## torchrl/objectives/value/advantages.py

```diff
@@ -1,112 +1,251 @@
 # Copyright (c) Meta Platforms, Inc. and affiliates.
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
-
+import abc
+import functools
+import warnings
 from functools import wraps
-from typing import List, Optional, Tuple, Union
+from typing import Callable, List, Optional, Tuple, Union
 
 import torch
-from tensordict.nn import dispatch
+from tensordict.nn import (
+    dispatch,
+    is_functional,
+    set_skip_existing,
+    TensorDictModule,
+    TensorDictModuleBase,
+)
 from tensordict.tensordict import TensorDictBase
 from torch import nn, Tensor
 
 from torchrl.envs.utils import step_mdp
-from torchrl.modules import SafeModule
 
 from torchrl.objectives.utils import hold_out_net
 from torchrl.objectives.value.functional import (
-    td_advantage_estimate,
-    td_lambda_advantage_estimate,
+    generalized_advantage_estimate,
+    td0_return_estimate,
+    td_lambda_return_estimate,
     vec_generalized_advantage_estimate,
-    vec_td_lambda_advantage_estimate,
+    vec_td1_return_estimate,
+    vec_td_lambda_return_estimate,
 )
 
 
 def _self_set_grad_enabled(fun):
     @wraps(fun)
     def new_fun(self, *args, **kwargs):
         with torch.set_grad_enabled(self.differentiable):
             return fun(self, *args, **kwargs)
 
     return new_fun
 
 
-class TDEstimate(nn.Module):
-    """Temporal Difference estimate of advantage function.
+def _self_set_skip_existing(fun):
+    @functools.wraps(fun)
+    def new_func(self, *args, **kwargs):
+        if self.skip_existing is not None:
+            with set_skip_existing(self.skip_existing):
+                return fun(self, *args, **kwargs)
+        return fun(self, *args, **kwargs)
+
+    return new_func
+
+
+class ValueEstimatorBase(TensorDictModuleBase):
+    """An abstract parent class for value function modules.
+
+    Its :meth:`ValueFunctionBase.forward` method will compute the value (given
+    by the value network) and the value estimate (given by the value estimator)
+    as well as the advantage and write these values in the output tensordict.
 
-    Args:
-        gamma (scalar): exponential mean discount.
-        value_network (SafeModule): value operator used to retrieve the value estimates.
-        average_rewards (bool, optional): if True, rewards will be standardized
-            before the TD is computed.
-        differentiable (bool, optional): if True, gradients are propagated throught
-            the computation of the value function. Default is :obj:`False`.
-        advantage_key (str or tuple of str, optional): the key of the advantage entry.
-            Defaults to "advantage".
-        value_target_key (str or tuple of str, optional): the key of the advantage entry.
-            Defaults to "value_target".
-        value_key (str or tuple of str, optional): the value key to read from the input tensordict.
-            Defaults to "state_value".
+    If only the value estimate is needed, the :meth:`ValueFunctionBase.value_estimate`
+    should be used instead.
 
     """
 
+    value_network: Union[TensorDictModule, Callable]
+    value_key: Union[Tuple[str], str]
+
+    @abc.abstractmethod
+    def forward(
+        self,
+        tensordict: TensorDictBase,
+        params: Optional[TensorDictBase] = None,
+        target_params: Optional[TensorDictBase] = None,
+    ) -> TensorDictBase:
+        """Computes the advantage estimate given the data in tensordict.
+
+        If a functional module is provided, a nested TensorDict containing the parameters
+        (and if relevant the target parameters) can be passed to the module.
+
+        Args:
+            tensordict (TensorDictBase): A TensorDict containing the data
+                (an observation key, "action", ("next", "reward"), ("next", "done") and "next" tensordict state
+                as returned by the environment) necessary to compute the value estimates and the TDEstimate.
+                The data passed to this module should be structured as :obj:`[*B, T, F]` where :obj:`B` are
+                the batch size, :obj:`T` the time dimension and :obj:`F` the feature dimension(s).
+            params (TensorDictBase, optional): A nested TensorDict containing the params
+                to be passed to the functional value network module.
+            target_params (TensorDictBase, optional): A nested TensorDict containing the
+                target params to be passed to the functional value network module.
+
+        Returns:
+            An updated TensorDict with an advantage and a value_error keys as defined in the constructor.
+        """
+        raise NotImplementedError
+
     def __init__(
         self,
-        gamma: Union[float, torch.Tensor],
-        value_network: SafeModule,
-        average_rewards: bool = False,
+        *,
+        value_network: TensorDictModule,
         differentiable: bool = False,
         advantage_key: Union[str, Tuple] = "advantage",
         value_target_key: Union[str, Tuple] = "value_target",
         value_key: Union[str, Tuple] = "state_value",
+        skip_existing: Optional[bool] = None,
     ):
         super().__init__()
-        try:
-            device = next(value_network.parameters()).device
-        except StopIteration:
-            device = torch.device("cpu")
-        self.register_buffer("gamma", torch.tensor(gamma, device=device))
-        self.value_network = value_network
-
-        self.average_rewards = average_rewards
         self.differentiable = differentiable
+        self.skip_existing = skip_existing
+        self.value_network = value_network
         self.value_key = value_key
-        if value_key not in value_network.out_keys:
+        if (
+            hasattr(value_network, "out_keys")
+            and value_key not in value_network.out_keys
+        ):
             raise KeyError(
                 f"value key '{value_key}' not found in value network out_keys."
             )
 
         self.advantage_key = advantage_key
         self.value_target_key = value_target_key
 
-        self.in_keys = (
-            value_network.in_keys
-            + [("next", "reward"), ("next", "done")]
-            + [("next", in_key) for in_key in value_network.in_keys]
-        )
+        try:
+            self.in_keys = (
+                value_network.in_keys
+                + [("next", "reward"), ("next", "done")]
+                + [("next", in_key) for in_key in value_network.in_keys]
+            )
+        except AttributeError:
+            # value network does not have an `in_keys` attribute
+            self.in_keys = []
+            pass
+
         self.out_keys = [self.advantage_key, self.value_target_key]
 
+    def value_estimate(
+        self,
+        tensordict,
+        target_params: Optional[TensorDictBase] = None,
+        **kwargs,
+    ):
+        """Gets a value estimate, usually used as a target value for the value network.
+
+        If the state value key is present under ``tensordict.get(("next", self.value_key))``
+        then this value will be used without recurring to the value network.
+
+        Args:
+            tensordict (TensorDictBase): the tensordict containing the data to
+                read.
+            target_params (TensorDictBase, optional): A nested TensorDict containing the
+                target params to be passed to the functional value network module.
+            **kwargs: the keyword arguments to be passed to the value network.
+
+        Returns: a tensor corresponding to the state value.
+
+        """
+        raise NotImplementedError
+
     @property
     def is_functional(self):
-        return (
-            "_is_stateless" in self.value_network.__dict__
-            and self.value_network.__dict__["_is_stateless"]
+        if isinstance(self.value_network, nn.Module):
+            return is_functional(self.value_network)
+        elif self.value_network is None:
+            return None
+        else:
+            raise RuntimeError("Cannot determine if value network is functional.")
+
+    @property
+    def is_stateless(self):
+        if not self.is_functional:
+            return False
+        return self.value_network._is_stateless
+
+
+class TD0Estimator(ValueEstimatorBase):
+    """Temporal Difference (TD(0)) estimate of advantage function.
+
+    AKA bootstrapped temporal difference or 1-step return.
+
+    Keyword Args:
+        gamma (scalar): exponential mean discount.
+        value_network (TensorDictModule): value operator used to retrieve
+            the value estimates.
+        average_rewards (bool, optional): if ``True``, rewards will be standardized
+            before the TD is computed.
+        differentiable (bool, optional): if ``True``, gradients are propagated through
+            the computation of the value function. Default is ``False``.
+
+            .. note::
+              The proper way to make the function call non-differentiable is to
+              decorate it in a `torch.no_grad()` context manager/decorator or
+              pass detached parameters for functional modules.
+
+        advantage_key (str or tuple of str, optional): the key of the advantage entry.
+            Defaults to "advantage".
+        value_target_key (str or tuple of str, optional): the key of the advantage entry.
+            Defaults to "value_target".
+        value_key (str or tuple of str, optional): the value key to read from the input tensordict.
+            Defaults to "state_value".
+        skip_existing (bool, optional): if ``True``, the value network will skip
+            modules which outputs are already present in the tensordict.
+            Defaults to ``None``, ie. the value of :func:`tensordict.nn.skip_existing()`
+            is not affected.
+
+    """
+
+    def __init__(
+        self,
+        *,
+        gamma: Union[float, torch.Tensor],
+        value_network: TensorDictModule,
+        average_rewards: bool = False,
+        differentiable: bool = False,
+        advantage_key: Union[str, Tuple] = "advantage",
+        value_target_key: Union[str, Tuple] = "value_target",
+        value_key: Union[str, Tuple] = "state_value",
+        skip_existing: Optional[bool] = None,
+    ):
+        super().__init__(
+            value_network=value_network,
+            differentiable=differentiable,
+            advantage_key=advantage_key,
+            value_target_key=value_target_key,
+            value_key=value_key,
+            skip_existing=skip_existing,
         )
+        try:
+            device = next(value_network.parameters()).device
+        except (AttributeError, StopIteration):
+            device = torch.device("cpu")
+        self.register_buffer("gamma", torch.tensor(gamma, device=device))
+        self.average_rewards = average_rewards
 
+    @_self_set_skip_existing
     @_self_set_grad_enabled
     @dispatch
     def forward(
         self,
         tensordict: TensorDictBase,
         params: Optional[TensorDictBase] = None,
         target_params: Optional[TensorDictBase] = None,
     ) -> TensorDictBase:
-        """Computes the TDEstimate given the data in tensordict.
+        """Computes the TD(0) advantage given the data in tensordict.
 
         If a functional module is provided, a nested TensorDict containing the parameters
         (and if relevant the target parameters) can be passed to the module.
 
         Args:
             tensordict (TensorDictBase): A TensorDict containing the data
                 (an observation key, "action", ("next", "reward"), ("next", "done") and "next" tensordict state
@@ -119,168 +258,350 @@
                 target params to be passed to the functional value network module.
 
         Returns:
             An updated TensorDict with an advantage and a value_error keys as defined in the constructor.
 
         Examples:
             >>> from tensordict import TensorDict
-            >>> value_net = SafeModule(
+            >>> value_net = TensorDictModule(
             ...     nn.Linear(3, 1), in_keys=["obs"], out_keys=["state_value"]
             ... )
             >>> module = TDEstimate(
             ...     gamma=0.98,
             ...     value_network=value_net,
-            ...     differentiable=False,
             ... )
             >>> obs, next_obs = torch.randn(2, 1, 10, 3)
             >>> reward = torch.randn(1, 10, 1)
             >>> done = torch.zeros(1, 10, 1, dtype=torch.bool)
             >>> tensordict = TensorDict({"obs": obs, "next": {"obs": next_obs, "done": done, "reward": reward}}, [1, 10])
             >>> _ = module(tensordict)
             >>> assert "advantage" in tensordict.keys()
 
         The module supports non-tensordict (i.e. unpacked tensordict) inputs too:
 
         Examples:
-            >>> value_net = SafeModule(
+            >>> value_net = TensorDictModule(
             ...     nn.Linear(3, 1), in_keys=["obs"], out_keys=["state_value"]
             ... )
             >>> module = TDEstimate(
             ...     gamma=0.98,
             ...     value_network=value_net,
-            ...     differentiable=False,
             ... )
             >>> obs, next_obs = torch.randn(2, 1, 10, 3)
             >>> reward = torch.randn(1, 10, 1)
             >>> done = torch.zeros(1, 10, 1, dtype=torch.bool)
             >>> advantage, value_target = module(obs=obs, reward=reward, done=done, next_obs=next_obs)
 
         """
         if tensordict.batch_dims < 1:
             raise RuntimeError(
                 "Expected input tensordict to have at least one dimensions, got"
                 f"tensordict.batch_size = {tensordict.batch_size}"
             )
+
+        kwargs = {}
+        if self.is_stateless and params is None:
+            raise RuntimeError(
+                "Expected params to be passed to advantage module but got none."
+            )
+        if params is not None:
+            kwargs["params"] = params.detach()
+        with hold_out_net(self.value_network):
+            self.value_network(tensordict, **kwargs)
+            value = tensordict.get(self.value_key)
+
+        if params is not None and target_params is None:
+            target_params = params.detach()
+        value_target = self.value_estimate(tensordict, target_params=target_params)
+        tensordict.set("advantage", value_target - value)
+        tensordict.set("value_target", value_target)
+        return tensordict
+
+    def value_estimate(
+        self,
+        tensordict,
+        target_params: Optional[TensorDictBase] = None,
+        **kwargs,
+    ):
         reward = tensordict.get(("next", "reward"))
+        device = reward.device
+        gamma = self.gamma.to(device)
+        steps_to_next_obs = tensordict.get("steps_to_next_obs", None)
+        if steps_to_next_obs is not None:
+            gamma = gamma ** steps_to_next_obs.view_as(reward)
+
         if self.average_rewards:
             reward = reward - reward.mean()
             reward = reward / reward.std().clamp_min(1e-4)
             tensordict.set(
                 ("next", "reward"), reward
             )  # we must update the rewards if they are used later in the code
+        step_td = step_mdp(tensordict)
+        if self.value_network is not None:
+            if target_params is not None:
+                kwargs["params"] = target_params
+            with hold_out_net(self.value_network):
+                self.value_network(step_td, **kwargs)
+        next_value = step_td.get(self.value_key)
+
+        done = tensordict.get(("next", "done"))
+        value_target = td0_return_estimate(
+            gamma=gamma, next_state_value=next_value, reward=reward, done=done
+        )
+        return value_target
+
+
+class TD1Estimator(ValueEstimatorBase):
+    r""":math:`\infty`-Temporal Difference (TD(1)) estimate of advantage function.
+
+    Keyword Args:
+        gamma (scalar): exponential mean discount.
+        value_network (TensorDictModule): value operator used to retrieve the value estimates.
+        average_rewards (bool, optional): if ``True``, rewards will be standardized
+            before the TD is computed.
+        differentiable (bool, optional): if ``True``, gradients are propagated through
+            the computation of the value function. Default is ``False``.
+
+            .. note::
+              The proper way to make the function call non-differentiable is to
+              decorate it in a `torch.no_grad()` context manager/decorator or
+              pass detached parameters for functional modules.
+
+        advantage_key (str or tuple of str, optional): the key of the advantage entry.
+            Defaults to "advantage".
+        value_target_key (str or tuple of str, optional): the key of the advantage entry.
+            Defaults to "value_target".
+        value_key (str or tuple of str, optional): the value key to read from the input tensordict.
+            Defaults to "state_value".
+        skip_existing (bool, optional): if ``True``, the value network will skip
+            modules which outputs are already present in the tensordict.
+            Defaults to ``None``, ie. the value of :func:`tensordict.nn.skip_existing()`
+            is not affected.
+
+    """
+
+    def __init__(
+        self,
+        *,
+        gamma: Union[float, torch.Tensor],
+        value_network: TensorDictModule,
+        average_rewards: bool = False,
+        differentiable: bool = False,
+        advantage_key: Union[str, Tuple] = "advantage",
+        value_target_key: Union[str, Tuple] = "value_target",
+        value_key: Union[str, Tuple] = "state_value",
+        skip_existing: Optional[bool] = None,
+    ):
+        super().__init__(
+            value_network=value_network,
+            differentiable=differentiable,
+            advantage_key=advantage_key,
+            value_target_key=value_target_key,
+            value_key=value_key,
+            skip_existing=skip_existing,
+        )
+        try:
+            device = next(value_network.parameters()).device
+        except (AttributeError, StopIteration):
+            device = torch.device("cpu")
+        self.register_buffer("gamma", torch.tensor(gamma, device=device))
+        self.average_rewards = average_rewards
+
+    @_self_set_skip_existing
+    @_self_set_grad_enabled
+    @dispatch
+    def forward(
+        self,
+        tensordict: TensorDictBase,
+        params: Optional[TensorDictBase] = None,
+        target_params: Optional[TensorDictBase] = None,
+    ) -> TensorDictBase:
+        """Computes the TD(1) advantage given the data in tensordict.
+
+        If a functional module is provided, a nested TensorDict containing the parameters
+        (and if relevant the target parameters) can be passed to the module.
+
+        Args:
+            tensordict (TensorDictBase): A TensorDict containing the data
+                (an observation key, "action", ("next", "reward"), ("next", "done") and "next" tensordict state
+                as returned by the environment) necessary to compute the value estimates and the TDEstimate.
+                The data passed to this module should be structured as :obj:`[*B, T, F]` where :obj:`B` are
+                the batch size, :obj:`T` the time dimension and :obj:`F` the feature dimension(s).
+            params (TensorDictBase, optional): A nested TensorDict containing the params
+                to be passed to the functional value network module.
+            target_params (TensorDictBase, optional): A nested TensorDict containing the
+                target params to be passed to the functional value network module.
+
+        Returns:
+            An updated TensorDict with an advantage and a value_error keys as defined in the constructor.
+
+        Examples:
+            >>> from tensordict import TensorDict
+            >>> value_net = TensorDictModule(
+            ...     nn.Linear(3, 1), in_keys=["obs"], out_keys=["state_value"]
+            ... )
+            >>> module = TDEstimate(
+            ...     gamma=0.98,
+            ...     value_network=value_net,
+            ... )
+            >>> obs, next_obs = torch.randn(2, 1, 10, 3)
+            >>> reward = torch.randn(1, 10, 1)
+            >>> done = torch.zeros(1, 10, 1, dtype=torch.bool)
+            >>> tensordict = TensorDict({"obs": obs, "next": {"obs": next_obs, "done": done, "reward": reward}}, [1, 10])
+            >>> _ = module(tensordict)
+            >>> assert "advantage" in tensordict.keys()
+
+        The module supports non-tensordict (i.e. unpacked tensordict) inputs too:
+
+        Examples:
+            >>> value_net = TensorDictModule(
+            ...     nn.Linear(3, 1), in_keys=["obs"], out_keys=["state_value"]
+            ... )
+            >>> module = TDEstimate(
+            ...     gamma=0.98,
+            ...     value_network=value_net,
+            ... )
+            >>> obs, next_obs = torch.randn(2, 1, 10, 3)
+            >>> reward = torch.randn(1, 10, 1)
+            >>> done = torch.zeros(1, 10, 1, dtype=torch.bool)
+            >>> advantage, value_target = module(obs=obs, reward=reward, done=done, next_obs=next_obs)
+
+        """
+        if tensordict.batch_dims < 1:
+            raise RuntimeError(
+                "Expected input tensordict to have at least one dimensions, got"
+                f"tensordict.batch_size = {tensordict.batch_size}"
+            )
 
-        gamma = self.gamma
         kwargs = {}
-        if self.is_functional and params is None:
+        if self.is_stateless and params is None:
             raise RuntimeError(
                 "Expected params to be passed to advantage module but got none."
             )
         if params is not None:
             kwargs["params"] = params.detach()
-        with hold_out_net(self.value_network):
-            self.value_network(tensordict, **kwargs)
-            value = tensordict.get(self.value_key)
+        if self.value_network is not None:
+            with hold_out_net(self.value_network):
+                self.value_network(tensordict, **kwargs)
+        value = tensordict.get(self.value_key)
 
-        # we may still need to pass gradient, but we don't want to assign grads to
-        # value net params
+        if params is not None and target_params is None:
+            target_params = params.detach()
+        value_target = self.value_estimate(tensordict, target_params=target_params)
+        tensordict.set("advantage", value_target - value)
+        tensordict.set("value_target", value_target)
+        return tensordict
+
+    def value_estimate(
+        self,
+        tensordict,
+        target_params: Optional[TensorDictBase] = None,
+        **kwargs,
+    ):
+        reward = tensordict.get(("next", "reward"))
+        device = reward.device
+        gamma = self.gamma.to(device)
+        steps_to_next_obs = tensordict.get("steps_to_next_obs", None)
+        if steps_to_next_obs is not None:
+            gamma = gamma ** steps_to_next_obs.view_as(reward)
+
+        if self.average_rewards:
+            reward = reward - reward.mean()
+            reward = reward / reward.std().clamp_min(1e-4)
+            tensordict.set(
+                ("next", "reward"), reward
+            )  # we must update the rewards if they are used later in the code
         step_td = step_mdp(tensordict)
-        if target_params is not None:
-            # we assume that target parameters are not differentiable
-            kwargs["params"] = target_params
-        elif "params" in kwargs:
-            kwargs["params"] = kwargs["params"].detach()
-        with hold_out_net(self.value_network):
-            self.value_network(step_td, **kwargs)
-            next_value = step_td.get(self.value_key)
+        if self.value_network is not None:
+            if target_params is not None:
+                kwargs["params"] = target_params
+            with hold_out_net(self.value_network):
+                self.value_network(step_td, **kwargs)
+        next_value = step_td.get(self.value_key)
 
         done = tensordict.get(("next", "done"))
-        adv = td_advantage_estimate(gamma, value, next_value, reward, done)
-        tensordict.set("advantage", adv)
-        tensordict.set("value_target", adv + value)
-        return tensordict
+        value_target = vec_td1_return_estimate(
+            gamma, next_value, reward, done, time_dim=tensordict.ndim - 1
+        )
+        return value_target
 
 
-class TDLambdaEstimate(nn.Module):
-    """TD-Lambda estimate of advantage function.
+class TDLambdaEstimator(ValueEstimatorBase):
+    r"""TD(:math:`\lambda`) estimate of advantage function.
 
     Args:
         gamma (scalar): exponential mean discount.
         lmbda (scalar): trajectory discount.
-        value_network (SafeModule): value operator used to retrieve the value estimates.
-        average_rewards (bool, optional): if True, rewards will be standardized
+        value_network (TensorDictModule): value operator used to retrieve the value estimates.
+        average_rewards (bool, optional): if ``True``, rewards will be standardized
             before the TD is computed.
-        differentiable (bool, optional): if True, gradients are propagated throught
-            the computation of the value function. Default is :obj:`False`.
+        differentiable (bool, optional): if ``True``, gradients are propagated through
+            the computation of the value function. Default is ``False``.
+
+            .. note::
+              The proper way to make the function call non-differentiable is to
+              decorate it in a `torch.no_grad()` context manager/decorator or
+              pass detached parameters for functional modules.
+
         vectorized (bool, optional): whether to use the vectorized version of the
             lambda return. Default is `True`.
         advantage_key (str or tuple of str, optional): the key of the advantage entry.
             Defaults to "advantage".
         value_target_key (str or tuple of str, optional): the key of the advantage entry.
             Defaults to "value_target".
         value_key (str or tuple of str, optional): the value key to read from the input tensordict.
             Defaults to "state_value".
+        skip_existing (bool, optional): if ``True``, the value network will skip
+            modules which outputs are already present in the tensordict.
+            Defaults to ``None``, ie. the value of :func:`tensordict.nn.skip_existing()`
+            is not affected.
 
     """
 
     def __init__(
         self,
+        *,
         gamma: Union[float, torch.Tensor],
         lmbda: Union[float, torch.Tensor],
-        value_network: SafeModule,
+        value_network: TensorDictModule,
         average_rewards: bool = False,
         differentiable: bool = False,
         vectorized: bool = True,
         advantage_key: Union[str, Tuple] = "advantage",
         value_target_key: Union[str, Tuple] = "value_target",
         value_key: Union[str, Tuple] = "state_value",
+        skip_existing: Optional[bool] = None,
     ):
-        super().__init__()
+        super().__init__(
+            value_network=value_network,
+            differentiable=differentiable,
+            advantage_key=advantage_key,
+            value_target_key=value_target_key,
+            value_key=value_key,
+            skip_existing=skip_existing,
+        )
         try:
             device = next(value_network.parameters()).device
-        except StopIteration:
+        except (AttributeError, StopIteration):
             device = torch.device("cpu")
         self.register_buffer("gamma", torch.tensor(gamma, device=device))
         self.register_buffer("lmbda", torch.tensor(lmbda, device=device))
-        self.value_network = value_network
-        self.vectorized = vectorized
-
         self.average_rewards = average_rewards
-        self.differentiable = differentiable
-        self.value_key = value_key
-        if value_key not in value_network.out_keys:
-            raise KeyError(
-                f"value key '{value_key}' not found in value network out_keys."
-            )
-
-        self.advantage_key = advantage_key
-        self.value_target_key = value_target_key
-
-        self.in_keys = (
-            value_network.in_keys
-            + [("next", "reward"), ("next", "done")]
-            + [("next", in_key) for in_key in value_network.in_keys]
-        )
-        self.out_keys = [self.advantage_key, self.value_target_key]
-
-    @property
-    def is_functional(self):
-        return (
-            "_is_stateless" in self.value_network.__dict__
-            and self.value_network.__dict__["_is_stateless"]
-        )
+        self.vectorized = vectorized
 
+    @_self_set_skip_existing
     @_self_set_grad_enabled
     @dispatch
     def forward(
         self,
         tensordict: TensorDictBase,
         params: Optional[List[Tensor]] = None,
         target_params: Optional[List[Tensor]] = None,
     ) -> TensorDictBase:
-        """Computes the TDLambdaEstimate given the data in tensordict.
+        r"""Computes the TD(:math:`\lambda`) advantage given the data in tensordict.
 
         If a functional module is provided, a nested TensorDict containing the parameters
         (and if relevant the target parameters) can be passed to the module.
 
         Args:
             tensordict (TensorDictBase): A TensorDict containing the data
                 (an observation key, "action", ("next", "reward"), ("next", "done") and "next" tensordict state
@@ -293,177 +614,190 @@
                 target params to be passed to the functional value network module.
 
         Returns:
             An updated TensorDict with an advantage and a value_error keys as defined in the constructor.
 
         Examples:
             >>> from tensordict import TensorDict
-            >>> value_net = SafeModule(
+            >>> value_net = TensorDictModule(
             ...     nn.Linear(3, 1), in_keys=["obs"], out_keys=["state_value"]
             ... )
-            >>> module = TDLambdaEstimate(
+            >>> module = TDLambdaEstimator(
             ...     gamma=0.98,
             ...     lmbda=0.94,
             ...     value_network=value_net,
-            ...     differentiable=False,
             ... )
             >>> obs, next_obs = torch.randn(2, 1, 10, 3)
             >>> reward = torch.randn(1, 10, 1)
             >>> done = torch.zeros(1, 10, 1, dtype=torch.bool)
             >>> tensordict = TensorDict({"obs": obs, "next": {"obs": next_obs, "done": done, "reward": reward}}, [1, 10])
             >>> _ = module(tensordict)
             >>> assert "advantage" in tensordict.keys()
 
         The module supports non-tensordict (i.e. unpacked tensordict) inputs too:
 
         Examples:
-            >>> value_net = SafeModule(
+            >>> value_net = TensorDictModule(
             ...     nn.Linear(3, 1), in_keys=["obs"], out_keys=["state_value"]
             ... )
-            >>> module = TDLambdaEstimate(
+            >>> module = TDLambdaEstimator(
             ...     gamma=0.98,
             ...     lmbda=0.94,
             ...     value_network=value_net,
-            ...     differentiable=False,
             ... )
             >>> obs, next_obs = torch.randn(2, 1, 10, 3)
             >>> reward = torch.randn(1, 10, 1)
             >>> done = torch.zeros(1, 10, 1, dtype=torch.bool)
             >>> advantage, value_target = module(obs=obs, reward=reward, done=done, next_obs=next_obs)
 
         """
         if tensordict.batch_dims < 1:
             raise RuntimeError(
                 "Expected input tensordict to have at least one dimensions, got"
                 f"tensordict.batch_size = {tensordict.batch_size}"
             )
+        kwargs = {}
+        if self.is_stateless and params is None:
+            raise RuntimeError(
+                "Expected params to be passed to advantage module but got none."
+            )
+        if params is not None:
+            kwargs["params"] = params
+        if self.value_network is not None:
+            with hold_out_net(self.value_network):
+                self.value_network(tensordict, **kwargs)
+        value = tensordict.get(self.value_key)
+        if params is not None and target_params is None:
+            target_params = params.detach()
+        value_target = self.value_estimate(tensordict, target_params=target_params)
+
+        tensordict.set(self.advantage_key, value_target - value)
+        tensordict.set(self.value_target_key, value_target)
+        return tensordict
+
+    def value_estimate(
+        self,
+        tensordict,
+        target_params: Optional[TensorDictBase] = None,
+        **kwargs,
+    ):
         reward = tensordict.get(("next", "reward"))
+        device = reward.device
+        gamma = self.gamma.to(device)
+        steps_to_next_obs = tensordict.get("steps_to_next_obs", None)
+        if steps_to_next_obs is not None:
+            gamma = gamma ** steps_to_next_obs.view_as(reward)
+
+        lmbda = self.lmbda
         if self.average_rewards:
             reward = reward - reward.mean()
             reward = reward / reward.std().clamp_min(1e-4)
             tensordict.set(
                 ("next", "reward"), reward
             )  # we must update the rewards if they are used later in the code
 
-        gamma = self.gamma
-        lmbda = self.lmbda
-
-        kwargs = {}
-        if self.is_functional and params is None:
-            raise RuntimeError(
-                "Expected params to be passed to advantage module but got none."
-            )
-        if params is not None:
-            kwargs["params"] = params
-        with hold_out_net(self.value_network):
-            self.value_network(tensordict, **kwargs)
-            value = tensordict.get(self.value_key)
-
         step_td = step_mdp(tensordict)
-        if target_params is not None:
-            # we assume that target parameters are not differentiable
-            kwargs["params"] = target_params
-        elif "params" in kwargs:
-            kwargs["params"] = kwargs["params"].detach()
-        with hold_out_net(self.value_network):
-            # we may still need to pass gradient, but we don't want to assign grads to
-            # value net params
-            self.value_network(step_td, **kwargs)
-            next_value = step_td.get(self.value_key)
+        if self.value_network is not None:
+            if target_params is not None:
+                kwargs["params"] = target_params
+            with hold_out_net(self.value_network):
+                self.value_network(step_td, **kwargs)
+        next_value = step_td.get(self.value_key)
 
         done = tensordict.get(("next", "done"))
         if self.vectorized:
-            adv = vec_td_lambda_advantage_estimate(
-                gamma, lmbda, value, next_value, reward, done
+            val = vec_td_lambda_return_estimate(
+                gamma, lmbda, next_value, reward, done, time_dim=tensordict.ndim - 1
             )
         else:
-            adv = td_lambda_advantage_estimate(
-                gamma, lmbda, value, next_value, reward, done
+            val = td_lambda_return_estimate(
+                gamma, lmbda, next_value, reward, done, time_dim=tensordict.ndim - 1
             )
-
-        tensordict.set(self.advantage_key, adv)
-        tensordict.set(self.value_target_key, adv + value)
-        return tensordict
+        return val
 
 
-class GAE(nn.Module):
+class GAE(ValueEstimatorBase):
     """A class wrapper around the generalized advantage estimate functional.
 
     Refer to "HIGH-DIMENSIONAL CONTINUOUS CONTROL USING GENERALIZED ADVANTAGE ESTIMATION"
     https://arxiv.org/pdf/1506.02438.pdf for more context.
 
     Args:
         gamma (scalar): exponential mean discount.
         lmbda (scalar): trajectory discount.
-        value_network (SafeModule): value operator used to retrieve the value estimates.
-        average_gae (bool): if True, the resulting GAE values will be standardized.
-            Default is :obj:`False`.
-        differentiable (bool, optional): if True, gradients are propagated throught
-            the computation of the value function. Default is :obj:`False`.
+        value_network (TensorDictModule): value operator used to retrieve the value estimates.
+        average_gae (bool): if ``True``, the resulting GAE values will be standardized.
+            Default is ``False``.
+        differentiable (bool, optional): if ``True``, gradients are propagated through
+            the computation of the value function. Default is ``False``.
+
+            .. note::
+              The proper way to make the function call non-differentiable is to
+              decorate it in a `torch.no_grad()` context manager/decorator or
+              pass detached parameters for functional modules.
+
+        vectorized (bool, optional): whether to use the vectorized version of the
+            lambda return. Default is `True`.
         advantage_key (str or tuple of str, optional): the key of the advantage entry.
             Defaults to "advantage".
         value_target_key (str or tuple of str, optional): the key of the advantage entry.
             Defaults to "value_target".
         value_key (str or tuple of str, optional): the value key to read from the input tensordict.
             Defaults to "state_value".
+        skip_existing (bool, optional): if ``True``, the value network will skip
+            modules which outputs are already present in the tensordict.
+            Defaults to ``None``, ie. the value of :func:`tensordict.nn.skip_existing()`
+            is not affected.
 
     GAE will return an :obj:`"advantage"` entry containing the advange value. It will also
     return a :obj:`"value_target"` entry with the return value that is to be used
     to train the value network. Finally, if :obj:`gradient_mode` is :obj:`True`,
     an additional and differentiable :obj:`"value_error"` entry will be returned,
     which simple represents the difference between the return and the value network
     output (i.e. an additional distance loss should be applied to that signed value).
 
+    .. note::
+      As other advantage functions do, if the ``value_key`` is already present
+      in the input tensordict, the GAE module will ignore the calls to the value
+      network (if any) and use the provided value instead.
+
     """
 
     def __init__(
         self,
+        *,
         gamma: Union[float, torch.Tensor],
         lmbda: float,
-        value_network: SafeModule,
+        value_network: TensorDictModule,
         average_gae: bool = False,
         differentiable: bool = False,
+        vectorized: bool = True,
         advantage_key: Union[str, Tuple] = "advantage",
         value_target_key: Union[str, Tuple] = "value_target",
         value_key: Union[str, Tuple] = "state_value",
+        skip_existing: Optional[bool] = None,
     ):
-        super().__init__()
+        super().__init__(
+            value_network=value_network,
+            differentiable=differentiable,
+            advantage_key=advantage_key,
+            value_target_key=value_target_key,
+            value_key=value_key,
+            skip_existing=skip_existing,
+        )
         try:
             device = next(value_network.parameters()).device
-        except StopIteration:
+        except (AttributeError, StopIteration):
             device = torch.device("cpu")
         self.register_buffer("gamma", torch.tensor(gamma, device=device))
         self.register_buffer("lmbda", torch.tensor(lmbda, device=device))
-        self.value_network = value_network
-        self.value_key = value_key
-        if value_key not in value_network.out_keys:
-            raise KeyError(
-                f"value key '{value_key}' not found in value network out_keys."
-            )
-
         self.average_gae = average_gae
-        self.differentiable = differentiable
-
-        self.advantage_key = advantage_key
-        self.value_target_key = value_target_key
-
-        self.in_keys = (
-            value_network.in_keys
-            + [("next", "reward"), ("next", "done")]
-            + [("next", in_key) for in_key in value_network.in_keys]
-        )
-        self.out_keys = [self.advantage_key, self.value_target_key]
-
-    @property
-    def is_functional(self):
-        return (
-            "_is_stateless" in self.value_network.__dict__
-            and self.value_network.__dict__["_is_stateless"]
-        )
+        self.vectorized = vectorized
 
+    @_self_set_skip_existing
     @_self_set_grad_enabled
     @dispatch
     def forward(
         self,
         tensordict: TensorDictBase,
         *unused_args,
         params: Optional[List[Tensor]] = None,
@@ -486,15 +820,15 @@
                 target params to be passed to the functional value network module.
 
         Returns:
             An updated TensorDict with an advantage and a value_error keys as defined in the constructor.
 
         Examples:
             >>> from tensordict import TensorDict
-            >>> value_net = SafeModule(
+            >>> value_net = TensorDictModule(
             ...     nn.Linear(3, 1), in_keys=["obs"], out_keys=["state_value"]
             ... )
             >>> module = GAE(
             ...     gamma=0.98,
             ...     lmbda=0.94,
             ...     value_network=value_net,
             ...     differentiable=False,
@@ -505,15 +839,15 @@
             >>> tensordict = TensorDict({"obs": obs, "next": {"obs": next_obs}, "done": done, "reward": reward}, [1, 10])
             >>> _ = module(tensordict)
             >>> assert "advantage" in tensordict.keys()
 
         The module supports non-tensordict (i.e. unpacked tensordict) inputs too:
 
         Examples:
-            >>> value_net = SafeModule(
+            >>> value_net = TensorDictModule(
             ...     nn.Linear(3, 1), in_keys=["obs"], out_keys=["state_value"]
             ... )
             >>> module = GAE(
             ...     gamma=0.98,
             ...     lmbda=0.94,
             ...     value_network=value_net,
             ...     differentiable=False,
@@ -522,52 +856,147 @@
             >>> reward = torch.randn(1, 10, 1)
             >>> done = torch.zeros(1, 10, 1, dtype=torch.bool)
             >>> advantage, value_target = module(obs=obs, reward=reward, done=done, next_obs=next_obs)
 
         """
         if tensordict.batch_dims < 1:
             raise RuntimeError(
-                "Expected input tensordict to have at least one dimensions, got"
+                "Expected input tensordict to have at least one dimensions, got "
                 f"tensordict.batch_size = {tensordict.batch_size}"
             )
         reward = tensordict.get(("next", "reward"))
-        gamma, lmbda = self.gamma, self.lmbda
+        device = reward.device
+        gamma, lmbda = self.gamma.to(device), self.lmbda.to(device)
+        steps_to_next_obs = tensordict.get("steps_to_next_obs", None)
+        if steps_to_next_obs is not None:
+            gamma = gamma ** steps_to_next_obs.view_as(reward)
+
         kwargs = {}
-        if self.is_functional and params is None:
+        if self.is_stateless and params is None:
             raise RuntimeError(
                 "Expected params to be passed to advantage module but got none."
             )
         if params is not None:
             kwargs["params"] = params
-        with hold_out_net(self.value_network):
-            # we may still need to pass gradient, but we don't want to assign grads to
-            # value net params
-            self.value_network(tensordict, **kwargs)
+
+        if self.value_network is not None:
+            with hold_out_net(self.value_network):
+                # we may still need to pass gradient, but we don't want to assign grads to
+                # value net params
+                self.value_network(tensordict, **kwargs)
 
         value = tensordict.get(self.value_key)
 
         step_td = step_mdp(tensordict)
         if target_params is not None:
             # we assume that target parameters are not differentiable
             kwargs["params"] = target_params
         elif "params" in kwargs:
             kwargs["params"] = kwargs["params"].detach()
-        with hold_out_net(self.value_network):
-            # we may still need to pass gradient, but we don't want to assign grads to
-            # value net params
-            self.value_network(step_td, **kwargs)
+        if self.value_network is not None:
+            with hold_out_net(self.value_network):
+                # we may still need to pass gradient, but we don't want to assign grads to
+                # value net params
+                self.value_network(step_td, **kwargs)
         next_value = step_td.get(self.value_key)
         done = tensordict.get(("next", "done"))
-        adv, value_target = vec_generalized_advantage_estimate(
-            gamma, lmbda, value, next_value, reward, done
-        )
+        if self.vectorized:
+            adv, value_target = vec_generalized_advantage_estimate(
+                gamma,
+                lmbda,
+                value,
+                next_value,
+                reward,
+                done,
+                time_dim=tensordict.ndim - 1,
+            )
+        else:
+            adv, value_target = generalized_advantage_estimate(
+                gamma,
+                lmbda,
+                value,
+                next_value,
+                reward,
+                done,
+                time_dim=tensordict.ndim - 1,
+            )
 
         if self.average_gae:
             loc = adv.mean()
             scale = adv.std().clamp_min(1e-4)
             adv = adv - loc
             adv = adv / scale
 
         tensordict.set(self.advantage_key, adv)
         tensordict.set(self.value_target_key, value_target)
 
         return tensordict
+
+    def value_estimate(
+        self,
+        tensordict,
+        params: Optional[TensorDictBase] = None,
+        target_params: Optional[TensorDictBase] = None,
+        **kwargs,
+    ):
+        if tensordict.batch_dims < 1:
+            raise RuntimeError(
+                "Expected input tensordict to have at least one dimensions, got"
+                f"tensordict.batch_size = {tensordict.batch_size}"
+            )
+        reward = tensordict.get(("next", "reward"))
+        device = reward.device
+        gamma, lmbda = self.gamma.to(device), self.lmbda.to(device)
+        steps_to_next_obs = tensordict.get("steps_to_next_obs", None)
+        if steps_to_next_obs is not None:
+            gamma = gamma ** steps_to_next_obs.view_as(reward)
+
+        if self.is_stateless and params is None:
+            raise RuntimeError(
+                "Expected params to be passed to advantage module but got none."
+            )
+        if params is not None:
+            kwargs["params"] = params
+        if self.value_network is not None:
+            with hold_out_net(self.value_network):
+                # we may still need to pass gradient, but we don't want to assign grads to
+                # value net params
+                self.value_network(tensordict, **kwargs)
+
+        value = tensordict.get(self.value_key)
+
+        step_td = step_mdp(tensordict)
+        if target_params is not None:
+            # we assume that target parameters are not differentiable
+            kwargs["params"] = target_params
+        elif "params" in kwargs:
+            kwargs["params"] = kwargs["params"].detach()
+        if self.value_network is not None:
+            with hold_out_net(self.value_network):
+                # we may still need to pass gradient, but we don't want to assign grads to
+                # value net params
+                self.value_network(step_td, **kwargs)
+        next_value = step_td.get(self.value_key)
+        done = tensordict.get(("next", "done"))
+        _, value_target = vec_generalized_advantage_estimate(
+            gamma, lmbda, value, next_value, reward, done, time_dim=tensordict.ndim - 1
+        )
+        return value_target
+
+
+def _deprecate_class(cls, new_cls):
+    @wraps(cls.__init__)
+    def new_init(self, *args, **kwargs):
+        warnings.warn(f"class {cls} is deprecated, please use {new_cls} instead.")
+        cls.__init__(self, *args, **kwargs)
+
+    cls.__init__ = new_init
+
+
+TD0Estimate = type("TD0Estimate", TD0Estimator.__bases__, dict(TD0Estimator.__dict__))
+_deprecate_class(TD0Estimate, TD0Estimator)
+TD1Estimate = type("TD1Estimate", TD1Estimator.__bases__, dict(TD1Estimator.__dict__))
+_deprecate_class(TD1Estimate, TD1Estimator)
+TDLambdaEstimate = type(
+    "TDLambdaEstimate", TDLambdaEstimator.__bases__, dict(TDLambdaEstimator.__dict__)
+)
+_deprecate_class(TDLambdaEstimate, TDLambdaEstimator)
```

## torchrl/objectives/value/functional.py

```diff
@@ -1,65 +1,107 @@
 # Copyright (c) Meta Platforms, Inc. and affiliates.
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
-
+from functools import wraps
 from typing import Optional, Tuple
 
 import torch
+from tensordict import MemmapTensor, TensorDictBase
 
 __all__ = [
     "generalized_advantage_estimate",
     "vec_generalized_advantage_estimate",
-    "vec_td_lambda_return_estimate",
-    "vec_td_lambda_advantage_estimate",
+    "td0_advantage_estimate",
+    "td0_return_estimate",
+    "td1_return_estimate",
+    "vec_td1_return_estimate",
+    "td1_advantage_estimate",
+    "vec_td1_advantage_estimate",
     "td_lambda_return_estimate",
+    "vec_td_lambda_return_estimate",
     "td_lambda_advantage_estimate",
-    "td_advantage_estimate",
+    "vec_td_lambda_advantage_estimate",
 ]
 
 from torchrl.objectives.value.utils import _custom_conv1d, _make_gammas_tensor
 
 
+def _transpose_time(fun):
+    """Checks the time_dim argument of the function to allow for any dim.
+
+    If not -2, makes a transpose of all the multi-dim input tensors to bring
+    time at -2, and does the opposite transform for the outputs.
+    """
+
+    @wraps(fun)
+    def transposed_fun(*args, time_dim=-2, **kwargs):
+        def transpose_tensor(tensor):
+            if isinstance(tensor, (torch.Tensor, MemmapTensor)) and tensor.ndim >= 2:
+                tensor = tensor.transpose(time_dim, -2)
+            return tensor
+
+        if time_dim != -2:
+            args = [transpose_tensor(arg) for arg in args]
+            kwargs = {k: transpose_tensor(item) for k, item in kwargs.items()}
+            out = fun(*args, time_dim=-2, **kwargs)
+            if isinstance(out, torch.Tensor):
+                return transpose_tensor(out)
+            return tuple(transpose_tensor(_out) for _out in out)
+        return fun(*args, time_dim=time_dim, **kwargs)
+
+    return transposed_fun
+
+
+########################################################################
+# GAE
+# ---
+
+
+@_transpose_time
 def generalized_advantage_estimate(
     gamma: float,
     lmbda: float,
     state_value: torch.Tensor,
     next_state_value: torch.Tensor,
     reward: torch.Tensor,
     done: torch.Tensor,
+    time_dim: int = -2,
 ) -> Tuple[torch.Tensor, torch.Tensor]:
-    """Get generalized advantage estimate of a trajectory.
+    """Generalized advantage estimate of a trajectory.
 
     Refer to "HIGH-DIMENSIONAL CONTINUOUS CONTROL USING GENERALIZED ADVANTAGE ESTIMATION"
     https://arxiv.org/pdf/1506.02438.pdf for more context.
 
     Args:
         gamma (scalar): exponential mean discount.
         lmbda (scalar): trajectory discount.
         state_value (Tensor): value function result with old_state input.
-            must be a [Batch x TimeSteps x 1] or [Batch x TimeSteps] tensor
         next_state_value (Tensor): value function result with new_state input.
-            must be a [Batch x TimeSteps x 1] or [Batch x TimeSteps] tensor
         reward (Tensor): reward of taking actions in the environment.
-            must be a [Batch x TimeSteps x 1] or [Batch x TimeSteps] tensor
         done (Tensor): boolean flag for end of episode.
+        time_dim (int): dimension where the time is unrolled. Defaults to -2.
+
+    All tensors (values, reward and done) must have shape
+    ``[*Batch x TimeSteps x *F]``, with ``*F`` feature dimensions.
 
     """
-    for tensor in (next_state_value, state_value, reward, done):
-        if tensor.shape[-1] != 1:
-            raise RuntimeError(
-                "Last dimension of generalized_advantage_estimate inputs must be a singleton dimension."
-            )
+    if not (next_state_value.shape == state_value.shape == reward.shape == done.shape):
+        raise RuntimeError(
+            "All input tensors (value, reward and done states) must share a unique shape."
+        )
     dtype = next_state_value.dtype
     device = state_value.device
+    lastdim = next_state_value.shape[-1]
 
     not_done = 1 - done.to(dtype)
     *batch_size, time_steps = not_done.shape[:-1]
-    advantage = torch.empty(*batch_size, time_steps, 1, device=device, dtype=dtype)
+    advantage = torch.empty(
+        *batch_size, time_steps, lastdim, device=device, dtype=dtype
+    )
     prev_advantage = 0
     for t in reversed(range(time_steps)):
         delta = (
             reward[..., t, :]
             + (gamma * next_state_value[..., t, :] * not_done[..., t, :])
             - state_value[..., t, :]
         )
@@ -68,47 +110,49 @@
         )
 
     value_target = advantage + state_value
 
     return advantage, value_target
 
 
+@_transpose_time
 def vec_generalized_advantage_estimate(
     gamma: float,
     lmbda: float,
     state_value: torch.Tensor,
     next_state_value: torch.Tensor,
     reward: torch.Tensor,
     done: torch.Tensor,
+    time_dim: int = -2,
 ) -> Tuple[torch.Tensor, torch.Tensor]:
-    """Get generalized advantage estimate of a trajectory.
+    """Vectorized Generalized advantage estimate of a trajectory.
 
     Refer to "HIGH-DIMENSIONAL CONTINUOUS CONTROL USING GENERALIZED ADVANTAGE ESTIMATION"
     https://arxiv.org/pdf/1506.02438.pdf for more context.
 
     Args:
         gamma (scalar): exponential mean discount.
         lmbda (scalar): trajectory discount.
         state_value (Tensor): value function result with old_state input.
-            must be a [Batch x TimeSteps x 1] or [Batch x TimeSteps] tensor
         next_state_value (Tensor): value function result with new_state input.
-            must be a [Batch x TimeSteps x 1] or [Batch x TimeSteps] tensor
         reward (Tensor): reward of taking actions in the environment.
-            must be a [Batch x TimeSteps x 1] or [Batch x TimeSteps] tensor
         done (Tensor): boolean flag for end of episode.
+        time_dim (int): dimension where the time is unrolled. Defaults to -2.
+
+    All tensors (values, reward and done) must have shape
+    ``[*Batch x TimeSteps x *F]``, with ``*F`` feature dimensions.
 
     """
-    for tensor in (next_state_value, state_value, reward, done):
-        if tensor.shape[-1] != 1:
-            raise RuntimeError(
-                "Last dimension of generalized_advantage_estimate inputs must be a singleton dimension."
-            )
+    if not (next_state_value.shape == state_value.shape == reward.shape == done.shape):
+        raise RuntimeError(
+            "All input tensors (value, reward and done states) must share a unique shape."
+        )
     dtype = state_value.dtype
     not_done = 1 - done.to(dtype)
-    *batch_size, time_steps = not_done.shape[:-1]
+    *batch_size, time_steps, lastdim = not_done.shape
 
     value = gamma * lmbda
     if isinstance(value, torch.Tensor):
         # create tensor while ensuring that gradients are passed
         gammalmbdas = torch.ones_like(not_done) * not_done * value
     else:
         gammalmbdas = torch.full_like(not_done, value) * not_done
@@ -124,78 +168,122 @@
     td0 = reward + not_done * gamma * next_state_value - state_value
 
     if len(batch_size) > 1:
         td0 = td0.flatten(0, len(batch_size) - 1)
     elif not len(batch_size):
         td0 = td0.unsqueeze(0)
 
-    advantage = _custom_conv1d(td0.transpose(-2, -1), gammalmbdas)
+    td0_r = td0.transpose(-2, -1)
+    shapes = td0_r.shape[:2]
+    if lastdim != 1:
+        # then we flatten again the first dims and reset a singleton in between
+        td0_r = td0_r.flatten(0, 1).unsqueeze(1)
+    advantage = _custom_conv1d(td0_r, gammalmbdas)
+    if lastdim != 1:
+        advantage = advantage.squeeze(1).unflatten(0, shapes)
 
     if len(batch_size) > 1:
         advantage = advantage.unflatten(0, batch_size)
     elif not len(batch_size):
         advantage = advantage.squeeze(0)
 
     advantage = advantage.transpose(-2, -1)
     value_target = advantage + state_value
     return advantage, value_target
 
 
-def td_advantage_estimate(
+########################################################################
+# TD(0)
+# -----
+
+
+def td0_advantage_estimate(
     gamma: float,
     state_value: torch.Tensor,
     next_state_value: torch.Tensor,
     reward: torch.Tensor,
     done: torch.Tensor,
 ) -> Tuple[torch.Tensor, torch.Tensor]:
-    """Get generalized advantage estimate of a trajectory.
+    """TD(0) advantage estimate of a trajectory.
 
-    Refer to "HIGH-DIMENSIONAL CONTINUOUS CONTROL USING GENERALIZED ADVANTAGE ESTIMATION"
-    https://arxiv.org/pdf/1506.02438.pdf for more context.
+    Also known as bootstrapped Temporal Difference or one-step return.
 
     Args:
         gamma (scalar): exponential mean discount.
         state_value (Tensor): value function result with old_state input.
-            must be a [Batch x TimeSteps x 1] or [Batch x TimeSteps] tensor
+        next_state_value (Tensor): value function result with new_state input.
+        reward (Tensor): reward of taking actions in the environment.
+        done (Tensor): boolean flag for end of episode.
+
+    All tensors (values, reward and done) must have shape
+    ``[*Batch x TimeSteps x *F]``, with ``*F`` feature dimensions.
+
+    """
+    if not (next_state_value.shape == state_value.shape == reward.shape == done.shape):
+        raise RuntimeError(
+            "All input tensors (value, reward and done states) must share a unique shape."
+        )
+    returns = td0_return_estimate(gamma, next_state_value, reward, done)
+    advantage = returns - state_value
+    return advantage
+
+
+def td0_return_estimate(
+    gamma: float,
+    next_state_value: torch.Tensor,
+    reward: torch.Tensor,
+    done: torch.Tensor,
+) -> Tuple[torch.Tensor, torch.Tensor]:
+    """TD(0) discounted return estimate of a trajectory.
+
+    Also known as bootstrapped Temporal Difference or one-step return.
+
+    Args:
+        gamma (scalar): exponential mean discount.
         next_state_value (Tensor): value function result with new_state input.
             must be a [Batch x TimeSteps x 1] or [Batch x TimeSteps] tensor
         reward (Tensor): reward of taking actions in the environment.
             must be a [Batch x TimeSteps x 1] or [Batch x TimeSteps] tensor
         done (Tensor): boolean flag for end of episode.
 
+    All tensors (values, reward and done) must have shape
+    ``[*Batch x TimeSteps x *F]``, with ``*F`` feature dimensions.
+
     """
-    for tensor in (next_state_value, state_value, reward, done):
-        if tensor.shape[-1] != 1:
-            raise RuntimeError(
-                "Last dimension of generalized_advantage_estimate inputs must be a singleton dimension."
-            )
+    if not (next_state_value.shape == reward.shape == done.shape):
+        raise RuntimeError(
+            "All input tensors (value, reward and done states) must share a unique shape."
+        )
     not_done = 1 - done.to(next_state_value.dtype)
-    advantage = reward + gamma * not_done * next_state_value - state_value
+    advantage = reward + gamma * not_done * next_state_value
     return advantage
 
 
-def td_lambda_return_estimate(
+########################################################################
+# TD(1)
+# ----------
+
+
+@_transpose_time
+def td1_return_estimate(
     gamma: float,
-    lmbda: float,
     next_state_value: torch.Tensor,
     reward: torch.Tensor,
     done: torch.Tensor,
     rolling_gamma: bool = None,
+    time_dim: int = -2,
 ) -> torch.Tensor:
-    """TD(lambda) return estimate.
+    r"""TD(1) return estimate.
 
     Args:
         gamma (scalar): exponential mean discount.
-        lmbda (scalar): trajectory discount.
         next_state_value (Tensor): value function result with new_state input.
-            must be a [Batch x TimeSteps x 1] or [Batch x TimeSteps] tensor
         reward (Tensor): reward of taking actions in the environment.
-            must be a [Batch x TimeSteps x 1] or [Batch x TimeSteps] tensor
         done (Tensor): boolean flag for end of episode.
-        rolling_gamma (bool, optional): if True, it is assumed that each gamma
+        rolling_gamma (bool, optional): if ``True``, it is assumed that each gamma
             if a gamma tensor is tied to a single event:
               gamma = [g1, g2, g3, g4]
               value = [v1, v2, v3, v4]
               return = [
                 v1 + g1 v2 + g1 g2 v3 + g1 g2 g3 v4,
                 v2 + g2 v3 + g2 g3 v4,
                 v3 + g3 v4,
@@ -208,91 +296,77 @@
               return = [
                 v1 + g1 v2 + g1**2 v3 + g**3 v4,
                 v2 + g2 v3 + g2**2 v4,
                 v3 + g3 v4,
                 v4,
               ]
             Default is True.
+        time_dim (int): dimension where the time is unrolled. Defaults to -2.
+
+    All tensors (values, reward and done) must have shape
+    ``[*Batch x TimeSteps x *F]``, with ``*F`` feature dimensions.
 
     """
-    for tensor in (next_state_value, reward, done):
-        if tensor.shape[-1] != 1:
-            raise RuntimeError(
-                "Last dimension of generalized_advantage_estimate inputs must be a singleton dimension."
-            )
+    if not (next_state_value.shape == reward.shape == done.shape):
+        raise RuntimeError(
+            "All input tensors (value, reward and done states) must share a unique shape."
+        )
     not_done = 1 - done.to(next_state_value.dtype)
 
     returns = torch.empty_like(next_state_value)
 
     T = returns.shape[-2]
 
-    # if gamma is not a tensor of the same shape as other inputs, we use rolling_gamma = True
     single_gamma = False
     if not (isinstance(gamma, torch.Tensor) and gamma.shape == not_done.shape):
         single_gamma = True
         gamma = torch.full_like(next_state_value, gamma)
 
-    single_lambda = False
-    if not (isinstance(lmbda, torch.Tensor) and lmbda.shape == not_done.shape):
-        single_lambda = True
-        lmbda = torch.full_like(next_state_value, lmbda)
-
     if rolling_gamma is None:
         rolling_gamma = True
-    elif not rolling_gamma and single_gamma and single_lambda:
+    elif not rolling_gamma and single_gamma:
         raise RuntimeError(
-            "rolling_gamma=False is expected only with time-sensitive gamma or lambda values"
+            "rolling_gamma=False is expected only with time-sensitive gamma values"
         )
 
     if rolling_gamma:
         gamma = gamma * not_done
         g = next_state_value[..., -1, :]
         for i in reversed(range(T)):
-            g = returns[..., i, :] = reward[..., i, :] + gamma[..., i, :] * (
-                (1 - lmbda[..., i, :]) * next_state_value[..., i, :]
-                + lmbda[..., i, :] * g
-            )
+            g = returns[..., i, :] = reward[..., i, :] + gamma[..., i, :] * g
     else:
         for k in range(T):
             g = next_state_value[..., -1, :]
             _gamma = gamma[..., k, :]
-            _lambda = lmbda[..., k, :]
             nd = not_done
             _gamma = _gamma.unsqueeze(-2) * nd
             for i in reversed(range(k, T)):
-                g = reward[..., i, :] + _gamma[..., i, :] * (
-                    (1 - _lambda) * next_state_value[..., i, :] + _lambda * g
-                )
+                g = reward[..., i, :] + _gamma[..., i, :] * g
             returns[..., k, :] = g
-
     return returns
 
 
-def td_lambda_advantage_estimate(
+def td1_advantage_estimate(
     gamma: float,
-    lmbda: float,
     state_value: torch.Tensor,
     next_state_value: torch.Tensor,
     reward: torch.Tensor,
     done: torch.Tensor,
     rolling_gamma: bool = None,
+    time_dim: int = -2,
 ) -> torch.Tensor:
-    """TD(lambda) advantage estimate.
+    """TD(1) advantage estimate.
 
     Args:
         gamma (scalar): exponential mean discount.
-        lmbda (scalar): trajectory discount.
         state_value (Tensor): value function result with old_state input.
-            must be a [Batch x TimeSteps x 1] or [Batch x TimeSteps] tensor
         next_state_value (Tensor): value function result with new_state input.
-            must be a [Batch x TimeSteps x 1] or [Batch x TimeSteps] tensor
         reward (Tensor): reward of taking actions in the environment.
-            must be a [Batch x TimeSteps x 1] or [Batch x TimeSteps] tensor
         done (Tensor): boolean flag for end of episode.
-        rolling_gamma (bool, optional): if True, it is assumed that each gamma
+        rolling_gamma (bool, optional): if ``True``, it is assumed that each gamma
             if a gamma tensor is tied to a single event:
               gamma = [g1, g2, g3, g4]
               value = [v1, v2, v3, v4]
               return = [
                 v1 + g1 v2 + g1 g2 v3 + g1 g2 g3 v4,
                 v2 + g2 v3 + g2 g3 v4,
                 v3 + g3 v4,
@@ -305,48 +379,105 @@
               return = [
                 v1 + g1 v2 + g1**2 v3 + g**3 v4,
                 v2 + g2 v3 + g2**2 v4,
                 v3 + g3 v4,
                 v4,
               ]
             Default is True.
+        time_dim (int): dimension where the time is unrolled. Defaults to -2.
+
+    All tensors (values, reward and done) must have shape
+    ``[*Batch x TimeSteps x *F]``, with ``*F`` feature dimensions.
 
     """
+    if not (next_state_value.shape == state_value.shape == reward.shape == done.shape):
+        raise RuntimeError(
+            "All input tensors (value, reward and done states) must share a unique shape."
+        )
     if not state_value.shape == next_state_value.shape:
         raise RuntimeError("shape of state_value and next_state_value must match")
-    returns = td_lambda_return_estimate(
-        gamma, lmbda, next_state_value, reward, done, rolling_gamma
+    returns = td1_return_estimate(
+        gamma, next_state_value, reward, done, rolling_gamma, time_dim=time_dim
     )
     advantage = returns - state_value
     return advantage
 
 
-def vec_td_lambda_advantage_estimate(
+@_transpose_time
+def vec_td1_return_estimate(
+    gamma,
+    next_state_value,
+    reward,
+    done,
+    rolling_gamma: Optional[bool] = None,
+    time_dim: int = -2,
+):
+    """Vectorized TD(1) return estimate.
+
+    Args:
+        gamma (scalar, Tensor): exponential mean discount. If tensor-valued,
+        next_state_value (Tensor): value function result with new_state input.
+        reward (Tensor): reward of taking actions in the environment.
+        done (Tensor): boolean flag for end of episode.
+        rolling_gamma (bool, optional): if ``True``, it is assumed that each gamma
+            if a gamma tensor is tied to a single event:
+              gamma = [g1, g2, g3, g4]
+              value = [v1, v2, v3, v4]
+              return = [
+                v1 + g1 v2 + g1 g2 v3 + g1 g2 g3 v4,
+                v2 + g2 v3 + g2 g3 v4,
+                v3 + g3 v4,
+                v4,
+              ]
+            if False, it is assumed that each gamma is tied to the upcoming
+            trajectory:
+              gamma = [g1, g2, g3, g4]
+              value = [v1, v2, v3, v4]
+              return = [
+                v1 + g1 v2 + g1**2 v3 + g**3 v4,
+                v2 + g2 v3 + g2**2 v4,
+                v3 + g3 v4,
+                v4,
+              ]
+            Default is True.
+        time_dim (int): dimension where the time is unrolled. Defaults to -2.
+
+    All tensors (values, reward and done) must have shape
+    ``[*Batch x TimeSteps x *F]``, with ``*F`` feature dimensions.
+
+    """
+    return vec_td_lambda_return_estimate(
+        gamma=gamma,
+        next_state_value=next_state_value,
+        reward=reward,
+        done=done,
+        rolling_gamma=rolling_gamma,
+        lmbda=1,
+        time_dim=time_dim,
+    )
+
+
+def vec_td1_advantage_estimate(
     gamma,
-    lmbda,
     state_value,
     next_state_value,
     reward,
     done,
     rolling_gamma: bool = None,
+    time_dim: int = -2,
 ):
-    """Vectorized TD(lambda) advantage estimate.
+    """Vectorized TD(1) advantage estimate.
 
     Args:
         gamma (scalar, Tensor): exponential mean discount. If tensor-valued,
-            must be a [Batch x TimeSteps x 1] tensor.
-        lmbda (scalar): trajectory discount.
         state_value (Tensor): value function result with old_state input.
-            must be a [Batch x TimeSteps x 1] or [Batch x TimeSteps] tensor
         next_state_value (Tensor): value function result with new_state input.
-            must be a [Batch x TimeSteps x 1] or [Batch x TimeSteps] tensor
         reward (Tensor): reward of taking actions in the environment.
-            must be a [Batch x TimeSteps x 1] or [Batch x TimeSteps] tensor
         done (Tensor): boolean flag for end of episode.
-        rolling_gamma (bool, optional): if True, it is assumed that each gamma
+        rolling_gamma (bool, optional): if ``True``, it is assumed that each gamma
             if a gamma tensor is tied to a single event:
               gamma = [g1, g2, g3, g4]
               value = [v1, v2, v3, v4]
               return = [
                 v1 + g1 v2 + g1 g2 v3 + g1 g2 g3 v4,
                 v2 + g2 v3 + g2 g3 v4,
                 v3 + g3 v4,
@@ -359,39 +490,216 @@
               return = [
                 v1 + g1 v2 + g1**2 v3 + g**3 v4,
                 v2 + g2 v3 + g2**2 v4,
                 v3 + g3 v4,
                 v4,
               ]
             Default is True.
+        time_dim (int): dimension where the time is unrolled. Defaults to -2.
+
+    All tensors (values, reward and done) must have shape
+    ``[*Batch x TimeSteps x *F]``, with ``*F`` feature dimensions.
 
     """
+    if not (next_state_value.shape == state_value.shape == reward.shape == done.shape):
+        raise RuntimeError(
+            "All input tensors (value, reward and done states) must share a unique shape."
+        )
     return (
-        vec_td_lambda_return_estimate(
-            gamma, lmbda, next_state_value, reward, done, rolling_gamma
+        vec_td1_return_estimate(
+            gamma, next_state_value, reward, done, rolling_gamma, time_dim=time_dim
         )
         - state_value
     )
 
 
+########################################################################
+# TD(lambda)
+# ----------
+
+
+@_transpose_time
+def td_lambda_return_estimate(
+    gamma: float,
+    lmbda: float,
+    next_state_value: torch.Tensor,
+    reward: torch.Tensor,
+    done: torch.Tensor,
+    rolling_gamma: bool = None,
+    time_dim: int = -2,
+) -> torch.Tensor:
+    r"""TD(:math:`\lambda`) return estimate.
+
+    Args:
+        gamma (scalar): exponential mean discount.
+        lmbda (scalar): trajectory discount.
+        next_state_value (Tensor): value function result with new_state input.
+        reward (Tensor): reward of taking actions in the environment.
+        done (Tensor): boolean flag for end of episode.
+        rolling_gamma (bool, optional): if ``True``, it is assumed that each gamma
+            if a gamma tensor is tied to a single event:
+              gamma = [g1, g2, g3, g4]
+              value = [v1, v2, v3, v4]
+              return = [
+                v1 + g1 v2 + g1 g2 v3 + g1 g2 g3 v4,
+                v2 + g2 v3 + g2 g3 v4,
+                v3 + g3 v4,
+                v4,
+              ]
+            if False, it is assumed that each gamma is tied to the upcoming
+            trajectory:
+              gamma = [g1, g2, g3, g4]
+              value = [v1, v2, v3, v4]
+              return = [
+                v1 + g1 v2 + g1**2 v3 + g**3 v4,
+                v2 + g2 v3 + g2**2 v4,
+                v3 + g3 v4,
+                v4,
+              ]
+            Default is True.
+        time_dim (int): dimension where the time is unrolled. Defaults to -2.
+
+    All tensors (values, reward and done) must have shape
+    ``[*Batch x TimeSteps x *F]``, with ``*F`` feature dimensions.
+
+    """
+    if not (next_state_value.shape == reward.shape == done.shape):
+        raise RuntimeError(
+            "All input tensors (value, reward and done states) must share a unique shape."
+        )
+
+    not_done = 1 - done.to(next_state_value.dtype)
+
+    returns = torch.empty_like(next_state_value)
+
+    *batch, T, lastdim = returns.shape
+
+    # if gamma is not a tensor of the same shape as other inputs, we use rolling_gamma = True
+    single_gamma = False
+    if not (isinstance(gamma, torch.Tensor) and gamma.shape == not_done.shape):
+        single_gamma = True
+        gamma = torch.full_like(next_state_value, gamma)
+
+    single_lambda = False
+    if not (isinstance(lmbda, torch.Tensor) and lmbda.shape == not_done.shape):
+        single_lambda = True
+        lmbda = torch.full_like(next_state_value, lmbda)
+
+    if rolling_gamma is None:
+        rolling_gamma = True
+    elif not rolling_gamma and single_gamma and single_lambda:
+        raise RuntimeError(
+            "rolling_gamma=False is expected only with time-sensitive gamma or lambda values"
+        )
+
+    if rolling_gamma:
+        gamma = gamma * not_done
+        g = next_state_value[..., -1, :]
+        for i in reversed(range(T)):
+            g = returns[..., i, :] = reward[..., i, :] + gamma[..., i, :] * (
+                (1 - lmbda[..., i, :]) * next_state_value[..., i, :]
+                + lmbda[..., i, :] * g
+            )
+    else:
+        for k in range(T):
+            g = next_state_value[..., -1, :]
+            _gamma = gamma[..., k, :]
+            _lambda = lmbda[..., k, :]
+            nd = not_done
+            _gamma = _gamma.unsqueeze(-2) * nd
+            for i in reversed(range(k, T)):
+                g = reward[..., i, :] + _gamma[..., i, :] * (
+                    (1 - _lambda) * next_state_value[..., i, :] + _lambda * g
+                )
+            returns[..., k, :] = g
+
+    return returns
+
+
+def td_lambda_advantage_estimate(
+    gamma: float,
+    lmbda: float,
+    state_value: torch.Tensor,
+    next_state_value: torch.Tensor,
+    reward: torch.Tensor,
+    done: torch.Tensor,
+    rolling_gamma: bool = None,
+    time_dim: int = -2,
+) -> torch.Tensor:
+    r"""TD(:math:`\lambda`) advantage estimate.
+
+    Args:
+        gamma (scalar): exponential mean discount.
+        lmbda (scalar): trajectory discount.
+        state_value (Tensor): value function result with old_state input.
+        next_state_value (Tensor): value function result with new_state input.
+        reward (Tensor): reward of taking actions in the environment.
+        done (Tensor): boolean flag for end of episode.
+        rolling_gamma (bool, optional): if ``True``, it is assumed that each gamma
+            if a gamma tensor is tied to a single event:
+              gamma = [g1, g2, g3, g4]
+              value = [v1, v2, v3, v4]
+              return = [
+                v1 + g1 v2 + g1 g2 v3 + g1 g2 g3 v4,
+                v2 + g2 v3 + g2 g3 v4,
+                v3 + g3 v4,
+                v4,
+              ]
+            if False, it is assumed that each gamma is tied to the upcoming
+            trajectory:
+              gamma = [g1, g2, g3, g4]
+              value = [v1, v2, v3, v4]
+              return = [
+                v1 + g1 v2 + g1**2 v3 + g**3 v4,
+                v2 + g2 v3 + g2**2 v4,
+                v3 + g3 v4,
+                v4,
+              ]
+            Default is True.
+        time_dim (int): dimension where the time is unrolled. Defaults to -2.
+
+    All tensors (values, reward and done) must have shape
+    ``[*Batch x TimeSteps x *F]``, with ``*F`` feature dimensions.
+
+    """
+    if not (next_state_value.shape == state_value.shape == reward.shape == done.shape):
+        raise RuntimeError(
+            "All input tensors (value, reward and done states) must share a unique shape."
+        )
+    if not state_value.shape == next_state_value.shape:
+        raise RuntimeError("shape of state_value and next_state_value must match")
+    returns = td_lambda_return_estimate(
+        gamma, lmbda, next_state_value, reward, done, rolling_gamma, time_dim=time_dim
+    )
+    advantage = returns - state_value
+    return advantage
+
+
+@_transpose_time
 def vec_td_lambda_return_estimate(
-    gamma, lmbda, next_state_value, reward, done, rolling_gamma: Optional[bool] = None
+    gamma,
+    lmbda,
+    next_state_value,
+    reward,
+    done,
+    rolling_gamma: Optional[bool] = None,
+    time_dim: int = -2,
 ):
-    """Vectorized TD(lambda) return estimate.
+    r"""Vectorized TD(:math:`\lambda`) return estimate.
 
     Args:
         gamma (scalar, Tensor): exponential mean discount. If tensor-valued,
             must be a [Batch x TimeSteps x 1] tensor.
         lmbda (scalar): trajectory discount.
         next_state_value (Tensor): value function result with new_state input.
             must be a [Batch x TimeSteps x 1] tensor
         reward (Tensor): reward of taking actions in the environment.
             must be a [Batch x TimeSteps x 1] or [Batch x TimeSteps] tensor
         done (Tensor): boolean flag for end of episode.
-        rolling_gamma (bool, optional): if True, it is assumed that each gamma
+        rolling_gamma (bool, optional): if ``True``, it is assumed that each gamma
             if a gamma tensor is tied to a single event:
               gamma = [g1, g2, g3, g4]
               value = [v1, v2, v3, v4]
               return = [
                 v1 + g1 v2 + g1 g2 v3 + g1 g2 g3 v4,
                 v2 + g2 v3 + g2 g3 v4,
                 v3 + g3 v4,
@@ -404,24 +712,35 @@
               return = [
                 v1 + g1 v2 + g1**2 v3 + g**3 v4,
                 v2 + g2 v3 + g2**2 v4,
                 v3 + g3 v4,
                 v4,
               ]
             Default is True.
+        time_dim (int): dimension where the time is unrolled. Defaults to -2.
+
+    All tensors (values, reward and done) must have shape
+    ``[*Batch x TimeSteps x *F]``, with ``*F`` feature dimensions.
 
     """
+    if not (next_state_value.shape == reward.shape == done.shape):
+        raise RuntimeError(
+            "All input tensors (value, reward and done states) must share a unique shape."
+        )
     shape = next_state_value.shape
-    if not shape[-1] == 1:
-        raise RuntimeError("last dimension of inputs shape must be singleton")
 
-    T = shape[-2]
+    *batch, T, lastdim = shape
 
-    next_state_value = next_state_value.view(-1, 1, T)
-    reward = reward.view(-1, 1, T)
+    next_state_value = next_state_value.transpose(-2, -1).unsqueeze(-2)
+    if len(batch):
+        next_state_value = next_state_value.flatten(0, len(batch))
+
+    reward = reward.transpose(-2, -1).unsqueeze(-2)
+    if len(batch):
+        reward = reward.flatten(0, len(batch))
 
     """Vectorized version of td_lambda_advantage_estimate"""
     device = reward.device
     not_done = 1 - done.to(next_state_value.dtype)
 
     first_below_thr_gamma = None
 
@@ -489,15 +808,15 @@
         if lambdas.ndimension() == 4 and lambdas.shape[1] > 1:
             lambdas = lambdas[:, :1]
         v3 = (gammas * lambdas).squeeze(-1) * next_state_value
         v3[..., :-1] = 0
         out = _custom_conv1d(
             reward + (gammas * (1 - lambdas)).squeeze(-1) * next_state_value + v3, dec
         )
-        return out.view(shape)
+        return out.view(*batch, lastdim, T).transpose(-2, -1)
     else:
         v1 = _custom_conv1d(reward, dec)
 
         if gammas.ndimension() == 4 and gammas.shape[1] > 1:
             gammas = gammas[:, :, :1].transpose(1, 2)
         if lambdas.ndimension() == 4 and lambdas.shape[1] > 1:
             lambdas = lambdas[:, :, :1].transpose(1, 2)
@@ -505,8 +824,314 @@
         v2 = _custom_conv1d(
             next_state_value * not_done.view_as(next_state_value),
             dec * (gammas * (1 - lambdas)).transpose(1, 2),
         )
         v3 = next_state_value * not_done.view_as(next_state_value)
         v3[..., :-1] = 0
         v3 = _custom_conv1d(v3, dec * (gammas * lambdas).transpose(1, 2))
-        return (v1 + v2 + v3).view(shape)
+        return (v1 + v2 + v3).view(*batch, lastdim, T).transpose(-2, -1)
+
+
+def vec_td_lambda_advantage_estimate(
+    gamma,
+    lmbda,
+    state_value,
+    next_state_value,
+    reward,
+    done,
+    rolling_gamma: bool = None,
+    time_dim: int = -2,
+):
+    r"""Vectorized TD(:math:`\lambda`) advantage estimate.
+
+    Args:
+        gamma (scalar, Tensor): exponential mean discount. If tensor-valued,
+        lmbda (scalar): trajectory discount.
+        state_value (Tensor): value function result with old_state input.
+        next_state_value (Tensor): value function result with new_state input.
+        reward (Tensor): reward of taking actions in the environment.
+        done (Tensor): boolean flag for end of episode.
+        rolling_gamma (bool, optional): if ``True``, it is assumed that each gamma
+            if a gamma tensor is tied to a single event:
+              gamma = [g1, g2, g3, g4]
+              value = [v1, v2, v3, v4]
+              return = [
+                v1 + g1 v2 + g1 g2 v3 + g1 g2 g3 v4,
+                v2 + g2 v3 + g2 g3 v4,
+                v3 + g3 v4,
+                v4,
+              ]
+            if False, it is assumed that each gamma is tied to the upcoming
+            trajectory:
+              gamma = [g1, g2, g3, g4]
+              value = [v1, v2, v3, v4]
+              return = [
+                v1 + g1 v2 + g1**2 v3 + g**3 v4,
+                v2 + g2 v3 + g2**2 v4,
+                v3 + g3 v4,
+                v4,
+              ]
+            Default is True.
+        time_dim (int): dimension where the time is unrolled. Defaults to -2.
+
+    All tensors (values, reward and done) must have shape
+    ``[*Batch x TimeSteps x *F]``, with ``*F`` feature dimensions.
+
+    """
+    if not (next_state_value.shape == state_value.shape == reward.shape == done.shape):
+        raise RuntimeError(
+            "All input tensors (value, reward and done states) must share a unique shape."
+        )
+    return (
+        vec_td_lambda_return_estimate(
+            gamma,
+            lmbda,
+            next_state_value,
+            reward,
+            done,
+            rolling_gamma,
+            time_dim=time_dim,
+        )
+        - state_value
+    )
+
+
+########################################################################
+# Reward to go
+# ------------
+
+
+def _flatten_batch(tensor):
+    """Because we mark the end of each batch with a truncated signal, we can concatenate them.
+
+    Args:
+        tensor (torch.Tensor): a tensor of shape [B, T]
+    """
+    return tensor.flatten(0, 1)
+
+
+def _get_num_per_traj(dones_and_truncated):
+    """Because we mark the end of each batch with a truncated signal, we can concatenate them.
+
+    Args:
+        dones_and_truncated (torch.Tensor): A done or truncated mark of shape [B, T]
+
+    Returns:
+        A list of integers representing the number of steps in each trajectories
+    """
+    dones_and_truncated = dones_and_truncated.clone()
+    dones_and_truncated[..., -1] = 1
+    dones_and_truncated = _flatten_batch(dones_and_truncated)
+    num_per_traj = torch.ones_like(dones_and_truncated).cumsum(0)[dones_and_truncated]
+    num_per_traj[1:] -= num_per_traj[:-1].clone()
+    return num_per_traj
+
+
+def _get_num_per_traj_init(is_init):
+    """Like _get_num_per_traj, but with is_init signal."""
+    done = torch.zeros_like(is_init)
+    done[..., :-1][is_init[..., 1:]] = 1
+    return _get_num_per_traj(done)
+
+
+def _split_and_pad_sequence(tensor, splits):
+    """Given a tensor of size [B, T, *other] and the corresponding traj lengths (flattened), returns the padded trajectories [NPad, Tmax, *other].
+
+    Compatible with tensordict inputs.
+
+    Examples:
+        >>> from tensordict import TensorDict
+        >>> is_init = torch.zeros(4, 5, dtype=torch.bool)
+        >>> is_init[:, 0] = True
+        >>> is_init[0, 3] = True
+        >>> is_init[1, 2] = True
+        >>> tensordict = TensorDict({
+        ...     "is_init": is_init,
+        ...     "obs": torch.arange(20).view(4, 5).unsqueeze(-1).expand(4, 5, 3),
+        ... }, [4, 5])
+        >>> splits = _get_num_per_traj_init(is_init)
+        >>> print(splits)
+        tensor([3, 2, 2, 3, 5, 5])
+        >>> td = _split_and_pad_sequence(tensordict, splits)
+        >>> print(td)
+        TensorDict(
+            fields={
+                is_init: Tensor(shape=torch.Size([6, 5]), device=cpu, dtype=torch.bool, is_shared=False),
+                obs: Tensor(shape=torch.Size([6, 5, 3]), device=cpu, dtype=torch.int64, is_shared=False)},
+            batch_size=torch.Size([6, 5]),
+            device=None,
+            is_shared=False)
+        >>> print(td["obs"])
+        tensor([[[ 0,  0,  0],
+                 [ 1,  1,  1],
+                 [ 2,  2,  2],
+                 [ 0,  0,  0],
+                 [ 0,  0,  0]],
+        <BLANKLINE>
+                [[ 3,  3,  3],
+                 [ 4,  4,  4],
+                 [ 0,  0,  0],
+                 [ 0,  0,  0],
+                 [ 0,  0,  0]],
+        <BLANKLINE>
+                [[ 5,  5,  5],
+                 [ 6,  6,  6],
+                 [ 0,  0,  0],
+                 [ 0,  0,  0],
+                 [ 0,  0,  0]],
+        <BLANKLINE>
+                [[ 7,  7,  7],
+                 [ 8,  8,  8],
+                 [ 9,  9,  9],
+                 [ 0,  0,  0],
+                 [ 0,  0,  0]],
+        <BLANKLINE>
+                [[10, 10, 10],
+                 [11, 11, 11],
+                 [12, 12, 12],
+                 [13, 13, 13],
+                 [14, 14, 14]],
+        <BLANKLINE>
+                [[15, 15, 15],
+                 [16, 16, 16],
+                 [17, 17, 17],
+                 [18, 18, 18],
+                 [19, 19, 19]]])
+
+    """
+    tensor = _flatten_batch(tensor)
+    max_val = max(splits)
+    mask = torch.zeros(len(splits), max_val, dtype=torch.bool, device=tensor.device)
+    mask.scatter_(
+        index=max_val - torch.tensor(splits, device=tensor.device).unsqueeze(-1),
+        dim=1,
+        value=1,
+    )
+    mask = mask.cumsum(-1).flip(-1).bool()
+
+    def _fill_tensor(tensor):
+        empty_tensor = torch.zeros(
+            len(splits),
+            max_val,
+            *tensor.shape[1:],
+            dtype=tensor.dtype,
+            device=tensor.device,
+        )
+        empty_tensor[mask] = tensor
+        return empty_tensor
+
+    if isinstance(tensor, TensorDictBase):
+        tensor = tensor.apply(_fill_tensor, batch_size=[len(splits), max_val])
+    else:
+        tensor = _fill_tensor(tensor)
+    return tensor
+
+
+def _inv_pad_sequence(tensor, splits):
+    """Inverses a pad_sequence operation.
+
+    Examples:
+        >>> rewards = torch.randn(100, 20)
+        >>> num_per_traj = _get_num_per_traj(torch.zeros(100, 20).bernoulli_(0.1))
+        >>> padded = _split_and_pad_sequence(rewards, num_per_traj.tolist())
+        >>> reconstructed = _inv_pad_sequence(padded, num_per_traj)
+        >>> assert (reconstructed==rewards).all()
+
+
+    Compatible with tensordict inputs.
+
+    Examples:
+        >>> from tensordict import TensorDict
+        >>> is_init = torch.zeros(4, 5, dtype=torch.bool)
+        >>> is_init[:, 0] = True
+        >>> is_init[0, 3] = True
+        >>> is_init[1, 2] = True
+        >>> tensordict = TensorDict({
+        ...     "is_init": is_init,
+        ...     "obs": torch.arange(20).view(4, 5).unsqueeze(-1).expand(4, 5, 3),
+        ... }, [4, 5])
+        >>> splits = _get_num_per_traj_init(is_init)
+        >>> td = _split_and_pad_sequence(tensordict, splits)
+        >>> assert (_inv_pad_sequence(td, splits).view(tensordict.shape) == tensordict).all()
+
+    """
+    offset = torch.ones_like(splits) * tensor.shape[-1]
+    offset[0] = 0
+    offset = offset.cumsum(0)
+    z = torch.zeros(tensor.numel(), dtype=torch.bool, device=offset.device)
+
+    ones = offset + splits
+    ones = ones[ones < tensor.numel()]
+    # while ones[-1] == tensor.numel():
+    #     ones = ones[:-1]
+    z[ones] = 1
+    z_idx = z[offset[1:]]
+    z[offset[1:]] = torch.bitwise_xor(
+        z_idx, torch.ones_like(z_idx)
+    )  # make sure that the longest is accounted for
+    idx = z.cumsum(0) % 2 == 0
+    return tensor.reshape(-1)[idx]
+
+
+@_transpose_time
+def reward2go(
+    reward,
+    done,
+    gamma,
+    time_dim: int = -2,
+):
+    """Compute the discounted cumulative sum of rewards given multiple trajectories and the episode ends.
+
+    Args:
+        reward (torch.Tensor): A tensor containing the rewards
+            received at each time step over multiple trajectories.
+        done (torch.Tensor): A tensor with done (or truncated) states.
+        gamma (float, optional): The discount factor to use for computing the
+            discounted cumulative sum of rewards. Defaults to 1.0.
+        time_dim (int): dimension where the time is unrolled. Defaults to -2.
+
+    Returns:
+        torch.Tensor: A tensor of shape [B, T] containing the discounted cumulative
+            sum of rewards (reward-to-go) at each time step.
+
+    Examples:
+        >>> reward = torch.ones(1, 10)
+        >>> done = torch.zeros(1, 10, dtype=torch.bool)
+        >>> done[:, [3, 7]] = True
+        >>> reward2go(reward, done, 0.99, time_dim=-1)
+        tensor([[3.9404],
+                [2.9701],
+                [1.9900],
+                [1.0000],
+                [3.9404],
+                [2.9701],
+                [1.9900],
+                [1.0000],
+                [1.9900],
+                [1.0000]])
+
+    """
+    shape = reward.shape
+    if shape != done.shape:
+        raise ValueError(
+            f"reward and done must share the same shape, got {reward.shape} and {done.shape}"
+        )
+    # place time at dim -1
+    reward = reward.transpose(-2, -1)
+    done = done.transpose(-2, -1)
+    # flatten if needed
+    if reward.ndim > 2:
+        reward = reward.flatten(0, -2)
+        done = done.flatten(0, -2)
+
+    num_per_traj = _get_num_per_traj(done)
+    td0_flat = _split_and_pad_sequence(reward, num_per_traj)
+    gammas = torch.ones_like(td0_flat[0])
+    gammas[1:] = gamma
+    gammas[1:] = gammas[1:].cumprod(0)
+    gammas = gammas.unsqueeze(-1)
+    cumsum = _custom_conv1d(td0_flat.unsqueeze(1), gammas)
+    cumsum = _inv_pad_sequence(cumsum, num_per_traj)
+    cumsum = cumsum.view_as(reward)
+    if cumsum.shape != shape:
+        cumsum = cumsum.view(shape)
+    return cumsum
```

## torchrl/objectives/value/utils.py

```diff
@@ -130,33 +130,34 @@
     else:
         raise NotImplementedError(f"dim {dim} is not supported.")
 
 
 def _make_gammas_tensor(gamma: torch.Tensor, T: int, rolling_gamma: bool):
     """Prepares a decay tensor for a matrix multiplication.
 
-    Given a tensor gamma of size [*batch, T, 1],
-    it will return a new tensor with size [*batch, T, T+1, 1].
+    Given a tensor gamma of size [*batch, T, D],
+    it will return a new tensor with size [*batch, T, T+1, D].
     In the rolling_gamma case, a rolling of the gamma values will be performed
     along the T axis, e.g.:
     [[ 1, g1, g2, g3],
     [ 1, g2, g3, 0],
     [ 1, g3, 0, 0]]
 
     Args:
         gamma (torch.tensor): the gamma tensor to be prepared.
         T (int): the time length
-        rolling_gamma (bool): if True, the gamma value is set for each step
+        rolling_gamma (bool): if ``True``, the gamma value is set for each step
             independently. If False, the gamma value at (i, t) will be used for the
             trajectory following (i, t).
 
     Returns: the prepared gamma decay tensor
 
     """
     # some reshaping code vendored from vec_td_lambda_return_estimate
+    gamma = gamma.transpose(-2, -1).contiguous()
     gamma = gamma.view(-1, T)
     dtype = gamma.dtype
     device = gamma.device
     if rolling_gamma:
         # # loop
         # gammas = gamma.unsqueeze(-2).expand(gamma.shape[0], T, T).contiguous()
         # for i in range(1, T):
```

## torchrl/record/recorder.py

```diff
@@ -30,15 +30,15 @@
             should be written.
         tag (str): the video tag in the logger.
         in_keys (Sequence[str], optional): keys to be read to produce the video.
             Default is :obj:`"pixels"`.
         skip (int): frame interval in the output video.
             Default is 2.
         center_crop (int, optional): value of square center crop.
-        make_grid (bool, optional): if True, a grid is created assuming that a
+        make_grid (bool, optional): if ``True``, a grid is created assuming that a
             tensor of shape [B x W x H x 3] is provided, with B being the batch
             size. Default is True.
 
     """
 
     def __init__(
         self,
@@ -134,15 +134,15 @@
     """TensorDict recorder.
 
     When the 'dump' method is called, this class will save a stack of the tensordict resulting from :obj:`env.step(td)` in a
     file with a prefix defined by the out_file_base argument.
 
     Args:
         out_file_base (str): a string defining the prefix of the file where the tensordict will be written.
-        skip_reset (bool): if True, the first TensorDict of the list will be discarded (usually the tensordict
+        skip_reset (bool): if ``True``, the first TensorDict of the list will be discarded (usually the tensordict
             resulting from the call to :obj:`env.reset()`)
             default: True
         skip (int): frame interval for the saved tensordict.
             default: 4
 
     """
```

## torchrl/record/loggers/csv.py

```diff
@@ -70,14 +70,15 @@
 
     def __init__(self, exp_name: str, log_dir: Optional[str] = None) -> None:
         if log_dir is None:
             log_dir = "csv_logs"
         super().__init__(exp_name=exp_name, log_dir=log_dir)
 
         self._has_imported_moviepy = False
+        print(f"self.log_dir: {self.experiment.log_dir}")
 
     def _create_experiment(self) -> "CSVExperiment":
         """Creates a CSV experiment."""
         log_dir = str(os.path.join(self.log_dir, self.exp_name))
         return CSVExperiment(log_dir)
 
     def log_scalar(self, name: str, value: float, step: int = None) -> None:
```

## torchrl/trainers/trainers.py

```diff
@@ -11,25 +11,26 @@
 from collections import defaultdict, OrderedDict
 from copy import deepcopy
 from textwrap import indent
 from typing import Any, Callable, Dict, List, Optional, Sequence, Tuple, Type, Union
 
 import numpy as np
 import torch.nn
+from tensordict.nn import TensorDictModule
 from tensordict.tensordict import pad, TensorDictBase
 from tensordict.utils import expand_right
 from torch import nn, optim
 
 from torchrl._utils import _CKPT_BACKEND, KeyDependentDefaultDict, VERBOSE
-from torchrl.collectors.collectors import _DataCollector
+from torchrl.collectors.collectors import DataCollectorBase
+from torchrl.collectors.utils import split_trajectories
 from torchrl.data import TensorDictPrioritizedReplayBuffer, TensorDictReplayBuffer
 from torchrl.data.utils import DEVICE_TYPING
 from torchrl.envs.common import EnvBase
-from torchrl.envs.utils import set_exploration_mode
-from torchrl.modules import SafeModule
+from torchrl.envs.utils import ExplorationType, set_exploration_type
 from torchrl.objectives.common import LossModule
 from torchrl.record.loggers import Logger
 
 try:
     from tqdm import tqdm
 
     _has_tqdm = True
@@ -66,14 +67,25 @@
 
     @abc.abstractmethod
     def load_state_dict(self, state_dict: Dict[str, Any]) -> None:
         raise NotImplementedError
 
     @abc.abstractmethod
     def register(self, trainer: Trainer, name: str):
+        """Registers the hook in the trainer at a default location.
+
+        Args:
+            trainer (Trainer): the trainer where the hook must be registered.
+            name (str): the name of the hook.
+
+        .. note::
+          To register the hook at another location than the default, use
+          :meth:`~torchrl.trainers.Trainer.register_op`.
+
+        """
         raise NotImplementedError
 
 
 class Trainer:
     """A generic Trainer class.
 
     A trainer is responsible for collecting data and training the model.
@@ -91,75 +103,80 @@
             training.
         loss_module (LossModule): A module that reads TensorDict batches
             (possibly sampled from a replay buffer) and return a loss
             TensorDict where every key points to a different loss component.
         optimizer (optim.Optimizer): An optimizer that trains the parameters
             of the model.
         logger (Logger, optional): a Logger that will handle the logging.
-        optim_steps_per_batch (int, optional): number of optimization steps
+        optim_steps_per_batch (int): number of optimization steps
             per collection of data. An trainer works as follows: a main loop
             collects batches of data (epoch loop), and a sub-loop (training
             loop) performs model updates in between two collections of data.
-            Default is 500
         clip_grad_norm (bool, optional): If True, the gradients will be clipped
             based on the total norm of the model parameters. If False,
             all the partial derivatives will be clamped to
             (-clip_norm, clip_norm). Default is :obj:`True`.
         clip_norm (Number, optional): value to be used for clipping gradients.
-            Default is 100.0.
+            Default is None (no clip norm).
         progress_bar (bool, optional): If True, a progress bar will be
             displayed using tqdm. If tqdm is not installed, this option
             won't have any effect. Default is :obj:`True`
         seed (int, optional): Seed to be used for the collector, pytorch and
-            numpy. Default is 42.
+            numpy. Default is ``None``.
         save_trainer_interval (int, optional): How often the trainer should be
-            saved to disk. Default is 10000.
+            saved to disk, in frame count. Default is 10000.
+        log_interval (int, optional): How often the values should be logged,
+            in frame count. Default is 10000.
         save_trainer_file (path, optional): path where to save the trainer.
             Default is None (no saving)
     """
 
     @classmethod
     def __new__(cls, *args, **kwargs):
         # trackers
         cls._optim_count: int = 0
         cls._collected_frames: int = 0
         cls._last_log: Dict[str, Any] = {}
         cls._last_save: int = 0
-        cls._log_interval: int = 10000
         cls.collected_frames = 0
         cls._app_state = None
         return super().__new__(cls)
 
     def __init__(
         self,
-        collector: _DataCollector,
+        *,
+        collector: DataCollectorBase,
         total_frames: int,
         frame_skip: int,
+        optim_steps_per_batch: int,
         loss_module: Union[LossModule, Callable[[TensorDictBase], TensorDictBase]],
         optimizer: Optional[optim.Optimizer] = None,
         logger: Optional[Logger] = None,
-        optim_steps_per_batch: int = 500,
         clip_grad_norm: bool = True,
-        clip_norm: float = 100.0,
+        clip_norm: float = None,
         progress_bar: bool = True,
-        seed: int = 42,
+        seed: int = None,
         save_trainer_interval: int = 10000,
+        log_interval: int = 10000,
         save_trainer_file: Optional[Union[str, pathlib.Path]] = None,
     ) -> None:
 
         # objects
         self.frame_skip = frame_skip
         self.collector = collector
         self.loss_module = loss_module
         self.optimizer = optimizer
         self.logger = logger
 
+        self._log_interval = log_interval
+
         # seeding
         self.seed = seed
-        self.set_seed()
+        if seed is not None:
+            self.set_seed()
 
         # constants
         self.optim_steps_per_batch = optim_steps_per_batch
         self.total_frames = total_frames
         self.clip_grad_norm = clip_grad_norm
         self.clip_norm = clip_norm
         if progress_bar and not _has_tqdm:
@@ -282,19 +299,19 @@
 
     def set_seed(self):
         seed = self.collector.set_seed(self.seed, static_seed=False)
         torch.manual_seed(seed)
         np.random.seed(seed)
 
     @property
-    def collector(self) -> _DataCollector:
+    def collector(self) -> DataCollectorBase:
         return self._collector
 
     @collector.setter
-    def collector(self, collector: _DataCollector) -> None:
+    def collector(self, collector: DataCollectorBase) -> None:
         self._collector = collector
 
     def register_op(self, dest: str, op: Callable, **kwargs) -> None:
         if dest == "batch_process":
             _check_input_output_typehint(
                 op, input=TensorDictBase, output=TensorDictBase
             )
@@ -417,22 +434,22 @@
     def train(self):
         if self.progress_bar:
             self._pbar = tqdm(total=self.total_frames)
             self._pbar_str = {}
 
         for batch in self.collector:
             batch = self._process_batch_hook(batch)
-            self._pre_steps_log_hook(batch)
             current_frames = (
                 batch.get(("collector", "mask"), torch.tensor(batch.numel()))
                 .sum()
                 .item()
                 * self.frame_skip
             )
             self.collected_frames += current_frames
+            self._pre_steps_log_hook(batch)
 
             if self.collected_frames > self.collector.init_random_frames:
                 self.optim_steps(batch)
             self._post_steps_hook()
 
             self._post_steps_log_hook(batch)
 
@@ -485,15 +502,14 @@
                 **average_losses,
             )
 
     def _log(self, log_pbar=False, **kwargs) -> None:
         collected_frames = self.collected_frames
         for key, item in kwargs.items():
             self._log_dict[key].append(item)
-
             if (collected_frames - self._last_log.get(key, 0)) > self._log_interval:
                 self._last_log[key] = collected_frames
                 _log = True
             else:
                 _log = False
             method = LOGGER_METHODS.get(key, "log_scalar")
             if _log and self.logger is not None:
@@ -597,21 +613,23 @@
 
 
 class ReplayBufferTrainer(TrainerHookBase):
     """Replay buffer hook provider.
 
     Args:
         replay_buffer (TensorDictReplayBuffer): replay buffer to be used.
-        batch_size (int): batch size when sampling data from the
-            latest collection or from the replay buffer.
-        memmap (bool, optional): if True, a memmap tensordict is created.
+        batch_size (int, optional): batch size when sampling data from the
+            latest collection or from the replay buffer. If none is provided,
+            the replay buffer batch-size will be used (preferred option for
+            unchanged batch-sizes).
+        memmap (bool, optional): if ``True``, a memmap tensordict is created.
             Default is False.
         device (device, optional): device where the samples must be placed.
             Default is cpu.
-        flatten_tensordicts (bool, optional): if True, the tensordicts will be
+        flatten_tensordicts (bool, optional): if ``True``, the tensordicts will be
             flattened (or equivalently masked with the valid mask obtained from
             the collector) before being passed to the replay buffer. Otherwise,
             no transform will be achieved other than padding (see :obj:`max_dims` arg below).
             Defaults to True
         max_dims (sequence of int, optional): if :obj:`flatten_tensordicts` is set to False,
             this will be a list of the length of the batch_size of the provided
             tensordicts that represent the maximum size of each. If provided,
@@ -626,24 +644,32 @@
         >>> trainer.register_op("post_loss", rb_trainer.update_priority)
 
     """
 
     def __init__(
         self,
         replay_buffer: TensorDictReplayBuffer,
-        batch_size: int,
+        batch_size: Optional[int] = None,
         memmap: bool = False,
         device: DEVICE_TYPING = "cpu",
-        flatten_tensordicts: bool = True,
+        flatten_tensordicts: bool = None,
         max_dims: Optional[Sequence[int]] = None,
     ) -> None:
         self.replay_buffer = replay_buffer
         self.batch_size = batch_size
         self.memmap = memmap
         self.device = device
+        if flatten_tensordicts is None:
+            warnings.warn(
+                "flatten_tensordicts default value will soon be changed "
+                "to False for a faster execution. Make sure your "
+                "code is robust to this change.",
+                category=DeprecationWarning,
+            )
+            flatten_tensordicts = True
         self.flatten_tensordicts = flatten_tensordicts
         self.max_dims = max_dims
 
     def extend(self, batch: TensorDictBase) -> TensorDictBase:
         if self.flatten_tensordicts:
             if ("collector", "mask") in batch.keys(True):
                 batch = batch[batch.get(("collector", "mask"))]
@@ -664,15 +690,15 @@
         if self.memmap:
             # We can already place the tensords on the device if they're memmap,
             # as this is a lazy op
             batch = batch.memmap_().to(self.device)
         self.replay_buffer.extend(batch)
 
     def sample(self, batch: TensorDictBase) -> TensorDictBase:
-        sample = self.replay_buffer.sample(self.batch_size)
+        sample = self.replay_buffer.sample(batch_size=self.batch_size)
         return sample.to(self.device, non_blocking=True)
 
     def update_priority(self, batch: TensorDictBase) -> None:
         self.replay_buffer.update_tensordict_priority(batch)
 
     def state_dict(self) -> Dict[str, Any]:
         return {
@@ -722,19 +748,20 @@
             self.loss_components = set(self.loss_components)
 
     def _grad_clip(self, clip_grad_norm: bool, clip_norm: float) -> float:
         params = []
         for param_group in self.optimizer.param_groups:
             params += param_group["params"]
 
-        if clip_grad_norm:
+        if clip_grad_norm and clip_norm is not None:
             gn = nn.utils.clip_grad_norm_(params, clip_norm)
         else:
             gn = sum([p.grad.pow(2).sum() for p in params if p.grad is not None]).sqrt()
-            nn.utils.clip_grad_value_(params, clip_norm)
+            if clip_norm is not None:
+                nn.utils.clip_grad_value_(params, clip_norm)
 
         return float(gn)
 
     def __call__(
         self,
         losses_td: TensorDictBase,
         clip_grad_norm: bool,
@@ -788,16 +815,16 @@
 
 
 class LogReward(TrainerHookBase):
     """Reward logger hook.
 
     Args:
         logname (str, optional): name of the rewards to be logged. Default is :obj:`"r_training"`.
-        log_pbar (bool, optional): if True, the reward value will be logged on
-            the progression bar. Default is :obj:`False`.
+        log_pbar (bool, optional): if ``True``, the reward value will be logged on
+            the progression bar. Default is ``False``.
         reward_key (str or tuple, optional): the key where to find the reward
             in the input batch. Defaults to ``("next", "reward")``
 
     Examples:
         >>> log_reward = LogReward(("next", "reward"))
         >>> trainer.register_op("pre_steps_log", log_reward)
 
@@ -1089,126 +1116,141 @@
             "process_optim_batch",
             self,
         )
         trainer.register_module(name, self)
 
 
 class Recorder(TrainerHookBase):
-    """Recorder hook for Trainer.
+    """Recorder hook for :class:`~torchrl.trainers.Trainer`.
 
     Args:
         record_interval (int): total number of optimisation steps
             between two calls to the recorder for testing.
         record_frames (int): number of frames to be recorded during
             testing.
         frame_skip (int): frame_skip used in the environment. It is
             important to let the trainer know the number of frames skipped at
             each iteration, otherwise the frame count can be underestimated.
             For logging, this parameter is important to normalize the reward.
             Finally, to compare different runs with different frame_skip,
-            one must normalize the frame count and rewards. Default is 1.
+            one must normalize the frame count and rewards. Defaults to ``1``.
         policy_exploration (ProbabilisticTDModule): a policy
             instance used for
 
             (1) updating the exploration noise schedule;
 
             (2) testing the policy on the recorder.
 
             Given that this instance is supposed to both explore and render
             the performance of the policy, it should be possible to turn off
             the explorative behaviour by calling the
-            `set_exploration_mode('mode')` context manager.
-        recorder (EnvBase): An environment instance to be used
+            `set_exploration_type(ExplorationType.MODE)` context manager.
+        environment (EnvBase): An environment instance to be used
             for testing.
-        exploration_mode (str, optional): exploration mode to use for the
+        exploration_type (ExplorationType, optional): exploration mode to use for the
             policy. By default, no exploration is used and the value used is
-            "mode". Set to "random" to enable exploration
-        out_key (str, optional): reward key to set to the logger. Default is
-            `"reward_evaluation"`.
+            ExplorationType.MODE. Set to ExplorationType.RANDOM to enable exploration
+        log_keys (sequence of str or tuples or str, optional): keys to read in the tensordict
+            for logging. Defaults to ``[("next", "reward")]``.
+        out_keys (Dict[str, str], optional): a dictionary mapping the ``log_keys``
+            to their name in the logs. Defaults to ``{("next", "reward"): "r_evaluation"}``.
         suffix (str, optional): suffix of the video to be recorded.
-        log_pbar (bool, optional): if True, the reward value will be logged on
+        log_pbar (bool, optional): if ``True``, the reward value will be logged on
             the progression bar. Default is `False`.
 
     """
 
+    ENV_DEPREC = (
+        "the environment should be passed under the 'environment' key"
+        " and not the 'recorder' key."
+    )
+
     def __init__(
         self,
+        *,
         record_interval: int,
         record_frames: int,
-        frame_skip: int,
-        policy_exploration: SafeModule,
-        recorder: EnvBase,
-        exploration_mode: str = "random",
-        log_keys: Optional[List[str]] = None,
-        out_keys: Optional[Dict[str, str]] = None,
+        frame_skip: int = 1,
+        policy_exploration: TensorDictModule,
+        environment: EnvBase = None,
+        exploration_type: ExplorationType = ExplorationType.RANDOM,
+        log_keys: Optional[List[Union[str, Tuple[str]]]] = None,
+        out_keys: Optional[Dict[Union[str, Tuple[str]], str]] = None,
         suffix: Optional[str] = None,
         log_pbar: bool = False,
+        recorder: EnvBase = None,
     ) -> None:
-
+        if environment is None and recorder is not None:
+            warnings.warn(self.ENV_DEPREC)
+            environment = recorder
+        elif environment is not None and recorder is not None:
+            raise ValueError("environment and recorder conflict.")
         self.policy_exploration = policy_exploration
-        self.recorder = recorder
+        self.environment = environment
         self.record_frames = record_frames
         self.frame_skip = frame_skip
         self._count = 0
         self.record_interval = record_interval
-        self.exploration_mode = exploration_mode
+        self.exploration_type = exploration_type
         if log_keys is None:
             log_keys = [("next", "reward")]
         if out_keys is None:
             out_keys = KeyDependentDefaultDict(lambda x: x)
             out_keys[("next", "reward")] = "r_evaluation"
         self.log_keys = log_keys
         self.out_keys = out_keys
         self.suffix = suffix
         self.log_pbar = log_pbar
 
     @torch.inference_mode()
     def __call__(self, batch: TensorDictBase) -> Dict:
         out = None
         if self._count % self.record_interval == 0:
-            with set_exploration_mode(self.exploration_mode):
+            with set_exploration_type(self.exploration_type):
                 if isinstance(self.policy_exploration, torch.nn.Module):
                     self.policy_exploration.eval()
-                self.recorder.eval()
-                td_record = self.recorder.rollout(
+                self.environment.eval()
+                td_record = self.environment.rollout(
                     policy=self.policy_exploration,
                     max_steps=self.record_frames,
                     auto_reset=True,
                     auto_cast_to_device=True,
                     break_when_any_done=False,
                 ).clone()
+                td_record = split_trajectories(td_record)
                 if isinstance(self.policy_exploration, torch.nn.Module):
                     self.policy_exploration.train()
-                self.recorder.train()
-                self.recorder.transform.dump(suffix=self.suffix)
+                self.environment.train()
+                self.environment.transform.dump(suffix=self.suffix)
 
                 out = {}
                 for key in self.log_keys:
                     value = td_record.get(key).float()
                     if key == ("next", "reward"):
-                        mean_value = value.mean() / self.frame_skip
-                        total_value = value.sum()
+                        mask = td_record["mask"]
+                        mean_value = value[mask].mean() / self.frame_skip
+                        total_value = value.sum(dim=td_record.ndim - 1).mean()
                         out[self.out_keys[key]] = mean_value
                         out["total_" + self.out_keys[key]] = total_value
                         continue
                     out[self.out_keys[key]] = value
                 out["log_pbar"] = self.log_pbar
         self._count += 1
-        self.recorder.close()
+        self.environment.close()
         return out
 
     def state_dict(self) -> Dict:
         return {
             "_count": self._count,
-            "recorder_state_dict": self.recorder.state_dict(),
+            "recorder_state_dict": self.environment.state_dict(),
         }
 
     def load_state_dict(self, state_dict: Dict) -> None:
         self._count = state_dict["_count"]
-        self.recorder.load_state_dict(state_dict["recorder_state_dict"])
+        self.environment.load_state_dict(state_dict["recorder_state_dict"])
 
     def register(self, trainer: Trainer, name: str = "recorder"):
         trainer.register_module(name, self)
         trainer.register_op(
             "post_steps_log",
             self,
         )
@@ -1219,26 +1261,26 @@
 
     This hook must be used whenever the collector policy weights sit on a
     different device than the policy weights being trained by the Trainer.
     In that case, those weights must be synced across devices at regular
     intervals. If the devices match, this will result in a no-op.
 
     Args:
-        collector (_DataCollector): A data collector where the policy weights
+        collector (DataCollectorBase): A data collector where the policy weights
             must be synced.
         update_weights_interval (int): Interval (in terms of number of batches
             collected) where the sync must take place.
 
     Examples:
         >>> update_weights = UpdateWeights(trainer.collector, T)
         >>> trainer.register_op("post_steps", update_weights)
 
     """
 
-    def __init__(self, collector: _DataCollector, update_weights_interval: int):
+    def __init__(self, collector: DataCollectorBase, update_weights_interval: int):
         self.collector = collector
         self.update_weights_interval = update_weights_interval
         self.counter = 0
 
     def __call__(self):
         self.counter += 1
         if self.counter % self.update_weights_interval == 0:
@@ -1261,15 +1303,15 @@
 class CountFramesLog(TrainerHookBase):
     """A frame counter hook.
 
     Args:
         frame_skip (int): frame skip of the environment. This argument is
             important to keep track of the total number of frames, not the
             apparent one.
-        log_pbar (bool, optional): if True, the reward value will be logged on
+        log_pbar (bool, optional): if ``True``, the reward value will be logged on
             the progression bar. Default is `False`.
 
     Examples:
         >>> count_frames = CountFramesLog(frame_skip=frame_skip)
         >>> trainer.register_op("pre_steps_log", count_frames)
```

## torchrl/trainers/helpers/collectors.py

```diff
@@ -2,27 +2,27 @@
 #
 # This source code is licensed under the MIT license found in the
 # LICENSE file in the root directory of this source tree.
 
 from dataclasses import dataclass, field
 from typing import Any, Callable, Dict, List, Optional, Type, Union
 
-from tensordict.nn import TensorDictModuleWrapper
+from tensordict.nn import ProbabilisticTensorDictSequential, TensorDictModuleWrapper
 from tensordict.tensordict import TensorDictBase
 
 from torchrl.collectors.collectors import (
-    _DataCollector,
+    DataCollectorBase,
     MultiaSyncDataCollector,
     MultiSyncDataCollector,
     SyncDataCollector,
 )
 from torchrl.data import MultiStep
 from torchrl.envs import ParallelEnv
 from torchrl.envs.common import EnvBase
-from torchrl.modules import SafeProbabilisticSequential
+from torchrl.envs.utils import ExplorationType
 
 
 def sync_async_collector(
     env_fns: Union[Callable, List[Callable]],
     env_kwargs: Optional[Union[dict, List[dict]]],
     num_env_per_collector: Optional[int] = None,
     num_collectors: Optional[int] = None,
@@ -171,15 +171,15 @@
     max_frames_per_traj: int = -1,
     frames_per_batch: int = 200,
     total_frames: Optional[int] = None,
     postproc: Optional[Callable] = None,
     num_env_per_collector: Optional[int] = None,
     num_collectors: Optional[int] = None,
     **kwargs,
-) -> _DataCollector:
+) -> DataCollectorBase:
     if env_kwargs is None:
         env_kwargs = {}
     if isinstance(env_fns, list):
         num_env = len(env_fns)
         if num_env_per_collector is None:
             num_env_per_collector = -(num_env // -num_collectors)
         elif num_collectors is None:
@@ -245,18 +245,20 @@
         postproc=postproc,
         **kwargs,
     )
 
 
 def make_collector_offpolicy(
     make_env: Callable[[], EnvBase],
-    actor_model_explore: Union[TensorDictModuleWrapper, SafeProbabilisticSequential],
+    actor_model_explore: Union[
+        TensorDictModuleWrapper, ProbabilisticTensorDictSequential
+    ],
     cfg: "DictConfig",  # noqa: F821
     make_env_kwargs: Optional[Dict] = None,
-) -> _DataCollector:
+) -> DataCollectorBase:
     """Returns a data collector for off-policy algorithms.
 
     Args:
         make_env (Callable): environment creator
         actor_model_explore (SafeModule): Model instance used for evaluation and exploration update
         cfg (DictConfig): config for creating collector object
         make_env_kwargs (dict): kwargs for the env creator
@@ -276,49 +278,51 @@
         ms = None
 
     env_kwargs = {}
     if make_env_kwargs is not None and isinstance(make_env_kwargs, dict):
         env_kwargs.update(make_env_kwargs)
     elif make_env_kwargs is not None:
         env_kwargs = make_env_kwargs
-    cfg.collector_devices = (
-        cfg.collector_devices
-        if len(cfg.collector_devices) > 1
-        else cfg.collector_devices[0]
+    cfg.collector_device = (
+        cfg.collector_device
+        if len(cfg.collector_device) > 1
+        else cfg.collector_device[0]
     )
     collector_helper_kwargs = {
         "env_fns": make_env,
         "env_kwargs": env_kwargs,
         "policy": actor_model_explore,
         "max_frames_per_traj": cfg.max_frames_per_traj,
         "frames_per_batch": cfg.frames_per_batch,
         "total_frames": cfg.total_frames,
         "postproc": ms,
         "num_env_per_collector": 1,
         # we already took care of building the make_parallel_env function
         "num_collectors": -cfg.num_workers // -cfg.env_per_collector,
-        "device": cfg.collector_devices,
-        "storing_device": cfg.collector_devices,
+        "device": cfg.collector_device,
+        "storing_device": cfg.collector_device,
         "init_random_frames": cfg.init_random_frames,
         "split_trajs": True,
         # trajectories must be separated if multi-step is used
-        "exploration_mode": cfg.exploration_mode,
+        "exploration_type": ExplorationType.from_str(cfg.exploration_mode),
     }
 
     collector = collector_helper(**collector_helper_kwargs)
     collector.set_seed(cfg.seed)
     return collector
 
 
 def make_collector_onpolicy(
     make_env: Callable[[], EnvBase],
-    actor_model_explore: Union[TensorDictModuleWrapper, SafeProbabilisticSequential],
+    actor_model_explore: Union[
+        TensorDictModuleWrapper, ProbabilisticTensorDictSequential
+    ],
     cfg: "DictConfig",  # noqa: F821
     make_env_kwargs: Optional[Dict] = None,
-) -> _DataCollector:
+) -> DataCollectorBase:
     """Makes a collector in on-policy settings.
 
     Args:
         make_env (Callable): environment creator
         actor_model_explore (SafeModule): Model instance used for evaluation and exploration update
         cfg (DictConfig): config for creating collector object
         make_env_kwargs (dict): kwargs for the env creator
@@ -329,52 +333,52 @@
     ms = None
 
     env_kwargs = {}
     if make_env_kwargs is not None and isinstance(make_env_kwargs, dict):
         env_kwargs.update(make_env_kwargs)
     elif make_env_kwargs is not None:
         env_kwargs = make_env_kwargs
-    cfg.collector_devices = (
-        cfg.collector_devices
-        if len(cfg.collector_devices) > 1
-        else cfg.collector_devices[0]
+    cfg.collector_device = (
+        cfg.collector_device
+        if len(cfg.collector_device) > 1
+        else cfg.collector_device[0]
     )
     collector_helper_kwargs = {
         "env_fns": make_env,
         "env_kwargs": env_kwargs,
         "policy": actor_model_explore,
         "max_frames_per_traj": cfg.max_frames_per_traj,
         "frames_per_batch": cfg.frames_per_batch,
         "total_frames": cfg.total_frames,
         "postproc": ms,
         "num_env_per_collector": 1,
         # we already took care of building the make_parallel_env function
         "num_collectors": -cfg.num_workers // -cfg.env_per_collector,
-        "device": cfg.collector_devices,
-        "storing_device": cfg.collector_devices,
+        "device": cfg.collector_device,
+        "storing_device": cfg.collector_device,
         "split_trajs": True,
         # trajectories must be separated in online settings
         "exploration_mode": cfg.exploration_mode,
     }
 
     collector = collector_helper(**collector_helper_kwargs)
     collector.set_seed(cfg.seed)
     return collector
 
 
 @dataclass
 class OnPolicyCollectorConfig:
     """On-policy collector config struct."""
 
-    collector_devices: Any = field(default_factory=lambda: ["cpu"])
+    collector_device: Any = field(default_factory=lambda: ["cpu"])
     # device on which the data collector should store the trajectories to be passed to this script.
     # If the collector device differs from the policy device (cuda:0 if available), then the
     # weights of the collector policy are synchronized with collector.update_policy_weights_().
     pin_memory: bool = False
-    # if True, the data collector will call pin_memory before dispatching tensordicts onto the passing device
+    # if ``True``, the data collector will call pin_memory before dispatching tensordicts onto the passing device
     frames_per_batch: int = 1000
     # number of steps executed in the environment per collection.
     # This value represents how many steps will the data collector execute and return in *each*
     # environment that has been created in between two rounds of optimization
     # (see the optim_steps_per_batch above).
     # On the one hand, a low value will enhance the data throughput between processes in async
     # settings, which can make the accessing of data a computational bottleneck.
@@ -389,15 +393,15 @@
     env_per_collector: int = 8
     # Number of environments per collector. If the env_per_collector is in the range:
     # 1<env_per_collector<=num_workers, then the collector runs
     # ceil(num_workers/env_per_collector) in parallel and executes the policy steps synchronously
     # for each of these parallel wrappers. If env_per_collector=num_workers, no parallel wrapper is created
     seed: int = 42
     # seed used for the environment, pytorch and numpy.
-    exploration_mode: str = ""
+    exploration_mode: str = "random"
     # exploration mode of the data collector.
     async_collection: bool = False
     # whether data collection should be done asynchrously. Asynchrounous data collection means
     # that the data collector will keep on running the environment with the previous weights
     # configuration while the optimization loop is being done. If the algorithm is trained
     # synchronously, data collection and optimization will occur iteratively, not concurrently.
```

## torchrl/trainers/helpers/envs.py

```diff
@@ -16,25 +16,29 @@
 from torchrl.envs.libs.gym import GymEnv
 from torchrl.envs.transforms import (
     CatFrames,
     CatTensors,
     CenterCrop,
     Compose,
     DoubleToFloat,
-    FiniteTensorDictCheck,
     GrayScale,
     NoopResetEnv,
     ObservationNorm,
     Resize,
     RewardScaling,
     ToTensorImage,
     TransformedEnv,
     VecNorm,
 )
-from torchrl.envs.transforms.transforms import FlattenObservation, gSDENoise
+from torchrl.envs.transforms.transforms import (
+    FlattenObservation,
+    gSDENoise,
+    InitTracker,
+    StepCounter,
+)
 from torchrl.record.loggers import Logger
 from torchrl.record.recorder import VideoRecorder
 
 LIBS = {
     "gym": GymEnv,
     "dm_control": DMControlEnv,
 }
@@ -201,15 +205,16 @@
         )
 
     if hasattr(cfg, "gSDE") and cfg.gSDE:
         env.append_transform(
             gSDENoise(action_dim=action_dim_gsde, state_dim=state_dim_gsde)
         )
 
-    env.append_transform(FiniteTensorDictCheck())
+    env.append_transform(StepCounter())
+    env.append_transform(InitTracker())
 
     return env
 
 
 def transformed_env_constructor(
     cfg: "DictConfig",  # noqa: F821
     video_tag: str = "",
@@ -240,15 +245,15 @@
         custom_env_maker (callable, optional): if your env maker is not part
             of torchrl env wrappers, a custom callable
             can be passed instead. In this case it will override the
             constructor retrieved from `args`.
         custom_env (EnvBase, optional): if an existing environment needs to be
             transformed_in, it can be passed directly to this helper. `custom_env_maker`
             and `custom_env` are exclusive features.
-        return_transformed_envs (bool, optional): if True, a transformed_in environment
+        return_transformed_envs (bool, optional): if ``True``, a transformed_in environment
             is returned.
         action_dim_gsde (int, Optional): if gSDE is used, this can present the action dim to initialize the noise.
             Make sure this is indicated in environment executed in parallel.
         state_dim_gsde: if gSDE is used, this can present the state dim to initialize the noise.
             Make sure this is indicated in environment executed in parallel.
         batch_dims (int, optional): number of dimensions of a batch of data. If a single env is
             used, it should be 0 (default). If multiple envs are being transformed in parallel,
@@ -262,21 +267,21 @@
         env_task = cfg.env_task
         env_library = LIBS[cfg.env_library]
         frame_skip = cfg.frame_skip
         from_pixels = cfg.from_pixels
         categorical_action_encoding = cfg.categorical_action_encoding
 
         if custom_env is None and custom_env_maker is None:
-            if isinstance(cfg.collector_devices, str):
-                device = cfg.collector_devices
-            elif isinstance(cfg.collector_devices, Sequence):
-                device = cfg.collector_devices[0]
+            if isinstance(cfg.collector_device, str):
+                device = cfg.collector_device
+            elif isinstance(cfg.collector_device, Sequence):
+                device = cfg.collector_device[0]
             else:
                 raise ValueError(
-                    "collector_devices must be either a string or a sequence of strings"
+                    "collector_device must be either a string or a sequence of strings"
                 )
             env_kwargs = {
                 "env_name": env_name,
                 "device": device,
                 "frame_skip": frame_skip,
                 "from_pixels": from_pixels or len(video_tag),
                 "pixels_only": from_pixels,
@@ -552,11 +557,11 @@
     center_crop: Any = dataclass_field(default_factory=lambda: [])
     # center crop size.
     grayscale: bool = True
     # Disables grayscale transform.
     max_frames_per_traj: int = 1000
     # Number of steps before a reset of the environment is called (if it has not been flagged as done before).
     batch_transform: bool = False
-    # if True, the transforms will be applied to the parallel env, and not to each individual env.\
+    # if ``True``, the transforms will be applied to the parallel env, and not to each individual env.\
     image_size: int = 84
     # if True and environment has discrete action space, then it is encoded as categorical values rather than one-hot.
     categorical_action_encoding: bool = False
```

## torchrl/trainers/helpers/losses.py

```diff
@@ -36,16 +36,14 @@
             target_net_updater = SoftUpdate(
                 loss_module, 1 - 1 / cfg.value_network_update_interval
             )
         else:
             target_net_updater = HardUpdate(
                 loss_module, cfg.value_network_update_interval
             )
-        # assert len(target_net_updater.net_pairs) == 3, "length of target_net_updater nets should be 3"
-        target_net_updater.init_()
     else:
         if cfg.hard_update:
             raise RuntimeError(
                 "hard/soft-update are supposed to be used with double SAC loss. "
                 "Consider using --loss=double or discarding the hard_update flag."
             )
         target_net_updater = None
@@ -91,17 +89,17 @@
     actor_model, qvalue_model, value_model = model
 
     loss_module = loss_class(
         actor_network=actor_model,
         qvalue_network=qvalue_model,
         value_network=value_model,
         num_qvalue_nets=cfg.num_q_values,
-        gamma=cfg.gamma,
         **loss_kwargs,
     )
+    loss_module.make_value_estimator(gamma=cfg.gamma)
     target_net_updater = make_target_updater(cfg, loss_module)
     return loss_module, target_net_updater
 
 
 def make_redq_loss(
     model, cfg
 ) -> Tuple[REDQLoss_deprecated, Optional[TargetNetUpdater]]:
@@ -126,18 +124,18 @@
     else:
         actor_model, qvalue_model = model
 
     loss_module = loss_class(
         actor_network=actor_model,
         qvalue_network=qvalue_model,
         num_qvalue_nets=cfg.num_q_values,
-        gamma=cfg.gamma,
         gSDE=cfg.gSDE,
         **loss_kwargs,
     )
+    loss_module.make_value_estimator(gamma=cfg.gamma)
     target_net_updater = make_target_updater(cfg, loss_module)
     return loss_module, target_net_updater
 
 
 def make_ddpg_loss(model, cfg) -> Tuple[DDPGLoss, Optional[TargetNetUpdater]]:
     """Builds the DDPG loss module."""
     actor, value_net = model
@@ -147,15 +145,16 @@
     else:
         loss_kwargs.update({"loss_function": cfg.loss_function})
         loss_class = DDPGLoss
     if cfg.loss not in ("single", "double"):
         raise NotImplementedError
     double_loss = cfg.loss == "double"
     loss_kwargs.update({"delay_actor": double_loss, "delay_value": double_loss})
-    loss_module = loss_class(actor, value_net, gamma=cfg.gamma, **loss_kwargs)
+    loss_module = loss_class(actor, value_net, **loss_kwargs)
+    loss_module.make_value_estimator(gamma=cfg.gamma)
     target_net_updater = make_target_updater(cfg, loss_module)
     return loss_module, target_net_updater
 
 
 def make_dqn_loss(model, cfg) -> Tuple[DQNLoss, Optional[TargetNetUpdater]]:
     """Builds the DQN loss module."""
     loss_kwargs = {}
@@ -163,15 +162,16 @@
         loss_class = DistributionalDQNLoss
     else:
         loss_kwargs.update({"loss_function": cfg.loss_function})
         loss_class = DQNLoss
     if cfg.loss not in ("single", "double"):
         raise NotImplementedError
     loss_kwargs.update({"delay_value": cfg.loss == "double"})
-    loss_module = loss_class(model, gamma=cfg.gamma, **loss_kwargs)
+    loss_module = loss_class(model, **loss_kwargs)
+    loss_module.make_value_estimator(gamma=cfg.gamma)
     target_net_updater = make_target_updater(cfg, loss_module)
     return loss_module, target_net_updater
 
 
 def make_a2c_loss(model, cfg) -> A2CLoss:
     """Builds the A2C loss module."""
     actor_model = model.get_policy_operator()
```

## torchrl/trainers/helpers/models.py

```diff
@@ -4,33 +4,34 @@
 # LICENSE file in the root directory of this source tree.
 
 import itertools
 from dataclasses import dataclass
 from typing import Optional, Sequence
 
 import torch
+from tensordict.nn import InteractionType
 from torch import distributions as d, nn
 
 from torchrl.data.tensor_specs import (
     CompositeSpec,
     DiscreteTensorSpec,
     UnboundedContinuousTensorSpec,
 )
 from torchrl.data.utils import DEVICE_TYPING
 from torchrl.envs import TensorDictPrimer, TransformedEnv
 from torchrl.envs.common import EnvBase
 from torchrl.envs.model_based.dreamer import DreamerEnv
-from torchrl.envs.utils import set_exploration_mode
+from torchrl.envs.utils import ExplorationType, set_exploration_type
 from torchrl.modules import (
     ActorValueOperator,
     NoisyLinear,
     NormalParamWrapper,
     SafeModule,
     SafeProbabilisticModule,
-    SafeProbabilisticSequential,
+    SafeProbabilisticTensorDictSequential,
     SafeSequential,
 )
 from torchrl.modules.distributions import (
     Delta,
     OneHotCategorical,
     TanhDelta,
     TanhNormal,
@@ -400,15 +401,15 @@
         out_keys=out_keys,
         module=q_net,
     )
 
     module = torch.nn.ModuleList([actor, value]).to(device)
 
     # init
-    with torch.no_grad(), set_exploration_mode("random"):
+    with torch.no_grad(), set_exploration_type(ExplorationType.RANDOM):
         td = proof_environment.rollout(max_steps=1000)
         td = td.to(device)
         module[0](td)
         module[1](td)
 
     return module
 
@@ -604,15 +605,15 @@
                 ),
             )
 
         policy_operator = ProbabilisticActor(
             spec=CompositeSpec(action=action_spec),
             module=actor_module,
             in_keys=dist_in_keys,
-            default_interaction_mode="random",
+            default_interaction_type=InteractionType.RANDOM,
             distribution_class=policy_distribution_class,
             distribution_kwargs=policy_distribution_kwargs,
             return_log_prob=True,
         )
         value_net = MLP(
             num_cells=[64],
             out_features=1,
@@ -684,28 +685,28 @@
         policy_po = ProbabilisticActor(
             actor_module,
             spec=action_spec,
             in_keys=dist_in_keys,
             distribution_class=policy_distribution_class,
             distribution_kwargs=policy_distribution_kwargs,
             return_log_prob=True,
-            default_interaction_mode="random",
+            default_interaction_type=InteractionType.RANDOM,
         )
 
         value_net = MLP(
             num_cells=[64, 64],
             out_features=1,
         )
         value_po = ValueOperator(
             value_net,
             in_keys=in_keys_critic,
         )
         actor_value = ActorCriticWrapper(policy_po, value_po).to(device)
 
-    with torch.no_grad(), set_exploration_mode("random"):
+    with torch.no_grad(), set_exploration_type(ExplorationType.RANDOM):
         td = proof_environment.rollout(max_steps=1000)
         td_device = td.to(device)
         td_device = actor_value(td_device)  # for init
     return actor_value
 
 
 def make_ppo_model(
@@ -899,15 +900,15 @@
                 ),
             )
 
         policy_operator = ProbabilisticActor(
             spec=CompositeSpec(action=action_spec),
             module=actor_module,
             in_keys=dist_in_keys,
-            default_interaction_mode="random",
+            default_interaction_type=InteractionType.RANDOM,
             distribution_class=policy_distribution_class,
             distribution_kwargs=policy_distribution_kwargs,
             return_log_prob=True,
         )
         value_net = MLP(
             num_cells=[200],
             out_features=1,
@@ -979,28 +980,28 @@
         policy_po = ProbabilisticActor(
             actor_module,
             spec=action_spec,
             in_keys=dist_in_keys,
             distribution_class=policy_distribution_class,
             distribution_kwargs=policy_distribution_kwargs,
             return_log_prob=True,
-            default_interaction_mode="random",
+            default_interaction_type=InteractionType.RANDOM,
         )
 
         value_net = MLP(
             num_cells=[400, 300],
             out_features=1,
         )
         value_po = ValueOperator(
             value_net,
             in_keys=in_keys_critic,
         )
         actor_value = ActorCriticWrapper(policy_po, value_po).to(device)
 
-    with torch.no_grad(), set_exploration_mode("random"):
+    with torch.no_grad(), set_exploration_type(ExplorationType.RANDOM):
         td = proof_environment.rollout(max_steps=1000)
         td_device = td.to(device)
         td_device = actor_value(td_device)  # for init
     return actor_value
 
 
 def make_sac_model(
@@ -1194,30 +1195,30 @@
 
     actor = ProbabilisticActor(
         spec=action_spec,
         in_keys=["loc", "scale"],
         module=actor_module,
         distribution_class=dist_class,
         distribution_kwargs=dist_kwargs,
-        default_interaction_mode="random",
+        default_interaction_type=InteractionType.RANDOM,
         return_log_prob=False,
     )
 
     qvalue = ValueOperator(
         in_keys=["action"] + in_keys,
         module=qvalue_net,
     )
     value = ValueOperator(
         in_keys=in_keys,
         module=value_net,
     )
     model = nn.ModuleList([actor, qvalue, value]).to(device)
 
     # init nets
-    with torch.no_grad(), set_exploration_mode("random"):
+    with torch.no_grad(), set_exploration_type(ExplorationType.RANDOM):
         td = proof_environment.reset()
         td = td.to(device)
         for net in model:
             net(td)
     del td
 
     return model
@@ -1437,25 +1438,25 @@
 
     actor = ProbabilisticActor(
         spec=action_spec,
         in_keys=["loc", "scale"],
         module=actor_module,
         distribution_class=dist_class,
         distribution_kwargs=dist_kwargs,
-        default_interaction_mode="random",
+        default_interaction_type=InteractionType.RANDOM,
         return_log_prob=True,
     )
     qvalue = ValueOperator(
         in_keys=in_keys_qvalue,
         module=qvalue_net,
     )
     model = nn.ModuleList([actor, qvalue]).to(device)
 
     # init nets
-    with torch.no_grad(), set_exploration_mode("random"):
+    with torch.no_grad(), set_exploration_type(ExplorationType.RANDOM):
         td = proof_environment.rollout(1000)
         td = td.to(device)
         for net in model:
             net(td)
     del td
     return model
 
@@ -1515,15 +1516,15 @@
     reward_module = MLP(
         out_features=1, depth=2, num_cells=cfg.mlp_num_units, activation_class=nn.ELU
     )
 
     world_model = _dreamer_make_world_model(
         obs_encoder, obs_decoder, rssm_prior, rssm_posterior, reward_module
     ).to(device)
-    with torch.no_grad(), set_exploration_mode("random"):
+    with torch.no_grad(), set_exploration_type(ExplorationType.RANDOM):
         tensordict = proof_environment.rollout(4)
         tensordict = tensordict.to_tensordict().to(device)
         tensordict = tensordict.to(device)
         world_model(tensordict)
 
     model_based_env = _dreamer_make_mbenv(
         reward_module,
@@ -1544,15 +1545,15 @@
         action_key,
         proof_environment,
     )
     actor_simulator = actor_simulator.to(device)
 
     value_model = _dreamer_make_value_model(cfg.mlp_num_units, value_key)
     value_model = value_model.to(device)
-    with torch.no_grad(), set_exploration_mode("random"):
+    with torch.no_grad(), set_exploration_type(ExplorationType.RANDOM):
         tensordict = model_based_env.rollout(4)
         tensordict = tensordict.to(device)
         tensordict = actor_simulator(tensordict)
         value_model(tensordict)
 
     actor_realworld = actor_realworld.to(device)
     if proof_env_is_none:
@@ -1640,15 +1641,15 @@
         action_key,
         proof_environment,
     )
     return actor_simulator, actor_realworld
 
 
 def _dreamer_make_actor_sim(action_key, proof_environment, actor_module):
-    actor_simulator = SafeProbabilisticSequential(
+    actor_simulator = SafeProbabilisticTensorDictSequential(
         SafeModule(
             actor_module,
             in_keys=["state", "belief"],
             out_keys=["loc", "scale"],
             spec=CompositeSpec(
                 **{
                     "loc": UnboundedContinuousTensorSpec(
@@ -1661,15 +1662,15 @@
                     ),
                 }
             ),
         ),
         SafeProbabilisticModule(
             in_keys=["loc", "scale"],
             out_keys=[action_key],
-            default_interaction_mode="random",
+            default_interaction_type=InteractionType.RANDOM,
             distribution_class=TanhNormal,
             spec=CompositeSpec(**{action_key: proof_environment.action_spec}),
         ),
     )
     return actor_simulator
 
 
@@ -1690,15 +1691,15 @@
             in_keys=["belief", "encoded_latents"],
             out_keys=[
                 "_",
                 "_",
                 "state",
             ],
         ),
-        SafeProbabilisticSequential(
+        SafeProbabilisticTensorDictSequential(
             SafeModule(
                 actor_module,
                 in_keys=["state", "belief"],
                 out_keys=["loc", "scale"],
                 spec=CompositeSpec(
                     **{
                         "loc": UnboundedContinuousTensorSpec(
@@ -1709,15 +1710,15 @@
                         ),
                     }
                 ),
             ),
             SafeProbabilisticModule(
                 in_keys=["loc", "scale"],
                 out_keys=[action_key],
-                default_interaction_mode="random",
+                default_interaction_type=InteractionType.RANDOM,
                 distribution_class=TanhNormal,
                 spec=CompositeSpec(
                     **{action_key: proof_environment.action_spec.to("cpu")}
                 ),
             ),
         ),
         SafeModule(
```

## torchrl/trainers/helpers/replay_buffer.py

```diff
@@ -31,14 +31,15 @@
             cfg.buffer_size,
             scratch_dir=cfg.buffer_scratch_dir,
             # device=device,  # when using prefetch, this can overload the GPU memory
         ),
         sampler=sampler,
         pin_memory=device != torch.device("cpu"),
         prefetch=cfg.buffer_prefetch,
+        batch_size=cfg.batch_size,
     )
     return buffer
 
 
 @dataclass
 class ReplayArgsConfig:
     """Generic Replay Buffer config struct."""
```

## torchrl/trainers/helpers/trainers.py

```diff
@@ -4,23 +4,24 @@
 # LICENSE file in the root directory of this source tree.
 
 from dataclasses import dataclass
 from typing import List, Optional, Union
 from warnings import warn
 
 import torch
-from tensordict.nn import TensorDictModuleWrapper
+from tensordict.nn import TensorDictModule, TensorDictModuleWrapper
 from torch import optim
 from torch.optim.lr_scheduler import CosineAnnealingLR
 
 from torchrl._utils import VERBOSE
-from torchrl.collectors.collectors import _DataCollector
+from torchrl.collectors.collectors import DataCollectorBase
 from torchrl.data import ReplayBuffer
 from torchrl.envs.common import EnvBase
-from torchrl.modules import reset_noise, SafeModule
+from torchrl.envs.utils import ExplorationType
+from torchrl.modules import reset_noise
 from torchrl.objectives.common import LossModule
 from torchrl.objectives.utils import TargetNetUpdater
 from torchrl.record.loggers import Logger
 from torchrl.trainers.trainers import (
     BatchSubSampler,
     ClearCudaCache,
     CountFramesLog,
@@ -73,27 +74,29 @@
     normalize_rewards_online_decay: float = 0.9999
     # Decay of the reward moving averaging
     sub_traj_len: int = -1
     # length of the trajectories that sub-samples must have in online settings.
 
 
 def make_trainer(
-    collector: _DataCollector,
+    collector: DataCollectorBase,
     loss_module: LossModule,
     recorder: Optional[EnvBase] = None,
     target_net_updater: Optional[TargetNetUpdater] = None,
-    policy_exploration: Optional[Union[TensorDictModuleWrapper, SafeModule]] = None,
+    policy_exploration: Optional[
+        Union[TensorDictModuleWrapper, TensorDictModule]
+    ] = None,
     replay_buffer: Optional[ReplayBuffer] = None,
     logger: Optional[Logger] = None,
     cfg: "DictConfig" = None,  # noqa: F821
 ) -> Trainer:
     """Creates a Trainer instance given its constituents.
 
     Args:
-        collector (_DataCollector): A data collector to be used to collect data.
+        collector (DataCollectorBase): A data collector to be used to collect data.
         loss_module (LossModule): A TorchRL loss module
         recorder (EnvBase, optional): a recorder environment. If None, the trainer will train the policy without
             testing it.
         target_net_updater (TargetNetUpdater, optional): A target network update object.
         policy_exploration (TDModule or TensorDictModuleWrapper, optional): a policy to be used for recording and exploration
             updates (should be synced with the learnt policy).
         replay_buffer (ReplayBuffer, optional): a replay buffer to be used to collect data.
@@ -207,15 +210,19 @@
         trainer.register_op("batch_process", SelectKeys(cfg.selected_keys))
     trainer.register_op("batch_process", lambda batch: batch.cpu())
 
     if replay_buffer is not None:
         # replay buffer is used 2 or 3 times: to register data, to sample
         # data and to update priorities
         rb_trainer = ReplayBufferTrainer(
-            replay_buffer, cfg.batch_size, memmap=False, device=device
+            replay_buffer,
+            cfg.batch_size,
+            flatten_tensordicts=False,
+            memmap=False,
+            device=device,
         )
 
         trainer.register_op("batch_process", rb_trainer.extend)
         trainer.register_op("process_optim_batch", rb_trainer.sample)
         trainer.register_op("post_loss", rb_trainer.update_priority)
     else:
         # trainer.register_op("batch_process", mask_batch)
@@ -251,30 +258,30 @@
     )
 
     if recorder is not None:
         recorder_obj = Recorder(
             record_frames=cfg.record_frames,
             frame_skip=cfg.frame_skip,
             policy_exploration=policy_exploration,
-            recorder=recorder,
+            environment=recorder,
             record_interval=cfg.record_interval,
             log_keys=cfg.recorder_log_keys,
         )
         trainer.register_op(
             "post_steps_log",
             recorder_obj,
         )
         recorder_obj(None)
         recorder_obj_explore = Recorder(
             record_frames=cfg.record_frames,
             frame_skip=cfg.frame_skip,
             policy_exploration=policy_exploration,
-            recorder=recorder,
+            environment=recorder,
             record_interval=cfg.record_interval,
-            exploration_mode="random",
+            exploration_type=ExplorationType.RANDOM,
             suffix="exploration",
             out_keys={("next", "reward"): "r_evaluation_exploration"},
         )
         trainer.register_op(
             "post_steps_log",
             recorder_obj_explore,
         )
```

## Comparing `torchrl-0.1.0.dist-info/LICENSE` & `torchrl-0.1.1.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `torchrl-0.1.0.dist-info/METADATA` & `torchrl-0.1.1.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: torchrl
-Version: 0.1.0
+Version: 0.1.1
 Summary: UNKNOWN
 Home-page: https://github.com/pytorch/rl
 Author: torchrl contributors
 Author-email: vmoens@fb.com
 License: BSD
 Platform: UNKNOWN
 Classifier: Programming Language :: Python :: 3.7
@@ -20,15 +20,15 @@
 Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
 Description-Content-Type: text/markdown
 License-File: LICENSE
 Requires-Dist: torch
 Requires-Dist: numpy
 Requires-Dist: packaging
 Requires-Dist: cloudpickle
-Requires-Dist: tensordict (>=0.0.3)
+Requires-Dist: tensordict (>=0.1.1)
 Provides-Extra: atari
 Requires-Dist: gym (<=0.24) ; extra == 'atari'
 Requires-Dist: atari-py ; extra == 'atari'
 Requires-Dist: ale-py ; extra == 'atari'
 Requires-Dist: gym[accept-rom-license] ; extra == 'atari'
 Requires-Dist: pygame ; extra == 'atari'
 Provides-Extra: checkpointing
@@ -50,14 +50,15 @@
 Requires-Dist: wandb ; extra == 'utils'
 Requires-Dist: tqdm ; extra == 'utils'
 Requires-Dist: hydra-core (>=1.1) ; extra == 'utils'
 Requires-Dist: hydra-submitit-launcher ; extra == 'utils'
 
 [![pytorch](https://circleci.com/gh/pytorch/rl.svg?style=shield)](https://circleci.com/gh/pytorch/rl)
 [![Documentation](https://img.shields.io/badge/Documentation-blue.svg)](https://pytorch.org/rl/)
+[![Benchmarks](https://img.shields.io/badge/Benchmarks-blue.svg)](https://pytorch.github.io/rl/dev/bench/)
 [![codecov](https://codecov.io/gh/pytorch/rl/branch/main/graph/badge.svg?token=HcpK1ILV6r)](https://codecov.io/gh/pytorch/rl)
 [![Twitter Follow](https://img.shields.io/twitter/follow/torchrl1?style=social)](https://twitter.com/torchrl1)
 [![Python 3.7, 3.8](https://img.shields.io/badge/python-3.7%20%7C%203.8%20%7C%203.9%20%7C%203.10-blue.svg)](https://www.python.org/downloads/)
 [![GitHub license](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/pytorch/rl/blob/main/LICENSE)
 <a href="https://pypi.org/project/torchrl"><img src="https://img.shields.io/pypi/v/torchrl" alt="pypi version"></a>
 <a href="https://pypi.org/project/torchrl-nightly"><img src="https://img.shields.io/pypi/v/torchrl-nightly?label=nightly" alt="pypi nightly version"></a>
 [![Downloads](https://static.pepy.tech/personalized-badge/torchrl?period=total&units=international_system&left_color=blue&right_color=orange&left_text=Downloads)](https://pepy.tech/project/torchrl)
@@ -459,18 +460,18 @@
   policy_module = SafeModule(
       NormalParamsWrapper(
           MLP(num_cells=[64, 64], out_features=32, activation=nn.ELU)
       ),
       in_keys=["hidden"],
       out_keys=["loc", "scale"],
   )
-  # Use a SafeProbabilisticSequential to combine the SafeModule with a
+  # Use a SafeProbabilisticTensorDictSequential to combine the SafeModule with a
   # SafeProbabilisticModule, indicating how to build the
   # torch.distribution.Distribution object and what to do with it
-  policy_module = SafeProbabilisticSequential(  # stochastic policy
+  policy_module = SafeProbabilisticTensorDictSequential(  # stochastic policy
       policy_module,
       SafeProbabilisticModule(
           in_keys=["loc", "scale"],
           out_keys="action",
           distribution_class=TanhNormal,
       ),
   )
@@ -489,17 +490,17 @@
 - exploration [wrappers](torchrl/modules/tensordict_module/exploration.py) and
   [modules](torchrl/modules/models/exploration.py) to easily swap between exploration and exploitation<sup>(1)</sup>:
   <details>
     <summary>Code</summary>
 
   ```python
   policy_explore = EGreedyWrapper(policy)
-  with set_exploration_mode("random"):
+  with set_exploration_type(ExplorationType.RANDOM):
       tensordict = policy_explore(tensordict)  # will use eps-greedy
-  with set_exploration_mode("mode"):
+  with set_exploration_type(ExplorationType.MODE):
       tensordict = policy_explore(tensordict)  # will not use eps-greedy
   ```
   </details>
 
 - A series of efficient [loss modules](https://github.com/pytorch/rl/tree/main/torchrl/objectives)
   and highly vectorized
   [functional return and advantage](https://github.com/pytorch/rl/blob/main/torchrl/objectives/value/functional.py)
@@ -539,15 +540,15 @@
 ## Examples, tutorials and demos
 
 A series of [examples](examples/) are provided with an illustrative purpose:
 - [DQN and Rainbow](examples/dqn/dqn.py)
 - [DDPG](examples/ddpg/ddpg.py)
 - [IQL](examples/iql/iql.py)
 - [TD3](examples/td3/td3.py)
-- [A2C](examples/a2c/a2c.py)
+- [A2C](examples/a2c_old/a2c.py)
 - [PPO](examples/ppo/ppo.py)
 - [SAC](examples/sac/sac.py)
 - [REDQ](examples/redq/redq.py)
 - [Dreamer](examples/dreamer/dreamer.py)
 
 and many more to come!
 
@@ -692,15 +693,15 @@
 
 If you're using TorchRL, please refer to this BibTeX entry to cite this work:
 ```
 @software{TorchRL,
   author = {Moens, Vincent},
   title = {{TorchRL: an open-source Reinforcement Learning (RL) library for PyTorch}},
   url = {https://github.com/pytorch/rl},
-  version = {0.1.0},
+  version = {0.1.1},
   year = {2023}
 }
 ```
 
 ## Contributing
 
 Internal collaborations to torchrl are welcome! Feel free to fork, submit issues and PRs.
```

### html2text {}

```diff
@@ -1,20 +1,20 @@
-Metadata-Version: 2.1 Name: torchrl Version: 0.1.0 Summary: UNKNOWN Home-page:
+Metadata-Version: 2.1 Name: torchrl Version: 0.1.1 Summary: UNKNOWN Home-page:
 https://github.com/pytorch/rl Author: torchrl contributors Author-email:
 vmoens@fb.com License: BSD Platform: UNKNOWN Classifier: Programming Language
 :: Python :: 3.7 Classifier: Programming Language :: Python :: 3.8 Classifier:
 Programming Language :: Python :: 3.9 Classifier: Programming Language ::
 Python :: 3.10 Classifier: License :: OSI Approved :: MIT License Classifier:
 Operating System :: OS Independent Classifier: Development Status :: 4 - Beta
 Classifier: Intended Audience :: Developers Classifier: Intended Audience ::
 Science/Research Classifier: License :: OSI Approved :: BSD License Classifier:
 Topic :: Scientific/Engineering :: Artificial Intelligence Description-Content-
 Type: text/markdown License-File: LICENSE Requires-Dist: torch Requires-Dist:
 numpy Requires-Dist: packaging Requires-Dist: cloudpickle Requires-Dist:
-tensordict (>=0.0.3) Provides-Extra: atari Requires-Dist: gym (<=0.24) ; extra
+tensordict (>=0.1.1) Provides-Extra: atari Requires-Dist: gym (<=0.24) ; extra
 == 'atari' Requires-Dist: atari-py ; extra == 'atari' Requires-Dist: ale-py ;
 extra == 'atari' Requires-Dist: gym[accept-rom-license] ; extra == 'atari'
 Requires-Dist: pygame ; extra == 'atari' Provides-Extra: checkpointing
 Requires-Dist: torchsnapshot ; extra == 'checkpointing' Provides-Extra:
 dm_control Requires-Dist: dm-control ; extra == 'dm_control' Provides-Extra:
 gym_continuous Requires-Dist: mujoco-py ; extra == 'gym_continuous' Requires-
 Dist: mujoco ; extra == 'gym_continuous' Provides-Extra: rendering Requires-
@@ -23,18 +23,20 @@
 Dist: pytest-instafail ; extra == 'tests' Requires-Dist: scipy ; extra ==
 'tests' Provides-Extra: utils Requires-Dist: tensorboard ; extra == 'utils'
 Requires-Dist: wandb ; extra == 'utils' Requires-Dist: tqdm ; extra == 'utils'
 Requires-Dist: hydra-core (>=1.1) ; extra == 'utils' Requires-Dist: hydra-
 submitit-launcher ; extra == 'utils' [![pytorch](https://circleci.com/gh/
 pytorch/rl.svg?style=shield)](https://circleci.com/gh/pytorch/rl) [!
 [Documentation](https://img.shields.io/badge/Documentation-blue.svg)](https://
-pytorch.org/rl/) [![codecov](https://codecov.io/gh/pytorch/rl/branch/main/
-graph/badge.svg?token=HcpK1ILV6r)](https://codecov.io/gh/pytorch/rl) [![Twitter
-Follow](https://img.shields.io/twitter/follow/torchrl1?style=social)](https://
-twitter.com/torchrl1) [![Python 3.7, 3.8](https://img.shields.io/badge/python-
+pytorch.org/rl/) [![Benchmarks](https://img.shields.io/badge/Benchmarks-
+blue.svg)](https://pytorch.github.io/rl/dev/bench/) [![codecov](https://
+codecov.io/gh/pytorch/rl/branch/main/graph/badge.svg?token=HcpK1ILV6r)](https:/
+/codecov.io/gh/pytorch/rl) [![Twitter Follow](https://img.shields.io/twitter/
+follow/torchrl1?style=social)](https://twitter.com/torchrl1) [![Python 3.7,
+3.8](https://img.shields.io/badge/python-
 3.7%20%7C%203.8%20%7C%203.9%20%7C%203.10-blue.svg)](https://www.python.org/
 downloads/) [![GitHub license](https://img.shields.io/badge/license-MIT-
 blue.svg)](https://github.com/pytorch/rl/blob/main/LICENSE) [pypi_version]
 [pypi_nightly_version] [![Downloads](https://static.pepy.tech/personalized-
 badge/
 torchrl?period=total&units=international_system&left_color=blue&right_color=orange&left_text=Downloads)]
 (https://pepy.tech/project/torchrl) [![Downloads](https://static.pepy.tech/
@@ -224,59 +226,60 @@
 ) # Wrap it in a SafeModule, indicating what key to read in and where to #
 write out the output common_module = SafeModule( common_module, in_keys=
 ["pixels"], out_keys=["hidden"], ) # Wrap the policy module in
 NormalParamsWrapper, such that the output # tensor is split in loc and scale,
 and scale is mapped onto a positive space policy_module = SafeModule
 ( NormalParamsWrapper( MLP(num_cells=[64, 64], out_features=32,
 activation=nn.ELU) ), in_keys=["hidden"], out_keys=["loc", "scale"], ) # Use a
-SafeProbabilisticSequential to combine the SafeModule with a #
+SafeProbabilisticTensorDictSequential to combine the SafeModule with a #
 SafeProbabilisticModule, indicating how to build the #
 torch.distribution.Distribution object and what to do with it policy_module =
-SafeProbabilisticSequential( # stochastic policy policy_module,
+SafeProbabilisticTensorDictSequential( # stochastic policy policy_module,
 SafeProbabilisticModule( in_keys=["loc", "scale"], out_keys="action",
 distribution_class=TanhNormal, ), ) value_module = MLP( num_cells=[64, 64],
 out_features=1, activation=nn.ELU, ) # Wrap the policy and value funciton in a
 common module actor_value = ActorValueOperator(common_module, policy_module,
 value_module) # standalone policy from this standalone_policy =
 actor_value.get_policy_operator() ```  - exploration [wrappers](torchrl/
 modules/tensordict_module/exploration.py) and [modules](torchrl/modules/models/
 exploration.py) to easily swap between exploration and exploitation(1):  Code
-```python policy_explore = EGreedyWrapper(policy) with set_exploration_mode
-("random"): tensordict = policy_explore(tensordict) # will use eps-greedy with
-set_exploration_mode("mode"): tensordict = policy_explore(tensordict) # will
-not use eps-greedy ```  - A series of efficient [loss modules](https://
-github.com/pytorch/rl/tree/main/torchrl/objectives) and highly vectorized
-[functional return and advantage](https://github.com/pytorch/rl/blob/main/
-torchrl/objectives/value/functional.py) computation.  Code ### Loss modules
-```python from torchrl.objectives import DQNLoss loss_module = DQNLoss
-(value_network=value_network, gamma=0.99) tensordict = replay_buffer.sample
-(batch_size) loss = loss_module(tensordict) ``` ### Advantage computation
-```python from torchrl.objectives.value.functional import
-vec_td_lambda_return_estimate advantage = vec_td_lambda_return_estimate(gamma,
-lmbda, next_state_value, reward, done) ```  - a generic [trainer class]
-(torchrl/trainers/trainers.py)(1) that executes the aforementioned training
-loop. Through a hooking mechanism, it also supports any logging or data
-transformation operation at any given time. - various [recipes](torchrl/
-trainers/helpers/models.py) to build models that correspond to the environment
-being deployed. If you feel a feature is missing from the library, please
-submit an issue! If you would like to contribute to new features, check our
-[call for contributions](https://github.com/pytorch/rl/issues/509) and our
-[contribution](CONTRIBUTING.md) page. ## Examples, tutorials and demos A series
-of [examples](examples/) are provided with an illustrative purpose: - [DQN and
-Rainbow](examples/dqn/dqn.py) - [DDPG](examples/ddpg/ddpg.py) - [IQL](examples/
-iql/iql.py) - [TD3](examples/td3/td3.py) - [A2C](examples/a2c/a2c.py) - [PPO]
-(examples/ppo/ppo.py) - [SAC](examples/sac/sac.py) - [REDQ](examples/redq/
-redq.py) - [Dreamer](examples/dreamer/dreamer.py) and many more to come! Check
-the [examples markdown](examples/EXAMPLES.md) directory for more details about
-handling the various configuration settings. We also provide [tutorials and
-demos](https://pytorch.org/rl/#tutorials) that give a sense of what the library
-can do. ## Installation Create a conda environment where the packages will be
-installed. ``` conda create --name torch_rl python=3.9 conda activate torch_rl
-``` **PyTorch** Depending on the use of functorch that you want to make, you
-may want to install the latest (nightly) PyTorch release or the latest stable
+```python policy_explore = EGreedyWrapper(policy) with set_exploration_type
+(ExplorationType.RANDOM): tensordict = policy_explore(tensordict) # will use
+eps-greedy with set_exploration_type(ExplorationType.MODE): tensordict =
+policy_explore(tensordict) # will not use eps-greedy ```  - A series of
+efficient [loss modules](https://github.com/pytorch/rl/tree/main/torchrl/
+objectives) and highly vectorized [functional return and advantage](https://
+github.com/pytorch/rl/blob/main/torchrl/objectives/value/functional.py)
+computation.  Code ### Loss modules ```python from torchrl.objectives import
+DQNLoss loss_module = DQNLoss(value_network=value_network, gamma=0.99)
+tensordict = replay_buffer.sample(batch_size) loss = loss_module(tensordict)
+``` ### Advantage computation ```python from
+torchrl.objectives.value.functional import vec_td_lambda_return_estimate
+advantage = vec_td_lambda_return_estimate(gamma, lmbda, next_state_value,
+reward, done) ```  - a generic [trainer class](torchrl/trainers/trainers.py)(1)
+that executes the aforementioned training loop. Through a hooking mechanism, it
+also supports any logging or data transformation operation at any given time. -
+various [recipes](torchrl/trainers/helpers/models.py) to build models that
+correspond to the environment being deployed. If you feel a feature is missing
+from the library, please submit an issue! If you would like to contribute to
+new features, check our [call for contributions](https://github.com/pytorch/rl/
+issues/509) and our [contribution](CONTRIBUTING.md) page. ## Examples,
+tutorials and demos A series of [examples](examples/) are provided with an
+illustrative purpose: - [DQN and Rainbow](examples/dqn/dqn.py) - [DDPG]
+(examples/ddpg/ddpg.py) - [IQL](examples/iql/iql.py) - [TD3](examples/td3/
+td3.py) - [A2C](examples/a2c_old/a2c.py) - [PPO](examples/ppo/ppo.py) - [SAC]
+(examples/sac/sac.py) - [REDQ](examples/redq/redq.py) - [Dreamer](examples/
+dreamer/dreamer.py) and many more to come! Check the [examples markdown]
+(examples/EXAMPLES.md) directory for more details about handling the various
+configuration settings. We also provide [tutorials and demos](https://
+pytorch.org/rl/#tutorials) that give a sense of what the library can do. ##
+Installation Create a conda environment where the packages will be installed.
+``` conda create --name torch_rl python=3.9 conda activate torch_rl ```
+**PyTorch** Depending on the use of functorch that you want to make, you may
+want to install the latest (nightly) PyTorch release or the latest stable
 version of PyTorch. See [here](https://pytorch.org/get-started/locally/) for a
 detailed list of commands, including `pip3` or windows/OSX compatible
 installation commands. **Torchrl** You can install the **latest stable
 release** by using ``` pip3 install torchrl ``` This should work on linux and
 MacOs (not M1). For Windows and M1/M2 machines, one should install the library
 locally (see below). The **nightly build** can be installed via ``` pip install
 torchrl-nightly ``` To install extra dependencies, call ``` pip3 install
@@ -318,15 +321,15 @@
 complete explanation and proposed workarounds. ## Asking a question If you spot
 a bug in the library, please raise an issue in this repo. If you have a more
 generic question regarding RL in PyTorch, post it on the [PyTorch forum](https:
 //discuss.pytorch.org/c/reinforcement-learning/6). ## Citation If you're using
 TorchRL, please refer to this BibTeX entry to cite this work: ``` @software
 {TorchRL, author = {Moens, Vincent}, title = {{TorchRL: an open-source
 Reinforcement Learning (RL) library for PyTorch}}, url = {https://github.com/
-pytorch/rl}, version = {0.1.0}, year = {2023} } ``` ## Contributing Internal
+pytorch/rl}, version = {0.1.1}, year = {2023} } ``` ## Contributing Internal
 collaborations to torchrl are welcome! Feel free to fork, submit issues and
 PRs. You can checkout the detailed contribution guide [here](CONTRIBUTING.md).
 As mentioned above, a list of open contributions can be found in [here](https:/
 /github.com/pytorch/rl/issues/509). Contributors are recommended to install
 [pre-commit hooks](https://pre-commit.com/) (using `pre-commit install`). pre-
 commit will check for linting related issues when the code is commited locally.
 You can disable th check by appending `-n` to your commit command: `git commit
```

## Comparing `torchrl-0.1.0.dist-info/RECORD` & `torchrl-0.1.1.dist-info/RECORD`

 * *Files 18% similar despite different names*

```diff
@@ -1,122 +1,127 @@
 build_tools/__init__.py,sha256=5xRGSM4YMr794wxfVj_SQly2cyHNyhXTdXdWUZJoM2M,183
 build_tools/setup_helpers/__init__.py,sha256=uwhUMyZq6dm1J5T_rjItc0aZb8-WSJFYd81pU3aJQsE,245
 build_tools/setup_helpers/extension.py,sha256=8u0VrdMo3WzXp1V9KrB_tq2EfkGkWncQ6G8yzW8gcyo,6085
 torchrl/__init__.py,sha256=cOWCLNeRq7gnOXqFzcFKPm93wefcLaa1LgWRe59xmUI,957
 torchrl/_extension.py,sha256=N01cFr5HT6P8G81alGHUWFGVWHHeTgJAJT88Lz6MZRk,868
-torchrl/_torchrl.pyd,sha256=hhpPYCgZa-oOCyviNaDN2umt3pgVhS24QjFgJmQOERk,330240
-torchrl/_utils.py,sha256=Bv3-PbVOUi4Q3chIUgJy8sWePBRPHGlHs5U9-iy98yc,9652
-torchrl/collectors/__init__.py,sha256=-ur4at2x3PJn214IxsJ5IGb8MHogQTy1bXei-tZC-cA,323
-torchrl/collectors/collectors.py,sha256=0JZ9CsOOEEPLO5V0e9C7omfjOsRgzfqIdjG8zOkNG44,87773
+torchrl/_torchrl.pyd,sha256=iRgbTFblTaxfpf_zLYaPBsnwy5c9W3ssyNKV3fJGCyg,330240
+torchrl/_utils.py,sha256=sPsco15Ls8RU-i3ubdGhg7eoNzfLev10v45phgu87X4,17746
+torchrl/collectors/__init__.py,sha256=Wbyd0dYtj4Oe-XLTlT5VG4yl0cHhLjXjmxA-8L0bjp8,366
+torchrl/collectors/collectors.py,sha256=0MWgB4HC-2EuXQdb8Vact6Y9r81NRt64OJOSLbjWuPM,97240
 torchrl/collectors/utils.py,sha256=D9ggquoMMQhvasgRNTMBvZicMpRvYKOzp2zwWVIviQo,3847
-torchrl/collectors/distributed/__init__.py,sha256=SLeg4HQpxTmCNYITLhM0Ug3OnI3mXVVxTMh3CEZwbbw,381
+torchrl/collectors/distributed/__init__.py,sha256=5qoBlS2wvrEFc9SRGwNMDcvCJ_XukVLyyvX7MwN9slU,412
 torchrl/collectors/distributed/default_configs.py,sha256=RkY8hmAzDttCXAjfoqdvAsCSwaXdtN4AGWJ70hSUmic,674
-torchrl/collectors/distributed/generic.py,sha256=5rtlGJNYflRKMS5RLWp-d97YSdakDJJyF5Zpgxg91ZI,33562
-torchrl/collectors/distributed/rpc.py,sha256=d9Tk9jK3PKuKaBTdacE9IhicEVriptPKiTfZ05-e0bM,27373
-torchrl/collectors/distributed/sync.py,sha256=OoNzeEruza1hKNhVeNmnx5rNDV0AXqczxgmo2e4NGaY,19805
-torchrl/collectors/distributed/utils.py,sha256=UaMvCRTEm6hRCPMIhbflvETBZUo8cKrKcnfP77CBm3E,6005
-torchrl/data/__init__.py,sha256=Ra4UvIay2QToeUx5_owFbFm0wZeDhr09lklnEfOb9tU,822
-torchrl/data/tensor_specs.py,sha256=JhYA8EpcEX819W3uYSe1Y-PzGvKHuImUf8e0A32dmu0,79465
+torchrl/collectors/distributed/generic.py,sha256=QPJtNsB6niAbVkvhLoWwjGkNp6uKvew3tK1Y69NQgQM,34086
+torchrl/collectors/distributed/ray.py,sha256=j_9OOcoMsVSg11MhHMKqR5WR4XHuD_JRCzVq4_ZvNyE,27837
+torchrl/collectors/distributed/rpc.py,sha256=slSbSiVgMsfTd7eYOQ748ctF19hXnr3-frWrgd6PBSc,27697
+torchrl/collectors/distributed/sync.py,sha256=8_oTr7m0kkSNlAEbkhT7ZPqsf3nB8Fxg_Soju9yeBjk,20055
+torchrl/collectors/distributed/utils.py,sha256=M6s0Z2NBzukTnDKrcRtoIB2cj9xFU1f0git3cjnsaBU,6244
+torchrl/data/__init__.py,sha256=h1ag8XFzEpUXIe8xbQCLNXk5KfW8-S7hFeeCJ0248OU,905
+torchrl/data/tensor_specs.py,sha256=DPoXeijOvE4Y_p5xe31B4rOX9yZn6tb8Rd6p17lZA8g,118083
 torchrl/data/utils.py,sha256=7ng9E6GM--i0yeFFQSyCUAHZ5NMKCQ_x9c0ps_fw3MU,2061
-torchrl/data/datasets/__init__.py,sha256=GABwY7wxoUnwX1k_eP-vAH_O-0mZ1RcTlmgCrV0yl5Y,40
-torchrl/data/datasets/d4rl.py,sha256=AfZGQqZw2_Ex6O95K5n0vMKUGQ9w5_dbawuIrNUkvHM,11118
+torchrl/data/datasets/__init__.py,sha256=JBXEjRRaZyPmX7dMKDp4hEHT84JscNSgt8eeI-LLc7w,84
+torchrl/data/datasets/d4rl.py,sha256=fy7puhFbgRXYib_0HNLmZs9qBm3xg_xfl6mne8Ebn3Q,12501
+torchrl/data/datasets/openml.py,sha256=2gf11rEdVlj_28egD4WDuF83_JPDderPWfQtFjqkFgU,6333
 torchrl/data/postprocs/__init__.py,sha256=DG7YUtvdqTYkGfgqLaF-bneXlzvAM8h00WqhSjavWa4,219
-torchrl/data/postprocs/postprocs.py,sha256=SMrl1aTSfLFrf1yHxlPWqQL-TwwY9SR8lCSb5EgBRtY,9361
+torchrl/data/postprocs/postprocs.py,sha256=Xh8HbkMM8kiULvjezygFSik6uv7WvlDnjxvrI-0pZMs,9361
 torchrl/data/replay_buffers/__init__.py,sha256=QWJpIckkHgC4b3x1lDQxj9y3d2_x9rm7B5rmwG0WFoo,620
-torchrl/data/replay_buffers/replay_buffers.py,sha256=QR16Fuq8yLatc6vVz3Br1UtQ3Uqpg3mbhZpvLg1uUrg,25854
-torchrl/data/replay_buffers/samplers.py,sha256=F7f0OJ-5OPDAZ_WwxsfBD2Bc7Si3KDjp5BIHoWfG0A8,11363
-torchrl/data/replay_buffers/storages.py,sha256=SsfKpUzLarGHCry0mAwqph3am8Vf0DwxITi_5jPVuVQ,16631
+torchrl/data/replay_buffers/replay_buffers.py,sha256=s91X2hVM_QqJBccPkA0RnamS17Tw_Tk-VdVfObD403w,42723
+torchrl/data/replay_buffers/samplers.py,sha256=gEyLZKC5waeI17LFGskKnN4_xQ5G93bTvvnQG_6D4lc,11538
+torchrl/data/replay_buffers/storages.py,sha256=HL5_1lqDA_gcQa-7Un5DpjT6wDfo-YstzgmZ3fZ2Av8,17810
 torchrl/data/replay_buffers/utils.py,sha256=AMqZHEaFigINSlulfq_duCD4D70F1yRXkMsDhzOv5pA,1079
 torchrl/data/replay_buffers/writers.py,sha256=QZJcV3kNyuQurrWJ9DTaAU9CCymP0C1FjDQRUhPf4ik,2486
-torchrl/envs/__init__.py,sha256=ys4kplqqMq74fJjCEFNPlKEvqE1HwXttG6v5xmKXj-g,1258
-torchrl/envs/common.py,sha256=UAmzr65b9MLmTknaNrKo4gBFSlAddCDkDGziZ-MWmNA,37573
+torchrl/envs/__init__.py,sha256=zjdiL1G5MZOUdBEo3Z6AVDLuv9S9CEhOlXkAHhcy1jU,1515
+torchrl/envs/common.py,sha256=NSdZNECXTsmAjsOpSXaL9yfv_HNjs7gkOyuWz0lIm4o,43940
 torchrl/envs/env_creator.py,sha256=4YHoWHyRxzbBJjLPo3kFL_1rRCAKCcHkNCQBYEXbhR4,7603
-torchrl/envs/gym_like.py,sha256=IJ9YxJR3WB4h5NLJqYq6UKpvRqHpFu9mKGGCS7cRmow,12623
-torchrl/envs/utils.py,sha256=3zU1mcslz-xJAMyiSGG-3MMq7v9pT_HcN3R72p70khU,15289
-torchrl/envs/vec_env.py,sha256=nwpuXyXDuhS7GYI5UUr1TvLyxbW2RFmqUYRKAwMJGB8,51335
+torchrl/envs/gym_like.py,sha256=nbr0SGyKNfMmdMKllaTYvxaPEuYsrACs_-2PmVkCq2I,12626
+torchrl/envs/utils.py,sha256=hyGHLxjYNCHVGoUU_9vwuDalB6xgqkT0yMQSkJJA6b8,18346
+torchrl/envs/vec_env.py,sha256=8NAQvMlbf7IwT-9HEhCc68OhxBAsfUOHkyjEkVr0B2w,52854
 torchrl/envs/libs/__init__.py,sha256=5xRGSM4YMr794wxfVj_SQly2cyHNyhXTdXdWUZJoM2M,183
-torchrl/envs/libs/brax.py,sha256=VShUNEELIck5mcx05gUT_brUjxsMBLJhHsYk5DwFzCM,14334
-torchrl/envs/libs/dm_control.py,sha256=Xefsdrz9XHLjHR1ZaJVQJz43YNlkJdvW-ksGGn1XCis,12161
-torchrl/envs/libs/gym.py,sha256=lHq_4xwlzFmJ3W58pEeuBC4TdP-L_pyxwimDqo42yxc,18339
-torchrl/envs/libs/habitat.py,sha256=L8E4Zzw4EU2pzhM9W-0pn5Ere2dTSUxUGogEc-LRuuY,2902
-torchrl/envs/libs/jax_utils.py,sha256=HSYLG1vTNwknYN8trSPmxkdDCjy-PYymXNiTXh_Ocw0,4305
-torchrl/envs/libs/jumanji.py,sha256=TiQ9pzML8B1cp1XVxmX0KTAoeHJGvSrvSKTIJypJfVA,12761
-torchrl/envs/libs/utils.py,sha256=lKYp5rscdocVQglpfI5crqGE3BeikBlGEmcfwX5RF9M,5265
-torchrl/envs/libs/vmas.py,sha256=YZpFmNYp5OlipZVDDELNm-SfW1xb5JIbsh2cjVc7tmk,16414
+torchrl/envs/libs/brax.py,sha256=U5vRVvj9U8vQhK-OzVnU56Zj267cUhh8-WqDXkQ6y7A,15512
+torchrl/envs/libs/dm_control.py,sha256=-ShX_8-e3s5f8m9sQPZ9tIQE0KuRfc8oBCgVj1tPu1I,12169
+torchrl/envs/libs/gym.py,sha256=Z3RGE0WCZFtFciYiKZMNNo5WMxqUDWv4ypT5PkJ1xgA,25967
+torchrl/envs/libs/habitat.py,sha256=z2Wh3F4jWZGvdU5_3Sl4NQf3jVinqzTMYyyfJnfVXJ8,2857
+torchrl/envs/libs/jax_utils.py,sha256=NEeX2k5zyXW5d0hJqExbwYyQltZSWn0pzahuUmw_o9s,4699
+torchrl/envs/libs/jumanji.py,sha256=qsu6k0RyoE7lWVnSAgp3qaxdJiLu6gs7ZjeoLlh-P44,12836
+torchrl/envs/libs/openml.py,sha256=5iOhK-gyQldwIm30ugz0ySIxWPOn0Ix56l6Rhx6P0cM,5260
+torchrl/envs/libs/utils.py,sha256=s6MI4Lg1uzI0YRNXLDZfmChlDhmYECq9UQB4o3gVXPQ,5319
+torchrl/envs/libs/vmas.py,sha256=DqLOGuwGEp30YBjJNQZsTbTTu-UYxY4TM177X-a893c,18211
 torchrl/envs/model_based/__init__.py,sha256=RbHJKAHB05r2rISOy79qA5QW-iDfDNmCFXdSw6ZQfyQ,224
-torchrl/envs/model_based/common.py,sha256=VVO-yrEYWLfEXDxees0o2V5UeJE-JVW8jSK0syB-YS0,8025
-torchrl/envs/model_based/dreamer.py,sha256=w4XlPdFnAOuRQ_0h66s7jFg-LE1rkfjKsiaCfm6lpSs,2792
-torchrl/envs/transforms/__init__.py,sha256=026l-umaZlE1zDg_KG_rQFBQmT1Z2Ejd9QU-5x4_LiQ,996
+torchrl/envs/model_based/common.py,sha256=L4tHAMT2sk9aH35Y0Hd0aMT6DBaCXrIs6YAvGhDuoiU,8029
+torchrl/envs/model_based/dreamer.py,sha256=DHRMDnin--U2XATJBL3HSbXZLelRWo5R8q199poH9-k,2790
+torchrl/envs/transforms/__init__.py,sha256=4riL4ELuRmeBA9-q31t7TilKW4sCPFXTQOpMr6e28xQ,1040
 torchrl/envs/transforms/functional.py,sha256=yyLZRk246UEUEXjdbzfLNY0tDR9O32QsoqoQ_tAxkPU,1485
-torchrl/envs/transforms/r3m.py,sha256=QdMP0dNvW8-DUlkgmwG0xJBW0HRP5yR-CZ-b_ct66C4,13722
-torchrl/envs/transforms/transforms.py,sha256=EFow_cDtWd_W9b9n19IrajNh08eF0Q4izO-1J8kWZ_A,141937
+torchrl/envs/transforms/r3m.py,sha256=5iWJEGH3UDZnZGaI_mII4Qssc-RHZ91xjiBg3iIwtBk,13726
+torchrl/envs/transforms/transforms.py,sha256=Dz1ZujdZYdvf4-6x6vis5QleFN_PMOrVG7Z_FM09yf0,166778
 torchrl/envs/transforms/utils.py,sha256=QffY6UmUQGOu5fg61M0J1aJlGQmdK0iFZHRM9uE58TQ,408
-torchrl/envs/transforms/vip.py,sha256=jrTMTGRZSK_76vsEjED5wIA4OkpbtXjURwbr7t2GlTU,14083
-torchrl/modules/__init__.py,sha256=OGsZdfM-fQAcnjWZohgxkogpuh0GoiTWsQKNvbtifnw,1269
-torchrl/modules/distributions/__init__.py,sha256=q5ADqWZMCsTTN9PzQAoe5EP71wUNGyRwfPBj1H8l7LE,581
-torchrl/modules/distributions/continuous.py,sha256=g0NeLmiGwtMxQct-hq7m844DtqEvJBIuV8wM48PEMeU,21186
-torchrl/modules/distributions/discrete.py,sha256=48c1xTjdyTpR51KouEtCK8PjWPYBYfNzHk7tuuqUGDo,2619
+torchrl/envs/transforms/vip.py,sha256=NO4TlDdDBii8JgwV9IOOI4_UdvyeJLQ9N7b1HbE1rH0,14087
+torchrl/modules/__init__.py,sha256=JC7AZoAmcj8urrYD4h8txA5NYQw8rUHbJ6nQwtbC5SY,1420
+torchrl/modules/distributions/__init__.py,sha256=qmiRUETpiycLvNHxbKtPl4_ZCbPDyAQPghdNOfxd8PI,600
+torchrl/modules/distributions/continuous.py,sha256=0htqTNH-9hh3Pmut8EjgS5LkWh1iWoeQMpWtS6ATcYg,21253
+torchrl/modules/distributions/discrete.py,sha256=axz7CvwYEEBZB7sabLLhDCplT0P5ohUYLrcSgzcw560,9293
 torchrl/modules/distributions/truncated_normal.py,sha256=NQ1p5oFGCr-jojzVEHM_gDanMQItqocgtrCg5u8BErI,5988
-torchrl/modules/distributions/utils.py,sha256=8sfNjuNlb69xCHj-NvRERqvpVaHfYjVtEzCBPB8FmdA,1133
+torchrl/modules/distributions/utils.py,sha256=HxwsWknmWb0O6gcK6rrHPHst6qbpL7822LBXwXdvQlw,3841
 torchrl/modules/models/__init__.py,sha256=9F6tvu3wZP1JgzmqPjssOtxdtRYgnZZZvJc1C8ia7EM,580
-torchrl/modules/models/exploration.py,sha256=esJpN_xTRQZzfbDTKl7D5g8yLp-eytDHXNasCtq5z-E,20146
-torchrl/modules/models/model_based.py,sha256=2H0zT_TrD_ttixZhdY4TkY8aZVE810Uc2cqaJ2Nfct0,11860
-torchrl/modules/models/models.py,sha256=ZszL88XOmeFS97MDh7XPLYME-WvfXfWFD8toFzqGyxw,43772
+torchrl/modules/models/exploration.py,sha256=4Ixql_q3LIpIYcI4FIwoD4oTX_Y6iHQjcO4rOoYWe5g,20516
+torchrl/modules/models/model_based.py,sha256=vLHkYV-6Nq-J3GTi5DtA0vwncZCCZYh6ZYbW1dDy8HQ,11863
+torchrl/modules/models/models.py,sha256=EGV-4qH73xvysm43CFr_L6EOg1CM7ld680POzJatDtc,45667
 torchrl/modules/models/utils.py,sha256=TKji7lSi_1jgEqqC6kJ-TOOgNuVbbk2seM348uK7THk,4023
 torchrl/modules/planners/__init__.py,sha256=xxRLqxJcXo38KjFeZiNuSoD8l6u-kPsZ4PRsWCdzqZA,281
-torchrl/modules/planners/cem.py,sha256=FExJUt5GHcsQP0gZHrEJRnYXDwR3fvBdFULVPUlAzlc,9147
+torchrl/modules/planners/cem.py,sha256=vJWn7h0x1UcqhMNgo1k2YVVMF6IKerPy3yghE3PJaOs,9572
 torchrl/modules/planners/common.py,sha256=FbL8WstVp1QY8_YHlaH3EFpsd9I_CMn1JWx7z5SlbRk,2455
-torchrl/modules/planners/mppi.py,sha256=QWzVxssafJKUoS-TozdOKuetXtGJA2-oDIbeJlsaQPI,10333
-torchrl/modules/tensordict_module/__init__.py,sha256=qHcF6ojIDJhLf6loG83CeFC-H4G5yoB98Hv4S3jq-i4,710
-torchrl/modules/tensordict_module/actors.py,sha256=93gviInviU-C_aRQaeCrNs3icDfqZvbXib-dxrx6hUY,37611
-torchrl/modules/tensordict_module/common.py,sha256=gqefJA9PFR2u748Q9d2rUOE-GqhY26JDpLDyyQLGSvI,16488
-torchrl/modules/tensordict_module/exploration.py,sha256=DGFxVrWqVjgTAEMWXq6gUnoWfSHlyCi2lJ6G1OmyFnk,18755
-torchrl/modules/tensordict_module/probabilistic.py,sha256=yNwctOFRB4c-XXqjnw4c93A9gR6nKoBN07WzjwCweHQ,11277
-torchrl/modules/tensordict_module/sequence.py,sha256=5g-R6pKRlvyMwUbSuNUGruaxvCnJXmfix2n9_RPglyo,5828
-torchrl/modules/tensordict_module/world_models.py,sha256=Imr9P7Jkwbwdb2UXv-F4mGVe0j92qLJtvI__qbWpxes,1318
-torchrl/modules/utils/__init__.py,sha256=CbbG_Ev3PP7s3_1gYbaU8bEv7GmBjjEMl4vFC7ET1Fk,3982
+torchrl/modules/planners/mppi.py,sha256=cKkB8ql7D82khYSdbSxxyHa8Ph3j2ciaPfazdolKHv4,10683
+torchrl/modules/tensordict_module/__init__.py,sha256=Wd-MwreePr0k8ALbZ822R6O151ZvrxTZLWlt9RIVr1w,865
+torchrl/modules/tensordict_module/actors.py,sha256=-dKczuk7NgrFgnEqxJWFXVDmA5KqBGp0Ufz6OUgWiI8,71610
+torchrl/modules/tensordict_module/common.py,sha256=l9sT0BWxqKWZ_OxzJ14aeWitz3ZTpzc6SWUBdkY1cWE,17209
+torchrl/modules/tensordict_module/exploration.py,sha256=8nXpmPYYATGOuEvDh9g4hVd6jIuJcaC7L5IHSwslbrE,24439
+torchrl/modules/tensordict_module/probabilistic.py,sha256=rVUpYscVh36pHDerq7QtbgASGnLI0590E2aBh2FZJIk,11471
+torchrl/modules/tensordict_module/rnn.py,sha256=oeyAAVrvcoFicPsLjPZjHDhNYsdj1i_VPqE0DJDgc3I,18148
+torchrl/modules/tensordict_module/sequence.py,sha256=3K4ay54sFCzNMI9E83wVmPiZwTEYaIcYNioxpOOmyzU,5838
+torchrl/modules/tensordict_module/world_models.py,sha256=9qlJKd1GDKeVtkTNRg9eUpx6AGzKCiABOVX40jxUnqU,1360
+torchrl/modules/utils/__init__.py,sha256=YDiFNwjc0U8SD_WoTpTroQ-J2aaXuaTLnkR1sP8EXjk,3984
 torchrl/modules/utils/mappings.py,sha256=ZurH7TLCDroHVzRTFcBajy6btc-dECLNh_pP1iM0ne4,2435
-torchrl/objectives/__init__.py,sha256=iQAld57jZF0K0RPJJmri4-8AOD9jw4XSHTTSrSPt994,829
-torchrl/objectives/a2c.py,sha256=dKi43uQNVWo-ahFHkF0TbmlomLqtdmo3Wqxuv8_R-Bo,5863
-torchrl/objectives/common.py,sha256=YfrA0Z7GBS8yBE_zkGc0idW4Y2X998h8hAl-CO-gprw,14310
-torchrl/objectives/ddpg.py,sha256=PnWFFet5edJwkgtQBZ68yvu0SrzOydUUWeX0eIOQFj0,6564
-torchrl/objectives/deprecated.py,sha256=WcNP62TBifJAhFL-KOoiZVVeVNA687wU2dYFTqR243g,10691
-torchrl/objectives/dqn.py,sha256=fAkbBQ_qMe9hHG4NpWLlMsz6VlJQNboLSeZufZP_4sg,12339
-torchrl/objectives/dreamer.py,sha256=VOmhgCzRRbuKuP-LR9nzIF2YZD1e-EPujzNqbUzPN6c,10819
+torchrl/modules/utils/utils.py,sha256=IOXtM_-Ru-wvmZCQNNZCeIJhwnYB40vtP2cLdFPHq5Q,1368
+torchrl/objectives/__init__.py,sha256=ngQ_RE4aeDchY6DojoTy1XiAqfUZOWyi7y6ZW43_e1E,895
+torchrl/objectives/a2c.py,sha256=RR1KW8imT37B6SUoXS6qkLRipgsi4BeWQTOX5kj9-tU,9506
+torchrl/objectives/common.py,sha256=tmoaeJyuEnOsdeV0P-JnLOUurQVwlhBdKqqmb82usew,23370
+torchrl/objectives/ddpg.py,sha256=H_HIRX626wrFRUxsfxUBgOSg-87lWHbmOrDlcnPcKv4,7549
+torchrl/objectives/deprecated.py,sha256=wB6xWQ_hZJlJGahPPTR7cY3qv313gjbWwM5ZtGf87Lg,12829
+torchrl/objectives/dqn.py,sha256=m2n_RoQJfdxK-8NXfOgD2FbvRCaQcVlrWKvmdFac0Qg,17568
+torchrl/objectives/dreamer.py,sha256=3r3hK2J4J3-y6hZ2cCz0pMZLkkpRhAYMz2O7mXxrSwU,13161
 torchrl/objectives/functional.py,sha256=BzT7OBk-FOoIYPaXBx73eOHAeEc6LnjRJeL472AWMHI,2119
-torchrl/objectives/iql.py,sha256=BauPnU2_W7Okx2r3VwayBc45Dj6D9hhedK5EZ2kFuWU,9414
-torchrl/objectives/ppo.py,sha256=PM-xjTgqp3gMaYoRYoSM-DPgT6sdKgS6SnABWk3UHl0,17489
-torchrl/objectives/redq.py,sha256=GervqFCePn2u20oioOtbaawimEr4PPcmkOQzcsHkc3A,12398
-torchrl/objectives/reinforce.py,sha256=KBtbrcu9lfa9I54AXCqFHGIRQDjtdhzhZKLnzF1PUN4,3474
-torchrl/objectives/sac.py,sha256=bVUG6ydJ46MKFB-fG8jJXqKYkBu6KpCD95j9mLIBq3U,16418
-torchrl/objectives/td3.py,sha256=LDrMm8ifAIyMo9NOxEr03991I9b9tjSRAwtiiqS0Gnw,8291
-torchrl/objectives/utils.py,sha256=mp2q9hv5TVunxtiNK94YaLuyeNBJv1n5nJinqVuH7gY,12368
-torchrl/objectives/value/__init__.py,sha256=fPoKYs3luWqvjvv8ncafGHx-SFxfbF2wRd-9FIx_BaE,244
-torchrl/objectives/value/advantages.py,sha256=7C5KlkvXNQssujj2UsJNz0HpkvtonR1Sq4H30aEa33g,24520
-torchrl/objectives/value/functional.py,sha256=GOqPY1GNOkmYhS5YabiujKLiiwVBSx8G9RCxiYK4IZ0,20126
+torchrl/objectives/iql.py,sha256=RWesIylFsFqD-pQT_BjXYPBPZBTHQAuf-pKBaA4fTqQ,10465
+torchrl/objectives/ppo.py,sha256=jhMoQLS8zgauBHnSMWm41sEnbOMltPnakEvkpSIlDeE,29370
+torchrl/objectives/redq.py,sha256=yDrazUDHyMsqiD7SoJf3vT0xOW3Wt9a7SBV_KPJqQgQ,14194
+torchrl/objectives/reinforce.py,sha256=TjoKsR-YrE38y0MOJGJ2mbhCVgBOZivez4Y3B2cjlpM,7221
+torchrl/objectives/sac.py,sha256=_gRjlyOR42C2nR2tujAJKnOK5kHfgXbkWi4rf6ISXWg,30845
+torchrl/objectives/td3.py,sha256=g1UwIf4E9Eb5n9pmY3hi984fe59ojQcHNkL_aqp9ArU,9845
+torchrl/objectives/utils.py,sha256=napvMKw4kEgsr2m5oWIlZOV7LBqJd7gB17BXZwPtiEs,14764
+torchrl/objectives/value/__init__.py,sha256=3YD7d9rTodAFMFj74ugS-25CaDU2b6mVv466Sx1iNiw,371
+torchrl/objectives/value/advantages.py,sha256=zzGupaUPDh8LTja0h75vijz56igeBvTyNSsYkNqC6kE,42893
+torchrl/objectives/value/functional.py,sha256=0fP77cClR03TcIjrHvqMV292Lxg4-GAaGn4rn4-eSJ4,41525
 torchrl/objectives/value/pg.py,sha256=fM3XbHBkiT1FTfENSF8RkkZ3ZTJOLaaXTA99E74KQlU,317
-torchrl/objectives/value/utils.py,sha256=VZ9kdN0Hv-BBMoiF6Y9vzuZn3Ik9Xfvb-OKwag9ZS0Y,7629
+torchrl/objectives/value/utils.py,sha256=unoSMfzHO05sM3fqqsdx6N--cGDXzFUbu4hYENobnYw,7683
 torchrl/objectives/value/vtrace.py,sha256=hEc0WuYrixYDM7c7w_P7yU0NVGEkOXcqBQaanGeRqX8,1724
 torchrl/record/__init__.py,sha256=T0-JvaHHfgq8BsZtVFKcLfOYj-j9Ssws7dXvUKBX3pE,242
-torchrl/record/recorder.py,sha256=Nd9bM7yaj4k_DidHTltaiOWcOdqx4Bh-NzgOvN5T32o,6831
+torchrl/record/recorder.py,sha256=9h0h_6lw0ZZ6qstbGVJsdDpRY9aw6CXTgRhC3n8GNV4,6839
 torchrl/record/loggers/__init__.py,sha256=KsUdcrrM7nPvyHaSDvoqFsVRux1sFpsWi12y76zvt0c,413
 torchrl/record/loggers/common.py,sha256=d87eOL6fmHwIoeLoZTUsVVVjJlihd_LWo2GYq7hlY_g,1130
-torchrl/record/loggers/csv.py,sha256=_UrwHAGIyqrOoqum1wKW1oWFXoBzRsc2fIhrCy_F4RI,4650
+torchrl/record/loggers/csv.py,sha256=_43-GkHNKLwlDzFG_m1g-Ewqu_l0aP1gKJlmds1yBSI,4709
 torchrl/record/loggers/mlflow.py,sha256=iWZOI-yRzovF9_2MjCNsH1TFNmjcPcWSjC8fOJ_pkhs,4344
 torchrl/record/loggers/tensorboard.py,sha256=U1DHSGVC_yj0pxP7Db-Vzhn3BquymAOvbMktwSSpwDo,3412
 torchrl/record/loggers/utils.py,sha256=bOVmPOK3YPCHwajfkyyF7PNvjz4GnM09AYsgLw7oH3k,2248
 torchrl/record/loggers/wandb.py,sha256=omcjDccUzgARipO7uvI1zXeV4G-fMGefdf4OZm3Azzo,6025
 torchrl/trainers/__init__.py,sha256=f9u3CLeSN-LpSsS709rahhHGm4G1KK2bqB2l0F7NxME,467
-torchrl/trainers/trainers.py,sha256=oraIAFOkp1HXuhJPAZ_o9GfAgg20XxmNwGOg-_wgfEA,49723
+torchrl/trainers/trainers.py,sha256=9GijOHo0k-rV-Zp_fHtEz3JzAmYH9n9C1GGAO9dMohc,52048
 torchrl/trainers/helpers/__init__.py,sha256=olPgYXwiN0mmsE4DistxVdmnAXAHGm5RL5YeKLmmTUM,942
-torchrl/trainers/helpers/collectors.py,sha256=vUlKjvD8bXslKUogGFKqz0pDUNSuqkjiuWfvbyxumHc,19204
-torchrl/trainers/helpers/envs.py,sha256=3s9g9kcCde_1ym8RfjT_F8oCPpODZF96CLS03oUAojY,22562
+torchrl/trainers/helpers/collectors.py,sha256=bA0vf2EZk-CNOMSXV2N1Kqlfsr4EQPGceO_FaGM1iAY,19309
+torchrl/trainers/helpers/envs.py,sha256=pXneijTiHMR0PCVx3Z3VotuLZg9aw_14oMIf70cpWBM,22620
 torchrl/trainers/helpers/logger.py,sha256=aRoSh9zpXy46MTqhqZBoCuKZko2LN-SePiAWgX9W5iA,1206
-torchrl/trainers/helpers/losses.py,sha256=0A2nmFHAbEWu8ZVbByxkqRXxauvBNT3QyTIe2q7fXRc,10928
-torchrl/trainers/helpers/models.py,sha256=XagLMFA-GUdF_vC1cBgrS1_bbO3tsx-MgqmxJVP3Qko,76993
-torchrl/trainers/helpers/replay_buffer.py,sha256=3LcHmFsOP1oQLNVtJbbdGHXoLaTEQSa6tYFDArd20uI,1903
-torchrl/trainers/helpers/trainers.py,sha256=NJO-9m57OPWDQD-Hs1niNutsvLREfyc-KdC6KeM61lc,11891
-torchrl-0.1.0.dist-info/LICENSE,sha256=PGO-oZsq4EzhE1-WQS2xGiEF3UCVb9YawfQ09cIMV_8,1119
-torchrl-0.1.0.dist-info/METADATA,sha256=OVsYL8xBplHFdqnbltx4C4-LXUk9IGMk-4tfOC2zMkg,28394
-torchrl-0.1.0.dist-info/WHEEL,sha256=eep6QWEFiQfg2wcclssb_WY-D33AnLYLnEKGA9Rn-VU,100
-torchrl-0.1.0.dist-info/top_level.txt,sha256=JeTJ1jV7QJwLcUS1nr21aPn_wb-XlAZ9c-z_EH472JA,20
-torchrl-0.1.0.dist-info/RECORD,,
+torchrl/trainers/helpers/losses.py,sha256=rS1ZSBM1h3Pk1rStsdLBpJHLYXKRFGEcmnF7YpnZkvw,10920
+torchrl/trainers/helpers/models.py,sha256=pubTyfqMpYbzbDshiQZ3jXb5j906pFADhQ4QLNUoujM,77293
+torchrl/trainers/helpers/replay_buffer.py,sha256=R9kriPfZOJ1s-kaGkn2w4tcZH2iC-u22pWQwqqw3c-A,1939
+torchrl/trainers/helpers/trainers.py,sha256=H76tq76L5t-6S-z22F9RAYjxiOO2RSNvs4IXuPn22Ok,12076
+torchrl-0.1.1.dist-info/LICENSE,sha256=PGO-oZsq4EzhE1-WQS2xGiEF3UCVb9YawfQ09cIMV_8,1119
+torchrl-0.1.1.dist-info/METADATA,sha256=gOzH167FfFRLcc-FvCjekYoD_Y0mr8uh39DpzgNkR1A,28554
+torchrl-0.1.1.dist-info/WHEEL,sha256=eep6QWEFiQfg2wcclssb_WY-D33AnLYLnEKGA9Rn-VU,100
+torchrl-0.1.1.dist-info/top_level.txt,sha256=JeTJ1jV7QJwLcUS1nr21aPn_wb-XlAZ9c-z_EH472JA,20
+torchrl-0.1.1.dist-info/RECORD,,
```

